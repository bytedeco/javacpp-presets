diff -ruN tensorflow-1.15.3/tensorflow/core/kernels/bincount_op_gpu.cu.cc tensorflow-1.15.3-cuda11/tensorflow/core/kernels/bincount_op_gpu.cu.cc
--- tensorflow-1.15.3/tensorflow/core/kernels/bincount_op_gpu.cu.cc	2020-05-15 07:21:31.000000000 +0900
+++ tensorflow-1.15.3-cuda11/tensorflow/core/kernels/bincount_op_gpu.cu.cc	2020-06-13 08:56:51.785446100 +0900
@@ -18,7 +18,7 @@
 #define EIGEN_USE_GPU
 
 #if GOOGLE_CUDA
-#include "third_party/cub/device/device_histogram.cuh"
+#include "cub/device/device_histogram.cuh"
 #elif TENSORFLOW_USE_ROCM
 #include "external/rocprim_archive/hipcub/include/hipcub/hipcub.hpp"
 #endif
diff -ruN tensorflow-1.15.3/tensorflow/core/kernels/BUILD tensorflow-1.15.3-cuda11/tensorflow/core/kernels/BUILD
--- tensorflow-1.15.3/tensorflow/core/kernels/BUILD	2020-05-15 07:21:31.000000000 +0900
+++ tensorflow-1.15.3-cuda11/tensorflow/core/kernels/BUILD	2020-06-13 08:53:43.025172700 +0900
@@ -1339,8 +1339,6 @@
     ],
     deps = if_cuda_or_rocm([
         ":cuda_solvers",
-    ]) + if_cuda([
-        "@cub_archive//:cub",
     ]) + if_rocm([
         "@rocprim_archive//:rocprim",
     ]) + ARRAY_DEPS,
@@ -2502,7 +2500,7 @@
     deps = DYNAMIC_DEPS + [
         ":fill_functor",
         ":gather_functor",
-    ] + if_cuda(["@cub_archive//:cub"]) + if_rocm([
+    ] + if_rocm([
         "@rocprim_archive//:rocprim",
     ]),
 )
@@ -2905,7 +2903,7 @@
 tf_kernel_library(
     name = "non_max_suppression_op",
     prefix = "non_max_suppression_op",
-    deps = IMAGE_DEPS + if_cuda(["@cub_archive//:cub"]),
+    deps = IMAGE_DEPS,
 )
 
 tf_kernel_library(
@@ -3823,9 +3821,8 @@
     name = "reduction_ops",
     gpu_srcs = ["reduction_gpu_kernels.cu.h"],
     prefix = "reduction_ops",
-    deps = MATH_DEPS + [":transpose_functor"] + if_cuda([
-        "@cub_archive//:cub",
-    ]) + if_rocm([
+    deps = MATH_DEPS + [":transpose_functor"] +
+    if_rocm([
         "@rocprim_archive//:rocprim",
     ]),
 )
@@ -3850,9 +3847,8 @@
         "scan_ops_gpu_half.cu.cc",
         "scan_ops_gpu_int.cu.cc",
     ],
-    deps = MATH_DEPS + if_cuda([
-        "@cub_archive//:cub",
-    ]) + if_rocm([
+    deps = MATH_DEPS +
+    if_rocm([
         "@rocprim_archive//:rocprim",
     ]),
 )
@@ -4284,7 +4280,6 @@
         "//tensorflow/core:framework",
         "//tensorflow/core:lib",
     ] + if_cuda([
-        "@cub_archive//:cub",
         "@local_config_cuda//cuda:cudnn_header",
     ]) + if_rocm([
         "@rocprim_archive//:rocprim",
@@ -4373,7 +4368,6 @@
     ] + if_cuda_or_rocm([
         ":reduction_ops",
     ]) + if_cuda([
-        "@cub_archive//:cub",
         "//tensorflow/core:stream_executor",
         "//tensorflow/stream_executor/cuda:cuda_stream",
     ]) + if_rocm([
@@ -4415,8 +4409,6 @@
     prefix = "softmax_op",
     deps = NN_DEPS + if_cuda_or_rocm([
         ":reduction_ops",
-    ]) + if_cuda([
-        "@cub_archive//:cub",
     ]) + if_rocm([
         "@rocprim_archive//:rocprim",
     ]),
@@ -4451,9 +4443,8 @@
         "topk_op_gpu_int8.cu.cc",
         "topk_op_gpu_uint8.cu.cc",
     ],
-    deps = NN_DEPS + if_cuda([
-        "@cub_archive//:cub",
-    ]) + if_rocm([
+    deps = NN_DEPS +
+    if_rocm([
         "@rocprim_archive//:rocprim",
     ]),
 )
@@ -4478,7 +4469,7 @@
         "//tensorflow/core:lib",
         "//tensorflow/core:lib_internal",
         "//third_party/eigen3",
-    ] + if_cuda(["@cub_archive//:cub"]) + if_rocm([
+    ] + if_rocm([
         "@rocprim_archive//:rocprim",
     ]),
 )
@@ -4491,7 +4482,7 @@
         "//tensorflow/core:lib",
         "//tensorflow/core:lib_internal",
         "//third_party/eigen3",
-    ] + if_cuda(["@cub_archive//:cub"]) + if_rocm([
+    ] + if_rocm([
         "@rocprim_archive//:rocprim",
     ]),
 )
@@ -4506,7 +4497,7 @@
         "//tensorflow/core:lib",
         "//tensorflow/core:lib_internal",
         "//tensorflow/core:nn_grad",
-    ] + if_cuda(["@cub_archive//:cub"]) + if_rocm([
+    ] + if_rocm([
         "@rocprim_archive//:rocprim",
     ]),
 )
@@ -5084,8 +5075,6 @@
         "//third_party/eigen3",
     ] + if_cuda_or_rocm([
         ":reduction_ops",
-    ]) + if_cuda([
-        "@cub_archive//:cub",
     ]) + if_rocm([
         "@rocprim_archive//:rocprim",
     ]),
@@ -5637,8 +5626,6 @@
         "//tensorflow/core:lib_internal",
     ] + if_cuda_or_rocm([
         ":reduction_ops",
-    ]) + if_cuda([
-        "@cub_archive//:cub",
     ]) + if_rocm([
         "@rocprim_archive//:rocprim",
     ]),
diff -ruN tensorflow-1.15.3/tensorflow/core/kernels/cuda_sparse.cc tensorflow-1.15.3-cuda11/tensorflow/core/kernels/cuda_sparse.cc
--- tensorflow-1.15.3/tensorflow/core/kernels/cuda_sparse.cc	2020-05-15 07:21:31.000000000 +0900
+++ tensorflow-1.15.3-cuda11/tensorflow/core/kernels/cuda_sparse.cc	2020-06-13 08:56:52.055022000 +0900
@@ -188,7 +188,7 @@
 // to immutable arguments, while the actual headers have them as expected.
 // Check the actual declarations in the cusparse.h header file.
 //=============================================================================
-
+#if 0
 template <typename Scalar, typename SparseFn>
 static inline Status GtsvImpl(SparseFn op, cusparseHandle_t cusparse_handle,
                               int m, int n, const Scalar* dl, const Scalar* d,
@@ -248,7 +248,7 @@
   }
 
 TF_CALL_LAPACK_TYPES(GTSV_STRIDED_BATCH_INSTANCE);
-
+#endif
 template <typename Scalar, typename SparseFn>
 static inline Status Gtsv2Impl(SparseFn op, cusparseHandle_t cusparse_handle,
                                int m, int n, const Scalar* dl, const Scalar* d,
diff -ruN tensorflow-1.15.3/tensorflow/core/kernels/dynamic_partition_op_gpu.cu.cc tensorflow-1.15.3-cuda11/tensorflow/core/kernels/dynamic_partition_op_gpu.cu.cc
--- tensorflow-1.15.3/tensorflow/core/kernels/dynamic_partition_op_gpu.cu.cc	2020-05-15 07:21:31.000000000 +0900
+++ tensorflow-1.15.3-cuda11/tensorflow/core/kernels/dynamic_partition_op_gpu.cu.cc	2020-06-13 08:56:52.819630500 +0900
@@ -36,10 +36,10 @@
 #define EIGEN_USE_GPU
 
 #if GOOGLE_CUDA
-#include "third_party/cub/device/device_radix_sort.cuh"
-#include "third_party/cub/device/device_reduce.cuh"
-#include "third_party/cub/iterator/constant_input_iterator.cuh"
-#include "third_party/cub/thread/thread_operators.cuh"
+#include "cub/device/device_radix_sort.cuh"
+#include "cub/device/device_reduce.cuh"
+#include "cub/iterator/constant_input_iterator.cuh"
+#include "cub/thread/thread_operators.cuh"
 #elif TENSORFLOW_USE_ROCM
 #include "external/rocprim_archive/hipcub/include/hipcub/hipcub.hpp"
 #endif
diff -ruN tensorflow-1.15.3/tensorflow/core/kernels/histogram_op_gpu.cu.cc tensorflow-1.15.3-cuda11/tensorflow/core/kernels/histogram_op_gpu.cu.cc
--- tensorflow-1.15.3/tensorflow/core/kernels/histogram_op_gpu.cu.cc	2020-05-15 07:21:31.000000000 +0900
+++ tensorflow-1.15.3-cuda11/tensorflow/core/kernels/histogram_op_gpu.cu.cc	2020-06-13 08:56:53.089243000 +0900
@@ -19,7 +19,7 @@
 
 #include "third_party/eigen3/unsupported/Eigen/CXX11/Tensor"
 #if GOOGLE_CUDA
-#include "third_party/cub/device/device_histogram.cuh"
+#include "cub/device/device_histogram.cuh"
 #elif TENSORFLOW_USE_ROCM
 #include "external/rocprim_archive/hipcub/include/hipcub/hipcub.hpp"
 #endif
diff -ruN tensorflow-1.15.3/tensorflow/core/kernels/non_max_suppression_op.cu.cc tensorflow-1.15.3-cuda11/tensorflow/core/kernels/non_max_suppression_op.cu.cc
--- tensorflow-1.15.3/tensorflow/core/kernels/non_max_suppression_op.cu.cc	2020-05-15 07:21:31.000000000 +0900
+++ tensorflow-1.15.3-cuda11/tensorflow/core/kernels/non_max_suppression_op.cu.cc	2020-06-13 08:56:53.421364500 +0900
@@ -19,9 +19,9 @@
 
 #include "absl/strings/str_cat.h"
 #include "third_party/eigen3/unsupported/Eigen/CXX11/Tensor"
-#include "third_party/cub/device/device_radix_sort.cuh"
-#include "third_party/cub/device/device_segmented_radix_sort.cuh"
-#include "third_party/cub/device/device_select.cuh"
+#include "cub/device/device_radix_sort.cuh"
+#include "cub/device/device_segmented_radix_sort.cuh"
+#include "cub/device/device_select.cuh"
 #include "tensorflow/core/framework/numeric_types.h"
 #include "tensorflow/core/framework/op_kernel.h"
 #include "tensorflow/core/framework/tensor_types.h"
diff -ruN tensorflow-1.15.3/tensorflow/core/kernels/reduction_gpu_kernels.cu.h tensorflow-1.15.3-cuda11/tensorflow/core/kernels/reduction_gpu_kernels.cu.h
--- tensorflow-1.15.3/tensorflow/core/kernels/reduction_gpu_kernels.cu.h	2020-05-15 07:21:31.000000000 +0900
+++ tensorflow-1.15.3-cuda11/tensorflow/core/kernels/reduction_gpu_kernels.cu.h	2020-06-13 08:54:57.862648000 +0900
@@ -24,11 +24,11 @@
 
 #include "third_party/eigen3/unsupported/Eigen/CXX11/Tensor"
 #if GOOGLE_CUDA
-#include "third_party/cub/device/device_reduce.cuh"
-#include "third_party/cub/device/device_segmented_reduce.cuh"
-#include "third_party/cub/iterator/counting_input_iterator.cuh"
-#include "third_party/cub/iterator/transform_input_iterator.cuh"
-#include "third_party/cub/warp/warp_reduce.cuh"
+#include "cub/device/device_reduce.cuh"
+#include "cub/device/device_segmented_reduce.cuh"
+#include "cub/iterator/counting_input_iterator.cuh"
+#include "cub/iterator/transform_input_iterator.cuh"
+#include "cub/warp/warp_reduce.cuh"
 #include "third_party/gpus/cuda/include/cuComplex.h"
 #elif TENSORFLOW_USE_ROCM
 #include "external/rocprim_archive/hipcub/include/hipcub/hipcub.hpp"
diff -ruN tensorflow-1.15.3/tensorflow/core/kernels/scan_ops_gpu.h tensorflow-1.15.3-cuda11/tensorflow/core/kernels/scan_ops_gpu.h
--- tensorflow-1.15.3/tensorflow/core/kernels/scan_ops_gpu.h	2020-05-15 07:21:31.000000000 +0900
+++ tensorflow-1.15.3-cuda11/tensorflow/core/kernels/scan_ops_gpu.h	2020-06-13 08:54:50.786563200 +0900
@@ -25,11 +25,11 @@
 #endif  // CUDA_VERSION >= 9000
 
 #if GOOGLE_CUDA
-#include "third_party/cub/block/block_load.cuh"
-#include "third_party/cub/block/block_scan.cuh"
-#include "third_party/cub/block/block_store.cuh"
-#include "third_party/cub/iterator/counting_input_iterator.cuh"
-#include "third_party/cub/iterator/transform_input_iterator.cuh"
+#include "cub/block/block_load.cuh"
+#include "cub/block/block_scan.cuh"
+#include "cub/block/block_store.cuh"
+#include "cub/iterator/counting_input_iterator.cuh"
+#include "cub/iterator/transform_input_iterator.cuh"
 #include "third_party/gpus/cuda/include/cuComplex.h"
 #elif TENSORFLOW_USE_ROCM
 #include "external/rocprim_archive/hipcub/include/hipcub/hipcub.hpp"
diff -ruN tensorflow-1.15.3/tensorflow/core/kernels/topk_op_gpu.h tensorflow-1.15.3-cuda11/tensorflow/core/kernels/topk_op_gpu.h
--- tensorflow-1.15.3/tensorflow/core/kernels/topk_op_gpu.h	2020-05-15 07:21:31.000000000 +0900
+++ tensorflow-1.15.3-cuda11/tensorflow/core/kernels/topk_op_gpu.h	2020-06-13 08:54:50.886825000 +0900
@@ -23,9 +23,9 @@
 #include <vector>
 
 #include "third_party/eigen3/unsupported/Eigen/CXX11/Tensor"
-#include "third_party/cub/device/device_segmented_radix_sort.cuh"
-#include "third_party/cub/iterator/counting_input_iterator.cuh"
-#include "third_party/cub/iterator/transform_input_iterator.cuh"
+#include "cub/device/device_segmented_radix_sort.cuh"
+#include "cub/iterator/counting_input_iterator.cuh"
+#include "cub/iterator/transform_input_iterator.cuh"
 #include "tensorflow/core/framework/op_kernel.h"
 #include "tensorflow/core/framework/register_types.h"
 #include "tensorflow/core/framework/tensor.h"
diff -ruN tensorflow-1.15.3/tensorflow/core/kernels/where_op_gpu.cu.h tensorflow-1.15.3-cuda11/tensorflow/core/kernels/where_op_gpu.cu.h
--- tensorflow-1.15.3/tensorflow/core/kernels/where_op_gpu.cu.h	2020-05-15 07:21:31.000000000 +0900
+++ tensorflow-1.15.3-cuda11/tensorflow/core/kernels/where_op_gpu.cu.h	2020-06-13 08:54:57.878272200 +0900
@@ -22,10 +22,10 @@
 
 #include "third_party/eigen3/unsupported/Eigen/CXX11/Tensor"
 #if GOOGLE_CUDA
-#include "third_party/cub/device/device_reduce.cuh"
-#include "third_party/cub/device/device_select.cuh"
-#include "third_party/cub/iterator/counting_input_iterator.cuh"
-#include "third_party/cub/iterator/transform_input_iterator.cuh"
+#include "cub/device/device_reduce.cuh"
+#include "cub/device/device_select.cuh"
+#include "cub/iterator/counting_input_iterator.cuh"
+#include "cub/iterator/transform_input_iterator.cuh"
 #elif TENSORFLOW_USE_ROCM
 #include "external/rocprim_archive/hipcub/include/hipcub/hipcub.hpp"
 #endif
diff -ruN tensorflow-1.15.3/tensorflow/stream_executor/cuda/cublas_10_0.inc tensorflow-1.15.3-cuda11/tensorflow/stream_executor/cuda/cublas_10_0.inc
--- tensorflow-1.15.3/tensorflow/stream_executor/cuda/cublas_10_0.inc	2020-05-15 07:21:31.000000000 +0900
+++ tensorflow-1.15.3-cuda11/tensorflow/stream_executor/cuda/cublas_10_0.inc	2020-06-13 08:52:31.229682000 +0900
@@ -2227,9 +2227,9 @@
                                                       void *C,
                                                       cudaDataType Ctype,
                                                       int ldc,
-                                                      cudaDataType computeType,
+                                                      cublasComputeType_t computeType,
                                                       cublasGemmAlgo_t algo) {
-  using FuncPtr = cublasStatus_t (CUBLASWINAPI *)(cublasHandle_t, cublasOperation_t, cublasOperation_t, int, int, int, const void *, const void *, cudaDataType, int, const void *, cudaDataType, int, const void *, void *, cudaDataType, int, cudaDataType, cublasGemmAlgo_t);
+  using FuncPtr = cublasStatus_t (CUBLASWINAPI *)(cublasHandle_t, cublasOperation_t, cublasOperation_t, int, int, int, const void *, const void *, cudaDataType, int, const void *, cudaDataType, int, const void *, void *, cudaDataType, int, cublasComputeType_t, cublasGemmAlgo_t);
   static auto func_ptr = LoadSymbol<FuncPtr>("cublasGemmEx");
   if (!func_ptr) return GetSymbolNotFoundError();
   return func_ptr(handle, transa, transb, m, n, k, alpha, A, Atype, lda, B, Btype, ldb, beta, C, Ctype, ldc, computeType, algo);
@@ -3061,9 +3061,9 @@
                                                       cudaDataType Ctype,
                                                       int ldc,
                                                       int batchCount,
-                                                      cudaDataType computeType,
+                                                      cublasComputeType_t computeType,
                                                       cublasGemmAlgo_t algo) {
-  using FuncPtr = cublasStatus_t (CUBLASWINAPI *)(cublasHandle_t, cublasOperation_t, cublasOperation_t, int, int, int, const void *, const void *const [], cudaDataType, int, const void *const [], cudaDataType, int, const void *, void *const [], cudaDataType, int, int, cudaDataType, cublasGemmAlgo_t);
+  using FuncPtr = cublasStatus_t (CUBLASWINAPI *)(cublasHandle_t, cublasOperation_t, cublasOperation_t, int, int, int, const void *, const void *const [], cudaDataType, int, const void *const [], cudaDataType, int, const void *, void *const [], cudaDataType, int, int, cublasComputeType_t, cublasGemmAlgo_t);
   static auto func_ptr = LoadSymbol<FuncPtr>("cublasGemmBatchedEx");
   if (!func_ptr) return GetSymbolNotFoundError();
   return func_ptr(handle, transa, transb, m, n, k, alpha, Aarray, Atype, lda, Barray, Btype, ldb, beta, Carray, Ctype, ldc, batchCount, computeType, algo);
@@ -3090,9 +3090,9 @@
                                                                  int ldc,
                                                                  long long int strideC,
                                                                  int batchCount,
-                                                                 cudaDataType computeType,
+                                                                 cublasComputeType_t computeType,
                                                                  cublasGemmAlgo_t algo) {
-  using FuncPtr = cublasStatus_t (CUBLASWINAPI *)(cublasHandle_t, cublasOperation_t, cublasOperation_t, int, int, int, const void *, const void *, cudaDataType, int, long long, const void *, cudaDataType, int, long long, const void *, void *, cudaDataType, int, long long, int, cudaDataType, cublasGemmAlgo_t);
+  using FuncPtr = cublasStatus_t (CUBLASWINAPI *)(cublasHandle_t, cublasOperation_t, cublasOperation_t, int, int, int, const void *, const void *, cudaDataType, int, long long, const void *, cudaDataType, int, long long, const void *, void *, cudaDataType, int, long long, int, cublasComputeType_t, cublasGemmAlgo_t);
   static auto func_ptr = LoadSymbol<FuncPtr>("cublasGemmStridedBatchedEx");
   if (!func_ptr) return GetSymbolNotFoundError();
   return func_ptr(handle, transa, transb, m, n, k, alpha, A, Atype, lda, strideA, B, Btype, ldb, strideB, beta, C, Ctype, ldc, strideC, batchCount, computeType, algo);
diff -ruN tensorflow-1.15.3/tensorflow/stream_executor/cuda/cuda_blas.cc tensorflow-1.15.3-cuda11/tensorflow/stream_executor/cuda/cuda_blas.cc
--- tensorflow-1.15.3/tensorflow/stream_executor/cuda/cuda_blas.cc	2020-05-15 07:21:31.000000000 +0900
+++ tensorflow-1.15.3-cuda11/tensorflow/stream_executor/cuda/cuda_blas.cc	2020-06-13 08:56:59.864015200 +0900
@@ -1944,7 +1944,7 @@
     return false;
   }
 #endif
-
+#if 0
   cudaDataType_t cuda_in_type = CUDADataType<InT>::type;
   // Since we are converting 'algorithm' to cublasGemmAlgo_t by static_cast,
   // we do the following compile-time check on the default value:
@@ -1976,6 +1976,8 @@
         timer->GetElapsedMilliseconds());
   }
   return result;
+#endif
+  return false;
 }
 
 bool CUDABlas::GetBlasGemmAlgorithms(
@@ -2209,7 +2211,7 @@
 
   cudaDataType_t data_type = CUDADataType<T>::type;
 
-#if CUDA_VERSION >= 9010
+#if 0
   int cc_major, cc_minor;
   if (stream->parent()->GetDeviceDescription().cuda_compute_capability(
           &cc_major, &cc_minor) &&
@@ -2217,7 +2219,7 @@
     bool use_tensor_ops = TensorOpMathEnabled() && data_type == CUDA_R_16F;
     cublasGemmAlgo_t algo =
         (use_tensor_ops ? CUBLAS_GEMM_DFALT_TENSOR_OP : CUBLAS_GEMM_DFALT);
-    cudaDataType_t compute_type =
+    cublasComputeType_t compute_type = (cublasComputeType_t)
         (data_type == CUDA_R_16F ? CUDA_R_32F : data_type);
     const void **a_void_ptrs = reinterpret_cast<const void **>(
         const_cast<const CUDA_T **>(GpuMemory(a)));
@@ -2370,7 +2372,7 @@
     if (cc_major >= 7 && TensorOpMathEnabled()) {
       use_tensor_ops = true;
     }
-#if CUDA_VERSION >= 9010
+#if 0
     if (cc_major >= 5) {
       cublasGemmAlgo_t algo =
           (use_tensor_ops ? CUBLAS_GEMM_DFALT_TENSOR_OP : CUBLAS_GEMM_DFALT);
@@ -2380,7 +2382,7 @@
           CUDABlasTranspose(transa), CUDABlasTranspose(transb), m, n, k, &alpha,
           GpuMemory(a), CUDA_R_16F, lda, stride_a, GpuMemory(b), CUDA_R_16F,
           ldb, stride_b, &beta, GpuMemoryMutable(c), CUDA_R_16F, ldc, stride_c,
-          batch_count, CUDA_R_32F, algo);
+          batch_count, (cublasComputeType_t)CUDA_R_32F, algo);
       if (ok) {
         return true;
       }
diff -ruN tensorflow-1.15.3/tensorflow/stream_executor/cuda/cuda_dnn.cc tensorflow-1.15.3-cuda11/tensorflow/stream_executor/cuda/cuda_dnn.cc
--- tensorflow-1.15.3/tensorflow/stream_executor/cuda/cuda_dnn.cc	2020-05-15 07:21:31.000000000 +0900
+++ tensorflow-1.15.3-cuda11/tensorflow/stream_executor/cuda/cuda_dnn.cc	2020-06-13 08:56:59.879636400 +0900
@@ -1208,7 +1208,7 @@
   cudnnRNNMode_t mode;
   cudnnRNNAlgo_t algo;
   cudnnDataType_t data_type;
-  RETURN_IF_CUDNN_ERROR(cudnnGetRNNDescriptor(
+  RETURN_IF_CUDNN_ERROR(cudnnGetRNNDescriptor_v6(
       /*handle=*/cudnn.handle(), /*rnnDesc=*/rnn_desc,
       /*hiddenSize=*/&hidden_size_v,
       /*numLayers=*/&num_layers_v,
@@ -2316,14 +2316,11 @@
     const CudnnFilterDescriptor& filter, const CudnnConvolutionDescriptor& conv,
     const CudnnTensorDescriptor& output_nd, bool specify_workspace_limit,
     size_t memory_limit_bytes) {
-  cudnnConvolutionFwdPreference_t preference =
-      specify_workspace_limit ? CUDNN_CONVOLUTION_FWD_SPECIFY_WORKSPACE_LIMIT
-                              : CUDNN_CONVOLUTION_FWD_NO_WORKSPACE;
-  cudnnConvolutionFwdAlgo_t algo_to_use;
-  RETURN_IF_CUDNN_ERROR(cudnnGetConvolutionForwardAlgorithm(
+  cudnnConvolutionFwdAlgoPerf_t algo_to_use;
+  RETURN_IF_CUDNN_ERROR(cudnnGetConvolutionForwardAlgorithm_v7(
       cudnn.handle(), input_nd.handle(), filter.handle(), conv.handle(),
-      output_nd.handle(), preference, memory_limit_bytes, &algo_to_use));
-  return algo_to_use;
+      output_nd.handle(), 1, 0, &algo_to_use));
+  return algo_to_use.algo;
 }
 
 port::StatusOr<cudnnConvolutionBwdDataAlgo_t>
@@ -2334,15 +2331,11 @@
                                     const CudnnTensorDescriptor& output_nd,
                                     bool specify_workspace_limit,
                                     size_t memory_limit_bytes) {
-  cudnnConvolutionBwdDataPreference_t preference =
-      specify_workspace_limit
-          ? CUDNN_CONVOLUTION_BWD_DATA_SPECIFY_WORKSPACE_LIMIT
-          : CUDNN_CONVOLUTION_BWD_DATA_NO_WORKSPACE;
-  cudnnConvolutionBwdDataAlgo_t algo_to_use;
-  RETURN_IF_CUDNN_ERROR(cudnnGetConvolutionBackwardDataAlgorithm(
+  cudnnConvolutionBwdDataAlgoPerf_t algo_to_use;
+  RETURN_IF_CUDNN_ERROR(cudnnGetConvolutionBackwardDataAlgorithm_v7(
       cudnn.handle(), filter.handle(), output_nd.handle(), conv.handle(),
-      input_nd.handle(), preference, memory_limit_bytes, &algo_to_use));
-  return algo_to_use;
+      input_nd.handle(), 1, 0, &algo_to_use));
+  return algo_to_use.algo;
 }
 
 port::StatusOr<cudnnConvolutionBwdFilterAlgo_t>
@@ -2353,15 +2346,11 @@
                                       const CudnnTensorDescriptor& output_nd,
                                       bool specify_workspace_limit,
                                       size_t memory_limit_bytes) {
-  cudnnConvolutionBwdFilterPreference_t preference =
-      specify_workspace_limit
-          ? CUDNN_CONVOLUTION_BWD_FILTER_SPECIFY_WORKSPACE_LIMIT
-          : CUDNN_CONVOLUTION_BWD_FILTER_NO_WORKSPACE;
-  cudnnConvolutionBwdFilterAlgo_t algo_to_use;
-  RETURN_IF_CUDNN_ERROR(cudnnGetConvolutionBackwardFilterAlgorithm(
+  cudnnConvolutionBwdFilterAlgoPerf_t algo_to_use;
+  RETURN_IF_CUDNN_ERROR(cudnnGetConvolutionBackwardFilterAlgorithm_v7(
       cudnn.handle(), input_nd.handle(), output_nd.handle(), conv.handle(),
-      filter.handle(), preference, memory_limit_bytes, &algo_to_use));
-  return algo_to_use;
+      filter.handle(), 1, 0, &algo_to_use));
+  return algo_to_use.algo;
 }
 
 port::StatusOr<DeviceMemory<uint8>> AllocateCudnnConvolutionForwardWorkspace(
diff -ruN tensorflow-1.15.3/tensorflow/stream_executor/cuda/cuda_driver.cc tensorflow-1.15.3-cuda11/tensorflow/stream_executor/cuda/cuda_driver.cc
--- tensorflow-1.15.3/tensorflow/stream_executor/cuda/cuda_driver.cc	2020-05-15 07:21:31.000000000 +0900
+++ tensorflow-1.15.3-cuda11/tensorflow/stream_executor/cuda/cuda_driver.cc	2020-06-13 08:56:59.879636400 +0900
@@ -178,7 +178,7 @@
   // If we failed, reset cuda error status to avoid poisoning cuda streams.
   if (err != cudaSuccess) cudaGetLastError();
   bool points_to_host_memory = (err == cudaErrorInvalidValue ||
-                                attributes.memoryType != cudaMemoryTypeDevice);
+                                attributes.type != cudaMemoryTypeDevice);
   CHECK_EQ(is_host_ptr, points_to_host_memory) << absl::StreamFormat(
       "%s pointer is not actually on %s: %p", name, is_host_ptr ? "CPU" : "GPU",
       reinterpret_cast<const void*>(ptr));
diff -ruN tensorflow-1.15.3/tensorflow/stream_executor/cuda/cudnn_7_6.inc tensorflow-1.15.3-cuda11/tensorflow/stream_executor/cuda/cudnn_7_6.inc
--- tensorflow-1.15.3/tensorflow/stream_executor/cuda/cudnn_7_6.inc	2020-05-15 07:21:31.000000000 +0900
+++ tensorflow-1.15.3-cuda11/tensorflow/stream_executor/cuda/cudnn_7_6.inc	2020-06-13 08:52:31.251830000 +0900
@@ -759,7 +759,7 @@
   if (!func_ptr) return GetSymbolNotFoundError();
   return func_ptr(handle, xDesc, x, wDesc, w, convDesc, yDesc, y, requestedAlgoCount, returnedAlgoCount, perfResults, workSpace, workSpaceSizeInBytes);
 }
-
+#if 0
 cudnnStatus_t CUDNNWINAPI
 cudnnGetConvolutionForwardAlgorithm(cudnnHandle_t handle,
                                     const cudnnTensorDescriptor_t xDesc,
@@ -774,7 +774,7 @@
   if (!func_ptr) return GetSymbolNotFoundError();
   return func_ptr(handle, xDesc, wDesc, convDesc, yDesc, preference, memoryLimitInBytes, algo);
 }
-
+#endif
 cudnnStatus_t CUDNNWINAPI
 cudnnGetConvolutionForwardAlgorithm_v7(cudnnHandle_t handle,
                                        const cudnnTensorDescriptor_t srcDesc,
@@ -905,7 +905,7 @@
   if (!func_ptr) return GetSymbolNotFoundError();
   return func_ptr(handle, xDesc, x, dyDesc, y, convDesc, dwDesc, dw, requestedAlgoCount, returnedAlgoCount, perfResults, workSpace, workSpaceSizeInBytes);
 }
-
+#if 0
 cudnnStatus_t CUDNNWINAPI
 cudnnGetConvolutionBackwardFilterAlgorithm(cudnnHandle_t handle,
                                            const cudnnTensorDescriptor_t xDesc,
@@ -920,7 +920,7 @@
   if (!func_ptr) return GetSymbolNotFoundError();
   return func_ptr(handle, xDesc, dyDesc, convDesc, dwDesc, preference, memoryLimitInBytes, algo);
 }
-
+#endif
 cudnnStatus_t CUDNNWINAPI
 cudnnGetConvolutionBackwardFilterAlgorithm_v7(cudnnHandle_t handle,
                                               const cudnnTensorDescriptor_t srcDesc,
@@ -1012,7 +1012,7 @@
   if (!func_ptr) return GetSymbolNotFoundError();
   return func_ptr(handle, wDesc, w, dyDesc, dy, convDesc, dxDesc, dx, requestedAlgoCount, returnedAlgoCount, perfResults, workSpace, workSpaceSizeInBytes);
 }
-
+#if 0
 cudnnStatus_t CUDNNWINAPI
 cudnnGetConvolutionBackwardDataAlgorithm(cudnnHandle_t handle,
                                          const cudnnFilterDescriptor_t wDesc,
@@ -1027,7 +1027,7 @@
   if (!func_ptr) return GetSymbolNotFoundError();
   return func_ptr(handle, wDesc, dyDesc, convDesc, dxDesc, preference, memoryLimitInBytes, algo);
 }
-
+#endif
 cudnnStatus_t CUDNNWINAPI
 cudnnGetConvolutionBackwardDataAlgorithm_v7(cudnnHandle_t handle,
                                             const cudnnFilterDescriptor_t filterDesc,
@@ -1912,7 +1912,7 @@
 }
 
 cudnnStatus_t CUDNNWINAPI
-cudnnGetRNNDescriptor(cudnnHandle_t handle,
+cudnnGetRNNDescriptor_v6(cudnnHandle_t handle,
                       cudnnRNNDescriptor_t rnnDesc,
                       int *hiddenSize,
                       int *numLayers,
@@ -1923,7 +1923,7 @@
                       cudnnRNNAlgo_t *algo,
                       cudnnDataType_t *mathPrec) {
   using FuncPtr = cudnnStatus_t (CUDNNWINAPI *)(cudnnHandle_t, cudnnRNNDescriptor_t, int *, int *, cudnnDropoutDescriptor_t *, cudnnRNNInputMode_t *, cudnnDirectionMode_t *, cudnnRNNMode_t *, cudnnRNNAlgo_t *, cudnnDataType_t *);
-  static auto func_ptr = LoadSymbol<FuncPtr>("cudnnGetRNNDescriptor");
+  static auto func_ptr = LoadSymbol<FuncPtr>("cudnnGetRNNDescriptor_v6");
   if (!func_ptr) return GetSymbolNotFoundError();
   return func_ptr(handle, rnnDesc, hiddenSize, numLayers, dropoutDesc, inputMode, direction, mode, algo, mathPrec);
 }
@@ -2862,7 +2862,7 @@
     const int *inputLengths,                     /* the lengths of timing steps in each batch, in CPU memory */
     void *costs,                                 /* the returned costs of CTC, in GPU memory */
     const cudnnTensorDescriptor_t gradientsDesc, /* Tensor descriptor for gradients, the dimensions are T,N,A */
-    const void *gradients,   /* the returned CTC gradients, in GPU memory, to compute costs only, set it to NULL */
+    void *gradients,   /* the returned CTC gradients, in GPU memory, to compute costs only, set it to NULL */
     cudnnCTCLossAlgo_t algo, /* algorithm selected, supported now 0 and 1 */
     cudnnCTCLossDescriptor_t ctcLossDesc,
     void *workspace,              /* pointer to the workspace, in GPU memory */
diff -ruN tensorflow-1.15.3/tensorflow/stream_executor/cuda/cudnn_stub.cc tensorflow-1.15.3-cuda11/tensorflow/stream_executor/cuda/cudnn_stub.cc
--- tensorflow-1.15.3/tensorflow/stream_executor/cuda/cudnn_stub.cc	2020-05-15 07:21:31.000000000 +0900
+++ tensorflow-1.15.3-cuda11/tensorflow/stream_executor/cuda/cudnn_stub.cc	2020-06-13 08:56:59.910853200 +0900
@@ -47,18 +47,18 @@
 cudnnStatus_t GetSymbolNotFoundError() { return CUDNN_STATUS_INTERNAL_ERROR; }
 }  // namespace
 
-#if CUDNN_MAJOR < 6
-#error cuDNN version earlier than 6 is not supported.
-#elif CUDNN_MAJOR < 7
-#include "tensorflow/stream_executor/cuda/cudnn_6_0.inc"
-#elif CUDNN_MINOR < 1
-#include "tensorflow/stream_executor/cuda/cudnn_7_0.inc"
-#elif CUDNN_MINOR < 3
-#include "tensorflow/stream_executor/cuda/cudnn_7_1.inc"
-#elif CUDNN_MINOR < 4
-#include "tensorflow/stream_executor/cuda/cudnn_7_3.inc"
-#elif CUDNN_MINOR < 6
-#include "tensorflow/stream_executor/cuda/cudnn_7_4.inc"
-#else
+//#if CUDNN_MAJOR < 6
+//#error cuDNN version earlier than 6 is not supported.
+//#elif CUDNN_MAJOR < 7
+//#include "tensorflow/stream_executor/cuda/cudnn_6_0.inc"
+//#elif CUDNN_MINOR < 1
+//#include "tensorflow/stream_executor/cuda/cudnn_7_0.inc"
+//#elif CUDNN_MINOR < 3
+//#include "tensorflow/stream_executor/cuda/cudnn_7_1.inc"
+//#elif CUDNN_MINOR < 4
+//#include "tensorflow/stream_executor/cuda/cudnn_7_3.inc"
+//#elif CUDNN_MINOR < 6
+//#include "tensorflow/stream_executor/cuda/cudnn_7_4.inc"
+//#else
 #include "tensorflow/stream_executor/cuda/cudnn_7_6.inc"
-#endif
+//#endif
diff -ruN tensorflow-1.15.3/tensorflow/stream_executor/cuda/cusparse_9_0.inc tensorflow-1.15.3-cuda11/tensorflow/stream_executor/cuda/cusparse_9_0.inc
--- tensorflow-1.15.3/tensorflow/stream_executor/cuda/cusparse_9_0.inc	2020-05-15 07:21:31.000000000 +0900
+++ tensorflow-1.15.3-cuda11/tensorflow/stream_executor/cuda/cusparse_9_0.inc	2020-06-13 08:52:31.251830000 +0900
@@ -128,7 +128,7 @@
   if (!func_ptr) return GetSymbolNotFoundError();
   return func_ptr(descrA, base);
 }
-
+#if 0
 cusparseStatus_t CUSPARSEAPI
 cusparseCreateSolveAnalysisInfo(cusparseSolveAnalysisInfo_t *info) {
   using FuncPtr =
@@ -156,7 +156,7 @@
   if (!func_ptr) return GetSymbolNotFoundError();
   return func_ptr(handle, info, nlevels, levelPtr, levelInd);
 }
-
+#endif
 cusparseStatus_t CUSPARSEAPI cusparseCreateCsrsv2Info(csrsv2Info_t *info) {
   using FuncPtr = cusparseStatus_t(CUSPARSEAPI *)(csrsv2Info_t *);
   static auto func_ptr = LoadSymbol<FuncPtr>("cusparseCreateCsrsv2Info");
@@ -254,7 +254,7 @@
   if (!func_ptr) return GetSymbolNotFoundError();
   return func_ptr(info);
 }
-
+#if 0
 cusparseStatus_t CUSPARSEAPI cusparseCreateHybMat(cusparseHybMat_t *hybA) {
   using FuncPtr = cusparseStatus_t(CUSPARSEAPI *)(cusparseHybMat_t *);
   static auto func_ptr = LoadSymbol<FuncPtr>("cusparseCreateHybMat");
@@ -268,7 +268,7 @@
   if (!func_ptr) return GetSymbolNotFoundError();
   return func_ptr(hybA);
 }
-
+#endif
 cusparseStatus_t CUSPARSEAPI cusparseCreateCsru2csrInfo(csru2csrInfo_t *info) {
   using FuncPtr = cusparseStatus_t(CUSPARSEAPI *)(csru2csrInfo_t *);
   static auto func_ptr = LoadSymbol<FuncPtr>("cusparseCreateCsru2csrInfo");
@@ -905,7 +905,7 @@
   return func_ptr(handle, transA, m, n, nnz, alpha, descrA, csrSortedValA,
                   csrSortedRowPtrA, csrSortedColIndA, x, beta, y);
 }
-
+#if 0
 cusparseStatus_t CUSPARSEAPI cusparseShybmv(
     cusparseHandle_t handle, cusparseOperation_t transA, const float *alpha,
     const cusparseMatDescr_t descrA, const cusparseHybMat_t hybA,
@@ -958,7 +958,7 @@
   if (!func_ptr) return GetSymbolNotFoundError();
   return func_ptr(handle, transA, alpha, descrA, hybA, x, beta, y);
 }
-
+#endif
 cusparseStatus_t CUSPARSEAPI cusparseSbsrmv(
     cusparseHandle_t handle, cusparseDirection_t dirA,
     cusparseOperation_t transA, int mb, int nb, int nnzb, const float *alpha,
@@ -1111,7 +1111,7 @@
                   bsrSortedValA, bsrSortedMaskPtrA, bsrSortedRowPtrA,
                   bsrSortedEndPtrA, bsrSortedColIndA, blockDim, x, beta, y);
 }
-
+#if 0
 cusparseStatus_t CUSPARSEAPI cusparseCsrsv_analysisEx(
     cusparseHandle_t handle, cusparseOperation_t transA, int m, int nnz,
     const cusparseMatDescr_t descrA, const void *csrSortedValA,
@@ -1269,7 +1269,7 @@
   return func_ptr(handle, transA, m, alpha, descrA, csrSortedValA,
                   csrSortedRowPtrA, csrSortedColIndA, info, f, x);
 }
-
+#endif
 cusparseStatus_t CUSPARSEAPI cusparseXcsrsv2_zeroPivot(cusparseHandle_t handle,
                                                        csrsv2Info_t info,
                                                        int *position) {
@@ -1812,7 +1812,7 @@
                   bsrSortedRowPtrA, bsrSortedColIndA, blockDim, info, f, x,
                   policy, pBuffer);
 }
-
+#if 0
 cusparseStatus_t CUSPARSEAPI
 cusparseShybsv_analysis(cusparseHandle_t handle, cusparseOperation_t transA,
                         const cusparseMatDescr_t descrA, cusparseHybMat_t hybA,
@@ -1913,7 +1913,7 @@
   if (!func_ptr) return GetSymbolNotFoundError();
   return func_ptr(handle, trans, alpha, descra, hybA, info, f, x);
 }
-
+#endif
 cusparseStatus_t CUSPARSEAPI
 cusparseScsrmm(cusparseHandle_t handle, cusparseOperation_t transA, int m,
                int n, int k, int nnz, const float *alpha,
@@ -2199,7 +2199,7 @@
   return func_ptr(handle, m, n, k, nnz, alpha, A, lda, cscValB, cscColPtrB,
                   cscRowIndB, beta, C, ldc);
 }
-
+#if 0
 cusparseStatus_t CUSPARSEAPI cusparseScsrsm_analysis(
     cusparseHandle_t handle, cusparseOperation_t transA, int m, int nnz,
     const cusparseMatDescr_t descrA, const float *csrSortedValA,
@@ -2321,7 +2321,7 @@
   return func_ptr(handle, transA, m, n, alpha, descrA, csrSortedValA,
                   csrSortedRowPtrA, csrSortedColIndA, info, F, ldf, X, ldx);
 }
-
+#endif
 cusparseStatus_t CUSPARSEAPI cusparseXbsrsm2_zeroPivot(cusparseHandle_t handle,
                                                        bsrsm2Info_t info,
                                                        int *position) {
@@ -2624,7 +2624,7 @@
                   bsrSortedVal, bsrSortedRowPtr, bsrSortedColInd, blockSize,
                   info, F, ldf, X, ldx, policy, pBuffer);
 }
-
+#if 0
 cusparseStatus_t CUSPARSEAPI cusparseCsrilu0Ex(
     cusparseHandle_t handle, cusparseOperation_t trans, int m,
     const cusparseMatDescr_t descrA, void *csrSortedValA_ValM,
@@ -2707,7 +2707,7 @@
   return func_ptr(handle, trans, m, descrA, csrSortedValA_ValM,
                   csrSortedRowPtrA, csrSortedColIndA, info);
 }
-
+#endif
 cusparseStatus_t CUSPARSEAPI cusparseScsrilu02_numericBoost(
     cusparseHandle_t handle, csrilu02Info_t info, int enable_boost, double *tol,
     float *boost_val) {
@@ -3263,7 +3263,7 @@
   return func_ptr(handle, dirA, mb, nnzb, descra, bsrSortedVal, bsrSortedRowPtr,
                   bsrSortedColInd, blockDim, info, policy, pBuffer);
 }
-
+#if 0
 cusparseStatus_t CUSPARSEAPI
 cusparseScsric0(cusparseHandle_t handle, cusparseOperation_t trans, int m,
                 const cusparseMatDescr_t descrA, float *csrSortedValA_ValM,
@@ -3327,7 +3327,7 @@
   return func_ptr(handle, trans, m, descrA, csrSortedValA_ValM,
                   csrSortedRowPtrA, csrSortedColIndA, info);
 }
-
+#endif
 cusparseStatus_t CUSPARSEAPI cusparseXcsric02_zeroPivot(cusparseHandle_t handle,
                                                         csric02Info_t info,
                                                         int *position) {
@@ -5260,7 +5260,7 @@
                   csrSortedColInd, cscSortedVal, cscSortedRowInd,
                   cscSortedColPtr, copyValues, idxBase);
 }
-
+#if 0
 cusparseStatus_t CUSPARSEAPI cusparseSdense2hyb(
     cusparseHandle_t handle, int m, int n, const cusparseMatDescr_t descrA,
     const float *A, int lda, const int *nnzPerRow, cusparseHybMat_t hybA,
@@ -5596,7 +5596,7 @@
   return func_ptr(handle, descrA, hybA, cscSortedVal, cscSortedRowInd,
                   cscSortedColPtr);
 }
-
+#endif
 cusparseStatus_t CUSPARSEAPI cusparseXcsr2bsrNnz(
     cusparseHandle_t handle, cusparseDirection_t dirA, int m, int n,
     const cusparseMatDescr_t descrA, const int *csrSortedRowPtrA,
diff -ruN tensorflow-1.15.3/third_party/gpus/crosstool/windows/msvc_wrapper_for_nvcc.py.tpl tensorflow-1.15.3-cuda11/third_party/gpus/crosstool/windows/msvc_wrapper_for_nvcc.py.tpl
--- tensorflow-1.15.3/third_party/gpus/crosstool/windows/msvc_wrapper_for_nvcc.py.tpl	2020-05-15 07:21:31.000000000 +0900
+++ tensorflow-1.15.3-cuda11/third_party/gpus/crosstool/windows/msvc_wrapper_for_nvcc.py.tpl	2020-06-13 08:59:25.687890600 +0900
@@ -143,7 +143,7 @@
   nvccopts += undefines
   nvccopts += defines
   nvccopts += m_options
-  nvccopts += ['--compiler-options="' + " ".join(host_compiler_options) + '"']
+  nvccopts += ['--compiler-options=' + ",".join(host_compiler_options)]
   nvccopts += ['-x', 'cu'] + opt + includes + out + ['-c'] + src_files
   # If we don't specify --keep-dir, nvcc will generate intermediate files under TEMP
   # Put them under NVCC_TEMP_DIR instead, then Bazel can ignore files under NVCC_TEMP_DIR during dependency check
diff -ruN tensorflow-1.15.3/third_party/gpus/cuda_configure.bzl tensorflow-1.15.3-cuda11/third_party/gpus/cuda_configure.bzl
--- tensorflow-1.15.3/third_party/gpus/cuda_configure.bzl	2020-05-15 07:21:31.000000000 +0900
+++ tensorflow-1.15.3-cuda11/third_party/gpus/cuda_configure.bzl	2020-06-13 08:52:31.267459300 +0900
@@ -1053,8 +1053,28 @@
     copy_rules.append(make_copy_files_rule(
         repository_ctx,
         name = "cudnn-include",
-        srcs = [cudnn_header_dir + "/cudnn.h"],
-        outs = ["cudnn/include/cudnn.h"],
+        srcs = [
+            cudnn_header_dir + "/cudnn.h",
+            cudnn_header_dir + "/cudnn_version.h",
+            cudnn_header_dir + "/cudnn_ops_infer.h",
+            cudnn_header_dir + "/cudnn_ops_train.h",
+            cudnn_header_dir + "/cudnn_adv_infer.h",
+            cudnn_header_dir + "/cudnn_adv_train.h",
+            cudnn_header_dir + "/cudnn_cnn_infer.h",
+            cudnn_header_dir + "/cudnn_cnn_train.h",
+            cudnn_header_dir + "/cudnn_backend.h",
+        ],
+        outs = [
+            "cudnn/include/cudnn.h",
+            "cudnn/include/cudnn_version.h",
+            "cudnn/include/cudnn_ops_infer.h",
+            "cudnn/include/cudnn_ops_train.h",
+            "cudnn/include/cudnn_adv_infer.h",
+            "cudnn/include/cudnn_adv_train.h",
+            "cudnn/include/cudnn_cnn_infer.h",
+            "cudnn/include/cudnn_cnn_train.h",
+            "cudnn/include/cudnn_backend.h",
+        ],
     ))
 
     # Set up BUILD file for cuda/
