diff -ruN java/org/tensorflow/op/core/Abort.java java-ops/org/tensorflow/op/core/Abort.java
--- java/org/tensorflow/op/core/Abort.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Abort.java	2018-10-16 20:18:38.149432439 +0900
@@ -0,0 +1,105 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Raise a exception to abort the process when called.
+ * <p>
+ * If exit_without_error is true, the process will exit normally,
+ * otherwise it will exit with a SIGABORT signal.
+ * <p>
+ * Returns nothing but an exception.
+ */
+@Operator
+public final class Abort extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Abort}
+   */
+  public static class Options {
+    
+    /**
+     * @param errorMsg A string which is the message associated with the exception.
+     */
+    public Options errorMsg(String errorMsg) {
+      this.errorMsg = errorMsg;
+      return this;
+    }
+    
+    /**
+     * @param exitWithoutError 
+     */
+    public Options exitWithoutError(Boolean exitWithoutError) {
+      this.exitWithoutError = exitWithoutError;
+      return this;
+    }
+    
+    private String errorMsg;
+    private Boolean exitWithoutError;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Abort operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param options carries optional attributes values
+   * @return a new instance of Abort
+   */
+  public static Abort create(Scope scope, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Abort", scope.makeOpName("Abort"));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.errorMsg != null) {
+          opBuilder.setAttr("error_msg", opts.errorMsg);
+        }
+        if (opts.exitWithoutError != null) {
+          opBuilder.setAttr("exit_without_error", opts.exitWithoutError);
+        }
+      }
+    }
+    return new Abort(opBuilder.build());
+  }
+  
+  /**
+   * @param errorMsg A string which is the message associated with the exception.
+   */
+  public static Options errorMsg(String errorMsg) {
+    return new Options().errorMsg(errorMsg);
+  }
+  
+  /**
+   * @param exitWithoutError 
+   */
+  public static Options exitWithoutError(Boolean exitWithoutError) {
+    return new Options().exitWithoutError(exitWithoutError);
+  }
+  
+  
+  private Abort(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Abs.java java-ops/org/tensorflow/op/core/Abs.java
--- java/org/tensorflow/op/core/Abs.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Abs.java	2018-10-16 20:18:38.149432439 +0900
@@ -0,0 +1,71 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the absolute value of a tensor.
+ * <p>
+ * Given a tensor `x`, this operation returns a tensor containing the absolute
+ * value of each element in `x`. For example, if x is an input element and y is
+ * an output element, this operation computes \\(y = |x|\\).
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class Abs<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Abs operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of Abs
+   */
+  public static <T extends Number> Abs<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Abs", scope.makeOpName("Abs"));
+    opBuilder.addInput(x.asOutput());
+    return new Abs<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private Abs(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/AccumulateNV2.java java-ops/org/tensorflow/op/core/AccumulateNV2.java
--- java/org/tensorflow/op/core/AccumulateNV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/AccumulateNV2.java	2018-10-16 20:18:38.150432438 +0900
@@ -0,0 +1,79 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns the element-wise sum of a list of tensors.
+ * <p>
+ * `tf.accumulate_n_v2` performs the same operation as `tf.add_n`, but does not
+ * wait for all of its inputs to be ready before beginning to sum. This can
+ * save memory if inputs are ready at different times, since minimum temporary
+ * storage is proportional to the output size rather than the inputs size.
+ * <p>
+ * Unlike the original `accumulate_n`, `accumulate_n_v2` is differentiable.
+ * <p>
+ * Returns a `Tensor` of same shape and type as the elements of `inputs`.
+ * 
+ * @param <T> data type for {@code sum()} output
+ */
+@Operator
+public final class AccumulateNV2<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new AccumulateNV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputs A list of `Tensor` objects, each with same shape and type.
+   * @param shape Shape of elements of `inputs`.
+   * @return a new instance of AccumulateNV2
+   */
+  public static <T> AccumulateNV2<T> create(Scope scope, Operand<T> inputs, Shape shape) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("AccumulateNV2", scope.makeOpName("AccumulateNV2"));
+    opBuilder.addInput(inputs.asOutput());
+    opBuilder.setAttr("shape", shape);
+    return new AccumulateNV2<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> sum() {
+    return sum;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return sum;
+  }
+  
+  private Output<T> sum;
+  
+  private AccumulateNV2(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    sum = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/AccumulatorApplyGradient.java java-ops/org/tensorflow/op/core/AccumulatorApplyGradient.java
--- java/org/tensorflow/op/core/AccumulatorApplyGradient.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/AccumulatorApplyGradient.java	2018-10-16 20:18:38.150432438 +0900
@@ -0,0 +1,56 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Applies a gradient to a given accumulator.
+ * <p>
+ * Does not add if local_step is lesser than the accumulator's global_step.
+ */
+@Operator
+public final class AccumulatorApplyGradient extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new AccumulatorApplyGradient operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param handle The handle to a accumulator.
+   * @param localStep The local_step value at which the gradient was computed.
+   * @param gradient A tensor of the gradient to be accumulated.
+   * @return a new instance of AccumulatorApplyGradient
+   */
+  public static <T> AccumulatorApplyGradient create(Scope scope, Operand<String> handle, Operand<Long> localStep, Operand<T> gradient) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("AccumulatorApplyGradient", scope.makeOpName("AccumulatorApplyGradient"));
+    opBuilder.addInput(handle.asOutput());
+    opBuilder.addInput(localStep.asOutput());
+    opBuilder.addInput(gradient.asOutput());
+    return new AccumulatorApplyGradient(opBuilder.build());
+  }
+  
+  
+  private AccumulatorApplyGradient(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/AccumulatorNumAccumulated.java java-ops/org/tensorflow/op/core/AccumulatorNumAccumulated.java
--- java/org/tensorflow/op/core/AccumulatorNumAccumulated.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/AccumulatorNumAccumulated.java	2018-10-16 20:18:38.150432438 +0900
@@ -0,0 +1,66 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns the number of gradients aggregated in the given accumulators.
+ */
+@Operator
+public final class AccumulatorNumAccumulated extends PrimitiveOp implements Operand<Integer> {
+  
+  /**
+   * Factory method to create a class to wrap a new AccumulatorNumAccumulated operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param handle The handle to an accumulator.
+   * @return a new instance of AccumulatorNumAccumulated
+   */
+  public static AccumulatorNumAccumulated create(Scope scope, Operand<String> handle) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("AccumulatorNumAccumulated", scope.makeOpName("AccumulatorNumAccumulated"));
+    opBuilder.addInput(handle.asOutput());
+    return new AccumulatorNumAccumulated(opBuilder.build());
+  }
+  
+  /**
+   * The number of gradients aggregated in the given accumulator.
+   */
+  public Output<Integer> numAccumulated() {
+    return numAccumulated;
+  }
+  
+  @Override
+  public Output<Integer> asOutput() {
+    return numAccumulated;
+  }
+  
+  private Output<Integer> numAccumulated;
+  
+  private AccumulatorNumAccumulated(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    numAccumulated = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/AccumulatorSetGlobalStep.java java-ops/org/tensorflow/op/core/AccumulatorSetGlobalStep.java
--- java/org/tensorflow/op/core/AccumulatorSetGlobalStep.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/AccumulatorSetGlobalStep.java	2018-10-16 20:18:38.151432437 +0900
@@ -0,0 +1,55 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Updates the accumulator with a new value for global_step.
+ * <p>
+ * Logs warning if the accumulator's value is already higher than
+ * new_global_step.
+ */
+@Operator
+public final class AccumulatorSetGlobalStep extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new AccumulatorSetGlobalStep operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param handle The handle to an accumulator.
+   * @param newGlobalStep The new global_step value to set.
+   * @return a new instance of AccumulatorSetGlobalStep
+   */
+  public static AccumulatorSetGlobalStep create(Scope scope, Operand<String> handle, Operand<Long> newGlobalStep) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("AccumulatorSetGlobalStep", scope.makeOpName("AccumulatorSetGlobalStep"));
+    opBuilder.addInput(handle.asOutput());
+    opBuilder.addInput(newGlobalStep.asOutput());
+    return new AccumulatorSetGlobalStep(opBuilder.build());
+  }
+  
+  
+  private AccumulatorSetGlobalStep(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/AccumulatorTakeGradient.java java-ops/org/tensorflow/op/core/AccumulatorTakeGradient.java
--- java/org/tensorflow/op/core/AccumulatorTakeGradient.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/AccumulatorTakeGradient.java	2018-10-16 20:18:38.151432437 +0900
@@ -0,0 +1,80 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Extracts the average gradient in the given ConditionalAccumulator.
+ * <p>
+ * The op blocks until sufficient (i.e., more than num_required)
+ * gradients have been accumulated.  If the accumulator has already
+ * aggregated more than num_required gradients, it returns the average of
+ * the accumulated gradients.  Also automatically increments the recorded
+ * global_step in the accumulator by 1, and resets the aggregate to 0.
+ * 
+ * @param <T> data type for {@code average()} output
+ */
+@Operator
+public final class AccumulatorTakeGradient<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new AccumulatorTakeGradient operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param handle The handle to an accumulator.
+   * @param numRequired Number of gradients required before we return an aggregate.
+   * @param dtype The data type of accumulated gradients. Needs to correspond to the type
+   * of the accumulator.
+   * @return a new instance of AccumulatorTakeGradient
+   */
+  public static <T> AccumulatorTakeGradient<T> create(Scope scope, Operand<String> handle, Operand<Integer> numRequired, Class<T> dtype) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("AccumulatorTakeGradient", scope.makeOpName("AccumulatorTakeGradient"));
+    opBuilder.addInput(handle.asOutput());
+    opBuilder.addInput(numRequired.asOutput());
+    opBuilder.setAttr("dtype", DataType.fromClass(dtype));
+    return new AccumulatorTakeGradient<T>(opBuilder.build());
+  }
+  
+  /**
+   * The average of the accumulated gradients.
+   */
+  public Output<T> average() {
+    return average;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return average;
+  }
+  
+  private Output<T> average;
+  
+  private AccumulatorTakeGradient(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    average = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Acosh.java java-ops/org/tensorflow/op/core/Acosh.java
--- java/org/tensorflow/op/core/Acosh.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Acosh.java	2018-10-16 20:18:38.151432437 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes inverse hyperbolic cosine of x element-wise.
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class Acosh<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Acosh operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of Acosh
+   */
+  public static <T> Acosh<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Acosh", scope.makeOpName("Acosh"));
+    opBuilder.addInput(x.asOutput());
+    return new Acosh<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private Acosh(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Acos.java java-ops/org/tensorflow/op/core/Acos.java
--- java/org/tensorflow/op/core/Acos.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Acos.java	2018-10-16 20:18:38.151432437 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes acos of x element-wise.
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class Acos<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Acos operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of Acos
+   */
+  public static <T> Acos<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Acos", scope.makeOpName("Acos"));
+    opBuilder.addInput(x.asOutput());
+    return new Acos<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private Acos(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Add.java java-ops/org/tensorflow/op/core/Add.java
--- java/org/tensorflow/op/core/Add.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Add.java	2018-10-16 20:18:38.152432437 +0900
@@ -0,0 +1,72 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns x + y element-wise.
+ * <p>
+ * <i>NOTE</i>: `Add` supports broadcasting. `AddN` does not. More about broadcasting
+ * [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
+ * 
+ * @param <T> data type for {@code z()} output
+ */
+@Operator
+public final class Add<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Add operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param y 
+   * @return a new instance of Add
+   */
+  public static <T> Add<T> create(Scope scope, Operand<T> x, Operand<T> y) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Add", scope.makeOpName("Add"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(y.asOutput());
+    return new Add<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return z;
+  }
+  
+  private Output<T> z;
+  
+  private Add(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/AddManySparseToTensorsMap.java java-ops/org/tensorflow/op/core/AddManySparseToTensorsMap.java
--- java/org/tensorflow/op/core/AddManySparseToTensorsMap.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/AddManySparseToTensorsMap.java	2018-10-16 20:18:38.153432436 +0900
@@ -0,0 +1,150 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Add an `N`-minibatch `SparseTensor` to a `SparseTensorsMap`, return `N` handles.
+ * <p>
+ * A `SparseTensor` of rank `R` is represented by three tensors: `sparse_indices`,
+ * `sparse_values`, and `sparse_shape`, where
+ * <pre>{@code
+ * sparse_indices.shape[1] == sparse_shape.shape[0] == R}</pre>
+ * An `N`-minibatch of `SparseTensor` objects is represented as a `SparseTensor`
+ * having a first `sparse_indices` column taking values between `[0, N)`, where
+ * the minibatch size `N == sparse_shape[0]`.
+ * <p>
+ * The input `SparseTensor` must have rank `R` greater than 1, and the first
+ * dimension is treated as the minibatch dimension.  Elements of the `SparseTensor`
+ * must be sorted in increasing order of this first dimension.  The stored
+ * `SparseTensor` objects pointed to by each row of the output `sparse_handles`
+ * will have rank `R-1`.
+ * <p>
+ * The `SparseTensor` values can then be read out as part of a minibatch by passing
+ * the given keys as vector elements to `TakeManySparseFromTensorsMap`.  To ensure
+ * the correct `SparseTensorsMap` is accessed, ensure that the same
+ * `container` and `shared_name` are passed to that Op.  If no `shared_name`
+ * is provided here, instead use the <i>name</i> of the Operation created by calling
+ * `AddManySparseToTensorsMap` as the `shared_name` passed to
+ * `TakeManySparseFromTensorsMap`.  Ensure the Operations are colocated.
+ */
+@Operator
+public final class AddManySparseToTensorsMap extends PrimitiveOp implements Operand<Long> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.AddManySparseToTensorsMap}
+   */
+  public static class Options {
+    
+    /**
+     * @param container The container name for the `SparseTensorsMap` created by this op.
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName The shared name for the `SparseTensorsMap` created by this op.
+     * If blank, the new Operation's unique name is used.
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new AddManySparseToTensorsMap operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param sparseIndices 2-D.  The `indices` of the minibatch `SparseTensor`.
+   * `sparse_indices[:, 0]` must be ordered values in `[0, N)`.
+   * @param sparseValues 1-D.  The `values` of the minibatch `SparseTensor`.
+   * @param sparseShape 1-D.  The `shape` of the minibatch `SparseTensor`.
+   * The minibatch size `N == sparse_shape[0]`.
+   * @param options carries optional attributes values
+   * @return a new instance of AddManySparseToTensorsMap
+   */
+  public static <T> AddManySparseToTensorsMap create(Scope scope, Operand<Long> sparseIndices, Operand<T> sparseValues, Operand<Long> sparseShape, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("AddManySparseToTensorsMap", scope.makeOpName("AddManySparseToTensorsMap"));
+    opBuilder.addInput(sparseIndices.asOutput());
+    opBuilder.addInput(sparseValues.asOutput());
+    opBuilder.addInput(sparseShape.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new AddManySparseToTensorsMap(opBuilder.build());
+  }
+  
+  /**
+   * @param container The container name for the `SparseTensorsMap` created by this op.
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName The shared name for the `SparseTensorsMap` created by this op.
+   * If blank, the new Operation's unique name is used.
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   * 1-D.  The handles of the `SparseTensor` now stored in the
+   * `SparseTensorsMap`.  Shape: `[N]`.
+   */
+  public Output<Long> sparseHandles() {
+    return sparseHandles;
+  }
+  
+  @Override
+  public Output<Long> asOutput() {
+    return sparseHandles;
+  }
+  
+  private Output<Long> sparseHandles;
+  
+  private AddManySparseToTensorsMap(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    sparseHandles = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/AddN.java java-ops/org/tensorflow/op/core/AddN.java
--- java/org/tensorflow/op/core/AddN.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/AddN.java	2018-10-16 20:18:38.153432436 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Add all input tensors element wise.
+ * 
+ * @param <T> data type for {@code sum()} output
+ */
+@Operator
+public final class AddN<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new AddN operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputs Must all be the same size and shape.
+   * @return a new instance of AddN
+   */
+  public static <T> AddN<T> create(Scope scope, Operand<T> inputs) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("AddN", scope.makeOpName("AddN"));
+    opBuilder.addInput(inputs.asOutput());
+    return new AddN<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> sum() {
+    return sum;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return sum;
+  }
+  
+  private Output<T> sum;
+  
+  private AddN(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    sum = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/AddSparseToTensorsMap.java java-ops/org/tensorflow/op/core/AddSparseToTensorsMap.java
--- java/org/tensorflow/op/core/AddSparseToTensorsMap.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/AddSparseToTensorsMap.java	2018-10-16 20:18:38.154432435 +0900
@@ -0,0 +1,141 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Add a `SparseTensor` to a `SparseTensorsMap` return its handle.
+ * <p>
+ * A `SparseTensor` is represented by three tensors: `sparse_indices`,
+ * `sparse_values`, and `sparse_shape`.
+ * <p>
+ * This operator takes the given `SparseTensor` and adds it to a container
+ * object (a `SparseTensorsMap`).  A unique key within this container is generated
+ * in the form of an `int64`, and this is the value that is returned.
+ * <p>
+ * The `SparseTensor` can then be read out as part of a minibatch by passing
+ * the key as a vector element to `TakeManySparseFromTensorsMap`.  To ensure
+ * the correct `SparseTensorsMap` is accessed, ensure that the same
+ * `container` and `shared_name` are passed to that Op.  If no `shared_name`
+ * is provided here, instead use the <i>name</i> of the Operation created by calling
+ * `AddSparseToTensorsMap` as the `shared_name` passed to
+ * `TakeManySparseFromTensorsMap`.  Ensure the Operations are colocated.
+ */
+@Operator
+public final class AddSparseToTensorsMap extends PrimitiveOp implements Operand<Long> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.AddSparseToTensorsMap}
+   */
+  public static class Options {
+    
+    /**
+     * @param container The container name for the `SparseTensorsMap` created by this op.
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName The shared name for the `SparseTensorsMap` created by this op.
+     * If blank, the new Operation's unique name is used.
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new AddSparseToTensorsMap operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param sparseIndices 2-D.  The `indices` of the `SparseTensor`.
+   * @param sparseValues 1-D.  The `values` of the `SparseTensor`.
+   * @param sparseShape 1-D.  The `shape` of the `SparseTensor`.
+   * @param options carries optional attributes values
+   * @return a new instance of AddSparseToTensorsMap
+   */
+  public static <T> AddSparseToTensorsMap create(Scope scope, Operand<Long> sparseIndices, Operand<T> sparseValues, Operand<Long> sparseShape, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("AddSparseToTensorsMap", scope.makeOpName("AddSparseToTensorsMap"));
+    opBuilder.addInput(sparseIndices.asOutput());
+    opBuilder.addInput(sparseValues.asOutput());
+    opBuilder.addInput(sparseShape.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new AddSparseToTensorsMap(opBuilder.build());
+  }
+  
+  /**
+   * @param container The container name for the `SparseTensorsMap` created by this op.
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName The shared name for the `SparseTensorsMap` created by this op.
+   * If blank, the new Operation's unique name is used.
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   * 0-D.  The handle of the `SparseTensor` now stored in the
+   * `SparseTensorsMap`.
+   */
+  public Output<Long> sparseHandle() {
+    return sparseHandle;
+  }
+  
+  @Override
+  public Output<Long> asOutput() {
+    return sparseHandle;
+  }
+  
+  private Output<Long> sparseHandle;
+  
+  private AddSparseToTensorsMap(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    sparseHandle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/AddV2.java java-ops/org/tensorflow/op/core/AddV2.java
--- java/org/tensorflow/op/core/AddV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/AddV2.java	2018-10-16 20:18:38.154432435 +0900
@@ -0,0 +1,72 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns x + y element-wise.
+ * <p>
+ * <i>NOTE</i>: `Add` supports broadcasting. `AddN` does not. More about broadcasting
+ * [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
+ * 
+ * @param <T> data type for {@code z()} output
+ */
+@Operator
+public final class AddV2<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new AddV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param y 
+   * @return a new instance of AddV2
+   */
+  public static <T> AddV2<T> create(Scope scope, Operand<T> x, Operand<T> y) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("AddV2", scope.makeOpName("AddV2"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(y.asOutput());
+    return new AddV2<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return z;
+  }
+  
+  private Output<T> z;
+  
+  private AddV2(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/AdjustContrast.java java-ops/org/tensorflow/op/core/AdjustContrast.java
--- java/org/tensorflow/op/core/AdjustContrast.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/AdjustContrast.java	2018-10-16 20:18:38.155432435 +0900
@@ -0,0 +1,78 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Adjust the contrast of one or more images.
+ * <p>
+ * `images` is a tensor of at least 3 dimensions.  The last 3 dimensions are
+ * interpreted as `[height, width, channels]`.  The other dimensions only
+ * represent a collection of images, such as `[batch, height, width, channels].`
+ * <p>
+ * Contrast is adjusted independently for each channel of each image.
+ * <p>
+ * For each channel, the Op first computes the mean of the image pixels in the
+ * channel and then adjusts each component of each pixel to
+ * `(x - mean) * contrast_factor + mean`.
+ */
+@Operator
+public final class AdjustContrast extends PrimitiveOp implements Operand<Float> {
+  
+  /**
+   * Factory method to create a class to wrap a new AdjustContrast operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param images Images to adjust.  At least 3-D.
+   * @param contrastFactor A float multiplier for adjusting contrast.
+   * @return a new instance of AdjustContrast
+   */
+  public static AdjustContrast create(Scope scope, Operand<Float> images, Operand<Float> contrastFactor) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("AdjustContrastv2", scope.makeOpName("AdjustContrast"));
+    opBuilder.addInput(images.asOutput());
+    opBuilder.addInput(contrastFactor.asOutput());
+    return new AdjustContrast(opBuilder.build());
+  }
+  
+  /**
+   * The contrast-adjusted image or images.
+   */
+  public Output<Float> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<Float> asOutput() {
+    return output;
+  }
+  
+  private Output<Float> output;
+  
+  private AdjustContrast(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/AdjustHue.java java-ops/org/tensorflow/op/core/AdjustHue.java
--- java/org/tensorflow/op/core/AdjustHue.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/AdjustHue.java	2018-10-16 20:18:38.155432435 +0900
@@ -0,0 +1,75 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Adjust the hue of one or more images.
+ * <p>
+ * `images` is a tensor of at least 3 dimensions.  The last dimension is
+ * interpretted as channels, and must be three.
+ * <p>
+ * The input image is considered in the RGB colorspace. Conceptually, the RGB
+ * colors are first mapped into HSV. A delta is then applied all the hue values,
+ * and then remapped back to RGB colorspace.
+ */
+@Operator
+public final class AdjustHue extends PrimitiveOp implements Operand<Float> {
+  
+  /**
+   * Factory method to create a class to wrap a new AdjustHue operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param images Images to adjust.  At least 3-D.
+   * @param delta A float delta to add to the hue.
+   * @return a new instance of AdjustHue
+   */
+  public static AdjustHue create(Scope scope, Operand<Float> images, Operand<Float> delta) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("AdjustHue", scope.makeOpName("AdjustHue"));
+    opBuilder.addInput(images.asOutput());
+    opBuilder.addInput(delta.asOutput());
+    return new AdjustHue(opBuilder.build());
+  }
+  
+  /**
+   * The hue-adjusted image or images.
+   */
+  public Output<Float> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<Float> asOutput() {
+    return output;
+  }
+  
+  private Output<Float> output;
+  
+  private AdjustHue(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/AdjustSaturation.java java-ops/org/tensorflow/op/core/AdjustSaturation.java
--- java/org/tensorflow/op/core/AdjustSaturation.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/AdjustSaturation.java	2018-10-16 20:18:38.155432435 +0900
@@ -0,0 +1,75 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Adjust the saturation of one or more images.
+ * <p>
+ * `images` is a tensor of at least 3 dimensions.  The last dimension is
+ * interpretted as channels, and must be three.
+ * <p>
+ * The input image is considered in the RGB colorspace. Conceptually, the RGB
+ * colors are first mapped into HSV. A scale is then applied all the saturation
+ * values, and then remapped back to RGB colorspace.
+ */
+@Operator
+public final class AdjustSaturation extends PrimitiveOp implements Operand<Float> {
+  
+  /**
+   * Factory method to create a class to wrap a new AdjustSaturation operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param images Images to adjust.  At least 3-D.
+   * @param scale A float scale to add to the saturation.
+   * @return a new instance of AdjustSaturation
+   */
+  public static AdjustSaturation create(Scope scope, Operand<Float> images, Operand<Float> scale) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("AdjustSaturation", scope.makeOpName("AdjustSaturation"));
+    opBuilder.addInput(images.asOutput());
+    opBuilder.addInput(scale.asOutput());
+    return new AdjustSaturation(opBuilder.build());
+  }
+  
+  /**
+   * The hue-adjusted image or images.
+   */
+  public Output<Float> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<Float> asOutput() {
+    return output;
+  }
+  
+  private Output<Float> output;
+  
+  private AdjustSaturation(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/AllCandidateSampler.java java-ops/org/tensorflow/op/core/AllCandidateSampler.java
--- java/org/tensorflow/op/core/AllCandidateSampler.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/AllCandidateSampler.java	2018-10-16 20:18:38.157432433 +0900
@@ -0,0 +1,161 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Generates labels for candidate sampling with a learned unigram distribution.
+ * <p>
+ * See explanations of candidate sampling and the data formats at
+ * go/candidate-sampling.
+ * <p>
+ * For each batch, this op picks a single set of sampled candidate labels.
+ * <p>
+ * The advantages of sampling candidates per-batch are simplicity and the
+ * possibility of efficient dense matrix multiplication. The disadvantage is that
+ * the sampled candidates must be chosen independently of the context and of the
+ * true labels.
+ */
+@Operator
+public final class AllCandidateSampler extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.AllCandidateSampler}
+   */
+  public static class Options {
+    
+    /**
+     * @param seed If either seed or seed2 are set to be non-zero, the random number
+     * generator is seeded by the given seed.  Otherwise, it is seeded by a
+     * random seed.
+     */
+    public Options seed(Long seed) {
+      this.seed = seed;
+      return this;
+    }
+    
+    /**
+     * @param seed2 An second seed to avoid seed collision.
+     */
+    public Options seed2(Long seed2) {
+      this.seed2 = seed2;
+      return this;
+    }
+    
+    private Long seed;
+    private Long seed2;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new AllCandidateSampler operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param trueClasses A batch_size * num_true matrix, in which each row contains the
+   * IDs of the num_true target_classes in the corresponding original label.
+   * @param numTrue Number of true labels per context.
+   * @param numSampled Number of candidates to produce.
+   * @param unique If unique is true, we sample with rejection, so that all sampled
+   * candidates in a batch are unique. This requires some approximation to
+   * estimate the post-rejection sampling probabilities.
+   * @param options carries optional attributes values
+   * @return a new instance of AllCandidateSampler
+   */
+  public static AllCandidateSampler create(Scope scope, Operand<Long> trueClasses, Long numTrue, Long numSampled, Boolean unique, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("AllCandidateSampler", scope.makeOpName("AllCandidateSampler"));
+    opBuilder.addInput(trueClasses.asOutput());
+    opBuilder.setAttr("num_true", numTrue);
+    opBuilder.setAttr("num_sampled", numSampled);
+    opBuilder.setAttr("unique", unique);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.seed != null) {
+          opBuilder.setAttr("seed", opts.seed);
+        }
+        if (opts.seed2 != null) {
+          opBuilder.setAttr("seed2", opts.seed2);
+        }
+      }
+    }
+    return new AllCandidateSampler(opBuilder.build());
+  }
+  
+  /**
+   * @param seed If either seed or seed2 are set to be non-zero, the random number
+   * generator is seeded by the given seed.  Otherwise, it is seeded by a
+   * random seed.
+   */
+  public static Options seed(Long seed) {
+    return new Options().seed(seed);
+  }
+  
+  /**
+   * @param seed2 An second seed to avoid seed collision.
+   */
+  public static Options seed2(Long seed2) {
+    return new Options().seed2(seed2);
+  }
+  
+  /**
+   * A vector of length num_sampled, in which each element is
+   * the ID of a sampled candidate.
+   */
+  public Output<Long> sampledCandidates() {
+    return sampledCandidates;
+  }
+  
+  /**
+   * A batch_size * num_true matrix, representing
+   * the number of times each candidate is expected to occur in a batch
+   * of sampled candidates. If unique=true, then this is a probability.
+   */
+  public Output<Float> trueExpectedCount() {
+    return trueExpectedCount;
+  }
+  
+  /**
+   * A vector of length num_sampled, for each sampled
+   * candidate representing the number of times the candidate is expected
+   * to occur in a batch of sampled candidates.  If unique=true, then this is a
+   * probability.
+   */
+  public Output<Float> sampledExpectedCount() {
+    return sampledExpectedCount;
+  }
+  
+  private Output<Long> sampledCandidates;
+  private Output<Float> trueExpectedCount;
+  private Output<Float> sampledExpectedCount;
+  
+  private AllCandidateSampler(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    sampledCandidates = operation.output(outputIdx++);
+    trueExpectedCount = operation.output(outputIdx++);
+    sampledExpectedCount = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/All.java java-ops/org/tensorflow/op/core/All.java
--- java/org/tensorflow/op/core/All.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/All.java	2018-10-16 20:18:38.156432434 +0900
@@ -0,0 +1,108 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the "logical and" of elements across dimensions of a tensor.
+ * <p>
+ * Reduces `input` along the dimensions given in `axis`. Unless
+ * `keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
+ * `axis`. If `keep_dims` is true, the reduced dimensions are
+ * retained with length 1.
+ */
+@Operator
+public final class All extends PrimitiveOp implements Operand<Boolean> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.All}
+   */
+  public static class Options {
+    
+    /**
+     * @param keepDims If true, retain reduced dimensions with length 1.
+     */
+    public Options keepDims(Boolean keepDims) {
+      this.keepDims = keepDims;
+      return this;
+    }
+    
+    private Boolean keepDims;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new All operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input The tensor to reduce.
+   * @param axis The dimensions to reduce. Must be in the range
+   * `[-rank(input), rank(input))`.
+   * @param options carries optional attributes values
+   * @return a new instance of All
+   */
+  public static <T extends Number> All create(Scope scope, Operand<Boolean> input, Operand<T> axis, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("All", scope.makeOpName("All"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(axis.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.keepDims != null) {
+          opBuilder.setAttr("keep_dims", opts.keepDims);
+        }
+      }
+    }
+    return new All(opBuilder.build());
+  }
+  
+  /**
+   * @param keepDims If true, retain reduced dimensions with length 1.
+   */
+  public static Options keepDims(Boolean keepDims) {
+    return new Options().keepDims(keepDims);
+  }
+  
+  /**
+   * The reduced tensor.
+   */
+  public Output<Boolean> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<Boolean> asOutput() {
+    return output;
+  }
+  
+  private Output<Boolean> output;
+  
+  private All(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Angle.java java-ops/org/tensorflow/op/core/Angle.java
--- java/org/tensorflow/op/core/Angle.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Angle.java	2018-10-16 20:18:38.157432433 +0900
@@ -0,0 +1,97 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns the argument of a complex number.
+ * <p>
+ * Given a tensor `input` of complex numbers, this operation returns a tensor of
+ * type `float` that is the argument of each element in `input`. All elements in
+ * `input` must be complex numbers of the form \\(a + bj\\), where <i>a</i>
+ * is the real part and <i>b</i> is the imaginary part.
+ * <p>
+ * The argument returned by this operation is of the form \\(atan2(b, a)\\).
+ * <p>
+ * For example:
+ * <pre>{@code
+ * # tensor 'input' is [-2.25 + 4.75j, 3.25 + 5.75j]
+ * tf.angle(input) ==> [2.0132, 1.056]
+ * }</pre>
+ * @compatibility(numpy)
+ * Equivalent to np.angle.
+ * @end_compatibility
+ * 
+ * @param <U> data type for {@code output()} output
+ */
+@Operator
+public final class Angle<U extends Number> extends PrimitiveOp implements Operand<U> {
+  
+  /**
+   * Factory method to create a class to wrap a new Angle operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param Tout 
+   * @return a new instance of Angle
+   */
+  public static <U extends Number, T> Angle<U> create(Scope scope, Operand<T> input, Class<U> Tout) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Angle", scope.makeOpName("Angle"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.setAttr("Tout", DataType.fromClass(Tout));
+    return new Angle<U>(opBuilder.build());
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Angle operation to the graph, using default output types.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @return a new instance of Angle
+   */
+  public static <T> Angle<Float> create(Scope scope, Operand<T> input) {
+    return create(scope, input, Float.class);
+  }
+  
+  /**
+   */
+  public Output<U> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<U> asOutput() {
+    return output;
+  }
+  
+  private Output<U> output;
+  
+  private Angle(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/AnonymousIterator.java java-ops/org/tensorflow/op/core/AnonymousIterator.java
--- java/org/tensorflow/op/core/AnonymousIterator.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/AnonymousIterator.java	2018-10-16 20:18:38.157432433 +0900
@@ -0,0 +1,83 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * A container for an iterator resource.
+ */
+@Operator
+public final class AnonymousIterator extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new AnonymousIterator operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param outputTypes 
+   * @param outputShapes 
+   * @return a new instance of AnonymousIterator
+   */
+  public static AnonymousIterator create(Scope scope, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("AnonymousIterator", scope.makeOpName("AnonymousIterator"));
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new AnonymousIterator(opBuilder.build());
+  }
+  
+  /**
+   * A handle to the iterator that can be passed to a "MakeIterator" or
+   * "IteratorGetNext" op. In contrast to Iterator, AnonymousIterator prevents
+   * resource sharing by name, and does not keep a reference to the resource
+   * container.
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private AnonymousIterator(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Any.java java-ops/org/tensorflow/op/core/Any.java
--- java/org/tensorflow/op/core/Any.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Any.java	2018-10-16 20:18:38.158432433 +0900
@@ -0,0 +1,108 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the "logical or" of elements across dimensions of a tensor.
+ * <p>
+ * Reduces `input` along the dimensions given in `axis`. Unless
+ * `keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
+ * `axis`. If `keep_dims` is true, the reduced dimensions are
+ * retained with length 1.
+ */
+@Operator
+public final class Any extends PrimitiveOp implements Operand<Boolean> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Any}
+   */
+  public static class Options {
+    
+    /**
+     * @param keepDims If true, retain reduced dimensions with length 1.
+     */
+    public Options keepDims(Boolean keepDims) {
+      this.keepDims = keepDims;
+      return this;
+    }
+    
+    private Boolean keepDims;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Any operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input The tensor to reduce.
+   * @param axis The dimensions to reduce. Must be in the range
+   * `[-rank(input), rank(input))`.
+   * @param options carries optional attributes values
+   * @return a new instance of Any
+   */
+  public static <T extends Number> Any create(Scope scope, Operand<Boolean> input, Operand<T> axis, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Any", scope.makeOpName("Any"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(axis.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.keepDims != null) {
+          opBuilder.setAttr("keep_dims", opts.keepDims);
+        }
+      }
+    }
+    return new Any(opBuilder.build());
+  }
+  
+  /**
+   * @param keepDims If true, retain reduced dimensions with length 1.
+   */
+  public static Options keepDims(Boolean keepDims) {
+    return new Options().keepDims(keepDims);
+  }
+  
+  /**
+   * The reduced tensor.
+   */
+  public Output<Boolean> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<Boolean> asOutput() {
+    return output;
+  }
+  
+  private Output<Boolean> output;
+  
+  private Any(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ApplyAdadelta.java java-ops/org/tensorflow/op/core/ApplyAdadelta.java
--- java/org/tensorflow/op/core/ApplyAdadelta.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ApplyAdadelta.java	2018-10-16 20:18:38.159432432 +0900
@@ -0,0 +1,121 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update '*var' according to the adadelta scheme.
+ * <p>
+ * accum = rho() * accum + (1 - rho()) * grad.square();
+ * update = (update_accum + epsilon).sqrt() * (accum + epsilon()).rsqrt() * grad;
+ * update_accum = rho() * update_accum + (1 - rho()) * update.square();
+ * var -= update;
+ * 
+ * @param <T> data type for {@code out()} output
+ */
+@Operator
+public final class ApplyAdadelta<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ApplyAdadelta}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If True, updating of the var, accum and update_accum tensors will be protected by
+     * a lock; otherwise the behavior is undefined, but may exhibit less contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ApplyAdadelta operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param accum Should be from a Variable().
+   * @param accumUpdate Should be from a Variable().
+   * @param lr Scaling factor. Must be a scalar.
+   * @param rho Decay factor. Must be a scalar.
+   * @param epsilon Constant factor. Must be a scalar.
+   * @param grad The gradient.
+   * @param options carries optional attributes values
+   * @return a new instance of ApplyAdadelta
+   */
+  public static <T> ApplyAdadelta<T> create(Scope scope, Operand<T> var, Operand<T> accum, Operand<T> accumUpdate, Operand<T> lr, Operand<T> rho, Operand<T> epsilon, Operand<T> grad, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ApplyAdadelta", scope.makeOpName("ApplyAdadelta"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(accum.asOutput());
+    opBuilder.addInput(accumUpdate.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(rho.asOutput());
+    opBuilder.addInput(epsilon.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ApplyAdadelta<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If True, updating of the var, accum and update_accum tensors will be protected by
+   * a lock; otherwise the behavior is undefined, but may exhibit less contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * Same as "var".
+   */
+  public Output<T> out() {
+    return out;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return out;
+  }
+  
+  private Output<T> out;
+  
+  private ApplyAdadelta(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    out = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ApplyAdagradDA.java java-ops/org/tensorflow/op/core/ApplyAdagradDA.java
--- java/org/tensorflow/op/core/ApplyAdagradDA.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ApplyAdagradDA.java	2018-10-16 20:18:38.160432431 +0900
@@ -0,0 +1,118 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update '*var' according to the proximal adagrad scheme.
+ * 
+ * @param <T> data type for {@code out()} output
+ */
+@Operator
+public final class ApplyAdagradDA<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ApplyAdagradDA}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If True, updating of the var and accum tensors will be protected by
+     * a lock; otherwise the behavior is undefined, but may exhibit less contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ApplyAdagradDA operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param gradientAccumulator Should be from a Variable().
+   * @param gradientSquaredAccumulator Should be from a Variable().
+   * @param grad The gradient.
+   * @param lr Scaling factor. Must be a scalar.
+   * @param l1 L1 regularization. Must be a scalar.
+   * @param l2 L2 regularization. Must be a scalar.
+   * @param globalStep Training step number. Must be a scalar.
+   * @param options carries optional attributes values
+   * @return a new instance of ApplyAdagradDA
+   */
+  public static <T> ApplyAdagradDA<T> create(Scope scope, Operand<T> var, Operand<T> gradientAccumulator, Operand<T> gradientSquaredAccumulator, Operand<T> grad, Operand<T> lr, Operand<T> l1, Operand<T> l2, Operand<Long> globalStep, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ApplyAdagradDA", scope.makeOpName("ApplyAdagradDA"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(gradientAccumulator.asOutput());
+    opBuilder.addInput(gradientSquaredAccumulator.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(l1.asOutput());
+    opBuilder.addInput(l2.asOutput());
+    opBuilder.addInput(globalStep.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ApplyAdagradDA<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If True, updating of the var and accum tensors will be protected by
+   * a lock; otherwise the behavior is undefined, but may exhibit less contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * Same as "var".
+   */
+  public Output<T> out() {
+    return out;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return out;
+  }
+  
+  private Output<T> out;
+  
+  private ApplyAdagradDA(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    out = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ApplyAdagrad.java java-ops/org/tensorflow/op/core/ApplyAdagrad.java
--- java/org/tensorflow/op/core/ApplyAdagrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ApplyAdagrad.java	2018-10-16 20:18:38.160432431 +0900
@@ -0,0 +1,134 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update '*var' according to the adagrad scheme.
+ * <p>
+ * accum += grad * grad
+ * var -= lr * grad * (1 / sqrt(accum))
+ * 
+ * @param <T> data type for {@code out()} output
+ */
+@Operator
+public final class ApplyAdagrad<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ApplyAdagrad}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If `True`, updating of the var and accum tensors will be protected
+     * by a lock; otherwise the behavior is undefined, but may exhibit less
+     * contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    /**
+     * @param updateSlots 
+     */
+    public Options updateSlots(Boolean updateSlots) {
+      this.updateSlots = updateSlots;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    private Boolean updateSlots;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ApplyAdagrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param accum Should be from a Variable().
+   * @param lr Scaling factor. Must be a scalar.
+   * @param grad The gradient.
+   * @param options carries optional attributes values
+   * @return a new instance of ApplyAdagrad
+   */
+  public static <T> ApplyAdagrad<T> create(Scope scope, Operand<T> var, Operand<T> accum, Operand<T> lr, Operand<T> grad, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ApplyAdagrad", scope.makeOpName("ApplyAdagrad"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(accum.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+        if (opts.updateSlots != null) {
+          opBuilder.setAttr("update_slots", opts.updateSlots);
+        }
+      }
+    }
+    return new ApplyAdagrad<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If `True`, updating of the var and accum tensors will be protected
+   * by a lock; otherwise the behavior is undefined, but may exhibit less
+   * contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * @param updateSlots 
+   */
+  public static Options updateSlots(Boolean updateSlots) {
+    return new Options().updateSlots(updateSlots);
+  }
+  
+  /**
+   * Same as "var".
+   */
+  public Output<T> out() {
+    return out;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return out;
+  }
+  
+  private Output<T> out;
+  
+  private ApplyAdagrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    out = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ApplyAdaMax.java java-ops/org/tensorflow/op/core/ApplyAdaMax.java
--- java/org/tensorflow/op/core/ApplyAdaMax.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ApplyAdaMax.java	2018-10-16 20:18:38.158432433 +0900
@@ -0,0 +1,124 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Update '*var' according to the AdaMax algorithm.
+ * <p>
+ * m_t <- beta1 * m_{t-1} + (1 - beta1) * g
+ * v_t <- max(beta2 * v_{t-1}, abs(g))
+ * variable <- variable - learning_rate / (1 - beta1^t) * m_t / (v_t + epsilon)
+ * 
+ * @param <T> data type for {@code out()} output
+ */
+public final class ApplyAdaMax<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ApplyAdaMax}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If `True`, updating of the var, m, and v tensors will be protected
+     * by a lock; otherwise the behavior is undefined, but may exhibit less
+     * contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ApplyAdaMax operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param m Should be from a Variable().
+   * @param v Should be from a Variable().
+   * @param beta1Power Must be a scalar.
+   * @param lr Scaling factor. Must be a scalar.
+   * @param beta1 Momentum factor. Must be a scalar.
+   * @param beta2 Momentum factor. Must be a scalar.
+   * @param epsilon Ridge term. Must be a scalar.
+   * @param grad The gradient.
+   * @param options carries optional attributes values
+   * @return a new instance of ApplyAdaMax
+   */
+  public static <T> ApplyAdaMax<T> create(Scope scope, Operand<T> var, Operand<T> m, Operand<T> v, Operand<T> beta1Power, Operand<T> lr, Operand<T> beta1, Operand<T> beta2, Operand<T> epsilon, Operand<T> grad, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ApplyAdaMax", scope.makeOpName("ApplyAdaMax"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(m.asOutput());
+    opBuilder.addInput(v.asOutput());
+    opBuilder.addInput(beta1Power.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(beta1.asOutput());
+    opBuilder.addInput(beta2.asOutput());
+    opBuilder.addInput(epsilon.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ApplyAdaMax<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If `True`, updating of the var, m, and v tensors will be protected
+   * by a lock; otherwise the behavior is undefined, but may exhibit less
+   * contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * Same as "var".
+   */
+  public Output<T> out() {
+    return out;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return out;
+  }
+  
+  private Output<T> out;
+  
+  private ApplyAdaMax(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    out = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ApplyAdam.java java-ops/org/tensorflow/op/core/ApplyAdam.java
--- java/org/tensorflow/op/core/ApplyAdam.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ApplyAdam.java	2018-10-16 20:18:38.161432430 +0900
@@ -0,0 +1,148 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update '*var' according to the Adam algorithm.
+ * <p>
+ * $$lr_t := \text{learning\_rate} * \sqrt{1 - beta_2^t} / (1 - beta_1^t)$$
+ * $$m_t := beta_1 * m_{t-1} + (1 - beta_1) * g$$
+ * $$v_t := beta_2 * v_{t-1} + (1 - beta_2) * g * g$$
+ * $$variable := variable - lr_t * m_t / (\sqrt{v_t} + \epsilon)$$
+ * 
+ * @param <T> data type for {@code out()} output
+ */
+@Operator
+public final class ApplyAdam<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ApplyAdam}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If `True`, updating of the var, m, and v tensors will be protected
+     * by a lock; otherwise the behavior is undefined, but may exhibit less
+     * contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    /**
+     * @param useNesterov If `True`, uses the nesterov update.
+     */
+    public Options useNesterov(Boolean useNesterov) {
+      this.useNesterov = useNesterov;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    private Boolean useNesterov;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ApplyAdam operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param m Should be from a Variable().
+   * @param v Should be from a Variable().
+   * @param beta1Power Must be a scalar.
+   * @param beta2Power Must be a scalar.
+   * @param lr Scaling factor. Must be a scalar.
+   * @param beta1 Momentum factor. Must be a scalar.
+   * @param beta2 Momentum factor. Must be a scalar.
+   * @param epsilon Ridge term. Must be a scalar.
+   * @param grad The gradient.
+   * @param options carries optional attributes values
+   * @return a new instance of ApplyAdam
+   */
+  public static <T> ApplyAdam<T> create(Scope scope, Operand<T> var, Operand<T> m, Operand<T> v, Operand<T> beta1Power, Operand<T> beta2Power, Operand<T> lr, Operand<T> beta1, Operand<T> beta2, Operand<T> epsilon, Operand<T> grad, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ApplyAdam", scope.makeOpName("ApplyAdam"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(m.asOutput());
+    opBuilder.addInput(v.asOutput());
+    opBuilder.addInput(beta1Power.asOutput());
+    opBuilder.addInput(beta2Power.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(beta1.asOutput());
+    opBuilder.addInput(beta2.asOutput());
+    opBuilder.addInput(epsilon.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+        if (opts.useNesterov != null) {
+          opBuilder.setAttr("use_nesterov", opts.useNesterov);
+        }
+      }
+    }
+    return new ApplyAdam<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If `True`, updating of the var, m, and v tensors will be protected
+   * by a lock; otherwise the behavior is undefined, but may exhibit less
+   * contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * @param useNesterov If `True`, uses the nesterov update.
+   */
+  public static Options useNesterov(Boolean useNesterov) {
+    return new Options().useNesterov(useNesterov);
+  }
+  
+  /**
+   * Same as "var".
+   */
+  public Output<T> out() {
+    return out;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return out;
+  }
+  
+  private Output<T> out;
+  
+  private ApplyAdam(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    out = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ApplyAddSign.java java-ops/org/tensorflow/op/core/ApplyAddSign.java
--- java/org/tensorflow/op/core/ApplyAddSign.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ApplyAddSign.java	2018-10-16 20:18:38.161432430 +0900
@@ -0,0 +1,122 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update '*var' according to the AddSign update.
+ * <p>
+ * m_t <- beta1 * m_{t-1} + (1 - beta1) * g
+ * update <- (alpha + sign_decay * sign(g) *sign(m)) * g
+ * variable <- variable - lr_t * update
+ * 
+ * @param <T> data type for {@code out()} output
+ */
+@Operator
+public final class ApplyAddSign<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ApplyAddSign}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If `True`, updating of the var and m tensors is
+     * protected by a lock; otherwise the behavior is undefined, but may exhibit less
+     * contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ApplyAddSign operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param m Should be from a Variable().
+   * @param lr Scaling factor. Must be a scalar.
+   * @param alpha Must be a scalar.
+   * @param signDecay Must be a scalar.
+   * @param beta Must be a scalar.
+   * @param grad The gradient.
+   * @param options carries optional attributes values
+   * @return a new instance of ApplyAddSign
+   */
+  public static <T> ApplyAddSign<T> create(Scope scope, Operand<T> var, Operand<T> m, Operand<T> lr, Operand<T> alpha, Operand<T> signDecay, Operand<T> beta, Operand<T> grad, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ApplyAddSign", scope.makeOpName("ApplyAddSign"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(m.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(alpha.asOutput());
+    opBuilder.addInput(signDecay.asOutput());
+    opBuilder.addInput(beta.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ApplyAddSign<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If `True`, updating of the var and m tensors is
+   * protected by a lock; otherwise the behavior is undefined, but may exhibit less
+   * contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * Same as "var".
+   */
+  public Output<T> out() {
+    return out;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return out;
+  }
+  
+  private Output<T> out;
+  
+  private ApplyAddSign(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    out = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ApplyCenteredRMSProp.java java-ops/org/tensorflow/op/core/ApplyCenteredRMSProp.java
--- java/org/tensorflow/op/core/ApplyCenteredRMSProp.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ApplyCenteredRMSProp.java	2018-10-16 20:18:38.162432430 +0900
@@ -0,0 +1,141 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update '*var' according to the centered RMSProp algorithm.
+ * <p>
+ * The centered RMSProp algorithm uses an estimate of the centered second moment
+ * (i.e., the variance) for normalization, as opposed to regular RMSProp, which
+ * uses the (uncentered) second moment. This often helps with training, but is
+ * slightly more expensive in terms of computation and memory.
+ * <p>
+ * Note that in dense implementation of this algorithm, mg, ms, and mom will
+ * update even if the grad is zero, but in this sparse implementation, mg, ms,
+ * and mom will not update in iterations during which the grad is zero.
+ * <p>
+ * mean_square = decay * mean_square + (1-decay) * gradient ** 2
+ * mean_grad = decay * mean_grad + (1-decay) * gradient
+ * <p>
+ * Delta = learning_rate * gradient / sqrt(mean_square + epsilon - mean_grad ** 2)
+ * <p>
+ * mg <- rho * mg_{t-1} + (1-rho) * grad
+ * ms <- rho * ms_{t-1} + (1-rho) * grad * grad
+ * mom <- momentum * mom_{t-1} + lr * grad / sqrt(ms - mg * mg + epsilon)
+ * var <- var - mom
+ * 
+ * @param <T> data type for {@code out()} output
+ */
+@Operator
+public final class ApplyCenteredRMSProp<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ApplyCenteredRMSProp}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If `True`, updating of the var, mg, ms, and mom tensors is
+     * protected by a lock; otherwise the behavior is undefined, but may exhibit less
+     * contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ApplyCenteredRMSProp operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param mg Should be from a Variable().
+   * @param ms Should be from a Variable().
+   * @param mom Should be from a Variable().
+   * @param lr Scaling factor. Must be a scalar.
+   * @param rho Decay rate. Must be a scalar.
+   * @param momentum 
+   * @param epsilon Ridge term. Must be a scalar.
+   * @param grad The gradient.
+   * @param options carries optional attributes values
+   * @return a new instance of ApplyCenteredRMSProp
+   */
+  public static <T> ApplyCenteredRMSProp<T> create(Scope scope, Operand<T> var, Operand<T> mg, Operand<T> ms, Operand<T> mom, Operand<T> lr, Operand<T> rho, Operand<T> momentum, Operand<T> epsilon, Operand<T> grad, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ApplyCenteredRMSProp", scope.makeOpName("ApplyCenteredRMSProp"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(mg.asOutput());
+    opBuilder.addInput(ms.asOutput());
+    opBuilder.addInput(mom.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(rho.asOutput());
+    opBuilder.addInput(momentum.asOutput());
+    opBuilder.addInput(epsilon.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ApplyCenteredRMSProp<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If `True`, updating of the var, mg, ms, and mom tensors is
+   * protected by a lock; otherwise the behavior is undefined, but may exhibit less
+   * contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * Same as "var".
+   */
+  public Output<T> out() {
+    return out;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return out;
+  }
+  
+  private Output<T> out;
+  
+  private ApplyCenteredRMSProp(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    out = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ApplyFtrl.java java-ops/org/tensorflow/op/core/ApplyFtrl.java
--- java/org/tensorflow/op/core/ApplyFtrl.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ApplyFtrl.java	2018-10-16 20:18:38.163432429 +0900
@@ -0,0 +1,126 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update '*var' according to the Ftrl-proximal scheme.
+ * <p>
+ * accum_new = accum + grad * grad
+ * linear += grad + (accum_new^(-lr_power) - accum^(-lr_power)) / lr * var
+ * quadratic = 1.0 / (accum_new^(lr_power) * lr) + 2 * l2
+ * var = (sign(linear) * l1 - linear) / quadratic if |linear| > l1 else 0.0
+ * accum = accum_new
+ * 
+ * @param <T> data type for {@code out()} output
+ */
+@Operator
+public final class ApplyFtrl<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ApplyFtrl}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If `True`, updating of the var and accum tensors will be protected
+     * by a lock; otherwise the behavior is undefined, but may exhibit less
+     * contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ApplyFtrl operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param accum Should be from a Variable().
+   * @param linear Should be from a Variable().
+   * @param grad The gradient.
+   * @param lr Scaling factor. Must be a scalar.
+   * @param l1 L1 regulariation. Must be a scalar.
+   * @param l2 L2 regulariation. Must be a scalar.
+   * @param lrPower Scaling factor. Must be a scalar.
+   * @param options carries optional attributes values
+   * @return a new instance of ApplyFtrl
+   */
+  public static <T> ApplyFtrl<T> create(Scope scope, Operand<T> var, Operand<T> accum, Operand<T> linear, Operand<T> grad, Operand<T> lr, Operand<T> l1, Operand<T> l2, Operand<T> lrPower, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ApplyFtrl", scope.makeOpName("ApplyFtrl"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(accum.asOutput());
+    opBuilder.addInput(linear.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(l1.asOutput());
+    opBuilder.addInput(l2.asOutput());
+    opBuilder.addInput(lrPower.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ApplyFtrl<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If `True`, updating of the var and accum tensors will be protected
+   * by a lock; otherwise the behavior is undefined, but may exhibit less
+   * contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * Same as "var".
+   */
+  public Output<T> out() {
+    return out;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return out;
+  }
+  
+  private Output<T> out;
+  
+  private ApplyFtrl(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    out = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ApplyFtrlV2.java java-ops/org/tensorflow/op/core/ApplyFtrlV2.java
--- java/org/tensorflow/op/core/ApplyFtrlV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ApplyFtrlV2.java	2018-10-16 20:18:38.164432428 +0900
@@ -0,0 +1,130 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update '*var' according to the Ftrl-proximal scheme.
+ * <p>
+ * grad_with_shrinkage = grad + 2 * l2_shrinkage * var
+ * accum_new = accum + grad_with_shrinkage * grad_with_shrinkage
+ * linear += grad_with_shrinkage +
+ *     (accum_new^(-lr_power) - accum^(-lr_power)) / lr * var
+ * quadratic = 1.0 / (accum_new^(lr_power) * lr) + 2 * l2
+ * var = (sign(linear) * l1 - linear) / quadratic if |linear| > l1 else 0.0
+ * accum = accum_new
+ * 
+ * @param <T> data type for {@code out()} output
+ */
+@Operator
+public final class ApplyFtrlV2<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ApplyFtrlV2}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If `True`, updating of the var and accum tensors will be protected
+     * by a lock; otherwise the behavior is undefined, but may exhibit less
+     * contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ApplyFtrlV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param accum Should be from a Variable().
+   * @param linear Should be from a Variable().
+   * @param grad The gradient.
+   * @param lr Scaling factor. Must be a scalar.
+   * @param l1 L1 regulariation. Must be a scalar.
+   * @param l2 L2 shrinkage regulariation. Must be a scalar.
+   * @param l2Shrinkage 
+   * @param lrPower Scaling factor. Must be a scalar.
+   * @param options carries optional attributes values
+   * @return a new instance of ApplyFtrlV2
+   */
+  public static <T> ApplyFtrlV2<T> create(Scope scope, Operand<T> var, Operand<T> accum, Operand<T> linear, Operand<T> grad, Operand<T> lr, Operand<T> l1, Operand<T> l2, Operand<T> l2Shrinkage, Operand<T> lrPower, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ApplyFtrlV2", scope.makeOpName("ApplyFtrlV2"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(accum.asOutput());
+    opBuilder.addInput(linear.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(l1.asOutput());
+    opBuilder.addInput(l2.asOutput());
+    opBuilder.addInput(l2Shrinkage.asOutput());
+    opBuilder.addInput(lrPower.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ApplyFtrlV2<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If `True`, updating of the var and accum tensors will be protected
+   * by a lock; otherwise the behavior is undefined, but may exhibit less
+   * contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * Same as "var".
+   */
+  public Output<T> out() {
+    return out;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return out;
+  }
+  
+  private Output<T> out;
+  
+  private ApplyFtrlV2(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    out = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ApplyGradientDescent.java java-ops/org/tensorflow/op/core/ApplyGradientDescent.java
--- java/org/tensorflow/op/core/ApplyGradientDescent.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ApplyGradientDescent.java	2018-10-16 20:18:38.164432428 +0900
@@ -0,0 +1,108 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update '*var' by subtracting 'alpha' * 'delta' from it.
+ * 
+ * @param <T> data type for {@code out()} output
+ */
+@Operator
+public final class ApplyGradientDescent<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ApplyGradientDescent}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If `True`, the subtraction will be protected by a lock;
+     * otherwise the behavior is undefined, but may exhibit less contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ApplyGradientDescent operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param alpha Scaling factor. Must be a scalar.
+   * @param delta The change.
+   * @param options carries optional attributes values
+   * @return a new instance of ApplyGradientDescent
+   */
+  public static <T> ApplyGradientDescent<T> create(Scope scope, Operand<T> var, Operand<T> alpha, Operand<T> delta, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ApplyGradientDescent", scope.makeOpName("ApplyGradientDescent"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(alpha.asOutput());
+    opBuilder.addInput(delta.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ApplyGradientDescent<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If `True`, the subtraction will be protected by a lock;
+   * otherwise the behavior is undefined, but may exhibit less contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * Same as "var".
+   */
+  public Output<T> out() {
+    return out;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return out;
+  }
+  
+  private Output<T> out;
+  
+  private ApplyGradientDescent(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    out = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ApplyMomentum.java java-ops/org/tensorflow/op/core/ApplyMomentum.java
--- java/org/tensorflow/op/core/ApplyMomentum.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ApplyMomentum.java	2018-10-16 20:18:38.165432427 +0900
@@ -0,0 +1,142 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update '*var' according to the momentum scheme. Set use_nesterov = True if you
+ * <p>
+ * want to use Nesterov momentum.
+ * <p>
+ * accum = accum * momentum + grad
+ * var -= lr * accum
+ * 
+ * @param <T> data type for {@code out()} output
+ */
+@Operator
+public final class ApplyMomentum<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ApplyMomentum}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If `True`, updating of the var and accum tensors will be protected
+     * by a lock; otherwise the behavior is undefined, but may exhibit less
+     * contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    /**
+     * @param useNesterov If `True`, the tensor passed to compute grad will be
+     * var - lr * momentum * accum, so in the end, the var you get is actually
+     * var - lr * momentum * accum.
+     */
+    public Options useNesterov(Boolean useNesterov) {
+      this.useNesterov = useNesterov;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    private Boolean useNesterov;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ApplyMomentum operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param accum Should be from a Variable().
+   * @param lr Scaling factor. Must be a scalar.
+   * @param grad The gradient.
+   * @param momentum Momentum. Must be a scalar.
+   * @param options carries optional attributes values
+   * @return a new instance of ApplyMomentum
+   */
+  public static <T> ApplyMomentum<T> create(Scope scope, Operand<T> var, Operand<T> accum, Operand<T> lr, Operand<T> grad, Operand<T> momentum, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ApplyMomentum", scope.makeOpName("ApplyMomentum"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(accum.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    opBuilder.addInput(momentum.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+        if (opts.useNesterov != null) {
+          opBuilder.setAttr("use_nesterov", opts.useNesterov);
+        }
+      }
+    }
+    return new ApplyMomentum<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If `True`, updating of the var and accum tensors will be protected
+   * by a lock; otherwise the behavior is undefined, but may exhibit less
+   * contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * @param useNesterov If `True`, the tensor passed to compute grad will be
+   * var - lr * momentum * accum, so in the end, the var you get is actually
+   * var - lr * momentum * accum.
+   */
+  public static Options useNesterov(Boolean useNesterov) {
+    return new Options().useNesterov(useNesterov);
+  }
+  
+  /**
+   * Same as "var".
+   */
+  public Output<T> out() {
+    return out;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return out;
+  }
+  
+  private Output<T> out;
+  
+  private ApplyMomentum(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    out = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ApplyPowerSign.java java-ops/org/tensorflow/op/core/ApplyPowerSign.java
--- java/org/tensorflow/op/core/ApplyPowerSign.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ApplyPowerSign.java	2018-10-16 20:18:38.165432427 +0900
@@ -0,0 +1,122 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update '*var' according to the AddSign update.
+ * <p>
+ * m_t <- beta1 * m_{t-1} + (1 - beta1) * g
+ * update <- exp(logbase * sign_decay * sign(g) * sign(m_t)) * g
+ * variable <- variable - lr_t * update
+ * 
+ * @param <T> data type for {@code out()} output
+ */
+@Operator
+public final class ApplyPowerSign<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ApplyPowerSign}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If `True`, updating of the var and m tensors is
+     * protected by a lock; otherwise the behavior is undefined, but may exhibit less
+     * contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ApplyPowerSign operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param m Should be from a Variable().
+   * @param lr Scaling factor. Must be a scalar.
+   * @param logbase Must be a scalar.
+   * @param signDecay Must be a scalar.
+   * @param beta Must be a scalar.
+   * @param grad The gradient.
+   * @param options carries optional attributes values
+   * @return a new instance of ApplyPowerSign
+   */
+  public static <T> ApplyPowerSign<T> create(Scope scope, Operand<T> var, Operand<T> m, Operand<T> lr, Operand<T> logbase, Operand<T> signDecay, Operand<T> beta, Operand<T> grad, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ApplyPowerSign", scope.makeOpName("ApplyPowerSign"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(m.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(logbase.asOutput());
+    opBuilder.addInput(signDecay.asOutput());
+    opBuilder.addInput(beta.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ApplyPowerSign<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If `True`, updating of the var and m tensors is
+   * protected by a lock; otherwise the behavior is undefined, but may exhibit less
+   * contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * Same as "var".
+   */
+  public Output<T> out() {
+    return out;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return out;
+  }
+  
+  private Output<T> out;
+  
+  private ApplyPowerSign(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    out = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ApplyProximalAdagrad.java java-ops/org/tensorflow/op/core/ApplyProximalAdagrad.java
--- java/org/tensorflow/op/core/ApplyProximalAdagrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ApplyProximalAdagrad.java	2018-10-16 20:18:38.166432427 +0900
@@ -0,0 +1,118 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update '*var' and '*accum' according to FOBOS with Adagrad learning rate.
+ * <p>
+ * accum += grad <i> grad
+ * prox_v = var - lr </i> grad <i> (1 / sqrt(accum))
+ * var = sign(prox_v)/(1+lr</i>l2) <i> max{|prox_v|-lr</i>l1,0}
+ * 
+ * @param <T> data type for {@code out()} output
+ */
+@Operator
+public final class ApplyProximalAdagrad<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ApplyProximalAdagrad}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If True, updating of the var and accum tensors will be protected by
+     * a lock; otherwise the behavior is undefined, but may exhibit less contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ApplyProximalAdagrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param accum Should be from a Variable().
+   * @param lr Scaling factor. Must be a scalar.
+   * @param l1 L1 regularization. Must be a scalar.
+   * @param l2 L2 regularization. Must be a scalar.
+   * @param grad The gradient.
+   * @param options carries optional attributes values
+   * @return a new instance of ApplyProximalAdagrad
+   */
+  public static <T> ApplyProximalAdagrad<T> create(Scope scope, Operand<T> var, Operand<T> accum, Operand<T> lr, Operand<T> l1, Operand<T> l2, Operand<T> grad, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ApplyProximalAdagrad", scope.makeOpName("ApplyProximalAdagrad"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(accum.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(l1.asOutput());
+    opBuilder.addInput(l2.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ApplyProximalAdagrad<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If True, updating of the var and accum tensors will be protected by
+   * a lock; otherwise the behavior is undefined, but may exhibit less contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * Same as "var".
+   */
+  public Output<T> out() {
+    return out;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return out;
+  }
+  
+  private Output<T> out;
+  
+  private ApplyProximalAdagrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    out = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ApplyProximalGradientDescent.java java-ops/org/tensorflow/op/core/ApplyProximalGradientDescent.java
--- java/org/tensorflow/op/core/ApplyProximalGradientDescent.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ApplyProximalGradientDescent.java	2018-10-16 20:18:38.166432427 +0900
@@ -0,0 +1,115 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update '*var' as FOBOS algorithm with fixed learning rate.
+ * <p>
+ * prox_v = var - alpha <i> delta
+ * var = sign(prox_v)/(1+alpha</i>l2) <i> max{|prox_v|-alpha</i>l1,0}
+ * 
+ * @param <T> data type for {@code out()} output
+ */
+@Operator
+public final class ApplyProximalGradientDescent<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ApplyProximalGradientDescent}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If True, the subtraction will be protected by a lock;
+     * otherwise the behavior is undefined, but may exhibit less contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ApplyProximalGradientDescent operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param alpha Scaling factor. Must be a scalar.
+   * @param l1 L1 regularization. Must be a scalar.
+   * @param l2 L2 regularization. Must be a scalar.
+   * @param delta The change.
+   * @param options carries optional attributes values
+   * @return a new instance of ApplyProximalGradientDescent
+   */
+  public static <T> ApplyProximalGradientDescent<T> create(Scope scope, Operand<T> var, Operand<T> alpha, Operand<T> l1, Operand<T> l2, Operand<T> delta, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ApplyProximalGradientDescent", scope.makeOpName("ApplyProximalGradientDescent"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(alpha.asOutput());
+    opBuilder.addInput(l1.asOutput());
+    opBuilder.addInput(l2.asOutput());
+    opBuilder.addInput(delta.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ApplyProximalGradientDescent<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If True, the subtraction will be protected by a lock;
+   * otherwise the behavior is undefined, but may exhibit less contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * Same as "var".
+   */
+  public Output<T> out() {
+    return out;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return out;
+  }
+  
+  private Output<T> out;
+  
+  private ApplyProximalGradientDescent(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    out = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ApplyRMSProp.java java-ops/org/tensorflow/op/core/ApplyRMSProp.java
--- java/org/tensorflow/op/core/ApplyRMSProp.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ApplyRMSProp.java	2018-10-16 20:18:38.167432426 +0900
@@ -0,0 +1,131 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update '*var' according to the RMSProp algorithm.
+ * <p>
+ * Note that in dense implementation of this algorithm, ms and mom will
+ * update even if the grad is zero, but in this sparse implementation, ms
+ * and mom will not update in iterations during which the grad is zero.
+ * <p>
+ * mean_square = decay * mean_square + (1-decay) * gradient ** 2
+ * Delta = learning_rate * gradient / sqrt(mean_square + epsilon)
+ * <p>
+ * ms <- rho * ms_{t-1} + (1-rho) * grad * grad
+ * mom <- momentum * mom_{t-1} + lr * grad / sqrt(ms + epsilon)
+ * var <- var - mom
+ * 
+ * @param <T> data type for {@code out()} output
+ */
+@Operator
+public final class ApplyRMSProp<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ApplyRMSProp}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If `True`, updating of the var, ms, and mom tensors is protected
+     * by a lock; otherwise the behavior is undefined, but may exhibit less
+     * contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ApplyRMSProp operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param ms Should be from a Variable().
+   * @param mom Should be from a Variable().
+   * @param lr Scaling factor. Must be a scalar.
+   * @param rho Decay rate. Must be a scalar.
+   * @param momentum 
+   * @param epsilon Ridge term. Must be a scalar.
+   * @param grad The gradient.
+   * @param options carries optional attributes values
+   * @return a new instance of ApplyRMSProp
+   */
+  public static <T> ApplyRMSProp<T> create(Scope scope, Operand<T> var, Operand<T> ms, Operand<T> mom, Operand<T> lr, Operand<T> rho, Operand<T> momentum, Operand<T> epsilon, Operand<T> grad, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ApplyRMSProp", scope.makeOpName("ApplyRMSProp"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(ms.asOutput());
+    opBuilder.addInput(mom.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(rho.asOutput());
+    opBuilder.addInput(momentum.asOutput());
+    opBuilder.addInput(epsilon.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ApplyRMSProp<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If `True`, updating of the var, ms, and mom tensors is protected
+   * by a lock; otherwise the behavior is undefined, but may exhibit less
+   * contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * Same as "var".
+   */
+  public Output<T> out() {
+    return out;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return out;
+  }
+  
+  private Output<T> out;
+  
+  private ApplyRMSProp(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    out = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ApproximateEqual.java java-ops/org/tensorflow/op/core/ApproximateEqual.java
--- java/org/tensorflow/op/core/ApproximateEqual.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ApproximateEqual.java	2018-10-16 20:18:38.167432426 +0900
@@ -0,0 +1,101 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns the truth value of abs(x-y) < tolerance element-wise.
+ */
+@Operator
+public final class ApproximateEqual extends PrimitiveOp implements Operand<Boolean> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ApproximateEqual}
+   */
+  public static class Options {
+    
+    /**
+     * @param tolerance 
+     */
+    public Options tolerance(Float tolerance) {
+      this.tolerance = tolerance;
+      return this;
+    }
+    
+    private Float tolerance;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ApproximateEqual operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param y 
+   * @param options carries optional attributes values
+   * @return a new instance of ApproximateEqual
+   */
+  public static <T> ApproximateEqual create(Scope scope, Operand<T> x, Operand<T> y, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ApproximateEqual", scope.makeOpName("ApproximateEqual"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(y.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.tolerance != null) {
+          opBuilder.setAttr("tolerance", opts.tolerance);
+        }
+      }
+    }
+    return new ApproximateEqual(opBuilder.build());
+  }
+  
+  /**
+   * @param tolerance 
+   */
+  public static Options tolerance(Float tolerance) {
+    return new Options().tolerance(tolerance);
+  }
+  
+  /**
+   */
+  public Output<Boolean> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<Boolean> asOutput() {
+    return z;
+  }
+  
+  private Output<Boolean> z;
+  
+  private ApproximateEqual(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ArgMax.java java-ops/org/tensorflow/op/core/ArgMax.java
--- java/org/tensorflow/op/core/ArgMax.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ArgMax.java	2018-10-16 20:18:38.168432425 +0900
@@ -0,0 +1,90 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns the index with the largest value across dimensions of a tensor.
+ * <p>
+ * Note that in case of ties the identity of the return value is not guaranteed.
+ * 
+ * @param <V> data type for {@code output()} output
+ */
+@Operator
+public final class ArgMax<V extends Number> extends PrimitiveOp implements Operand<V> {
+  
+  /**
+   * Factory method to create a class to wrap a new ArgMax operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param dimension int32 or int64, must be in the range `[-rank(input), rank(input))`.
+   * Describes which dimension of the input Tensor to reduce across. For vectors,
+   * use dimension = 0.
+   * @param outputType 
+   * @return a new instance of ArgMax
+   */
+  public static <V extends Number, T, U extends Number> ArgMax<V> create(Scope scope, Operand<T> input, Operand<U> dimension, Class<V> outputType) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ArgMax", scope.makeOpName("ArgMax"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(dimension.asOutput());
+    opBuilder.setAttr("output_type", DataType.fromClass(outputType));
+    return new ArgMax<V>(opBuilder.build());
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ArgMax operation to the graph, using default output types.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param dimension int32 or int64, must be in the range `[-rank(input), rank(input))`.
+   * Describes which dimension of the input Tensor to reduce across. For vectors,
+   * use dimension = 0.
+   * @return a new instance of ArgMax
+   */
+  public static <T, U extends Number> ArgMax<Long> create(Scope scope, Operand<T> input, Operand<U> dimension) {
+    return create(scope, input, dimension, Long.class);
+  }
+  
+  /**
+   */
+  public Output<V> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<V> asOutput() {
+    return output;
+  }
+  
+  private Output<V> output;
+  
+  private ArgMax(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ArgMin.java java-ops/org/tensorflow/op/core/ArgMin.java
--- java/org/tensorflow/op/core/ArgMin.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ArgMin.java	2018-10-16 20:18:38.168432425 +0900
@@ -0,0 +1,90 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns the index with the smallest value across dimensions of a tensor.
+ * <p>
+ * Note that in case of ties the identity of the return value is not guaranteed.
+ * 
+ * @param <V> data type for {@code output()} output
+ */
+@Operator
+public final class ArgMin<V extends Number> extends PrimitiveOp implements Operand<V> {
+  
+  /**
+   * Factory method to create a class to wrap a new ArgMin operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param dimension int32 or int64, must be in the range `[-rank(input), rank(input))`.
+   * Describes which dimension of the input Tensor to reduce across. For vectors,
+   * use dimension = 0.
+   * @param outputType 
+   * @return a new instance of ArgMin
+   */
+  public static <V extends Number, T, U extends Number> ArgMin<V> create(Scope scope, Operand<T> input, Operand<U> dimension, Class<V> outputType) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ArgMin", scope.makeOpName("ArgMin"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(dimension.asOutput());
+    opBuilder.setAttr("output_type", DataType.fromClass(outputType));
+    return new ArgMin<V>(opBuilder.build());
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ArgMin operation to the graph, using default output types.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param dimension int32 or int64, must be in the range `[-rank(input), rank(input))`.
+   * Describes which dimension of the input Tensor to reduce across. For vectors,
+   * use dimension = 0.
+   * @return a new instance of ArgMin
+   */
+  public static <T, U extends Number> ArgMin<Long> create(Scope scope, Operand<T> input, Operand<U> dimension) {
+    return create(scope, input, dimension, Long.class);
+  }
+  
+  /**
+   */
+  public Output<V> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<V> asOutput() {
+    return output;
+  }
+  
+  private Output<V> output;
+  
+  private ArgMin(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Asinh.java java-ops/org/tensorflow/op/core/Asinh.java
--- java/org/tensorflow/op/core/Asinh.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Asinh.java	2018-10-16 20:18:38.169432425 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes inverse hyperbolic sine of x element-wise.
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class Asinh<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Asinh operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of Asinh
+   */
+  public static <T> Asinh<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Asinh", scope.makeOpName("Asinh"));
+    opBuilder.addInput(x.asOutput());
+    return new Asinh<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private Asinh(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Asin.java java-ops/org/tensorflow/op/core/Asin.java
--- java/org/tensorflow/op/core/Asin.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Asin.java	2018-10-16 20:18:38.169432425 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes asin of x element-wise.
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class Asin<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Asin operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of Asin
+   */
+  public static <T> Asin<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Asin", scope.makeOpName("Asin"));
+    opBuilder.addInput(x.asOutput());
+    return new Asin<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private Asin(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Assert.java java-ops/org/tensorflow/op/core/Assert.java
--- java/org/tensorflow/op/core/Assert.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Assert.java	2018-10-16 20:18:38.169432425 +0900
@@ -0,0 +1,88 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Asserts that the given condition is true.
+ * <p>
+ * If `condition` evaluates to false, print the list of tensors in `data`.
+ * `summarize` determines how many entries of the tensors to print.
+ */
+public final class Assert extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Assert}
+   */
+  public static class Options {
+    
+    /**
+     * @param summarize Print this many entries of each tensor.
+     */
+    public Options summarize(Long summarize) {
+      this.summarize = summarize;
+      return this;
+    }
+    
+    private Long summarize;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Assert operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param condition The condition to evaluate.
+   * @param data The tensors to print out when condition is false.
+   * @param options carries optional attributes values
+   * @return a new instance of Assert
+   */
+  public static Assert create(Scope scope, Operand<Boolean> condition, Iterable<Operand<?>> data, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Assert", scope.makeOpName("Assert"));
+    opBuilder.addInput(condition.asOutput());
+    opBuilder.addInputList(Operands.asOutputs(data));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.summarize != null) {
+          opBuilder.setAttr("summarize", opts.summarize);
+        }
+      }
+    }
+    return new Assert(opBuilder.build());
+  }
+  
+  /**
+   * @param summarize Print this many entries of each tensor.
+   */
+  public static Options summarize(Long summarize) {
+    return new Options().summarize(summarize);
+  }
+  
+  
+  private Assert(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/AssignAdd.java java-ops/org/tensorflow/op/core/AssignAdd.java
--- java/org/tensorflow/op/core/AssignAdd.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/AssignAdd.java	2018-10-16 20:18:38.170432424 +0900
@@ -0,0 +1,110 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update 'ref' by adding 'value' to it.
+ * <p>
+ * This operation outputs "ref" after the update is done.
+ * This makes it easier to chain operations that need to use the reset value.
+ * 
+ * @param <T> data type for {@code outputRef()} output
+ */
+@Operator
+public final class AssignAdd<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.AssignAdd}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If True, the addition will be protected by a lock;
+     * otherwise the behavior is undefined, but may exhibit less contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new AssignAdd operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param ref Should be from a `Variable` node.
+   * @param value The value to be added to the variable.
+   * @param options carries optional attributes values
+   * @return a new instance of AssignAdd
+   */
+  public static <T> AssignAdd<T> create(Scope scope, Operand<T> ref, Operand<T> value, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("AssignAdd", scope.makeOpName("AssignAdd"));
+    opBuilder.addInput(ref.asOutput());
+    opBuilder.addInput(value.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new AssignAdd<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If True, the addition will be protected by a lock;
+   * otherwise the behavior is undefined, but may exhibit less contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * = Same as "ref".  Returned as a convenience for operations that want
+   * to use the new value after the variable has been updated.
+   */
+  public Output<T> outputRef() {
+    return outputRef;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return outputRef;
+  }
+  
+  private Output<T> outputRef;
+  
+  private AssignAdd(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    outputRef = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/AssignAddVariableOp.java java-ops/org/tensorflow/op/core/AssignAddVariableOp.java
--- java/org/tensorflow/op/core/AssignAddVariableOp.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/AssignAddVariableOp.java	2018-10-16 20:18:38.170432424 +0900
@@ -0,0 +1,55 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Adds a value to the current value of a variable.
+ * <p>
+ * Any ReadVariableOp with a control dependency on this op is guaranteed to
+ * see the incremented value or a subsequent newer one.
+ */
+@Operator
+public final class AssignAddVariableOp extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new AssignAddVariableOp operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param resource handle to the resource in which to store the variable.
+   * @param value the value by which the variable will be incremented.
+   * @return a new instance of AssignAddVariableOp
+   */
+  public static <T> AssignAddVariableOp create(Scope scope, Operand<?> resource, Operand<T> value) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("AssignAddVariableOp", scope.makeOpName("AssignAddVariableOp"));
+    opBuilder.addInput(resource.asOutput());
+    opBuilder.addInput(value.asOutput());
+    return new AssignAddVariableOp(opBuilder.build());
+  }
+  
+  
+  private AssignAddVariableOp(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Assign.java java-ops/org/tensorflow/op/core/Assign.java
--- java/org/tensorflow/op/core/Assign.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Assign.java	2018-10-16 20:18:38.170432424 +0900
@@ -0,0 +1,133 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update 'ref' by assigning 'value' to it.
+ * <p>
+ * This operation outputs "ref" after the assignment is done.
+ * This makes it easier to chain operations that need to use the reset value.
+ * 
+ * @param <T> data type for {@code outputRef()} output
+ */
+@Operator
+public final class Assign<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Assign}
+   */
+  public static class Options {
+    
+    /**
+     * @param validateShape If true, the operation will validate that the shape
+     * of 'value' matches the shape of the Tensor being assigned to.  If false,
+     * 'ref' will take on the shape of 'value'.
+     */
+    public Options validateShape(Boolean validateShape) {
+      this.validateShape = validateShape;
+      return this;
+    }
+    
+    /**
+     * @param useLocking If True, the assignment will be protected by a lock;
+     * otherwise the behavior is undefined, but may exhibit less contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean validateShape;
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Assign operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param ref Should be from a `Variable` node. May be uninitialized.
+   * @param value The value to be assigned to the variable.
+   * @param options carries optional attributes values
+   * @return a new instance of Assign
+   */
+  public static <T> Assign<T> create(Scope scope, Operand<T> ref, Operand<T> value, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Assign", scope.makeOpName("Assign"));
+    opBuilder.addInput(ref.asOutput());
+    opBuilder.addInput(value.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.validateShape != null) {
+          opBuilder.setAttr("validate_shape", opts.validateShape);
+        }
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new Assign<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param validateShape If true, the operation will validate that the shape
+   * of 'value' matches the shape of the Tensor being assigned to.  If false,
+   * 'ref' will take on the shape of 'value'.
+   */
+  public static Options validateShape(Boolean validateShape) {
+    return new Options().validateShape(validateShape);
+  }
+  
+  /**
+   * @param useLocking If True, the assignment will be protected by a lock;
+   * otherwise the behavior is undefined, but may exhibit less contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * = Same as "ref".  Returned as a convenience for operations that want
+   * to use the new value after the variable has been reset.
+   */
+  public Output<T> outputRef() {
+    return outputRef;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return outputRef;
+  }
+  
+  private Output<T> outputRef;
+  
+  private Assign(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    outputRef = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/AssignSub.java java-ops/org/tensorflow/op/core/AssignSub.java
--- java/org/tensorflow/op/core/AssignSub.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/AssignSub.java	2018-10-16 20:18:38.170432424 +0900
@@ -0,0 +1,110 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update 'ref' by subtracting 'value' from it.
+ * <p>
+ * This operation outputs "ref" after the update is done.
+ * This makes it easier to chain operations that need to use the reset value.
+ * 
+ * @param <T> data type for {@code outputRef()} output
+ */
+@Operator
+public final class AssignSub<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.AssignSub}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If True, the subtraction will be protected by a lock;
+     * otherwise the behavior is undefined, but may exhibit less contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new AssignSub operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param ref Should be from a `Variable` node.
+   * @param value The value to be subtracted to the variable.
+   * @param options carries optional attributes values
+   * @return a new instance of AssignSub
+   */
+  public static <T> AssignSub<T> create(Scope scope, Operand<T> ref, Operand<T> value, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("AssignSub", scope.makeOpName("AssignSub"));
+    opBuilder.addInput(ref.asOutput());
+    opBuilder.addInput(value.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new AssignSub<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If True, the subtraction will be protected by a lock;
+   * otherwise the behavior is undefined, but may exhibit less contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * = Same as "ref".  Returned as a convenience for operations that want
+   * to use the new value after the variable has been updated.
+   */
+  public Output<T> outputRef() {
+    return outputRef;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return outputRef;
+  }
+  
+  private Output<T> outputRef;
+  
+  private AssignSub(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    outputRef = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/AssignSubVariableOp.java java-ops/org/tensorflow/op/core/AssignSubVariableOp.java
--- java/org/tensorflow/op/core/AssignSubVariableOp.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/AssignSubVariableOp.java	2018-10-16 20:18:38.171432423 +0900
@@ -0,0 +1,55 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Subtracts a value from the current value of a variable.
+ * <p>
+ * Any ReadVariableOp with a control dependency on this op is guaranteed to
+ * see the decremented value or a subsequent newer one.
+ */
+@Operator
+public final class AssignSubVariableOp extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new AssignSubVariableOp operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param resource handle to the resource in which to store the variable.
+   * @param value the value by which the variable will be incremented.
+   * @return a new instance of AssignSubVariableOp
+   */
+  public static <T> AssignSubVariableOp create(Scope scope, Operand<?> resource, Operand<T> value) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("AssignSubVariableOp", scope.makeOpName("AssignSubVariableOp"));
+    opBuilder.addInput(resource.asOutput());
+    opBuilder.addInput(value.asOutput());
+    return new AssignSubVariableOp(opBuilder.build());
+  }
+  
+  
+  private AssignSubVariableOp(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/AssignVariableOp.java java-ops/org/tensorflow/op/core/AssignVariableOp.java
--- java/org/tensorflow/op/core/AssignVariableOp.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/AssignVariableOp.java	2018-10-16 20:18:38.171432423 +0900
@@ -0,0 +1,55 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Assigns a new value to a variable.
+ * <p>
+ * Any ReadVariableOp with a control dependency on this op is guaranteed to return
+ * this value or a subsequent newer value of the variable.
+ */
+@Operator
+public final class AssignVariableOp extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new AssignVariableOp operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param resource handle to the resource in which to store the variable.
+   * @param value the value to set the new tensor to use.
+   * @return a new instance of AssignVariableOp
+   */
+  public static <T> AssignVariableOp create(Scope scope, Operand<?> resource, Operand<T> value) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("AssignVariableOp", scope.makeOpName("AssignVariableOp"));
+    opBuilder.addInput(resource.asOutput());
+    opBuilder.addInput(value.asOutput());
+    return new AssignVariableOp(opBuilder.build());
+  }
+  
+  
+  private AssignVariableOp(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/AsString.java java-ops/org/tensorflow/op/core/AsString.java
--- java/org/tensorflow/op/core/AsString.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/AsString.java	2018-10-16 20:18:38.169432425 +0900
@@ -0,0 +1,187 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Converts each entry in the given tensor to strings.  Supports many numeric
+ * <p>
+ * types and boolean.
+ */
+@Operator
+public final class AsString extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.AsString}
+   */
+  public static class Options {
+    
+    /**
+     * @param precision The post-decimal precision to use for floating point numbers.
+     * Only used if precision > -1.
+     */
+    public Options precision(Long precision) {
+      this.precision = precision;
+      return this;
+    }
+    
+    /**
+     * @param scientific Use scientific notation for floating point numbers.
+     */
+    public Options scientific(Boolean scientific) {
+      this.scientific = scientific;
+      return this;
+    }
+    
+    /**
+     * @param shortest Use shortest representation (either scientific or standard) for
+     * floating point numbers.
+     */
+    public Options shortest(Boolean shortest) {
+      this.shortest = shortest;
+      return this;
+    }
+    
+    /**
+     * @param width Pad pre-decimal numbers to this width.
+     * Applies to both floating point and integer numbers.
+     * Only used if width > -1.
+     */
+    public Options width(Long width) {
+      this.width = width;
+      return this;
+    }
+    
+    /**
+     * @param fill The value to pad if width > -1.  If empty, pads with spaces.
+     * Another typical value is '0'.  String cannot be longer than 1 character.
+     */
+    public Options fill(String fill) {
+      this.fill = fill;
+      return this;
+    }
+    
+    private Long precision;
+    private Boolean scientific;
+    private Boolean shortest;
+    private Long width;
+    private String fill;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new AsString operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param options carries optional attributes values
+   * @return a new instance of AsString
+   */
+  public static <T> AsString create(Scope scope, Operand<T> input, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("AsString", scope.makeOpName("AsString"));
+    opBuilder.addInput(input.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.precision != null) {
+          opBuilder.setAttr("precision", opts.precision);
+        }
+        if (opts.scientific != null) {
+          opBuilder.setAttr("scientific", opts.scientific);
+        }
+        if (opts.shortest != null) {
+          opBuilder.setAttr("shortest", opts.shortest);
+        }
+        if (opts.width != null) {
+          opBuilder.setAttr("width", opts.width);
+        }
+        if (opts.fill != null) {
+          opBuilder.setAttr("fill", opts.fill);
+        }
+      }
+    }
+    return new AsString(opBuilder.build());
+  }
+  
+  /**
+   * @param precision The post-decimal precision to use for floating point numbers.
+   * Only used if precision > -1.
+   */
+  public static Options precision(Long precision) {
+    return new Options().precision(precision);
+  }
+  
+  /**
+   * @param scientific Use scientific notation for floating point numbers.
+   */
+  public static Options scientific(Boolean scientific) {
+    return new Options().scientific(scientific);
+  }
+  
+  /**
+   * @param shortest Use shortest representation (either scientific or standard) for
+   * floating point numbers.
+   */
+  public static Options shortest(Boolean shortest) {
+    return new Options().shortest(shortest);
+  }
+  
+  /**
+   * @param width Pad pre-decimal numbers to this width.
+   * Applies to both floating point and integer numbers.
+   * Only used if width > -1.
+   */
+  public static Options width(Long width) {
+    return new Options().width(width);
+  }
+  
+  /**
+   * @param fill The value to pad if width > -1.  If empty, pads with spaces.
+   * Another typical value is '0'.  String cannot be longer than 1 character.
+   */
+  public static Options fill(String fill) {
+    return new Options().fill(fill);
+  }
+  
+  /**
+   */
+  public Output<String> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return output;
+  }
+  
+  private Output<String> output;
+  
+  private AsString(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Atan2.java java-ops/org/tensorflow/op/core/Atan2.java
--- java/org/tensorflow/op/core/Atan2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Atan2.java	2018-10-16 20:18:38.171432423 +0900
@@ -0,0 +1,75 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes arctangent of `y/x` element-wise, respecting signs of the arguments.
+ * <p>
+ * This is the angle \( \theta \in [-\pi, \pi] \) such that
+ * \[ x = r \cos(\theta) \]
+ * and
+ * \[ y = r \sin(\theta) \]
+ * where \(r = \sqrt(x^2 + y^2) \).
+ * 
+ * @param <T> data type for {@code z()} output
+ */
+@Operator
+public final class Atan2<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Atan2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param y 
+   * @param x 
+   * @return a new instance of Atan2
+   */
+  public static <T extends Number> Atan2<T> create(Scope scope, Operand<T> y, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Atan2", scope.makeOpName("Atan2"));
+    opBuilder.addInput(y.asOutput());
+    opBuilder.addInput(x.asOutput());
+    return new Atan2<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return z;
+  }
+  
+  private Output<T> z;
+  
+  private Atan2(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Atanh.java java-ops/org/tensorflow/op/core/Atanh.java
--- java/org/tensorflow/op/core/Atanh.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Atanh.java	2018-10-16 20:18:38.172432423 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes inverse hyperbolic tangent of x element-wise.
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class Atanh<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Atanh operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of Atanh
+   */
+  public static <T> Atanh<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Atanh", scope.makeOpName("Atanh"));
+    opBuilder.addInput(x.asOutput());
+    return new Atanh<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private Atanh(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Atan.java java-ops/org/tensorflow/op/core/Atan.java
--- java/org/tensorflow/op/core/Atan.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Atan.java	2018-10-16 20:18:38.171432423 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes atan of x element-wise.
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class Atan<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Atan operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of Atan
+   */
+  public static <T> Atan<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Atan", scope.makeOpName("Atan"));
+    opBuilder.addInput(x.asOutput());
+    return new Atan<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private Atan(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/AudioSpectrogram.java java-ops/org/tensorflow/op/core/AudioSpectrogram.java
--- java/org/tensorflow/op/core/AudioSpectrogram.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/AudioSpectrogram.java	2018-10-16 20:18:38.172432423 +0900
@@ -0,0 +1,133 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Produces a visualization of audio data over time.
+ * <p>
+ * Spectrograms are a standard way of representing audio information as a series of
+ * slices of frequency information, one slice for each window of time. By joining
+ * these together into a sequence, they form a distinctive fingerprint of the sound
+ * over time.
+ * <p>
+ * This op expects to receive audio data as an input, stored as floats in the range
+ * -1 to 1, together with a window width in samples, and a stride specifying how
+ * far to move the window between slices. From this it generates a three
+ * dimensional output. The lowest dimension has an amplitude value for each
+ * frequency during that time slice. The next dimension is time, with successive
+ * frequency slices. The final dimension is for the channels in the input, so a
+ * stereo audio input would have two here for example.
+ * <p>
+ * This means the layout when converted and saved as an image is rotated 90 degrees
+ * clockwise from a typical spectrogram. Time is descending down the Y axis, and
+ * the frequency decreases from left to right.
+ * <p>
+ * Each value in the result represents the square root of the sum of the real and
+ * imaginary parts of an FFT on the current window of samples. In this way, the
+ * lowest dimension represents the power of each frequency in the current window,
+ * and adjacent windows are concatenated in the next dimension.
+ * <p>
+ * To get a more intuitive and visual look at what this operation does, you can run
+ * tensorflow/examples/wav_to_spectrogram to read in an audio file and save out the
+ * resulting spectrogram as a PNG image.
+ */
+@Operator
+public final class AudioSpectrogram extends PrimitiveOp implements Operand<Float> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.AudioSpectrogram}
+   */
+  public static class Options {
+    
+    /**
+     * @param magnitudeSquared Whether to return the squared magnitude or just the
+     * magnitude. Using squared magnitude can avoid extra calculations.
+     */
+    public Options magnitudeSquared(Boolean magnitudeSquared) {
+      this.magnitudeSquared = magnitudeSquared;
+      return this;
+    }
+    
+    private Boolean magnitudeSquared;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new AudioSpectrogram operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input Float representation of audio data.
+   * @param windowSize How wide the input window is in samples. For the highest efficiency
+   * this should be a power of two, but other values are accepted.
+   * @param stride How widely apart the center of adjacent sample windows should be.
+   * @param options carries optional attributes values
+   * @return a new instance of AudioSpectrogram
+   */
+  public static AudioSpectrogram create(Scope scope, Operand<Float> input, Long windowSize, Long stride, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("AudioSpectrogram", scope.makeOpName("AudioSpectrogram"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.setAttr("window_size", windowSize);
+    opBuilder.setAttr("stride", stride);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.magnitudeSquared != null) {
+          opBuilder.setAttr("magnitude_squared", opts.magnitudeSquared);
+        }
+      }
+    }
+    return new AudioSpectrogram(opBuilder.build());
+  }
+  
+  /**
+   * @param magnitudeSquared Whether to return the squared magnitude or just the
+   * magnitude. Using squared magnitude can avoid extra calculations.
+   */
+  public static Options magnitudeSquared(Boolean magnitudeSquared) {
+    return new Options().magnitudeSquared(magnitudeSquared);
+  }
+  
+  /**
+   * 3D representation of the audio frequencies as an image.
+   */
+  public Output<Float> spectrogram() {
+    return spectrogram;
+  }
+  
+  @Override
+  public Output<Float> asOutput() {
+    return spectrogram;
+  }
+  
+  private Output<Float> spectrogram;
+  
+  private AudioSpectrogram(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    spectrogram = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/AudioSummary.java java-ops/org/tensorflow/op/core/AudioSummary.java
--- java/org/tensorflow/op/core/AudioSummary.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/AudioSummary.java	2018-10-16 20:18:38.174432421 +0900
@@ -0,0 +1,119 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Outputs a `Summary` protocol buffer with audio.
+ * <p>
+ * The summary has up to `max_outputs` summary values containing audio. The
+ * audio is built from `tensor` which must be 3-D with shape `[batch_size,
+ * frames, channels]` or 2-D with shape `[batch_size, frames]`. The values are
+ * assumed to be in the range of `[-1.0, 1.0]` with a sample rate of `sample_rate`.
+ * <p>
+ * The `tag` argument is a scalar `Tensor` of type `string`.  It is used to
+ * build the `tag` of the summary values:
+ * <ul>
+ * <li>
+ * If `max_outputs` is 1, the summary value tag is '<i>tag</i>/audio'.
+ * </li>
+ * <li>
+ * If `max_outputs` is greater than 1, the summary value tags are
+ *    generated sequentially as '<i>tag</i>/audio/0', '<i>tag</i>/audio/1', etc.
+ */
+@Operator
+public final class AudioSummary extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.AudioSummary}
+   */
+  public static class Options {
+    
+    /**
+     * @param maxOutputs Max number of batch elements to generate audio for.
+     */
+    public Options maxOutputs(Long maxOutputs) {
+      this.maxOutputs = maxOutputs;
+      return this;
+    }
+    
+    private Long maxOutputs;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new AudioSummary operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param tag Scalar. Used to build the `tag` attribute of the summary values.
+   * @param tensor 2-D of shape `[batch_size, frames]`.
+   * @param sampleRate The sample rate of the signal in hertz.
+   * @param options carries optional attributes values
+   * @return a new instance of AudioSummary
+   */
+  public static AudioSummary create(Scope scope, Operand<String> tag, Operand<Float> tensor, Operand<Float> sampleRate, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("AudioSummaryV2", scope.makeOpName("AudioSummary"));
+    opBuilder.addInput(tag.asOutput());
+    opBuilder.addInput(tensor.asOutput());
+    opBuilder.addInput(sampleRate.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.maxOutputs != null) {
+          opBuilder.setAttr("max_outputs", opts.maxOutputs);
+        }
+      }
+    }
+    return new AudioSummary(opBuilder.build());
+  }
+  
+  /**
+   * @param maxOutputs Max number of batch elements to generate audio for.
+   */
+  public static Options maxOutputs(Long maxOutputs) {
+    return new Options().maxOutputs(maxOutputs);
+  }
+  
+  /**
+   * Scalar. Serialized `Summary` protocol buffer.
+   */
+  public Output<String> summary() {
+    return summary;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return summary;
+  }
+  
+  private Output<String> summary;
+  
+  private AudioSummary(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    summary = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/AvgPool3DGrad.java java-ops/org/tensorflow/op/core/AvgPool3DGrad.java
--- java/org/tensorflow/op/core/AvgPool3DGrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/AvgPool3DGrad.java	2018-10-16 20:18:38.176432420 +0900
@@ -0,0 +1,129 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes gradients of average pooling function.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class AvgPool3DGrad<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.AvgPool3DGrad}
+   */
+  public static class Options {
+    
+    /**
+     * @param dataFormat The data format of the input and output data. With the
+     * default format "NDHWC", the data is stored in the order of:
+     *     [batch, in_depth, in_height, in_width, in_channels].
+     * Alternatively, the format could be "NCDHW", the data storage order is:
+     *     [batch, in_channels, in_depth, in_height, in_width].
+     */
+    public Options dataFormat(String dataFormat) {
+      this.dataFormat = dataFormat;
+      return this;
+    }
+    
+    private String dataFormat;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new AvgPool3DGrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param origInputShape The original input dimensions.
+   * @param grad Output backprop of shape `[batch, depth, rows, cols, channels]`.
+   * @param ksize 1-D tensor of length 5. The size of the window for each dimension of
+   * the input tensor. Must have `ksize[0] = ksize[4] = 1`.
+   * @param strides 1-D tensor of length 5. The stride of the sliding window for each
+   * dimension of `input`. Must have `strides[0] = strides[4] = 1`.
+   * @param padding The type of padding algorithm to use.
+   * @param options carries optional attributes values
+   * @return a new instance of AvgPool3DGrad
+   */
+  public static <T extends Number> AvgPool3DGrad<T> create(Scope scope, Operand<Integer> origInputShape, Operand<T> grad, List<Long> ksize, List<Long> strides, String padding, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("AvgPool3DGrad", scope.makeOpName("AvgPool3DGrad"));
+    opBuilder.addInput(origInputShape.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    long[] ksizeArray = new long[ksize.size()];
+    for (int i = 0; i < ksizeArray.length; ++i) {
+      ksizeArray[i] = ksize.get(i);
+    }
+    opBuilder.setAttr("ksize", ksizeArray);
+    long[] stridesArray = new long[strides.size()];
+    for (int i = 0; i < stridesArray.length; ++i) {
+      stridesArray[i] = strides.get(i);
+    }
+    opBuilder.setAttr("strides", stridesArray);
+    opBuilder.setAttr("padding", padding);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.dataFormat != null) {
+          opBuilder.setAttr("data_format", opts.dataFormat);
+        }
+      }
+    }
+    return new AvgPool3DGrad<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param dataFormat The data format of the input and output data. With the
+   * default format "NDHWC", the data is stored in the order of:
+   *     [batch, in_depth, in_height, in_width, in_channels].
+   * Alternatively, the format could be "NCDHW", the data storage order is:
+   *     [batch, in_channels, in_depth, in_height, in_width].
+   */
+  public static Options dataFormat(String dataFormat) {
+    return new Options().dataFormat(dataFormat);
+  }
+  
+  /**
+   * The backprop for input.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private AvgPool3DGrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/AvgPool3D.java java-ops/org/tensorflow/op/core/AvgPool3D.java
--- java/org/tensorflow/op/core/AvgPool3D.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/AvgPool3D.java	2018-10-16 20:18:38.175432421 +0900
@@ -0,0 +1,127 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Performs 3D average pooling on the input.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class AvgPool3D<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.AvgPool3D}
+   */
+  public static class Options {
+    
+    /**
+     * @param dataFormat The data format of the input and output data. With the
+     * default format "NDHWC", the data is stored in the order of:
+     *     [batch, in_depth, in_height, in_width, in_channels].
+     * Alternatively, the format could be "NCDHW", the data storage order is:
+     *     [batch, in_channels, in_depth, in_height, in_width].
+     */
+    public Options dataFormat(String dataFormat) {
+      this.dataFormat = dataFormat;
+      return this;
+    }
+    
+    private String dataFormat;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new AvgPool3D operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input Shape `[batch, depth, rows, cols, channels]` tensor to pool over.
+   * @param ksize 1-D tensor of length 5. The size of the window for each dimension of
+   * the input tensor. Must have `ksize[0] = ksize[4] = 1`.
+   * @param strides 1-D tensor of length 5. The stride of the sliding window for each
+   * dimension of `input`. Must have `strides[0] = strides[4] = 1`.
+   * @param padding The type of padding algorithm to use.
+   * @param options carries optional attributes values
+   * @return a new instance of AvgPool3D
+   */
+  public static <T extends Number> AvgPool3D<T> create(Scope scope, Operand<T> input, List<Long> ksize, List<Long> strides, String padding, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("AvgPool3D", scope.makeOpName("AvgPool3D"));
+    opBuilder.addInput(input.asOutput());
+    long[] ksizeArray = new long[ksize.size()];
+    for (int i = 0; i < ksizeArray.length; ++i) {
+      ksizeArray[i] = ksize.get(i);
+    }
+    opBuilder.setAttr("ksize", ksizeArray);
+    long[] stridesArray = new long[strides.size()];
+    for (int i = 0; i < stridesArray.length; ++i) {
+      stridesArray[i] = strides.get(i);
+    }
+    opBuilder.setAttr("strides", stridesArray);
+    opBuilder.setAttr("padding", padding);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.dataFormat != null) {
+          opBuilder.setAttr("data_format", opts.dataFormat);
+        }
+      }
+    }
+    return new AvgPool3D<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param dataFormat The data format of the input and output data. With the
+   * default format "NDHWC", the data is stored in the order of:
+   *     [batch, in_depth, in_height, in_width, in_channels].
+   * Alternatively, the format could be "NCDHW", the data storage order is:
+   *     [batch, in_channels, in_depth, in_height, in_width].
+   */
+  public static Options dataFormat(String dataFormat) {
+    return new Options().dataFormat(dataFormat);
+  }
+  
+  /**
+   * The average pooled output tensor.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private AvgPool3D(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/AvgPoolGrad.java java-ops/org/tensorflow/op/core/AvgPoolGrad.java
--- java/org/tensorflow/op/core/AvgPoolGrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/AvgPoolGrad.java	2018-10-16 20:18:38.177432419 +0900
@@ -0,0 +1,126 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Computes gradients of the average pooling function.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+public final class AvgPoolGrad<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.AvgPoolGrad}
+   */
+  public static class Options {
+    
+    /**
+     * @param dataFormat Specify the data format of the input and output data. With the
+     * default format "NHWC", the data is stored in the order of:
+     *     [batch, in_height, in_width, in_channels].
+     * Alternatively, the format could be "NCHW", the data storage order of:
+     *     [batch, in_channels, in_height, in_width].
+     */
+    public Options dataFormat(String dataFormat) {
+      this.dataFormat = dataFormat;
+      return this;
+    }
+    
+    private String dataFormat;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new AvgPoolGrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param origInputShape 1-D.  Shape of the original input to `avg_pool`.
+   * @param grad 4-D with shape `[batch, height, width, channels]`.  Gradients w.r.t.
+   * the output of `avg_pool`.
+   * @param ksize The size of the sliding window for each dimension of the input.
+   * @param strides The stride of the sliding window for each dimension of the input.
+   * @param padding The type of padding algorithm to use.
+   * @param options carries optional attributes values
+   * @return a new instance of AvgPoolGrad
+   */
+  public static <T extends Number> AvgPoolGrad<T> create(Scope scope, Operand<Integer> origInputShape, Operand<T> grad, List<Long> ksize, List<Long> strides, String padding, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("AvgPoolGrad", scope.makeOpName("AvgPoolGrad"));
+    opBuilder.addInput(origInputShape.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    long[] ksizeArray = new long[ksize.size()];
+    for (int i = 0; i < ksizeArray.length; ++i) {
+      ksizeArray[i] = ksize.get(i);
+    }
+    opBuilder.setAttr("ksize", ksizeArray);
+    long[] stridesArray = new long[strides.size()];
+    for (int i = 0; i < stridesArray.length; ++i) {
+      stridesArray[i] = strides.get(i);
+    }
+    opBuilder.setAttr("strides", stridesArray);
+    opBuilder.setAttr("padding", padding);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.dataFormat != null) {
+          opBuilder.setAttr("data_format", opts.dataFormat);
+        }
+      }
+    }
+    return new AvgPoolGrad<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param dataFormat Specify the data format of the input and output data. With the
+   * default format "NHWC", the data is stored in the order of:
+   *     [batch, in_height, in_width, in_channels].
+   * Alternatively, the format could be "NCHW", the data storage order of:
+   *     [batch, in_channels, in_height, in_width].
+   */
+  public static Options dataFormat(String dataFormat) {
+    return new Options().dataFormat(dataFormat);
+  }
+  
+  /**
+   * 4-D.  Gradients w.r.t. the input of `avg_pool`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private AvgPoolGrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/AvgPool.java java-ops/org/tensorflow/op/core/AvgPool.java
--- java/org/tensorflow/op/core/AvgPool.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/AvgPool.java	2018-10-16 20:18:38.174432421 +0900
@@ -0,0 +1,128 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Performs average pooling on the input.
+ * <p>
+ * Each entry in `output` is the mean of the corresponding size `ksize`
+ * window in `value`.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class AvgPool<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.AvgPool}
+   */
+  public static class Options {
+    
+    /**
+     * @param dataFormat Specify the data format of the input and output data. With the
+     * default format "NHWC", the data is stored in the order of:
+     *     [batch, in_height, in_width, in_channels].
+     * Alternatively, the format could be "NCHW", the data storage order of:
+     *     [batch, in_channels, in_height, in_width].
+     */
+    public Options dataFormat(String dataFormat) {
+      this.dataFormat = dataFormat;
+      return this;
+    }
+    
+    private String dataFormat;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new AvgPool operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param value 4-D with shape `[batch, height, width, channels]`.
+   * @param ksize The size of the sliding window for each dimension of `value`.
+   * @param strides The stride of the sliding window for each dimension of `value`.
+   * @param padding The type of padding algorithm to use.
+   * @param options carries optional attributes values
+   * @return a new instance of AvgPool
+   */
+  public static <T extends Number> AvgPool<T> create(Scope scope, Operand<T> value, List<Long> ksize, List<Long> strides, String padding, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("AvgPool", scope.makeOpName("AvgPool"));
+    opBuilder.addInput(value.asOutput());
+    long[] ksizeArray = new long[ksize.size()];
+    for (int i = 0; i < ksizeArray.length; ++i) {
+      ksizeArray[i] = ksize.get(i);
+    }
+    opBuilder.setAttr("ksize", ksizeArray);
+    long[] stridesArray = new long[strides.size()];
+    for (int i = 0; i < stridesArray.length; ++i) {
+      stridesArray[i] = strides.get(i);
+    }
+    opBuilder.setAttr("strides", stridesArray);
+    opBuilder.setAttr("padding", padding);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.dataFormat != null) {
+          opBuilder.setAttr("data_format", opts.dataFormat);
+        }
+      }
+    }
+    return new AvgPool<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param dataFormat Specify the data format of the input and output data. With the
+   * default format "NHWC", the data is stored in the order of:
+   *     [batch, in_height, in_width, in_channels].
+   * Alternatively, the format could be "NCHW", the data storage order of:
+   *     [batch, in_channels, in_height, in_width].
+   */
+  public static Options dataFormat(String dataFormat) {
+    return new Options().dataFormat(dataFormat);
+  }
+  
+  /**
+   * The average pooled output tensor.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private AvgPool(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BarrierClose.java java-ops/org/tensorflow/op/core/BarrierClose.java
--- java/org/tensorflow/op/core/BarrierClose.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BarrierClose.java	2018-10-16 20:18:38.177432419 +0900
@@ -0,0 +1,95 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Closes the given barrier.
+ * <p>
+ * This operation signals that no more new elements will be inserted in the
+ * given barrier. Subsequent InsertMany that try to introduce a new key will fail.
+ * Subsequent InsertMany operations that just add missing components to already
+ * existing elements will continue to succeed. Subsequent TakeMany operations will
+ * continue to succeed if sufficient completed elements remain in the barrier.
+ * Subsequent TakeMany operations that would block will fail immediately.
+ */
+@Operator
+public final class BarrierClose extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.BarrierClose}
+   */
+  public static class Options {
+    
+    /**
+     * @param cancelPendingEnqueues If true, all pending enqueue requests that are
+     * blocked on the barrier's queue will be canceled. InsertMany will fail, even
+     * if no new key is introduced.
+     */
+    public Options cancelPendingEnqueues(Boolean cancelPendingEnqueues) {
+      this.cancelPendingEnqueues = cancelPendingEnqueues;
+      return this;
+    }
+    
+    private Boolean cancelPendingEnqueues;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new BarrierClose operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param handle The handle to a barrier.
+   * @param options carries optional attributes values
+   * @return a new instance of BarrierClose
+   */
+  public static BarrierClose create(Scope scope, Operand<String> handle, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BarrierClose", scope.makeOpName("BarrierClose"));
+    opBuilder.addInput(handle.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.cancelPendingEnqueues != null) {
+          opBuilder.setAttr("cancel_pending_enqueues", opts.cancelPendingEnqueues);
+        }
+      }
+    }
+    return new BarrierClose(opBuilder.build());
+  }
+  
+  /**
+   * @param cancelPendingEnqueues If true, all pending enqueue requests that are
+   * blocked on the barrier's queue will be canceled. InsertMany will fail, even
+   * if no new key is introduced.
+   */
+  public static Options cancelPendingEnqueues(Boolean cancelPendingEnqueues) {
+    return new Options().cancelPendingEnqueues(cancelPendingEnqueues);
+  }
+  
+  
+  private BarrierClose(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BarrierIncompleteSize.java java-ops/org/tensorflow/op/core/BarrierIncompleteSize.java
--- java/org/tensorflow/op/core/BarrierIncompleteSize.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BarrierIncompleteSize.java	2018-10-16 20:18:38.178432418 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the number of incomplete elements in the given barrier.
+ */
+@Operator
+public final class BarrierIncompleteSize extends PrimitiveOp implements Operand<Integer> {
+  
+  /**
+   * Factory method to create a class to wrap a new BarrierIncompleteSize operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param handle The handle to a barrier.
+   * @return a new instance of BarrierIncompleteSize
+   */
+  public static BarrierIncompleteSize create(Scope scope, Operand<String> handle) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BarrierIncompleteSize", scope.makeOpName("BarrierIncompleteSize"));
+    opBuilder.addInput(handle.asOutput());
+    return new BarrierIncompleteSize(opBuilder.build());
+  }
+  
+  /**
+   * The number of incomplete elements (i.e. those with some of their value
+   * components not set) in the barrier.
+   */
+  public Output<Integer> size() {
+    return size;
+  }
+  
+  @Override
+  public Output<Integer> asOutput() {
+    return size;
+  }
+  
+  private Output<Integer> size;
+  
+  private BarrierIncompleteSize(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    size = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BarrierInsertMany.java java-ops/org/tensorflow/op/core/BarrierInsertMany.java
--- java/org/tensorflow/op/core/BarrierInsertMany.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BarrierInsertMany.java	2018-10-16 20:18:38.178432418 +0900
@@ -0,0 +1,62 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * For each key, assigns the respective value to the specified component.
+ * <p>
+ * If a key is not found in the barrier, this operation will create a new
+ * incomplete element. If a key is found in the barrier, and the element
+ * already has a value at component_index, this operation will fail with
+ * INVALID_ARGUMENT, and leave the barrier in an undefined state.
+ */
+@Operator
+public final class BarrierInsertMany extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new BarrierInsertMany operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param handle The handle to a barrier.
+   * @param keys A one-dimensional tensor of keys, with length n.
+   * @param values An any-dimensional tensor of values, which are associated with the
+   * respective keys. The 0th dimension must have length n.
+   * @param componentIndex The component of the barrier elements that is being assigned.
+   * @return a new instance of BarrierInsertMany
+   */
+  public static <T> BarrierInsertMany create(Scope scope, Operand<String> handle, Operand<String> keys, Operand<T> values, Long componentIndex) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BarrierInsertMany", scope.makeOpName("BarrierInsertMany"));
+    opBuilder.addInput(handle.asOutput());
+    opBuilder.addInput(keys.asOutput());
+    opBuilder.addInput(values.asOutput());
+    opBuilder.setAttr("component_index", componentIndex);
+    return new BarrierInsertMany(opBuilder.build());
+  }
+  
+  
+  private BarrierInsertMany(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Barrier.java java-ops/org/tensorflow/op/core/Barrier.java
--- java/org/tensorflow/op/core/Barrier.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Barrier.java	2018-10-16 20:18:38.177432419 +0900
@@ -0,0 +1,187 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Defines a barrier that persists across different graph executions.
+ * <p>
+ * A barrier represents a key-value map, where each key is a string, and
+ * each value is a tuple of tensors.
+ * <p>
+ * At runtime, the barrier contains 'complete' and 'incomplete'
+ * elements. A complete element has defined tensors for all components of
+ * its value tuple, and may be accessed using BarrierTakeMany. An
+ * incomplete element has some undefined components in its value tuple,
+ * and may be updated using BarrierInsertMany.
+ */
+@Operator
+public final class Barrier extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Barrier}
+   */
+  public static class Options {
+    
+    /**
+     * @param shapes The shape of each component in a value. Each shape must be 1 in the
+     * first dimension. The length of this attr must be the same as the length of
+     * component_types.
+     */
+    public Options shapes(List<Shape> shapes) {
+      this.shapes = shapes;
+      return this;
+    }
+    
+    /**
+     * @param capacity The capacity of the barrier.  The default capacity is MAX_INT32,
+     * which is the largest capacity of the underlying queue.
+     */
+    public Options capacity(Long capacity) {
+      this.capacity = capacity;
+      return this;
+    }
+    
+    /**
+     * @param container If non-empty, this barrier is placed in the given container.
+     * Otherwise, a default container is used.
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName If non-empty, this barrier will be shared under the given name
+     * across multiple sessions.
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private List<Shape> shapes;
+    private Long capacity;
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Barrier operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param componentTypes The type of each component in a value.
+   * @param options carries optional attributes values
+   * @return a new instance of Barrier
+   */
+  public static Barrier create(Scope scope, List<Class<?>> componentTypes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Barrier", scope.makeOpName("Barrier"));
+    DataType[] componentTypesArray = new DataType[componentTypes.size()];
+    for (int i = 0; i < componentTypesArray.length; ++i) {
+      componentTypesArray[i] = DataType.fromClass(componentTypes.get(i));
+    }
+    opBuilder.setAttr("component_types", componentTypesArray);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.shapes != null) {
+          Shape[] shapesArray = new Shape[opts.shapes.size()];
+          for (int i = 0; i < shapesArray.length; ++i) {
+            shapesArray[i] = opts.shapes.get(i);
+          }
+          opBuilder.setAttr("shapes", shapesArray);
+        }
+        if (opts.capacity != null) {
+          opBuilder.setAttr("capacity", opts.capacity);
+        }
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new Barrier(opBuilder.build());
+  }
+  
+  /**
+   * @param shapes The shape of each component in a value. Each shape must be 1 in the
+   * first dimension. The length of this attr must be the same as the length of
+   * component_types.
+   */
+  public static Options shapes(List<Shape> shapes) {
+    return new Options().shapes(shapes);
+  }
+  
+  /**
+   * @param capacity The capacity of the barrier.  The default capacity is MAX_INT32,
+   * which is the largest capacity of the underlying queue.
+   */
+  public static Options capacity(Long capacity) {
+    return new Options().capacity(capacity);
+  }
+  
+  /**
+   * @param container If non-empty, this barrier is placed in the given container.
+   * Otherwise, a default container is used.
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName If non-empty, this barrier will be shared under the given name
+   * across multiple sessions.
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   * The handle to the barrier.
+   */
+  public Output<String> handle() {
+    return handle;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return handle;
+  }
+  
+  private Output<String> handle;
+  
+  private Barrier(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BarrierReadySize.java java-ops/org/tensorflow/op/core/BarrierReadySize.java
--- java/org/tensorflow/op/core/BarrierReadySize.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BarrierReadySize.java	2018-10-16 20:18:38.178432418 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the number of complete elements in the given barrier.
+ */
+@Operator
+public final class BarrierReadySize extends PrimitiveOp implements Operand<Integer> {
+  
+  /**
+   * Factory method to create a class to wrap a new BarrierReadySize operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param handle The handle to a barrier.
+   * @return a new instance of BarrierReadySize
+   */
+  public static BarrierReadySize create(Scope scope, Operand<String> handle) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BarrierReadySize", scope.makeOpName("BarrierReadySize"));
+    opBuilder.addInput(handle.asOutput());
+    return new BarrierReadySize(opBuilder.build());
+  }
+  
+  /**
+   * The number of complete elements (i.e. those with all of their value
+   * components set) in the barrier.
+   */
+  public Output<Integer> size() {
+    return size;
+  }
+  
+  @Override
+  public Output<Integer> asOutput() {
+    return size;
+  }
+  
+  private Output<Integer> size;
+  
+  private BarrierReadySize(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    size = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BarrierTakeMany.java java-ops/org/tensorflow/op/core/BarrierTakeMany.java
--- java/org/tensorflow/op/core/BarrierTakeMany.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BarrierTakeMany.java	2018-10-16 20:18:38.179432418 +0900
@@ -0,0 +1,182 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Takes the given number of completed elements from a barrier.
+ * <p>
+ * This operation concatenates completed-element component tensors along
+ * the 0th dimension to make a single component tensor.
+ * <p>
+ * Elements come out of the barrier when they are complete, and in the order
+ * in which they were placed into the barrier.  The indices output provides
+ * information about the batch in which each element was originally inserted
+ * into the barrier.
+ */
+@Operator
+public final class BarrierTakeMany extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.BarrierTakeMany}
+   */
+  public static class Options {
+    
+    /**
+     * @param allowSmallBatch Allow to return less than num_elements items if barrier is
+     * already closed.
+     */
+    public Options allowSmallBatch(Boolean allowSmallBatch) {
+      this.allowSmallBatch = allowSmallBatch;
+      return this;
+    }
+    
+    /**
+     * @param waitForIncomplete 
+     */
+    public Options waitForIncomplete(Boolean waitForIncomplete) {
+      this.waitForIncomplete = waitForIncomplete;
+      return this;
+    }
+    
+    /**
+     * @param timeoutMs If the queue is empty, this operation will block for up to
+     * timeout_ms milliseconds.
+     * Note: This option is not supported yet.
+     */
+    public Options timeoutMs(Long timeoutMs) {
+      this.timeoutMs = timeoutMs;
+      return this;
+    }
+    
+    private Boolean allowSmallBatch;
+    private Boolean waitForIncomplete;
+    private Long timeoutMs;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new BarrierTakeMany operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param handle The handle to a barrier.
+   * @param numElements A single-element tensor containing the number of elements to
+   * take.
+   * @param componentTypes The type of each component in a value.
+   * @param options carries optional attributes values
+   * @return a new instance of BarrierTakeMany
+   */
+  public static BarrierTakeMany create(Scope scope, Operand<String> handle, Operand<Integer> numElements, List<Class<?>> componentTypes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BarrierTakeMany", scope.makeOpName("BarrierTakeMany"));
+    opBuilder.addInput(handle.asOutput());
+    opBuilder.addInput(numElements.asOutput());
+    DataType[] componentTypesArray = new DataType[componentTypes.size()];
+    for (int i = 0; i < componentTypesArray.length; ++i) {
+      componentTypesArray[i] = DataType.fromClass(componentTypes.get(i));
+    }
+    opBuilder.setAttr("component_types", componentTypesArray);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.allowSmallBatch != null) {
+          opBuilder.setAttr("allow_small_batch", opts.allowSmallBatch);
+        }
+        if (opts.waitForIncomplete != null) {
+          opBuilder.setAttr("wait_for_incomplete", opts.waitForIncomplete);
+        }
+        if (opts.timeoutMs != null) {
+          opBuilder.setAttr("timeout_ms", opts.timeoutMs);
+        }
+      }
+    }
+    return new BarrierTakeMany(opBuilder.build());
+  }
+  
+  /**
+   * @param allowSmallBatch Allow to return less than num_elements items if barrier is
+   * already closed.
+   */
+  public static Options allowSmallBatch(Boolean allowSmallBatch) {
+    return new Options().allowSmallBatch(allowSmallBatch);
+  }
+  
+  /**
+   * @param waitForIncomplete 
+   */
+  public static Options waitForIncomplete(Boolean waitForIncomplete) {
+    return new Options().waitForIncomplete(waitForIncomplete);
+  }
+  
+  /**
+   * @param timeoutMs If the queue is empty, this operation will block for up to
+   * timeout_ms milliseconds.
+   * Note: This option is not supported yet.
+   */
+  public static Options timeoutMs(Long timeoutMs) {
+    return new Options().timeoutMs(timeoutMs);
+  }
+  
+  /**
+   * A one-dimensional tensor of indices, with length num_elems.
+   * These indices refer to the batch in which the values were placed into the
+   * barrier (starting with MIN_LONG and increasing with each BarrierInsertMany).
+   */
+  public Output<Long> indices() {
+    return indices;
+  }
+  
+  /**
+   * A one-dimensional tensor of keys, with length num_elements.
+   */
+  public Output<String> keys() {
+    return keys;
+  }
+  
+  /**
+   * One any-dimensional tensor per component in a barrier element. All
+   * values have length num_elements in the 0th dimension.
+   */
+  public List<Output<?>> values() {
+    return values;
+  }
+  
+  private Output<Long> indices;
+  private Output<String> keys;
+  private List<Output<?>> values;
+  
+  private BarrierTakeMany(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    indices = operation.output(outputIdx++);
+    keys = operation.output(outputIdx++);
+    int valuesLength = operation.outputListLength("values");
+    values = Arrays.asList(operation.outputList(outputIdx, valuesLength));
+    outputIdx += valuesLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/BatchCholeskyGrad.java java-ops/org/tensorflow/op/core/BatchCholeskyGrad.java
--- java/org/tensorflow/op/core/BatchCholeskyGrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BatchCholeskyGrad.java	2018-10-16 20:18:38.180432417 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class BatchCholeskyGrad<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new BatchCholeskyGrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param l 
+   * @param grad 
+   * @return a new instance of BatchCholeskyGrad
+   */
+  public static <T extends Number> BatchCholeskyGrad<T> create(Scope scope, Operand<T> l, Operand<T> grad) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BatchCholeskyGrad", scope.makeOpName("BatchCholeskyGrad"));
+    opBuilder.addInput(l.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    return new BatchCholeskyGrad<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private BatchCholeskyGrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BatchCholesky.java java-ops/org/tensorflow/op/core/BatchCholesky.java
--- java/org/tensorflow/op/core/BatchCholesky.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BatchCholesky.java	2018-10-16 20:18:38.180432417 +0900
@@ -0,0 +1,65 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class BatchCholesky<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new BatchCholesky operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @return a new instance of BatchCholesky
+   */
+  public static <T extends Number> BatchCholesky<T> create(Scope scope, Operand<T> input) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BatchCholesky", scope.makeOpName("BatchCholesky"));
+    opBuilder.addInput(input.asOutput());
+    return new BatchCholesky<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private BatchCholesky(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BatchDataset.java java-ops/org/tensorflow/op/core/BatchDataset.java
--- java/org/tensorflow/op/core/BatchDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BatchDataset.java	2018-10-16 20:18:38.180432417 +0900
@@ -0,0 +1,84 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Creates a dataset that batches `batch_size` elements from `input_dataset`.
+ */
+@Operator
+public final class BatchDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new BatchDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputDataset 
+   * @param batchSize A scalar representing the number of elements to accumulate in a
+   * batch.
+   * @param outputTypes 
+   * @param outputShapes 
+   * @return a new instance of BatchDataset
+   */
+  public static BatchDataset create(Scope scope, Operand<?> inputDataset, Operand<Long> batchSize, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BatchDataset", scope.makeOpName("BatchDataset"));
+    opBuilder.addInput(inputDataset.asOutput());
+    opBuilder.addInput(batchSize.asOutput());
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new BatchDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private BatchDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BatchDatasetV2.java java-ops/org/tensorflow/op/core/BatchDatasetV2.java
--- java/org/tensorflow/op/core/BatchDatasetV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BatchDatasetV2.java	2018-10-16 20:18:38.181432416 +0900
@@ -0,0 +1,84 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Creates a dataset that batches `batch_size` elements from `input_dataset`.
+ */
+public final class BatchDatasetV2 extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new BatchDatasetV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputDataset 
+   * @param batchSize A scalar representing the number of elements to accumulate in a batch.
+   * @param dropRemainder A scalar representing whether the last batch should be dropped in case its size
+   * is smaller than desired.
+   * @param outputTypes 
+   * @param outputShapes 
+   * @return a new instance of BatchDatasetV2
+   */
+  public static BatchDatasetV2 create(Scope scope, Operand<?> inputDataset, Operand<Long> batchSize, Operand<Boolean> dropRemainder, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BatchDatasetV2", scope.makeOpName("BatchDatasetV2"));
+    opBuilder.addInput(inputDataset.asOutput());
+    opBuilder.addInput(batchSize.asOutput());
+    opBuilder.addInput(dropRemainder.asOutput());
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new BatchDatasetV2(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private BatchDatasetV2(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BatchFFT2D.java java-ops/org/tensorflow/op/core/BatchFFT2D.java
--- java/org/tensorflow/op/core/BatchFFT2D.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BatchFFT2D.java	2018-10-16 20:18:38.181432416 +0900
@@ -0,0 +1,65 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ */
+@Operator
+public final class BatchFFT2D extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new BatchFFT2D operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @return a new instance of BatchFFT2D
+   */
+  public static BatchFFT2D create(Scope scope, Operand<?> input) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BatchFFT2D", scope.makeOpName("BatchFFT2D"));
+    opBuilder.addInput(input.asOutput());
+    return new BatchFFT2D(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> output() {
+    return output;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) output;
+  }
+  
+  private Output<?> output;
+  
+  private BatchFFT2D(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BatchFFT3D.java java-ops/org/tensorflow/op/core/BatchFFT3D.java
--- java/org/tensorflow/op/core/BatchFFT3D.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BatchFFT3D.java	2018-10-16 20:18:38.181432416 +0900
@@ -0,0 +1,65 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ */
+@Operator
+public final class BatchFFT3D extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new BatchFFT3D operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @return a new instance of BatchFFT3D
+   */
+  public static BatchFFT3D create(Scope scope, Operand<?> input) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BatchFFT3D", scope.makeOpName("BatchFFT3D"));
+    opBuilder.addInput(input.asOutput());
+    return new BatchFFT3D(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> output() {
+    return output;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) output;
+  }
+  
+  private Output<?> output;
+  
+  private BatchFFT3D(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BatchFFT.java java-ops/org/tensorflow/op/core/BatchFFT.java
--- java/org/tensorflow/op/core/BatchFFT.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BatchFFT.java	2018-10-16 20:18:38.181432416 +0900
@@ -0,0 +1,65 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ */
+@Operator
+public final class BatchFFT extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new BatchFFT operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @return a new instance of BatchFFT
+   */
+  public static BatchFFT create(Scope scope, Operand<?> input) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BatchFFT", scope.makeOpName("BatchFFT"));
+    opBuilder.addInput(input.asOutput());
+    return new BatchFFT(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> output() {
+    return output;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) output;
+  }
+  
+  private Output<?> output;
+  
+  private BatchFFT(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BatchIFFT2D.java java-ops/org/tensorflow/op/core/BatchIFFT2D.java
--- java/org/tensorflow/op/core/BatchIFFT2D.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BatchIFFT2D.java	2018-10-16 20:18:38.182432416 +0900
@@ -0,0 +1,65 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ */
+@Operator
+public final class BatchIFFT2D extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new BatchIFFT2D operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @return a new instance of BatchIFFT2D
+   */
+  public static BatchIFFT2D create(Scope scope, Operand<?> input) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BatchIFFT2D", scope.makeOpName("BatchIFFT2D"));
+    opBuilder.addInput(input.asOutput());
+    return new BatchIFFT2D(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> output() {
+    return output;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) output;
+  }
+  
+  private Output<?> output;
+  
+  private BatchIFFT2D(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BatchIFFT3D.java java-ops/org/tensorflow/op/core/BatchIFFT3D.java
--- java/org/tensorflow/op/core/BatchIFFT3D.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BatchIFFT3D.java	2018-10-16 20:18:38.182432416 +0900
@@ -0,0 +1,65 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ */
+@Operator
+public final class BatchIFFT3D extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new BatchIFFT3D operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @return a new instance of BatchIFFT3D
+   */
+  public static BatchIFFT3D create(Scope scope, Operand<?> input) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BatchIFFT3D", scope.makeOpName("BatchIFFT3D"));
+    opBuilder.addInput(input.asOutput());
+    return new BatchIFFT3D(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> output() {
+    return output;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) output;
+  }
+  
+  private Output<?> output;
+  
+  private BatchIFFT3D(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BatchIFFT.java java-ops/org/tensorflow/op/core/BatchIFFT.java
--- java/org/tensorflow/op/core/BatchIFFT.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BatchIFFT.java	2018-10-16 20:18:38.181432416 +0900
@@ -0,0 +1,65 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ */
+@Operator
+public final class BatchIFFT extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new BatchIFFT operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @return a new instance of BatchIFFT
+   */
+  public static BatchIFFT create(Scope scope, Operand<?> input) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BatchIFFT", scope.makeOpName("BatchIFFT"));
+    opBuilder.addInput(input.asOutput());
+    return new BatchIFFT(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> output() {
+    return output;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) output;
+  }
+  
+  private Output<?> output;
+  
+  private BatchIFFT(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Batch.java java-ops/org/tensorflow/op/core/Batch.java
--- java/org/tensorflow/op/core/Batch.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Batch.java	2018-10-16 20:18:38.179432418 +0900
@@ -0,0 +1,240 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Batches all input tensors nondeterministically.
+ * <p>
+ * When many instances of this Op are being run concurrently with the same
+ * container/shared_name in the same device, some will output zero-shaped Tensors
+ * and others will output Tensors of size up to max_batch_size.
+ * <p>
+ * All Tensors in in_tensors are batched together (so, for example, labels and
+ * features should be batched with a single instance of this operation.
+ * <p>
+ * Each invocation of batch emits an `id` scalar which will be used to identify
+ * this particular invocation when doing unbatch or its gradient.
+ * <p>
+ * Each op which emits a non-empty batch will also emit a non-empty batch_index
+ * Tensor, which, is a [K, 3] matrix where each row contains the invocation's id,
+ * start, and length of elements of each set of Tensors present in batched_tensors.
+ * <p>
+ * Batched tensors are concatenated along the first dimension, and all tensors in
+ * in_tensors must have the first dimension of the same size.
+ * <p>
+ * in_tensors: The tensors to be batched.
+ * num_batch_threads: Number of scheduling threads for processing batches of work.
+ *  Determines the number of batches processed in parallel.
+ * max_batch_size: Batch sizes will never be bigger than this.
+ * batch_timeout_micros: Maximum number of microseconds to wait before outputting
+ *  an incomplete batch.
+ * allowed_batch_sizes: Optional list of allowed batch sizes. If left empty, does
+ *  nothing. Otherwise, supplies a list of batch sizes, causing the op to pad
+ *  batches up to one of those sizes. The entries must increase monotonically, and
+ *  the final entry must equal max_batch_size.
+ * grad_timeout_micros: The timeout to use for the gradient. See Unbatch.
+ * batched_tensors: Either empty tensors or a batch of concatenated Tensors.
+ * batch_index: If out_tensors is non-empty, has information to invert it.
+ * container: Controls the scope of sharing of this batch.
+ * id: always contains a scalar with a unique ID for this invocation of Batch.
+ * shared_name: Concurrently running instances of batch in the same device with the
+ *  same container and shared_name will batch their elements together. If left
+ *  empty, the op name will be used as the shared name.
+ * T: the types of tensors to be batched.
+ */
+@Operator
+public final class Batch extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Batch}
+   */
+  public static class Options {
+    
+    /**
+     * @param maxEnqueuedBatches 
+     */
+    public Options maxEnqueuedBatches(Long maxEnqueuedBatches) {
+      this.maxEnqueuedBatches = maxEnqueuedBatches;
+      return this;
+    }
+    
+    /**
+     * @param allowedBatchSizes 
+     */
+    public Options allowedBatchSizes(List<Long> allowedBatchSizes) {
+      this.allowedBatchSizes = allowedBatchSizes;
+      return this;
+    }
+    
+    /**
+     * @param container 
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName 
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    /**
+     * @param batchingQueue 
+     */
+    public Options batchingQueue(String batchingQueue) {
+      this.batchingQueue = batchingQueue;
+      return this;
+    }
+    
+    private Long maxEnqueuedBatches;
+    private List<Long> allowedBatchSizes;
+    private String container;
+    private String sharedName;
+    private String batchingQueue;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Batch operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inTensors 
+   * @param numBatchThreads 
+   * @param maxBatchSize 
+   * @param batchTimeoutMicros 
+   * @param gradTimeoutMicros 
+   * @param options carries optional attributes values
+   * @return a new instance of Batch
+   */
+  public static Batch create(Scope scope, Iterable<Operand<?>> inTensors, Long numBatchThreads, Long maxBatchSize, Long batchTimeoutMicros, Long gradTimeoutMicros, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Batch", scope.makeOpName("Batch"));
+    opBuilder.addInputList(Operands.asOutputs(inTensors));
+    opBuilder.setAttr("num_batch_threads", numBatchThreads);
+    opBuilder.setAttr("max_batch_size", maxBatchSize);
+    opBuilder.setAttr("batch_timeout_micros", batchTimeoutMicros);
+    opBuilder.setAttr("grad_timeout_micros", gradTimeoutMicros);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.maxEnqueuedBatches != null) {
+          opBuilder.setAttr("max_enqueued_batches", opts.maxEnqueuedBatches);
+        }
+        if (opts.allowedBatchSizes != null) {
+          long[] allowedBatchSizesArray = new long[opts.allowedBatchSizes.size()];
+          for (int i = 0; i < allowedBatchSizesArray.length; ++i) {
+            allowedBatchSizesArray[i] = opts.allowedBatchSizes.get(i);
+          }
+          opBuilder.setAttr("allowed_batch_sizes", allowedBatchSizesArray);
+        }
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+        if (opts.batchingQueue != null) {
+          opBuilder.setAttr("batching_queue", opts.batchingQueue);
+        }
+      }
+    }
+    return new Batch(opBuilder.build());
+  }
+  
+  /**
+   * @param maxEnqueuedBatches 
+   */
+  public static Options maxEnqueuedBatches(Long maxEnqueuedBatches) {
+    return new Options().maxEnqueuedBatches(maxEnqueuedBatches);
+  }
+  
+  /**
+   * @param allowedBatchSizes 
+   */
+  public static Options allowedBatchSizes(List<Long> allowedBatchSizes) {
+    return new Options().allowedBatchSizes(allowedBatchSizes);
+  }
+  
+  /**
+   * @param container 
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName 
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   * @param batchingQueue 
+   */
+  public static Options batchingQueue(String batchingQueue) {
+    return new Options().batchingQueue(batchingQueue);
+  }
+  
+  /**
+   */
+  public List<Output<?>> batchedTensors() {
+    return batchedTensors;
+  }
+  
+  /**
+   */
+  public Output<Long> batchIndex() {
+    return batchIndex;
+  }
+  
+  /**
+   */
+  public Output<Long> id() {
+    return id;
+  }
+  
+  private List<Output<?>> batchedTensors;
+  private Output<Long> batchIndex;
+  private Output<Long> id;
+  
+  private Batch(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    int batchedTensorsLength = operation.outputListLength("batched_tensors");
+    batchedTensors = Arrays.asList(operation.outputList(outputIdx, batchedTensorsLength));
+    outputIdx += batchedTensorsLength;
+    batchIndex = operation.output(outputIdx++);
+    id = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BatchMatMul.java java-ops/org/tensorflow/op/core/BatchMatMul.java
--- java/org/tensorflow/op/core/BatchMatMul.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BatchMatMul.java	2018-10-16 20:18:38.183432415 +0900
@@ -0,0 +1,142 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Multiplies slices of two tensors in batches.
+ * <p>
+ * Multiplies all slices of `Tensor` `x` and `y` (each slice can be
+ * viewed as an element of a batch), and arranges the individual results
+ * in a single output tensor of the same batch size. Each of the
+ * individual slices can optionally be adjointed (to adjoint a matrix
+ * means to transpose and conjugate it) before multiplication by setting
+ * the `adj_x` or `adj_y` flag to `True`, which are by default `False`.
+ * <p>
+ * The input tensors `x` and `y` are 2-D or higher with shape `[..., r_x, c_x]`
+ * and `[..., r_y, c_y]`.
+ * <p>
+ * The output tensor is 2-D or higher with shape `[..., r_o, c_o]`, where:
+ * <p>
+ *     r_o = c_x if adj_x else r_x
+ *     c_o = r_y if adj_y else c_y
+ * <p>
+ * It is computed as:
+ * <p>
+ *     output[..., :, :] = matrix(x[..., :, :]) * matrix(y[..., :, :])
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class BatchMatMul<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.BatchMatMul}
+   */
+  public static class Options {
+    
+    /**
+     * @param adjX If `True`, adjoint the slices of `x`. Defaults to `False`.
+     */
+    public Options adjX(Boolean adjX) {
+      this.adjX = adjX;
+      return this;
+    }
+    
+    /**
+     * @param adjY If `True`, adjoint the slices of `y`. Defaults to `False`.
+     */
+    public Options adjY(Boolean adjY) {
+      this.adjY = adjY;
+      return this;
+    }
+    
+    private Boolean adjX;
+    private Boolean adjY;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new BatchMatMul operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 2-D or higher with shape `[..., r_x, c_x]`.
+   * @param y 2-D or higher with shape `[..., r_y, c_y]`.
+   * @param options carries optional attributes values
+   * @return a new instance of BatchMatMul
+   */
+  public static <T> BatchMatMul<T> create(Scope scope, Operand<T> x, Operand<T> y, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BatchMatMul", scope.makeOpName("BatchMatMul"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(y.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.adjX != null) {
+          opBuilder.setAttr("adj_x", opts.adjX);
+        }
+        if (opts.adjY != null) {
+          opBuilder.setAttr("adj_y", opts.adjY);
+        }
+      }
+    }
+    return new BatchMatMul<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param adjX If `True`, adjoint the slices of `x`. Defaults to `False`.
+   */
+  public static Options adjX(Boolean adjX) {
+    return new Options().adjX(adjX);
+  }
+  
+  /**
+   * @param adjY If `True`, adjoint the slices of `y`. Defaults to `False`.
+   */
+  public static Options adjY(Boolean adjY) {
+    return new Options().adjY(adjY);
+  }
+  
+  /**
+   * 3-D or higher with shape `[..., r_o, c_o]`
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private BatchMatMul(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BatchMatrixBandPart.java java-ops/org/tensorflow/op/core/BatchMatrixBandPart.java
--- java/org/tensorflow/op/core/BatchMatrixBandPart.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BatchMatrixBandPart.java	2018-10-16 20:18:38.183432415 +0900
@@ -0,0 +1,69 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * @param <T> data type for {@code band()} output
+ */
+@Operator
+public final class BatchMatrixBandPart<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new BatchMatrixBandPart operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param numLower 
+   * @param numUpper 
+   * @return a new instance of BatchMatrixBandPart
+   */
+  public static <T> BatchMatrixBandPart<T> create(Scope scope, Operand<T> input, Operand<Long> numLower, Operand<Long> numUpper) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BatchMatrixBandPart", scope.makeOpName("BatchMatrixBandPart"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(numLower.asOutput());
+    opBuilder.addInput(numUpper.asOutput());
+    return new BatchMatrixBandPart<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> band() {
+    return band;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return band;
+  }
+  
+  private Output<T> band;
+  
+  private BatchMatrixBandPart(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    band = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BatchMatrixDeterminant.java java-ops/org/tensorflow/op/core/BatchMatrixDeterminant.java
--- java/org/tensorflow/op/core/BatchMatrixDeterminant.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BatchMatrixDeterminant.java	2018-10-16 20:18:38.183432415 +0900
@@ -0,0 +1,65 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class BatchMatrixDeterminant<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new BatchMatrixDeterminant operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @return a new instance of BatchMatrixDeterminant
+   */
+  public static <T> BatchMatrixDeterminant<T> create(Scope scope, Operand<T> input) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BatchMatrixDeterminant", scope.makeOpName("BatchMatrixDeterminant"));
+    opBuilder.addInput(input.asOutput());
+    return new BatchMatrixDeterminant<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private BatchMatrixDeterminant(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BatchMatrixDiag.java java-ops/org/tensorflow/op/core/BatchMatrixDiag.java
--- java/org/tensorflow/op/core/BatchMatrixDiag.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BatchMatrixDiag.java	2018-10-16 20:18:38.184432414 +0900
@@ -0,0 +1,65 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class BatchMatrixDiag<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new BatchMatrixDiag operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param diagonal 
+   * @return a new instance of BatchMatrixDiag
+   */
+  public static <T> BatchMatrixDiag<T> create(Scope scope, Operand<T> diagonal) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BatchMatrixDiag", scope.makeOpName("BatchMatrixDiag"));
+    opBuilder.addInput(diagonal.asOutput());
+    return new BatchMatrixDiag<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private BatchMatrixDiag(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BatchMatrixDiagPart.java java-ops/org/tensorflow/op/core/BatchMatrixDiagPart.java
--- java/org/tensorflow/op/core/BatchMatrixDiagPart.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BatchMatrixDiagPart.java	2018-10-16 20:18:38.184432414 +0900
@@ -0,0 +1,65 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * @param <T> data type for {@code diagonal()} output
+ */
+@Operator
+public final class BatchMatrixDiagPart<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new BatchMatrixDiagPart operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @return a new instance of BatchMatrixDiagPart
+   */
+  public static <T> BatchMatrixDiagPart<T> create(Scope scope, Operand<T> input) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BatchMatrixDiagPart", scope.makeOpName("BatchMatrixDiagPart"));
+    opBuilder.addInput(input.asOutput());
+    return new BatchMatrixDiagPart<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> diagonal() {
+    return diagonal;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return diagonal;
+  }
+  
+  private Output<T> diagonal;
+  
+  private BatchMatrixDiagPart(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    diagonal = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BatchMatrixInverse.java java-ops/org/tensorflow/op/core/BatchMatrixInverse.java
--- java/org/tensorflow/op/core/BatchMatrixInverse.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BatchMatrixInverse.java	2018-10-16 20:18:38.184432414 +0900
@@ -0,0 +1,99 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class BatchMatrixInverse<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.BatchMatrixInverse}
+   */
+  public static class Options {
+    
+    /**
+     * @param adjoint 
+     */
+    public Options adjoint(Boolean adjoint) {
+      this.adjoint = adjoint;
+      return this;
+    }
+    
+    private Boolean adjoint;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new BatchMatrixInverse operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param options carries optional attributes values
+   * @return a new instance of BatchMatrixInverse
+   */
+  public static <T extends Number> BatchMatrixInverse<T> create(Scope scope, Operand<T> input, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BatchMatrixInverse", scope.makeOpName("BatchMatrixInverse"));
+    opBuilder.addInput(input.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.adjoint != null) {
+          opBuilder.setAttr("adjoint", opts.adjoint);
+        }
+      }
+    }
+    return new BatchMatrixInverse<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param adjoint 
+   */
+  public static Options adjoint(Boolean adjoint) {
+    return new Options().adjoint(adjoint);
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private BatchMatrixInverse(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BatchMatrixSetDiag.java java-ops/org/tensorflow/op/core/BatchMatrixSetDiag.java
--- java/org/tensorflow/op/core/BatchMatrixSetDiag.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BatchMatrixSetDiag.java	2018-10-16 20:18:38.184432414 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class BatchMatrixSetDiag<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new BatchMatrixSetDiag operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param diagonal 
+   * @return a new instance of BatchMatrixSetDiag
+   */
+  public static <T> BatchMatrixSetDiag<T> create(Scope scope, Operand<T> input, Operand<T> diagonal) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BatchMatrixSetDiag", scope.makeOpName("BatchMatrixSetDiag"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(diagonal.asOutput());
+    return new BatchMatrixSetDiag<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private BatchMatrixSetDiag(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BatchMatrixSolve.java java-ops/org/tensorflow/op/core/BatchMatrixSolve.java
--- java/org/tensorflow/op/core/BatchMatrixSolve.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BatchMatrixSolve.java	2018-10-16 20:18:38.184432414 +0900
@@ -0,0 +1,101 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class BatchMatrixSolve<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.BatchMatrixSolve}
+   */
+  public static class Options {
+    
+    /**
+     * @param adjoint 
+     */
+    public Options adjoint(Boolean adjoint) {
+      this.adjoint = adjoint;
+      return this;
+    }
+    
+    private Boolean adjoint;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new BatchMatrixSolve operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param matrix 
+   * @param rhs 
+   * @param options carries optional attributes values
+   * @return a new instance of BatchMatrixSolve
+   */
+  public static <T extends Number> BatchMatrixSolve<T> create(Scope scope, Operand<T> matrix, Operand<T> rhs, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BatchMatrixSolve", scope.makeOpName("BatchMatrixSolve"));
+    opBuilder.addInput(matrix.asOutput());
+    opBuilder.addInput(rhs.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.adjoint != null) {
+          opBuilder.setAttr("adjoint", opts.adjoint);
+        }
+      }
+    }
+    return new BatchMatrixSolve<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param adjoint 
+   */
+  public static Options adjoint(Boolean adjoint) {
+    return new Options().adjoint(adjoint);
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private BatchMatrixSolve(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BatchMatrixSolveLs.java java-ops/org/tensorflow/op/core/BatchMatrixSolveLs.java
--- java/org/tensorflow/op/core/BatchMatrixSolveLs.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BatchMatrixSolveLs.java	2018-10-16 20:18:38.185432414 +0900
@@ -0,0 +1,103 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class BatchMatrixSolveLs<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.BatchMatrixSolveLs}
+   */
+  public static class Options {
+    
+    /**
+     * @param fast 
+     */
+    public Options fast(Boolean fast) {
+      this.fast = fast;
+      return this;
+    }
+    
+    private Boolean fast;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new BatchMatrixSolveLs operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param matrix 
+   * @param rhs 
+   * @param l2Regularizer 
+   * @param options carries optional attributes values
+   * @return a new instance of BatchMatrixSolveLs
+   */
+  public static <T extends Number> BatchMatrixSolveLs<T> create(Scope scope, Operand<T> matrix, Operand<T> rhs, Operand<Double> l2Regularizer, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BatchMatrixSolveLs", scope.makeOpName("BatchMatrixSolveLs"));
+    opBuilder.addInput(matrix.asOutput());
+    opBuilder.addInput(rhs.asOutput());
+    opBuilder.addInput(l2Regularizer.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.fast != null) {
+          opBuilder.setAttr("fast", opts.fast);
+        }
+      }
+    }
+    return new BatchMatrixSolveLs<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param fast 
+   */
+  public static Options fast(Boolean fast) {
+    return new Options().fast(fast);
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private BatchMatrixSolveLs(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BatchMatrixTriangularSolve.java java-ops/org/tensorflow/op/core/BatchMatrixTriangularSolve.java
--- java/org/tensorflow/op/core/BatchMatrixTriangularSolve.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BatchMatrixTriangularSolve.java	2018-10-16 20:18:38.185432414 +0900
@@ -0,0 +1,120 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class BatchMatrixTriangularSolve<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.BatchMatrixTriangularSolve}
+   */
+  public static class Options {
+    
+    /**
+     * @param lower 
+     */
+    public Options lower(Boolean lower) {
+      this.lower = lower;
+      return this;
+    }
+    
+    /**
+     * @param adjoint 
+     */
+    public Options adjoint(Boolean adjoint) {
+      this.adjoint = adjoint;
+      return this;
+    }
+    
+    private Boolean lower;
+    private Boolean adjoint;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new BatchMatrixTriangularSolve operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param matrix 
+   * @param rhs 
+   * @param options carries optional attributes values
+   * @return a new instance of BatchMatrixTriangularSolve
+   */
+  public static <T extends Number> BatchMatrixTriangularSolve<T> create(Scope scope, Operand<T> matrix, Operand<T> rhs, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BatchMatrixTriangularSolve", scope.makeOpName("BatchMatrixTriangularSolve"));
+    opBuilder.addInput(matrix.asOutput());
+    opBuilder.addInput(rhs.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.lower != null) {
+          opBuilder.setAttr("lower", opts.lower);
+        }
+        if (opts.adjoint != null) {
+          opBuilder.setAttr("adjoint", opts.adjoint);
+        }
+      }
+    }
+    return new BatchMatrixTriangularSolve<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param lower 
+   */
+  public static Options lower(Boolean lower) {
+    return new Options().lower(lower);
+  }
+  
+  /**
+   * @param adjoint 
+   */
+  public static Options adjoint(Boolean adjoint) {
+    return new Options().adjoint(adjoint);
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private BatchMatrixTriangularSolve(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BatchNormWithGlobalNormalizationGrad.java java-ops/org/tensorflow/op/core/BatchNormWithGlobalNormalizationGrad.java
--- java/org/tensorflow/op/core/BatchNormWithGlobalNormalizationGrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BatchNormWithGlobalNormalizationGrad.java	2018-10-16 20:18:38.186432413 +0900
@@ -0,0 +1,120 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Gradients for batch normalization.
+ * <p>
+ * This op is deprecated. See `tf.nn.batch_normalization`.
+ * 
+ * @param <T> data type for {@code dx()} output
+ */
+@Operator
+public final class BatchNormWithGlobalNormalizationGrad<T> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new BatchNormWithGlobalNormalizationGrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param t A 4D input Tensor.
+   * @param m A 1D mean Tensor with size matching the last dimension of t.
+   * This is the first output from tf.nn.moments,
+   * or a saved moving average thereof.
+   * @param v A 1D variance Tensor with size matching the last dimension of t.
+   * This is the second output from tf.nn.moments,
+   * or a saved moving average thereof.
+   * @param gamma A 1D gamma Tensor with size matching the last dimension of t.
+   * If "scale_after_normalization" is true, this Tensor will be multiplied
+   * with the normalized Tensor.
+   * @param backprop 4D backprop Tensor.
+   * @param varianceEpsilon A small float number to avoid dividing by 0.
+   * @param scaleAfterNormalization A bool indicating whether the resulted tensor
+   * needs to be multiplied with gamma.
+   * @return a new instance of BatchNormWithGlobalNormalizationGrad
+   */
+  public static <T> BatchNormWithGlobalNormalizationGrad<T> create(Scope scope, Operand<T> t, Operand<T> m, Operand<T> v, Operand<T> gamma, Operand<T> backprop, Float varianceEpsilon, Boolean scaleAfterNormalization) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BatchNormWithGlobalNormalizationGrad", scope.makeOpName("BatchNormWithGlobalNormalizationGrad"));
+    opBuilder.addInput(t.asOutput());
+    opBuilder.addInput(m.asOutput());
+    opBuilder.addInput(v.asOutput());
+    opBuilder.addInput(gamma.asOutput());
+    opBuilder.addInput(backprop.asOutput());
+    opBuilder.setAttr("variance_epsilon", varianceEpsilon);
+    opBuilder.setAttr("scale_after_normalization", scaleAfterNormalization);
+    return new BatchNormWithGlobalNormalizationGrad<T>(opBuilder.build());
+  }
+  
+  /**
+   * 4D backprop tensor for input.
+   */
+  public Output<T> dx() {
+    return dx;
+  }
+  
+  /**
+   * 1D backprop tensor for mean.
+   */
+  public Output<T> dm() {
+    return dm;
+  }
+  
+  /**
+   * 1D backprop tensor for variance.
+   */
+  public Output<T> dv() {
+    return dv;
+  }
+  
+  /**
+   * 1D backprop tensor for beta.
+   */
+  public Output<T> db() {
+    return db;
+  }
+  
+  /**
+   * 1D backprop tensor for gamma.
+   */
+  public Output<T> dg() {
+    return dg;
+  }
+  
+  private Output<T> dx;
+  private Output<T> dm;
+  private Output<T> dv;
+  private Output<T> db;
+  private Output<T> dg;
+  
+  private BatchNormWithGlobalNormalizationGrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    dx = operation.output(outputIdx++);
+    dm = operation.output(outputIdx++);
+    dv = operation.output(outputIdx++);
+    db = operation.output(outputIdx++);
+    dg = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BatchNormWithGlobalNormalization.java java-ops/org/tensorflow/op/core/BatchNormWithGlobalNormalization.java
--- java/org/tensorflow/op/core/BatchNormWithGlobalNormalization.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BatchNormWithGlobalNormalization.java	2018-10-16 20:18:38.186432413 +0900
@@ -0,0 +1,89 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Batch normalization.
+ * <p>
+ * This op is deprecated. Prefer `tf.nn.batch_normalization`.
+ * 
+ * @param <T> data type for {@code result()} output
+ */
+@Operator
+public final class BatchNormWithGlobalNormalization<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new BatchNormWithGlobalNormalization operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param t A 4D input Tensor.
+   * @param m A 1D mean Tensor with size matching the last dimension of t.
+   * This is the first output from tf.nn.moments,
+   * or a saved moving average thereof.
+   * @param v A 1D variance Tensor with size matching the last dimension of t.
+   * This is the second output from tf.nn.moments,
+   * or a saved moving average thereof.
+   * @param beta A 1D beta Tensor with size matching the last dimension of t.
+   * An offset to be added to the normalized tensor.
+   * @param gamma A 1D gamma Tensor with size matching the last dimension of t.
+   * If "scale_after_normalization" is true, this tensor will be multiplied
+   * with the normalized tensor.
+   * @param varianceEpsilon A small float number to avoid dividing by 0.
+   * @param scaleAfterNormalization A bool indicating whether the resulted tensor
+   * needs to be multiplied with gamma.
+   * @return a new instance of BatchNormWithGlobalNormalization
+   */
+  public static <T> BatchNormWithGlobalNormalization<T> create(Scope scope, Operand<T> t, Operand<T> m, Operand<T> v, Operand<T> beta, Operand<T> gamma, Float varianceEpsilon, Boolean scaleAfterNormalization) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BatchNormWithGlobalNormalization", scope.makeOpName("BatchNormWithGlobalNormalization"));
+    opBuilder.addInput(t.asOutput());
+    opBuilder.addInput(m.asOutput());
+    opBuilder.addInput(v.asOutput());
+    opBuilder.addInput(beta.asOutput());
+    opBuilder.addInput(gamma.asOutput());
+    opBuilder.setAttr("variance_epsilon", varianceEpsilon);
+    opBuilder.setAttr("scale_after_normalization", scaleAfterNormalization);
+    return new BatchNormWithGlobalNormalization<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> result() {
+    return result;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return result;
+  }
+  
+  private Output<T> result;
+  
+  private BatchNormWithGlobalNormalization(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    result = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BatchSelfAdjointEig.java java-ops/org/tensorflow/op/core/BatchSelfAdjointEig.java
--- java/org/tensorflow/op/core/BatchSelfAdjointEig.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BatchSelfAdjointEig.java	2018-10-16 20:18:38.186432413 +0900
@@ -0,0 +1,65 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class BatchSelfAdjointEig<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new BatchSelfAdjointEig operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @return a new instance of BatchSelfAdjointEig
+   */
+  public static <T extends Number> BatchSelfAdjointEig<T> create(Scope scope, Operand<T> input) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BatchSelfAdjointEig", scope.makeOpName("BatchSelfAdjointEig"));
+    opBuilder.addInput(input.asOutput());
+    return new BatchSelfAdjointEig<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private BatchSelfAdjointEig(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BatchSelfAdjointEigV2.java java-ops/org/tensorflow/op/core/BatchSelfAdjointEigV2.java
--- java/org/tensorflow/op/core/BatchSelfAdjointEigV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BatchSelfAdjointEigV2.java	2018-10-16 20:18:38.187432412 +0900
@@ -0,0 +1,102 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * @param <T> data type for {@code e()} output
+ */
+@Operator
+public final class BatchSelfAdjointEigV2<T extends Number> extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.BatchSelfAdjointEigV2}
+   */
+  public static class Options {
+    
+    /**
+     * @param computeV 
+     */
+    public Options computeV(Boolean computeV) {
+      this.computeV = computeV;
+      return this;
+    }
+    
+    private Boolean computeV;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new BatchSelfAdjointEigV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param options carries optional attributes values
+   * @return a new instance of BatchSelfAdjointEigV2
+   */
+  public static <T extends Number> BatchSelfAdjointEigV2<T> create(Scope scope, Operand<T> input, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BatchSelfAdjointEigV2", scope.makeOpName("BatchSelfAdjointEigV2"));
+    opBuilder.addInput(input.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.computeV != null) {
+          opBuilder.setAttr("compute_v", opts.computeV);
+        }
+      }
+    }
+    return new BatchSelfAdjointEigV2<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param computeV 
+   */
+  public static Options computeV(Boolean computeV) {
+    return new Options().computeV(computeV);
+  }
+  
+  /**
+   */
+  public Output<T> e() {
+    return e;
+  }
+  
+  /**
+   */
+  public Output<T> v() {
+    return v;
+  }
+  
+  private Output<T> e;
+  private Output<T> v;
+  
+  private BatchSelfAdjointEigV2(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    e = operation.output(outputIdx++);
+    v = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BatchSvd.java java-ops/org/tensorflow/op/core/BatchSvd.java
--- java/org/tensorflow/op/core/BatchSvd.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BatchSvd.java	2018-10-16 20:18:38.187432412 +0900
@@ -0,0 +1,129 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * @param <T> data type for {@code s()} output
+ */
+@Operator
+public final class BatchSvd<T> extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.BatchSvd}
+   */
+  public static class Options {
+    
+    /**
+     * @param computeUv 
+     */
+    public Options computeUv(Boolean computeUv) {
+      this.computeUv = computeUv;
+      return this;
+    }
+    
+    /**
+     * @param fullMatrices 
+     */
+    public Options fullMatrices(Boolean fullMatrices) {
+      this.fullMatrices = fullMatrices;
+      return this;
+    }
+    
+    private Boolean computeUv;
+    private Boolean fullMatrices;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new BatchSvd operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param options carries optional attributes values
+   * @return a new instance of BatchSvd
+   */
+  public static <T> BatchSvd<T> create(Scope scope, Operand<T> input, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BatchSvd", scope.makeOpName("BatchSvd"));
+    opBuilder.addInput(input.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.computeUv != null) {
+          opBuilder.setAttr("compute_uv", opts.computeUv);
+        }
+        if (opts.fullMatrices != null) {
+          opBuilder.setAttr("full_matrices", opts.fullMatrices);
+        }
+      }
+    }
+    return new BatchSvd<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param computeUv 
+   */
+  public static Options computeUv(Boolean computeUv) {
+    return new Options().computeUv(computeUv);
+  }
+  
+  /**
+   * @param fullMatrices 
+   */
+  public static Options fullMatrices(Boolean fullMatrices) {
+    return new Options().fullMatrices(fullMatrices);
+  }
+  
+  /**
+   */
+  public Output<T> s() {
+    return s;
+  }
+  
+  /**
+   */
+  public Output<T> u() {
+    return u;
+  }
+  
+  /**
+   */
+  public Output<T> v() {
+    return v;
+  }
+  
+  private Output<T> s;
+  private Output<T> u;
+  private Output<T> v;
+  
+  private BatchSvd(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    s = operation.output(outputIdx++);
+    u = operation.output(outputIdx++);
+    v = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BatchToSpace.java java-ops/org/tensorflow/op/core/BatchToSpace.java
--- java/org/tensorflow/op/core/BatchToSpace.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BatchToSpace.java	2018-10-16 20:18:38.188432412 +0900
@@ -0,0 +1,139 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * BatchToSpace for 4-D tensors of type T.
+ * <p>
+ * This is a legacy version of the more general BatchToSpaceND.
+ * <p>
+ * Rearranges (permutes) data from batch into blocks of spatial data, followed by
+ * cropping. This is the reverse transformation of SpaceToBatch. More specifically,
+ * this op outputs a copy of the input tensor where values from the `batch`
+ * dimension are moved in spatial blocks to the `height` and `width` dimensions,
+ * followed by cropping along the `height` and `width` dimensions.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class BatchToSpace<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new BatchToSpace operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 4-D tensor with shape
+   * `[batch<i>block_size</i>block_size, height_pad/block_size, width_pad/block_size,
+   *   depth]`. Note that the batch size of the input tensor must be divisible by
+   * `block_size * block_size`.
+   * @param crops 2-D tensor of non-negative integers with shape `[2, 2]`. It specifies
+   * how many elements to crop from the intermediate result across the spatial
+   * dimensions as follows:
+   * <p>
+   *     crops = [[crop_top, crop_bottom], [crop_left, crop_right]]
+   * @param blockSize 
+   * @return a new instance of BatchToSpace
+   */
+  public static <T, U extends Number> BatchToSpace<T> create(Scope scope, Operand<T> input, Operand<U> crops, Long blockSize) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BatchToSpace", scope.makeOpName("BatchToSpace"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(crops.asOutput());
+    opBuilder.setAttr("block_size", blockSize);
+    return new BatchToSpace<T>(opBuilder.build());
+  }
+  
+  /**
+   * 4-D with shape `[batch, height, width, depth]`, where:
+   * <p>
+   *       height = height_pad - crop_top - crop_bottom
+   *       width = width_pad - crop_left - crop_right
+   * <p>
+   * The attr `block_size` must be greater than one. It indicates the block size.
+   * <p>
+   * Some examples:
+   * <p>
+   * (1) For the following input of shape `[4, 1, 1, 1]` and block_size of 2:
+   * <pre>{@code
+   * [[[[1]]], [[[2]]], [[[3]]], [[[4]]]]
+   * }</pre>
+   * The output tensor has shape `[1, 2, 2, 1]` and value:
+   * <pre>{@code
+   * x = [[[[1], [2]], [[3], [4]]]]
+   * }</pre>
+   * (2) For the following input of shape `[4, 1, 1, 3]` and block_size of 2:
+   * <pre>{@code
+   * [[[1, 2, 3]], [[4, 5, 6]], [[7, 8, 9]], [[10, 11, 12]]]
+   * }</pre>
+   * The output tensor has shape `[1, 2, 2, 3]` and value:
+   * <pre>{@code
+   * x = [[[[1, 2, 3], [4, 5, 6]],
+   *       [[7, 8, 9], [10, 11, 12]]]]
+   * }</pre>
+   * (3) For the following input of shape `[4, 2, 2, 1]` and block_size of 2:
+   * <pre>{@code
+   * x = [[[[1], [3]], [[9], [11]]],
+   *      [[[2], [4]], [[10], [12]]],
+   *      [[[5], [7]], [[13], [15]]],
+   *      [[[6], [8]], [[14], [16]]]]
+   * }</pre>
+   * The output tensor has shape `[1, 4, 4, 1]` and value:
+   * <pre>{@code
+   * x = [[[1],   [2],  [3],  [4]],
+   *      [[5],   [6],  [7],  [8]],
+   *      [[9],  [10], [11],  [12]],
+   *      [[13], [14], [15],  [16]]]
+   * }</pre>
+   * (4) For the following input of shape `[8, 1, 2, 1]` and block_size of 2:
+   * <pre>{@code
+   * x = [[[[1], [3]]], [[[9], [11]]], [[[2], [4]]], [[[10], [12]]],
+   *      [[[5], [7]]], [[[13], [15]]], [[[6], [8]]], [[[14], [16]]]]
+   * }</pre>
+   * The output tensor has shape `[2, 2, 4, 1]` and value:
+   * <pre>{@code
+   * x = [[[[1], [3]], [[5], [7]]],
+   *      [[[2], [4]], [[10], [12]]],
+   *      [[[5], [7]], [[13], [15]]],
+   *      [[[6], [8]], [[14], [16]]]]
+   * }</pre>
+   * 
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private BatchToSpace(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BatchToSpaceND.java java-ops/org/tensorflow/op/core/BatchToSpaceND.java
--- java/org/tensorflow/op/core/BatchToSpaceND.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BatchToSpaceND.java	2018-10-16 20:18:38.191432409 +0900
@@ -0,0 +1,173 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * BatchToSpace for N-D tensors of type T.
+ * <p>
+ * This operation reshapes the "batch" dimension 0 into `M + 1` dimensions of shape
+ * `block_shape + [batch]`, interleaves these blocks back into the grid defined by
+ * the spatial dimensions `[1, ..., M]`, to obtain a result with the same rank as
+ * the input.  The spatial dimensions of this intermediate result are then
+ * optionally cropped according to `crops` to produce the output.  This is the
+ * reverse of SpaceToBatch.  See below for a precise description.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class BatchToSpaceND<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new BatchToSpaceND operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input N-D with shape `input_shape = [batch] + spatial_shape + remaining_shape`,
+   * where spatial_shape has M dimensions.
+   * @param blockShape 1-D with shape `[M]`, all values must be >= 1.
+   * @param crops 2-D with shape `[M, 2]`, all values must be >= 0.
+   *   `crops[i] = [crop_start, crop_end]` specifies the amount to crop from input
+   *   dimension `i + 1`, which corresponds to spatial dimension `i`.  It is
+   *   required that
+   *   `crop_start[i] + crop_end[i] <= block_shape[i] * input_shape[i + 1]`.
+   * <p>
+   * This operation is equivalent to the following steps:
+   * <p>
+   * 1. Reshape `input` to `reshaped` of shape:
+   *      [block_shape[0], ..., block_shape[M-1],
+   *       batch / prod(block_shape),
+   *       input_shape[1], ..., input_shape[N-1]]
+   * <p>
+   * 2. Permute dimensions of `reshaped` to produce `permuted` of shape
+   *      [batch / prod(block_shape),
+   * <p>
+   *       input_shape[1], block_shape[0],
+   *       ...,
+   *       input_shape[M], block_shape[M-1],
+   * <p>
+   *       input_shape[M+1], ..., input_shape[N-1]]
+   * <p>
+   * 3. Reshape `permuted` to produce `reshaped_permuted` of shape
+   *      [batch / prod(block_shape),
+   * <p>
+   *       input_shape[1] * block_shape[0],
+   *       ...,
+   *       input_shape[M] * block_shape[M-1],
+   * <p>
+   *       input_shape[M+1],
+   *       ...,
+   *       input_shape[N-1]]
+   * <p>
+   * 4. Crop the start and end of dimensions `[1, ..., M]` of
+   *    `reshaped_permuted` according to `crops` to produce the output of shape:
+   *      [batch / prod(block_shape),
+   * <p>
+   *       input_shape[1] * block_shape[0] - crops[0,0] - crops[0,1],
+   *       ...,
+   *       input_shape[M] * block_shape[M-1] - crops[M-1,0] - crops[M-1,1],
+   * <p>
+   *       input_shape[M+1], ..., input_shape[N-1]]
+   * <p>
+   * Some examples:
+   * <p>
+   * (1) For the following input of shape `[4, 1, 1, 1]`, `block_shape = [2, 2]`, and
+   *     `crops = [[0, 0], [0, 0]]`:
+   * <pre>{@code
+   * [[[[1]]], [[[2]]], [[[3]]], [[[4]]]]
+   * }</pre>
+   * The output tensor has shape `[1, 2, 2, 1]` and value:
+   * <pre>{@code
+   * x = [[[[1], [2]], [[3], [4]]]]
+   * }</pre>
+   * (2) For the following input of shape `[4, 1, 1, 3]`, `block_shape = [2, 2]`, and
+   *     `crops = [[0, 0], [0, 0]]`:
+   * <pre>{@code
+   * [[[1, 2, 3]], [[4, 5, 6]], [[7, 8, 9]], [[10, 11, 12]]]
+   * }</pre>
+   * The output tensor has shape `[1, 2, 2, 3]` and value:
+   * <pre>{@code
+   * x = [[[[1, 2, 3], [4, 5, 6]],
+   *       [[7, 8, 9], [10, 11, 12]]]]
+   * }</pre>
+   * (3) For the following input of shape `[4, 2, 2, 1]`, `block_shape = [2, 2]`, and
+   *     `crops = [[0, 0], [0, 0]]`:
+   * <pre>{@code
+   * x = [[[[1], [3]], [[9], [11]]],
+   *      [[[2], [4]], [[10], [12]]],
+   *      [[[5], [7]], [[13], [15]]],
+   *      [[[6], [8]], [[14], [16]]]]
+   * }</pre>
+   * The output tensor has shape `[1, 4, 4, 1]` and value:
+   * <pre>{@code
+   * x = [[[1],   [2],  [3],  [4]],
+   *      [[5],   [6],  [7],  [8]],
+   *      [[9],  [10], [11],  [12]],
+   *      [[13], [14], [15],  [16]]]
+   * }</pre>
+   * (4) For the following input of shape `[8, 1, 3, 1]`, `block_shape = [2, 2]`, and
+   *     `crops = [[0, 0], [2, 0]]`:
+   * <pre>{@code
+   * x = [[[[0], [1], [3]]], [[[0], [9], [11]]],
+   *      [[[0], [2], [4]]], [[[0], [10], [12]]],
+   *      [[[0], [5], [7]]], [[[0], [13], [15]]],
+   *      [[[0], [6], [8]]], [[[0], [14], [16]]]]
+   * }</pre>
+   * The output tensor has shape `[2, 2, 4, 1]` and value:
+   * <pre>{@code
+   * x = [[[[1],   [2],  [3],  [4]],
+   *       [[5],   [6],  [7],  [8]]],
+   *      [[[9],  [10], [11],  [12]],
+   *       [[13], [14], [15],  [16]]]]
+   * }</pre>
+   * 
+   * @return a new instance of BatchToSpaceND
+   */
+  public static <T, U extends Number, V extends Number> BatchToSpaceND<T> create(Scope scope, Operand<T> input, Operand<U> blockShape, Operand<V> crops) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BatchToSpaceND", scope.makeOpName("BatchToSpaceND"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(blockShape.asOutput());
+    opBuilder.addInput(crops.asOutput());
+    return new BatchToSpaceND<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private BatchToSpaceND(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BesselI0e.java java-ops/org/tensorflow/op/core/BesselI0e.java
--- java/org/tensorflow/op/core/BesselI0e.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BesselI0e.java	2018-10-16 20:18:38.192432409 +0900
@@ -0,0 +1,72 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the Bessel i0e function of `x` element-wise.
+ * <p>
+ * Exponentially scaled modified Bessel function of order 0 defined as
+ * `bessel_i0e(x) = exp(-abs(x)) bessel_i0(x)`.
+ * <p>
+ * This function is faster and numerically stabler than `bessel_i0(x)`.
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class BesselI0e<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new BesselI0e operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of BesselI0e
+   */
+  public static <T extends Number> BesselI0e<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BesselI0e", scope.makeOpName("BesselI0e"));
+    opBuilder.addInput(x.asOutput());
+    return new BesselI0e<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private BesselI0e(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BesselI1e.java java-ops/org/tensorflow/op/core/BesselI1e.java
--- java/org/tensorflow/op/core/BesselI1e.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BesselI1e.java	2018-10-16 20:18:38.192432409 +0900
@@ -0,0 +1,72 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the Bessel i1e function of `x` element-wise.
+ * <p>
+ * Exponentially scaled modified Bessel function of order 0 defined as
+ * `bessel_i1e(x) = exp(-abs(x)) bessel_i1(x)`.
+ * <p>
+ * This function is faster and numerically stabler than `bessel_i1(x)`.
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class BesselI1e<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new BesselI1e operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of BesselI1e
+   */
+  public static <T extends Number> BesselI1e<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BesselI1e", scope.makeOpName("BesselI1e"));
+    opBuilder.addInput(x.asOutput());
+    return new BesselI1e<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private BesselI1e(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Betainc.java java-ops/org/tensorflow/op/core/Betainc.java
--- java/org/tensorflow/op/core/Betainc.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Betainc.java	2018-10-16 20:18:38.193432408 +0900
@@ -0,0 +1,82 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Compute the regularized incomplete beta integral \\(I_x(a, b)\\).
+ * <p>
+ * The regularized incomplete beta integral is defined as:
+ * <p>
+ * \\(I_x(a, b) = \frac{B(x; a, b)}{B(a, b)}\\)
+ * <p>
+ * where
+ * <p>
+ * \\(B(x; a, b) = \int_0^x t^{a-1} (1 - t)^{b-1} dt\\)
+ * <p>
+ * is the incomplete beta function and \\(B(a, b)\\) is the <i>complete</i>
+ * beta function.
+ * 
+ * @param <T> data type for {@code z()} output
+ */
+@Operator
+public final class Betainc<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Betainc operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param a 
+   * @param b 
+   * @param x 
+   * @return a new instance of Betainc
+   */
+  public static <T extends Number> Betainc<T> create(Scope scope, Operand<T> a, Operand<T> b, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Betainc", scope.makeOpName("Betainc"));
+    opBuilder.addInput(a.asOutput());
+    opBuilder.addInput(b.asOutput());
+    opBuilder.addInput(x.asOutput());
+    return new Betainc<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return z;
+  }
+  
+  private Output<T> z;
+  
+  private Betainc(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BiasAddGrad.java java-ops/org/tensorflow/op/core/BiasAddGrad.java
--- java/org/tensorflow/op/core/BiasAddGrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BiasAddGrad.java	2018-10-16 20:18:38.194432407 +0900
@@ -0,0 +1,118 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * The backward operation for "BiasAdd" on the "bias" tensor.
+ * <p>
+ * It accumulates all the values from out_backprop into the feature dimension.
+ * For NHWC data format, the feature dimension is the last. For NCHW data format,
+ * the feature dimension is the third-to-last.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class BiasAddGrad<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.BiasAddGrad}
+   */
+  public static class Options {
+    
+    /**
+     * @param dataFormat Specify the data format of the input and output data. With the
+     * default format "NHWC", the bias tensor will be added to the last dimension
+     * of the value tensor.
+     * Alternatively, the format could be "NCHW", the data storage order of:
+     *     [batch, in_channels, in_height, in_width].
+     * The tensor will be added to "in_channels", the third-to-the-last
+     *     dimension.
+     */
+    public Options dataFormat(String dataFormat) {
+      this.dataFormat = dataFormat;
+      return this;
+    }
+    
+    private String dataFormat;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new BiasAddGrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param outBackprop Any number of dimensions.
+   * @param options carries optional attributes values
+   * @return a new instance of BiasAddGrad
+   */
+  public static <T> BiasAddGrad<T> create(Scope scope, Operand<T> outBackprop, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BiasAddGrad", scope.makeOpName("BiasAddGrad"));
+    opBuilder.addInput(outBackprop.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.dataFormat != null) {
+          opBuilder.setAttr("data_format", opts.dataFormat);
+        }
+      }
+    }
+    return new BiasAddGrad<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param dataFormat Specify the data format of the input and output data. With the
+   * default format "NHWC", the bias tensor will be added to the last dimension
+   * of the value tensor.
+   * Alternatively, the format could be "NCHW", the data storage order of:
+   *     [batch, in_channels, in_height, in_width].
+   * The tensor will be added to "in_channels", the third-to-the-last
+   *     dimension.
+   */
+  public static Options dataFormat(String dataFormat) {
+    return new Options().dataFormat(dataFormat);
+  }
+  
+  /**
+   * 1-D with size the feature dimension of `out_backprop`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private BiasAddGrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BiasAdd.java java-ops/org/tensorflow/op/core/BiasAdd.java
--- java/org/tensorflow/op/core/BiasAdd.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BiasAdd.java	2018-10-16 20:18:38.193432408 +0900
@@ -0,0 +1,119 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Adds `bias` to `value`.
+ * <p>
+ * This is a special case of `tf.add` where `bias` is restricted to be 1-D.
+ * Broadcasting is supported, so `value` may have any number of dimensions.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class BiasAdd<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.BiasAdd}
+   */
+  public static class Options {
+    
+    /**
+     * @param dataFormat Specify the data format of the input and output data. With the
+     * default format "NHWC", the bias tensor will be added to the last dimension
+     * of the value tensor.
+     * Alternatively, the format could be "NCHW", the data storage order of:
+     *     [batch, in_channels, in_height, in_width].
+     * The tensor will be added to "in_channels", the third-to-the-last
+     *     dimension.
+     */
+    public Options dataFormat(String dataFormat) {
+      this.dataFormat = dataFormat;
+      return this;
+    }
+    
+    private String dataFormat;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new BiasAdd operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param value Any number of dimensions.
+   * @param bias 1-D with size the last dimension of `value`.
+   * @param options carries optional attributes values
+   * @return a new instance of BiasAdd
+   */
+  public static <T> BiasAdd<T> create(Scope scope, Operand<T> value, Operand<T> bias, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BiasAdd", scope.makeOpName("BiasAdd"));
+    opBuilder.addInput(value.asOutput());
+    opBuilder.addInput(bias.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.dataFormat != null) {
+          opBuilder.setAttr("data_format", opts.dataFormat);
+        }
+      }
+    }
+    return new BiasAdd<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param dataFormat Specify the data format of the input and output data. With the
+   * default format "NHWC", the bias tensor will be added to the last dimension
+   * of the value tensor.
+   * Alternatively, the format could be "NCHW", the data storage order of:
+   *     [batch, in_channels, in_height, in_width].
+   * The tensor will be added to "in_channels", the third-to-the-last
+   *     dimension.
+   */
+  public static Options dataFormat(String dataFormat) {
+    return new Options().dataFormat(dataFormat);
+  }
+  
+  /**
+   * Broadcasted sum of `value` and `bias`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private BiasAdd(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BigQueryReader.java java-ops/org/tensorflow/op/core/BigQueryReader.java
--- java/org/tensorflow/op/core/BigQueryReader.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BigQueryReader.java	2018-10-16 20:18:38.194432407 +0900
@@ -0,0 +1,157 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * A Reader that outputs rows from a BigQuery table as tensorflow Examples.
+ */
+@Operator
+public final class BigQueryReader extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.BigQueryReader}
+   */
+  public static class Options {
+    
+    /**
+     * @param container If non-empty, this reader is placed in the given container.
+     * Otherwise, a default container is used.
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName If non-empty, this reader is named in the given bucket
+     * with this shared_name. Otherwise, the node name is used instead.
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    /**
+     * @param testEndPoint Do not use. For testing purposes only.
+     */
+    public Options testEndPoint(String testEndPoint) {
+      this.testEndPoint = testEndPoint;
+      return this;
+    }
+    
+    private String container;
+    private String sharedName;
+    private String testEndPoint;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new BigQueryReader operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param projectId GCP project ID.
+   * @param datasetId BigQuery Dataset ID.
+   * @param tableId Table to read.
+   * @param columns List of columns to read. Leave empty to read all columns.
+   * @param timestampMillis Table snapshot timestamp in millis since epoch. Relative
+   * (negative or zero) snapshot times are not allowed. For more details, see
+   * 'Table Decorators' in BigQuery docs.
+   * @param options carries optional attributes values
+   * @return a new instance of BigQueryReader
+   */
+  public static BigQueryReader create(Scope scope, String projectId, String datasetId, String tableId, List<String> columns, Long timestampMillis, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BigQueryReader", scope.makeOpName("BigQueryReader"));
+    opBuilder.setAttr("project_id", projectId);
+    opBuilder.setAttr("dataset_id", datasetId);
+    opBuilder.setAttr("table_id", tableId);
+    String[] columnsArray = new String[columns.size()];
+    for (int i = 0; i < columnsArray.length; ++i) {
+      columnsArray[i] = columns.get(i);
+    }
+    opBuilder.setAttr("columns", columnsArray);
+    opBuilder.setAttr("timestamp_millis", timestampMillis);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+        if (opts.testEndPoint != null) {
+          opBuilder.setAttr("test_end_point", opts.testEndPoint);
+        }
+      }
+    }
+    return new BigQueryReader(opBuilder.build());
+  }
+  
+  /**
+   * @param container If non-empty, this reader is placed in the given container.
+   * Otherwise, a default container is used.
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName If non-empty, this reader is named in the given bucket
+   * with this shared_name. Otherwise, the node name is used instead.
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   * @param testEndPoint Do not use. For testing purposes only.
+   */
+  public static Options testEndPoint(String testEndPoint) {
+    return new Options().testEndPoint(testEndPoint);
+  }
+  
+  /**
+   * The handle to reference the Reader.
+   */
+  public Output<String> readerHandle() {
+    return readerHandle;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return readerHandle;
+  }
+  
+  private Output<String> readerHandle;
+  
+  private BigQueryReader(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    readerHandle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Bincount.java java-ops/org/tensorflow/op/core/Bincount.java
--- java/org/tensorflow/op/core/Bincount.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Bincount.java	2018-10-16 20:18:38.195432406 +0900
@@ -0,0 +1,83 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Counts the number of occurrences of each value in an integer array.
+ * <p>
+ * Outputs a vector with length `size` and the same dtype as `weights`. If
+ * `weights` are empty, then index `i` stores the number of times the value `i` is
+ * counted in `arr`. If `weights` are non-empty, then index `i` stores the sum of
+ * the value in `weights` at each index where the corresponding value in `arr` is
+ * `i`.
+ * <p>
+ * Values in `arr` outside of the range [0, size) are ignored.
+ * 
+ * @param <T> data type for {@code bins()} output
+ */
+@Operator
+public final class Bincount<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Bincount operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param arr int32 `Tensor`.
+   * @param size non-negative int32 scalar `Tensor`.
+   * @param weights is an int32, int64, float32, or float64 `Tensor` with the same
+   * shape as `arr`, or a length-0 `Tensor`, in which case it acts as all weights
+   * equal to 1.
+   * @return a new instance of Bincount
+   */
+  public static <T extends Number> Bincount<T> create(Scope scope, Operand<Integer> arr, Operand<Integer> size, Operand<T> weights) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Bincount", scope.makeOpName("Bincount"));
+    opBuilder.addInput(arr.asOutput());
+    opBuilder.addInput(size.asOutput());
+    opBuilder.addInput(weights.asOutput());
+    return new Bincount<T>(opBuilder.build());
+  }
+  
+  /**
+   * 1D `Tensor` with length equal to `size`. The counts or summed weights for
+   * each value in the range [0, size).
+   */
+  public Output<T> bins() {
+    return bins;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return bins;
+  }
+  
+  private Output<T> bins;
+  
+  private Bincount(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    bins = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Bitcast.java java-ops/org/tensorflow/op/core/Bitcast.java
--- java/org/tensorflow/op/core/Bitcast.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Bitcast.java	2018-10-16 20:18:38.195432406 +0900
@@ -0,0 +1,83 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Bitcasts a tensor from one type to another without copying data.
+ * <p>
+ * Given a tensor `input`, this operation returns a tensor that has the same buffer
+ * data as `input` with datatype `type`.
+ * <p>
+ * If the input datatype `T` is larger than the output datatype `type` then the
+ * shape changes from [...] to [..., sizeof(`T`)/sizeof(`type`)].
+ * <p>
+ * If `T` is smaller than `type`, the operator requires that the rightmost
+ * dimension be equal to sizeof(`type`)/sizeof(`T`). The shape then goes from
+ * [..., sizeof(`type`)/sizeof(`T`)] to [...].
+ * <p>
+ * <i>NOTE</i>: Bitcast is implemented as a low-level cast, so machines with different
+ * endian orderings will give different results.
+ * 
+ * @param <U> data type for {@code output()} output
+ */
+@Operator
+public final class Bitcast<U> extends PrimitiveOp implements Operand<U> {
+  
+  /**
+   * Factory method to create a class to wrap a new Bitcast operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param type 
+   * @return a new instance of Bitcast
+   */
+  public static <U, T> Bitcast<U> create(Scope scope, Operand<T> input, Class<U> type) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Bitcast", scope.makeOpName("Bitcast"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.setAttr("type", DataType.fromClass(type));
+    return new Bitcast<U>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<U> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<U> asOutput() {
+    return output;
+  }
+  
+  private Output<U> output;
+  
+  private Bitcast(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BitwiseAnd.java java-ops/org/tensorflow/op/core/BitwiseAnd.java
--- java/org/tensorflow/op/core/BitwiseAnd.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BitwiseAnd.java	2018-10-16 20:18:38.195432406 +0900
@@ -0,0 +1,72 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Elementwise computes the bitwise AND of `x` and `y`.
+ * <p>
+ * The result will have those bits set, that are set in both `x` and `y`. The
+ * computation is performed on the underlying representations of `x` and `y`.
+ * 
+ * @param <T> data type for {@code z()} output
+ */
+@Operator
+public final class BitwiseAnd<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new BitwiseAnd operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param y 
+   * @return a new instance of BitwiseAnd
+   */
+  public static <T extends Number> BitwiseAnd<T> create(Scope scope, Operand<T> x, Operand<T> y) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BitwiseAnd", scope.makeOpName("BitwiseAnd"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(y.asOutput());
+    return new BitwiseAnd<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return z;
+  }
+  
+  private Output<T> z;
+  
+  private BitwiseAnd(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BitwiseOr.java java-ops/org/tensorflow/op/core/BitwiseOr.java
--- java/org/tensorflow/op/core/BitwiseOr.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BitwiseOr.java	2018-10-16 20:18:38.196432406 +0900
@@ -0,0 +1,72 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Elementwise computes the bitwise OR of `x` and `y`.
+ * <p>
+ * The result will have those bits set, that are set in `x`, `y` or both. The
+ * computation is performed on the underlying representations of `x` and `y`.
+ * 
+ * @param <T> data type for {@code z()} output
+ */
+@Operator
+public final class BitwiseOr<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new BitwiseOr operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param y 
+   * @return a new instance of BitwiseOr
+   */
+  public static <T extends Number> BitwiseOr<T> create(Scope scope, Operand<T> x, Operand<T> y) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BitwiseOr", scope.makeOpName("BitwiseOr"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(y.asOutput());
+    return new BitwiseOr<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return z;
+  }
+  
+  private Output<T> z;
+  
+  private BitwiseOr(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BitwiseXor.java java-ops/org/tensorflow/op/core/BitwiseXor.java
--- java/org/tensorflow/op/core/BitwiseXor.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BitwiseXor.java	2018-10-16 20:18:38.196432406 +0900
@@ -0,0 +1,72 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Elementwise computes the bitwise XOR of `x` and `y`.
+ * <p>
+ * The result will have those bits set, that are different in `x` and `y`. The
+ * computation is performed on the underlying representations of `x` and `y`.
+ * 
+ * @param <T> data type for {@code z()} output
+ */
+@Operator
+public final class BitwiseXor<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new BitwiseXor operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param y 
+   * @return a new instance of BitwiseXor
+   */
+  public static <T extends Number> BitwiseXor<T> create(Scope scope, Operand<T> x, Operand<T> y) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BitwiseXor", scope.makeOpName("BitwiseXor"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(y.asOutput());
+    return new BitwiseXor<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return z;
+  }
+  
+  private Output<T> z;
+  
+  private BitwiseXor(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BoostedTreesBucketize.java java-ops/org/tensorflow/op/core/BoostedTreesBucketize.java
--- java/org/tensorflow/op/core/BoostedTreesBucketize.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BoostedTreesBucketize.java	2018-10-16 20:18:38.196432406 +0900
@@ -0,0 +1,78 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.Iterator;
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Bucketize each feature based on bucket boundaries.
+ * <p>
+ * An op that returns a list of float tensors, where each tensor represents the
+ * bucketized values for a single feature.
+ */
+public final class BoostedTreesBucketize extends PrimitiveOp implements Iterable<Operand<Integer>> {
+  
+  /**
+   * Factory method to create a class to wrap a new BoostedTreesBucketize operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param floatValues float; List of Rank 2 Tensor each containing float values for a single feature.
+   * @param bucketBoundaries float; List of Rank 1 Tensors each containing the bucket boundaries for a single
+   * feature.
+   * @return a new instance of BoostedTreesBucketize
+   */
+  public static BoostedTreesBucketize create(Scope scope, Iterable<Operand<Float>> floatValues, Iterable<Operand<Float>> bucketBoundaries) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BoostedTreesBucketize", scope.makeOpName("BoostedTreesBucketize"));
+    opBuilder.addInputList(Operands.asOutputs(floatValues));
+    opBuilder.addInputList(Operands.asOutputs(bucketBoundaries));
+    return new BoostedTreesBucketize(opBuilder.build());
+  }
+  
+  /**
+   * int; List of Rank 2 Tensors each containing the bucketized values for a single feature.
+   */
+  public List<Output<Integer>> buckets() {
+    return buckets;
+  }
+  
+  @Override
+  @SuppressWarnings({"rawtypes", "unchecked"})
+  public Iterator<Operand<Integer>> iterator() {
+    return (Iterator) buckets.iterator();
+  }
+  
+  private List<Output<Integer>> buckets;
+  
+  @SuppressWarnings("unchecked")
+  private BoostedTreesBucketize(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    int bucketsLength = operation.outputListLength("buckets");
+    buckets = Arrays.asList((Output<Integer>[])operation.outputList(outputIdx, bucketsLength));
+    outputIdx += bucketsLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/BoostedTreesCalculateBestGainsPerFeature.java java-ops/org/tensorflow/op/core/BoostedTreesCalculateBestGainsPerFeature.java
--- java/org/tensorflow/op/core/BoostedTreesCalculateBestGainsPerFeature.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BoostedTreesCalculateBestGainsPerFeature.java	2018-10-16 20:18:38.197432405 +0900
@@ -0,0 +1,130 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Calculates gains for each feature and returns the best possible split information for the feature.
+ * <p>
+ * The split information is the best threshold (bucket id), gains and left/right node contributions per node for each feature.
+ * <p>
+ * It is possible that not all nodes can be split on each feature. Hence, the list of possible nodes can differ between the features. Therefore, we return `node_ids_list` for each feature, containing the list of nodes that this feature can be used to split.
+ * <p>
+ * In this manner, the output is the best split per features and per node, so that it needs to be combined later to produce the best split for each node (among all possible features).
+ * <p>
+ * The length of output lists are all of the same length, `num_features`.
+ * The output shapes are compatible in a way that the first dimension of all tensors of all lists are the same and equal to the number of possible split nodes for each feature.
+ */
+public final class BoostedTreesCalculateBestGainsPerFeature extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new BoostedTreesCalculateBestGainsPerFeature operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param nodeIdRange A Rank 1 tensor (shape=[2]) to specify the range [first, last) of node ids to process within `stats_summary_list`. The nodes are iterated between the two nodes specified by the tensor, as like `for node_id in range(node_id_range[0], node_id_range[1])` (Note that the last index node_id_range[1] is exclusive).
+   * @param statsSummaryList A list of Rank 3 tensor (#shape=[max_splits, bucket, 2]) for accumulated stats summary (gradient/hessian) per node per buckets for each feature. The first dimension of the tensor is the maximum number of splits, and thus not all elements of it will be used, but only the indexes specified by node_ids will be used.
+   * @param l1 l1 regularization factor on leaf weights, per instance based.
+   * @param l2 l2 regularization factor on leaf weights, per instance based.
+   * @param treeComplexity adjustment to the gain, per leaf based.
+   * @param minNodeWeight mininum avg of hessians in a node before required for the node to be considered for splitting.
+   * @param maxSplits the number of nodes that can be split in the whole tree. Used as a dimension of output tensors.
+   * @return a new instance of BoostedTreesCalculateBestGainsPerFeature
+   */
+  public static BoostedTreesCalculateBestGainsPerFeature create(Scope scope, Operand<Integer> nodeIdRange, Iterable<Operand<Float>> statsSummaryList, Operand<Float> l1, Operand<Float> l2, Operand<Float> treeComplexity, Operand<Float> minNodeWeight, Long maxSplits) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BoostedTreesCalculateBestGainsPerFeature", scope.makeOpName("BoostedTreesCalculateBestGainsPerFeature"));
+    opBuilder.addInput(nodeIdRange.asOutput());
+    opBuilder.addInputList(Operands.asOutputs(statsSummaryList));
+    opBuilder.addInput(l1.asOutput());
+    opBuilder.addInput(l2.asOutput());
+    opBuilder.addInput(treeComplexity.asOutput());
+    opBuilder.addInput(minNodeWeight.asOutput());
+    opBuilder.setAttr("max_splits", maxSplits);
+    return new BoostedTreesCalculateBestGainsPerFeature(opBuilder.build());
+  }
+  
+  /**
+   * An output list of Rank 1 tensors indicating possible split node ids for each feature. The length of the list is num_features, but each tensor has different size as each feature provides different possible nodes. See above for details like shapes and sizes.
+   */
+  public List<Output<Integer>> nodeIdsList() {
+    return nodeIdsList;
+  }
+  
+  /**
+   * An output list of Rank 1 tensors indicating the best gains for each feature to split for certain nodes. See above for details like shapes and sizes.
+   */
+  public List<Output<Float>> gainsList() {
+    return gainsList;
+  }
+  
+  /**
+   * An output list of Rank 1 tensors indicating the bucket id to compare with (as a threshold) for split in each node. See above for details like shapes and sizes.
+   */
+  public List<Output<Integer>> thresholdsList() {
+    return thresholdsList;
+  }
+  
+  /**
+   * A list of Rank 2 tensors indicating the contribution of the left nodes when branching from parent nodes (given by the tensor element in the output node_ids_list) to the left direction by the given threshold for each feature. This value will be used to make the left node value by adding to the parent node value. Second dimension size is 1 for 1-dimensional logits, but would be larger for multi-class problems. See above for details like shapes and sizes.
+   */
+  public List<Output<Float>> leftNodeContribsList() {
+    return leftNodeContribsList;
+  }
+  
+  /**
+   * A list of Rank 2 tensors, with the same shape/conditions as left_node_contribs_list, but just that the value is for the right node.
+   */
+  public List<Output<Float>> rightNodeContribsList() {
+    return rightNodeContribsList;
+  }
+  
+  private List<Output<Integer>> nodeIdsList;
+  private List<Output<Float>> gainsList;
+  private List<Output<Integer>> thresholdsList;
+  private List<Output<Float>> leftNodeContribsList;
+  private List<Output<Float>> rightNodeContribsList;
+  
+  @SuppressWarnings("unchecked")
+  private BoostedTreesCalculateBestGainsPerFeature(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    int nodeIdsListLength = operation.outputListLength("node_ids_list");
+    nodeIdsList = Arrays.asList((Output<Integer>[])operation.outputList(outputIdx, nodeIdsListLength));
+    outputIdx += nodeIdsListLength;
+    int gainsListLength = operation.outputListLength("gains_list");
+    gainsList = Arrays.asList((Output<Float>[])operation.outputList(outputIdx, gainsListLength));
+    outputIdx += gainsListLength;
+    int thresholdsListLength = operation.outputListLength("thresholds_list");
+    thresholdsList = Arrays.asList((Output<Integer>[])operation.outputList(outputIdx, thresholdsListLength));
+    outputIdx += thresholdsListLength;
+    int leftNodeContribsListLength = operation.outputListLength("left_node_contribs_list");
+    leftNodeContribsList = Arrays.asList((Output<Float>[])operation.outputList(outputIdx, leftNodeContribsListLength));
+    outputIdx += leftNodeContribsListLength;
+    int rightNodeContribsListLength = operation.outputListLength("right_node_contribs_list");
+    rightNodeContribsList = Arrays.asList((Output<Float>[])operation.outputList(outputIdx, rightNodeContribsListLength));
+    outputIdx += rightNodeContribsListLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/BoostedTreesCenterBias.java java-ops/org/tensorflow/op/core/BoostedTreesCenterBias.java
--- java/org/tensorflow/op/core/BoostedTreesCenterBias.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BoostedTreesCenterBias.java	2018-10-16 20:18:38.198432404 +0900
@@ -0,0 +1,72 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Calculates the prior from the training data (the bias) and fills in the first node with the logits' prior. Returns a boolean indicating whether to continue centering.
+ */
+public final class BoostedTreesCenterBias extends PrimitiveOp implements Operand<Boolean> {
+  
+  /**
+   * Factory method to create a class to wrap a new BoostedTreesCenterBias operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param treeEnsembleHandle Handle to the tree ensemble.
+   * @param meanGradients A tensor with shape=[logits_dimension] with mean of gradients for a first node.
+   * @param meanHessians A tensor with shape=[logits_dimension] mean of hessians for a first node.
+   * @param l1 l1 regularization factor on leaf weights, per instance based.
+   * @param l2 l2 regularization factor on leaf weights, per instance based.
+   * @return a new instance of BoostedTreesCenterBias
+   */
+  public static BoostedTreesCenterBias create(Scope scope, Operand<?> treeEnsembleHandle, Operand<Float> meanGradients, Operand<Float> meanHessians, Operand<Float> l1, Operand<Float> l2) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BoostedTreesCenterBias", scope.makeOpName("BoostedTreesCenterBias"));
+    opBuilder.addInput(treeEnsembleHandle.asOutput());
+    opBuilder.addInput(meanGradients.asOutput());
+    opBuilder.addInput(meanHessians.asOutput());
+    opBuilder.addInput(l1.asOutput());
+    opBuilder.addInput(l2.asOutput());
+    return new BoostedTreesCenterBias(opBuilder.build());
+  }
+  
+  /**
+   * Bool, whether to continue bias centering.
+   */
+  public Output<Boolean> continueCentering() {
+    return continueCentering;
+  }
+  
+  @Override
+  public Output<Boolean> asOutput() {
+    return continueCentering;
+  }
+  
+  private Output<Boolean> continueCentering;
+  
+  private BoostedTreesCenterBias(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    continueCentering = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BoostedTreesCreateEnsemble.java java-ops/org/tensorflow/op/core/BoostedTreesCreateEnsemble.java
--- java/org/tensorflow/op/core/BoostedTreesCreateEnsemble.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BoostedTreesCreateEnsemble.java	2018-10-16 20:18:38.198432404 +0900
@@ -0,0 +1,52 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Creates a tree ensemble model and returns a handle to it.
+ */
+public final class BoostedTreesCreateEnsemble extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new BoostedTreesCreateEnsemble operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param treeEnsembleHandle Handle to the tree ensemble resource to be created.
+   * @param stampToken Token to use as the initial value of the resource stamp.
+   * @param treeEnsembleSerialized Serialized proto of the tree ensemble.
+   * @return a new instance of BoostedTreesCreateEnsemble
+   */
+  public static BoostedTreesCreateEnsemble create(Scope scope, Operand<?> treeEnsembleHandle, Operand<Long> stampToken, Operand<String> treeEnsembleSerialized) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BoostedTreesCreateEnsemble", scope.makeOpName("BoostedTreesCreateEnsemble"));
+    opBuilder.addInput(treeEnsembleHandle.asOutput());
+    opBuilder.addInput(stampToken.asOutput());
+    opBuilder.addInput(treeEnsembleSerialized.asOutput());
+    return new BoostedTreesCreateEnsemble(opBuilder.build());
+  }
+  
+  
+  private BoostedTreesCreateEnsemble(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BoostedTreesCreateQuantileStreamResource.java java-ops/org/tensorflow/op/core/BoostedTreesCreateQuantileStreamResource.java
--- java/org/tensorflow/op/core/BoostedTreesCreateQuantileStreamResource.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BoostedTreesCreateQuantileStreamResource.java	2018-10-16 20:18:38.198432404 +0900
@@ -0,0 +1,86 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Create the Resource for Quantile Streams.
+ */
+public final class BoostedTreesCreateQuantileStreamResource extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.BoostedTreesCreateQuantileStreamResource}
+   */
+  public static class Options {
+    
+    /**
+     * @param maxElements int; The maximum number of data points that can be fed to the stream.
+     */
+    public Options maxElements(Long maxElements) {
+      this.maxElements = maxElements;
+      return this;
+    }
+    
+    private Long maxElements;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new BoostedTreesCreateQuantileStreamResource operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param quantileStreamResourceHandle resource; Handle to quantile stream resource.
+   * @param epsilon float; The required approximation error of the stream resource.
+   * @param numStreams int; The number of streams managed by the resource that shares the same epsilon.
+   * @param options carries optional attributes values
+   * @return a new instance of BoostedTreesCreateQuantileStreamResource
+   */
+  public static BoostedTreesCreateQuantileStreamResource create(Scope scope, Operand<?> quantileStreamResourceHandle, Operand<Float> epsilon, Operand<Long> numStreams, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BoostedTreesCreateQuantileStreamResource", scope.makeOpName("BoostedTreesCreateQuantileStreamResource"));
+    opBuilder.addInput(quantileStreamResourceHandle.asOutput());
+    opBuilder.addInput(epsilon.asOutput());
+    opBuilder.addInput(numStreams.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.maxElements != null) {
+          opBuilder.setAttr("max_elements", opts.maxElements);
+        }
+      }
+    }
+    return new BoostedTreesCreateQuantileStreamResource(opBuilder.build());
+  }
+  
+  /**
+   * @param maxElements int; The maximum number of data points that can be fed to the stream.
+   */
+  public static Options maxElements(Long maxElements) {
+    return new Options().maxElements(maxElements);
+  }
+  
+  
+  private BoostedTreesCreateQuantileStreamResource(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BoostedTreesDeserializeEnsemble.java java-ops/org/tensorflow/op/core/BoostedTreesDeserializeEnsemble.java
--- java/org/tensorflow/op/core/BoostedTreesDeserializeEnsemble.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BoostedTreesDeserializeEnsemble.java	2018-10-16 20:18:38.198432404 +0900
@@ -0,0 +1,54 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Deserializes a serialized tree ensemble config and replaces current tree
+ * <p>
+ * ensemble.
+ */
+public final class BoostedTreesDeserializeEnsemble extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new BoostedTreesDeserializeEnsemble operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param treeEnsembleHandle Handle to the tree ensemble.
+   * @param stampToken Token to use as the new value of the resource stamp.
+   * @param treeEnsembleSerialized Serialized proto of the ensemble.
+   * @return a new instance of BoostedTreesDeserializeEnsemble
+   */
+  public static BoostedTreesDeserializeEnsemble create(Scope scope, Operand<?> treeEnsembleHandle, Operand<Long> stampToken, Operand<String> treeEnsembleSerialized) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BoostedTreesDeserializeEnsemble", scope.makeOpName("BoostedTreesDeserializeEnsemble"));
+    opBuilder.addInput(treeEnsembleHandle.asOutput());
+    opBuilder.addInput(stampToken.asOutput());
+    opBuilder.addInput(treeEnsembleSerialized.asOutput());
+    return new BoostedTreesDeserializeEnsemble(opBuilder.build());
+  }
+  
+  
+  private BoostedTreesDeserializeEnsemble(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BoostedTreesEnsembleResourceHandleOp.java java-ops/org/tensorflow/op/core/BoostedTreesEnsembleResourceHandleOp.java
--- java/org/tensorflow/op/core/BoostedTreesEnsembleResourceHandleOp.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BoostedTreesEnsembleResourceHandleOp.java	2018-10-16 20:18:38.199432404 +0900
@@ -0,0 +1,115 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Creates a handle to a BoostedTreesEnsembleResource
+ */
+public final class BoostedTreesEnsembleResourceHandleOp extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.BoostedTreesEnsembleResourceHandleOp}
+   */
+  public static class Options {
+    
+    /**
+     * @param container 
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName 
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new BoostedTreesEnsembleResourceHandleOp operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param options carries optional attributes values
+   * @return a new instance of BoostedTreesEnsembleResourceHandleOp
+   */
+  public static BoostedTreesEnsembleResourceHandleOp create(Scope scope, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BoostedTreesEnsembleResourceHandleOp", scope.makeOpName("BoostedTreesEnsembleResourceHandleOp"));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new BoostedTreesEnsembleResourceHandleOp(opBuilder.build());
+  }
+  
+  /**
+   * @param container 
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName 
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   */
+  public Output<?> resource() {
+    return resource;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) resource;
+  }
+  
+  private Output<?> resource;
+  
+  private BoostedTreesEnsembleResourceHandleOp(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    resource = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BoostedTreesExampleDebugOutputs.java java-ops/org/tensorflow/op/core/BoostedTreesExampleDebugOutputs.java
--- java/org/tensorflow/op/core/BoostedTreesExampleDebugOutputs.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BoostedTreesExampleDebugOutputs.java	2018-10-16 20:18:38.199432404 +0900
@@ -0,0 +1,75 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Debugging/model interpretability outputs for each example.
+ * <p>
+ * It traverses all the trees and computes debug metrics for individual examples, 
+ * such as getting split feature ids and logits after each split along the decision
+ * path used to compute directional feature contributions.
+ */
+public final class BoostedTreesExampleDebugOutputs extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Factory method to create a class to wrap a new BoostedTreesExampleDebugOutputs operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param treeEnsembleHandle 
+   * @param bucketizedFeatures A list of rank 1 Tensors containing bucket id for each
+   * feature.
+   * @param logitsDimension scalar, dimension of the logits, to be used for constructing the protos in
+   * examples_debug_outputs_serialized.
+   * @return a new instance of BoostedTreesExampleDebugOutputs
+   */
+  public static BoostedTreesExampleDebugOutputs create(Scope scope, Operand<?> treeEnsembleHandle, Iterable<Operand<Integer>> bucketizedFeatures, Long logitsDimension) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BoostedTreesExampleDebugOutputs", scope.makeOpName("BoostedTreesExampleDebugOutputs"));
+    opBuilder.addInput(treeEnsembleHandle.asOutput());
+    opBuilder.addInputList(Operands.asOutputs(bucketizedFeatures));
+    opBuilder.setAttr("logits_dimension", logitsDimension);
+    return new BoostedTreesExampleDebugOutputs(opBuilder.build());
+  }
+  
+  /**
+   * Output rank 1 Tensor containing a proto serialized as a string for each example.
+   */
+  public Output<String> examplesDebugOutputsSerialized() {
+    return examplesDebugOutputsSerialized;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return examplesDebugOutputsSerialized;
+  }
+  
+  private Output<String> examplesDebugOutputsSerialized;
+  
+  private BoostedTreesExampleDebugOutputs(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    examplesDebugOutputsSerialized = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BoostedTreesGetEnsembleStates.java java-ops/org/tensorflow/op/core/BoostedTreesGetEnsembleStates.java
--- java/org/tensorflow/op/core/BoostedTreesGetEnsembleStates.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BoostedTreesGetEnsembleStates.java	2018-10-16 20:18:38.199432404 +0900
@@ -0,0 +1,96 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Retrieves the tree ensemble resource stamp token, number of trees and growing statistics.
+ */
+public final class BoostedTreesGetEnsembleStates extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new BoostedTreesGetEnsembleStates operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param treeEnsembleHandle Handle to the tree ensemble.
+   * @return a new instance of BoostedTreesGetEnsembleStates
+   */
+  public static BoostedTreesGetEnsembleStates create(Scope scope, Operand<?> treeEnsembleHandle) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BoostedTreesGetEnsembleStates", scope.makeOpName("BoostedTreesGetEnsembleStates"));
+    opBuilder.addInput(treeEnsembleHandle.asOutput());
+    return new BoostedTreesGetEnsembleStates(opBuilder.build());
+  }
+  
+  /**
+   * Stamp token of the tree ensemble resource.
+   */
+  public Output<Long> stampToken() {
+    return stampToken;
+  }
+  
+  /**
+   * The number of trees in the tree ensemble resource.
+   */
+  public Output<Integer> numTrees() {
+    return numTrees;
+  }
+  
+  /**
+   * The number of trees that were finished successfully.
+   */
+  public Output<Integer> numFinalizedTrees() {
+    return numFinalizedTrees;
+  }
+  
+  /**
+   * The number of layers we attempted to build (but not necessarily succeeded).
+   */
+  public Output<Integer> numAttemptedLayers() {
+    return numAttemptedLayers;
+  }
+  
+  /**
+   * Rank size 2 tensor that contains start and end ids of the nodes in the latest
+   * layer.
+   */
+  public Output<Integer> lastLayerNodesRange() {
+    return lastLayerNodesRange;
+  }
+  
+  private Output<Long> stampToken;
+  private Output<Integer> numTrees;
+  private Output<Integer> numFinalizedTrees;
+  private Output<Integer> numAttemptedLayers;
+  private Output<Integer> lastLayerNodesRange;
+  
+  private BoostedTreesGetEnsembleStates(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    stampToken = operation.output(outputIdx++);
+    numTrees = operation.output(outputIdx++);
+    numFinalizedTrees = operation.output(outputIdx++);
+    numAttemptedLayers = operation.output(outputIdx++);
+    lastLayerNodesRange = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BoostedTreesMakeQuantileSummaries.java java-ops/org/tensorflow/op/core/BoostedTreesMakeQuantileSummaries.java
--- java/org/tensorflow/op/core/BoostedTreesMakeQuantileSummaries.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BoostedTreesMakeQuantileSummaries.java	2018-10-16 20:18:38.200432403 +0900
@@ -0,0 +1,79 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.Iterator;
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Makes the summary of quantiles for the batch.
+ * <p>
+ * An op that takes a list of tensors and outputs the quantile summaries for each tensor.
+ */
+public final class BoostedTreesMakeQuantileSummaries extends PrimitiveOp implements Iterable<Operand<Float>> {
+  
+  /**
+   * Factory method to create a class to wrap a new BoostedTreesMakeQuantileSummaries operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param floatValues float; List of Rank 2 Tensors each containing values for a single feature.
+   * @param exampleWeights float; Rank 1 Tensor with weights per instance.
+   * @param epsilon float; The required maximum approximation error.
+   * @return a new instance of BoostedTreesMakeQuantileSummaries
+   */
+  public static BoostedTreesMakeQuantileSummaries create(Scope scope, Iterable<Operand<Float>> floatValues, Operand<Float> exampleWeights, Operand<Float> epsilon) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BoostedTreesMakeQuantileSummaries", scope.makeOpName("BoostedTreesMakeQuantileSummaries"));
+    opBuilder.addInputList(Operands.asOutputs(floatValues));
+    opBuilder.addInput(exampleWeights.asOutput());
+    opBuilder.addInput(epsilon.asOutput());
+    return new BoostedTreesMakeQuantileSummaries(opBuilder.build());
+  }
+  
+  /**
+   * float; List of Rank 2 Tensors each containing the quantile summary (value, weight,
+   * min_rank, max_rank) of a single feature.
+   */
+  public List<Output<Float>> summaries() {
+    return summaries;
+  }
+  
+  @Override
+  @SuppressWarnings({"rawtypes", "unchecked"})
+  public Iterator<Operand<Float>> iterator() {
+    return (Iterator) summaries.iterator();
+  }
+  
+  private List<Output<Float>> summaries;
+  
+  @SuppressWarnings("unchecked")
+  private BoostedTreesMakeQuantileSummaries(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    int summariesLength = operation.outputListLength("summaries");
+    summaries = Arrays.asList((Output<Float>[])operation.outputList(outputIdx, summariesLength));
+    outputIdx += summariesLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/BoostedTreesMakeStatsSummary.java java-ops/org/tensorflow/op/core/BoostedTreesMakeStatsSummary.java
--- java/org/tensorflow/op/core/BoostedTreesMakeStatsSummary.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BoostedTreesMakeStatsSummary.java	2018-10-16 20:18:38.200432403 +0900
@@ -0,0 +1,77 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Makes the summary of accumulated stats for the batch.
+ * <p>
+ * The summary stats contains gradients and hessians accumulated into the corresponding node and bucket for each example.
+ */
+public final class BoostedTreesMakeStatsSummary extends PrimitiveOp implements Operand<Float> {
+  
+  /**
+   * Factory method to create a class to wrap a new BoostedTreesMakeStatsSummary operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param nodeIds int32 Rank 1 Tensor containing node ids, which each example falls into for the requested layer.
+   * @param gradients float32; Rank 2 Tensor (shape=[#examples, 1]) for gradients.
+   * @param hessians float32; Rank 2 Tensor (shape=[#examples, 1]) for hessians.
+   * @param bucketizedFeaturesList int32 list of Rank 1 Tensors, each containing the bucketized feature (for each feature column).
+   * @param maxSplits int; the maximum number of splits possible in the whole tree.
+   * @param numBuckets int; equals to the maximum possible value of bucketized feature.
+   * @return a new instance of BoostedTreesMakeStatsSummary
+   */
+  public static BoostedTreesMakeStatsSummary create(Scope scope, Operand<Integer> nodeIds, Operand<Float> gradients, Operand<Float> hessians, Iterable<Operand<Integer>> bucketizedFeaturesList, Long maxSplits, Long numBuckets) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BoostedTreesMakeStatsSummary", scope.makeOpName("BoostedTreesMakeStatsSummary"));
+    opBuilder.addInput(nodeIds.asOutput());
+    opBuilder.addInput(gradients.asOutput());
+    opBuilder.addInput(hessians.asOutput());
+    opBuilder.addInputList(Operands.asOutputs(bucketizedFeaturesList));
+    opBuilder.setAttr("max_splits", maxSplits);
+    opBuilder.setAttr("num_buckets", numBuckets);
+    return new BoostedTreesMakeStatsSummary(opBuilder.build());
+  }
+  
+  /**
+   * output Rank 4 Tensor (shape=[#features, #splits, #buckets, 2]) containing accumulated stats put into the corresponding node and bucket. The first index of 4th dimension refers to gradients, and the second to hessians.
+   */
+  public Output<Float> statsSummary() {
+    return statsSummary;
+  }
+  
+  @Override
+  public Output<Float> asOutput() {
+    return statsSummary;
+  }
+  
+  private Output<Float> statsSummary;
+  
+  private BoostedTreesMakeStatsSummary(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    statsSummary = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BoostedTreesPredict.java java-ops/org/tensorflow/op/core/BoostedTreesPredict.java
--- java/org/tensorflow/op/core/BoostedTreesPredict.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BoostedTreesPredict.java	2018-10-16 20:18:38.200432403 +0900
@@ -0,0 +1,74 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Runs multiple additive regression ensemble predictors on input instances and
+ * <p>
+ * computes the logits. It is designed to be used during prediction.
+ * It traverses all the trees and calculates the final score for each instance.
+ */
+public final class BoostedTreesPredict extends PrimitiveOp implements Operand<Float> {
+  
+  /**
+   * Factory method to create a class to wrap a new BoostedTreesPredict operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param treeEnsembleHandle 
+   * @param bucketizedFeatures A list of rank 1 Tensors containing bucket id for each
+   * feature.
+   * @param logitsDimension scalar, dimension of the logits, to be used for partial logits
+   * shape.
+   * @return a new instance of BoostedTreesPredict
+   */
+  public static BoostedTreesPredict create(Scope scope, Operand<?> treeEnsembleHandle, Iterable<Operand<Integer>> bucketizedFeatures, Long logitsDimension) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BoostedTreesPredict", scope.makeOpName("BoostedTreesPredict"));
+    opBuilder.addInput(treeEnsembleHandle.asOutput());
+    opBuilder.addInputList(Operands.asOutputs(bucketizedFeatures));
+    opBuilder.setAttr("logits_dimension", logitsDimension);
+    return new BoostedTreesPredict(opBuilder.build());
+  }
+  
+  /**
+   * Output rank 2 Tensor containing logits for each example.
+   */
+  public Output<Float> logits() {
+    return logits;
+  }
+  
+  @Override
+  public Output<Float> asOutput() {
+    return logits;
+  }
+  
+  private Output<Float> logits;
+  
+  private BoostedTreesPredict(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    logits = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BoostedTreesQuantileStreamResourceAddSummaries.java java-ops/org/tensorflow/op/core/BoostedTreesQuantileStreamResourceAddSummaries.java
--- java/org/tensorflow/op/core/BoostedTreesQuantileStreamResourceAddSummaries.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BoostedTreesQuantileStreamResourceAddSummaries.java	2018-10-16 20:18:38.201432402 +0900
@@ -0,0 +1,55 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Add the quantile summaries to each quantile stream resource.
+ * <p>
+ * An op that adds a list of quantile summaries to a quantile stream resource. Each
+ * summary Tensor is rank 2, containing summaries (value, weight, min_rank, max_rank)
+ * for a single feature.
+ */
+public final class BoostedTreesQuantileStreamResourceAddSummaries extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new BoostedTreesQuantileStreamResourceAddSummaries operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param quantileStreamResourceHandle resource handle referring to a QuantileStreamResource.
+   * @param summaries string; List of Rank 2 Tensor each containing the summaries for a single feature.
+   * @return a new instance of BoostedTreesQuantileStreamResourceAddSummaries
+   */
+  public static BoostedTreesQuantileStreamResourceAddSummaries create(Scope scope, Operand<?> quantileStreamResourceHandle, Iterable<Operand<Float>> summaries) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BoostedTreesQuantileStreamResourceAddSummaries", scope.makeOpName("BoostedTreesQuantileStreamResourceAddSummaries"));
+    opBuilder.addInput(quantileStreamResourceHandle.asOutput());
+    opBuilder.addInputList(Operands.asOutputs(summaries));
+    return new BoostedTreesQuantileStreamResourceAddSummaries(opBuilder.build());
+  }
+  
+  
+  private BoostedTreesQuantileStreamResourceAddSummaries(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BoostedTreesQuantileStreamResourceFlush.java java-ops/org/tensorflow/op/core/BoostedTreesQuantileStreamResourceFlush.java
--- java/org/tensorflow/op/core/BoostedTreesQuantileStreamResourceFlush.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BoostedTreesQuantileStreamResourceFlush.java	2018-10-16 20:18:38.201432402 +0900
@@ -0,0 +1,96 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Flush the summaries for a quantile stream resource.
+ * <p>
+ * An op that flushes the summaries for a quantile stream resource.
+ */
+public final class BoostedTreesQuantileStreamResourceFlush extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.BoostedTreesQuantileStreamResourceFlush}
+   */
+  public static class Options {
+    
+    /**
+     * @param generateQuantiles bool; If True, the output will be the num_quantiles for each stream where the ith
+     * entry is the ith quantile of the input with an approximation error of epsilon.
+     * Duplicate values may be present.
+     * If False, the output will be the points in the histogram that we got which roughly
+     * translates to 1/epsilon boundaries and without any duplicates.
+     * Default to False.
+     */
+    public Options generateQuantiles(Boolean generateQuantiles) {
+      this.generateQuantiles = generateQuantiles;
+      return this;
+    }
+    
+    private Boolean generateQuantiles;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new BoostedTreesQuantileStreamResourceFlush operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param quantileStreamResourceHandle resource handle referring to a QuantileStreamResource.
+   * @param numBuckets int; approximate number of buckets unless using generate_quantiles.
+   * @param options carries optional attributes values
+   * @return a new instance of BoostedTreesQuantileStreamResourceFlush
+   */
+  public static BoostedTreesQuantileStreamResourceFlush create(Scope scope, Operand<?> quantileStreamResourceHandle, Operand<Long> numBuckets, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BoostedTreesQuantileStreamResourceFlush", scope.makeOpName("BoostedTreesQuantileStreamResourceFlush"));
+    opBuilder.addInput(quantileStreamResourceHandle.asOutput());
+    opBuilder.addInput(numBuckets.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.generateQuantiles != null) {
+          opBuilder.setAttr("generate_quantiles", opts.generateQuantiles);
+        }
+      }
+    }
+    return new BoostedTreesQuantileStreamResourceFlush(opBuilder.build());
+  }
+  
+  /**
+   * @param generateQuantiles bool; If True, the output will be the num_quantiles for each stream where the ith
+   * entry is the ith quantile of the input with an approximation error of epsilon.
+   * Duplicate values may be present.
+   * If False, the output will be the points in the histogram that we got which roughly
+   * translates to 1/epsilon boundaries and without any duplicates.
+   * Default to False.
+   */
+  public static Options generateQuantiles(Boolean generateQuantiles) {
+    return new Options().generateQuantiles(generateQuantiles);
+  }
+  
+  
+  private BoostedTreesQuantileStreamResourceFlush(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BoostedTreesQuantileStreamResourceGetBucketBoundaries.java java-ops/org/tensorflow/op/core/BoostedTreesQuantileStreamResourceGetBucketBoundaries.java
--- java/org/tensorflow/op/core/BoostedTreesQuantileStreamResourceGetBucketBoundaries.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BoostedTreesQuantileStreamResourceGetBucketBoundaries.java	2018-10-16 20:18:38.201432402 +0900
@@ -0,0 +1,76 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.Iterator;
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Generate the bucket boundaries for each feature based on accumulated summaries.
+ * <p>
+ * An op that returns a list of float tensors for a quantile stream resource. Each
+ * tensor is Rank 1 containing bucket boundaries for a single feature.
+ */
+public final class BoostedTreesQuantileStreamResourceGetBucketBoundaries extends PrimitiveOp implements Iterable<Operand<Float>> {
+  
+  /**
+   * Factory method to create a class to wrap a new BoostedTreesQuantileStreamResourceGetBucketBoundaries operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param quantileStreamResourceHandle resource handle referring to a QuantileStreamResource.
+   * @param numFeatures inferred int; number of features to get bucket boundaries for.
+   * @return a new instance of BoostedTreesQuantileStreamResourceGetBucketBoundaries
+   */
+  public static BoostedTreesQuantileStreamResourceGetBucketBoundaries create(Scope scope, Operand<?> quantileStreamResourceHandle, Long numFeatures) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BoostedTreesQuantileStreamResourceGetBucketBoundaries", scope.makeOpName("BoostedTreesQuantileStreamResourceGetBucketBoundaries"));
+    opBuilder.addInput(quantileStreamResourceHandle.asOutput());
+    opBuilder.setAttr("num_features", numFeatures);
+    return new BoostedTreesQuantileStreamResourceGetBucketBoundaries(opBuilder.build());
+  }
+  
+  /**
+   * float; List of Rank 1 Tensors each containing the bucket boundaries for a feature.
+   */
+  public List<Output<Float>> bucketBoundaries() {
+    return bucketBoundaries;
+  }
+  
+  @Override
+  @SuppressWarnings({"rawtypes", "unchecked"})
+  public Iterator<Operand<Float>> iterator() {
+    return (Iterator) bucketBoundaries.iterator();
+  }
+  
+  private List<Output<Float>> bucketBoundaries;
+  
+  @SuppressWarnings("unchecked")
+  private BoostedTreesQuantileStreamResourceGetBucketBoundaries(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    int bucketBoundariesLength = operation.outputListLength("bucket_boundaries");
+    bucketBoundaries = Arrays.asList((Output<Float>[])operation.outputList(outputIdx, bucketBoundariesLength));
+    outputIdx += bucketBoundariesLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/BoostedTreesQuantileStreamResourceHandleOp.java java-ops/org/tensorflow/op/core/BoostedTreesQuantileStreamResourceHandleOp.java
--- java/org/tensorflow/op/core/BoostedTreesQuantileStreamResourceHandleOp.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BoostedTreesQuantileStreamResourceHandleOp.java	2018-10-16 20:18:38.201432402 +0900
@@ -0,0 +1,115 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Creates a handle to a BoostedTreesQuantileStreamResource.
+ */
+public final class BoostedTreesQuantileStreamResourceHandleOp extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.BoostedTreesQuantileStreamResourceHandleOp}
+   */
+  public static class Options {
+    
+    /**
+     * @param container 
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName 
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new BoostedTreesQuantileStreamResourceHandleOp operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param options carries optional attributes values
+   * @return a new instance of BoostedTreesQuantileStreamResourceHandleOp
+   */
+  public static BoostedTreesQuantileStreamResourceHandleOp create(Scope scope, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BoostedTreesQuantileStreamResourceHandleOp", scope.makeOpName("BoostedTreesQuantileStreamResourceHandleOp"));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new BoostedTreesQuantileStreamResourceHandleOp(opBuilder.build());
+  }
+  
+  /**
+   * @param container 
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName 
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   */
+  public Output<?> resource() {
+    return resource;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) resource;
+  }
+  
+  private Output<?> resource;
+  
+  private BoostedTreesQuantileStreamResourceHandleOp(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    resource = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BoostedTreesSerializeEnsemble.java java-ops/org/tensorflow/op/core/BoostedTreesSerializeEnsemble.java
--- java/org/tensorflow/op/core/BoostedTreesSerializeEnsemble.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BoostedTreesSerializeEnsemble.java	2018-10-16 20:18:38.202432402 +0900
@@ -0,0 +1,68 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Serializes the tree ensemble to a proto.
+ */
+public final class BoostedTreesSerializeEnsemble extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new BoostedTreesSerializeEnsemble operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param treeEnsembleHandle Handle to the tree ensemble.
+   * @return a new instance of BoostedTreesSerializeEnsemble
+   */
+  public static BoostedTreesSerializeEnsemble create(Scope scope, Operand<?> treeEnsembleHandle) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BoostedTreesSerializeEnsemble", scope.makeOpName("BoostedTreesSerializeEnsemble"));
+    opBuilder.addInput(treeEnsembleHandle.asOutput());
+    return new BoostedTreesSerializeEnsemble(opBuilder.build());
+  }
+  
+  /**
+   * Stamp token of the tree ensemble resource.
+   */
+  public Output<Long> stampToken() {
+    return stampToken;
+  }
+  
+  /**
+   * Serialized proto of the ensemble.
+   */
+  public Output<String> treeEnsembleSerialized() {
+    return treeEnsembleSerialized;
+  }
+  
+  private Output<Long> stampToken;
+  private Output<String> treeEnsembleSerialized;
+  
+  private BoostedTreesSerializeEnsemble(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    stampToken = operation.output(outputIdx++);
+    treeEnsembleSerialized = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BoostedTreesTrainingPredict.java java-ops/org/tensorflow/op/core/BoostedTreesTrainingPredict.java
--- java/org/tensorflow/op/core/BoostedTreesTrainingPredict.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BoostedTreesTrainingPredict.java	2018-10-16 20:18:38.202432402 +0900
@@ -0,0 +1,95 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Runs multiple additive regression ensemble predictors on input instances and
+ * <p>
+ * computes the update to cached logits. It is designed to be used during training.
+ * It traverses the trees starting from cached tree id and cached node id and
+ * calculates the updates to be pushed to the cache.
+ */
+public final class BoostedTreesTrainingPredict extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new BoostedTreesTrainingPredict operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param treeEnsembleHandle 
+   * @param cachedTreeIds Rank 1 Tensor containing cached tree ids which is the starting
+   * tree of prediction.
+   * @param cachedNodeIds Rank 1 Tensor containing cached node id which is the starting
+   * node of prediction.
+   * @param bucketizedFeatures A list of rank 1 Tensors containing bucket id for each
+   * feature.
+   * @param logitsDimension scalar, dimension of the logits, to be used for partial logits
+   * shape.
+   * @return a new instance of BoostedTreesTrainingPredict
+   */
+  public static BoostedTreesTrainingPredict create(Scope scope, Operand<?> treeEnsembleHandle, Operand<Integer> cachedTreeIds, Operand<Integer> cachedNodeIds, Iterable<Operand<Integer>> bucketizedFeatures, Long logitsDimension) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BoostedTreesTrainingPredict", scope.makeOpName("BoostedTreesTrainingPredict"));
+    opBuilder.addInput(treeEnsembleHandle.asOutput());
+    opBuilder.addInput(cachedTreeIds.asOutput());
+    opBuilder.addInput(cachedNodeIds.asOutput());
+    opBuilder.addInputList(Operands.asOutputs(bucketizedFeatures));
+    opBuilder.setAttr("logits_dimension", logitsDimension);
+    return new BoostedTreesTrainingPredict(opBuilder.build());
+  }
+  
+  /**
+   * Rank 2 Tensor containing logits update (with respect to cached
+   * values stored) for each example.
+   */
+  public Output<Float> partialLogits() {
+    return partialLogits;
+  }
+  
+  /**
+   * Rank 1 Tensor containing new tree ids for each example.
+   */
+  public Output<Integer> treeIds() {
+    return treeIds;
+  }
+  
+  /**
+   * Rank 1 Tensor containing new node ids in the new tree_ids.
+   */
+  public Output<Integer> nodeIds() {
+    return nodeIds;
+  }
+  
+  private Output<Float> partialLogits;
+  private Output<Integer> treeIds;
+  private Output<Integer> nodeIds;
+  
+  private BoostedTreesTrainingPredict(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    partialLogits = operation.output(outputIdx++);
+    treeIds = operation.output(outputIdx++);
+    nodeIds = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BoostedTreesUpdateEnsemble.java java-ops/org/tensorflow/op/core/BoostedTreesUpdateEnsemble.java
--- java/org/tensorflow/op/core/BoostedTreesUpdateEnsemble.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BoostedTreesUpdateEnsemble.java	2018-10-16 20:18:38.202432402 +0900
@@ -0,0 +1,77 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Updates the tree ensemble by either adding a layer to the last tree being grown
+ * <p>
+ * or by starting a new tree.
+ */
+public final class BoostedTreesUpdateEnsemble extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new BoostedTreesUpdateEnsemble operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param treeEnsembleHandle Handle to the ensemble variable.
+   * @param featureIds Rank 1 tensor with ids for each feature. This is the real id of
+   * the feature that will be used in the split.
+   * @param nodeIds List of rank 1 tensors representing the nodes for which this feature
+   * has a split.
+   * @param gains List of rank 1 tensors representing the gains for each of the feature's
+   * split.
+   * @param thresholds List of rank 1 tensors representing the thesholds for each of the
+   * feature's split.
+   * @param leftNodeContribs List of rank 2 tensors with left leaf contribs for each of
+   * the feature's splits. Will be added to the previous node values to constitute
+   * the values of the left nodes.
+   * @param rightNodeContribs List of rank 2 tensors with right leaf contribs for each
+   * of the feature's splits. Will be added to the previous node values to constitute
+   * the values of the right nodes.
+   * @param maxDepth Max depth of the tree to build.
+   * @param learningRate shrinkage const for each new tree.
+   * @param pruningMode 0-No pruning, 1-Pre-pruning, 2-Post-pruning.
+   * @return a new instance of BoostedTreesUpdateEnsemble
+   */
+  public static BoostedTreesUpdateEnsemble create(Scope scope, Operand<?> treeEnsembleHandle, Operand<Integer> featureIds, Iterable<Operand<Integer>> nodeIds, Iterable<Operand<Float>> gains, Iterable<Operand<Integer>> thresholds, Iterable<Operand<Float>> leftNodeContribs, Iterable<Operand<Float>> rightNodeContribs, Operand<Integer> maxDepth, Operand<Float> learningRate, Long pruningMode) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BoostedTreesUpdateEnsemble", scope.makeOpName("BoostedTreesUpdateEnsemble"));
+    opBuilder.addInput(treeEnsembleHandle.asOutput());
+    opBuilder.addInput(featureIds.asOutput());
+    opBuilder.addInputList(Operands.asOutputs(nodeIds));
+    opBuilder.addInputList(Operands.asOutputs(gains));
+    opBuilder.addInputList(Operands.asOutputs(thresholds));
+    opBuilder.addInputList(Operands.asOutputs(leftNodeContribs));
+    opBuilder.addInputList(Operands.asOutputs(rightNodeContribs));
+    opBuilder.addInput(maxDepth.asOutput());
+    opBuilder.addInput(learningRate.asOutput());
+    opBuilder.setAttr("pruning_mode", pruningMode);
+    return new BoostedTreesUpdateEnsemble(opBuilder.build());
+  }
+  
+  
+  private BoostedTreesUpdateEnsemble(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BroadcastDynamicShape.java java-ops/org/tensorflow/op/core/BroadcastDynamicShape.java
--- java/org/tensorflow/op/core/BroadcastDynamicShape.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BroadcastDynamicShape.java	2018-10-16 20:18:38.203432401 +0900
@@ -0,0 +1,72 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Return the shape of s0 op s1 with broadcast.
+ * <p>
+ * Given `s0` and `s1`, tensors that represent shapes, compute `r0`, the
+ * broadcasted shape. `s0`, `s1` and `r0` are all integer vectors.
+ * 
+ * @param <T> data type for {@code r0()} output
+ */
+@Operator
+public final class BroadcastDynamicShape<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new BroadcastDynamicShape operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param s0 
+   * @param s1 
+   * @return a new instance of BroadcastDynamicShape
+   */
+  public static <T extends Number> BroadcastDynamicShape<T> create(Scope scope, Operand<T> s0, Operand<T> s1) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BroadcastArgs", scope.makeOpName("BroadcastDynamicShape"));
+    opBuilder.addInput(s0.asOutput());
+    opBuilder.addInput(s1.asOutput());
+    return new BroadcastDynamicShape<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> r0() {
+    return r0;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return r0;
+  }
+  
+  private Output<T> r0;
+  
+  private BroadcastDynamicShape(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    r0 = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BroadcastGradientArgs.java java-ops/org/tensorflow/op/core/BroadcastGradientArgs.java
--- java/org/tensorflow/op/core/BroadcastGradientArgs.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BroadcastGradientArgs.java	2018-10-16 20:18:38.203432401 +0900
@@ -0,0 +1,72 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Return the reduction indices for computing gradients of s0 op s1 with broadcast.
+ * <p>
+ * This is typically used by gradient computations for a broadcasting operation.
+ * 
+ * @param <T> data type for {@code r0()} output
+ */
+public final class BroadcastGradientArgs<T extends Number> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new BroadcastGradientArgs operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param s0 
+   * @param s1 
+   * @return a new instance of BroadcastGradientArgs
+   */
+  public static <T extends Number> BroadcastGradientArgs<T> create(Scope scope, Operand<T> s0, Operand<T> s1) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BroadcastGradientArgs", scope.makeOpName("BroadcastGradientArgs"));
+    opBuilder.addInput(s0.asOutput());
+    opBuilder.addInput(s1.asOutput());
+    return new BroadcastGradientArgs<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> r0() {
+    return r0;
+  }
+  
+  /**
+   */
+  public Output<T> r1() {
+    return r1;
+  }
+  
+  private Output<T> r0;
+  private Output<T> r1;
+  
+  private BroadcastGradientArgs(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    r0 = operation.output(outputIdx++);
+    r1 = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BroadcastTo.java java-ops/org/tensorflow/op/core/BroadcastTo.java
--- java/org/tensorflow/op/core/BroadcastTo.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BroadcastTo.java	2018-10-16 20:18:38.204432400 +0900
@@ -0,0 +1,88 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Broadcast an array for a compatible shape.
+ * <p>
+ * Broadcasting is the process of making arrays to have compatible shapes
+ * for arithmetic operations. Two shapes are compatible if for each
+ * dimension pair they are either equal or one of them is one. When trying
+ * to broadcast a Tensor to a shape, it starts with the trailing dimensions,
+ * and works its way forward.
+ * <p>
+ * For example,
+ * <pre>{@code
+ * >>> x = tf.constant([1, 2, 3])
+ * >>> y = tf.broadcast_to(x, [3, 3])
+ * >>> sess.run(y)
+ * array([[1, 2, 3],
+ *        [1, 2, 3],
+ *        [1, 2, 3]], dtype=int32)
+ * }</pre>
+ * In the above example, the input Tensor with the shape of `[1, 3]`
+ * is broadcasted to output Tensor with shape of `[3, 3]`.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class BroadcastTo<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new BroadcastTo operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input A Tensor to broadcast.
+   * @param shape An 1-D `int` Tensor. The shape of the desired output.
+   * @return a new instance of BroadcastTo
+   */
+  public static <T, U extends Number> BroadcastTo<T> create(Scope scope, Operand<T> input, Operand<U> shape) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BroadcastTo", scope.makeOpName("BroadcastTo"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(shape.asOutput());
+    return new BroadcastTo<T>(opBuilder.build());
+  }
+  
+  /**
+   * A Tensor.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private BroadcastTo(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Bucketize.java java-ops/org/tensorflow/op/core/Bucketize.java
--- java/org/tensorflow/op/core/Bucketize.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Bucketize.java	2018-10-16 20:18:38.204432400 +0900
@@ -0,0 +1,88 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Bucketizes 'input' based on 'boundaries'.
+ * <p>
+ * For example, if the inputs are
+ *     boundaries = [0, 10, 100]
+ *     input = [[-5, 10000]
+ *              [150,   10]
+ *              [5,    100]]
+ * <p>
+ * then the output will be
+ *     output = [[0, 3]
+ *               [3, 2]
+ *               [1, 3]]
+ */
+@Operator
+public final class Bucketize extends PrimitiveOp implements Operand<Integer> {
+  
+  /**
+   * Factory method to create a class to wrap a new Bucketize operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input Any shape of Tensor contains with int or float type.
+   * @param boundaries A sorted list of floats gives the boundary of the buckets.
+   * @return a new instance of Bucketize
+   */
+  public static <T extends Number> Bucketize create(Scope scope, Operand<T> input, List<Float> boundaries) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Bucketize", scope.makeOpName("Bucketize"));
+    opBuilder.addInput(input.asOutput());
+    float[] boundariesArray = new float[boundaries.size()];
+    for (int i = 0; i < boundariesArray.length; ++i) {
+      boundariesArray[i] = boundaries.get(i);
+    }
+    opBuilder.setAttr("boundaries", boundariesArray);
+    return new Bucketize(opBuilder.build());
+  }
+  
+  /**
+   * Same shape with 'input', each value of input replaced with bucket index.
+   * <p>
+   * @compatibility(numpy)
+   * Equivalent to np.digitize.
+   * @end_compatibility
+   */
+  public Output<Integer> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<Integer> asOutput() {
+    return output;
+  }
+  
+  private Output<Integer> output;
+  
+  private Bucketize(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/BytesProducedStatsDataset.java java-ops/org/tensorflow/op/core/BytesProducedStatsDataset.java
--- java/org/tensorflow/op/core/BytesProducedStatsDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/BytesProducedStatsDataset.java	2018-10-16 20:18:38.204432400 +0900
@@ -0,0 +1,83 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Records the bytes size of each element of `input_dataset` in a StatsAggregator.
+ */
+@Operator
+public final class BytesProducedStatsDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new BytesProducedStatsDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputDataset 
+   * @param tag 
+   * @param outputTypes 
+   * @param outputShapes 
+   * @return a new instance of BytesProducedStatsDataset
+   */
+  public static BytesProducedStatsDataset create(Scope scope, Operand<?> inputDataset, Operand<String> tag, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("BytesProducedStatsDataset", scope.makeOpName("BytesProducedStatsDataset"));
+    opBuilder.addInput(inputDataset.asOutput());
+    opBuilder.addInput(tag.asOutput());
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new BytesProducedStatsDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private BytesProducedStatsDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/CacheDataset.java java-ops/org/tensorflow/op/core/CacheDataset.java
--- java/org/tensorflow/op/core/CacheDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/CacheDataset.java	2018-10-16 20:18:38.207432398 +0900
@@ -0,0 +1,89 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Creates a dataset that caches elements from `input_dataset`.
+ * <p>
+ * A CacheDataset will iterate over the input_dataset, and store tensors. If the
+ * cache already exists, the cache will be used. If the cache is inappropriate
+ * (e.g. cannot be opened, contains tensors of the wrong shape / size), an error
+ * will the returned when used.
+ */
+@Operator
+public final class CacheDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new CacheDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputDataset 
+   * @param filename A path on the filesystem where we should cache the dataset. Note: this
+   * will be a directory.
+   * @param outputTypes 
+   * @param outputShapes 
+   * @return a new instance of CacheDataset
+   */
+  public static CacheDataset create(Scope scope, Operand<?> inputDataset, Operand<String> filename, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("CacheDataset", scope.makeOpName("CacheDataset"));
+    opBuilder.addInput(inputDataset.asOutput());
+    opBuilder.addInput(filename.asOutput());
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new CacheDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private CacheDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Cast.java java-ops/org/tensorflow/op/core/Cast.java
--- java/org/tensorflow/op/core/Cast.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Cast.java	2018-10-16 20:18:38.207432398 +0900
@@ -0,0 +1,104 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Cast x of type SrcT to y of DstT.
+ * 
+ * @param <U> data type for {@code y()} output
+ */
+@Operator
+public final class Cast<U> extends PrimitiveOp implements Operand<U> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Cast}
+   */
+  public static class Options {
+    
+    /**
+     * @param Truncate 
+     */
+    public Options Truncate(Boolean Truncate) {
+      this.Truncate = Truncate;
+      return this;
+    }
+    
+    private Boolean Truncate;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Cast operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param DstT 
+   * @param options carries optional attributes values
+   * @return a new instance of Cast
+   */
+  public static <U, T> Cast<U> create(Scope scope, Operand<T> x, Class<U> DstT, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Cast", scope.makeOpName("Cast"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.setAttr("DstT", DataType.fromClass(DstT));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.Truncate != null) {
+          opBuilder.setAttr("Truncate", opts.Truncate);
+        }
+      }
+    }
+    return new Cast<U>(opBuilder.build());
+  }
+  
+  /**
+   * @param Truncate 
+   */
+  public static Options Truncate(Boolean Truncate) {
+    return new Options().Truncate(Truncate);
+  }
+  
+  /**
+   */
+  public Output<U> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<U> asOutput() {
+    return y;
+  }
+  
+  private Output<U> y;
+  
+  private Cast(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Ceil.java java-ops/org/tensorflow/op/core/Ceil.java
--- java/org/tensorflow/op/core/Ceil.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Ceil.java	2018-10-16 20:18:38.208432397 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns element-wise smallest integer not less than x.
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class Ceil<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Ceil operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of Ceil
+   */
+  public static <T extends Number> Ceil<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Ceil", scope.makeOpName("Ceil"));
+    opBuilder.addInput(x.asOutput());
+    return new Ceil<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private Ceil(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/CheckNumerics.java java-ops/org/tensorflow/op/core/CheckNumerics.java
--- java/org/tensorflow/op/core/CheckNumerics.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/CheckNumerics.java	2018-10-16 20:18:38.208432397 +0900
@@ -0,0 +1,72 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Checks a tensor for NaN and Inf values.
+ * <p>
+ * When run, reports an `InvalidArgument` error if `tensor` has any values
+ * that are not a number (NaN) or infinity (Inf). Otherwise, passes `tensor` as-is.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class CheckNumerics<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new CheckNumerics operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param tensor 
+   * @param message Prefix of the error message.
+   * @return a new instance of CheckNumerics
+   */
+  public static <T extends Number> CheckNumerics<T> create(Scope scope, Operand<T> tensor, String message) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("CheckNumerics", scope.makeOpName("CheckNumerics"));
+    opBuilder.addInput(tensor.asOutput());
+    opBuilder.setAttr("message", message);
+    return new CheckNumerics<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private CheckNumerics(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/CholeskyGrad.java java-ops/org/tensorflow/op/core/CholeskyGrad.java
--- java/org/tensorflow/op/core/CholeskyGrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/CholeskyGrad.java	2018-10-16 20:18:38.209432397 +0900
@@ -0,0 +1,77 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the reverse mode backpropagated gradient of the Cholesky algorithm.
+ * <p>
+ * For an explanation see "Differentiation of the Cholesky algorithm" by
+ * Iain Murray http://arxiv.org/abs/1602.07527.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class CholeskyGrad<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new CholeskyGrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param l Output of batch Cholesky algorithm l = cholesky(A). Shape is `[..., M, M]`.
+   * Algorithm depends only on lower triangular part of the innermost matrices of
+   * this tensor.
+   * @param grad df/dl where f is some scalar function. Shape is `[..., M, M]`.
+   * Algorithm depends only on lower triangular part of the innermost matrices of
+   * this tensor.
+   * @return a new instance of CholeskyGrad
+   */
+  public static <T extends Number> CholeskyGrad<T> create(Scope scope, Operand<T> l, Operand<T> grad) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("CholeskyGrad", scope.makeOpName("CholeskyGrad"));
+    opBuilder.addInput(l.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    return new CholeskyGrad<T>(opBuilder.build());
+  }
+  
+  /**
+   * Symmetrized version of df/dA . Shape is `[..., M, M]`
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private CholeskyGrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Cholesky.java java-ops/org/tensorflow/op/core/Cholesky.java
--- java/org/tensorflow/op/core/Cholesky.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Cholesky.java	2018-10-16 20:18:38.209432397 +0900
@@ -0,0 +1,82 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the Cholesky decomposition of one or more square matrices.
+ * <p>
+ * The input is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions
+ * form square matrices.
+ * <p>
+ * The input has to be symmetric and positive definite. Only the lower-triangular
+ * part of the input will be used for this operation. The upper-triangular part
+ * will not be read.
+ * <p>
+ * The output is a tensor of the same shape as the input
+ * containing the Cholesky decompositions for all input submatrices `[..., :, :]`.
+ * <p>
+ * <b>Note</b>: The gradient computation on GPU is faster for large matrices but
+ * not for large batch dimensions when the submatrices are small. In this
+ * case it might be faster to use the CPU.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class Cholesky<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Cholesky operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input Shape is `[..., M, M]`.
+   * @return a new instance of Cholesky
+   */
+  public static <T> Cholesky<T> create(Scope scope, Operand<T> input) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Cholesky", scope.makeOpName("Cholesky"));
+    opBuilder.addInput(input.asOutput());
+    return new Cholesky<T>(opBuilder.build());
+  }
+  
+  /**
+   * Shape is `[..., M, M]`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private Cholesky(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ClipByValue.java java-ops/org/tensorflow/op/core/ClipByValue.java
--- java/org/tensorflow/op/core/ClipByValue.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ClipByValue.java	2018-10-16 20:18:38.210432396 +0900
@@ -0,0 +1,79 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Clips tensor values to a specified min and max.
+ * <p>
+ * Given a tensor `t`, this operation returns a tensor of the same type and
+ * shape as `t` with its values clipped to `clip_value_min` and `clip_value_max`.
+ * Any values less than `clip_value_min` are set to `clip_value_min`. Any values
+ * greater than `clip_value_max` are set to `clip_value_max`.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class ClipByValue<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new ClipByValue operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param t A `Tensor`.
+   * @param clipValueMin A 0-D (scalar) `Tensor`, or a `Tensor` with the same shape
+   * as `t`. The minimum value to clip by.
+   * @param clipValueMax A 0-D (scalar) `Tensor`, or a `Tensor` with the same shape
+   * as `t`. The maximum value to clip by.
+   * @return a new instance of ClipByValue
+   */
+  public static <T> ClipByValue<T> create(Scope scope, Operand<T> t, Operand<T> clipValueMin, Operand<T> clipValueMax) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ClipByValue", scope.makeOpName("ClipByValue"));
+    opBuilder.addInput(t.asOutput());
+    opBuilder.addInput(clipValueMin.asOutput());
+    opBuilder.addInput(clipValueMax.asOutput());
+    return new ClipByValue<T>(opBuilder.build());
+  }
+  
+  /**
+   * A clipped `Tensor` with the same shape as input 't'.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private ClipByValue(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/CloseSummaryWriter.java java-ops/org/tensorflow/op/core/CloseSummaryWriter.java
--- java/org/tensorflow/op/core/CloseSummaryWriter.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/CloseSummaryWriter.java	2018-10-16 20:18:38.210432396 +0900
@@ -0,0 +1,47 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ */
+public final class CloseSummaryWriter extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new CloseSummaryWriter operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param writer 
+   * @return a new instance of CloseSummaryWriter
+   */
+  public static CloseSummaryWriter create(Scope scope, Operand<?> writer) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("CloseSummaryWriter", scope.makeOpName("CloseSummaryWriter"));
+    opBuilder.addInput(writer.asOutput());
+    return new CloseSummaryWriter(opBuilder.build());
+  }
+  
+  
+  private CloseSummaryWriter(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/CollectiveBcastRecv.java java-ops/org/tensorflow/op/core/CollectiveBcastRecv.java
--- java/org/tensorflow/op/core/CollectiveBcastRecv.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/CollectiveBcastRecv.java	2018-10-16 20:18:38.210432396 +0900
@@ -0,0 +1,75 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Receives a tensor value broadcast from another device.
+ * 
+ * @param <T> data type for {@code data()} output
+ */
+public final class CollectiveBcastRecv<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new CollectiveBcastRecv operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param T 
+   * @param groupSize 
+   * @param groupKey 
+   * @param instanceKey 
+   * @param shape 
+   * @return a new instance of CollectiveBcastRecv
+   */
+  public static <T extends Number> CollectiveBcastRecv<T> create(Scope scope, Class<T> T, Long groupSize, Long groupKey, Long instanceKey, Shape shape) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("CollectiveBcastRecv", scope.makeOpName("CollectiveBcastRecv"));
+    opBuilder.setAttr("T", DataType.fromClass(T));
+    opBuilder.setAttr("group_size", groupSize);
+    opBuilder.setAttr("group_key", groupKey);
+    opBuilder.setAttr("instance_key", instanceKey);
+    opBuilder.setAttr("shape", shape);
+    return new CollectiveBcastRecv<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> data() {
+    return data;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return data;
+  }
+  
+  private Output<T> data;
+  
+  private CollectiveBcastRecv(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    data = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/CollectiveBcastSend.java java-ops/org/tensorflow/op/core/CollectiveBcastSend.java
--- java/org/tensorflow/op/core/CollectiveBcastSend.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/CollectiveBcastSend.java	2018-10-16 20:18:38.211432395 +0900
@@ -0,0 +1,74 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Broadcasts a tensor value to one or more other devices.
+ * 
+ * @param <T> data type for {@code data()} output
+ */
+public final class CollectiveBcastSend<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new CollectiveBcastSend operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param groupSize 
+   * @param groupKey 
+   * @param instanceKey 
+   * @param shape 
+   * @return a new instance of CollectiveBcastSend
+   */
+  public static <T extends Number> CollectiveBcastSend<T> create(Scope scope, Operand<T> input, Long groupSize, Long groupKey, Long instanceKey, Shape shape) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("CollectiveBcastSend", scope.makeOpName("CollectiveBcastSend"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.setAttr("group_size", groupSize);
+    opBuilder.setAttr("group_key", groupKey);
+    opBuilder.setAttr("instance_key", instanceKey);
+    opBuilder.setAttr("shape", shape);
+    return new CollectiveBcastSend<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> data() {
+    return data;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return data;
+  }
+  
+  private Output<T> data;
+  
+  private CollectiveBcastSend(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    data = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/CollectiveReduce.java java-ops/org/tensorflow/op/core/CollectiveReduce.java
--- java/org/tensorflow/op/core/CollectiveReduce.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/CollectiveReduce.java	2018-10-16 20:18:38.211432395 +0900
@@ -0,0 +1,82 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Mutually reduces multiple tensors of identical type and shape.
+ * 
+ * @param <T> data type for {@code data()} output
+ */
+public final class CollectiveReduce<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new CollectiveReduce operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param groupSize 
+   * @param groupKey 
+   * @param instanceKey 
+   * @param mergeOp 
+   * @param finalOp 
+   * @param subdivOffsets 
+   * @return a new instance of CollectiveReduce
+   */
+  public static <T extends Number> CollectiveReduce<T> create(Scope scope, Operand<T> input, Long groupSize, Long groupKey, Long instanceKey, String mergeOp, String finalOp, List<Long> subdivOffsets) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("CollectiveReduce", scope.makeOpName("CollectiveReduce"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.setAttr("group_size", groupSize);
+    opBuilder.setAttr("group_key", groupKey);
+    opBuilder.setAttr("instance_key", instanceKey);
+    opBuilder.setAttr("merge_op", mergeOp);
+    opBuilder.setAttr("final_op", finalOp);
+    long[] subdivOffsetsArray = new long[subdivOffsets.size()];
+    for (int i = 0; i < subdivOffsetsArray.length; ++i) {
+      subdivOffsetsArray[i] = subdivOffsets.get(i);
+    }
+    opBuilder.setAttr("subdiv_offsets", subdivOffsetsArray);
+    return new CollectiveReduce<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> data() {
+    return data;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return data;
+  }
+  
+  private Output<T> data;
+  
+  private CollectiveReduce(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    data = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/CompareAndBitpack.java java-ops/org/tensorflow/op/core/CompareAndBitpack.java
--- java/org/tensorflow/op/core/CompareAndBitpack.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/CompareAndBitpack.java	2018-10-16 20:18:38.211432395 +0900
@@ -0,0 +1,91 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+import org.tensorflow.types.UInt8;
+
+/**
+ * Compare values of `input` to `threshold` and pack resulting bits into a `uint8`.
+ * <p>
+ * Each comparison returns a boolean `true` (if `input_value > threshold`)
+ * or and `false` otherwise.
+ * <p>
+ * This operation is useful for Locality-Sensitive-Hashing (LSH) and other
+ * algorithms that use hashing approximations of cosine and `L2` distances;
+ * codes can be generated from an input via:
+ * <pre>{@code
+ * codebook_size = 50
+ * codebook_bits = codebook_size * 32
+ * codebook = tf.get_variable('codebook', [x.shape[-1].value, codebook_bits],
+ *                            dtype=x.dtype,
+ *                            initializer=tf.orthogonal_initializer())
+ * codes = compare_and_threshold(tf.matmul(x, codebook), threshold=0.)
+ * codes = tf.bitcast(codes, tf.int32)  # go from uint8 to int32
+ * # now codes has shape x.shape[:-1] + [codebook_size]
+ * }</pre>
+ * <b>NOTE</b>: Currently, the innermost dimension of the tensor must be divisible
+ * by 8.
+ * <p>
+ * Given an `input` shaped `[s0, s1, ..., s_n]`, the output is
+ * a `uint8` tensor shaped `[s0, s1, ..., s_n / 8]`.
+ */
+@Operator
+public final class CompareAndBitpack extends PrimitiveOp implements Operand<UInt8> {
+  
+  /**
+   * Factory method to create a class to wrap a new CompareAndBitpack operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input Values to compare against `threshold` and bitpack.
+   * @param threshold Threshold to compare against.
+   * @return a new instance of CompareAndBitpack
+   */
+  public static <T> CompareAndBitpack create(Scope scope, Operand<T> input, Operand<T> threshold) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("CompareAndBitpack", scope.makeOpName("CompareAndBitpack"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(threshold.asOutput());
+    return new CompareAndBitpack(opBuilder.build());
+  }
+  
+  /**
+   * The bitpacked comparisons.
+   */
+  public Output<UInt8> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<UInt8> asOutput() {
+    return output;
+  }
+  
+  private Output<UInt8> output;
+  
+  private CompareAndBitpack(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ComplexAbs.java java-ops/org/tensorflow/op/core/ComplexAbs.java
--- java/org/tensorflow/op/core/ComplexAbs.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ComplexAbs.java	2018-10-16 20:18:38.212432395 +0900
@@ -0,0 +1,86 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the complex absolute value of a tensor.
+ * <p>
+ * Given a tensor `x` of complex numbers, this operation returns a tensor of type
+ * `float` or `double` that is the absolute value of each element in `x`. All
+ * elements in `x` must be complex numbers of the form \\(a + bj\\). The absolute
+ * value is computed as \\( \sqrt{a^2 + b^2}\\).
+ * 
+ * @param <U> data type for {@code y()} output
+ */
+@Operator
+public final class ComplexAbs<U extends Number> extends PrimitiveOp implements Operand<U> {
+  
+  /**
+   * Factory method to create a class to wrap a new ComplexAbs operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param Tout 
+   * @return a new instance of ComplexAbs
+   */
+  public static <U extends Number, T> ComplexAbs<U> create(Scope scope, Operand<T> x, Class<U> Tout) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ComplexAbs", scope.makeOpName("ComplexAbs"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.setAttr("Tout", DataType.fromClass(Tout));
+    return new ComplexAbs<U>(opBuilder.build());
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ComplexAbs operation to the graph, using default output types.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of ComplexAbs
+   */
+  public static <T> ComplexAbs<Float> create(Scope scope, Operand<T> x) {
+    return create(scope, x, Float.class);
+  }
+  
+  /**
+   */
+  public Output<U> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<U> asOutput() {
+    return y;
+  }
+  
+  private Output<U> y;
+  
+  private ComplexAbs(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Complex.java java-ops/org/tensorflow/op/core/Complex.java
--- java/org/tensorflow/op/core/Complex.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Complex.java	2018-10-16 20:18:38.212432395 +0900
@@ -0,0 +1,87 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Converts two real numbers to a complex number.
+ * <p>
+ * Given a tensor `real` representing the real part of a complex number, and a
+ * tensor `imag` representing the imaginary part of a complex number, this
+ * operation returns complex numbers elementwise of the form \\(a + bj\\), where
+ * <i>a</i> represents the `real` part and <i>b</i> represents the `imag` part.
+ * <p>
+ * The input tensors `real` and `imag` must have the same shape.
+ * <p>
+ * For example:
+ * <pre>{@code
+ * # tensor 'real' is [2.25, 3.25]
+ * # tensor `imag` is [4.75, 5.75]
+ * tf.complex(real, imag) ==> [[2.25 + 4.75j], [3.25 + 5.75j]]
+ * }</pre>
+ * 
+ * 
+ * @param <U> data type for {@code out()} output
+ */
+@Operator
+public final class Complex<U> extends PrimitiveOp implements Operand<U> {
+  
+  /**
+   * Factory method to create a class to wrap a new Complex operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param real 
+   * @param imag 
+   * @param Tout 
+   * @return a new instance of Complex
+   */
+  public static <U, T extends Number> Complex<U> create(Scope scope, Operand<T> real, Operand<T> imag, Class<U> Tout) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Complex", scope.makeOpName("Complex"));
+    opBuilder.addInput(real.asOutput());
+    opBuilder.addInput(imag.asOutput());
+    opBuilder.setAttr("Tout", DataType.fromClass(Tout));
+    return new Complex<U>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<U> out() {
+    return out;
+  }
+  
+  @Override
+  public Output<U> asOutput() {
+    return out;
+  }
+  
+  private Output<U> out;
+  
+  private Complex(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    out = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ComputeAccidentalHits.java java-ops/org/tensorflow/op/core/ComputeAccidentalHits.java
--- java/org/tensorflow/op/core/ComputeAccidentalHits.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ComputeAccidentalHits.java	2018-10-16 20:18:38.213432394 +0900
@@ -0,0 +1,147 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the ids of the positions in sampled_candidates that match true_labels.
+ * <p>
+ * When doing log-odds NCE, the result of this op should be passed through a
+ * SparseToDense op, then added to the logits of the sampled candidates. This has
+ * the effect of 'removing' the sampled labels that match the true labels by
+ * making the classifier sure that they are sampled labels.
+ */
+@Operator
+public final class ComputeAccidentalHits extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ComputeAccidentalHits}
+   */
+  public static class Options {
+    
+    /**
+     * @param seed If either seed or seed2 are set to be non-zero, the random number
+     * generator is seeded by the given seed.  Otherwise, it is seeded by a
+     * random seed.
+     */
+    public Options seed(Long seed) {
+      this.seed = seed;
+      return this;
+    }
+    
+    /**
+     * @param seed2 An second seed to avoid seed collision.
+     */
+    public Options seed2(Long seed2) {
+      this.seed2 = seed2;
+      return this;
+    }
+    
+    private Long seed;
+    private Long seed2;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ComputeAccidentalHits operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param trueClasses The true_classes output of UnpackSparseLabels.
+   * @param sampledCandidates The sampled_candidates output of CandidateSampler.
+   * @param numTrue Number of true labels per context.
+   * @param options carries optional attributes values
+   * @return a new instance of ComputeAccidentalHits
+   */
+  public static ComputeAccidentalHits create(Scope scope, Operand<Long> trueClasses, Operand<Long> sampledCandidates, Long numTrue, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ComputeAccidentalHits", scope.makeOpName("ComputeAccidentalHits"));
+    opBuilder.addInput(trueClasses.asOutput());
+    opBuilder.addInput(sampledCandidates.asOutput());
+    opBuilder.setAttr("num_true", numTrue);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.seed != null) {
+          opBuilder.setAttr("seed", opts.seed);
+        }
+        if (opts.seed2 != null) {
+          opBuilder.setAttr("seed2", opts.seed2);
+        }
+      }
+    }
+    return new ComputeAccidentalHits(opBuilder.build());
+  }
+  
+  /**
+   * @param seed If either seed or seed2 are set to be non-zero, the random number
+   * generator is seeded by the given seed.  Otherwise, it is seeded by a
+   * random seed.
+   */
+  public static Options seed(Long seed) {
+    return new Options().seed(seed);
+  }
+  
+  /**
+   * @param seed2 An second seed to avoid seed collision.
+   */
+  public static Options seed2(Long seed2) {
+    return new Options().seed2(seed2);
+  }
+  
+  /**
+   * A vector of indices corresponding to rows of true_candidates.
+   */
+  public Output<Integer> indices() {
+    return indices;
+  }
+  
+  /**
+   * A vector of IDs of positions in sampled_candidates that match a true_label
+   * for the row with the corresponding index in indices.
+   */
+  public Output<Long> ids() {
+    return ids;
+  }
+  
+  /**
+   * A vector of the same length as indices and ids, in which each element
+   * is -FLOAT_MAX.
+   */
+  public Output<Float> weights() {
+    return weights;
+  }
+  
+  private Output<Integer> indices;
+  private Output<Long> ids;
+  private Output<Float> weights;
+  
+  private ComputeAccidentalHits(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    indices = operation.output(outputIdx++);
+    ids = operation.output(outputIdx++);
+    weights = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ConcatenateDataset.java java-ops/org/tensorflow/op/core/ConcatenateDataset.java
--- java/org/tensorflow/op/core/ConcatenateDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ConcatenateDataset.java	2018-10-16 20:18:38.214432393 +0900
@@ -0,0 +1,83 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Creates a dataset that concatenates `input_dataset` with `another_dataset`.
+ */
+@Operator
+public final class ConcatenateDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new ConcatenateDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputDataset 
+   * @param anotherDataset 
+   * @param outputTypes 
+   * @param outputShapes 
+   * @return a new instance of ConcatenateDataset
+   */
+  public static ConcatenateDataset create(Scope scope, Operand<?> inputDataset, Operand<?> anotherDataset, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ConcatenateDataset", scope.makeOpName("ConcatenateDataset"));
+    opBuilder.addInput(inputDataset.asOutput());
+    opBuilder.addInput(anotherDataset.asOutput());
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new ConcatenateDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private ConcatenateDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Concat.java java-ops/org/tensorflow/op/core/Concat.java
--- java/org/tensorflow/op/core/Concat.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Concat.java	2018-10-16 20:18:38.213432394 +0900
@@ -0,0 +1,74 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Concatenates tensors along one dimension.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class Concat<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Concat operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param values List of `N` Tensors to concatenate. Their ranks and types must match,
+   * and their sizes must match in all dimensions except `concat_dim`.
+   * @param axis 0-D.  The dimension along which to concatenate.  Must be in the
+   * range [-rank(values), rank(values)).
+   * @return a new instance of Concat
+   */
+  public static <T, U extends Number> Concat<T> create(Scope scope, Operand<T> values, Operand<U> axis) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ConcatV2", scope.makeOpName("Concat"));
+    opBuilder.addInput(values.asOutput());
+    opBuilder.addInput(axis.asOutput());
+    return new Concat<T>(opBuilder.build());
+  }
+  
+  /**
+   * A `Tensor` with the concatenation of values stacked along the
+   * `concat_dim` dimension.  This tensor's shape matches that of `values` except
+   * in `concat_dim` where it has the sum of the sizes.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private Concat(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ConditionalAccumulator.java java-ops/org/tensorflow/op/core/ConditionalAccumulator.java
--- java/org/tensorflow/op/core/ConditionalAccumulator.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ConditionalAccumulator.java	2018-10-16 20:18:38.214432393 +0900
@@ -0,0 +1,153 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * A conditional accumulator for aggregating gradients.
+ * <p>
+ * The accumulator accepts gradients marked with local_step greater or
+ * equal to the most recent global_step known to the accumulator. The
+ * average can be extracted from the accumulator, provided sufficient
+ * gradients have been accumulated. Extracting the average automatically
+ * resets the aggregate to 0, and increments the global_step recorded by
+ * the accumulator.
+ */
+@Operator
+public final class ConditionalAccumulator extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ConditionalAccumulator}
+   */
+  public static class Options {
+    
+    /**
+     * @param container If non-empty, this accumulator is placed in the given container.
+     * Otherwise, a default container is used.
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName If non-empty, this accumulator will be shared under the
+     * given name across multiple sessions.
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    /**
+     * @param reductionType 
+     */
+    public Options reductionType(String reductionType) {
+      this.reductionType = reductionType;
+      return this;
+    }
+    
+    private String container;
+    private String sharedName;
+    private String reductionType;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ConditionalAccumulator operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param dtype The type of the value being accumulated.
+   * @param shape The shape of the values, can be [], in which case shape is unknown.
+   * @param options carries optional attributes values
+   * @return a new instance of ConditionalAccumulator
+   */
+  public static <T> ConditionalAccumulator create(Scope scope, Class<T> dtype, Shape shape, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ConditionalAccumulator", scope.makeOpName("ConditionalAccumulator"));
+    opBuilder.setAttr("dtype", DataType.fromClass(dtype));
+    opBuilder.setAttr("shape", shape);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+        if (opts.reductionType != null) {
+          opBuilder.setAttr("reduction_type", opts.reductionType);
+        }
+      }
+    }
+    return new ConditionalAccumulator(opBuilder.build());
+  }
+  
+  /**
+   * @param container If non-empty, this accumulator is placed in the given container.
+   * Otherwise, a default container is used.
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName If non-empty, this accumulator will be shared under the
+   * given name across multiple sessions.
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   * @param reductionType 
+   */
+  public static Options reductionType(String reductionType) {
+    return new Options().reductionType(reductionType);
+  }
+  
+  /**
+   * The handle to the accumulator.
+   */
+  public Output<String> handle() {
+    return handle;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return handle;
+  }
+  
+  private Output<String> handle;
+  
+  private ConditionalAccumulator(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Conj.java java-ops/org/tensorflow/op/core/Conj.java
--- java/org/tensorflow/op/core/Conj.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Conj.java	2018-10-16 20:18:38.214432393 +0900
@@ -0,0 +1,81 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns the complex conjugate of a complex number.
+ * <p>
+ * Given a tensor `input` of complex numbers, this operation returns a tensor of
+ * complex numbers that are the complex conjugate of each element in `input`. The
+ * complex numbers in `input` must be of the form \\(a + bj\\), where <i>a</i> is the
+ * real part and <i>b</i> is the imaginary part.
+ * <p>
+ * The complex conjugate returned by this operation is of the form \\(a - bj\\).
+ * <p>
+ * For example:
+ * <pre>{@code
+ * # tensor 'input' is [-2.25 + 4.75j, 3.25 + 5.75j]
+ * tf.conj(input) ==> [-2.25 - 4.75j, 3.25 - 5.75j]
+ * }</pre>
+ * 
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class Conj<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Conj operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @return a new instance of Conj
+   */
+  public static <T> Conj<T> create(Scope scope, Operand<T> input) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Conj", scope.makeOpName("Conj"));
+    opBuilder.addInput(input.asOutput());
+    return new Conj<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private Conj(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ConjugateTranspose.java java-ops/org/tensorflow/op/core/ConjugateTranspose.java
--- java/org/tensorflow/op/core/ConjugateTranspose.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ConjugateTranspose.java	2018-10-16 20:18:38.215432392 +0900
@@ -0,0 +1,73 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Shuffle dimensions of x according to a permutation and conjugate the result.
+ * <p>
+ * The output `y` has the same rank as `x`. The shapes of `x` and `y` satisfy:
+ *   `y.shape[i] == x.shape[perm[i]] for i in [0, 1, ..., rank(x) - 1]`
+ *   `y[i,j,k,...,s,t,u] == conj(x[perm[i], perm[j], perm[k],...,perm[s], perm[t], perm[u]])`
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class ConjugateTranspose<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new ConjugateTranspose operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param perm 
+   * @return a new instance of ConjugateTranspose
+   */
+  public static <T, U extends Number> ConjugateTranspose<T> create(Scope scope, Operand<T> x, Operand<U> perm) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ConjugateTranspose", scope.makeOpName("ConjugateTranspose"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(perm.asOutput());
+    return new ConjugateTranspose<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private ConjugateTranspose(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Const.java java-ops/org/tensorflow/op/core/Const.java
--- java/org/tensorflow/op/core/Const.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Const.java	2018-10-16 20:18:38.215432392 +0900
@@ -0,0 +1,69 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Tensor;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Returns a constant tensor.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+public final class Const<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Const operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param value Attr `value` is the tensor to return.
+   * @param dtype 
+   * @return a new instance of Const
+   */
+  public static <T> Const<T> create(Scope scope, Tensor<?> value, Class<T> dtype) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Const", scope.makeOpName("Const"));
+    opBuilder.setAttr("value", value);
+    opBuilder.setAttr("dtype", DataType.fromClass(dtype));
+    return new Const<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private Const(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ConsumeMutexLock.java java-ops/org/tensorflow/op/core/ConsumeMutexLock.java
--- java/org/tensorflow/op/core/ConsumeMutexLock.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ConsumeMutexLock.java	2018-10-16 20:18:38.216432392 +0900
@@ -0,0 +1,58 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * This op consumes a lock created by `MutexLock`.
+ * <p>
+ * This op exists to consume a tensor created by `MutexLock` (other than
+ * direct control dependencies).  It should be the only that consumes the tensor,
+ * and will raise an error if it is not.  Its only purpose is to keep the
+ * mutex lock tensor alive until it is consumed by this op.
+ * <p>
+ * <b>NOTE</b>: This operation must run on the same device as its input.  This may
+ * be enforced via the `colocate_with` mechanism.
+ */
+@Operator
+public final class ConsumeMutexLock extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new ConsumeMutexLock operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param mutexLock A tensor returned by `MutexLock`.
+   * @return a new instance of ConsumeMutexLock
+   */
+  public static ConsumeMutexLock create(Scope scope, Operand<?> mutexLock) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ConsumeMutexLock", scope.makeOpName("ConsumeMutexLock"));
+    opBuilder.addInput(mutexLock.asOutput());
+    return new ConsumeMutexLock(opBuilder.build());
+  }
+  
+  
+  private ConsumeMutexLock(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ControlTrigger.java java-ops/org/tensorflow/op/core/ControlTrigger.java
--- java/org/tensorflow/op/core/ControlTrigger.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ControlTrigger.java	2018-10-16 20:18:38.216432392 +0900
@@ -0,0 +1,49 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Does nothing. Serves as a control trigger for scheduling.
+ * <p>
+ * Only useful as a placeholder for control edges.
+ */
+@Operator
+public final class ControlTrigger extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new ControlTrigger operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @return a new instance of ControlTrigger
+   */
+  public static ControlTrigger create(Scope scope) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ControlTrigger", scope.makeOpName("ControlTrigger"));
+    return new ControlTrigger(opBuilder.build());
+  }
+  
+  
+  private ControlTrigger(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Conv2DBackpropFilter.java java-ops/org/tensorflow/op/core/Conv2DBackpropFilter.java
--- java/org/tensorflow/op/core/Conv2DBackpropFilter.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Conv2DBackpropFilter.java	2018-10-16 20:18:38.218432390 +0900
@@ -0,0 +1,180 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the gradients of convolution with respect to the filter.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class Conv2DBackpropFilter<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Conv2DBackpropFilter}
+   */
+  public static class Options {
+    
+    /**
+     * @param useCudnnOnGpu 
+     */
+    public Options useCudnnOnGpu(Boolean useCudnnOnGpu) {
+      this.useCudnnOnGpu = useCudnnOnGpu;
+      return this;
+    }
+    
+    /**
+     * @param dataFormat Specify the data format of the input and output data. With the
+     * default format "NHWC", the data is stored in the order of:
+     *     [batch, in_height, in_width, in_channels].
+     * Alternatively, the format could be "NCHW", the data storage order of:
+     *     [batch, in_channels, in_height, in_width].
+     */
+    public Options dataFormat(String dataFormat) {
+      this.dataFormat = dataFormat;
+      return this;
+    }
+    
+    /**
+     * @param dilations 1-D tensor of length 4.  The dilation factor for each dimension of
+     * `input`. If set to k > 1, there will be k-1 skipped cells between each filter
+     * element on that dimension. The dimension order is determined by the value of
+     * `data_format`, see above for details. Dilations in the batch and depth
+     * dimensions must be 1.
+     */
+    public Options dilations(List<Long> dilations) {
+      this.dilations = dilations;
+      return this;
+    }
+    
+    private Boolean useCudnnOnGpu;
+    private String dataFormat;
+    private List<Long> dilations;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Conv2DBackpropFilter operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 4-D with shape `[batch, in_height, in_width, in_channels]`.
+   * @param filterSizes An integer vector representing the tensor shape of `filter`,
+   * where `filter` is a 4-D
+   * `[filter_height, filter_width, in_channels, out_channels]` tensor.
+   * @param outBackprop 4-D with shape `[batch, out_height, out_width, out_channels]`.
+   * Gradients w.r.t. the output of the convolution.
+   * @param strides The stride of the sliding window for each dimension of the input
+   * of the convolution. Must be in the same order as the dimension specified with
+   * format.
+   * @param padding The type of padding algorithm to use.
+   * @param options carries optional attributes values
+   * @return a new instance of Conv2DBackpropFilter
+   */
+  public static <T extends Number> Conv2DBackpropFilter<T> create(Scope scope, Operand<T> input, Operand<Integer> filterSizes, Operand<T> outBackprop, List<Long> strides, String padding, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Conv2DBackpropFilter", scope.makeOpName("Conv2DBackpropFilter"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(filterSizes.asOutput());
+    opBuilder.addInput(outBackprop.asOutput());
+    long[] stridesArray = new long[strides.size()];
+    for (int i = 0; i < stridesArray.length; ++i) {
+      stridesArray[i] = strides.get(i);
+    }
+    opBuilder.setAttr("strides", stridesArray);
+    opBuilder.setAttr("padding", padding);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useCudnnOnGpu != null) {
+          opBuilder.setAttr("use_cudnn_on_gpu", opts.useCudnnOnGpu);
+        }
+        if (opts.dataFormat != null) {
+          opBuilder.setAttr("data_format", opts.dataFormat);
+        }
+        if (opts.dilations != null) {
+          long[] dilationsArray = new long[opts.dilations.size()];
+          for (int i = 0; i < dilationsArray.length; ++i) {
+            dilationsArray[i] = opts.dilations.get(i);
+          }
+          opBuilder.setAttr("dilations", dilationsArray);
+        }
+      }
+    }
+    return new Conv2DBackpropFilter<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useCudnnOnGpu 
+   */
+  public static Options useCudnnOnGpu(Boolean useCudnnOnGpu) {
+    return new Options().useCudnnOnGpu(useCudnnOnGpu);
+  }
+  
+  /**
+   * @param dataFormat Specify the data format of the input and output data. With the
+   * default format "NHWC", the data is stored in the order of:
+   *     [batch, in_height, in_width, in_channels].
+   * Alternatively, the format could be "NCHW", the data storage order of:
+   *     [batch, in_channels, in_height, in_width].
+   */
+  public static Options dataFormat(String dataFormat) {
+    return new Options().dataFormat(dataFormat);
+  }
+  
+  /**
+   * @param dilations 1-D tensor of length 4.  The dilation factor for each dimension of
+   * `input`. If set to k > 1, there will be k-1 skipped cells between each filter
+   * element on that dimension. The dimension order is determined by the value of
+   * `data_format`, see above for details. Dilations in the batch and depth
+   * dimensions must be 1.
+   */
+  public static Options dilations(List<Long> dilations) {
+    return new Options().dilations(dilations);
+  }
+  
+  /**
+   * 4-D with shape
+   * `[filter_height, filter_width, in_channels, out_channels]`.  Gradient w.r.t.
+   * the `filter` input of the convolution.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private Conv2DBackpropFilter(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Conv2DBackpropInput.java java-ops/org/tensorflow/op/core/Conv2DBackpropInput.java
--- java/org/tensorflow/op/core/Conv2DBackpropInput.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Conv2DBackpropInput.java	2018-10-16 20:18:38.219432390 +0900
@@ -0,0 +1,179 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the gradients of convolution with respect to the input.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class Conv2DBackpropInput<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Conv2DBackpropInput}
+   */
+  public static class Options {
+    
+    /**
+     * @param useCudnnOnGpu 
+     */
+    public Options useCudnnOnGpu(Boolean useCudnnOnGpu) {
+      this.useCudnnOnGpu = useCudnnOnGpu;
+      return this;
+    }
+    
+    /**
+     * @param dataFormat Specify the data format of the input and output data. With the
+     * default format "NHWC", the data is stored in the order of:
+     *     [batch, in_height, in_width, in_channels].
+     * Alternatively, the format could be "NCHW", the data storage order of:
+     *     [batch, in_channels, in_height, in_width].
+     */
+    public Options dataFormat(String dataFormat) {
+      this.dataFormat = dataFormat;
+      return this;
+    }
+    
+    /**
+     * @param dilations 1-D tensor of length 4.  The dilation factor for each dimension of
+     * `input`. If set to k > 1, there will be k-1 skipped cells between each filter
+     * element on that dimension. The dimension order is determined by the value of
+     * `data_format`, see above for details. Dilations in the batch and depth
+     * dimensions must be 1.
+     */
+    public Options dilations(List<Long> dilations) {
+      this.dilations = dilations;
+      return this;
+    }
+    
+    private Boolean useCudnnOnGpu;
+    private String dataFormat;
+    private List<Long> dilations;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Conv2DBackpropInput operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputSizes An integer vector representing the shape of `input`,
+   * where `input` is a 4-D `[batch, height, width, channels]` tensor.
+   * @param filter 4-D with shape
+   * `[filter_height, filter_width, in_channels, out_channels]`.
+   * @param outBackprop 4-D with shape `[batch, out_height, out_width, out_channels]`.
+   * Gradients w.r.t. the output of the convolution.
+   * @param strides The stride of the sliding window for each dimension of the input
+   * of the convolution. Must be in the same order as the dimension specified with
+   * format.
+   * @param padding The type of padding algorithm to use.
+   * @param options carries optional attributes values
+   * @return a new instance of Conv2DBackpropInput
+   */
+  public static <T extends Number> Conv2DBackpropInput<T> create(Scope scope, Operand<Integer> inputSizes, Operand<T> filter, Operand<T> outBackprop, List<Long> strides, String padding, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Conv2DBackpropInput", scope.makeOpName("Conv2DBackpropInput"));
+    opBuilder.addInput(inputSizes.asOutput());
+    opBuilder.addInput(filter.asOutput());
+    opBuilder.addInput(outBackprop.asOutput());
+    long[] stridesArray = new long[strides.size()];
+    for (int i = 0; i < stridesArray.length; ++i) {
+      stridesArray[i] = strides.get(i);
+    }
+    opBuilder.setAttr("strides", stridesArray);
+    opBuilder.setAttr("padding", padding);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useCudnnOnGpu != null) {
+          opBuilder.setAttr("use_cudnn_on_gpu", opts.useCudnnOnGpu);
+        }
+        if (opts.dataFormat != null) {
+          opBuilder.setAttr("data_format", opts.dataFormat);
+        }
+        if (opts.dilations != null) {
+          long[] dilationsArray = new long[opts.dilations.size()];
+          for (int i = 0; i < dilationsArray.length; ++i) {
+            dilationsArray[i] = opts.dilations.get(i);
+          }
+          opBuilder.setAttr("dilations", dilationsArray);
+        }
+      }
+    }
+    return new Conv2DBackpropInput<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useCudnnOnGpu 
+   */
+  public static Options useCudnnOnGpu(Boolean useCudnnOnGpu) {
+    return new Options().useCudnnOnGpu(useCudnnOnGpu);
+  }
+  
+  /**
+   * @param dataFormat Specify the data format of the input and output data. With the
+   * default format "NHWC", the data is stored in the order of:
+   *     [batch, in_height, in_width, in_channels].
+   * Alternatively, the format could be "NCHW", the data storage order of:
+   *     [batch, in_channels, in_height, in_width].
+   */
+  public static Options dataFormat(String dataFormat) {
+    return new Options().dataFormat(dataFormat);
+  }
+  
+  /**
+   * @param dilations 1-D tensor of length 4.  The dilation factor for each dimension of
+   * `input`. If set to k > 1, there will be k-1 skipped cells between each filter
+   * element on that dimension. The dimension order is determined by the value of
+   * `data_format`, see above for details. Dilations in the batch and depth
+   * dimensions must be 1.
+   */
+  public static Options dilations(List<Long> dilations) {
+    return new Options().dilations(dilations);
+  }
+  
+  /**
+   * 4-D with shape `[batch, in_height, in_width, in_channels]`.  Gradient
+   * w.r.t. the input of the convolution.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private Conv2DBackpropInput(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Conv2D.java java-ops/org/tensorflow/op/core/Conv2D.java
--- java/org/tensorflow/op/core/Conv2D.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Conv2D.java	2018-10-16 20:18:38.217432391 +0900
@@ -0,0 +1,198 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes a 2-D convolution given 4-D `input` and `filter` tensors.
+ * <p>
+ * Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
+ * and a filter / kernel tensor of shape
+ * `[filter_height, filter_width, in_channels, out_channels]`, this op
+ * performs the following:
+ * <p>
+ * 1. Flattens the filter to a 2-D matrix with shape
+ *    `[filter_height * filter_width * in_channels, output_channels]`.
+ * 2. Extracts image patches from the input tensor to form a <i>virtual</i>
+ *    tensor of shape `[batch, out_height, out_width,
+ *    filter_height * filter_width * in_channels]`.
+ * 3. For each patch, right-multiplies the filter matrix and the image patch
+ *    vector.
+ * <p>
+ * In detail, with the default NHWC format,
+ * <p>
+ *     output[b, i, j, k] =
+ *         sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q] *
+ *                         filter[di, dj, q, k]
+ * <p>
+ * Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
+ * horizontal and vertices strides, `strides = [1, stride, stride, 1]`.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class Conv2D<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Conv2D}
+   */
+  public static class Options {
+    
+    /**
+     * @param useCudnnOnGpu 
+     */
+    public Options useCudnnOnGpu(Boolean useCudnnOnGpu) {
+      this.useCudnnOnGpu = useCudnnOnGpu;
+      return this;
+    }
+    
+    /**
+     * @param dataFormat Specify the data format of the input and output data. With the
+     * default format "NHWC", the data is stored in the order of:
+     *     [batch, height, width, channels].
+     * Alternatively, the format could be "NCHW", the data storage order of:
+     *     [batch, channels, height, width].
+     */
+    public Options dataFormat(String dataFormat) {
+      this.dataFormat = dataFormat;
+      return this;
+    }
+    
+    /**
+     * @param dilations 1-D tensor of length 4.  The dilation factor for each dimension of
+     * `input`. If set to k > 1, there will be k-1 skipped cells between each
+     * filter element on that dimension. The dimension order is determined by the
+     * value of `data_format`, see above for details. Dilations in the batch and
+     * depth dimensions must be 1.
+     */
+    public Options dilations(List<Long> dilations) {
+      this.dilations = dilations;
+      return this;
+    }
+    
+    private Boolean useCudnnOnGpu;
+    private String dataFormat;
+    private List<Long> dilations;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Conv2D operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input A 4-D tensor. The dimension order is interpreted according to the value
+   * of `data_format`, see below for details.
+   * @param filter A 4-D tensor of shape
+   * `[filter_height, filter_width, in_channels, out_channels]`
+   * @param strides 1-D tensor of length 4.  The stride of the sliding window for each
+   * dimension of `input`. The dimension order is determined by the value of
+   * `data_format`, see below for details.
+   * @param padding The type of padding algorithm to use.
+   * @param options carries optional attributes values
+   * @return a new instance of Conv2D
+   */
+  public static <T extends Number> Conv2D<T> create(Scope scope, Operand<T> input, Operand<T> filter, List<Long> strides, String padding, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Conv2D", scope.makeOpName("Conv2D"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(filter.asOutput());
+    long[] stridesArray = new long[strides.size()];
+    for (int i = 0; i < stridesArray.length; ++i) {
+      stridesArray[i] = strides.get(i);
+    }
+    opBuilder.setAttr("strides", stridesArray);
+    opBuilder.setAttr("padding", padding);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useCudnnOnGpu != null) {
+          opBuilder.setAttr("use_cudnn_on_gpu", opts.useCudnnOnGpu);
+        }
+        if (opts.dataFormat != null) {
+          opBuilder.setAttr("data_format", opts.dataFormat);
+        }
+        if (opts.dilations != null) {
+          long[] dilationsArray = new long[opts.dilations.size()];
+          for (int i = 0; i < dilationsArray.length; ++i) {
+            dilationsArray[i] = opts.dilations.get(i);
+          }
+          opBuilder.setAttr("dilations", dilationsArray);
+        }
+      }
+    }
+    return new Conv2D<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useCudnnOnGpu 
+   */
+  public static Options useCudnnOnGpu(Boolean useCudnnOnGpu) {
+    return new Options().useCudnnOnGpu(useCudnnOnGpu);
+  }
+  
+  /**
+   * @param dataFormat Specify the data format of the input and output data. With the
+   * default format "NHWC", the data is stored in the order of:
+   *     [batch, height, width, channels].
+   * Alternatively, the format could be "NCHW", the data storage order of:
+   *     [batch, channels, height, width].
+   */
+  public static Options dataFormat(String dataFormat) {
+    return new Options().dataFormat(dataFormat);
+  }
+  
+  /**
+   * @param dilations 1-D tensor of length 4.  The dilation factor for each dimension of
+   * `input`. If set to k > 1, there will be k-1 skipped cells between each
+   * filter element on that dimension. The dimension order is determined by the
+   * value of `data_format`, see above for details. Dilations in the batch and
+   * depth dimensions must be 1.
+   */
+  public static Options dilations(List<Long> dilations) {
+    return new Options().dilations(dilations);
+  }
+  
+  /**
+   * A 4-D tensor. The dimension order is determined by the value of
+   * `data_format`, see below for details.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private Conv2D(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Conv3DBackpropFilter.java java-ops/org/tensorflow/op/core/Conv3DBackpropFilter.java
--- java/org/tensorflow/op/core/Conv3DBackpropFilter.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Conv3DBackpropFilter.java	2018-10-16 20:18:38.221432388 +0900
@@ -0,0 +1,121 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the gradients of 3-D convolution with respect to the filter.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class Conv3DBackpropFilter<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Conv3DBackpropFilter}
+   */
+  public static class Options {
+    
+    /**
+     * @param dilations 
+     */
+    public Options dilations(List<Long> dilations) {
+      this.dilations = dilations;
+      return this;
+    }
+    
+    private List<Long> dilations;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Conv3DBackpropFilter operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input Shape `[batch, depth, rows, cols, in_channels]`.
+   * @param filter Shape `[depth, rows, cols, in_channels, out_channels]`.
+   * `in_channels` must match between `input` and `filter`.
+   * @param outBackprop Backprop signal of shape `[batch, out_depth, out_rows, out_cols,
+   * out_channels]`.
+   * @param strides 1-D tensor of length 5. The stride of the sliding window for each
+   * dimension of `input`. Must have `strides[0] = strides[4] = 1`.
+   * @param padding The type of padding algorithm to use.
+   * @param options carries optional attributes values
+   * @return a new instance of Conv3DBackpropFilter
+   */
+  public static <T extends Number> Conv3DBackpropFilter<T> create(Scope scope, Operand<T> input, Operand<T> filter, Operand<T> outBackprop, List<Long> strides, String padding, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Conv3DBackpropFilter", scope.makeOpName("Conv3DBackpropFilter"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(filter.asOutput());
+    opBuilder.addInput(outBackprop.asOutput());
+    long[] stridesArray = new long[strides.size()];
+    for (int i = 0; i < stridesArray.length; ++i) {
+      stridesArray[i] = strides.get(i);
+    }
+    opBuilder.setAttr("strides", stridesArray);
+    opBuilder.setAttr("padding", padding);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.dilations != null) {
+          long[] dilationsArray = new long[opts.dilations.size()];
+          for (int i = 0; i < dilationsArray.length; ++i) {
+            dilationsArray[i] = opts.dilations.get(i);
+          }
+          opBuilder.setAttr("dilations", dilationsArray);
+        }
+      }
+    }
+    return new Conv3DBackpropFilter<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param dilations 
+   */
+  public static Options dilations(List<Long> dilations) {
+    return new Options().dilations(dilations);
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private Conv3DBackpropFilter(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Conv3DBackpropFilterV2.java java-ops/org/tensorflow/op/core/Conv3DBackpropFilterV2.java
--- java/org/tensorflow/op/core/Conv3DBackpropFilterV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Conv3DBackpropFilterV2.java	2018-10-16 20:18:38.222432388 +0900
@@ -0,0 +1,158 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the gradients of 3-D convolution with respect to the filter.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class Conv3DBackpropFilterV2<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Conv3DBackpropFilterV2}
+   */
+  public static class Options {
+    
+    /**
+     * @param dataFormat The data format of the input and output data. With the
+     * default format "NDHWC", the data is stored in the order of:
+     *     [batch, in_depth, in_height, in_width, in_channels].
+     * Alternatively, the format could be "NCDHW", the data storage order is:
+     *     [batch, in_channels, in_depth, in_height, in_width].
+     */
+    public Options dataFormat(String dataFormat) {
+      this.dataFormat = dataFormat;
+      return this;
+    }
+    
+    /**
+     * @param dilations 1-D tensor of length 5.  The dilation factor for each dimension of
+     * `input`. If set to k > 1, there will be k-1 skipped cells between each
+     * filter element on that dimension. The dimension order is determined by the
+     * value of `data_format`, see above for details. Dilations in the batch and
+     * depth dimensions must be 1.
+     */
+    public Options dilations(List<Long> dilations) {
+      this.dilations = dilations;
+      return this;
+    }
+    
+    private String dataFormat;
+    private List<Long> dilations;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Conv3DBackpropFilterV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input Shape `[batch, depth, rows, cols, in_channels]`.
+   * @param filterSizes An integer vector representing the tensor shape of `filter`,
+   * where `filter` is a 5-D
+   * `[filter_depth, filter_height, filter_width, in_channels, out_channels]`
+   * tensor.
+   * @param outBackprop Backprop signal of shape `[batch, out_depth, out_rows, out_cols,
+   * out_channels]`.
+   * @param strides 1-D tensor of length 5. The stride of the sliding window for each
+   * dimension of `input`. Must have `strides[0] = strides[4] = 1`.
+   * @param padding The type of padding algorithm to use.
+   * @param options carries optional attributes values
+   * @return a new instance of Conv3DBackpropFilterV2
+   */
+  public static <T extends Number> Conv3DBackpropFilterV2<T> create(Scope scope, Operand<T> input, Operand<Integer> filterSizes, Operand<T> outBackprop, List<Long> strides, String padding, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Conv3DBackpropFilterV2", scope.makeOpName("Conv3DBackpropFilterV2"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(filterSizes.asOutput());
+    opBuilder.addInput(outBackprop.asOutput());
+    long[] stridesArray = new long[strides.size()];
+    for (int i = 0; i < stridesArray.length; ++i) {
+      stridesArray[i] = strides.get(i);
+    }
+    opBuilder.setAttr("strides", stridesArray);
+    opBuilder.setAttr("padding", padding);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.dataFormat != null) {
+          opBuilder.setAttr("data_format", opts.dataFormat);
+        }
+        if (opts.dilations != null) {
+          long[] dilationsArray = new long[opts.dilations.size()];
+          for (int i = 0; i < dilationsArray.length; ++i) {
+            dilationsArray[i] = opts.dilations.get(i);
+          }
+          opBuilder.setAttr("dilations", dilationsArray);
+        }
+      }
+    }
+    return new Conv3DBackpropFilterV2<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param dataFormat The data format of the input and output data. With the
+   * default format "NDHWC", the data is stored in the order of:
+   *     [batch, in_depth, in_height, in_width, in_channels].
+   * Alternatively, the format could be "NCDHW", the data storage order is:
+   *     [batch, in_channels, in_depth, in_height, in_width].
+   */
+  public static Options dataFormat(String dataFormat) {
+    return new Options().dataFormat(dataFormat);
+  }
+  
+  /**
+   * @param dilations 1-D tensor of length 5.  The dilation factor for each dimension of
+   * `input`. If set to k > 1, there will be k-1 skipped cells between each
+   * filter element on that dimension. The dimension order is determined by the
+   * value of `data_format`, see above for details. Dilations in the batch and
+   * depth dimensions must be 1.
+   */
+  public static Options dilations(List<Long> dilations) {
+    return new Options().dilations(dilations);
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private Conv3DBackpropFilterV2(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Conv3DBackpropInput.java java-ops/org/tensorflow/op/core/Conv3DBackpropInput.java
--- java/org/tensorflow/op/core/Conv3DBackpropInput.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Conv3DBackpropInput.java	2018-10-16 20:18:38.222432388 +0900
@@ -0,0 +1,121 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the gradients of 3-D convolution with respect to the input.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class Conv3DBackpropInput<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Conv3DBackpropInput}
+   */
+  public static class Options {
+    
+    /**
+     * @param dilations 
+     */
+    public Options dilations(List<Long> dilations) {
+      this.dilations = dilations;
+      return this;
+    }
+    
+    private List<Long> dilations;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Conv3DBackpropInput operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input Shape `[batch, depth, rows, cols, in_channels]`.
+   * @param filter Shape `[depth, rows, cols, in_channels, out_channels]`.
+   * `in_channels` must match between `input` and `filter`.
+   * @param outBackprop Backprop signal of shape `[batch, out_depth, out_rows, out_cols,
+   * out_channels]`.
+   * @param strides 1-D tensor of length 5. The stride of the sliding window for each
+   * dimension of `input`. Must have `strides[0] = strides[4] = 1`.
+   * @param padding The type of padding algorithm to use.
+   * @param options carries optional attributes values
+   * @return a new instance of Conv3DBackpropInput
+   */
+  public static <T extends Number> Conv3DBackpropInput<T> create(Scope scope, Operand<T> input, Operand<T> filter, Operand<T> outBackprop, List<Long> strides, String padding, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Conv3DBackpropInput", scope.makeOpName("Conv3DBackpropInput"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(filter.asOutput());
+    opBuilder.addInput(outBackprop.asOutput());
+    long[] stridesArray = new long[strides.size()];
+    for (int i = 0; i < stridesArray.length; ++i) {
+      stridesArray[i] = strides.get(i);
+    }
+    opBuilder.setAttr("strides", stridesArray);
+    opBuilder.setAttr("padding", padding);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.dilations != null) {
+          long[] dilationsArray = new long[opts.dilations.size()];
+          for (int i = 0; i < dilationsArray.length; ++i) {
+            dilationsArray[i] = opts.dilations.get(i);
+          }
+          opBuilder.setAttr("dilations", dilationsArray);
+        }
+      }
+    }
+    return new Conv3DBackpropInput<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param dilations 
+   */
+  public static Options dilations(List<Long> dilations) {
+    return new Options().dilations(dilations);
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private Conv3DBackpropInput(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Conv3DBackpropInputV2.java java-ops/org/tensorflow/op/core/Conv3DBackpropInputV2.java
--- java/org/tensorflow/op/core/Conv3DBackpropInputV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Conv3DBackpropInputV2.java	2018-10-16 20:18:38.225432386 +0900
@@ -0,0 +1,158 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the gradients of 3-D convolution with respect to the input.
+ * 
+ * @param <U> data type for {@code output()} output
+ */
+@Operator
+public final class Conv3DBackpropInputV2<U extends Number> extends PrimitiveOp implements Operand<U> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Conv3DBackpropInputV2}
+   */
+  public static class Options {
+    
+    /**
+     * @param dataFormat The data format of the input and output data. With the
+     * default format "NDHWC", the data is stored in the order of:
+     *     [batch, in_depth, in_height, in_width, in_channels].
+     * Alternatively, the format could be "NCDHW", the data storage order is:
+     *     [batch, in_channels, in_depth, in_height, in_width].
+     */
+    public Options dataFormat(String dataFormat) {
+      this.dataFormat = dataFormat;
+      return this;
+    }
+    
+    /**
+     * @param dilations 1-D tensor of length 5.  The dilation factor for each dimension of
+     * `input`. If set to k > 1, there will be k-1 skipped cells between each
+     * filter element on that dimension. The dimension order is determined by the
+     * value of `data_format`, see above for details. Dilations in the batch and
+     * depth dimensions must be 1.
+     */
+    public Options dilations(List<Long> dilations) {
+      this.dilations = dilations;
+      return this;
+    }
+    
+    private String dataFormat;
+    private List<Long> dilations;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Conv3DBackpropInputV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputSizes An integer vector representing the tensor shape of `input`,
+   * where `input` is a 5-D
+   * `[batch, depth, rows, cols, in_channels]` tensor.
+   * @param filter Shape `[depth, rows, cols, in_channels, out_channels]`.
+   * `in_channels` must match between `input` and `filter`.
+   * @param outBackprop Backprop signal of shape `[batch, out_depth, out_rows, out_cols,
+   * out_channels]`.
+   * @param strides 1-D tensor of length 5. The stride of the sliding window for each
+   * dimension of `input`. Must have `strides[0] = strides[4] = 1`.
+   * @param padding The type of padding algorithm to use.
+   * @param options carries optional attributes values
+   * @return a new instance of Conv3DBackpropInputV2
+   */
+  public static <U extends Number, T extends Number> Conv3DBackpropInputV2<U> create(Scope scope, Operand<T> inputSizes, Operand<U> filter, Operand<U> outBackprop, List<Long> strides, String padding, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Conv3DBackpropInputV2", scope.makeOpName("Conv3DBackpropInputV2"));
+    opBuilder.addInput(inputSizes.asOutput());
+    opBuilder.addInput(filter.asOutput());
+    opBuilder.addInput(outBackprop.asOutput());
+    long[] stridesArray = new long[strides.size()];
+    for (int i = 0; i < stridesArray.length; ++i) {
+      stridesArray[i] = strides.get(i);
+    }
+    opBuilder.setAttr("strides", stridesArray);
+    opBuilder.setAttr("padding", padding);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.dataFormat != null) {
+          opBuilder.setAttr("data_format", opts.dataFormat);
+        }
+        if (opts.dilations != null) {
+          long[] dilationsArray = new long[opts.dilations.size()];
+          for (int i = 0; i < dilationsArray.length; ++i) {
+            dilationsArray[i] = opts.dilations.get(i);
+          }
+          opBuilder.setAttr("dilations", dilationsArray);
+        }
+      }
+    }
+    return new Conv3DBackpropInputV2<U>(opBuilder.build());
+  }
+  
+  /**
+   * @param dataFormat The data format of the input and output data. With the
+   * default format "NDHWC", the data is stored in the order of:
+   *     [batch, in_depth, in_height, in_width, in_channels].
+   * Alternatively, the format could be "NCDHW", the data storage order is:
+   *     [batch, in_channels, in_depth, in_height, in_width].
+   */
+  public static Options dataFormat(String dataFormat) {
+    return new Options().dataFormat(dataFormat);
+  }
+  
+  /**
+   * @param dilations 1-D tensor of length 5.  The dilation factor for each dimension of
+   * `input`. If set to k > 1, there will be k-1 skipped cells between each
+   * filter element on that dimension. The dimension order is determined by the
+   * value of `data_format`, see above for details. Dilations in the batch and
+   * depth dimensions must be 1.
+   */
+  public static Options dilations(List<Long> dilations) {
+    return new Options().dilations(dilations);
+  }
+  
+  /**
+   */
+  public Output<U> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<U> asOutput() {
+    return output;
+  }
+  
+  private Output<U> output;
+  
+  private Conv3DBackpropInputV2(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Conv3D.java java-ops/org/tensorflow/op/core/Conv3D.java
--- java/org/tensorflow/op/core/Conv3D.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Conv3D.java	2018-10-16 20:18:38.220432389 +0900
@@ -0,0 +1,159 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes a 3-D convolution given 5-D `input` and `filter` tensors.
+ * <p>
+ * In signal processing, cross-correlation is a measure of similarity of
+ * two waveforms as a function of a time-lag applied to one of them. This
+ * is also known as a sliding dot product or sliding inner-product.
+ * <p>
+ * Our Conv3D implements a form of cross-correlation.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class Conv3D<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Conv3D}
+   */
+  public static class Options {
+    
+    /**
+     * @param dataFormat The data format of the input and output data. With the
+     * default format "NDHWC", the data is stored in the order of:
+     *     [batch, in_depth, in_height, in_width, in_channels].
+     * Alternatively, the format could be "NCDHW", the data storage order is:
+     *     [batch, in_channels, in_depth, in_height, in_width].
+     */
+    public Options dataFormat(String dataFormat) {
+      this.dataFormat = dataFormat;
+      return this;
+    }
+    
+    /**
+     * @param dilations 1-D tensor of length 5.  The dilation factor for each dimension of
+     * `input`. If set to k > 1, there will be k-1 skipped cells between each
+     * filter element on that dimension. The dimension order is determined by the
+     * value of `data_format`, see above for details. Dilations in the batch and
+     * depth dimensions must be 1.
+     */
+    public Options dilations(List<Long> dilations) {
+      this.dilations = dilations;
+      return this;
+    }
+    
+    private String dataFormat;
+    private List<Long> dilations;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Conv3D operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input Shape `[batch, in_depth, in_height, in_width, in_channels]`.
+   * @param filter Shape `[filter_depth, filter_height, filter_width, in_channels,
+   * out_channels]`. `in_channels` must match between `input` and `filter`.
+   * @param strides 1-D tensor of length 5. The stride of the sliding window for each
+   * dimension of `input`. Must have `strides[0] = strides[4] = 1`.
+   * @param padding The type of padding algorithm to use.
+   * @param options carries optional attributes values
+   * @return a new instance of Conv3D
+   */
+  public static <T extends Number> Conv3D<T> create(Scope scope, Operand<T> input, Operand<T> filter, List<Long> strides, String padding, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Conv3D", scope.makeOpName("Conv3D"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(filter.asOutput());
+    long[] stridesArray = new long[strides.size()];
+    for (int i = 0; i < stridesArray.length; ++i) {
+      stridesArray[i] = strides.get(i);
+    }
+    opBuilder.setAttr("strides", stridesArray);
+    opBuilder.setAttr("padding", padding);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.dataFormat != null) {
+          opBuilder.setAttr("data_format", opts.dataFormat);
+        }
+        if (opts.dilations != null) {
+          long[] dilationsArray = new long[opts.dilations.size()];
+          for (int i = 0; i < dilationsArray.length; ++i) {
+            dilationsArray[i] = opts.dilations.get(i);
+          }
+          opBuilder.setAttr("dilations", dilationsArray);
+        }
+      }
+    }
+    return new Conv3D<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param dataFormat The data format of the input and output data. With the
+   * default format "NDHWC", the data is stored in the order of:
+   *     [batch, in_depth, in_height, in_width, in_channels].
+   * Alternatively, the format could be "NCDHW", the data storage order is:
+   *     [batch, in_channels, in_depth, in_height, in_width].
+   */
+  public static Options dataFormat(String dataFormat) {
+    return new Options().dataFormat(dataFormat);
+  }
+  
+  /**
+   * @param dilations 1-D tensor of length 5.  The dilation factor for each dimension of
+   * `input`. If set to k > 1, there will be k-1 skipped cells between each
+   * filter element on that dimension. The dimension order is determined by the
+   * value of `data_format`, see above for details. Dilations in the batch and
+   * depth dimensions must be 1.
+   */
+  public static Options dilations(List<Long> dilations) {
+    return new Options().dilations(dilations);
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private Conv3D(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Cosh.java java-ops/org/tensorflow/op/core/Cosh.java
--- java/org/tensorflow/op/core/Cosh.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Cosh.java	2018-10-16 20:18:38.225432386 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes hyperbolic cosine of x element-wise.
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class Cosh<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Cosh operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of Cosh
+   */
+  public static <T> Cosh<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Cosh", scope.makeOpName("Cosh"));
+    opBuilder.addInput(x.asOutput());
+    return new Cosh<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private Cosh(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Cos.java java-ops/org/tensorflow/op/core/Cos.java
--- java/org/tensorflow/op/core/Cos.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Cos.java	2018-10-16 20:18:38.225432386 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes cos of x element-wise.
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class Cos<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Cos operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of Cos
+   */
+  public static <T> Cos<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Cos", scope.makeOpName("Cos"));
+    opBuilder.addInput(x.asOutput());
+    return new Cos<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private Cos(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/CountUpTo.java java-ops/org/tensorflow/op/core/CountUpTo.java
--- java/org/tensorflow/op/core/CountUpTo.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/CountUpTo.java	2018-10-16 20:18:38.225432386 +0900
@@ -0,0 +1,72 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Increments 'ref' until it reaches 'limit'.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class CountUpTo<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new CountUpTo operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param ref Should be from a scalar `Variable` node.
+   * @param limit If incrementing ref would bring it above limit, instead generates an
+   * 'OutOfRange' error.
+   * @return a new instance of CountUpTo
+   */
+  public static <T extends Number> CountUpTo<T> create(Scope scope, Operand<T> ref, Long limit) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("CountUpTo", scope.makeOpName("CountUpTo"));
+    opBuilder.addInput(ref.asOutput());
+    opBuilder.setAttr("limit", limit);
+    return new CountUpTo<T>(opBuilder.build());
+  }
+  
+  /**
+   * A copy of the input before increment. If nothing else modifies the
+   * input, the values produced will all be distinct.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private CountUpTo(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/CreateSummaryDbWriter.java java-ops/org/tensorflow/op/core/CreateSummaryDbWriter.java
--- java/org/tensorflow/op/core/CreateSummaryDbWriter.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/CreateSummaryDbWriter.java	2018-10-16 20:18:38.226432385 +0900
@@ -0,0 +1,55 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ */
+public final class CreateSummaryDbWriter extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new CreateSummaryDbWriter operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param writer 
+   * @param dbUri 
+   * @param experimentName 
+   * @param runName 
+   * @param userName 
+   * @return a new instance of CreateSummaryDbWriter
+   */
+  public static CreateSummaryDbWriter create(Scope scope, Operand<?> writer, Operand<String> dbUri, Operand<String> experimentName, Operand<String> runName, Operand<String> userName) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("CreateSummaryDbWriter", scope.makeOpName("CreateSummaryDbWriter"));
+    opBuilder.addInput(writer.asOutput());
+    opBuilder.addInput(dbUri.asOutput());
+    opBuilder.addInput(experimentName.asOutput());
+    opBuilder.addInput(runName.asOutput());
+    opBuilder.addInput(userName.asOutput());
+    return new CreateSummaryDbWriter(opBuilder.build());
+  }
+  
+  
+  private CreateSummaryDbWriter(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/CreateSummaryFileWriter.java java-ops/org/tensorflow/op/core/CreateSummaryFileWriter.java
--- java/org/tensorflow/op/core/CreateSummaryFileWriter.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/CreateSummaryFileWriter.java	2018-10-16 20:18:38.226432385 +0900
@@ -0,0 +1,55 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ */
+public final class CreateSummaryFileWriter extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new CreateSummaryFileWriter operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param writer 
+   * @param logdir 
+   * @param maxQueue 
+   * @param flushMillis 
+   * @param filenameSuffix 
+   * @return a new instance of CreateSummaryFileWriter
+   */
+  public static CreateSummaryFileWriter create(Scope scope, Operand<?> writer, Operand<String> logdir, Operand<Integer> maxQueue, Operand<Integer> flushMillis, Operand<String> filenameSuffix) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("CreateSummaryFileWriter", scope.makeOpName("CreateSummaryFileWriter"));
+    opBuilder.addInput(writer.asOutput());
+    opBuilder.addInput(logdir.asOutput());
+    opBuilder.addInput(maxQueue.asOutput());
+    opBuilder.addInput(flushMillis.asOutput());
+    opBuilder.addInput(filenameSuffix.asOutput());
+    return new CreateSummaryFileWriter(opBuilder.build());
+  }
+  
+  
+  private CreateSummaryFileWriter(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/CropAndResizeGradBoxes.java java-ops/org/tensorflow/op/core/CropAndResizeGradBoxes.java
--- java/org/tensorflow/op/core/CropAndResizeGradBoxes.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/CropAndResizeGradBoxes.java	2018-10-16 20:18:38.228432383 +0900
@@ -0,0 +1,119 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the gradient of the crop_and_resize op wrt the input boxes tensor.
+ */
+@Operator
+public final class CropAndResizeGradBoxes extends PrimitiveOp implements Operand<Float> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.CropAndResizeGradBoxes}
+   */
+  public static class Options {
+    
+    /**
+     * @param method A string specifying the interpolation method. Only 'bilinear' is
+     * supported for now.
+     */
+    public Options method(String method) {
+      this.method = method;
+      return this;
+    }
+    
+    private String method;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new CropAndResizeGradBoxes operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param grads A 4-D tensor of shape `[num_boxes, crop_height, crop_width, depth]`.
+   * @param image A 4-D tensor of shape `[batch, image_height, image_width, depth]`.
+   * Both `image_height` and `image_width` need to be positive.
+   * @param boxes A 2-D tensor of shape `[num_boxes, 4]`. The `i`-th row of the tensor
+   * specifies the coordinates of a box in the `box_ind[i]` image and is specified
+   * in normalized coordinates `[y1, x1, y2, x2]`. A normalized coordinate value of
+   * `y` is mapped to the image coordinate at `y * (image_height - 1)`, so as the
+   * `[0, 1]` interval of normalized image height is mapped to
+   * `[0, image_height - 1] in image height coordinates. We do allow y1 > y2, in
+   * which case the sampled crop is an up-down flipped version of the original
+   * image. The width dimension is treated similarly. Normalized coordinates
+   * outside the `[0, 1]` range are allowed, in which case we use
+   * `extrapolation_value` to extrapolate the input image values.
+   * @param boxInd A 1-D tensor of shape `[num_boxes]` with int32 values in `[0, batch)`.
+   * The value of `box_ind[i]` specifies the image that the `i`-th box refers to.
+   * @param options carries optional attributes values
+   * @return a new instance of CropAndResizeGradBoxes
+   */
+  public static <T extends Number> CropAndResizeGradBoxes create(Scope scope, Operand<Float> grads, Operand<T> image, Operand<Float> boxes, Operand<Integer> boxInd, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("CropAndResizeGradBoxes", scope.makeOpName("CropAndResizeGradBoxes"));
+    opBuilder.addInput(grads.asOutput());
+    opBuilder.addInput(image.asOutput());
+    opBuilder.addInput(boxes.asOutput());
+    opBuilder.addInput(boxInd.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.method != null) {
+          opBuilder.setAttr("method", opts.method);
+        }
+      }
+    }
+    return new CropAndResizeGradBoxes(opBuilder.build());
+  }
+  
+  /**
+   * @param method A string specifying the interpolation method. Only 'bilinear' is
+   * supported for now.
+   */
+  public static Options method(String method) {
+    return new Options().method(method);
+  }
+  
+  /**
+   * A 2-D tensor of shape `[num_boxes, 4]`.
+   */
+  public Output<Float> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<Float> asOutput() {
+    return output;
+  }
+  
+  private Output<Float> output;
+  
+  private CropAndResizeGradBoxes(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/CropAndResizeGradImage.java java-ops/org/tensorflow/op/core/CropAndResizeGradImage.java
--- java/org/tensorflow/op/core/CropAndResizeGradImage.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/CropAndResizeGradImage.java	2018-10-16 20:18:38.229432383 +0900
@@ -0,0 +1,125 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the gradient of the crop_and_resize op wrt the input image tensor.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class CropAndResizeGradImage<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.CropAndResizeGradImage}
+   */
+  public static class Options {
+    
+    /**
+     * @param method A string specifying the interpolation method. Only 'bilinear' is
+     * supported for now.
+     */
+    public Options method(String method) {
+      this.method = method;
+      return this;
+    }
+    
+    private String method;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new CropAndResizeGradImage operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param grads A 4-D tensor of shape `[num_boxes, crop_height, crop_width, depth]`.
+   * @param boxes A 2-D tensor of shape `[num_boxes, 4]`. The `i`-th row of the tensor
+   * specifies the coordinates of a box in the `box_ind[i]` image and is specified
+   * in normalized coordinates `[y1, x1, y2, x2]`. A normalized coordinate value of
+   * `y` is mapped to the image coordinate at `y * (image_height - 1)`, so as the
+   * `[0, 1]` interval of normalized image height is mapped to
+   * `[0, image_height - 1] in image height coordinates. We do allow y1 > y2, in
+   * which case the sampled crop is an up-down flipped version of the original
+   * image. The width dimension is treated similarly. Normalized coordinates
+   * outside the `[0, 1]` range are allowed, in which case we use
+   * `extrapolation_value` to extrapolate the input image values.
+   * @param boxInd A 1-D tensor of shape `[num_boxes]` with int32 values in `[0, batch)`.
+   * The value of `box_ind[i]` specifies the image that the `i`-th box refers to.
+   * @param imageSize A 1-D tensor with value `[batch, image_height, image_width, depth]`
+   * containing the original image size. Both `image_height` and `image_width` need
+   * to be positive.
+   * @param T 
+   * @param options carries optional attributes values
+   * @return a new instance of CropAndResizeGradImage
+   */
+  public static <T extends Number> CropAndResizeGradImage<T> create(Scope scope, Operand<Float> grads, Operand<Float> boxes, Operand<Integer> boxInd, Operand<Integer> imageSize, Class<T> T, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("CropAndResizeGradImage", scope.makeOpName("CropAndResizeGradImage"));
+    opBuilder.addInput(grads.asOutput());
+    opBuilder.addInput(boxes.asOutput());
+    opBuilder.addInput(boxInd.asOutput());
+    opBuilder.addInput(imageSize.asOutput());
+    opBuilder.setAttr("T", DataType.fromClass(T));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.method != null) {
+          opBuilder.setAttr("method", opts.method);
+        }
+      }
+    }
+    return new CropAndResizeGradImage<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param method A string specifying the interpolation method. Only 'bilinear' is
+   * supported for now.
+   */
+  public static Options method(String method) {
+    return new Options().method(method);
+  }
+  
+  /**
+   * A 4-D tensor of shape `[batch, image_height, image_width, depth]`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private CropAndResizeGradImage(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/CropAndResize.java java-ops/org/tensorflow/op/core/CropAndResize.java
--- java/org/tensorflow/op/core/CropAndResize.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/CropAndResize.java	2018-10-16 20:18:38.227432384 +0900
@@ -0,0 +1,159 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Extracts crops from the input image tensor and resizes them.
+ * <p>
+ * Extracts crops from the input image tensor and resizes them using bilinear
+ * sampling or nearest neighbor sampling (possibly with aspect ratio change) to a
+ * common output size specified by `crop_size`. This is more general than the
+ * `crop_to_bounding_box` op which extracts a fixed size slice from the input image
+ * and does not allow resizing or aspect ratio change.
+ * <p>
+ * Returns a tensor with `crops` from the input `image` at positions defined at the
+ * bounding box locations in `boxes`. The cropped boxes are all resized (with
+ * bilinear or nearest neighbor interpolation) to a fixed
+ * `size = [crop_height, crop_width]`. The result is a 4-D tensor
+ * `[num_boxes, crop_height, crop_width, depth]`. The resizing is corner aligned.
+ * In particular, if `boxes = [[0, 0, 1, 1]]`, the method will give identical
+ * results to using `tf.image.resize_bilinear()` or
+ * `tf.image.resize_nearest_neighbor()`(depends on the `method` argument) with
+ * `align_corners=True`.
+ */
+@Operator
+public final class CropAndResize extends PrimitiveOp implements Operand<Float> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.CropAndResize}
+   */
+  public static class Options {
+    
+    /**
+     * @param method A string specifying the sampling method for resizing. It can be either
+     * `"bilinear"` or `"nearest"` and default to `"bilinear"`. Currently two sampling
+     * methods are supported: Bilinear and Nearest Neighbor.
+     */
+    public Options method(String method) {
+      this.method = method;
+      return this;
+    }
+    
+    /**
+     * @param extrapolationValue Value used for extrapolation, when applicable.
+     */
+    public Options extrapolationValue(Float extrapolationValue) {
+      this.extrapolationValue = extrapolationValue;
+      return this;
+    }
+    
+    private String method;
+    private Float extrapolationValue;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new CropAndResize operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param image A 4-D tensor of shape `[batch, image_height, image_width, depth]`.
+   * Both `image_height` and `image_width` need to be positive.
+   * @param boxes A 2-D tensor of shape `[num_boxes, 4]`. The `i`-th row of the tensor
+   * specifies the coordinates of a box in the `box_ind[i]` image and is specified
+   * in normalized coordinates `[y1, x1, y2, x2]`. A normalized coordinate value of
+   * `y` is mapped to the image coordinate at `y * (image_height - 1)`, so as the
+   * `[0, 1]` interval of normalized image height is mapped to
+   * `[0, image_height - 1]` in image height coordinates. We do allow `y1` > `y2`, in
+   * which case the sampled crop is an up-down flipped version of the original
+   * image. The width dimension is treated similarly. Normalized coordinates
+   * outside the `[0, 1]` range are allowed, in which case we use
+   * `extrapolation_value` to extrapolate the input image values.
+   * @param boxInd A 1-D tensor of shape `[num_boxes]` with int32 values in `[0, batch)`.
+   * The value of `box_ind[i]` specifies the image that the `i`-th box refers to.
+   * @param cropSize A 1-D tensor of 2 elements, `size = [crop_height, crop_width]`. All
+   * cropped image patches are resized to this size. The aspect ratio of the image
+   * content is not preserved. Both `crop_height` and `crop_width` need to be
+   * positive.
+   * @param options carries optional attributes values
+   * @return a new instance of CropAndResize
+   */
+  public static <T extends Number> CropAndResize create(Scope scope, Operand<T> image, Operand<Float> boxes, Operand<Integer> boxInd, Operand<Integer> cropSize, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("CropAndResize", scope.makeOpName("CropAndResize"));
+    opBuilder.addInput(image.asOutput());
+    opBuilder.addInput(boxes.asOutput());
+    opBuilder.addInput(boxInd.asOutput());
+    opBuilder.addInput(cropSize.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.method != null) {
+          opBuilder.setAttr("method", opts.method);
+        }
+        if (opts.extrapolationValue != null) {
+          opBuilder.setAttr("extrapolation_value", opts.extrapolationValue);
+        }
+      }
+    }
+    return new CropAndResize(opBuilder.build());
+  }
+  
+  /**
+   * @param method A string specifying the sampling method for resizing. It can be either
+   * `"bilinear"` or `"nearest"` and default to `"bilinear"`. Currently two sampling
+   * methods are supported: Bilinear and Nearest Neighbor.
+   */
+  public static Options method(String method) {
+    return new Options().method(method);
+  }
+  
+  /**
+   * @param extrapolationValue Value used for extrapolation, when applicable.
+   */
+  public static Options extrapolationValue(Float extrapolationValue) {
+    return new Options().extrapolationValue(extrapolationValue);
+  }
+  
+  /**
+   * A 4-D tensor of shape `[num_boxes, crop_height, crop_width, depth]`.
+   */
+  public Output<Float> crops() {
+    return crops;
+  }
+  
+  @Override
+  public Output<Float> asOutput() {
+    return crops;
+  }
+  
+  private Output<Float> crops;
+  
+  private CropAndResize(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    crops = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Cross.java java-ops/org/tensorflow/op/core/Cross.java
--- java/org/tensorflow/op/core/Cross.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Cross.java	2018-10-16 20:18:38.229432383 +0900
@@ -0,0 +1,74 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Compute the pairwise cross product.
+ * <p>
+ * `a` and `b` must be the same shape; they can either be simple 3-element vectors,
+ * or any shape where the innermost dimension is 3. In the latter case, each pair
+ * of corresponding 3-element vectors is cross-multiplied independently.
+ * 
+ * @param <T> data type for {@code product()} output
+ */
+@Operator
+public final class Cross<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Cross operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param a A tensor containing 3-element vectors.
+   * @param b Another tensor, of same type and shape as `a`.
+   * @return a new instance of Cross
+   */
+  public static <T extends Number> Cross<T> create(Scope scope, Operand<T> a, Operand<T> b) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Cross", scope.makeOpName("Cross"));
+    opBuilder.addInput(a.asOutput());
+    opBuilder.addInput(b.asOutput());
+    return new Cross<T>(opBuilder.build());
+  }
+  
+  /**
+   * Pairwise cross product of the vectors in `a` and `b`.
+   */
+  public Output<T> product() {
+    return product;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return product;
+  }
+  
+  private Output<T> product;
+  
+  private Cross(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    product = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/CTCBeamSearchDecoder.java java-ops/org/tensorflow/op/core/CTCBeamSearchDecoder.java
--- java/org/tensorflow/op/core/CTCBeamSearchDecoder.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/CTCBeamSearchDecoder.java	2018-10-16 20:18:38.205432400 +0900
@@ -0,0 +1,150 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Performs beam search decoding on the logits given in input.
+ * <p>
+ * A note about the attribute merge_repeated: For the beam search decoder,
+ * this means that if consecutive entries in a beam are the same, only
+ * the first of these is emitted.  That is, when the top path is "A B B B B",
+ * "A B" is returned if merge_repeated = True but "A B B B B" is
+ * returned if merge_repeated = False.
+ */
+@Operator
+public final class CTCBeamSearchDecoder extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.CTCBeamSearchDecoder}
+   */
+  public static class Options {
+    
+    /**
+     * @param mergeRepeated If true, merge repeated classes in output.
+     */
+    public Options mergeRepeated(Boolean mergeRepeated) {
+      this.mergeRepeated = mergeRepeated;
+      return this;
+    }
+    
+    private Boolean mergeRepeated;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new CTCBeamSearchDecoder operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputs 3-D, shape: `(max_time x batch_size x num_classes)`, the logits.
+   * @param sequenceLength A vector containing sequence lengths, size `(batch)`.
+   * @param beamWidth A scalar >= 0 (beam search beam width).
+   * @param topPaths A scalar >= 0, <= beam_width (controls output size).
+   * @param options carries optional attributes values
+   * @return a new instance of CTCBeamSearchDecoder
+   */
+  public static CTCBeamSearchDecoder create(Scope scope, Operand<Float> inputs, Operand<Integer> sequenceLength, Long beamWidth, Long topPaths, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("CTCBeamSearchDecoder", scope.makeOpName("CTCBeamSearchDecoder"));
+    opBuilder.addInput(inputs.asOutput());
+    opBuilder.addInput(sequenceLength.asOutput());
+    opBuilder.setAttr("beam_width", beamWidth);
+    opBuilder.setAttr("top_paths", topPaths);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.mergeRepeated != null) {
+          opBuilder.setAttr("merge_repeated", opts.mergeRepeated);
+        }
+      }
+    }
+    return new CTCBeamSearchDecoder(opBuilder.build());
+  }
+  
+  /**
+   * @param mergeRepeated If true, merge repeated classes in output.
+   */
+  public static Options mergeRepeated(Boolean mergeRepeated) {
+    return new Options().mergeRepeated(mergeRepeated);
+  }
+  
+  /**
+   * A list (length: top_paths) of indices matrices.  Matrix j,
+   * size `(total_decoded_outputs[j] x 2)`, has indices of a
+   * `SparseTensor<int64, 2>`.  The rows store: [batch, time].
+   */
+  public List<Output<Long>> decodedIndices() {
+    return decodedIndices;
+  }
+  
+  /**
+   * A list (length: top_paths) of values vectors.  Vector j,
+   * size `(length total_decoded_outputs[j])`, has the values of a
+   * `SparseTensor<int64, 2>`.  The vector stores the decoded classes for beam j.
+   */
+  public List<Output<Long>> decodedValues() {
+    return decodedValues;
+  }
+  
+  /**
+   * A list (length: top_paths) of shape vector.  Vector j,
+   * size `(2)`, stores the shape of the decoded `SparseTensor[j]`.
+   * Its values are: `[batch_size, max_decoded_length[j]]`.
+   */
+  public List<Output<Long>> decodedShape() {
+    return decodedShape;
+  }
+  
+  /**
+   * A matrix, shaped: `(batch_size x top_paths)`.  The
+   * sequence log-probabilities.
+   */
+  public Output<Float> logProbability() {
+    return logProbability;
+  }
+  
+  private List<Output<Long>> decodedIndices;
+  private List<Output<Long>> decodedValues;
+  private List<Output<Long>> decodedShape;
+  private Output<Float> logProbability;
+  
+  @SuppressWarnings("unchecked")
+  private CTCBeamSearchDecoder(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    int decodedIndicesLength = operation.outputListLength("decoded_indices");
+    decodedIndices = Arrays.asList((Output<Long>[])operation.outputList(outputIdx, decodedIndicesLength));
+    outputIdx += decodedIndicesLength;
+    int decodedValuesLength = operation.outputListLength("decoded_values");
+    decodedValues = Arrays.asList((Output<Long>[])operation.outputList(outputIdx, decodedValuesLength));
+    outputIdx += decodedValuesLength;
+    int decodedShapeLength = operation.outputListLength("decoded_shape");
+    decodedShape = Arrays.asList((Output<Long>[])operation.outputList(outputIdx, decodedShapeLength));
+    outputIdx += decodedShapeLength;
+    logProbability = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/CTCGreedyDecoder.java java-ops/org/tensorflow/op/core/CTCGreedyDecoder.java
--- java/org/tensorflow/op/core/CTCGreedyDecoder.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/CTCGreedyDecoder.java	2018-10-16 20:18:38.206432399 +0900
@@ -0,0 +1,138 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Performs greedy decoding on the logits given in inputs.
+ * <p>
+ * A note about the attribute merge_repeated: if enabled, when
+ * consecutive logits' maximum indices are the same, only the first of
+ * these is emitted.  Labeling the blank '*', the sequence "A B B * B B"
+ * becomes "A B B" if merge_repeated = True and "A B B B B" if
+ * merge_repeated = False.
+ * <p>
+ * Regardless of the value of merge_repeated, if the maximum index of a given
+ * time and batch corresponds to the blank, index `(num_classes - 1)`, no new
+ * element is emitted.
+ */
+@Operator
+public final class CTCGreedyDecoder extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.CTCGreedyDecoder}
+   */
+  public static class Options {
+    
+    /**
+     * @param mergeRepeated If True, merge repeated classes in output.
+     */
+    public Options mergeRepeated(Boolean mergeRepeated) {
+      this.mergeRepeated = mergeRepeated;
+      return this;
+    }
+    
+    private Boolean mergeRepeated;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new CTCGreedyDecoder operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputs 3-D, shape: `(max_time x batch_size x num_classes)`, the logits.
+   * @param sequenceLength A vector containing sequence lengths, size `(batch_size)`.
+   * @param options carries optional attributes values
+   * @return a new instance of CTCGreedyDecoder
+   */
+  public static CTCGreedyDecoder create(Scope scope, Operand<Float> inputs, Operand<Integer> sequenceLength, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("CTCGreedyDecoder", scope.makeOpName("CTCGreedyDecoder"));
+    opBuilder.addInput(inputs.asOutput());
+    opBuilder.addInput(sequenceLength.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.mergeRepeated != null) {
+          opBuilder.setAttr("merge_repeated", opts.mergeRepeated);
+        }
+      }
+    }
+    return new CTCGreedyDecoder(opBuilder.build());
+  }
+  
+  /**
+   * @param mergeRepeated If True, merge repeated classes in output.
+   */
+  public static Options mergeRepeated(Boolean mergeRepeated) {
+    return new Options().mergeRepeated(mergeRepeated);
+  }
+  
+  /**
+   * Indices matrix, size `(total_decoded_outputs x 2)`,
+   * of a `SparseTensor<int64, 2>`.  The rows store: [batch, time].
+   */
+  public Output<Long> decodedIndices() {
+    return decodedIndices;
+  }
+  
+  /**
+   * Values vector, size: `(total_decoded_outputs)`,
+   * of a `SparseTensor<int64, 2>`.  The vector stores the decoded classes.
+   */
+  public Output<Long> decodedValues() {
+    return decodedValues;
+  }
+  
+  /**
+   * Shape vector, size `(2)`, of the decoded SparseTensor.
+   * Values are: `[batch_size, max_decoded_length]`.
+   */
+  public Output<Long> decodedShape() {
+    return decodedShape;
+  }
+  
+  /**
+   * Matrix, size `(batch_size x 1)`, containing sequence
+   * log-probabilities.
+   */
+  public Output<Float> logProbability() {
+    return logProbability;
+  }
+  
+  private Output<Long> decodedIndices;
+  private Output<Long> decodedValues;
+  private Output<Long> decodedShape;
+  private Output<Float> logProbability;
+  
+  private CTCGreedyDecoder(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    decodedIndices = operation.output(outputIdx++);
+    decodedValues = operation.output(outputIdx++);
+    decodedShape = operation.output(outputIdx++);
+    logProbability = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/CTCLoss.java java-ops/org/tensorflow/op/core/CTCLoss.java
--- java/org/tensorflow/op/core/CTCLoss.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/CTCLoss.java	2018-10-16 20:18:38.207432398 +0900
@@ -0,0 +1,164 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Calculates the CTC Loss (log probability) for each batch entry.  Also calculates
+ * <p>
+ * the gradient.  This class performs the softmax operation for you, so inputs
+ * should be e.g. linear projections of outputs by an LSTM.
+ */
+@Operator
+public final class CTCLoss extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.CTCLoss}
+   */
+  public static class Options {
+    
+    /**
+     * @param preprocessCollapseRepeated Scalar, if true then repeated labels are
+     * collapsed prior to the CTC calculation.
+     */
+    public Options preprocessCollapseRepeated(Boolean preprocessCollapseRepeated) {
+      this.preprocessCollapseRepeated = preprocessCollapseRepeated;
+      return this;
+    }
+    
+    /**
+     * @param ctcMergeRepeated Scalar.  If set to false, <i>during</i> CTC calculation
+     * repeated non-blank labels will not be merged and are interpreted as
+     * individual labels.  This is a simplified version of CTC.
+     */
+    public Options ctcMergeRepeated(Boolean ctcMergeRepeated) {
+      this.ctcMergeRepeated = ctcMergeRepeated;
+      return this;
+    }
+    
+    /**
+     * @param ignoreLongerOutputsThanInputs Scalar. If set to true, during CTC
+     * calculation, items that have longer output sequences than input sequences
+     * are skipped: they don't contribute to the loss term and have zero-gradient.
+     */
+    public Options ignoreLongerOutputsThanInputs(Boolean ignoreLongerOutputsThanInputs) {
+      this.ignoreLongerOutputsThanInputs = ignoreLongerOutputsThanInputs;
+      return this;
+    }
+    
+    private Boolean preprocessCollapseRepeated;
+    private Boolean ctcMergeRepeated;
+    private Boolean ignoreLongerOutputsThanInputs;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new CTCLoss operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputs 3-D, shape: `(max_time x batch_size x num_classes)`, the logits.
+   * @param labelsIndices The indices of a `SparseTensor<int32, 2>`.
+   * `labels_indices(i, :) == [b, t]` means `labels_values(i)` stores the id for
+   * `(batch b, time t)`.
+   * @param labelsValues The values (labels) associated with the given batch and time.
+   * @param sequenceLength A vector containing sequence lengths (batch).
+   * @param options carries optional attributes values
+   * @return a new instance of CTCLoss
+   */
+  public static CTCLoss create(Scope scope, Operand<Float> inputs, Operand<Long> labelsIndices, Operand<Integer> labelsValues, Operand<Integer> sequenceLength, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("CTCLoss", scope.makeOpName("CTCLoss"));
+    opBuilder.addInput(inputs.asOutput());
+    opBuilder.addInput(labelsIndices.asOutput());
+    opBuilder.addInput(labelsValues.asOutput());
+    opBuilder.addInput(sequenceLength.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.preprocessCollapseRepeated != null) {
+          opBuilder.setAttr("preprocess_collapse_repeated", opts.preprocessCollapseRepeated);
+        }
+        if (opts.ctcMergeRepeated != null) {
+          opBuilder.setAttr("ctc_merge_repeated", opts.ctcMergeRepeated);
+        }
+        if (opts.ignoreLongerOutputsThanInputs != null) {
+          opBuilder.setAttr("ignore_longer_outputs_than_inputs", opts.ignoreLongerOutputsThanInputs);
+        }
+      }
+    }
+    return new CTCLoss(opBuilder.build());
+  }
+  
+  /**
+   * @param preprocessCollapseRepeated Scalar, if true then repeated labels are
+   * collapsed prior to the CTC calculation.
+   */
+  public static Options preprocessCollapseRepeated(Boolean preprocessCollapseRepeated) {
+    return new Options().preprocessCollapseRepeated(preprocessCollapseRepeated);
+  }
+  
+  /**
+   * @param ctcMergeRepeated Scalar.  If set to false, <i>during</i> CTC calculation
+   * repeated non-blank labels will not be merged and are interpreted as
+   * individual labels.  This is a simplified version of CTC.
+   */
+  public static Options ctcMergeRepeated(Boolean ctcMergeRepeated) {
+    return new Options().ctcMergeRepeated(ctcMergeRepeated);
+  }
+  
+  /**
+   * @param ignoreLongerOutputsThanInputs Scalar. If set to true, during CTC
+   * calculation, items that have longer output sequences than input sequences
+   * are skipped: they don't contribute to the loss term and have zero-gradient.
+   */
+  public static Options ignoreLongerOutputsThanInputs(Boolean ignoreLongerOutputsThanInputs) {
+    return new Options().ignoreLongerOutputsThanInputs(ignoreLongerOutputsThanInputs);
+  }
+  
+  /**
+   * A vector (batch) containing log-probabilities.
+   */
+  public Output<Float> loss() {
+    return loss;
+  }
+  
+  /**
+   * The gradient of `loss`.  3-D, shape:
+   * `(max_time x batch_size x num_classes)`.
+   */
+  public Output<Float> gradient() {
+    return gradient;
+  }
+  
+  private Output<Float> loss;
+  private Output<Float> gradient;
+  
+  private CTCLoss(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    loss = operation.output(outputIdx++);
+    gradient = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/CudnnRNNBackprop.java java-ops/org/tensorflow/op/core/CudnnRNNBackprop.java
--- java/org/tensorflow/op/core/CudnnRNNBackprop.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/CudnnRNNBackprop.java	2018-10-16 20:18:38.231432381 +0900
@@ -0,0 +1,275 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Backprop step of CudnnRNN.
+ * <p>
+ * Compute the backprop of both data and weights in a RNN.
+ * <p>
+ * rnn_mode: Indicates the type of the RNN model.
+ * input_mode: Indicate whether there is a linear projection between the input and
+ *     the actual computation before the first layer. 'skip_input' is only allowed
+ *     when input_size == num_units; 'auto_select' implies 'skip_input' when
+ *     input_size == num_units; otherwise, it implies 'linear_input'.
+ * direction: Indicates whether a bidirectional model will be used. Should be
+ *   "unidirectional" or "bidirectional".
+ * dropout: Dropout probability. When set to 0., dropout is disabled.
+ * seed: The 1st part of a seed to initialize dropout.
+ * seed2: The 2nd part of a seed to initialize dropout.
+ * input: A 3-D tensor with the shape of [seq_length, batch_size, input_size].
+ * input_h: A 3-D tensor with the shape of [num_layer * dir, batch_size,
+ *     num_units].
+ * input_c: For LSTM, a 3-D tensor with the shape of
+ *     [num_layer * dir, batch, num_units]. For other models, it is ignored.
+ * params: A 1-D tensor that contains the weights and biases in an opaque layout.
+ *     The size must be created through CudnnRNNParamsSize, and initialized
+ *     separately. Note that they might not be compatible across different
+ *     generations. So it is a good idea to save and restore
+ * output: A 3-D tensor with the shape of [seq_length, batch_size,
+ *     dir * num_units].
+ * output_h: The same shape has input_h.
+ * output_c: The same shape as input_c for LSTM. An empty tensor for other models.
+ * output_backprop: A 3-D tensor with the same shape as output in the forward pass.
+ * output_h_backprop: A 3-D tensor with the same shape as output_h in the forward
+ *     pass.
+ * output_c_backprop: A 3-D tensor with the same shape as output_c in the forward
+ *     pass.
+ * reserve_space: The same reserve_space produced in for forward operation.
+ * input_backprop: The backprop to input in the forward pass. Has the same shape
+ *     as input.
+ * input_h_backprop: The backprop to input_h in the forward pass. Has the same
+ *     shape as input_h.
+ * input_c_backprop: The backprop to input_c in the forward pass. Has the same
+ *     shape as input_c.
+ * params_backprop: The backprop to the params buffer in the forward pass. Has the
+ *     same shape as params.
+ * 
+ * @param <T> data type for {@code inputBackprop()} output
+ */
+@Operator
+public final class CudnnRNNBackprop<T extends Number> extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.CudnnRNNBackprop}
+   */
+  public static class Options {
+    
+    /**
+     * @param rnnMode 
+     */
+    public Options rnnMode(String rnnMode) {
+      this.rnnMode = rnnMode;
+      return this;
+    }
+    
+    /**
+     * @param inputMode 
+     */
+    public Options inputMode(String inputMode) {
+      this.inputMode = inputMode;
+      return this;
+    }
+    
+    /**
+     * @param direction 
+     */
+    public Options direction(String direction) {
+      this.direction = direction;
+      return this;
+    }
+    
+    /**
+     * @param dropout 
+     */
+    public Options dropout(Float dropout) {
+      this.dropout = dropout;
+      return this;
+    }
+    
+    /**
+     * @param seed 
+     */
+    public Options seed(Long seed) {
+      this.seed = seed;
+      return this;
+    }
+    
+    /**
+     * @param seed2 
+     */
+    public Options seed2(Long seed2) {
+      this.seed2 = seed2;
+      return this;
+    }
+    
+    private String rnnMode;
+    private String inputMode;
+    private String direction;
+    private Float dropout;
+    private Long seed;
+    private Long seed2;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new CudnnRNNBackprop operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param inputH 
+   * @param inputC 
+   * @param params 
+   * @param output 
+   * @param outputH 
+   * @param outputC 
+   * @param outputBackprop 
+   * @param outputHBackprop 
+   * @param outputCBackprop 
+   * @param reserveSpace 
+   * @param options carries optional attributes values
+   * @return a new instance of CudnnRNNBackprop
+   */
+  public static <T extends Number> CudnnRNNBackprop<T> create(Scope scope, Operand<T> input, Operand<T> inputH, Operand<T> inputC, Operand<T> params, Operand<T> output, Operand<T> outputH, Operand<T> outputC, Operand<T> outputBackprop, Operand<T> outputHBackprop, Operand<T> outputCBackprop, Operand<T> reserveSpace, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("CudnnRNNBackprop", scope.makeOpName("CudnnRNNBackprop"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(inputH.asOutput());
+    opBuilder.addInput(inputC.asOutput());
+    opBuilder.addInput(params.asOutput());
+    opBuilder.addInput(output.asOutput());
+    opBuilder.addInput(outputH.asOutput());
+    opBuilder.addInput(outputC.asOutput());
+    opBuilder.addInput(outputBackprop.asOutput());
+    opBuilder.addInput(outputHBackprop.asOutput());
+    opBuilder.addInput(outputCBackprop.asOutput());
+    opBuilder.addInput(reserveSpace.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.rnnMode != null) {
+          opBuilder.setAttr("rnn_mode", opts.rnnMode);
+        }
+        if (opts.inputMode != null) {
+          opBuilder.setAttr("input_mode", opts.inputMode);
+        }
+        if (opts.direction != null) {
+          opBuilder.setAttr("direction", opts.direction);
+        }
+        if (opts.dropout != null) {
+          opBuilder.setAttr("dropout", opts.dropout);
+        }
+        if (opts.seed != null) {
+          opBuilder.setAttr("seed", opts.seed);
+        }
+        if (opts.seed2 != null) {
+          opBuilder.setAttr("seed2", opts.seed2);
+        }
+      }
+    }
+    return new CudnnRNNBackprop<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param rnnMode 
+   */
+  public static Options rnnMode(String rnnMode) {
+    return new Options().rnnMode(rnnMode);
+  }
+  
+  /**
+   * @param inputMode 
+   */
+  public static Options inputMode(String inputMode) {
+    return new Options().inputMode(inputMode);
+  }
+  
+  /**
+   * @param direction 
+   */
+  public static Options direction(String direction) {
+    return new Options().direction(direction);
+  }
+  
+  /**
+   * @param dropout 
+   */
+  public static Options dropout(Float dropout) {
+    return new Options().dropout(dropout);
+  }
+  
+  /**
+   * @param seed 
+   */
+  public static Options seed(Long seed) {
+    return new Options().seed(seed);
+  }
+  
+  /**
+   * @param seed2 
+   */
+  public static Options seed2(Long seed2) {
+    return new Options().seed2(seed2);
+  }
+  
+  /**
+   */
+  public Output<T> inputBackprop() {
+    return inputBackprop;
+  }
+  
+  /**
+   */
+  public Output<T> inputHBackprop() {
+    return inputHBackprop;
+  }
+  
+  /**
+   */
+  public Output<T> inputCBackprop() {
+    return inputCBackprop;
+  }
+  
+  /**
+   */
+  public Output<T> paramsBackprop() {
+    return paramsBackprop;
+  }
+  
+  private Output<T> inputBackprop;
+  private Output<T> inputHBackprop;
+  private Output<T> inputCBackprop;
+  private Output<T> paramsBackprop;
+  
+  private CudnnRNNBackprop(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    inputBackprop = operation.output(outputIdx++);
+    inputHBackprop = operation.output(outputIdx++);
+    inputCBackprop = operation.output(outputIdx++);
+    paramsBackprop = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/CudnnRNNBackpropV2.java java-ops/org/tensorflow/op/core/CudnnRNNBackpropV2.java
--- java/org/tensorflow/op/core/CudnnRNNBackpropV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/CudnnRNNBackpropV2.java	2018-10-16 20:18:38.232432381 +0900
@@ -0,0 +1,278 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Backprop step of CudnnRNN.
+ * <p>
+ * Compute the backprop of both data and weights in a RNN. Takes an extra
+ *     "host_reserved" inupt than CudnnRNNBackprop, which is used to determine RNN
+ *     cudnnRNNAlgo_t and cudnnMathType_t.
+ * <p>
+ * rnn_mode: Indicates the type of the RNN model.
+ * input_mode: Indicates whether there is a linear projection between the input and
+ *     the actual computation before the first layer. 'skip_input' is only allowed
+ *     when input_size == num_units; 'auto_select' implies 'skip_input' when
+ *     input_size == num_units; otherwise, it implies 'linear_input'.
+ * direction: Indicates whether a bidirectional model will be used. Should be
+ *   "unidirectional" or "bidirectional".
+ * dropout: Dropout probability. When set to 0., dropout is disabled.
+ * seed: The 1st part of a seed to initialize dropout.
+ * seed2: The 2nd part of a seed to initialize dropout.
+ * input: A 3-D tensor with the shape of [seq_length, batch_size, input_size].
+ * input_h: A 3-D tensor with the shape of [num_layer * dir, batch_size,
+ *     num_units].
+ * input_c: For LSTM, a 3-D tensor with the shape of
+ *     [num_layer * dir, batch, num_units]. For other models, it is ignored.
+ * params: A 1-D tensor that contains the weights and biases in an opaque layout.
+ *     The size must be created through CudnnRNNParamsSize, and initialized
+ *     separately. Note that they might not be compatible across different
+ *     generations. So it is a good idea to save and restore
+ * output: A 3-D tensor with the shape of [seq_length, batch_size,
+ *     dir * num_units].
+ * output_h: The same shape has input_h.
+ * output_c: The same shape as input_c for LSTM. An empty tensor for other models.
+ * output_backprop: A 3-D tensor with the same shape as output in the forward pass.
+ * output_h_backprop: A 3-D tensor with the same shape as output_h in the forward
+ *     pass.
+ * output_c_backprop: A 3-D tensor with the same shape as output_c in the forward
+ *     pass.
+ * reserve_space: The same reserve_space produced in the forward operation.
+ * host_reserved: The same host_reserved produced in the forward operation.
+ * input_backprop: The backprop to input in the forward pass. Has the same shape
+ *     as input.
+ * input_h_backprop: The backprop to input_h in the forward pass. Has the same
+ *     shape as input_h.
+ * input_c_backprop: The backprop to input_c in the forward pass. Has the same
+ *     shape as input_c.
+ * params_backprop: The backprop to the params buffer in the forward pass. Has the
+ *     same shape as params.
+ * 
+ * @param <T> data type for {@code inputBackprop()} output
+ */
+public final class CudnnRNNBackpropV2<T extends Number> extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.CudnnRNNBackpropV2}
+   */
+  public static class Options {
+    
+    /**
+     * @param rnnMode 
+     */
+    public Options rnnMode(String rnnMode) {
+      this.rnnMode = rnnMode;
+      return this;
+    }
+    
+    /**
+     * @param inputMode 
+     */
+    public Options inputMode(String inputMode) {
+      this.inputMode = inputMode;
+      return this;
+    }
+    
+    /**
+     * @param direction 
+     */
+    public Options direction(String direction) {
+      this.direction = direction;
+      return this;
+    }
+    
+    /**
+     * @param dropout 
+     */
+    public Options dropout(Float dropout) {
+      this.dropout = dropout;
+      return this;
+    }
+    
+    /**
+     * @param seed 
+     */
+    public Options seed(Long seed) {
+      this.seed = seed;
+      return this;
+    }
+    
+    /**
+     * @param seed2 
+     */
+    public Options seed2(Long seed2) {
+      this.seed2 = seed2;
+      return this;
+    }
+    
+    private String rnnMode;
+    private String inputMode;
+    private String direction;
+    private Float dropout;
+    private Long seed;
+    private Long seed2;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new CudnnRNNBackpropV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param inputH 
+   * @param inputC 
+   * @param params 
+   * @param output 
+   * @param outputH 
+   * @param outputC 
+   * @param outputBackprop 
+   * @param outputHBackprop 
+   * @param outputCBackprop 
+   * @param reserveSpace 
+   * @param hostReserved 
+   * @param options carries optional attributes values
+   * @return a new instance of CudnnRNNBackpropV2
+   */
+  public static <T extends Number> CudnnRNNBackpropV2<T> create(Scope scope, Operand<T> input, Operand<T> inputH, Operand<T> inputC, Operand<T> params, Operand<T> output, Operand<T> outputH, Operand<T> outputC, Operand<T> outputBackprop, Operand<T> outputHBackprop, Operand<T> outputCBackprop, Operand<T> reserveSpace, Operand<?> hostReserved, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("CudnnRNNBackpropV2", scope.makeOpName("CudnnRNNBackpropV2"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(inputH.asOutput());
+    opBuilder.addInput(inputC.asOutput());
+    opBuilder.addInput(params.asOutput());
+    opBuilder.addInput(output.asOutput());
+    opBuilder.addInput(outputH.asOutput());
+    opBuilder.addInput(outputC.asOutput());
+    opBuilder.addInput(outputBackprop.asOutput());
+    opBuilder.addInput(outputHBackprop.asOutput());
+    opBuilder.addInput(outputCBackprop.asOutput());
+    opBuilder.addInput(reserveSpace.asOutput());
+    opBuilder.addInput(hostReserved.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.rnnMode != null) {
+          opBuilder.setAttr("rnn_mode", opts.rnnMode);
+        }
+        if (opts.inputMode != null) {
+          opBuilder.setAttr("input_mode", opts.inputMode);
+        }
+        if (opts.direction != null) {
+          opBuilder.setAttr("direction", opts.direction);
+        }
+        if (opts.dropout != null) {
+          opBuilder.setAttr("dropout", opts.dropout);
+        }
+        if (opts.seed != null) {
+          opBuilder.setAttr("seed", opts.seed);
+        }
+        if (opts.seed2 != null) {
+          opBuilder.setAttr("seed2", opts.seed2);
+        }
+      }
+    }
+    return new CudnnRNNBackpropV2<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param rnnMode 
+   */
+  public static Options rnnMode(String rnnMode) {
+    return new Options().rnnMode(rnnMode);
+  }
+  
+  /**
+   * @param inputMode 
+   */
+  public static Options inputMode(String inputMode) {
+    return new Options().inputMode(inputMode);
+  }
+  
+  /**
+   * @param direction 
+   */
+  public static Options direction(String direction) {
+    return new Options().direction(direction);
+  }
+  
+  /**
+   * @param dropout 
+   */
+  public static Options dropout(Float dropout) {
+    return new Options().dropout(dropout);
+  }
+  
+  /**
+   * @param seed 
+   */
+  public static Options seed(Long seed) {
+    return new Options().seed(seed);
+  }
+  
+  /**
+   * @param seed2 
+   */
+  public static Options seed2(Long seed2) {
+    return new Options().seed2(seed2);
+  }
+  
+  /**
+   */
+  public Output<T> inputBackprop() {
+    return inputBackprop;
+  }
+  
+  /**
+   */
+  public Output<T> inputHBackprop() {
+    return inputHBackprop;
+  }
+  
+  /**
+   */
+  public Output<T> inputCBackprop() {
+    return inputCBackprop;
+  }
+  
+  /**
+   */
+  public Output<T> paramsBackprop() {
+    return paramsBackprop;
+  }
+  
+  private Output<T> inputBackprop;
+  private Output<T> inputHBackprop;
+  private Output<T> inputCBackprop;
+  private Output<T> paramsBackprop;
+  
+  private CudnnRNNBackpropV2(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    inputBackprop = operation.output(outputIdx++);
+    inputHBackprop = operation.output(outputIdx++);
+    inputCBackprop = operation.output(outputIdx++);
+    paramsBackprop = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/CudnnRNNCanonicalToParams.java java-ops/org/tensorflow/op/core/CudnnRNNCanonicalToParams.java
--- java/org/tensorflow/op/core/CudnnRNNCanonicalToParams.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/CudnnRNNCanonicalToParams.java	2018-10-16 20:18:38.233432380 +0900
@@ -0,0 +1,235 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Converts CudnnRNN params from canonical form to usable form.
+ * <p>
+ * Writes a set of weights into the opaque params buffer so they can be used in
+ * upcoming training or inferences.
+ * <p>
+ * Note that the params buffer may not be compatible across different GPUs. So any
+ * save and restoration should be converted to and from the canonical weights and
+ * biases.
+ * <p>
+ * num_layers: Specifies the number of layers in the RNN model.
+ * num_units: Specifies the size of the hidden state.
+ * input_size: Specifies the size of the input state.
+ * weights: the canonical form of weights that can be used for saving
+ *     and restoration. They are more likely to be compatible across different
+ *     generations.
+ * biases: the canonical form of biases that can be used for saving
+ *     and restoration. They are more likely to be compatible across different
+ *     generations.
+ * num_params: number of parameter sets for all layers.
+ *     Each layer may contain multiple parameter sets, with each set consisting of
+ *     a weight matrix and a bias vector.
+ * rnn_mode: Indicates the type of the RNN model.
+ * input_mode: Indicate whether there is a linear projection between the input and
+ *     The actual computation before the first layer. 'skip_input' is only allowed
+ *     when input_size == num_units; 'auto_select' implies 'skip_input' when
+ *     input_size == num_units; otherwise, it implies 'linear_input'.
+ * direction: Indicates whether a bidirectional model will be used.
+ *     dir = (direction == bidirectional) ? 2 : 1
+ * dropout: dropout probability. When set to 0., dropout is disabled.
+ * seed: the 1st part of a seed to initialize dropout.
+ * seed2: the 2nd part of a seed to initialize dropout.
+ * 
+ * @param <T> data type for {@code params()} output
+ */
+@Operator
+public final class CudnnRNNCanonicalToParams<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.CudnnRNNCanonicalToParams}
+   */
+  public static class Options {
+    
+    /**
+     * @param rnnMode 
+     */
+    public Options rnnMode(String rnnMode) {
+      this.rnnMode = rnnMode;
+      return this;
+    }
+    
+    /**
+     * @param inputMode 
+     */
+    public Options inputMode(String inputMode) {
+      this.inputMode = inputMode;
+      return this;
+    }
+    
+    /**
+     * @param direction 
+     */
+    public Options direction(String direction) {
+      this.direction = direction;
+      return this;
+    }
+    
+    /**
+     * @param dropout 
+     */
+    public Options dropout(Float dropout) {
+      this.dropout = dropout;
+      return this;
+    }
+    
+    /**
+     * @param seed 
+     */
+    public Options seed(Long seed) {
+      this.seed = seed;
+      return this;
+    }
+    
+    /**
+     * @param seed2 
+     */
+    public Options seed2(Long seed2) {
+      this.seed2 = seed2;
+      return this;
+    }
+    
+    private String rnnMode;
+    private String inputMode;
+    private String direction;
+    private Float dropout;
+    private Long seed;
+    private Long seed2;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new CudnnRNNCanonicalToParams operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param numLayers 
+   * @param numUnits 
+   * @param inputSize 
+   * @param weights 
+   * @param biases 
+   * @param options carries optional attributes values
+   * @return a new instance of CudnnRNNCanonicalToParams
+   */
+  public static <T extends Number> CudnnRNNCanonicalToParams<T> create(Scope scope, Operand<Integer> numLayers, Operand<Integer> numUnits, Operand<Integer> inputSize, Operand<T> weights, Iterable<Operand<T>> biases, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("CudnnRNNCanonicalToParams", scope.makeOpName("CudnnRNNCanonicalToParams"));
+    opBuilder.addInput(numLayers.asOutput());
+    opBuilder.addInput(numUnits.asOutput());
+    opBuilder.addInput(inputSize.asOutput());
+    opBuilder.addInput(weights.asOutput());
+    opBuilder.addInputList(Operands.asOutputs(biases));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.rnnMode != null) {
+          opBuilder.setAttr("rnn_mode", opts.rnnMode);
+        }
+        if (opts.inputMode != null) {
+          opBuilder.setAttr("input_mode", opts.inputMode);
+        }
+        if (opts.direction != null) {
+          opBuilder.setAttr("direction", opts.direction);
+        }
+        if (opts.dropout != null) {
+          opBuilder.setAttr("dropout", opts.dropout);
+        }
+        if (opts.seed != null) {
+          opBuilder.setAttr("seed", opts.seed);
+        }
+        if (opts.seed2 != null) {
+          opBuilder.setAttr("seed2", opts.seed2);
+        }
+      }
+    }
+    return new CudnnRNNCanonicalToParams<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param rnnMode 
+   */
+  public static Options rnnMode(String rnnMode) {
+    return new Options().rnnMode(rnnMode);
+  }
+  
+  /**
+   * @param inputMode 
+   */
+  public static Options inputMode(String inputMode) {
+    return new Options().inputMode(inputMode);
+  }
+  
+  /**
+   * @param direction 
+   */
+  public static Options direction(String direction) {
+    return new Options().direction(direction);
+  }
+  
+  /**
+   * @param dropout 
+   */
+  public static Options dropout(Float dropout) {
+    return new Options().dropout(dropout);
+  }
+  
+  /**
+   * @param seed 
+   */
+  public static Options seed(Long seed) {
+    return new Options().seed(seed);
+  }
+  
+  /**
+   * @param seed2 
+   */
+  public static Options seed2(Long seed2) {
+    return new Options().seed2(seed2);
+  }
+  
+  /**
+   */
+  public Output<T> params() {
+    return params;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return params;
+  }
+  
+  private Output<T> params;
+  
+  private CudnnRNNCanonicalToParams(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    params = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/CudnnRNN.java java-ops/org/tensorflow/op/core/CudnnRNN.java
--- java/org/tensorflow/op/core/CudnnRNN.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/CudnnRNN.java	2018-10-16 20:18:38.230432382 +0900
@@ -0,0 +1,271 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * A RNN backed by cuDNN.
+ * <p>
+ * Computes the RNN from the input and initial states, with respect to the params
+ * buffer.
+ * <p>
+ * rnn_mode: Indicates the type of the RNN model.
+ * input_mode: Indicate whether there is a linear projection between the input and
+ *   the actual computation before the first layer. 'skip_input' is only allowed
+ *   when input_size == num_units; 'auto_select' implies 'skip_input' when
+ *   input_size == num_units; otherwise, it implies 'linear_input'.
+ * direction: Indicates whether a bidirectional model will be used. Should be
+ *   "unidirectional" or "bidirectional".
+ * dropout: Dropout probability. When set to 0., dropout is disabled.
+ * seed: The 1st part of a seed to initialize dropout.
+ * seed2: The 2nd part of a seed to initialize dropout.
+ * input: A 3-D tensor with the shape of [seq_length, batch_size, input_size].
+ * input_h: A 3-D tensor with the shape of [num_layer * dir, batch_size,
+ *     num_units].
+ * input_c: For LSTM, a 3-D tensor with the shape of
+ *     [num_layer * dir, batch, num_units]. For other models, it is ignored.
+ * params: A 1-D tensor that contains the weights and biases in an opaque layout.
+ *     The size must be created through CudnnRNNParamsSize, and initialized
+ *     separately. Note that they might not be compatible across different
+ *     generations. So it is a good idea to save and restore
+ * output: A 3-D tensor with the shape of [seq_length, batch_size,
+ *     dir * num_units].
+ * output_h: The same shape has input_h.
+ * output_c: The same shape as input_c for LSTM. An empty tensor for other models.
+ * is_training: Indicates whether this operation is used for inferenece or
+ *   training.
+ * reserve_space: An opaque tensor that can be used in backprop calculation. It
+ *   is only produced if is_training is false.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class CudnnRNN<T extends Number> extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.CudnnRNN}
+   */
+  public static class Options {
+    
+    /**
+     * @param rnnMode 
+     */
+    public Options rnnMode(String rnnMode) {
+      this.rnnMode = rnnMode;
+      return this;
+    }
+    
+    /**
+     * @param inputMode 
+     */
+    public Options inputMode(String inputMode) {
+      this.inputMode = inputMode;
+      return this;
+    }
+    
+    /**
+     * @param direction 
+     */
+    public Options direction(String direction) {
+      this.direction = direction;
+      return this;
+    }
+    
+    /**
+     * @param dropout 
+     */
+    public Options dropout(Float dropout) {
+      this.dropout = dropout;
+      return this;
+    }
+    
+    /**
+     * @param seed 
+     */
+    public Options seed(Long seed) {
+      this.seed = seed;
+      return this;
+    }
+    
+    /**
+     * @param seed2 
+     */
+    public Options seed2(Long seed2) {
+      this.seed2 = seed2;
+      return this;
+    }
+    
+    /**
+     * @param isTraining 
+     */
+    public Options isTraining(Boolean isTraining) {
+      this.isTraining = isTraining;
+      return this;
+    }
+    
+    private String rnnMode;
+    private String inputMode;
+    private String direction;
+    private Float dropout;
+    private Long seed;
+    private Long seed2;
+    private Boolean isTraining;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new CudnnRNN operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param inputH 
+   * @param inputC 
+   * @param params 
+   * @param options carries optional attributes values
+   * @return a new instance of CudnnRNN
+   */
+  public static <T extends Number> CudnnRNN<T> create(Scope scope, Operand<T> input, Operand<T> inputH, Operand<T> inputC, Operand<T> params, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("CudnnRNN", scope.makeOpName("CudnnRNN"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(inputH.asOutput());
+    opBuilder.addInput(inputC.asOutput());
+    opBuilder.addInput(params.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.rnnMode != null) {
+          opBuilder.setAttr("rnn_mode", opts.rnnMode);
+        }
+        if (opts.inputMode != null) {
+          opBuilder.setAttr("input_mode", opts.inputMode);
+        }
+        if (opts.direction != null) {
+          opBuilder.setAttr("direction", opts.direction);
+        }
+        if (opts.dropout != null) {
+          opBuilder.setAttr("dropout", opts.dropout);
+        }
+        if (opts.seed != null) {
+          opBuilder.setAttr("seed", opts.seed);
+        }
+        if (opts.seed2 != null) {
+          opBuilder.setAttr("seed2", opts.seed2);
+        }
+        if (opts.isTraining != null) {
+          opBuilder.setAttr("is_training", opts.isTraining);
+        }
+      }
+    }
+    return new CudnnRNN<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param rnnMode 
+   */
+  public static Options rnnMode(String rnnMode) {
+    return new Options().rnnMode(rnnMode);
+  }
+  
+  /**
+   * @param inputMode 
+   */
+  public static Options inputMode(String inputMode) {
+    return new Options().inputMode(inputMode);
+  }
+  
+  /**
+   * @param direction 
+   */
+  public static Options direction(String direction) {
+    return new Options().direction(direction);
+  }
+  
+  /**
+   * @param dropout 
+   */
+  public static Options dropout(Float dropout) {
+    return new Options().dropout(dropout);
+  }
+  
+  /**
+   * @param seed 
+   */
+  public static Options seed(Long seed) {
+    return new Options().seed(seed);
+  }
+  
+  /**
+   * @param seed2 
+   */
+  public static Options seed2(Long seed2) {
+    return new Options().seed2(seed2);
+  }
+  
+  /**
+   * @param isTraining 
+   */
+  public static Options isTraining(Boolean isTraining) {
+    return new Options().isTraining(isTraining);
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  /**
+   */
+  public Output<T> outputH() {
+    return outputH;
+  }
+  
+  /**
+   */
+  public Output<T> outputC() {
+    return outputC;
+  }
+  
+  /**
+   */
+  public Output<T> reserveSpace() {
+    return reserveSpace;
+  }
+  
+  private Output<T> output;
+  private Output<T> outputH;
+  private Output<T> outputC;
+  private Output<T> reserveSpace;
+  
+  private CudnnRNN(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+    outputH = operation.output(outputIdx++);
+    outputC = operation.output(outputIdx++);
+    reserveSpace = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/CudnnRNNParamsSize.java java-ops/org/tensorflow/op/core/CudnnRNNParamsSize.java
--- java/org/tensorflow/op/core/CudnnRNNParamsSize.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/CudnnRNNParamsSize.java	2018-10-16 20:18:38.234432379 +0900
@@ -0,0 +1,227 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes size of weights that can be used by a Cudnn RNN model.
+ * <p>
+ * Return the params size that can be used by the Cudnn RNN model. Subsequent
+ * weight allocation and initialization should use this size.
+ * <p>
+ * num_layers: Specifies the number of layers in the RNN model.
+ * num_units: Specifies the size of the hidden state.
+ * input_size: Specifies the size of the input state.
+ * rnn_mode: Indicates the type of the RNN model.
+ * input_mode: Indicate whether there is a linear projection between the input and
+ *   The actual computation before the first layer. 'skip_input' is only allowed
+ *   when input_size == num_units; 'auto_select' implies 'skip_input' when
+ *   input_size == num_units; otherwise, it implies 'linear_input'.
+ * direction: Indicates whether a bidirectional model will be used.
+ *   dir = (direction == bidirectional) ? 2 : 1
+ * dropout: dropout probability. When set to 0., dropout is disabled.
+ * seed: the 1st part of a seed to initialize dropout.
+ * seed2: the 2nd part of a seed to initialize dropout.
+ * params_size: The size of the params buffer that should be allocated and
+ *   initialized for this RNN model. Note that this params buffer may not be
+ *   compatible across GPUs. Please use CudnnRNNParamsWeights and
+ *   CudnnRNNParamsBiases to save and restore them in a way that is compatible
+ *   across different runs.
+ * 
+ * @param <U> data type for {@code paramsSize()} output
+ */
+@Operator
+public final class CudnnRNNParamsSize<U extends Number> extends PrimitiveOp implements Operand<U> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.CudnnRNNParamsSize}
+   */
+  public static class Options {
+    
+    /**
+     * @param rnnMode 
+     */
+    public Options rnnMode(String rnnMode) {
+      this.rnnMode = rnnMode;
+      return this;
+    }
+    
+    /**
+     * @param inputMode 
+     */
+    public Options inputMode(String inputMode) {
+      this.inputMode = inputMode;
+      return this;
+    }
+    
+    /**
+     * @param direction 
+     */
+    public Options direction(String direction) {
+      this.direction = direction;
+      return this;
+    }
+    
+    /**
+     * @param dropout 
+     */
+    public Options dropout(Float dropout) {
+      this.dropout = dropout;
+      return this;
+    }
+    
+    /**
+     * @param seed 
+     */
+    public Options seed(Long seed) {
+      this.seed = seed;
+      return this;
+    }
+    
+    /**
+     * @param seed2 
+     */
+    public Options seed2(Long seed2) {
+      this.seed2 = seed2;
+      return this;
+    }
+    
+    private String rnnMode;
+    private String inputMode;
+    private String direction;
+    private Float dropout;
+    private Long seed;
+    private Long seed2;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new CudnnRNNParamsSize operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param numLayers 
+   * @param numUnits 
+   * @param inputSize 
+   * @param T 
+   * @param S 
+   * @param options carries optional attributes values
+   * @return a new instance of CudnnRNNParamsSize
+   */
+  public static <U extends Number, T extends Number> CudnnRNNParamsSize<U> create(Scope scope, Operand<Integer> numLayers, Operand<Integer> numUnits, Operand<Integer> inputSize, Class<T> T, Class<U> S, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("CudnnRNNParamsSize", scope.makeOpName("CudnnRNNParamsSize"));
+    opBuilder.addInput(numLayers.asOutput());
+    opBuilder.addInput(numUnits.asOutput());
+    opBuilder.addInput(inputSize.asOutput());
+    opBuilder.setAttr("T", DataType.fromClass(T));
+    opBuilder.setAttr("S", DataType.fromClass(S));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.rnnMode != null) {
+          opBuilder.setAttr("rnn_mode", opts.rnnMode);
+        }
+        if (opts.inputMode != null) {
+          opBuilder.setAttr("input_mode", opts.inputMode);
+        }
+        if (opts.direction != null) {
+          opBuilder.setAttr("direction", opts.direction);
+        }
+        if (opts.dropout != null) {
+          opBuilder.setAttr("dropout", opts.dropout);
+        }
+        if (opts.seed != null) {
+          opBuilder.setAttr("seed", opts.seed);
+        }
+        if (opts.seed2 != null) {
+          opBuilder.setAttr("seed2", opts.seed2);
+        }
+      }
+    }
+    return new CudnnRNNParamsSize<U>(opBuilder.build());
+  }
+  
+  /**
+   * @param rnnMode 
+   */
+  public static Options rnnMode(String rnnMode) {
+    return new Options().rnnMode(rnnMode);
+  }
+  
+  /**
+   * @param inputMode 
+   */
+  public static Options inputMode(String inputMode) {
+    return new Options().inputMode(inputMode);
+  }
+  
+  /**
+   * @param direction 
+   */
+  public static Options direction(String direction) {
+    return new Options().direction(direction);
+  }
+  
+  /**
+   * @param dropout 
+   */
+  public static Options dropout(Float dropout) {
+    return new Options().dropout(dropout);
+  }
+  
+  /**
+   * @param seed 
+   */
+  public static Options seed(Long seed) {
+    return new Options().seed(seed);
+  }
+  
+  /**
+   * @param seed2 
+   */
+  public static Options seed2(Long seed2) {
+    return new Options().seed2(seed2);
+  }
+  
+  /**
+   */
+  public Output<U> paramsSize() {
+    return paramsSize;
+  }
+  
+  @Override
+  public Output<U> asOutput() {
+    return paramsSize;
+  }
+  
+  private Output<U> paramsSize;
+  
+  private CudnnRNNParamsSize(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    paramsSize = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/CudnnRNNParamsToCanonical.java java-ops/org/tensorflow/op/core/CudnnRNNParamsToCanonical.java
--- java/org/tensorflow/op/core/CudnnRNNParamsToCanonical.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/CudnnRNNParamsToCanonical.java	2018-10-16 20:18:38.234432379 +0900
@@ -0,0 +1,244 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Retrieves CudnnRNN params in canonical form.
+ * <p>
+ * Retrieves a set of weights from the opaque params buffer that can be saved and
+ * restored in a way compatible with future runs.
+ * <p>
+ * Note that the params buffer may not be compatible across different GPUs. So any
+ * save and restoration should be converted to and from the canonical weights and
+ * biases.
+ * <p>
+ * num_layers: Specifies the number of layers in the RNN model.
+ * num_units: Specifies the size of the hidden state.
+ * input_size: Specifies the size of the input state.
+ * num_params: number of parameter sets for all layers.
+ *     Each layer may contain multiple parameter sets, with each set consisting of
+ *     a weight matrix and a bias vector.
+ * weights: the canonical form of weights that can be used for saving
+ *     and restoration. They are more likely to be compatible across different
+ *     generations.
+ * biases: the canonical form of biases that can be used for saving
+ *     and restoration. They are more likely to be compatible across different
+ *     generations.
+ * rnn_mode: Indicates the type of the RNN model.
+ * input_mode: Indicate whether there is a linear projection between the input and
+ *     The actual computation before the first layer. 'skip_input' is only allowed
+ *     when input_size == num_units; 'auto_select' implies 'skip_input' when
+ *     input_size == num_units; otherwise, it implies 'linear_input'.
+ * direction: Indicates whether a bidirectional model will be used.
+ *     dir = (direction == bidirectional) ? 2 : 1
+ * dropout: dropout probability. When set to 0., dropout is disabled.
+ * seed: the 1st part of a seed to initialize dropout.
+ * seed2: the 2nd part of a seed to initialize dropout.
+ * 
+ * @param <T> data type for {@code weights()} output
+ */
+@Operator
+public final class CudnnRNNParamsToCanonical<T extends Number> extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.CudnnRNNParamsToCanonical}
+   */
+  public static class Options {
+    
+    /**
+     * @param rnnMode 
+     */
+    public Options rnnMode(String rnnMode) {
+      this.rnnMode = rnnMode;
+      return this;
+    }
+    
+    /**
+     * @param inputMode 
+     */
+    public Options inputMode(String inputMode) {
+      this.inputMode = inputMode;
+      return this;
+    }
+    
+    /**
+     * @param direction 
+     */
+    public Options direction(String direction) {
+      this.direction = direction;
+      return this;
+    }
+    
+    /**
+     * @param dropout 
+     */
+    public Options dropout(Float dropout) {
+      this.dropout = dropout;
+      return this;
+    }
+    
+    /**
+     * @param seed 
+     */
+    public Options seed(Long seed) {
+      this.seed = seed;
+      return this;
+    }
+    
+    /**
+     * @param seed2 
+     */
+    public Options seed2(Long seed2) {
+      this.seed2 = seed2;
+      return this;
+    }
+    
+    private String rnnMode;
+    private String inputMode;
+    private String direction;
+    private Float dropout;
+    private Long seed;
+    private Long seed2;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new CudnnRNNParamsToCanonical operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param numLayers 
+   * @param numUnits 
+   * @param inputSize 
+   * @param params 
+   * @param numParams 
+   * @param options carries optional attributes values
+   * @return a new instance of CudnnRNNParamsToCanonical
+   */
+  public static <T extends Number> CudnnRNNParamsToCanonical<T> create(Scope scope, Operand<Integer> numLayers, Operand<Integer> numUnits, Operand<Integer> inputSize, Operand<T> params, Long numParams, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("CudnnRNNParamsToCanonical", scope.makeOpName("CudnnRNNParamsToCanonical"));
+    opBuilder.addInput(numLayers.asOutput());
+    opBuilder.addInput(numUnits.asOutput());
+    opBuilder.addInput(inputSize.asOutput());
+    opBuilder.addInput(params.asOutput());
+    opBuilder.setAttr("num_params", numParams);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.rnnMode != null) {
+          opBuilder.setAttr("rnn_mode", opts.rnnMode);
+        }
+        if (opts.inputMode != null) {
+          opBuilder.setAttr("input_mode", opts.inputMode);
+        }
+        if (opts.direction != null) {
+          opBuilder.setAttr("direction", opts.direction);
+        }
+        if (opts.dropout != null) {
+          opBuilder.setAttr("dropout", opts.dropout);
+        }
+        if (opts.seed != null) {
+          opBuilder.setAttr("seed", opts.seed);
+        }
+        if (opts.seed2 != null) {
+          opBuilder.setAttr("seed2", opts.seed2);
+        }
+      }
+    }
+    return new CudnnRNNParamsToCanonical<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param rnnMode 
+   */
+  public static Options rnnMode(String rnnMode) {
+    return new Options().rnnMode(rnnMode);
+  }
+  
+  /**
+   * @param inputMode 
+   */
+  public static Options inputMode(String inputMode) {
+    return new Options().inputMode(inputMode);
+  }
+  
+  /**
+   * @param direction 
+   */
+  public static Options direction(String direction) {
+    return new Options().direction(direction);
+  }
+  
+  /**
+   * @param dropout 
+   */
+  public static Options dropout(Float dropout) {
+    return new Options().dropout(dropout);
+  }
+  
+  /**
+   * @param seed 
+   */
+  public static Options seed(Long seed) {
+    return new Options().seed(seed);
+  }
+  
+  /**
+   * @param seed2 
+   */
+  public static Options seed2(Long seed2) {
+    return new Options().seed2(seed2);
+  }
+  
+  /**
+   */
+  public List<Output<T>> weights() {
+    return weights;
+  }
+  
+  /**
+   */
+  public List<Output<T>> biases() {
+    return biases;
+  }
+  
+  private List<Output<T>> weights;
+  private List<Output<T>> biases;
+  
+  @SuppressWarnings("unchecked")
+  private CudnnRNNParamsToCanonical(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    int weightsLength = operation.outputListLength("weights");
+    weights = Arrays.asList((Output<T>[])operation.outputList(outputIdx, weightsLength));
+    outputIdx += weightsLength;
+    int biasesLength = operation.outputListLength("biases");
+    biases = Arrays.asList((Output<T>[])operation.outputList(outputIdx, biasesLength));
+    outputIdx += biasesLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/CudnnRNNV2.java java-ops/org/tensorflow/op/core/CudnnRNNV2.java
--- java/org/tensorflow/op/core/CudnnRNNV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/CudnnRNNV2.java	2018-10-16 20:18:38.235432379 +0900
@@ -0,0 +1,280 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * A RNN backed by cuDNN.
+ * <p>
+ * Computes the RNN from the input and initial states, with respect to the params
+ * buffer. Produces one extra output "host_reserved" than CudnnRNN.
+ * <p>
+ * rnn_mode: Indicates the type of the RNN model.
+ * input_mode: Indicates whether there is a linear projection between the input and
+ *   the actual computation before the first layer. 'skip_input' is only allowed
+ *   when input_size == num_units; 'auto_select' implies 'skip_input' when
+ *   input_size == num_units; otherwise, it implies 'linear_input'.
+ * direction: Indicates whether a bidirectional model will be used. Should be
+ *   "unidirectional" or "bidirectional".
+ * dropout: Dropout probability. When set to 0., dropout is disabled.
+ * seed: The 1st part of a seed to initialize dropout.
+ * seed2: The 2nd part of a seed to initialize dropout.
+ * input: A 3-D tensor with the shape of [seq_length, batch_size, input_size].
+ * input_h: A 3-D tensor with the shape of [num_layer * dir, batch_size,
+ *     num_units].
+ * input_c: For LSTM, a 3-D tensor with the shape of
+ *     [num_layer * dir, batch, num_units]. For other models, it is ignored.
+ * params: A 1-D tensor that contains the weights and biases in an opaque layout.
+ *     The size must be created through CudnnRNNParamsSize, and initialized
+ *     separately. Note that they might not be compatible across different
+ *     generations. So it is a good idea to save and restore
+ * output: A 3-D tensor with the shape of [seq_length, batch_size,
+ *     dir * num_units].
+ * output_h: The same shape has input_h.
+ * output_c: The same shape as input_c for LSTM. An empty tensor for other models.
+ * is_training: Indicates whether this operation is used for inferenece or
+ *   training.
+ * reserve_space: An opaque tensor that can be used in backprop calculation. It
+ *   is only produced if is_training is true.
+ * host_reserved: An opaque tensor that can be used in backprop calculation. It is
+ *   only produced if is_training is true. It is output on host memory rather than
+ *   device memory.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+public final class CudnnRNNV2<T extends Number> extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.CudnnRNNV2}
+   */
+  public static class Options {
+    
+    /**
+     * @param rnnMode 
+     */
+    public Options rnnMode(String rnnMode) {
+      this.rnnMode = rnnMode;
+      return this;
+    }
+    
+    /**
+     * @param inputMode 
+     */
+    public Options inputMode(String inputMode) {
+      this.inputMode = inputMode;
+      return this;
+    }
+    
+    /**
+     * @param direction 
+     */
+    public Options direction(String direction) {
+      this.direction = direction;
+      return this;
+    }
+    
+    /**
+     * @param dropout 
+     */
+    public Options dropout(Float dropout) {
+      this.dropout = dropout;
+      return this;
+    }
+    
+    /**
+     * @param seed 
+     */
+    public Options seed(Long seed) {
+      this.seed = seed;
+      return this;
+    }
+    
+    /**
+     * @param seed2 
+     */
+    public Options seed2(Long seed2) {
+      this.seed2 = seed2;
+      return this;
+    }
+    
+    /**
+     * @param isTraining 
+     */
+    public Options isTraining(Boolean isTraining) {
+      this.isTraining = isTraining;
+      return this;
+    }
+    
+    private String rnnMode;
+    private String inputMode;
+    private String direction;
+    private Float dropout;
+    private Long seed;
+    private Long seed2;
+    private Boolean isTraining;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new CudnnRNNV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param inputH 
+   * @param inputC 
+   * @param params 
+   * @param options carries optional attributes values
+   * @return a new instance of CudnnRNNV2
+   */
+  public static <T extends Number> CudnnRNNV2<T> create(Scope scope, Operand<T> input, Operand<T> inputH, Operand<T> inputC, Operand<T> params, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("CudnnRNNV2", scope.makeOpName("CudnnRNNV2"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(inputH.asOutput());
+    opBuilder.addInput(inputC.asOutput());
+    opBuilder.addInput(params.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.rnnMode != null) {
+          opBuilder.setAttr("rnn_mode", opts.rnnMode);
+        }
+        if (opts.inputMode != null) {
+          opBuilder.setAttr("input_mode", opts.inputMode);
+        }
+        if (opts.direction != null) {
+          opBuilder.setAttr("direction", opts.direction);
+        }
+        if (opts.dropout != null) {
+          opBuilder.setAttr("dropout", opts.dropout);
+        }
+        if (opts.seed != null) {
+          opBuilder.setAttr("seed", opts.seed);
+        }
+        if (opts.seed2 != null) {
+          opBuilder.setAttr("seed2", opts.seed2);
+        }
+        if (opts.isTraining != null) {
+          opBuilder.setAttr("is_training", opts.isTraining);
+        }
+      }
+    }
+    return new CudnnRNNV2<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param rnnMode 
+   */
+  public static Options rnnMode(String rnnMode) {
+    return new Options().rnnMode(rnnMode);
+  }
+  
+  /**
+   * @param inputMode 
+   */
+  public static Options inputMode(String inputMode) {
+    return new Options().inputMode(inputMode);
+  }
+  
+  /**
+   * @param direction 
+   */
+  public static Options direction(String direction) {
+    return new Options().direction(direction);
+  }
+  
+  /**
+   * @param dropout 
+   */
+  public static Options dropout(Float dropout) {
+    return new Options().dropout(dropout);
+  }
+  
+  /**
+   * @param seed 
+   */
+  public static Options seed(Long seed) {
+    return new Options().seed(seed);
+  }
+  
+  /**
+   * @param seed2 
+   */
+  public static Options seed2(Long seed2) {
+    return new Options().seed2(seed2);
+  }
+  
+  /**
+   * @param isTraining 
+   */
+  public static Options isTraining(Boolean isTraining) {
+    return new Options().isTraining(isTraining);
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  /**
+   */
+  public Output<T> outputH() {
+    return outputH;
+  }
+  
+  /**
+   */
+  public Output<T> outputC() {
+    return outputC;
+  }
+  
+  /**
+   */
+  public Output<T> reserveSpace() {
+    return reserveSpace;
+  }
+  
+  /**
+   */
+  public Output<?> hostReserved() {
+    return hostReserved;
+  }
+  
+  private Output<T> output;
+  private Output<T> outputH;
+  private Output<T> outputC;
+  private Output<T> reserveSpace;
+  private Output<?> hostReserved;
+  
+  private CudnnRNNV2(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+    outputH = operation.output(outputIdx++);
+    outputC = operation.output(outputIdx++);
+    reserveSpace = operation.output(outputIdx++);
+    hostReserved = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Cumprod.java java-ops/org/tensorflow/op/core/Cumprod.java
--- java/org/tensorflow/op/core/Cumprod.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Cumprod.java	2018-10-16 20:18:38.236432378 +0900
@@ -0,0 +1,148 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Compute the cumulative product of the tensor `x` along `axis`.
+ * <p>
+ * By default, this op performs an inclusive cumprod, which means that the first
+ * element of the input is identical to the first element of the output:
+ * <pre>{@code
+ * tf.cumprod([a, b, c])  # => [a, a * b, a * b * c]
+ * }</pre>
+ * By setting the `exclusive` kwarg to `True`, an exclusive cumprod is
+ * performed instead:
+ * <pre>{@code
+ * tf.cumprod([a, b, c], exclusive=True)  # => [1, a, a * b]
+ * }</pre>
+ * By setting the `reverse` kwarg to `True`, the cumprod is performed in the
+ * opposite direction:
+ * <pre>{@code
+ * tf.cumprod([a, b, c], reverse=True)  # => [a * b * c, b * c, c]
+ * }</pre>
+ * This is more efficient than using separate `tf.reverse` ops.
+ * <p>
+ * The `reverse` and `exclusive` kwargs can also be combined:
+ * <pre>{@code
+ * tf.cumprod([a, b, c], exclusive=True, reverse=True)  # => [b * c, c, 1]
+ * }</pre>
+ * 
+ * 
+ * @param <T> data type for {@code out()} output
+ */
+@Operator
+public final class Cumprod<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Cumprod}
+   */
+  public static class Options {
+    
+    /**
+     * @param exclusive If `True`, perform exclusive cumprod.
+     */
+    public Options exclusive(Boolean exclusive) {
+      this.exclusive = exclusive;
+      return this;
+    }
+    
+    /**
+     * @param reverse A `bool` (default: False).
+     */
+    public Options reverse(Boolean reverse) {
+      this.reverse = reverse;
+      return this;
+    }
+    
+    private Boolean exclusive;
+    private Boolean reverse;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Cumprod operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x A `Tensor`. Must be one of the following types: `float32`, `float64`,
+   * `int64`, `int32`, `uint8`, `uint16`, `int16`, `int8`, `complex64`,
+   * `complex128`, `qint8`, `quint8`, `qint32`, `half`.
+   * @param axis A `Tensor` of type `int32` (default: 0). Must be in the range
+   * `[-rank(x), rank(x))`.
+   * @param options carries optional attributes values
+   * @return a new instance of Cumprod
+   */
+  public static <T, U extends Number> Cumprod<T> create(Scope scope, Operand<T> x, Operand<U> axis, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Cumprod", scope.makeOpName("Cumprod"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(axis.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.exclusive != null) {
+          opBuilder.setAttr("exclusive", opts.exclusive);
+        }
+        if (opts.reverse != null) {
+          opBuilder.setAttr("reverse", opts.reverse);
+        }
+      }
+    }
+    return new Cumprod<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param exclusive If `True`, perform exclusive cumprod.
+   */
+  public static Options exclusive(Boolean exclusive) {
+    return new Options().exclusive(exclusive);
+  }
+  
+  /**
+   * @param reverse A `bool` (default: False).
+   */
+  public static Options reverse(Boolean reverse) {
+    return new Options().reverse(reverse);
+  }
+  
+  /**
+   */
+  public Output<T> out() {
+    return out;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return out;
+  }
+  
+  private Output<T> out;
+  
+  private Cumprod(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    out = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Cumsum.java java-ops/org/tensorflow/op/core/Cumsum.java
--- java/org/tensorflow/op/core/Cumsum.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Cumsum.java	2018-10-16 20:18:38.237432377 +0900
@@ -0,0 +1,148 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Compute the cumulative sum of the tensor `x` along `axis`.
+ * <p>
+ * By default, this op performs an inclusive cumsum, which means that the first
+ * element of the input is identical to the first element of the output:
+ * <pre>{@code
+ * tf.cumsum([a, b, c])  # => [a, a + b, a + b + c]
+ * }</pre>
+ * By setting the `exclusive` kwarg to `True`, an exclusive cumsum is
+ * performed instead:
+ * <pre>{@code
+ * tf.cumsum([a, b, c], exclusive=True)  # => [0, a, a + b]
+ * }</pre>
+ * By setting the `reverse` kwarg to `True`, the cumsum is performed in the
+ * opposite direction:
+ * <pre>{@code
+ * tf.cumsum([a, b, c], reverse=True)  # => [a + b + c, b + c, c]
+ * }</pre>
+ * This is more efficient than using separate `tf.reverse` ops.
+ * <p>
+ * The `reverse` and `exclusive` kwargs can also be combined:
+ * <pre>{@code
+ * tf.cumsum([a, b, c], exclusive=True, reverse=True)  # => [b + c, c, 0]
+ * }</pre>
+ * 
+ * 
+ * @param <T> data type for {@code out()} output
+ */
+@Operator
+public final class Cumsum<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Cumsum}
+   */
+  public static class Options {
+    
+    /**
+     * @param exclusive If `True`, perform exclusive cumsum.
+     */
+    public Options exclusive(Boolean exclusive) {
+      this.exclusive = exclusive;
+      return this;
+    }
+    
+    /**
+     * @param reverse A `bool` (default: False).
+     */
+    public Options reverse(Boolean reverse) {
+      this.reverse = reverse;
+      return this;
+    }
+    
+    private Boolean exclusive;
+    private Boolean reverse;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Cumsum operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x A `Tensor`. Must be one of the following types: `float32`, `float64`,
+   * `int64`, `int32`, `uint8`, `uint16`, `int16`, `int8`, `complex64`,
+   * `complex128`, `qint8`, `quint8`, `qint32`, `half`.
+   * @param axis A `Tensor` of type `int32` (default: 0). Must be in the range
+   * `[-rank(x), rank(x))`.
+   * @param options carries optional attributes values
+   * @return a new instance of Cumsum
+   */
+  public static <T, U extends Number> Cumsum<T> create(Scope scope, Operand<T> x, Operand<U> axis, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Cumsum", scope.makeOpName("Cumsum"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(axis.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.exclusive != null) {
+          opBuilder.setAttr("exclusive", opts.exclusive);
+        }
+        if (opts.reverse != null) {
+          opBuilder.setAttr("reverse", opts.reverse);
+        }
+      }
+    }
+    return new Cumsum<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param exclusive If `True`, perform exclusive cumsum.
+   */
+  public static Options exclusive(Boolean exclusive) {
+    return new Options().exclusive(exclusive);
+  }
+  
+  /**
+   * @param reverse A `bool` (default: False).
+   */
+  public static Options reverse(Boolean reverse) {
+    return new Options().reverse(reverse);
+  }
+  
+  /**
+   */
+  public Output<T> out() {
+    return out;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return out;
+  }
+  
+  private Output<T> out;
+  
+  private Cumsum(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    out = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/DataFormatDimMap.java java-ops/org/tensorflow/op/core/DataFormatDimMap.java
--- java/org/tensorflow/op/core/DataFormatDimMap.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/DataFormatDimMap.java	2018-10-16 20:18:38.237432377 +0900
@@ -0,0 +1,124 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns the dimension index in the destination data format given the one in
+ * <p>
+ * the source data format.
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class DataFormatDimMap<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.DataFormatDimMap}
+   */
+  public static class Options {
+    
+    /**
+     * @param srcFormat source data format.
+     */
+    public Options srcFormat(String srcFormat) {
+      this.srcFormat = srcFormat;
+      return this;
+    }
+    
+    /**
+     * @param dstFormat destination data format.
+     */
+    public Options dstFormat(String dstFormat) {
+      this.dstFormat = dstFormat;
+      return this;
+    }
+    
+    private String srcFormat;
+    private String dstFormat;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new DataFormatDimMap operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x A Tensor with each element as a dimension index in source data format.
+   * Must be in the range [-4, 4).
+   * @param options carries optional attributes values
+   * @return a new instance of DataFormatDimMap
+   */
+  public static <T extends Number> DataFormatDimMap<T> create(Scope scope, Operand<T> x, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("DataFormatDimMap", scope.makeOpName("DataFormatDimMap"));
+    opBuilder.addInput(x.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.srcFormat != null) {
+          opBuilder.setAttr("src_format", opts.srcFormat);
+        }
+        if (opts.dstFormat != null) {
+          opBuilder.setAttr("dst_format", opts.dstFormat);
+        }
+      }
+    }
+    return new DataFormatDimMap<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param srcFormat source data format.
+   */
+  public static Options srcFormat(String srcFormat) {
+    return new Options().srcFormat(srcFormat);
+  }
+  
+  /**
+   * @param dstFormat destination data format.
+   */
+  public static Options dstFormat(String dstFormat) {
+    return new Options().dstFormat(dstFormat);
+  }
+  
+  /**
+   * A Tensor with each element as a dimension index in destination data format.
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private DataFormatDimMap(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/DataFormatVecPermute.java java-ops/org/tensorflow/op/core/DataFormatVecPermute.java
--- java/org/tensorflow/op/core/DataFormatVecPermute.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/DataFormatVecPermute.java	2018-10-16 20:18:38.237432377 +0900
@@ -0,0 +1,123 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns the permuted vector/tensor in the destination data format given the
+ * <p>
+ * one in the source data format.
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class DataFormatVecPermute<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.DataFormatVecPermute}
+   */
+  public static class Options {
+    
+    /**
+     * @param srcFormat source data format.
+     */
+    public Options srcFormat(String srcFormat) {
+      this.srcFormat = srcFormat;
+      return this;
+    }
+    
+    /**
+     * @param dstFormat destination data format.
+     */
+    public Options dstFormat(String dstFormat) {
+      this.dstFormat = dstFormat;
+      return this;
+    }
+    
+    private String srcFormat;
+    private String dstFormat;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new DataFormatVecPermute operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x Vector of size 4 or Tensor of shape (4, 2) in source data format.
+   * @param options carries optional attributes values
+   * @return a new instance of DataFormatVecPermute
+   */
+  public static <T extends Number> DataFormatVecPermute<T> create(Scope scope, Operand<T> x, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("DataFormatVecPermute", scope.makeOpName("DataFormatVecPermute"));
+    opBuilder.addInput(x.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.srcFormat != null) {
+          opBuilder.setAttr("src_format", opts.srcFormat);
+        }
+        if (opts.dstFormat != null) {
+          opBuilder.setAttr("dst_format", opts.dstFormat);
+        }
+      }
+    }
+    return new DataFormatVecPermute<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param srcFormat source data format.
+   */
+  public static Options srcFormat(String srcFormat) {
+    return new Options().srcFormat(srcFormat);
+  }
+  
+  /**
+   * @param dstFormat destination data format.
+   */
+  public static Options dstFormat(String dstFormat) {
+    return new Options().dstFormat(dstFormat);
+  }
+  
+  /**
+   * Vector of size 4 or Tensor of shape (4, 2) in destination data format.
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private DataFormatVecPermute(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/DatasetToGraph.java java-ops/org/tensorflow/op/core/DatasetToGraph.java
--- java/org/tensorflow/op/core/DatasetToGraph.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/DatasetToGraph.java	2018-10-16 20:18:38.238432376 +0900
@@ -0,0 +1,66 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Returns a serialized GraphDef representing `input_dataset`.
+ * <p>
+ * Returns a graph representation for `input_dataset`.
+ */
+public final class DatasetToGraph extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Factory method to create a class to wrap a new DatasetToGraph operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputDataset A variant tensor representing the dataset to return the graph representation for.
+   * @return a new instance of DatasetToGraph
+   */
+  public static DatasetToGraph create(Scope scope, Operand<?> inputDataset) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("DatasetToGraph", scope.makeOpName("DatasetToGraph"));
+    opBuilder.addInput(inputDataset.asOutput());
+    return new DatasetToGraph(opBuilder.build());
+  }
+  
+  /**
+   * The graph representation of the dataset (as serialized GraphDef).
+   */
+  public Output<String> graph() {
+    return graph;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return graph;
+  }
+  
+  private Output<String> graph;
+  
+  private DatasetToGraph(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    graph = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/DatasetToSingleElement.java java-ops/org/tensorflow/op/core/DatasetToSingleElement.java
--- java/org/tensorflow/op/core/DatasetToSingleElement.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/DatasetToSingleElement.java	2018-10-16 20:18:38.238432376 +0900
@@ -0,0 +1,86 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.Iterator;
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Outputs the single element from the given dataset.
+ */
+@Operator
+public final class DatasetToSingleElement extends PrimitiveOp implements Iterable<Operand<Object>> {
+  
+  /**
+   * Factory method to create a class to wrap a new DatasetToSingleElement operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param dataset A handle to a dataset that contains a single element.
+   * @param outputTypes 
+   * @param outputShapes 
+   * @return a new instance of DatasetToSingleElement
+   */
+  public static DatasetToSingleElement create(Scope scope, Operand<?> dataset, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("DatasetToSingleElement", scope.makeOpName("DatasetToSingleElement"));
+    opBuilder.addInput(dataset.asOutput());
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new DatasetToSingleElement(opBuilder.build());
+  }
+  
+  /**
+   * The components of the single element of `input`.
+   */
+  public List<Output<?>> components() {
+    return components;
+  }
+  
+  @Override
+  @SuppressWarnings({"rawtypes", "unchecked"})
+  public Iterator<Operand<Object>> iterator() {
+    return (Iterator) components.iterator();
+  }
+  
+  private List<Output<?>> components;
+  
+  private DatasetToSingleElement(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    int componentsLength = operation.outputListLength("components");
+    components = Arrays.asList(operation.outputList(outputIdx, componentsLength));
+    outputIdx += componentsLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/DatasetToTFRecord.java java-ops/org/tensorflow/op/core/DatasetToTFRecord.java
--- java/org/tensorflow/op/core/DatasetToTFRecord.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/DatasetToTFRecord.java	2018-10-16 20:18:38.238432376 +0900
@@ -0,0 +1,53 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Writes the given dataset to the given file using the TFRecord format.
+ */
+public final class DatasetToTFRecord extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new DatasetToTFRecord operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputDataset A variant tensor representing the dataset to write.
+   * @param filename A scalar string tensor representing the filename to use.
+   * @param compressionType A scalar string tensor containing either (i) the empty string (no
+   * compression), (ii) "ZLIB", or (iii) "GZIP".
+   * @return a new instance of DatasetToTFRecord
+   */
+  public static DatasetToTFRecord create(Scope scope, Operand<?> inputDataset, Operand<String> filename, Operand<String> compressionType) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("DatasetToTFRecord", scope.makeOpName("DatasetToTFRecord"));
+    opBuilder.addInput(inputDataset.asOutput());
+    opBuilder.addInput(filename.asOutput());
+    opBuilder.addInput(compressionType.asOutput());
+    return new DatasetToTFRecord(opBuilder.build());
+  }
+  
+  
+  private DatasetToTFRecord(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/DebugGradientIdentity.java java-ops/org/tensorflow/op/core/DebugGradientIdentity.java
--- java/org/tensorflow/op/core/DebugGradientIdentity.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/DebugGradientIdentity.java	2018-10-16 20:18:38.238432376 +0900
@@ -0,0 +1,71 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Identity op for gradient debugging.
+ * <p>
+ * This op is hidden from public in Python. It is used by TensorFlow Debugger to
+ * register gradient tensors for gradient debugging.
+ * This op operates on non-reference-type tensors.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class DebugGradientIdentity<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new DebugGradientIdentity operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @return a new instance of DebugGradientIdentity
+   */
+  public static <T> DebugGradientIdentity<T> create(Scope scope, Operand<T> input) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("DebugGradientIdentity", scope.makeOpName("DebugGradientIdentity"));
+    opBuilder.addInput(input.asOutput());
+    return new DebugGradientIdentity<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private DebugGradientIdentity(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/DebugGradientRefIdentity.java java-ops/org/tensorflow/op/core/DebugGradientRefIdentity.java
--- java/org/tensorflow/op/core/DebugGradientRefIdentity.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/DebugGradientRefIdentity.java	2018-10-16 20:18:38.239432376 +0900
@@ -0,0 +1,71 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Identity op for gradient debugging.
+ * <p>
+ * This op is hidden from public in Python. It is used by TensorFlow Debugger to
+ * register gradient tensors for gradient debugging.
+ * This op operates on reference-type tensors.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class DebugGradientRefIdentity<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new DebugGradientRefIdentity operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @return a new instance of DebugGradientRefIdentity
+   */
+  public static <T> DebugGradientRefIdentity<T> create(Scope scope, Operand<T> input) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("DebugGradientRefIdentity", scope.makeOpName("DebugGradientRefIdentity"));
+    opBuilder.addInput(input.asOutput());
+    return new DebugGradientRefIdentity<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private DebugGradientRefIdentity(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/DecodeAndCropJpeg.java java-ops/org/tensorflow/op/core/DecodeAndCropJpeg.java
--- java/org/tensorflow/op/core/DecodeAndCropJpeg.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/DecodeAndCropJpeg.java	2018-10-16 20:18:38.239432376 +0900
@@ -0,0 +1,237 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+import org.tensorflow.types.UInt8;
+
+/**
+ * Decode and Crop a JPEG-encoded image to a uint8 tensor.
+ * <p>
+ * The attr `channels` indicates the desired number of color channels for the
+ * decoded image.
+ * <p>
+ * Accepted values are:
+ * <ul>
+ * <li>
+ * 0: Use the number of channels in the JPEG-encoded image.
+ * </li>
+ * <li>
+ * 1: output a grayscale image.
+ * </li>
+ * <li>
+ * 3: output an RGB image.
+ * </li>
+ * </ul>
+ * If needed, the JPEG-encoded image is transformed to match the requested number
+ * of color channels.
+ * <p>
+ * The attr `ratio` allows downscaling the image by an integer factor during
+ * decoding.  Allowed values are: 1, 2, 4, and 8.  This is much faster than
+ * downscaling the image later.
+ * <p>
+ * It is equivalent to a combination of decode and crop, but much faster by only
+ * decoding partial jpeg image.
+ */
+@Operator
+public final class DecodeAndCropJpeg extends PrimitiveOp implements Operand<UInt8> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.DecodeAndCropJpeg}
+   */
+  public static class Options {
+    
+    /**
+     * @param channels Number of color channels for the decoded image.
+     */
+    public Options channels(Long channels) {
+      this.channels = channels;
+      return this;
+    }
+    
+    /**
+     * @param ratio Downscaling ratio.
+     */
+    public Options ratio(Long ratio) {
+      this.ratio = ratio;
+      return this;
+    }
+    
+    /**
+     * @param fancyUpscaling If true use a slower but nicer upscaling of the
+     * chroma planes (yuv420/422 only).
+     */
+    public Options fancyUpscaling(Boolean fancyUpscaling) {
+      this.fancyUpscaling = fancyUpscaling;
+      return this;
+    }
+    
+    /**
+     * @param tryRecoverTruncated If true try to recover an image from truncated input.
+     */
+    public Options tryRecoverTruncated(Boolean tryRecoverTruncated) {
+      this.tryRecoverTruncated = tryRecoverTruncated;
+      return this;
+    }
+    
+    /**
+     * @param acceptableFraction The minimum required fraction of lines before a truncated
+     * input is accepted.
+     */
+    public Options acceptableFraction(Float acceptableFraction) {
+      this.acceptableFraction = acceptableFraction;
+      return this;
+    }
+    
+    /**
+     * @param dctMethod string specifying a hint about the algorithm used for
+     * decompression.  Defaults to "" which maps to a system-specific
+     * default.  Currently valid values are ["INTEGER_FAST",
+     * "INTEGER_ACCURATE"].  The hint may be ignored (e.g., the internal
+     * jpeg library changes to a version that does not have that specific
+     * option.)
+     */
+    public Options dctMethod(String dctMethod) {
+      this.dctMethod = dctMethod;
+      return this;
+    }
+    
+    private Long channels;
+    private Long ratio;
+    private Boolean fancyUpscaling;
+    private Boolean tryRecoverTruncated;
+    private Float acceptableFraction;
+    private String dctMethod;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new DecodeAndCropJpeg operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param contents 0-D.  The JPEG-encoded image.
+   * @param cropWindow 1-D.  The crop window: [crop_y, crop_x, crop_height, crop_width].
+   * @param options carries optional attributes values
+   * @return a new instance of DecodeAndCropJpeg
+   */
+  public static DecodeAndCropJpeg create(Scope scope, Operand<String> contents, Operand<Integer> cropWindow, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("DecodeAndCropJpeg", scope.makeOpName("DecodeAndCropJpeg"));
+    opBuilder.addInput(contents.asOutput());
+    opBuilder.addInput(cropWindow.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.channels != null) {
+          opBuilder.setAttr("channels", opts.channels);
+        }
+        if (opts.ratio != null) {
+          opBuilder.setAttr("ratio", opts.ratio);
+        }
+        if (opts.fancyUpscaling != null) {
+          opBuilder.setAttr("fancy_upscaling", opts.fancyUpscaling);
+        }
+        if (opts.tryRecoverTruncated != null) {
+          opBuilder.setAttr("try_recover_truncated", opts.tryRecoverTruncated);
+        }
+        if (opts.acceptableFraction != null) {
+          opBuilder.setAttr("acceptable_fraction", opts.acceptableFraction);
+        }
+        if (opts.dctMethod != null) {
+          opBuilder.setAttr("dct_method", opts.dctMethod);
+        }
+      }
+    }
+    return new DecodeAndCropJpeg(opBuilder.build());
+  }
+  
+  /**
+   * @param channels Number of color channels for the decoded image.
+   */
+  public static Options channels(Long channels) {
+    return new Options().channels(channels);
+  }
+  
+  /**
+   * @param ratio Downscaling ratio.
+   */
+  public static Options ratio(Long ratio) {
+    return new Options().ratio(ratio);
+  }
+  
+  /**
+   * @param fancyUpscaling If true use a slower but nicer upscaling of the
+   * chroma planes (yuv420/422 only).
+   */
+  public static Options fancyUpscaling(Boolean fancyUpscaling) {
+    return new Options().fancyUpscaling(fancyUpscaling);
+  }
+  
+  /**
+   * @param tryRecoverTruncated If true try to recover an image from truncated input.
+   */
+  public static Options tryRecoverTruncated(Boolean tryRecoverTruncated) {
+    return new Options().tryRecoverTruncated(tryRecoverTruncated);
+  }
+  
+  /**
+   * @param acceptableFraction The minimum required fraction of lines before a truncated
+   * input is accepted.
+   */
+  public static Options acceptableFraction(Float acceptableFraction) {
+    return new Options().acceptableFraction(acceptableFraction);
+  }
+  
+  /**
+   * @param dctMethod string specifying a hint about the algorithm used for
+   * decompression.  Defaults to "" which maps to a system-specific
+   * default.  Currently valid values are ["INTEGER_FAST",
+   * "INTEGER_ACCURATE"].  The hint may be ignored (e.g., the internal
+   * jpeg library changes to a version that does not have that specific
+   * option.)
+   */
+  public static Options dctMethod(String dctMethod) {
+    return new Options().dctMethod(dctMethod);
+  }
+  
+  /**
+   * 3-D with shape `[height, width, channels]`..
+   */
+  public Output<UInt8> image() {
+    return image;
+  }
+  
+  @Override
+  public Output<UInt8> asOutput() {
+    return image;
+  }
+  
+  private Output<UInt8> image;
+  
+  private DecodeAndCropJpeg(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    image = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/DecodeBase64.java java-ops/org/tensorflow/op/core/DecodeBase64.java
--- java/org/tensorflow/op/core/DecodeBase64.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/DecodeBase64.java	2018-10-16 20:18:38.240432375 +0900
@@ -0,0 +1,69 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Decode web-safe base64-encoded strings.
+ * <p>
+ * Input may or may not have padding at the end. See EncodeBase64 for padding.
+ * Web-safe means that input must use - and _ instead of + and /.
+ */
+@Operator
+public final class DecodeBase64 extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Factory method to create a class to wrap a new DecodeBase64 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input Base64 strings to decode.
+   * @return a new instance of DecodeBase64
+   */
+  public static DecodeBase64 create(Scope scope, Operand<String> input) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("DecodeBase64", scope.makeOpName("DecodeBase64"));
+    opBuilder.addInput(input.asOutput());
+    return new DecodeBase64(opBuilder.build());
+  }
+  
+  /**
+   * Decoded strings.
+   */
+  public Output<String> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return output;
+  }
+  
+  private Output<String> output;
+  
+  private DecodeBase64(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/DecodeBmp.java java-ops/org/tensorflow/op/core/DecodeBmp.java
--- java/org/tensorflow/op/core/DecodeBmp.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/DecodeBmp.java	2018-10-16 20:18:38.240432375 +0900
@@ -0,0 +1,115 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+import org.tensorflow.types.UInt8;
+
+/**
+ * Decode the first frame of a BMP-encoded image to a uint8 tensor.
+ * <p>
+ * The attr `channels` indicates the desired number of color channels for the
+ * decoded image.
+ * <p>
+ * Accepted values are:
+ * <ul>
+ * <li>
+ * 0: Use the number of channels in the BMP-encoded image.
+ * </li>
+ * <li>
+ * 3: output an RGB image.
+ * </li>
+ * <li>
+ * 4: output an RGBA image.
+ */
+@Operator
+public final class DecodeBmp extends PrimitiveOp implements Operand<UInt8> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.DecodeBmp}
+   */
+  public static class Options {
+    
+    /**
+     * @param channels 
+     */
+    public Options channels(Long channels) {
+      this.channels = channels;
+      return this;
+    }
+    
+    private Long channels;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new DecodeBmp operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param contents 0-D.  The BMP-encoded image.
+   * @param options carries optional attributes values
+   * @return a new instance of DecodeBmp
+   */
+  public static DecodeBmp create(Scope scope, Operand<String> contents, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("DecodeBmp", scope.makeOpName("DecodeBmp"));
+    opBuilder.addInput(contents.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.channels != null) {
+          opBuilder.setAttr("channels", opts.channels);
+        }
+      }
+    }
+    return new DecodeBmp(opBuilder.build());
+  }
+  
+  /**
+   * @param channels 
+   */
+  public static Options channels(Long channels) {
+    return new Options().channels(channels);
+  }
+  
+  /**
+   * 3-D with shape `[height, width, channels]`. RGB order
+   */
+  public Output<UInt8> image() {
+    return image;
+  }
+  
+  @Override
+  public Output<UInt8> asOutput() {
+    return image;
+  }
+  
+  private Output<UInt8> image;
+  
+  private DecodeBmp(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    image = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/DecodeCompressed.java java-ops/org/tensorflow/op/core/DecodeCompressed.java
--- java/org/tensorflow/op/core/DecodeCompressed.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/DecodeCompressed.java	2018-10-16 20:18:38.241432374 +0900
@@ -0,0 +1,110 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Decompress strings.
+ * <p>
+ * This op decompresses each element of the `bytes` input `Tensor`, which
+ * is assumed to be compressed using the given `compression_type`.
+ * <p>
+ * The `output` is a string `Tensor` of the same shape as `bytes`,
+ * each element containing the decompressed data from the corresponding
+ * element in `bytes`.
+ */
+@Operator
+public final class DecodeCompressed extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.DecodeCompressed}
+   */
+  public static class Options {
+    
+    /**
+     * @param compressionType A scalar containing either (i) the empty string (no
+     * compression), (ii) "ZLIB", or (iii) "GZIP".
+     */
+    public Options compressionType(String compressionType) {
+      this.compressionType = compressionType;
+      return this;
+    }
+    
+    private String compressionType;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new DecodeCompressed operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param bytes A Tensor of string which is compressed.
+   * @param options carries optional attributes values
+   * @return a new instance of DecodeCompressed
+   */
+  public static DecodeCompressed create(Scope scope, Operand<String> bytes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("DecodeCompressed", scope.makeOpName("DecodeCompressed"));
+    opBuilder.addInput(bytes.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.compressionType != null) {
+          opBuilder.setAttr("compression_type", opts.compressionType);
+        }
+      }
+    }
+    return new DecodeCompressed(opBuilder.build());
+  }
+  
+  /**
+   * @param compressionType A scalar containing either (i) the empty string (no
+   * compression), (ii) "ZLIB", or (iii) "GZIP".
+   */
+  public static Options compressionType(String compressionType) {
+    return new Options().compressionType(compressionType);
+  }
+  
+  /**
+   * A Tensor with the same shape as input `bytes`, uncompressed
+   * from bytes.
+   */
+  public Output<String> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return output;
+  }
+  
+  private Output<String> output;
+  
+  private DecodeCompressed(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/DecodeCSV.java java-ops/org/tensorflow/op/core/DecodeCSV.java
--- java/org/tensorflow/op/core/DecodeCSV.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/DecodeCSV.java	2018-10-16 20:18:38.241432374 +0900
@@ -0,0 +1,181 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.Iterator;
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Convert CSV records to tensors. Each column maps to one tensor.
+ * <p>
+ * RFC 4180 format is expected for the CSV records.
+ * (https://tools.ietf.org/html/rfc4180)
+ * Note that we allow leading and trailing spaces with int or float field.
+ */
+@Operator
+public final class DecodeCSV extends PrimitiveOp implements Iterable<Operand<Object>> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.DecodeCSV}
+   */
+  public static class Options {
+    
+    /**
+     * @param fieldDelim char delimiter to separate fields in a record.
+     */
+    public Options fieldDelim(String fieldDelim) {
+      this.fieldDelim = fieldDelim;
+      return this;
+    }
+    
+    /**
+     * @param useQuoteDelim If false, treats double quotation marks as regular
+     * characters inside of the string fields (ignoring RFC 4180, Section 2,
+     * Bullet 5).
+     */
+    public Options useQuoteDelim(Boolean useQuoteDelim) {
+      this.useQuoteDelim = useQuoteDelim;
+      return this;
+    }
+    
+    /**
+     * @param naValue Additional string to recognize as NA/NaN.
+     */
+    public Options naValue(String naValue) {
+      this.naValue = naValue;
+      return this;
+    }
+    
+    /**
+     * @param selectCols 
+     */
+    public Options selectCols(List<Long> selectCols) {
+      this.selectCols = selectCols;
+      return this;
+    }
+    
+    private String fieldDelim;
+    private Boolean useQuoteDelim;
+    private String naValue;
+    private List<Long> selectCols;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new DecodeCSV operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param records Each string is a record/row in the csv and all records should have
+   * the same format.
+   * @param recordDefaults One tensor per column of the input record, with either a
+   * scalar default value for that column or an empty vector if the column is
+   * required.
+   * @param options carries optional attributes values
+   * @return a new instance of DecodeCSV
+   */
+  public static DecodeCSV create(Scope scope, Operand<String> records, Iterable<Operand<?>> recordDefaults, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("DecodeCSV", scope.makeOpName("DecodeCSV"));
+    opBuilder.addInput(records.asOutput());
+    opBuilder.addInputList(Operands.asOutputs(recordDefaults));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.fieldDelim != null) {
+          opBuilder.setAttr("field_delim", opts.fieldDelim);
+        }
+        if (opts.useQuoteDelim != null) {
+          opBuilder.setAttr("use_quote_delim", opts.useQuoteDelim);
+        }
+        if (opts.naValue != null) {
+          opBuilder.setAttr("na_value", opts.naValue);
+        }
+        if (opts.selectCols != null) {
+          long[] selectColsArray = new long[opts.selectCols.size()];
+          for (int i = 0; i < selectColsArray.length; ++i) {
+            selectColsArray[i] = opts.selectCols.get(i);
+          }
+          opBuilder.setAttr("select_cols", selectColsArray);
+        }
+      }
+    }
+    return new DecodeCSV(opBuilder.build());
+  }
+  
+  /**
+   * @param fieldDelim char delimiter to separate fields in a record.
+   */
+  public static Options fieldDelim(String fieldDelim) {
+    return new Options().fieldDelim(fieldDelim);
+  }
+  
+  /**
+   * @param useQuoteDelim If false, treats double quotation marks as regular
+   * characters inside of the string fields (ignoring RFC 4180, Section 2,
+   * Bullet 5).
+   */
+  public static Options useQuoteDelim(Boolean useQuoteDelim) {
+    return new Options().useQuoteDelim(useQuoteDelim);
+  }
+  
+  /**
+   * @param naValue Additional string to recognize as NA/NaN.
+   */
+  public static Options naValue(String naValue) {
+    return new Options().naValue(naValue);
+  }
+  
+  /**
+   * @param selectCols 
+   */
+  public static Options selectCols(List<Long> selectCols) {
+    return new Options().selectCols(selectCols);
+  }
+  
+  /**
+   * Each tensor will have the same shape as records.
+   */
+  public List<Output<?>> output() {
+    return output;
+  }
+  
+  @Override
+  @SuppressWarnings({"rawtypes", "unchecked"})
+  public Iterator<Operand<Object>> iterator() {
+    return (Iterator) output.iterator();
+  }
+  
+  private List<Output<?>> output;
+  
+  private DecodeCSV(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    int outputLength = operation.outputListLength("output");
+    output = Arrays.asList(operation.outputList(outputIdx, outputLength));
+    outputIdx += outputLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/DecodeGif.java java-ops/org/tensorflow/op/core/DecodeGif.java
--- java/org/tensorflow/op/core/DecodeGif.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/DecodeGif.java	2018-10-16 20:18:38.241432374 +0900
@@ -0,0 +1,75 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+import org.tensorflow.types.UInt8;
+
+/**
+ * Decode the first frame of a GIF-encoded image to a uint8 tensor.
+ * <p>
+ * GIF with frame or transparency compression are not supported
+ * convert animated GIF from compressed to uncompressed by:
+ * <p>
+ *     convert $src.gif -coalesce $dst.gif
+ * <p>
+ * This op also supports decoding JPEGs and PNGs, though it is cleaner to use
+ * `tf.image.decode_image`.
+ */
+@Operator
+public final class DecodeGif extends PrimitiveOp implements Operand<UInt8> {
+  
+  /**
+   * Factory method to create a class to wrap a new DecodeGif operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param contents 0-D.  The GIF-encoded image.
+   * @return a new instance of DecodeGif
+   */
+  public static DecodeGif create(Scope scope, Operand<String> contents) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("DecodeGif", scope.makeOpName("DecodeGif"));
+    opBuilder.addInput(contents.asOutput());
+    return new DecodeGif(opBuilder.build());
+  }
+  
+  /**
+   * 4-D with shape `[num_frames, height, width, 3]`. RGB order
+   */
+  public Output<UInt8> image() {
+    return image;
+  }
+  
+  @Override
+  public Output<UInt8> asOutput() {
+    return image;
+  }
+  
+  private Output<UInt8> image;
+  
+  private DecodeGif(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    image = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/DecodeJpeg.java java-ops/org/tensorflow/op/core/DecodeJpeg.java
--- java/org/tensorflow/op/core/DecodeJpeg.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/DecodeJpeg.java	2018-10-16 20:18:38.242432374 +0900
@@ -0,0 +1,235 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+import org.tensorflow.types.UInt8;
+
+/**
+ * Decode a JPEG-encoded image to a uint8 tensor.
+ * <p>
+ * The attr `channels` indicates the desired number of color channels for the
+ * decoded image.
+ * <p>
+ * Accepted values are:
+ * <ul>
+ * <li>
+ * 0: Use the number of channels in the JPEG-encoded image.
+ * </li>
+ * <li>
+ * 1: output a grayscale image.
+ * </li>
+ * <li>
+ * 3: output an RGB image.
+ * </li>
+ * </ul>
+ * If needed, the JPEG-encoded image is transformed to match the requested number
+ * of color channels.
+ * <p>
+ * The attr `ratio` allows downscaling the image by an integer factor during
+ * decoding.  Allowed values are: 1, 2, 4, and 8.  This is much faster than
+ * downscaling the image later.
+ * <p>
+ * This op also supports decoding PNGs and non-animated GIFs since the interface is
+ * the same, though it is cleaner to use `tf.image.decode_image`.
+ */
+@Operator
+public final class DecodeJpeg extends PrimitiveOp implements Operand<UInt8> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.DecodeJpeg}
+   */
+  public static class Options {
+    
+    /**
+     * @param channels Number of color channels for the decoded image.
+     */
+    public Options channels(Long channels) {
+      this.channels = channels;
+      return this;
+    }
+    
+    /**
+     * @param ratio Downscaling ratio.
+     */
+    public Options ratio(Long ratio) {
+      this.ratio = ratio;
+      return this;
+    }
+    
+    /**
+     * @param fancyUpscaling If true use a slower but nicer upscaling of the
+     * chroma planes (yuv420/422 only).
+     */
+    public Options fancyUpscaling(Boolean fancyUpscaling) {
+      this.fancyUpscaling = fancyUpscaling;
+      return this;
+    }
+    
+    /**
+     * @param tryRecoverTruncated If true try to recover an image from truncated input.
+     */
+    public Options tryRecoverTruncated(Boolean tryRecoverTruncated) {
+      this.tryRecoverTruncated = tryRecoverTruncated;
+      return this;
+    }
+    
+    /**
+     * @param acceptableFraction The minimum required fraction of lines before a truncated
+     * input is accepted.
+     */
+    public Options acceptableFraction(Float acceptableFraction) {
+      this.acceptableFraction = acceptableFraction;
+      return this;
+    }
+    
+    /**
+     * @param dctMethod string specifying a hint about the algorithm used for
+     * decompression.  Defaults to "" which maps to a system-specific
+     * default.  Currently valid values are ["INTEGER_FAST",
+     * "INTEGER_ACCURATE"].  The hint may be ignored (e.g., the internal
+     * jpeg library changes to a version that does not have that specific
+     * option.)
+     */
+    public Options dctMethod(String dctMethod) {
+      this.dctMethod = dctMethod;
+      return this;
+    }
+    
+    private Long channels;
+    private Long ratio;
+    private Boolean fancyUpscaling;
+    private Boolean tryRecoverTruncated;
+    private Float acceptableFraction;
+    private String dctMethod;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new DecodeJpeg operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param contents 0-D.  The JPEG-encoded image.
+   * @param options carries optional attributes values
+   * @return a new instance of DecodeJpeg
+   */
+  public static DecodeJpeg create(Scope scope, Operand<String> contents, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("DecodeJpeg", scope.makeOpName("DecodeJpeg"));
+    opBuilder.addInput(contents.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.channels != null) {
+          opBuilder.setAttr("channels", opts.channels);
+        }
+        if (opts.ratio != null) {
+          opBuilder.setAttr("ratio", opts.ratio);
+        }
+        if (opts.fancyUpscaling != null) {
+          opBuilder.setAttr("fancy_upscaling", opts.fancyUpscaling);
+        }
+        if (opts.tryRecoverTruncated != null) {
+          opBuilder.setAttr("try_recover_truncated", opts.tryRecoverTruncated);
+        }
+        if (opts.acceptableFraction != null) {
+          opBuilder.setAttr("acceptable_fraction", opts.acceptableFraction);
+        }
+        if (opts.dctMethod != null) {
+          opBuilder.setAttr("dct_method", opts.dctMethod);
+        }
+      }
+    }
+    return new DecodeJpeg(opBuilder.build());
+  }
+  
+  /**
+   * @param channels Number of color channels for the decoded image.
+   */
+  public static Options channels(Long channels) {
+    return new Options().channels(channels);
+  }
+  
+  /**
+   * @param ratio Downscaling ratio.
+   */
+  public static Options ratio(Long ratio) {
+    return new Options().ratio(ratio);
+  }
+  
+  /**
+   * @param fancyUpscaling If true use a slower but nicer upscaling of the
+   * chroma planes (yuv420/422 only).
+   */
+  public static Options fancyUpscaling(Boolean fancyUpscaling) {
+    return new Options().fancyUpscaling(fancyUpscaling);
+  }
+  
+  /**
+   * @param tryRecoverTruncated If true try to recover an image from truncated input.
+   */
+  public static Options tryRecoverTruncated(Boolean tryRecoverTruncated) {
+    return new Options().tryRecoverTruncated(tryRecoverTruncated);
+  }
+  
+  /**
+   * @param acceptableFraction The minimum required fraction of lines before a truncated
+   * input is accepted.
+   */
+  public static Options acceptableFraction(Float acceptableFraction) {
+    return new Options().acceptableFraction(acceptableFraction);
+  }
+  
+  /**
+   * @param dctMethod string specifying a hint about the algorithm used for
+   * decompression.  Defaults to "" which maps to a system-specific
+   * default.  Currently valid values are ["INTEGER_FAST",
+   * "INTEGER_ACCURATE"].  The hint may be ignored (e.g., the internal
+   * jpeg library changes to a version that does not have that specific
+   * option.)
+   */
+  public static Options dctMethod(String dctMethod) {
+    return new Options().dctMethod(dctMethod);
+  }
+  
+  /**
+   * 3-D with shape `[height, width, channels]`..
+   */
+  public Output<UInt8> image() {
+    return image;
+  }
+  
+  @Override
+  public Output<UInt8> asOutput() {
+    return image;
+  }
+  
+  private Output<UInt8> image;
+  
+  private DecodeJpeg(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    image = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/DecodeJSONExample.java java-ops/org/tensorflow/op/core/DecodeJSONExample.java
--- java/org/tensorflow/op/core/DecodeJSONExample.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/DecodeJSONExample.java	2018-10-16 20:18:38.242432374 +0900
@@ -0,0 +1,75 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Convert JSON-encoded Example records to binary protocol buffer strings.
+ * <p>
+ * This op translates a tensor containing Example records, encoded using
+ * the [standard JSON
+ * mapping](https://developers.google.com/protocol-buffers/docs/proto3#json),
+ * into a tensor containing the same records encoded as binary protocol
+ * buffers. The resulting tensor can then be fed to any of the other
+ * Example-parsing ops.
+ */
+@Operator
+public final class DecodeJSONExample extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Factory method to create a class to wrap a new DecodeJSONExample operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param jsonExamples Each string is a JSON object serialized according to the JSON
+   * mapping of the Example proto.
+   * @return a new instance of DecodeJSONExample
+   */
+  public static DecodeJSONExample create(Scope scope, Operand<String> jsonExamples) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("DecodeJSONExample", scope.makeOpName("DecodeJSONExample"));
+    opBuilder.addInput(jsonExamples.asOutput());
+    return new DecodeJSONExample(opBuilder.build());
+  }
+  
+  /**
+   * Each string is a binary Example protocol buffer corresponding
+   * to the respective element of `json_examples`.
+   */
+  public Output<String> binaryExamples() {
+    return binaryExamples;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return binaryExamples;
+  }
+  
+  private Output<String> binaryExamples;
+  
+  private DecodeJSONExample(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    binaryExamples = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/DecodePng.java java-ops/org/tensorflow/op/core/DecodePng.java
--- java/org/tensorflow/op/core/DecodePng.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/DecodePng.java	2018-10-16 20:18:38.243432373 +0900
@@ -0,0 +1,142 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+import org.tensorflow.types.UInt8;
+
+/**
+ * Decode a PNG-encoded image to a uint8 or uint16 tensor.
+ * <p>
+ * The attr `channels` indicates the desired number of color channels for the
+ * decoded image.
+ * <p>
+ * Accepted values are:
+ * <ul>
+ * <li>
+ * 0: Use the number of channels in the PNG-encoded image.
+ * </li>
+ * <li>
+ * 1: output a grayscale image.
+ * </li>
+ * <li>
+ * 3: output an RGB image.
+ * </li>
+ * <li>
+ * 4: output an RGBA image.
+ * </li>
+ * </ul>
+ * If needed, the PNG-encoded image is transformed to match the requested number
+ * of color channels.
+ * <p>
+ * This op also supports decoding JPEGs and non-animated GIFs since the interface
+ * is the same, though it is cleaner to use `tf.image.decode_image`.
+ * 
+ * @param <T> data type for {@code image()} output
+ */
+@Operator
+public final class DecodePng<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.DecodePng}
+   */
+  public static class Options {
+    
+    /**
+     * @param channels Number of color channels for the decoded image.
+     */
+    public Options channels(Long channels) {
+      this.channels = channels;
+      return this;
+    }
+    
+    private Long channels;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new DecodePng operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param contents 0-D.  The PNG-encoded image.
+   * @param dtype 
+   * @param options carries optional attributes values
+   * @return a new instance of DecodePng
+   */
+  public static <T extends Number> DecodePng<T> create(Scope scope, Operand<String> contents, Class<T> dtype, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("DecodePng", scope.makeOpName("DecodePng"));
+    opBuilder.addInput(contents.asOutput());
+    opBuilder.setAttr("dtype", DataType.fromClass(dtype));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.channels != null) {
+          opBuilder.setAttr("channels", opts.channels);
+        }
+      }
+    }
+    return new DecodePng<T>(opBuilder.build());
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new DecodePng operation to the graph, using default output types.
+   * 
+   * @param scope current graph scope
+   * @param contents 0-D.  The PNG-encoded image.
+   * @param options carries optional attributes values
+   * @return a new instance of DecodePng
+   */
+  public static DecodePng<UInt8> create(Scope scope, Operand<String> contents, Options... options) {
+    return create(scope, contents, UInt8.class, options);
+  }
+  
+  /**
+   * @param channels Number of color channels for the decoded image.
+   */
+  public static Options channels(Long channels) {
+    return new Options().channels(channels);
+  }
+  
+  /**
+   * 3-D with shape `[height, width, channels]`.
+   */
+  public Output<T> image() {
+    return image;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return image;
+  }
+  
+  private Output<T> image;
+  
+  private DecodePng(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    image = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/DecodeProtoV2.java java-ops/org/tensorflow/op/core/DecodeProtoV2.java
--- java/org/tensorflow/op/core/DecodeProtoV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/DecodeProtoV2.java	2018-10-16 20:18:38.244432372 +0900
@@ -0,0 +1,217 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * The op extracts fields from a serialized protocol buffers message into tensors.
+ * <p>
+ * The `decode_proto` op extracts fields from a serialized protocol buffers
+ * message into tensors.  The fields in `field_names` are decoded and converted
+ * to the corresponding `output_types` if possible.
+ * <p>
+ * A `message_type` name must be provided to give context for the field
+ * names. The actual message descriptor can be looked up either in the
+ * linked-in descriptor pool or a filename provided by the caller using
+ * the `descriptor_source` attribute.
+ * <p>
+ * Each output tensor is a dense tensor. This means that it is padded to
+ * hold the largest number of repeated elements seen in the input
+ * minibatch. (The shape is also padded by one to prevent zero-sized
+ * dimensions). The actual repeat counts for each example in the
+ * minibatch can be found in the `sizes` output. In many cases the output
+ * of `decode_proto` is fed immediately into tf.squeeze if missing values
+ * are not a concern. When using tf.squeeze, always pass the squeeze
+ * dimension explicitly to avoid surprises.
+ * <p>
+ * For the most part, the mapping between Proto field types and
+ * TensorFlow dtypes is straightforward. However, there are a few
+ * special cases:
+ * <p>
+ * - A proto field that contains a submessage or group can only be converted
+ * to `DT_STRING` (the serialized submessage). This is to reduce the
+ * complexity of the API. The resulting string can be used as input
+ * to another instance of the decode_proto op.
+ * <p>
+ * - TensorFlow lacks support for unsigned integers. The ops represent uint64
+ * types as a `DT_INT64` with the same twos-complement bit pattern
+ * (the obvious way). Unsigned int32 values can be represented exactly by
+ * specifying type `DT_INT64`, or using twos-complement if the caller
+ * specifies `DT_INT32` in the `output_types` attribute.
+ * <p>
+ * The `descriptor_source` attribute selects a source of protocol
+ * descriptors to consult when looking up `message_type`. This may be a
+ * filename containing a serialized `FileDescriptorSet` message,
+ * or the special value `local://`, in which case only descriptors linked
+ * into the code will be searched; the filename can be on any filesystem
+ * accessible to TensorFlow.
+ * <p>
+ * You can build a `descriptor_source` file using the `--descriptor_set_out`
+ * and `--include_imports` options to the protocol compiler `protoc`.
+ * <p>
+ * The `local://` database only covers descriptors linked into the
+ * code via C++ libraries, not Python imports. You can link in a proto descriptor
+ * by creating a cc_library target with alwayslink=1.
+ * <p>
+ * Both binary and text proto serializations are supported, and can be
+ * chosen using the `format` attribute.
+ */
+@Operator
+public final class DecodeProtoV2 extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.DecodeProtoV2}
+   */
+  public static class Options {
+    
+    /**
+     * @param descriptorSource Either the special value `local://` or a path to a file containing
+     * a serialized `FileDescriptorSet`.
+     */
+    public Options descriptorSource(String descriptorSource) {
+      this.descriptorSource = descriptorSource;
+      return this;
+    }
+    
+    /**
+     * @param messageFormat Either `binary` or `text`.
+     */
+    public Options messageFormat(String messageFormat) {
+      this.messageFormat = messageFormat;
+      return this;
+    }
+    
+    /**
+     * @param sanitize Whether to sanitize the result or not.
+     */
+    public Options sanitize(Boolean sanitize) {
+      this.sanitize = sanitize;
+      return this;
+    }
+    
+    private String descriptorSource;
+    private String messageFormat;
+    private Boolean sanitize;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new DecodeProtoV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param bytes Tensor of serialized protos with shape `batch_shape`.
+   * @param messageType Name of the proto message type to decode.
+   * @param fieldNames List of strings containing proto field names.
+   * @param outputTypes List of TF types to use for the respective field in field_names.
+   * @param options carries optional attributes values
+   * @return a new instance of DecodeProtoV2
+   */
+  public static DecodeProtoV2 create(Scope scope, Operand<String> bytes, String messageType, List<String> fieldNames, List<Class<?>> outputTypes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("DecodeProtoV2", scope.makeOpName("DecodeProtoV2"));
+    opBuilder.addInput(bytes.asOutput());
+    opBuilder.setAttr("message_type", messageType);
+    String[] fieldNamesArray = new String[fieldNames.size()];
+    for (int i = 0; i < fieldNamesArray.length; ++i) {
+      fieldNamesArray[i] = fieldNames.get(i);
+    }
+    opBuilder.setAttr("field_names", fieldNamesArray);
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.descriptorSource != null) {
+          opBuilder.setAttr("descriptor_source", opts.descriptorSource);
+        }
+        if (opts.messageFormat != null) {
+          opBuilder.setAttr("message_format", opts.messageFormat);
+        }
+        if (opts.sanitize != null) {
+          opBuilder.setAttr("sanitize", opts.sanitize);
+        }
+      }
+    }
+    return new DecodeProtoV2(opBuilder.build());
+  }
+  
+  /**
+   * @param descriptorSource Either the special value `local://` or a path to a file containing
+   * a serialized `FileDescriptorSet`.
+   */
+  public static Options descriptorSource(String descriptorSource) {
+    return new Options().descriptorSource(descriptorSource);
+  }
+  
+  /**
+   * @param messageFormat Either `binary` or `text`.
+   */
+  public static Options messageFormat(String messageFormat) {
+    return new Options().messageFormat(messageFormat);
+  }
+  
+  /**
+   * @param sanitize Whether to sanitize the result or not.
+   */
+  public static Options sanitize(Boolean sanitize) {
+    return new Options().sanitize(sanitize);
+  }
+  
+  /**
+   * Tensor of int32 with shape `[batch_shape, len(field_names)]`.
+   * Each entry is the number of values found for the corresponding field.
+   * Optional fields may have 0 or 1 values.
+   */
+  public Output<Integer> sizes() {
+    return sizes;
+  }
+  
+  /**
+   * List of tensors containing values for the corresponding field.
+   * `values[i]` has datatype `output_types[i]`
+   * and shape `[batch_shape, max(sizes[...,i])]`.
+   */
+  public List<Output<?>> values() {
+    return values;
+  }
+  
+  private Output<Integer> sizes;
+  private List<Output<?>> values;
+  
+  private DecodeProtoV2(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    sizes = operation.output(outputIdx++);
+    int valuesLength = operation.outputListLength("values");
+    values = Arrays.asList(operation.outputList(outputIdx, valuesLength));
+    outputIdx += valuesLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/DecodeRaw.java java-ops/org/tensorflow/op/core/DecodeRaw.java
--- java/org/tensorflow/op/core/DecodeRaw.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/DecodeRaw.java	2018-10-16 20:18:38.244432372 +0900
@@ -0,0 +1,111 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Reinterpret the bytes of a string as a vector of numbers.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class DecodeRaw<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.DecodeRaw}
+   */
+  public static class Options {
+    
+    /**
+     * @param littleEndian Whether the input `bytes` are in little-endian order.
+     * Ignored for `out_type` values that are stored in a single byte like
+     * `uint8`.
+     */
+    public Options littleEndian(Boolean littleEndian) {
+      this.littleEndian = littleEndian;
+      return this;
+    }
+    
+    private Boolean littleEndian;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new DecodeRaw operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param bytes All the elements must have the same length.
+   * @param outType 
+   * @param options carries optional attributes values
+   * @return a new instance of DecodeRaw
+   */
+  public static <T extends Number> DecodeRaw<T> create(Scope scope, Operand<String> bytes, Class<T> outType, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("DecodeRaw", scope.makeOpName("DecodeRaw"));
+    opBuilder.addInput(bytes.asOutput());
+    opBuilder.setAttr("out_type", DataType.fromClass(outType));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.littleEndian != null) {
+          opBuilder.setAttr("little_endian", opts.littleEndian);
+        }
+      }
+    }
+    return new DecodeRaw<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param littleEndian Whether the input `bytes` are in little-endian order.
+   * Ignored for `out_type` values that are stored in a single byte like
+   * `uint8`.
+   */
+  public static Options littleEndian(Boolean littleEndian) {
+    return new Options().littleEndian(littleEndian);
+  }
+  
+  /**
+   * A Tensor with one more dimension than the input `bytes`.  The
+   * added dimension will have size equal to the length of the elements
+   * of `bytes` divided by the number of bytes to represent `out_type`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private DecodeRaw(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/DecodeWav.java java-ops/org/tensorflow/op/core/DecodeWav.java
--- java/org/tensorflow/op/core/DecodeWav.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/DecodeWav.java	2018-10-16 20:18:38.245432371 +0900
@@ -0,0 +1,138 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Decode a 16-bit PCM WAV file to a float tensor.
+ * <p>
+ * The -32768 to 32767 signed 16-bit values will be scaled to -1.0 to 1.0 in float.
+ * <p>
+ * When desired_channels is set, if the input contains fewer channels than this
+ * then the last channel will be duplicated to give the requested number, else if
+ * the input has more channels than requested then the additional channels will be
+ * ignored.
+ * <p>
+ * If desired_samples is set, then the audio will be cropped or padded with zeroes
+ * to the requested length.
+ * <p>
+ * The first output contains a Tensor with the content of the audio samples. The
+ * lowest dimension will be the number of channels, and the second will be the
+ * number of samples. For example, a ten-sample-long stereo WAV file should give an
+ * output shape of [10, 2].
+ */
+@Operator
+public final class DecodeWav extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.DecodeWav}
+   */
+  public static class Options {
+    
+    /**
+     * @param desiredChannels Number of sample channels wanted.
+     */
+    public Options desiredChannels(Long desiredChannels) {
+      this.desiredChannels = desiredChannels;
+      return this;
+    }
+    
+    /**
+     * @param desiredSamples Length of audio requested.
+     */
+    public Options desiredSamples(Long desiredSamples) {
+      this.desiredSamples = desiredSamples;
+      return this;
+    }
+    
+    private Long desiredChannels;
+    private Long desiredSamples;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new DecodeWav operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param contents The WAV-encoded audio, usually from a file.
+   * @param options carries optional attributes values
+   * @return a new instance of DecodeWav
+   */
+  public static DecodeWav create(Scope scope, Operand<String> contents, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("DecodeWav", scope.makeOpName("DecodeWav"));
+    opBuilder.addInput(contents.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.desiredChannels != null) {
+          opBuilder.setAttr("desired_channels", opts.desiredChannels);
+        }
+        if (opts.desiredSamples != null) {
+          opBuilder.setAttr("desired_samples", opts.desiredSamples);
+        }
+      }
+    }
+    return new DecodeWav(opBuilder.build());
+  }
+  
+  /**
+   * @param desiredChannels Number of sample channels wanted.
+   */
+  public static Options desiredChannels(Long desiredChannels) {
+    return new Options().desiredChannels(desiredChannels);
+  }
+  
+  /**
+   * @param desiredSamples Length of audio requested.
+   */
+  public static Options desiredSamples(Long desiredSamples) {
+    return new Options().desiredSamples(desiredSamples);
+  }
+  
+  /**
+   * 2-D with shape `[length, channels]`.
+   */
+  public Output<Float> audio() {
+    return audio;
+  }
+  
+  /**
+   * Scalar holding the sample rate found in the WAV header.
+   */
+  public Output<Integer> sampleRate() {
+    return sampleRate;
+  }
+  
+  private Output<Float> audio;
+  private Output<Integer> sampleRate;
+  
+  private DecodeWav(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    audio = operation.output(outputIdx++);
+    sampleRate = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/DeepCopy.java java-ops/org/tensorflow/op/core/DeepCopy.java
--- java/org/tensorflow/op/core/DeepCopy.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/DeepCopy.java	2018-10-16 20:18:38.245432371 +0900
@@ -0,0 +1,69 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Makes a copy of `x`.
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class DeepCopy<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new DeepCopy operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x The source tensor of type `T`.
+   * @return a new instance of DeepCopy
+   */
+  public static <T> DeepCopy<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("DeepCopy", scope.makeOpName("DeepCopy"));
+    opBuilder.addInput(x.asOutput());
+    return new DeepCopy<T>(opBuilder.build());
+  }
+  
+  /**
+   *     y: A `Tensor` of type `T`. A copy of `x`. Guaranteed that `y`
+   *       is not an alias of `x`.
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private DeepCopy(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/DeleteSessionTensor.java java-ops/org/tensorflow/op/core/DeleteSessionTensor.java
--- java/org/tensorflow/op/core/DeleteSessionTensor.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/DeleteSessionTensor.java	2018-10-16 20:18:38.245432371 +0900
@@ -0,0 +1,50 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Delete the tensor specified by its handle in the session.
+ */
+@Operator
+public final class DeleteSessionTensor extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new DeleteSessionTensor operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param handle The handle for a tensor stored in the session state.
+   * @return a new instance of DeleteSessionTensor
+   */
+  public static DeleteSessionTensor create(Scope scope, Operand<String> handle) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("DeleteSessionTensor", scope.makeOpName("DeleteSessionTensor"));
+    opBuilder.addInput(handle.asOutput());
+    return new DeleteSessionTensor(opBuilder.build());
+  }
+  
+  
+  private DeleteSessionTensor(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/DenseToDenseSetOperation.java java-ops/org/tensorflow/op/core/DenseToDenseSetOperation.java
--- java/org/tensorflow/op/core/DenseToDenseSetOperation.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/DenseToDenseSetOperation.java	2018-10-16 20:18:38.246432371 +0900
@@ -0,0 +1,131 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Applies set operation along last dimension of 2 `Tensor` inputs.
+ * <p>
+ * See SetOperationOp::SetOperationFromContext for values of `set_operation`.
+ * <p>
+ * Output `result` is a `SparseTensor` represented by `result_indices`,
+ * `result_values`, and `result_shape`. For `set1` and `set2` ranked `n`, this
+ * has rank `n` and the same 1st `n-1` dimensions as `set1` and `set2`. The `nth`
+ * dimension contains the result of `set_operation` applied to the corresponding
+ * `[0...n-1]` dimension of `set`.
+ * 
+ * @param <T> data type for {@code resultValues()} output
+ */
+@Operator
+public final class DenseToDenseSetOperation<T> extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.DenseToDenseSetOperation}
+   */
+  public static class Options {
+    
+    /**
+     * @param validateIndices 
+     */
+    public Options validateIndices(Boolean validateIndices) {
+      this.validateIndices = validateIndices;
+      return this;
+    }
+    
+    private Boolean validateIndices;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new DenseToDenseSetOperation operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param set1 `Tensor` with rank `n`. 1st `n-1` dimensions must be the same as `set2`.
+   * Dimension `n` contains values in a set, duplicates are allowed but ignored.
+   * @param set2 `Tensor` with rank `n`. 1st `n-1` dimensions must be the same as `set1`.
+   * Dimension `n` contains values in a set, duplicates are allowed but ignored.
+   * @param setOperation 
+   * @param options carries optional attributes values
+   * @return a new instance of DenseToDenseSetOperation
+   */
+  public static <T> DenseToDenseSetOperation<T> create(Scope scope, Operand<T> set1, Operand<T> set2, String setOperation, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("DenseToDenseSetOperation", scope.makeOpName("DenseToDenseSetOperation"));
+    opBuilder.addInput(set1.asOutput());
+    opBuilder.addInput(set2.asOutput());
+    opBuilder.setAttr("set_operation", setOperation);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.validateIndices != null) {
+          opBuilder.setAttr("validate_indices", opts.validateIndices);
+        }
+      }
+    }
+    return new DenseToDenseSetOperation<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param validateIndices 
+   */
+  public static Options validateIndices(Boolean validateIndices) {
+    return new Options().validateIndices(validateIndices);
+  }
+  
+  /**
+   * 2D indices of a `SparseTensor`.
+   */
+  public Output<Long> resultIndices() {
+    return resultIndices;
+  }
+  
+  /**
+   * 1D values of a `SparseTensor`.
+   */
+  public Output<T> resultValues() {
+    return resultValues;
+  }
+  
+  /**
+   * 1D `Tensor` shape of a `SparseTensor`. `result_shape[0...n-1]` is
+   * the same as the 1st `n-1` dimensions of `set1` and `set2`, `result_shape[n]`
+   * is the max result set size across all `0...n-1` dimensions.
+   */
+  public Output<Long> resultShape() {
+    return resultShape;
+  }
+  
+  private Output<Long> resultIndices;
+  private Output<T> resultValues;
+  private Output<Long> resultShape;
+  
+  private DenseToDenseSetOperation(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    resultIndices = operation.output(outputIdx++);
+    resultValues = operation.output(outputIdx++);
+    resultShape = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/DenseToSparseBatchDataset.java java-ops/org/tensorflow/op/core/DenseToSparseBatchDataset.java
--- java/org/tensorflow/op/core/DenseToSparseBatchDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/DenseToSparseBatchDataset.java	2018-10-16 20:18:38.246432371 +0900
@@ -0,0 +1,88 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Creates a dataset that batches input elements into a SparseTensor.
+ */
+@Operator
+public final class DenseToSparseBatchDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new DenseToSparseBatchDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputDataset A handle to an input dataset. Must have a single component.
+   * @param batchSize A scalar representing the number of elements to accumulate in a
+   * batch.
+   * @param rowShape A vector representing the dense shape of each row in the produced
+   * SparseTensor. The shape may be partially specified, using `-1` to indicate
+   * that a particular dimension should use the maximum size of all batch elements.
+   * @param outputTypes 
+   * @param outputShapes 
+   * @return a new instance of DenseToSparseBatchDataset
+   */
+  public static DenseToSparseBatchDataset create(Scope scope, Operand<?> inputDataset, Operand<Long> batchSize, Operand<Long> rowShape, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("DenseToSparseBatchDataset", scope.makeOpName("DenseToSparseBatchDataset"));
+    opBuilder.addInput(inputDataset.asOutput());
+    opBuilder.addInput(batchSize.asOutput());
+    opBuilder.addInput(rowShape.asOutput());
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new DenseToSparseBatchDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private DenseToSparseBatchDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/DenseToSparseSetOperation.java java-ops/org/tensorflow/op/core/DenseToSparseSetOperation.java
--- java/org/tensorflow/op/core/DenseToSparseSetOperation.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/DenseToSparseSetOperation.java	2018-10-16 20:18:38.247432370 +0900
@@ -0,0 +1,146 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Applies set operation along last dimension of `Tensor` and `SparseTensor`.
+ * <p>
+ * See SetOperationOp::SetOperationFromContext for values of `set_operation`.
+ * <p>
+ * Input `set2` is a `SparseTensor` represented by `set2_indices`, `set2_values`,
+ * and `set2_shape`. For `set2` ranked `n`, 1st `n-1` dimensions must be the same
+ * as `set1`. Dimension `n` contains values in a set, duplicates are allowed but
+ * ignored.
+ * <p>
+ * If `validate_indices` is `True`, this op validates the order and range of `set2`
+ * indices.
+ * <p>
+ * Output `result` is a `SparseTensor` represented by `result_indices`,
+ * `result_values`, and `result_shape`. For `set1` and `set2` ranked `n`, this
+ * has rank `n` and the same 1st `n-1` dimensions as `set1` and `set2`. The `nth`
+ * dimension contains the result of `set_operation` applied to the corresponding
+ * `[0...n-1]` dimension of `set`.
+ * 
+ * @param <T> data type for {@code resultValues()} output
+ */
+@Operator
+public final class DenseToSparseSetOperation<T> extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.DenseToSparseSetOperation}
+   */
+  public static class Options {
+    
+    /**
+     * @param validateIndices 
+     */
+    public Options validateIndices(Boolean validateIndices) {
+      this.validateIndices = validateIndices;
+      return this;
+    }
+    
+    private Boolean validateIndices;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new DenseToSparseSetOperation operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param set1 `Tensor` with rank `n`. 1st `n-1` dimensions must be the same as `set2`.
+   * Dimension `n` contains values in a set, duplicates are allowed but ignored.
+   * @param set2Indices 2D `Tensor`, indices of a `SparseTensor`. Must be in row-major
+   * order.
+   * @param set2Values 1D `Tensor`, values of a `SparseTensor`. Must be in row-major
+   * order.
+   * @param set2Shape 1D `Tensor`, shape of a `SparseTensor`. `set2_shape[0...n-1]` must
+   * be the same as the 1st `n-1` dimensions of `set1`, `result_shape[n]` is the
+   * max set size across `n-1` dimensions.
+   * @param setOperation 
+   * @param options carries optional attributes values
+   * @return a new instance of DenseToSparseSetOperation
+   */
+  public static <T> DenseToSparseSetOperation<T> create(Scope scope, Operand<T> set1, Operand<Long> set2Indices, Operand<T> set2Values, Operand<Long> set2Shape, String setOperation, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("DenseToSparseSetOperation", scope.makeOpName("DenseToSparseSetOperation"));
+    opBuilder.addInput(set1.asOutput());
+    opBuilder.addInput(set2Indices.asOutput());
+    opBuilder.addInput(set2Values.asOutput());
+    opBuilder.addInput(set2Shape.asOutput());
+    opBuilder.setAttr("set_operation", setOperation);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.validateIndices != null) {
+          opBuilder.setAttr("validate_indices", opts.validateIndices);
+        }
+      }
+    }
+    return new DenseToSparseSetOperation<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param validateIndices 
+   */
+  public static Options validateIndices(Boolean validateIndices) {
+    return new Options().validateIndices(validateIndices);
+  }
+  
+  /**
+   * 2D indices of a `SparseTensor`.
+   */
+  public Output<Long> resultIndices() {
+    return resultIndices;
+  }
+  
+  /**
+   * 1D values of a `SparseTensor`.
+   */
+  public Output<T> resultValues() {
+    return resultValues;
+  }
+  
+  /**
+   * 1D `Tensor` shape of a `SparseTensor`. `result_shape[0...n-1]` is
+   * the same as the 1st `n-1` dimensions of `set1` and `set2`, `result_shape[n]`
+   * is the max result set size across all `0...n-1` dimensions.
+   */
+  public Output<Long> resultShape() {
+    return resultShape;
+  }
+  
+  private Output<Long> resultIndices;
+  private Output<T> resultValues;
+  private Output<Long> resultShape;
+  
+  private DenseToSparseSetOperation(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    resultIndices = operation.output(outputIdx++);
+    resultValues = operation.output(outputIdx++);
+    resultShape = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/DepthToSpace.java java-ops/org/tensorflow/op/core/DepthToSpace.java
--- java/org/tensorflow/op/core/DepthToSpace.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/DepthToSpace.java	2018-10-16 20:18:38.248432369 +0900
@@ -0,0 +1,183 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * DepthToSpace for tensors of type T.
+ * <p>
+ * Rearranges data from depth into blocks of spatial data.
+ * This is the reverse transformation of SpaceToDepth. More specifically,
+ * this op outputs a copy of the input tensor where values from the `depth`
+ * dimension are moved in spatial blocks to the `height` and `width` dimensions.
+ * The attr `block_size` indicates the input block size and how the data is moved.
+ * <p>
+ *   * Chunks of data of size `block_size * block_size` from depth are rearranged
+ *     into non-overlapping blocks of size `block_size x block_size`
+ *   * The width the output tensor is `input_depth * block_size`, whereas the
+ *     height is `input_height * block_size`.
+ *   * The Y, X coordinates within each block of the output image are determined
+ *     by the high order component of the input channel index.
+ *   * The depth of the input tensor must be divisible by
+ *     `block_size * block_size`.
+ * <p>
+ * The `data_format` attr specifies the layout of the input and output tensors
+ * with the following options:
+ *   "NHWC": `[ batch, height, width, channels ]`
+ *   "NCHW": `[ batch, channels, height, width ]`
+ *   "NCHW_VECT_C":
+ *       `qint8 [ batch, channels / 4, height, width, 4 ]`
+ * <p>
+ * It is useful to consider the operation as transforming a 6-D Tensor.
+ * e.g. for data_format = NHWC,
+ *      Each element in the input tensor can be specified via 6 coordinates,
+ *      ordered by decreasing memory layout significance as:
+ *      n,iY,iX,bY,bX,oC  (where n=batch index, iX, iY means X or Y coordinates
+ *                         within the input image, bX, bY means coordinates
+ *                         within the output block, oC means output channels).
+ *      The output would be the input transposed to the following layout:
+ *      n,iY,bY,iX,bX,oC
+ * <p>
+ * This operation is useful for resizing the activations between convolutions
+ * (but keeping all data), e.g. instead of pooling. It is also useful for training
+ * purely convolutional models.
+ * <p>
+ * For example, given an input of shape `[1, 1, 1, 4]`, data_format = "NHWC" and
+ * block_size = 2:
+ * <pre>{@code
+ * x = [[[[1, 2, 3, 4]]]]
+ * 
+ * }</pre>
+ * This operation will output a tensor of shape `[1, 2, 2, 1]`:
+ * <pre>{@code
+ *    [[[[1], [2]],
+ *      [[3], [4]]]]
+ * }</pre>
+ * Here, the input has a batch of 1 and each batch element has shape `[1, 1, 4]`,
+ * the corresponding output will have 2x2 elements and will have a depth of
+ * 1 channel (1 = `4 / (block_size * block_size)`).
+ * The output element shape is `[2, 2, 1]`.
+ * <p>
+ * For an input tensor with larger depth, here of shape `[1, 1, 1, 12]`, e.g.
+ * <pre>{@code
+ * x = [[[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]]]]
+ * }</pre>
+ * This operation, for block size of 2, will return the following tensor of shape
+ * `[1, 2, 2, 3]`
+ * <pre>{@code
+ *    [[[[1, 2, 3], [4, 5, 6]],
+ *      [[7, 8, 9], [10, 11, 12]]]]
+ * 
+ * }</pre>
+ * Similarly, for the following input of shape `[1 2 2 4]`, and a block size of 2:
+ * <pre>{@code
+ * x =  [[[[1, 2, 3, 4],
+ *        [5, 6, 7, 8]],
+ *       [[9, 10, 11, 12],
+ *        [13, 14, 15, 16]]]]
+ * }</pre>
+ * the operator will return the following tensor of shape `[1 4 4 1]`:
+ * <pre>{@code
+ * x = [[[ [1],   [2],  [5],  [6]],
+ *       [ [3],   [4],  [7],  [8]],
+ *       [ [9],  [10], [13],  [14]],
+ *       [ [11], [12], [15],  [16]]]]
+ * 
+ * }</pre>
+ * 
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class DepthToSpace<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.DepthToSpace}
+   */
+  public static class Options {
+    
+    /**
+     * @param dataFormat 
+     */
+    public Options dataFormat(String dataFormat) {
+      this.dataFormat = dataFormat;
+      return this;
+    }
+    
+    private String dataFormat;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new DepthToSpace operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param blockSize The size of the spatial block, same as in Space2Depth.
+   * @param options carries optional attributes values
+   * @return a new instance of DepthToSpace
+   */
+  public static <T> DepthToSpace<T> create(Scope scope, Operand<T> input, Long blockSize, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("DepthToSpace", scope.makeOpName("DepthToSpace"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.setAttr("block_size", blockSize);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.dataFormat != null) {
+          opBuilder.setAttr("data_format", opts.dataFormat);
+        }
+      }
+    }
+    return new DepthToSpace<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param dataFormat 
+   */
+  public static Options dataFormat(String dataFormat) {
+    return new Options().dataFormat(dataFormat);
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private DepthToSpace(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/DepthwiseConv2dNativeBackpropFilter.java java-ops/org/tensorflow/op/core/DepthwiseConv2dNativeBackpropFilter.java
--- java/org/tensorflow/op/core/DepthwiseConv2dNativeBackpropFilter.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/DepthwiseConv2dNativeBackpropFilter.java	2018-10-16 20:18:38.250432368 +0900
@@ -0,0 +1,164 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the gradients of depthwise convolution with respect to the filter.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class DepthwiseConv2dNativeBackpropFilter<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.DepthwiseConv2dNativeBackpropFilter}
+   */
+  public static class Options {
+    
+    /**
+     * @param dataFormat Specify the data format of the input and output data. With the
+     * default format "NHWC", the data is stored in the order of:
+     *     [batch, height, width, channels].
+     * Alternatively, the format could be "NCHW", the data storage order of:
+     *     [batch, channels, height, width].
+     */
+    public Options dataFormat(String dataFormat) {
+      this.dataFormat = dataFormat;
+      return this;
+    }
+    
+    /**
+     * @param dilations 1-D tensor of length 4.  The dilation factor for each dimension of
+     * `input`. If set to k > 1, there will be k-1 skipped cells between each filter
+     * element on that dimension. The dimension order is determined by the value of
+     * `data_format`, see above for details. Dilations in the batch and depth
+     * dimensions must be 1.
+     */
+    public Options dilations(List<Long> dilations) {
+      this.dilations = dilations;
+      return this;
+    }
+    
+    private String dataFormat;
+    private List<Long> dilations;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new DepthwiseConv2dNativeBackpropFilter operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 4-D with shape based on `data_format`.  For example, if
+   * `data_format` is 'NHWC' then `input` is a 4-D `[batch, in_height,
+   * in_width, in_channels]` tensor.
+   * @param filterSizes An integer vector representing the tensor shape of `filter`,
+   * where `filter` is a 4-D
+   * `[filter_height, filter_width, in_channels, depthwise_multiplier]` tensor.
+   * @param outBackprop 4-D with shape  based on `data_format`.
+   * For example, if `data_format` is 'NHWC' then
+   * out_backprop shape is `[batch, out_height, out_width, out_channels]`.
+   * Gradients w.r.t. the output of the convolution.
+   * @param strides The stride of the sliding window for each dimension of the input
+   * of the convolution.
+   * @param padding The type of padding algorithm to use.
+   * @param options carries optional attributes values
+   * @return a new instance of DepthwiseConv2dNativeBackpropFilter
+   */
+  public static <T extends Number> DepthwiseConv2dNativeBackpropFilter<T> create(Scope scope, Operand<T> input, Operand<Integer> filterSizes, Operand<T> outBackprop, List<Long> strides, String padding, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("DepthwiseConv2dNativeBackpropFilter", scope.makeOpName("DepthwiseConv2dNativeBackpropFilter"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(filterSizes.asOutput());
+    opBuilder.addInput(outBackprop.asOutput());
+    long[] stridesArray = new long[strides.size()];
+    for (int i = 0; i < stridesArray.length; ++i) {
+      stridesArray[i] = strides.get(i);
+    }
+    opBuilder.setAttr("strides", stridesArray);
+    opBuilder.setAttr("padding", padding);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.dataFormat != null) {
+          opBuilder.setAttr("data_format", opts.dataFormat);
+        }
+        if (opts.dilations != null) {
+          long[] dilationsArray = new long[opts.dilations.size()];
+          for (int i = 0; i < dilationsArray.length; ++i) {
+            dilationsArray[i] = opts.dilations.get(i);
+          }
+          opBuilder.setAttr("dilations", dilationsArray);
+        }
+      }
+    }
+    return new DepthwiseConv2dNativeBackpropFilter<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param dataFormat Specify the data format of the input and output data. With the
+   * default format "NHWC", the data is stored in the order of:
+   *     [batch, height, width, channels].
+   * Alternatively, the format could be "NCHW", the data storage order of:
+   *     [batch, channels, height, width].
+   */
+  public static Options dataFormat(String dataFormat) {
+    return new Options().dataFormat(dataFormat);
+  }
+  
+  /**
+   * @param dilations 1-D tensor of length 4.  The dilation factor for each dimension of
+   * `input`. If set to k > 1, there will be k-1 skipped cells between each filter
+   * element on that dimension. The dimension order is determined by the value of
+   * `data_format`, see above for details. Dilations in the batch and depth
+   * dimensions must be 1.
+   */
+  public static Options dilations(List<Long> dilations) {
+    return new Options().dilations(dilations);
+  }
+  
+  /**
+   * 4-D with shape
+   * `[filter_height, filter_width, in_channels, out_channels]`.  Gradient w.r.t.
+   * the `filter` input of the convolution.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private DepthwiseConv2dNativeBackpropFilter(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/DepthwiseConv2dNativeBackpropInput.java java-ops/org/tensorflow/op/core/DepthwiseConv2dNativeBackpropInput.java
--- java/org/tensorflow/op/core/DepthwiseConv2dNativeBackpropInput.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/DepthwiseConv2dNativeBackpropInput.java	2018-10-16 20:18:38.251432367 +0900
@@ -0,0 +1,164 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the gradients of depthwise convolution with respect to the input.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class DepthwiseConv2dNativeBackpropInput<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.DepthwiseConv2dNativeBackpropInput}
+   */
+  public static class Options {
+    
+    /**
+     * @param dataFormat Specify the data format of the input and output data. With the
+     * default format "NHWC", the data is stored in the order of:
+     *     [batch, height, width, channels].
+     * Alternatively, the format could be "NCHW", the data storage order of:
+     *     [batch, channels, height, width].
+     */
+    public Options dataFormat(String dataFormat) {
+      this.dataFormat = dataFormat;
+      return this;
+    }
+    
+    /**
+     * @param dilations 1-D tensor of length 4.  The dilation factor for each dimension of
+     * `input`. If set to k > 1, there will be k-1 skipped cells between each filter
+     * element on that dimension. The dimension order is determined by the value of
+     * `data_format`, see above for details. Dilations in the batch and depth
+     * dimensions must be 1.
+     */
+    public Options dilations(List<Long> dilations) {
+      this.dilations = dilations;
+      return this;
+    }
+    
+    private String dataFormat;
+    private List<Long> dilations;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new DepthwiseConv2dNativeBackpropInput operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputSizes An integer vector representing the shape of `input`, based
+   * on `data_format`.  For example, if `data_format` is 'NHWC' then
+   *  `input` is a 4-D `[batch, height, width, channels]` tensor.
+   * @param filter 4-D with shape
+   * `[filter_height, filter_width, in_channels, depthwise_multiplier]`.
+   * @param outBackprop 4-D with shape  based on `data_format`.
+   * For example, if `data_format` is 'NHWC' then
+   * out_backprop shape is `[batch, out_height, out_width, out_channels]`.
+   * Gradients w.r.t. the output of the convolution.
+   * @param strides The stride of the sliding window for each dimension of the input
+   * of the convolution.
+   * @param padding The type of padding algorithm to use.
+   * @param options carries optional attributes values
+   * @return a new instance of DepthwiseConv2dNativeBackpropInput
+   */
+  public static <T extends Number> DepthwiseConv2dNativeBackpropInput<T> create(Scope scope, Operand<Integer> inputSizes, Operand<T> filter, Operand<T> outBackprop, List<Long> strides, String padding, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("DepthwiseConv2dNativeBackpropInput", scope.makeOpName("DepthwiseConv2dNativeBackpropInput"));
+    opBuilder.addInput(inputSizes.asOutput());
+    opBuilder.addInput(filter.asOutput());
+    opBuilder.addInput(outBackprop.asOutput());
+    long[] stridesArray = new long[strides.size()];
+    for (int i = 0; i < stridesArray.length; ++i) {
+      stridesArray[i] = strides.get(i);
+    }
+    opBuilder.setAttr("strides", stridesArray);
+    opBuilder.setAttr("padding", padding);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.dataFormat != null) {
+          opBuilder.setAttr("data_format", opts.dataFormat);
+        }
+        if (opts.dilations != null) {
+          long[] dilationsArray = new long[opts.dilations.size()];
+          for (int i = 0; i < dilationsArray.length; ++i) {
+            dilationsArray[i] = opts.dilations.get(i);
+          }
+          opBuilder.setAttr("dilations", dilationsArray);
+        }
+      }
+    }
+    return new DepthwiseConv2dNativeBackpropInput<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param dataFormat Specify the data format of the input and output data. With the
+   * default format "NHWC", the data is stored in the order of:
+   *     [batch, height, width, channels].
+   * Alternatively, the format could be "NCHW", the data storage order of:
+   *     [batch, channels, height, width].
+   */
+  public static Options dataFormat(String dataFormat) {
+    return new Options().dataFormat(dataFormat);
+  }
+  
+  /**
+   * @param dilations 1-D tensor of length 4.  The dilation factor for each dimension of
+   * `input`. If set to k > 1, there will be k-1 skipped cells between each filter
+   * element on that dimension. The dimension order is determined by the value of
+   * `data_format`, see above for details. Dilations in the batch and depth
+   * dimensions must be 1.
+   */
+  public static Options dilations(List<Long> dilations) {
+    return new Options().dilations(dilations);
+  }
+  
+  /**
+   * 4-D with shape according to `data_format`.  For example, if
+   * `data_format` is 'NHWC', output shape is `[batch, in_height,
+   * in_width, in_channels]`.  Gradient w.r.t. the input of the
+   * convolution.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private DepthwiseConv2dNativeBackpropInput(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/DepthwiseConv2dNative.java java-ops/org/tensorflow/op/core/DepthwiseConv2dNative.java
--- java/org/tensorflow/op/core/DepthwiseConv2dNative.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/DepthwiseConv2dNative.java	2018-10-16 20:18:38.249432369 +0900
@@ -0,0 +1,169 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes a 2-D depthwise convolution given 4-D `input` and `filter` tensors.
+ * <p>
+ * Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
+ * and a filter / kernel tensor of shape
+ * `[filter_height, filter_width, in_channels, channel_multiplier]`, containing
+ * `in_channels` convolutional filters of depth 1, `depthwise_conv2d` applies
+ * a different filter to each input channel (expanding from 1 channel to
+ * `channel_multiplier` channels for each), then concatenates the results
+ * together. Thus, the output has `in_channels * channel_multiplier` channels.
+ * <pre>{@code
+ * for k in 0..in_channels-1
+ *   for q in 0..channel_multiplier-1
+ *     output[b, i, j, k * channel_multiplier + q] =
+ *       sum_{di, dj} input[b, strides[1] * i + di, strides[2] * j + dj, k] *
+ *                         filter[di, dj, k, q]
+ * }</pre>
+ * Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
+ * horizontal and vertices strides, `strides = [1, stride, stride, 1]`.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class DepthwiseConv2dNative<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.DepthwiseConv2dNative}
+   */
+  public static class Options {
+    
+    /**
+     * @param dataFormat Specify the data format of the input and output data. With the
+     * default format "NHWC", the data is stored in the order of:
+     *     [batch, height, width, channels].
+     * Alternatively, the format could be "NCHW", the data storage order of:
+     *     [batch, channels, height, width].
+     */
+    public Options dataFormat(String dataFormat) {
+      this.dataFormat = dataFormat;
+      return this;
+    }
+    
+    /**
+     * @param dilations 1-D tensor of length 4.  The dilation factor for each dimension of
+     * `input`. If set to k > 1, there will be k-1 skipped cells between each filter
+     * element on that dimension. The dimension order is determined by the value of
+     * `data_format`, see above for details. Dilations in the batch and depth
+     * dimensions must be 1.
+     */
+    public Options dilations(List<Long> dilations) {
+      this.dilations = dilations;
+      return this;
+    }
+    
+    private String dataFormat;
+    private List<Long> dilations;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new DepthwiseConv2dNative operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param filter 
+   * @param strides 1-D of length 4.  The stride of the sliding window for each dimension
+   * of `input`.
+   * @param padding The type of padding algorithm to use.
+   * @param options carries optional attributes values
+   * @return a new instance of DepthwiseConv2dNative
+   */
+  public static <T extends Number> DepthwiseConv2dNative<T> create(Scope scope, Operand<T> input, Operand<T> filter, List<Long> strides, String padding, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("DepthwiseConv2dNative", scope.makeOpName("DepthwiseConv2dNative"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(filter.asOutput());
+    long[] stridesArray = new long[strides.size()];
+    for (int i = 0; i < stridesArray.length; ++i) {
+      stridesArray[i] = strides.get(i);
+    }
+    opBuilder.setAttr("strides", stridesArray);
+    opBuilder.setAttr("padding", padding);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.dataFormat != null) {
+          opBuilder.setAttr("data_format", opts.dataFormat);
+        }
+        if (opts.dilations != null) {
+          long[] dilationsArray = new long[opts.dilations.size()];
+          for (int i = 0; i < dilationsArray.length; ++i) {
+            dilationsArray[i] = opts.dilations.get(i);
+          }
+          opBuilder.setAttr("dilations", dilationsArray);
+        }
+      }
+    }
+    return new DepthwiseConv2dNative<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param dataFormat Specify the data format of the input and output data. With the
+   * default format "NHWC", the data is stored in the order of:
+   *     [batch, height, width, channels].
+   * Alternatively, the format could be "NCHW", the data storage order of:
+   *     [batch, channels, height, width].
+   */
+  public static Options dataFormat(String dataFormat) {
+    return new Options().dataFormat(dataFormat);
+  }
+  
+  /**
+   * @param dilations 1-D tensor of length 4.  The dilation factor for each dimension of
+   * `input`. If set to k > 1, there will be k-1 skipped cells between each filter
+   * element on that dimension. The dimension order is determined by the value of
+   * `data_format`, see above for details. Dilations in the batch and depth
+   * dimensions must be 1.
+   */
+  public static Options dilations(List<Long> dilations) {
+    return new Options().dilations(dilations);
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private DepthwiseConv2dNative(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Dequantize.java java-ops/org/tensorflow/op/core/Dequantize.java
--- java/org/tensorflow/op/core/Dequantize.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Dequantize.java	2018-10-16 20:18:38.252432367 +0900
@@ -0,0 +1,171 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Dequantize the 'input' tensor into a float Tensor.
+ * <p>
+ * [min_range, max_range] are scalar floats that specify the range for
+ * the 'input' data. The 'mode' attribute controls exactly which calculations are
+ * used to convert the float values to their quantized equivalents.
+ * <p>
+ * In 'MIN_COMBINED' mode, each value of the tensor will undergo the following:
+ * <pre>{@code
+ * if T == qint8, in[i] += (range(T) + 1)/ 2.0
+ * out[i] = min_range + (in[i]* (max_range - min_range) / range(T))
+ * }</pre>
+ * here `range(T) = numeric_limits<T>::max() - numeric_limits<T>::min()`
+ * <p>
+ * <i>MIN_COMBINED Mode Example</i>
+ * <p>
+ * If the input comes from a QuantizedRelu6, the output type is
+ * quint8 (range of 0-255) but the possible range of QuantizedRelu6 is
+ * 0-6.  The min_range and max_range values are therefore 0.0 and 6.0.
+ * Dequantize on quint8 will take each value, cast to float, and multiply
+ * by 6 / 255.
+ * Note that if quantizedtype is qint8, the operation will additionally add
+ * each value by 128 prior to casting.
+ * <p>
+ * If the mode is 'MIN_FIRST', then this approach is used:
+ * <pre>{@code
+ * num_discrete_values = 1 << (# of bits in T)
+ * range_adjust = num_discrete_values / (num_discrete_values - 1)
+ * range = (range_max - range_min) * range_adjust
+ * range_scale = range / num_discrete_values
+ * const double offset_input = static_cast<double>(input) - lowest_quantized;
+ * result = range_min + ((input - numeric_limits<T>::min()) * range_scale)
+ * }</pre>
+ * <i>SCALED mode Example</i>
+ * <p>
+ * `SCALED` mode matches the quantization approach used in
+ * `QuantizeAndDequantize{V2|V3}`.
+ * <p>
+ * If the mode is `SCALED`, we do not use the full range of the output type,
+ * choosing to elide the lowest possible value for symmetry (e.g., output range is
+ * -127 to 127, not -128 to 127 for signed 8 bit quantization), so that 0.0 maps to
+ * 0.
+ * <p>
+ * We first find the range of values in our tensor. The
+ * range we use is always centered on 0, so we find m such that
+ * <pre>{@code
+ *   m = max(abs(input_min), abs(input_max))
+ * }</pre>
+ * Our input tensor range is then `[-m, m]`.
+ * <p>
+ * Next, we choose our fixed-point quantization buckets, `[min_fixed, max_fixed]`.
+ * If T is signed, this is
+ * <pre>{@code
+ *   num_bits = sizeof(T) * 8
+ *   [min_fixed, max_fixed] =
+ *       [-(1 << (num_bits - 1) - 1), (1 << (num_bits - 1)) - 1]
+ * }</pre>
+ * Otherwise, if T is unsigned, the fixed-point range is
+ * <pre>{@code
+ *   [min_fixed, max_fixed] = [0, (1 << num_bits) - 1]
+ * }</pre>
+ * From this we compute our scaling factor, s:
+ * <pre>{@code
+ *   s = (2 * m) / (max_fixed - min_fixed)
+ * }</pre>
+ * Now we can dequantize the elements of our tensor:
+ * <pre>{@code
+ * result = input * s
+ * }</pre>
+ * 
+ */
+@Operator
+public final class Dequantize extends PrimitiveOp implements Operand<Float> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Dequantize}
+   */
+  public static class Options {
+    
+    /**
+     * @param mode 
+     */
+    public Options mode(String mode) {
+      this.mode = mode;
+      return this;
+    }
+    
+    private String mode;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Dequantize operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param minRange The minimum scalar value possibly produced for the input.
+   * @param maxRange The maximum scalar value possibly produced for the input.
+   * @param options carries optional attributes values
+   * @return a new instance of Dequantize
+   */
+  public static <T> Dequantize create(Scope scope, Operand<T> input, Operand<Float> minRange, Operand<Float> maxRange, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Dequantize", scope.makeOpName("Dequantize"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(minRange.asOutput());
+    opBuilder.addInput(maxRange.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.mode != null) {
+          opBuilder.setAttr("mode", opts.mode);
+        }
+      }
+    }
+    return new Dequantize(opBuilder.build());
+  }
+  
+  /**
+   * @param mode 
+   */
+  public static Options mode(String mode) {
+    return new Options().mode(mode);
+  }
+  
+  /**
+   */
+  public Output<Float> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<Float> asOutput() {
+    return output;
+  }
+  
+  private Output<Float> output;
+  
+  private Dequantize(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/DeserializeIterator.java java-ops/org/tensorflow/op/core/DeserializeIterator.java
--- java/org/tensorflow/op/core/DeserializeIterator.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/DeserializeIterator.java	2018-10-16 20:18:38.252432367 +0900
@@ -0,0 +1,53 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Converts the given variant tensor to an iterator and stores it in the given resource.
+ */
+@Operator
+public final class DeserializeIterator extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new DeserializeIterator operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param resourceHandle A handle to an iterator resource.
+   * @param serialized A variant tensor storing the state of the iterator contained in the
+   * resource.
+   * @return a new instance of DeserializeIterator
+   */
+  public static DeserializeIterator create(Scope scope, Operand<?> resourceHandle, Operand<?> serialized) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("DeserializeIterator", scope.makeOpName("DeserializeIterator"));
+    opBuilder.addInput(resourceHandle.asOutput());
+    opBuilder.addInput(serialized.asOutput());
+    return new DeserializeIterator(opBuilder.build());
+  }
+  
+  
+  private DeserializeIterator(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/DeserializeManySparse.java java-ops/org/tensorflow/op/core/DeserializeManySparse.java
--- java/org/tensorflow/op/core/DeserializeManySparse.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/DeserializeManySparse.java	2018-10-16 20:18:38.253432366 +0900
@@ -0,0 +1,124 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Deserialize and concatenate `SparseTensors` from a serialized minibatch.
+ * <p>
+ * The input `serialized_sparse` must be a string matrix of shape `[N x 3]` where
+ * `N` is the minibatch size and the rows correspond to packed outputs of
+ * `SerializeSparse`.  The ranks of the original `SparseTensor` objects
+ * must all match.  When the final `SparseTensor` is created, it has rank one
+ * higher than the ranks of the incoming `SparseTensor` objects
+ * (they have been concatenated along a new row dimension).
+ * <p>
+ * The output `SparseTensor` object's shape values for all dimensions but the
+ * first are the max across the input `SparseTensor` objects' shape values
+ * for the corresponding dimensions.  Its first shape value is `N`, the minibatch
+ * size.
+ * <p>
+ * The input `SparseTensor` objects' indices are assumed ordered in
+ * standard lexicographic order.  If this is not the case, after this
+ * step run `SparseReorder` to restore index ordering.
+ * <p>
+ * For example, if the serialized input is a `[2 x 3]` matrix representing two
+ * original `SparseTensor` objects:
+ * <p>
+ *     index = [ 0]
+ *             [10]
+ *             [20]
+ *     values = [1, 2, 3]
+ *     shape = [50]
+ * <p>
+ * and
+ * <p>
+ *     index = [ 2]
+ *             [10]
+ *     values = [4, 5]
+ *     shape = [30]
+ * <p>
+ * then the final deserialized `SparseTensor` will be:
+ * <p>
+ *     index = [0  0]
+ *             [0 10]
+ *             [0 20]
+ *             [1  2]
+ *             [1 10]
+ *     values = [1, 2, 3, 4, 5]
+ *     shape = [2 50]
+ * 
+ * @param <T> data type for {@code sparseValues()} output
+ */
+@Operator
+public final class DeserializeManySparse<T> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new DeserializeManySparse operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param serializedSparse 2-D, The `N` serialized `SparseTensor` objects.
+   * Must have 3 columns.
+   * @param dtype The `dtype` of the serialized `SparseTensor` objects.
+   * @return a new instance of DeserializeManySparse
+   */
+  public static <T> DeserializeManySparse<T> create(Scope scope, Operand<String> serializedSparse, Class<T> dtype) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("DeserializeManySparse", scope.makeOpName("DeserializeManySparse"));
+    opBuilder.addInput(serializedSparse.asOutput());
+    opBuilder.setAttr("dtype", DataType.fromClass(dtype));
+    return new DeserializeManySparse<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<Long> sparseIndices() {
+    return sparseIndices;
+  }
+  
+  /**
+   */
+  public Output<T> sparseValues() {
+    return sparseValues;
+  }
+  
+  /**
+   */
+  public Output<Long> sparseShape() {
+    return sparseShape;
+  }
+  
+  private Output<Long> sparseIndices;
+  private Output<T> sparseValues;
+  private Output<Long> sparseShape;
+  
+  private DeserializeManySparse(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    sparseIndices = operation.output(outputIdx++);
+    sparseValues = operation.output(outputIdx++);
+    sparseShape = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/DeserializeSparse.java java-ops/org/tensorflow/op/core/DeserializeSparse.java
--- java/org/tensorflow/op/core/DeserializeSparse.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/DeserializeSparse.java	2018-10-16 20:18:38.254432365 +0900
@@ -0,0 +1,124 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Deserialize `SparseTensor` objects.
+ * <p>
+ * The input `serialized_sparse` must have the shape `[?, ?, ..., ?, 3]` where
+ * the last dimension stores serialized `SparseTensor` objects and the other N
+ * dimensions (N >= 0) correspond to a batch. The ranks of the original
+ * `SparseTensor` objects must all match. When the final `SparseTensor` is
+ * created, its rank is the rank of the incoming `SparseTensor` objects plus N;
+ * the sparse tensors have been concatenated along new dimensions, one for each
+ * batch.
+ * <p>
+ * The output `SparseTensor` object's shape values for the original dimensions
+ * are the max across the input `SparseTensor` objects' shape values for the
+ * corresponding dimensions. The new dimensions match the size of the batch.
+ * <p>
+ * The input `SparseTensor` objects' indices are assumed ordered in
+ * standard lexicographic order.  If this is not the case, after this
+ * step run `SparseReorder` to restore index ordering.
+ * <p>
+ * For example, if the serialized input is a `[2 x 3]` matrix representing two
+ * original `SparseTensor` objects:
+ * <p>
+ *     index = [ 0]
+ *             [10]
+ *             [20]
+ *     values = [1, 2, 3]
+ *     shape = [50]
+ * <p>
+ * and
+ * <p>
+ *     index = [ 2]
+ *             [10]
+ *     values = [4, 5]
+ *     shape = [30]
+ * <p>
+ * then the final deserialized `SparseTensor` will be:
+ * <p>
+ *     index = [0  0]
+ *             [0 10]
+ *             [0 20]
+ *             [1  2]
+ *             [1 10]
+ *     values = [1, 2, 3, 4, 5]
+ *     shape = [2 50]
+ * 
+ * @param <U> data type for {@code sparseValues()} output
+ */
+@Operator
+public final class DeserializeSparse<U> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new DeserializeSparse operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param serializedSparse The serialized `SparseTensor` objects. The last dimension
+   * must have 3 columns.
+   * @param dtype The `dtype` of the serialized `SparseTensor` objects.
+   * @return a new instance of DeserializeSparse
+   */
+  public static <U, T> DeserializeSparse<U> create(Scope scope, Operand<T> serializedSparse, Class<U> dtype) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("DeserializeSparse", scope.makeOpName("DeserializeSparse"));
+    opBuilder.addInput(serializedSparse.asOutput());
+    opBuilder.setAttr("dtype", DataType.fromClass(dtype));
+    return new DeserializeSparse<U>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<Long> sparseIndices() {
+    return sparseIndices;
+  }
+  
+  /**
+   */
+  public Output<U> sparseValues() {
+    return sparseValues;
+  }
+  
+  /**
+   */
+  public Output<Long> sparseShape() {
+    return sparseShape;
+  }
+  
+  private Output<Long> sparseIndices;
+  private Output<U> sparseValues;
+  private Output<Long> sparseShape;
+  
+  private DeserializeSparse(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    sparseIndices = operation.output(outputIdx++);
+    sparseValues = operation.output(outputIdx++);
+    sparseShape = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/DestroyResourceOp.java java-ops/org/tensorflow/op/core/DestroyResourceOp.java
--- java/org/tensorflow/op/core/DestroyResourceOp.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/DestroyResourceOp.java	2018-10-16 20:18:38.255432365 +0900
@@ -0,0 +1,89 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Deletes the resource specified by the handle.
+ * <p>
+ * All subsequent operations using the resource will result in a NotFound
+ * error status.
+ */
+@Operator
+public final class DestroyResourceOp extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.DestroyResourceOp}
+   */
+  public static class Options {
+    
+    /**
+     * @param ignoreLookupError whether to ignore the error when the resource
+     * doesn't exist.
+     */
+    public Options ignoreLookupError(Boolean ignoreLookupError) {
+      this.ignoreLookupError = ignoreLookupError;
+      return this;
+    }
+    
+    private Boolean ignoreLookupError;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new DestroyResourceOp operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param resource handle to the resource to delete.
+   * @param options carries optional attributes values
+   * @return a new instance of DestroyResourceOp
+   */
+  public static DestroyResourceOp create(Scope scope, Operand<?> resource, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("DestroyResourceOp", scope.makeOpName("DestroyResourceOp"));
+    opBuilder.addInput(resource.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.ignoreLookupError != null) {
+          opBuilder.setAttr("ignore_lookup_error", opts.ignoreLookupError);
+        }
+      }
+    }
+    return new DestroyResourceOp(opBuilder.build());
+  }
+  
+  /**
+   * @param ignoreLookupError whether to ignore the error when the resource
+   * doesn't exist.
+   */
+  public static Options ignoreLookupError(Boolean ignoreLookupError) {
+    return new Options().ignoreLookupError(ignoreLookupError);
+  }
+  
+  
+  private DestroyResourceOp(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/DestroyTemporaryVariable.java java-ops/org/tensorflow/op/core/DestroyTemporaryVariable.java
--- java/org/tensorflow/op/core/DestroyTemporaryVariable.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/DestroyTemporaryVariable.java	2018-10-16 20:18:38.255432365 +0900
@@ -0,0 +1,78 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Destroys the temporary variable and returns its final value.
+ * <p>
+ * Sets output to the value of the Tensor pointed to by 'ref', then destroys
+ * the temporary variable called 'var_name'.
+ * All other uses of 'ref' <i>must</i> have executed before this op.
+ * This is typically achieved by chaining the ref through each assign op, or by
+ * using control dependencies.
+ * <p>
+ * Outputs the final value of the tensor pointed to by 'ref'.
+ * 
+ * @param <T> data type for {@code value()} output
+ */
+@Operator
+public final class DestroyTemporaryVariable<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new DestroyTemporaryVariable operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param ref A reference to the temporary variable tensor.
+   * @param varName Name of the temporary variable, usually the name of the matching
+   * 'TemporaryVariable' op.
+   * @return a new instance of DestroyTemporaryVariable
+   */
+  public static <T> DestroyTemporaryVariable<T> create(Scope scope, Operand<T> ref, String varName) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("DestroyTemporaryVariable", scope.makeOpName("DestroyTemporaryVariable"));
+    opBuilder.addInput(ref.asOutput());
+    opBuilder.setAttr("var_name", varName);
+    return new DestroyTemporaryVariable<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> value() {
+    return value;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return value;
+  }
+  
+  private Output<T> value;
+  
+  private DestroyTemporaryVariable(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    value = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Diag.java java-ops/org/tensorflow/op/core/Diag.java
--- java/org/tensorflow/op/core/Diag.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Diag.java	2018-10-16 20:18:38.256432364 +0900
@@ -0,0 +1,85 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns a diagonal tensor with a given diagonal values.
+ * <p>
+ * Given a `diagonal`, this operation returns a tensor with the `diagonal` and
+ * everything else padded with zeros. The diagonal is computed as follows:
+ * <p>
+ * Assume `diagonal` has dimensions [D1,..., Dk], then the output is a tensor of
+ * rank 2k with dimensions [D1,..., Dk, D1,..., Dk] where:
+ * <p>
+ * `output[i1,..., ik, i1,..., ik] = diagonal[i1, ..., ik]` and 0 everywhere else.
+ * <p>
+ * For example:
+ * <pre>{@code
+ * # 'diagonal' is [1, 2, 3, 4]
+ * tf.diag(diagonal) ==> [[1, 0, 0, 0]
+ *                        [0, 2, 0, 0]
+ *                        [0, 0, 3, 0]
+ *                        [0, 0, 0, 4]]
+ * }</pre>
+ * 
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class Diag<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Diag operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param diagonal Rank k tensor where k is at most 1.
+   * @return a new instance of Diag
+   */
+  public static <T> Diag<T> create(Scope scope, Operand<T> diagonal) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Diag", scope.makeOpName("Diag"));
+    opBuilder.addInput(diagonal.asOutput());
+    return new Diag<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private Diag(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/DiagPart.java java-ops/org/tensorflow/op/core/DiagPart.java
--- java/org/tensorflow/op/core/DiagPart.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/DiagPart.java	2018-10-16 20:18:38.256432364 +0900
@@ -0,0 +1,87 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns the diagonal part of the tensor.
+ * <p>
+ * This operation returns a tensor with the `diagonal` part
+ * of the `input`. The `diagonal` part is computed as follows:
+ * <p>
+ * Assume `input` has dimensions `[D1,..., Dk, D1,..., Dk]`, then the output is a
+ * tensor of rank `k` with dimensions `[D1,..., Dk]` where:
+ * <p>
+ * `diagonal[i1,..., ik] = input[i1, ..., ik, i1,..., ik]`.
+ * <p>
+ * For example:
+ * <pre>{@code
+ * # 'input' is [[1, 0, 0, 0]
+ *               [0, 2, 0, 0]
+ *               [0, 0, 3, 0]
+ *               [0, 0, 0, 4]]
+ * 
+ * tf.diag_part(input) ==> [1, 2, 3, 4]
+ * }</pre>
+ * 
+ * 
+ * @param <T> data type for {@code diagonal()} output
+ */
+@Operator
+public final class DiagPart<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new DiagPart operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input Rank k tensor where k is even and not zero.
+   * @return a new instance of DiagPart
+   */
+  public static <T> DiagPart<T> create(Scope scope, Operand<T> input) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("DiagPart", scope.makeOpName("DiagPart"));
+    opBuilder.addInput(input.asOutput());
+    return new DiagPart<T>(opBuilder.build());
+  }
+  
+  /**
+   * The extracted diagonal.
+   */
+  public Output<T> diagonal() {
+    return diagonal;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return diagonal;
+  }
+  
+  private Output<T> diagonal;
+  
+  private DiagPart(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    diagonal = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Digamma.java java-ops/org/tensorflow/op/core/Digamma.java
--- java/org/tensorflow/op/core/Digamma.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Digamma.java	2018-10-16 20:18:38.256432364 +0900
@@ -0,0 +1,69 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes Psi, the derivative of Lgamma (the log of the absolute value of
+ * <p>
+ * `Gamma(x)`), element-wise.
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class Digamma<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Digamma operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of Digamma
+   */
+  public static <T extends Number> Digamma<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Digamma", scope.makeOpName("Digamma"));
+    opBuilder.addInput(x.asOutput());
+    return new Digamma<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private Digamma(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Dilation2DBackpropFilter.java java-ops/org/tensorflow/op/core/Dilation2DBackpropFilter.java
--- java/org/tensorflow/op/core/Dilation2DBackpropFilter.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Dilation2DBackpropFilter.java	2018-10-16 20:18:38.258432362 +0900
@@ -0,0 +1,89 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the gradient of morphological 2-D dilation with respect to the filter.
+ * 
+ * @param <T> data type for {@code filterBackprop()} output
+ */
+@Operator
+public final class Dilation2DBackpropFilter<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Dilation2DBackpropFilter operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 4-D with shape `[batch, in_height, in_width, depth]`.
+   * @param filter 3-D with shape `[filter_height, filter_width, depth]`.
+   * @param outBackprop 4-D with shape `[batch, out_height, out_width, depth]`.
+   * @param strides 1-D of length 4. The stride of the sliding window for each dimension of
+   * the input tensor. Must be: `[1, stride_height, stride_width, 1]`.
+   * @param rates 1-D of length 4. The input stride for atrous morphological dilation.
+   * Must be: `[1, rate_height, rate_width, 1]`.
+   * @param padding The type of padding algorithm to use.
+   * @return a new instance of Dilation2DBackpropFilter
+   */
+  public static <T extends Number> Dilation2DBackpropFilter<T> create(Scope scope, Operand<T> input, Operand<T> filter, Operand<T> outBackprop, List<Long> strides, List<Long> rates, String padding) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Dilation2DBackpropFilter", scope.makeOpName("Dilation2DBackpropFilter"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(filter.asOutput());
+    opBuilder.addInput(outBackprop.asOutput());
+    long[] stridesArray = new long[strides.size()];
+    for (int i = 0; i < stridesArray.length; ++i) {
+      stridesArray[i] = strides.get(i);
+    }
+    opBuilder.setAttr("strides", stridesArray);
+    long[] ratesArray = new long[rates.size()];
+    for (int i = 0; i < ratesArray.length; ++i) {
+      ratesArray[i] = rates.get(i);
+    }
+    opBuilder.setAttr("rates", ratesArray);
+    opBuilder.setAttr("padding", padding);
+    return new Dilation2DBackpropFilter<T>(opBuilder.build());
+  }
+  
+  /**
+   * 3-D with shape `[filter_height, filter_width, depth]`.
+   */
+  public Output<T> filterBackprop() {
+    return filterBackprop;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return filterBackprop;
+  }
+  
+  private Output<T> filterBackprop;
+  
+  private Dilation2DBackpropFilter(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    filterBackprop = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Dilation2DBackpropInput.java java-ops/org/tensorflow/op/core/Dilation2DBackpropInput.java
--- java/org/tensorflow/op/core/Dilation2DBackpropInput.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Dilation2DBackpropInput.java	2018-10-16 20:18:38.259432362 +0900
@@ -0,0 +1,89 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the gradient of morphological 2-D dilation with respect to the input.
+ * 
+ * @param <T> data type for {@code inBackprop()} output
+ */
+@Operator
+public final class Dilation2DBackpropInput<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Dilation2DBackpropInput operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 4-D with shape `[batch, in_height, in_width, depth]`.
+   * @param filter 3-D with shape `[filter_height, filter_width, depth]`.
+   * @param outBackprop 4-D with shape `[batch, out_height, out_width, depth]`.
+   * @param strides 1-D of length 4. The stride of the sliding window for each dimension of
+   * the input tensor. Must be: `[1, stride_height, stride_width, 1]`.
+   * @param rates 1-D of length 4. The input stride for atrous morphological dilation.
+   * Must be: `[1, rate_height, rate_width, 1]`.
+   * @param padding The type of padding algorithm to use.
+   * @return a new instance of Dilation2DBackpropInput
+   */
+  public static <T extends Number> Dilation2DBackpropInput<T> create(Scope scope, Operand<T> input, Operand<T> filter, Operand<T> outBackprop, List<Long> strides, List<Long> rates, String padding) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Dilation2DBackpropInput", scope.makeOpName("Dilation2DBackpropInput"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(filter.asOutput());
+    opBuilder.addInput(outBackprop.asOutput());
+    long[] stridesArray = new long[strides.size()];
+    for (int i = 0; i < stridesArray.length; ++i) {
+      stridesArray[i] = strides.get(i);
+    }
+    opBuilder.setAttr("strides", stridesArray);
+    long[] ratesArray = new long[rates.size()];
+    for (int i = 0; i < ratesArray.length; ++i) {
+      ratesArray[i] = rates.get(i);
+    }
+    opBuilder.setAttr("rates", ratesArray);
+    opBuilder.setAttr("padding", padding);
+    return new Dilation2DBackpropInput<T>(opBuilder.build());
+  }
+  
+  /**
+   * 4-D with shape `[batch, in_height, in_width, depth]`.
+   */
+  public Output<T> inBackprop() {
+    return inBackprop;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return inBackprop;
+  }
+  
+  private Output<T> inBackprop;
+  
+  private Dilation2DBackpropInput(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    inBackprop = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Dilation2D.java java-ops/org/tensorflow/op/core/Dilation2D.java
--- java/org/tensorflow/op/core/Dilation2D.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Dilation2D.java	2018-10-16 20:18:38.257432363 +0900
@@ -0,0 +1,111 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the grayscale dilation of 4-D `input` and 3-D `filter` tensors.
+ * <p>
+ * The `input` tensor has shape `[batch, in_height, in_width, depth]` and the
+ * `filter` tensor has shape `[filter_height, filter_width, depth]`, i.e., each
+ * input channel is processed independently of the others with its own structuring
+ * function. The `output` tensor has shape
+ * `[batch, out_height, out_width, depth]`. The spatial dimensions of the output
+ * tensor depend on the `padding` algorithm. We currently only support the default
+ * "NHWC" `data_format`.
+ * <p>
+ * In detail, the grayscale morphological 2-D dilation is the max-sum correlation
+ * (for consistency with `conv2d`, we use unmirrored filters):
+ * <p>
+ *     output[b, y, x, c] =
+ *        max_{dy, dx} input[b,
+ *                           strides[1] * y + rates[1] * dy,
+ *                           strides[2] * x + rates[2] * dx,
+ *                           c] +
+ *                     filter[dy, dx, c]
+ * <p>
+ * Max-pooling is a special case when the filter has size equal to the pooling
+ * kernel size and contains all zeros.
+ * <p>
+ * Note on duality: The dilation of `input` by the `filter` is equal to the
+ * negation of the erosion of `-input` by the reflected `filter`.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class Dilation2D<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Dilation2D operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 4-D with shape `[batch, in_height, in_width, depth]`.
+   * @param filter 3-D with shape `[filter_height, filter_width, depth]`.
+   * @param strides The stride of the sliding window for each dimension of the input
+   * tensor. Must be: `[1, stride_height, stride_width, 1]`.
+   * @param rates The input stride for atrous morphological dilation. Must be:
+   * `[1, rate_height, rate_width, 1]`.
+   * @param padding The type of padding algorithm to use.
+   * @return a new instance of Dilation2D
+   */
+  public static <T extends Number> Dilation2D<T> create(Scope scope, Operand<T> input, Operand<T> filter, List<Long> strides, List<Long> rates, String padding) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Dilation2D", scope.makeOpName("Dilation2D"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(filter.asOutput());
+    long[] stridesArray = new long[strides.size()];
+    for (int i = 0; i < stridesArray.length; ++i) {
+      stridesArray[i] = strides.get(i);
+    }
+    opBuilder.setAttr("strides", stridesArray);
+    long[] ratesArray = new long[rates.size()];
+    for (int i = 0; i < ratesArray.length; ++i) {
+      ratesArray[i] = rates.get(i);
+    }
+    opBuilder.setAttr("rates", ratesArray);
+    opBuilder.setAttr("padding", padding);
+    return new Dilation2D<T>(opBuilder.build());
+  }
+  
+  /**
+   * 4-D with shape `[batch, out_height, out_width, depth]`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private Dilation2D(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Div.java java-ops/org/tensorflow/op/core/Div.java
--- java/org/tensorflow/op/core/Div.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Div.java	2018-10-16 20:18:38.259432362 +0900
@@ -0,0 +1,72 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns x / y element-wise.
+ * <p>
+ * <i>NOTE</i>: `Div` supports broadcasting. More about broadcasting
+ * [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
+ * 
+ * @param <T> data type for {@code z()} output
+ */
+@Operator
+public final class Div<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Div operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param y 
+   * @return a new instance of Div
+   */
+  public static <T> Div<T> create(Scope scope, Operand<T> x, Operand<T> y) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Div", scope.makeOpName("Div"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(y.asOutput());
+    return new Div<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return z;
+  }
+  
+  private Output<T> z;
+  
+  private Div(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/DivNoNan.java java-ops/org/tensorflow/op/core/DivNoNan.java
--- java/org/tensorflow/op/core/DivNoNan.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/DivNoNan.java	2018-10-16 20:18:38.260432361 +0900
@@ -0,0 +1,73 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns 0 if the denominator is zero.
+ * <p>
+ * 
+ * <i>NOTE</i>: `DivNoNan` supports broadcasting. More about broadcasting
+ * [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
+ * 
+ * @param <T> data type for {@code z()} output
+ */
+@Operator
+public final class DivNoNan<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new DivNoNan operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param y 
+   * @return a new instance of DivNoNan
+   */
+  public static <T extends Number> DivNoNan<T> create(Scope scope, Operand<T> x, Operand<T> y) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("DivNoNan", scope.makeOpName("DivNoNan"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(y.asOutput());
+    return new DivNoNan<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return z;
+  }
+  
+  private Output<T> z;
+  
+  private DivNoNan(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/DrawBoundingBoxes.java java-ops/org/tensorflow/op/core/DrawBoundingBoxes.java
--- java/org/tensorflow/op/core/DrawBoundingBoxes.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/DrawBoundingBoxes.java	2018-10-16 20:18:38.260432361 +0900
@@ -0,0 +1,84 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Draw bounding boxes on a batch of images.
+ * <p>
+ * Outputs a copy of `images` but draws on top of the pixels zero or more bounding
+ * boxes specified by the locations in `boxes`. The coordinates of the each
+ * bounding box in `boxes` are encoded as `[y_min, x_min, y_max, x_max]`. The
+ * bounding box coordinates are floats in `[0.0, 1.0]` relative to the width and
+ * height of the underlying image.
+ * <p>
+ * For example, if an image is 100 x 200 pixels (height x width) and the bounding
+ * box is `[0.1, 0.2, 0.5, 0.9]`, the upper-left and bottom-right coordinates of
+ * the bounding box will be `(40, 10)` to `(180, 50)` (in (x,y) coordinates).
+ * <p>
+ * Parts of the bounding box may fall outside the image.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class DrawBoundingBoxes<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new DrawBoundingBoxes operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param images 4-D with shape `[batch, height, width, depth]`. A batch of images.
+   * @param boxes 3-D with shape `[batch, num_bounding_boxes, 4]` containing bounding
+   * boxes.
+   * @return a new instance of DrawBoundingBoxes
+   */
+  public static <T extends Number> DrawBoundingBoxes<T> create(Scope scope, Operand<T> images, Operand<Float> boxes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("DrawBoundingBoxes", scope.makeOpName("DrawBoundingBoxes"));
+    opBuilder.addInput(images.asOutput());
+    opBuilder.addInput(boxes.asOutput());
+    return new DrawBoundingBoxes<T>(opBuilder.build());
+  }
+  
+  /**
+   * 4-D with the same shape as `images`. The batch of input images with
+   * bounding boxes drawn on the images.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private DrawBoundingBoxes(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/DynamicPartition.java java-ops/org/tensorflow/op/core/DynamicPartition.java
--- java/org/tensorflow/op/core/DynamicPartition.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/DynamicPartition.java	2018-10-16 20:18:38.261432360 +0900
@@ -0,0 +1,112 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.Iterator;
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Partitions `data` into `num_partitions` tensors using indices from `partitions`.
+ * <p>
+ * For each index tuple `js` of size `partitions.ndim`, the slice `data[js, ...]`
+ * becomes part of `outputs[partitions[js]]`.  The slices with `partitions[js] = i`
+ * are placed in `outputs[i]` in lexicographic order of `js`, and the first
+ * dimension of `outputs[i]` is the number of entries in `partitions` equal to `i`.
+ * In detail,
+ * <pre>{@code
+ *     outputs[i].shape = [sum(partitions == i)] + data.shape[partitions.ndim:]
+ * 
+ *     outputs[i] = pack([data[js, ...] for js if partitions[js] == i])
+ * }</pre>
+ * `data.shape` must start with `partitions.shape`.
+ * <p>
+ * For example:
+ * <pre>{@code
+ *     # Scalar partitions.
+ *     partitions = 1
+ *     num_partitions = 2
+ *     data = [10, 20]
+ *     outputs[0] = []  # Empty with shape [0, 2]
+ *     outputs[1] = [[10, 20]]
+ * 
+ *     # Vector partitions.
+ *     partitions = [0, 0, 1, 1, 0]
+ *     num_partitions = 2
+ *     data = [10, 20, 30, 40, 50]
+ *     outputs[0] = [10, 20, 50]
+ *     outputs[1] = [30, 40]
+ * }</pre>
+ * See `dynamic_stitch` for an example on how to merge partitions back.
+ * <p>
+ * <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
+ * <img style="width:100%" src="https://www.tensorflow.org/images/DynamicPartition.png" alt>
+ * </div>
+ * 
+ * @param <T> data type for {@code outputs()} output
+ */
+@Operator
+public final class DynamicPartition<T> extends PrimitiveOp implements Iterable<Operand<T>> {
+  
+  /**
+   * Factory method to create a class to wrap a new DynamicPartition operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param data 
+   * @param partitions Any shape.  Indices in the range `[0, num_partitions)`.
+   * @param numPartitions The number of partitions to output.
+   * @return a new instance of DynamicPartition
+   */
+  public static <T> DynamicPartition<T> create(Scope scope, Operand<T> data, Operand<Integer> partitions, Long numPartitions) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("DynamicPartition", scope.makeOpName("DynamicPartition"));
+    opBuilder.addInput(data.asOutput());
+    opBuilder.addInput(partitions.asOutput());
+    opBuilder.setAttr("num_partitions", numPartitions);
+    return new DynamicPartition<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public List<Output<T>> outputs() {
+    return outputs;
+  }
+  
+  @Override
+  @SuppressWarnings({"rawtypes", "unchecked"})
+  public Iterator<Operand<T>> iterator() {
+    return (Iterator) outputs.iterator();
+  }
+  
+  private List<Output<T>> outputs;
+  
+  @SuppressWarnings("unchecked")
+  private DynamicPartition(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    int outputsLength = operation.outputListLength("outputs");
+    outputs = Arrays.asList((Output<T>[])operation.outputList(outputIdx, outputsLength));
+    outputIdx += outputsLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/DynamicStitch.java java-ops/org/tensorflow/op/core/DynamicStitch.java
--- java/org/tensorflow/op/core/DynamicStitch.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/DynamicStitch.java	2018-10-16 20:18:38.262432359 +0900
@@ -0,0 +1,125 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Interleave the values from the `data` tensors into a single tensor.
+ * <p>
+ * Builds a merged tensor such that
+ * <pre>{@code
+ *     merged[indices[m][i, ..., j], ...] = data[m][i, ..., j, ...]
+ * }</pre>
+ * For example, if each `indices[m]` is scalar or vector, we have
+ * <pre>{@code
+ *     # Scalar indices:
+ *     merged[indices[m], ...] = data[m][...]
+ * 
+ *     # Vector indices:
+ *     merged[indices[m][i], ...] = data[m][i, ...]
+ * }</pre>
+ * Each `data[i].shape` must start with the corresponding `indices[i].shape`,
+ * and the rest of `data[i].shape` must be constant w.r.t. `i`.  That is, we
+ * must have `data[i].shape = indices[i].shape + constant`.  In terms of this
+ * `constant`, the output shape is
+ * <p>
+ *     merged.shape = [max(indices)] + constant
+ * <p>
+ * Values are merged in order, so if an index appears in both `indices[m][i]` and
+ * `indices[n][j]` for `(m,i) < (n,j)` the slice `data[n][j]` will appear in the
+ * merged result. If you do not need this guarantee, ParallelDynamicStitch might
+ * perform better on some devices.
+ * <p>
+ * For example:
+ * <pre>{@code
+ *     indices[0] = 6
+ *     indices[1] = [4, 1]
+ *     indices[2] = [[5, 2], [0, 3]]
+ *     data[0] = [61, 62]
+ *     data[1] = [[41, 42], [11, 12]]
+ *     data[2] = [[[51, 52], [21, 22]], [[1, 2], [31, 32]]]
+ *     merged = [[1, 2], [11, 12], [21, 22], [31, 32], [41, 42],
+ *               [51, 52], [61, 62]]
+ * }</pre>
+ * This method can be used to merge partitions created by `dynamic_partition`
+ * as illustrated on the following example:
+ * <pre>{@code
+ *     # Apply function (increments x_i) on elements for which a certain condition
+ *     # apply (x_i != -1 in this example).
+ *     x=tf.constant([0.1, -1., 5.2, 4.3, -1., 7.4])
+ *     condition_mask=tf.not_equal(x,tf.constant(-1.))
+ *     partitioned_data = tf.dynamic_partition(
+ *         x, tf.cast(condition_mask, tf.int32) , 2)
+ *     partitioned_data[1] = partitioned_data[1] + 1.0
+ *     condition_indices = tf.dynamic_partition(
+ *         tf.range(tf.shape(x)[0]), tf.cast(condition_mask, tf.int32) , 2)
+ *     x = tf.dynamic_stitch(condition_indices, partitioned_data)
+ *     # Here x=[1.1, -1., 6.2, 5.3, -1, 8.4], the -1. values remain
+ *     # unchanged.
+ * }</pre>
+ * <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
+ * <img style="width:100%" src="https://www.tensorflow.org/images/DynamicStitch.png" alt>
+ * </div>
+ * 
+ * @param <T> data type for {@code merged()} output
+ */
+@Operator
+public final class DynamicStitch<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new DynamicStitch operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param indices 
+   * @param data 
+   * @return a new instance of DynamicStitch
+   */
+  public static <T> DynamicStitch<T> create(Scope scope, Iterable<Operand<Integer>> indices, Operand<T> data) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("DynamicStitch", scope.makeOpName("DynamicStitch"));
+    opBuilder.addInputList(Operands.asOutputs(indices));
+    opBuilder.addInput(data.asOutput());
+    return new DynamicStitch<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> merged() {
+    return merged;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return merged;
+  }
+  
+  private Output<T> merged;
+  
+  private DynamicStitch(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    merged = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/EagerPyFunc.java java-ops/org/tensorflow/op/core/EagerPyFunc.java
--- java/org/tensorflow/op/core/EagerPyFunc.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/EagerPyFunc.java	2018-10-16 20:18:38.262432359 +0900
@@ -0,0 +1,84 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.Iterator;
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Eagerly executes a python function to compute func(input)->output. The
+ * <p>
+ * semantics of the input, output, and attributes are the same as those for
+ * PyFunc.
+ */
+@Operator
+public final class EagerPyFunc extends PrimitiveOp implements Iterable<Operand<Object>> {
+  
+  /**
+   * Factory method to create a class to wrap a new EagerPyFunc operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param token 
+   * @param Tout 
+   * @return a new instance of EagerPyFunc
+   */
+  public static EagerPyFunc create(Scope scope, Iterable<Operand<?>> input, String token, List<Class<?>> Tout) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("EagerPyFunc", scope.makeOpName("EagerPyFunc"));
+    opBuilder.addInputList(Operands.asOutputs(input));
+    opBuilder.setAttr("token", token);
+    DataType[] ToutArray = new DataType[Tout.size()];
+    for (int i = 0; i < ToutArray.length; ++i) {
+      ToutArray[i] = DataType.fromClass(Tout.get(i));
+    }
+    opBuilder.setAttr("Tout", ToutArray);
+    return new EagerPyFunc(opBuilder.build());
+  }
+  
+  /**
+   */
+  public List<Output<?>> output() {
+    return output;
+  }
+  
+  @Override
+  @SuppressWarnings({"rawtypes", "unchecked"})
+  public Iterator<Operand<Object>> iterator() {
+    return (Iterator) output.iterator();
+  }
+  
+  private List<Output<?>> output;
+  
+  private EagerPyFunc(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    int outputLength = operation.outputListLength("output");
+    output = Arrays.asList(operation.outputList(outputIdx, outputLength));
+    outputIdx += outputLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/EditDistance.java java-ops/org/tensorflow/op/core/EditDistance.java
--- java/org/tensorflow/op/core/EditDistance.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/EditDistance.java	2018-10-16 20:18:38.263432359 +0900
@@ -0,0 +1,155 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the (possibly normalized) Levenshtein Edit Distance.
+ * <p>
+ * The inputs are variable-length sequences provided by SparseTensors
+ *   (hypothesis_indices, hypothesis_values, hypothesis_shape)
+ * and
+ *   (truth_indices, truth_values, truth_shape).
+ * <p>
+ * The inputs are:
+ */
+@Operator
+public final class EditDistance extends PrimitiveOp implements Operand<Float> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.EditDistance}
+   */
+  public static class Options {
+    
+    /**
+     * @param normalize boolean (if true, edit distances are normalized by length of truth).
+     * <p>
+     * The output is:
+     */
+    public Options normalize(Boolean normalize) {
+      this.normalize = normalize;
+      return this;
+    }
+    
+    private Boolean normalize;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new EditDistance operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param hypothesisIndices The indices of the hypothesis list SparseTensor.
+   * This is an N x R int64 matrix.
+   * @param hypothesisValues The values of the hypothesis list SparseTensor.
+   * This is an N-length vector.
+   * @param hypothesisShape The shape of the hypothesis list SparseTensor.
+   * This is an R-length vector.
+   * @param truthIndices The indices of the truth list SparseTensor.
+   * This is an M x R int64 matrix.
+   * @param truthValues The values of the truth list SparseTensor.
+   * This is an M-length vector.
+   * @param truthShape truth indices, vector.
+   * @param options carries optional attributes values
+   * @return a new instance of EditDistance
+   */
+  public static <T> EditDistance create(Scope scope, Operand<Long> hypothesisIndices, Operand<T> hypothesisValues, Operand<Long> hypothesisShape, Operand<Long> truthIndices, Operand<T> truthValues, Operand<Long> truthShape, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("EditDistance", scope.makeOpName("EditDistance"));
+    opBuilder.addInput(hypothesisIndices.asOutput());
+    opBuilder.addInput(hypothesisValues.asOutput());
+    opBuilder.addInput(hypothesisShape.asOutput());
+    opBuilder.addInput(truthIndices.asOutput());
+    opBuilder.addInput(truthValues.asOutput());
+    opBuilder.addInput(truthShape.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.normalize != null) {
+          opBuilder.setAttr("normalize", opts.normalize);
+        }
+      }
+    }
+    return new EditDistance(opBuilder.build());
+  }
+  
+  /**
+   * @param normalize boolean (if true, edit distances are normalized by length of truth).
+   * <p>
+   * The output is:
+   */
+  public static Options normalize(Boolean normalize) {
+    return new Options().normalize(normalize);
+  }
+  
+  /**
+   * A dense float tensor with rank R - 1.
+   * <p>
+   * For the example input:
+   * <p>
+   *     // hypothesis represents a 2x1 matrix with variable-length values:
+   *     //   (0,0) = ["a"]
+   *     //   (1,0) = ["b"]
+   *     hypothesis_indices = [[0, 0, 0],
+   *                           [1, 0, 0]]
+   *     hypothesis_values = ["a", "b"]
+   *     hypothesis_shape = [2, 1, 1]
+   * <p>
+   *     // truth represents a 2x2 matrix with variable-length values:
+   *     //   (0,0) = []
+   *     //   (0,1) = ["a"]
+   *     //   (1,0) = ["b", "c"]
+   *     //   (1,1) = ["a"]
+   *     truth_indices = [[0, 1, 0],
+   *                      [1, 0, 0],
+   *                      [1, 0, 1],
+   *                      [1, 1, 0]]
+   *     truth_values = ["a", "b", "c", "a"]
+   *     truth_shape = [2, 2, 2]
+   *     normalize = true
+   * <p>
+   * The output will be:
+   * <p>
+   *     // output is a 2x2 matrix with edit distances normalized by truth lengths.
+   *     output = [[inf, 1.0],  // (0,0): no truth, (0,1): no hypothesis
+   *               [0.5, 1.0]]  // (1,0): addition, (1,1): no hypothesis
+   */
+  public Output<Float> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<Float> asOutput() {
+    return output;
+  }
+  
+  private Output<Float> output;
+  
+  private EditDistance(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/EluGrad.java java-ops/org/tensorflow/op/core/EluGrad.java
--- java/org/tensorflow/op/core/EluGrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/EluGrad.java	2018-10-16 20:18:38.264432358 +0900
@@ -0,0 +1,69 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Computes gradients for the exponential linear (Elu) operation.
+ * 
+ * @param <T> data type for {@code backprops()} output
+ */
+public final class EluGrad<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new EluGrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param gradients The backpropagated gradients to the corresponding Elu operation.
+   * @param outputs The outputs of the corresponding Elu operation.
+   * @return a new instance of EluGrad
+   */
+  public static <T extends Number> EluGrad<T> create(Scope scope, Operand<T> gradients, Operand<T> outputs) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("EluGrad", scope.makeOpName("EluGrad"));
+    opBuilder.addInput(gradients.asOutput());
+    opBuilder.addInput(outputs.asOutput());
+    return new EluGrad<T>(opBuilder.build());
+  }
+  
+  /**
+   * The gradients: `gradients * (outputs + 1)` if outputs < 0,
+   * `gradients` otherwise.
+   */
+  public Output<T> backprops() {
+    return backprops;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return backprops;
+  }
+  
+  private Output<T> backprops;
+  
+  private EluGrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    backprops = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Elu.java java-ops/org/tensorflow/op/core/Elu.java
--- java/org/tensorflow/op/core/Elu.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Elu.java	2018-10-16 20:18:38.264432358 +0900
@@ -0,0 +1,70 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes exponential linear: `exp(features) - 1` if < 0, `features` otherwise.
+ * <p>
+ * See [Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)
+ * ](http://arxiv.org/abs/1511.07289)
+ * 
+ * @param <T> data type for {@code activations()} output
+ */
+@Operator
+public final class Elu<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Elu operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param features 
+   * @return a new instance of Elu
+   */
+  public static <T extends Number> Elu<T> create(Scope scope, Operand<T> features) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Elu", scope.makeOpName("Elu"));
+    opBuilder.addInput(features.asOutput());
+    return new Elu<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> activations() {
+    return activations;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return activations;
+  }
+  
+  private Output<T> activations;
+  
+  private Elu(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    activations = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Empty.java java-ops/org/tensorflow/op/core/Empty.java
--- java/org/tensorflow/op/core/Empty.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Empty.java	2018-10-16 20:18:38.265432357 +0900
@@ -0,0 +1,107 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Creates a tensor with the given shape.
+ * <p>
+ * This operation creates a tensor of `shape` and `dtype`.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class Empty<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Empty}
+   */
+  public static class Options {
+    
+    /**
+     * @param init If True, initialize the returned tensor with the default value of dtype.  Otherwise, the implementation is free not to initializethe tensor's content.
+     */
+    public Options init(Boolean init) {
+      this.init = init;
+      return this;
+    }
+    
+    private Boolean init;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Empty operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param shape 1-D. Represents the shape of the output tensor.
+   * @param dtype 
+   * @param options carries optional attributes values
+   * @return a new instance of Empty
+   */
+  public static <T> Empty<T> create(Scope scope, Operand<Integer> shape, Class<T> dtype, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Empty", scope.makeOpName("Empty"));
+    opBuilder.addInput(shape.asOutput());
+    opBuilder.setAttr("dtype", DataType.fromClass(dtype));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.init != null) {
+          opBuilder.setAttr("init", opts.init);
+        }
+      }
+    }
+    return new Empty<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param init If True, initialize the returned tensor with the default value of dtype.  Otherwise, the implementation is free not to initializethe tensor's content.
+   */
+  public static Options init(Boolean init) {
+    return new Options().init(init);
+  }
+  
+  /**
+   * A `Tensor` of type `T`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private Empty(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/EmptyTensorList.java java-ops/org/tensorflow/op/core/EmptyTensorList.java
--- java/org/tensorflow/op/core/EmptyTensorList.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/EmptyTensorList.java	2018-10-16 20:18:38.265432357 +0900
@@ -0,0 +1,76 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Creates and returns an empty tensor list.
+ * <p>
+ * All list elements must be tensors of dtype element_dtype and shape compatible
+ * with element_shape.
+ * <p>
+ * handle: an empty tensor list.
+ * element_dtype: the type of elements in the list.
+ * element_shape: a shape compatible with that of elements in the list.
+ */
+@Operator
+public final class EmptyTensorList extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new EmptyTensorList operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param elementShape 
+   * @param elementDtype 
+   * @return a new instance of EmptyTensorList
+   */
+  public static <T extends Number, U> EmptyTensorList create(Scope scope, Operand<T> elementShape, Class<U> elementDtype) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("EmptyTensorList", scope.makeOpName("EmptyTensorList"));
+    opBuilder.addInput(elementShape.asOutput());
+    opBuilder.setAttr("element_dtype", DataType.fromClass(elementDtype));
+    return new EmptyTensorList(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private EmptyTensorList(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/EncodeBase64.java java-ops/org/tensorflow/op/core/EncodeBase64.java
--- java/org/tensorflow/op/core/EncodeBase64.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/EncodeBase64.java	2018-10-16 20:18:38.265432357 +0900
@@ -0,0 +1,107 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Encode strings into web-safe base64 format.
+ * <p>
+ * Refer to the following article for more information on base64 format:
+ * en.wikipedia.org/wiki/Base64. Base64 strings may have padding with '=' at the
+ * end so that the encoded has length multiple of 4. See Padding section of the
+ * link above.
+ * <p>
+ * Web-safe means that the encoder uses - and _ instead of + and /.
+ */
+@Operator
+public final class EncodeBase64 extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.EncodeBase64}
+   */
+  public static class Options {
+    
+    /**
+     * @param pad Bool whether padding is applied at the ends.
+     */
+    public Options pad(Boolean pad) {
+      this.pad = pad;
+      return this;
+    }
+    
+    private Boolean pad;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new EncodeBase64 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input Strings to be encoded.
+   * @param options carries optional attributes values
+   * @return a new instance of EncodeBase64
+   */
+  public static EncodeBase64 create(Scope scope, Operand<String> input, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("EncodeBase64", scope.makeOpName("EncodeBase64"));
+    opBuilder.addInput(input.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.pad != null) {
+          opBuilder.setAttr("pad", opts.pad);
+        }
+      }
+    }
+    return new EncodeBase64(opBuilder.build());
+  }
+  
+  /**
+   * @param pad Bool whether padding is applied at the ends.
+   */
+  public static Options pad(Boolean pad) {
+    return new Options().pad(pad);
+  }
+  
+  /**
+   * Input strings encoded in base64.
+   */
+  public Output<String> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return output;
+  }
+  
+  private Output<String> output;
+  
+  private EncodeBase64(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/EncodeJpeg.java java-ops/org/tensorflow/op/core/EncodeJpeg.java
--- java/org/tensorflow/op/core/EncodeJpeg.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/EncodeJpeg.java	2018-10-16 20:18:38.266432357 +0900
@@ -0,0 +1,281 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+import org.tensorflow.types.UInt8;
+
+/**
+ * JPEG-encode an image.
+ * <p>
+ * `image` is a 3-D uint8 Tensor of shape `[height, width, channels]`.
+ * <p>
+ * The attr `format` can be used to override the color format of the encoded
+ * output.  Values can be:
+ * <ul>
+ * <li>
+ * `''`: Use a default format based on the number of channels in the image.
+ * </li>
+ * <li>
+ * `grayscale`: Output a grayscale JPEG image.  The `channels` dimension
+ *     of `image` must be 1.
+ * </li>
+ * <li>
+ * `rgb`: Output an RGB JPEG image. The `channels` dimension
+ *     of `image` must be 3.
+ * </li>
+ * </ul>
+ * If `format` is not specified or is the empty string, a default format is picked
+ * in function of the number of channels in `image`:
+ * <ul>
+ * <li>
+ * 1: Output a grayscale image.
+ * </li>
+ * <li>
+ * 3: Output an RGB image.
+ */
+@Operator
+public final class EncodeJpeg extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.EncodeJpeg}
+   */
+  public static class Options {
+    
+    /**
+     * @param format Per pixel image format.
+     */
+    public Options format(String format) {
+      this.format = format;
+      return this;
+    }
+    
+    /**
+     * @param quality Quality of the compression from 0 to 100 (higher is better and slower).
+     */
+    public Options quality(Long quality) {
+      this.quality = quality;
+      return this;
+    }
+    
+    /**
+     * @param progressive If True, create a JPEG that loads progressively (coarse to fine).
+     */
+    public Options progressive(Boolean progressive) {
+      this.progressive = progressive;
+      return this;
+    }
+    
+    /**
+     * @param optimizeSize If True, spend CPU/RAM to reduce size with no quality change.
+     */
+    public Options optimizeSize(Boolean optimizeSize) {
+      this.optimizeSize = optimizeSize;
+      return this;
+    }
+    
+    /**
+     * @param chromaDownsampling See http://en.wikipedia.org/wiki/Chroma_subsampling.
+     */
+    public Options chromaDownsampling(Boolean chromaDownsampling) {
+      this.chromaDownsampling = chromaDownsampling;
+      return this;
+    }
+    
+    /**
+     * @param densityUnit Unit used to specify `x_density` and `y_density`:
+     * pixels per inch (`'in'`) or centimeter (`'cm'`).
+     */
+    public Options densityUnit(String densityUnit) {
+      this.densityUnit = densityUnit;
+      return this;
+    }
+    
+    /**
+     * @param xDensity Horizontal pixels per density unit.
+     */
+    public Options xDensity(Long xDensity) {
+      this.xDensity = xDensity;
+      return this;
+    }
+    
+    /**
+     * @param yDensity Vertical pixels per density unit.
+     */
+    public Options yDensity(Long yDensity) {
+      this.yDensity = yDensity;
+      return this;
+    }
+    
+    /**
+     * @param xmpMetadata If not empty, embed this XMP metadata in the image header.
+     */
+    public Options xmpMetadata(String xmpMetadata) {
+      this.xmpMetadata = xmpMetadata;
+      return this;
+    }
+    
+    private String format;
+    private Long quality;
+    private Boolean progressive;
+    private Boolean optimizeSize;
+    private Boolean chromaDownsampling;
+    private String densityUnit;
+    private Long xDensity;
+    private Long yDensity;
+    private String xmpMetadata;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new EncodeJpeg operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param image 3-D with shape `[height, width, channels]`.
+   * @param options carries optional attributes values
+   * @return a new instance of EncodeJpeg
+   */
+  public static EncodeJpeg create(Scope scope, Operand<UInt8> image, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("EncodeJpeg", scope.makeOpName("EncodeJpeg"));
+    opBuilder.addInput(image.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.format != null) {
+          opBuilder.setAttr("format", opts.format);
+        }
+        if (opts.quality != null) {
+          opBuilder.setAttr("quality", opts.quality);
+        }
+        if (opts.progressive != null) {
+          opBuilder.setAttr("progressive", opts.progressive);
+        }
+        if (opts.optimizeSize != null) {
+          opBuilder.setAttr("optimize_size", opts.optimizeSize);
+        }
+        if (opts.chromaDownsampling != null) {
+          opBuilder.setAttr("chroma_downsampling", opts.chromaDownsampling);
+        }
+        if (opts.densityUnit != null) {
+          opBuilder.setAttr("density_unit", opts.densityUnit);
+        }
+        if (opts.xDensity != null) {
+          opBuilder.setAttr("x_density", opts.xDensity);
+        }
+        if (opts.yDensity != null) {
+          opBuilder.setAttr("y_density", opts.yDensity);
+        }
+        if (opts.xmpMetadata != null) {
+          opBuilder.setAttr("xmp_metadata", opts.xmpMetadata);
+        }
+      }
+    }
+    return new EncodeJpeg(opBuilder.build());
+  }
+  
+  /**
+   * @param format Per pixel image format.
+   */
+  public static Options format(String format) {
+    return new Options().format(format);
+  }
+  
+  /**
+   * @param quality Quality of the compression from 0 to 100 (higher is better and slower).
+   */
+  public static Options quality(Long quality) {
+    return new Options().quality(quality);
+  }
+  
+  /**
+   * @param progressive If True, create a JPEG that loads progressively (coarse to fine).
+   */
+  public static Options progressive(Boolean progressive) {
+    return new Options().progressive(progressive);
+  }
+  
+  /**
+   * @param optimizeSize If True, spend CPU/RAM to reduce size with no quality change.
+   */
+  public static Options optimizeSize(Boolean optimizeSize) {
+    return new Options().optimizeSize(optimizeSize);
+  }
+  
+  /**
+   * @param chromaDownsampling See http://en.wikipedia.org/wiki/Chroma_subsampling.
+   */
+  public static Options chromaDownsampling(Boolean chromaDownsampling) {
+    return new Options().chromaDownsampling(chromaDownsampling);
+  }
+  
+  /**
+   * @param densityUnit Unit used to specify `x_density` and `y_density`:
+   * pixels per inch (`'in'`) or centimeter (`'cm'`).
+   */
+  public static Options densityUnit(String densityUnit) {
+    return new Options().densityUnit(densityUnit);
+  }
+  
+  /**
+   * @param xDensity Horizontal pixels per density unit.
+   */
+  public static Options xDensity(Long xDensity) {
+    return new Options().xDensity(xDensity);
+  }
+  
+  /**
+   * @param yDensity Vertical pixels per density unit.
+   */
+  public static Options yDensity(Long yDensity) {
+    return new Options().yDensity(yDensity);
+  }
+  
+  /**
+   * @param xmpMetadata If not empty, embed this XMP metadata in the image header.
+   */
+  public static Options xmpMetadata(String xmpMetadata) {
+    return new Options().xmpMetadata(xmpMetadata);
+  }
+  
+  /**
+   * 0-D. JPEG-encoded image.
+   */
+  public Output<String> contents() {
+    return contents;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return contents;
+  }
+  
+  private Output<String> contents;
+  
+  private EncodeJpeg(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    contents = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/EncodePng.java java-ops/org/tensorflow/op/core/EncodePng.java
--- java/org/tensorflow/op/core/EncodePng.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/EncodePng.java	2018-10-16 20:18:38.266432357 +0900
@@ -0,0 +1,120 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * PNG-encode an image.
+ * <p>
+ * `image` is a 3-D uint8 or uint16 Tensor of shape `[height, width, channels]`
+ * where `channels` is:
+ * <ul>
+ * <li>
+ * 1: for grayscale.
+ * </li>
+ * <li>
+ * 2: for grayscale + alpha.
+ * </li>
+ * <li>
+ * 3: for RGB.
+ * </li>
+ * <li>
+ * 4: for RGBA.
+ * </li>
+ * </ul>
+ * The ZLIB compression level, `compression`, can be -1 for the PNG-encoder
+ * default or a value from 0 to 9.  9 is the highest compression level, generating
+ * the smallest output, but is slower.
+ */
+@Operator
+public final class EncodePng extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.EncodePng}
+   */
+  public static class Options {
+    
+    /**
+     * @param compression Compression level.
+     */
+    public Options compression(Long compression) {
+      this.compression = compression;
+      return this;
+    }
+    
+    private Long compression;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new EncodePng operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param image 3-D with shape `[height, width, channels]`.
+   * @param options carries optional attributes values
+   * @return a new instance of EncodePng
+   */
+  public static <T extends Number> EncodePng create(Scope scope, Operand<T> image, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("EncodePng", scope.makeOpName("EncodePng"));
+    opBuilder.addInput(image.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.compression != null) {
+          opBuilder.setAttr("compression", opts.compression);
+        }
+      }
+    }
+    return new EncodePng(opBuilder.build());
+  }
+  
+  /**
+   * @param compression Compression level.
+   */
+  public static Options compression(Long compression) {
+    return new Options().compression(compression);
+  }
+  
+  /**
+   * 0-D. PNG-encoded image.
+   */
+  public Output<String> contents() {
+    return contents;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return contents;
+  }
+  
+  private Output<String> contents;
+  
+  private EncodePng(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    contents = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/EncodeProto.java java-ops/org/tensorflow/op/core/EncodeProto.java
--- java/org/tensorflow/op/core/EncodeProto.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/EncodeProto.java	2018-10-16 20:18:38.267432356 +0900
@@ -0,0 +1,150 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * The op serializes protobuf messages provided in the input tensors.
+ * <p>
+ * The types of the tensors in `values` must match the schema for the
+ * fields specified in `field_names`. All the tensors in `values` must
+ * have a common shape prefix, <i>batch_shape</i>.
+ * <p>
+ * The `sizes` tensor specifies repeat counts for each field.  The repeat
+ * count (last dimension) of a each tensor in `values` must be greater
+ * than or equal to corresponding repeat count in `sizes`.
+ * <p>
+ * A `message_type` name must be provided to give context for the field
+ * names. The actual message descriptor can be looked up either in the
+ * linked-in descriptor pool or a filename provided by the caller using
+ * the `descriptor_source` attribute.
+ * <p>
+ * The `descriptor_source` attribute selects a source of protocol
+ * descriptors to consult when looking up `message_type`. This may be a
+ * filename containing a serialized `FileDescriptorSet` message,
+ * or the special value `local://`, in which case only descriptors linked
+ * into the code will be searched; the filename can be on any filesystem
+ * accessible to TensorFlow.
+ * <p>
+ * You can build a `descriptor_source` file using the `--descriptor_set_out`
+ * and `--include_imports` options to the protocol compiler `protoc`.
+ * <p>
+ * The `local://` database only covers descriptors linked into the
+ * code via C++ libraries, not Python imports. You can link in a proto descriptor
+ * by creating a cc_library target with alwayslink=1.
+ * <p>
+ * There are a few special cases in the value mapping:
+ * <p>
+ * Submessage and group fields must be pre-serialized as TensorFlow strings.
+ * <p>
+ * TensorFlow lacks support for unsigned int64s, so they must be
+ * represented as `tf.int64` with the same twos-complement bit pattern
+ * (the obvious way).
+ * <p>
+ * Unsigned int32 values can be represented exactly with `tf.int64`, or
+ * with sign wrapping if the input is of type `tf.int32`.
+ */
+@Operator
+public final class EncodeProto extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.EncodeProto}
+   */
+  public static class Options {
+    
+    /**
+     * @param descriptorSource 
+     */
+    public Options descriptorSource(String descriptorSource) {
+      this.descriptorSource = descriptorSource;
+      return this;
+    }
+    
+    private String descriptorSource;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new EncodeProto operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param sizes Tensor of int32 with shape `[batch_shape, len(field_names)]`.
+   * @param values List of tensors containing values for the corresponding field.
+   * @param fieldNames List of strings containing proto field names.
+   * @param messageType Name of the proto message type to decode.
+   * @param options carries optional attributes values
+   * @return a new instance of EncodeProto
+   */
+  public static EncodeProto create(Scope scope, Operand<Integer> sizes, Iterable<Operand<?>> values, List<String> fieldNames, String messageType, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("EncodeProto", scope.makeOpName("EncodeProto"));
+    opBuilder.addInput(sizes.asOutput());
+    opBuilder.addInputList(Operands.asOutputs(values));
+    String[] fieldNamesArray = new String[fieldNames.size()];
+    for (int i = 0; i < fieldNamesArray.length; ++i) {
+      fieldNamesArray[i] = fieldNames.get(i);
+    }
+    opBuilder.setAttr("field_names", fieldNamesArray);
+    opBuilder.setAttr("message_type", messageType);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.descriptorSource != null) {
+          opBuilder.setAttr("descriptor_source", opts.descriptorSource);
+        }
+      }
+    }
+    return new EncodeProto(opBuilder.build());
+  }
+  
+  /**
+   * @param descriptorSource 
+   */
+  public static Options descriptorSource(String descriptorSource) {
+    return new Options().descriptorSource(descriptorSource);
+  }
+  
+  /**
+   * Tensor of serialized protos with shape `batch_shape`.
+   */
+  public Output<String> bytes() {
+    return bytes;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return bytes;
+  }
+  
+  private Output<String> bytes;
+  
+  private EncodeProto(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    bytes = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/EncodeWav.java java-ops/org/tensorflow/op/core/EncodeWav.java
--- java/org/tensorflow/op/core/EncodeWav.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/EncodeWav.java	2018-10-16 20:18:38.267432356 +0900
@@ -0,0 +1,76 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Encode audio data using the WAV file format.
+ * <p>
+ * This operation will generate a string suitable to be saved out to create a .wav
+ * audio file. It will be encoded in the 16-bit PCM format. It takes in float
+ * values in the range -1.0f to 1.0f, and any outside that value will be clamped to
+ * that range.
+ * <p>
+ * `audio` is a 2-D float Tensor of shape `[length, channels]`.
+ * `sample_rate` is a scalar Tensor holding the rate to use (e.g. 44100).
+ */
+@Operator
+public final class EncodeWav extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Factory method to create a class to wrap a new EncodeWav operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param audio 2-D with shape `[length, channels]`.
+   * @param sampleRate Scalar containing the sample frequency.
+   * @return a new instance of EncodeWav
+   */
+  public static EncodeWav create(Scope scope, Operand<Float> audio, Operand<Integer> sampleRate) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("EncodeWav", scope.makeOpName("EncodeWav"));
+    opBuilder.addInput(audio.asOutput());
+    opBuilder.addInput(sampleRate.asOutput());
+    return new EncodeWav(opBuilder.build());
+  }
+  
+  /**
+   * 0-D. WAV-encoded file contents.
+   */
+  public Output<String> contents() {
+    return contents;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return contents;
+  }
+  
+  private Output<String> contents;
+  
+  private EncodeWav(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    contents = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/EnqueueInQueueDataset.java java-ops/org/tensorflow/op/core/EnqueueInQueueDataset.java
--- java/org/tensorflow/op/core/EnqueueInQueueDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/EnqueueInQueueDataset.java	2018-10-16 20:18:38.268432355 +0900
@@ -0,0 +1,52 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ */
+@Operator
+public final class EnqueueInQueueDataset extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new EnqueueInQueueDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param queue 
+   * @param components 
+   * @return a new instance of EnqueueInQueueDataset
+   */
+  public static EnqueueInQueueDataset create(Scope scope, Operand<?> queue, Iterable<Operand<?>> components) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("EnqueueInQueueDataset", scope.makeOpName("EnqueueInQueueDataset"));
+    opBuilder.addInput(queue.asOutput());
+    opBuilder.addInputList(Operands.asOutputs(components));
+    return new EnqueueInQueueDataset(opBuilder.build());
+  }
+  
+  
+  private EnqueueInQueueDataset(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/EnsureShape.java java-ops/org/tensorflow/op/core/EnsureShape.java
--- java/org/tensorflow/op/core/EnsureShape.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/EnsureShape.java	2018-10-16 20:18:38.268432355 +0900
@@ -0,0 +1,74 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Ensures that the tensor's shape matches the expected shape.
+ * <p>
+ * Raises an error if the input tensor's shape does not match the specified shape.
+ * Returns the input tensor otherwise.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class EnsureShape<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new EnsureShape operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input A tensor, whose shape is to be validated.
+   * @param shape The expected (possibly partially specified) shape of the input tensor.
+   * @return a new instance of EnsureShape
+   */
+  public static <T> EnsureShape<T> create(Scope scope, Operand<T> input, Shape shape) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("EnsureShape", scope.makeOpName("EnsureShape"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.setAttr("shape", shape);
+    return new EnsureShape<T>(opBuilder.build());
+  }
+  
+  /**
+   * A tensor with the same shape and contents as the input tensor or value.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private EnsureShape(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Enter.java java-ops/org/tensorflow/op/core/Enter.java
--- java/org/tensorflow/op/core/Enter.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Enter.java	2018-10-16 20:18:38.268432355 +0900
@@ -0,0 +1,127 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Creates or finds a child frame, and makes `data` available to the child frame.
+ * <p>
+ * This op is used together with `Exit` to create loops in the graph.
+ * The unique `frame_name` is used by the `Executor` to identify frames. If
+ * `is_constant` is true, `output` is a constant in the child frame; otherwise
+ * it may be changed in the child frame. At most `parallel_iterations` iterations
+ * are run in parallel in the child frame.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+public final class Enter<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Enter}
+   */
+  public static class Options {
+    
+    /**
+     * @param isConstant If true, the output is constant within the child frame.
+     */
+    public Options isConstant(Boolean isConstant) {
+      this.isConstant = isConstant;
+      return this;
+    }
+    
+    /**
+     * @param parallelIterations The number of iterations allowed to run in parallel.
+     */
+    public Options parallelIterations(Long parallelIterations) {
+      this.parallelIterations = parallelIterations;
+      return this;
+    }
+    
+    private Boolean isConstant;
+    private Long parallelIterations;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Enter operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param data The tensor to be made available to the child frame.
+   * @param frameName The name of the child frame.
+   * @param options carries optional attributes values
+   * @return a new instance of Enter
+   */
+  public static <T> Enter<T> create(Scope scope, Operand<T> data, String frameName, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Enter", scope.makeOpName("Enter"));
+    opBuilder.addInput(data.asOutput());
+    opBuilder.setAttr("frame_name", frameName);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.isConstant != null) {
+          opBuilder.setAttr("is_constant", opts.isConstant);
+        }
+        if (opts.parallelIterations != null) {
+          opBuilder.setAttr("parallel_iterations", opts.parallelIterations);
+        }
+      }
+    }
+    return new Enter<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param isConstant If true, the output is constant within the child frame.
+   */
+  public static Options isConstant(Boolean isConstant) {
+    return new Options().isConstant(isConstant);
+  }
+  
+  /**
+   * @param parallelIterations The number of iterations allowed to run in parallel.
+   */
+  public static Options parallelIterations(Long parallelIterations) {
+    return new Options().parallelIterations(parallelIterations);
+  }
+  
+  /**
+   * The same tensor as `data`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private Enter(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Equal.java java-ops/org/tensorflow/op/core/Equal.java
--- java/org/tensorflow/op/core/Equal.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Equal.java	2018-10-16 20:18:38.269432355 +0900
@@ -0,0 +1,70 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns the truth value of (x == y) element-wise.
+ * <p>
+ * <i>NOTE</i>: `Equal` supports broadcasting. More about broadcasting
+ * [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
+ */
+@Operator
+public final class Equal extends PrimitiveOp implements Operand<Boolean> {
+  
+  /**
+   * Factory method to create a class to wrap a new Equal operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param y 
+   * @return a new instance of Equal
+   */
+  public static <T> Equal create(Scope scope, Operand<T> x, Operand<T> y) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Equal", scope.makeOpName("Equal"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(y.asOutput());
+    return new Equal(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<Boolean> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<Boolean> asOutput() {
+    return z;
+  }
+  
+  private Output<Boolean> z;
+  
+  private Equal(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Erfc.java java-ops/org/tensorflow/op/core/Erfc.java
--- java/org/tensorflow/op/core/Erfc.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Erfc.java	2018-10-16 20:18:38.269432355 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the complementary error function of `x` element-wise.
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class Erfc<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Erfc operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of Erfc
+   */
+  public static <T extends Number> Erfc<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Erfc", scope.makeOpName("Erfc"));
+    opBuilder.addInput(x.asOutput());
+    return new Erfc<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private Erfc(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Erf.java java-ops/org/tensorflow/op/core/Erf.java
--- java/org/tensorflow/op/core/Erf.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Erf.java	2018-10-16 20:18:38.269432355 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the Gauss error function of `x` element-wise.
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class Erf<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Erf operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of Erf
+   */
+  public static <T extends Number> Erf<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Erf", scope.makeOpName("Erf"));
+    opBuilder.addInput(x.asOutput());
+    return new Erf<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private Erf(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Exit.java java-ops/org/tensorflow/op/core/Exit.java
--- java/org/tensorflow/op/core/Exit.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Exit.java	2018-10-16 20:18:38.270432354 +0900
@@ -0,0 +1,68 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Exits the current frame to its parent frame.
+ * <p>
+ * Exit makes its input `data` available to the parent frame.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+public final class Exit<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Exit operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param data The tensor to be made available to the parent frame.
+   * @return a new instance of Exit
+   */
+  public static <T> Exit<T> create(Scope scope, Operand<T> data) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Exit", scope.makeOpName("Exit"));
+    opBuilder.addInput(data.asOutput());
+    return new Exit<T>(opBuilder.build());
+  }
+  
+  /**
+   * The same tensor as `data`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private Exit(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ExpandDims.java java-ops/org/tensorflow/op/core/ExpandDims.java
--- java/org/tensorflow/op/core/ExpandDims.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ExpandDims.java	2018-10-16 20:18:38.270432354 +0900
@@ -0,0 +1,102 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Inserts a dimension of 1 into a tensor's shape.
+ * <p>
+ * Given a tensor `input`, this operation inserts a dimension of 1 at the
+ * dimension index `axis` of `input`'s shape. The dimension index `axis` starts at
+ * zero; if you specify a negative number for `axis` it is counted backward from
+ * the end.
+ * <p>
+ * This operation is useful if you want to add a batch dimension to a single
+ * element. For example, if you have a single image of shape `[height, width,
+ * channels]`, you can make it a batch of 1 image with `expand_dims(image, 0)`,
+ * which will make the shape `[1, height, width, channels]`.
+ * <p>
+ * Other examples:
+ * <pre>{@code
+ * # 't' is a tensor of shape [2]
+ * shape(expand_dims(t, 0)) ==> [1, 2]
+ * shape(expand_dims(t, 1)) ==> [2, 1]
+ * shape(expand_dims(t, -1)) ==> [2, 1]
+ * 
+ * # 't2' is a tensor of shape [2, 3, 5]
+ * shape(expand_dims(t2, 0)) ==> [1, 2, 3, 5]
+ * shape(expand_dims(t2, 2)) ==> [2, 3, 1, 5]
+ * shape(expand_dims(t2, 3)) ==> [2, 3, 5, 1]
+ * }</pre>
+ * This operation requires that:
+ * <p>
+ * `-1-input.dims() <= dim <= input.dims()`
+ * <p>
+ * This operation is related to `squeeze()`, which removes dimensions of
+ * size 1.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class ExpandDims<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new ExpandDims operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param axis 0-D (scalar). Specifies the dimension index at which to
+   * expand the shape of `input`. Must be in the range
+   * `[-rank(input) - 1, rank(input)]`.
+   * @return a new instance of ExpandDims
+   */
+  public static <T, U extends Number> ExpandDims<T> create(Scope scope, Operand<T> input, Operand<U> axis) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ExpandDims", scope.makeOpName("ExpandDims"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(axis.asOutput());
+    return new ExpandDims<T>(opBuilder.build());
+  }
+  
+  /**
+   * Contains the same data as `input`, but its shape has an additional
+   * dimension of size 1 added.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private ExpandDims(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ExperimentalAssertNextDataset.java java-ops/org/tensorflow/op/core/ExperimentalAssertNextDataset.java
--- java/org/tensorflow/op/core/ExperimentalAssertNextDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ExperimentalAssertNextDataset.java	2018-10-16 20:18:38.271432353 +0900
@@ -0,0 +1,80 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ */
+public final class ExperimentalAssertNextDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new ExperimentalAssertNextDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputDataset 
+   * @param transformations 
+   * @param outputTypes 
+   * @param outputShapes 
+   * @return a new instance of ExperimentalAssertNextDataset
+   */
+  public static ExperimentalAssertNextDataset create(Scope scope, Operand<?> inputDataset, Operand<String> transformations, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ExperimentalAssertNextDataset", scope.makeOpName("ExperimentalAssertNextDataset"));
+    opBuilder.addInput(inputDataset.asOutput());
+    opBuilder.addInput(transformations.asOutput());
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new ExperimentalAssertNextDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private ExperimentalAssertNextDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ExperimentalCSVDataset.java java-ops/org/tensorflow/op/core/ExperimentalCSVDataset.java
--- java/org/tensorflow/op/core/ExperimentalCSVDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ExperimentalCSVDataset.java	2018-10-16 20:18:38.271432353 +0900
@@ -0,0 +1,88 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ */
+public final class ExperimentalCSVDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new ExperimentalCSVDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param filenames 
+   * @param compressionType 
+   * @param bufferSize 
+   * @param header 
+   * @param fieldDelim 
+   * @param useQuoteDelim 
+   * @param naValue 
+   * @param selectCols 
+   * @param recordDefaults 
+   * @param outputShapes 
+   * @return a new instance of ExperimentalCSVDataset
+   */
+  public static ExperimentalCSVDataset create(Scope scope, Operand<String> filenames, Operand<String> compressionType, Operand<Long> bufferSize, Operand<Boolean> header, Operand<String> fieldDelim, Operand<Boolean> useQuoteDelim, Operand<String> naValue, Operand<Long> selectCols, Iterable<Operand<?>> recordDefaults, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ExperimentalCSVDataset", scope.makeOpName("ExperimentalCSVDataset"));
+    opBuilder.addInput(filenames.asOutput());
+    opBuilder.addInput(compressionType.asOutput());
+    opBuilder.addInput(bufferSize.asOutput());
+    opBuilder.addInput(header.asOutput());
+    opBuilder.addInput(fieldDelim.asOutput());
+    opBuilder.addInput(useQuoteDelim.asOutput());
+    opBuilder.addInput(naValue.asOutput());
+    opBuilder.addInput(selectCols.asOutput());
+    opBuilder.addInputList(Operands.asOutputs(recordDefaults));
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new ExperimentalCSVDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private ExperimentalCSVDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ExperimentalDirectedInterleaveDataset.java java-ops/org/tensorflow/op/core/ExperimentalDirectedInterleaveDataset.java
--- java/org/tensorflow/op/core/ExperimentalDirectedInterleaveDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ExperimentalDirectedInterleaveDataset.java	2018-10-16 20:18:38.272432353 +0900
@@ -0,0 +1,84 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * A substitute for `InterleaveDataset` on a fixed list of `N` datasets.
+ */
+public final class ExperimentalDirectedInterleaveDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new ExperimentalDirectedInterleaveDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param selectorInputDataset A dataset of scalar `DT_INT64` elements that determines which of the
+   * `N` data inputs should produce the next output element.
+   * @param dataInputDatasets `N` datasets with the same type that will be interleaved according to
+   * the values of `selector_input_dataset`.
+   * @param outputTypes 
+   * @param outputShapes 
+   * @return a new instance of ExperimentalDirectedInterleaveDataset
+   */
+  public static ExperimentalDirectedInterleaveDataset create(Scope scope, Operand<?> selectorInputDataset, Iterable<Operand<?>> dataInputDatasets, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ExperimentalDirectedInterleaveDataset", scope.makeOpName("ExperimentalDirectedInterleaveDataset"));
+    opBuilder.addInput(selectorInputDataset.asOutput());
+    opBuilder.addInputList(Operands.asOutputs(dataInputDatasets));
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new ExperimentalDirectedInterleaveDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private ExperimentalDirectedInterleaveDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ExperimentalFunctionBufferingResourceGetNext.java java-ops/org/tensorflow/op/core/ExperimentalFunctionBufferingResourceGetNext.java
--- java/org/tensorflow/op/core/ExperimentalFunctionBufferingResourceGetNext.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ExperimentalFunctionBufferingResourceGetNext.java	2018-10-16 20:18:38.272432353 +0900
@@ -0,0 +1,77 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.Iterator;
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Gets the next element from a FunctionBufferingResource.
+ */
+public final class ExperimentalFunctionBufferingResourceGetNext extends PrimitiveOp implements Iterable<Operand<Object>> {
+  
+  /**
+   * Factory method to create a class to wrap a new ExperimentalFunctionBufferingResourceGetNext operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param functionBufferResource The FunctionBufferingResource handle.
+   * @param outputTypes The type list for the return values.
+   * @return a new instance of ExperimentalFunctionBufferingResourceGetNext
+   */
+  public static ExperimentalFunctionBufferingResourceGetNext create(Scope scope, Operand<?> functionBufferResource, List<Class<?>> outputTypes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ExperimentalFunctionBufferingResourceGetNext", scope.makeOpName("ExperimentalFunctionBufferingResourceGetNext"));
+    opBuilder.addInput(functionBufferResource.asOutput());
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    return new ExperimentalFunctionBufferingResourceGetNext(opBuilder.build());
+  }
+  
+  /**
+   * A list of return values.
+   */
+  public List<Output<?>> output() {
+    return output;
+  }
+  
+  @Override
+  @SuppressWarnings({"rawtypes", "unchecked"})
+  public Iterator<Operand<Object>> iterator() {
+    return (Iterator) output.iterator();
+  }
+  
+  private List<Output<?>> output;
+  
+  private ExperimentalFunctionBufferingResourceGetNext(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    int outputLength = operation.outputListLength("output");
+    output = Arrays.asList(operation.outputList(outputIdx, outputLength));
+    outputIdx += outputLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/ExperimentalFunctionBufferingResourceReset.java java-ops/org/tensorflow/op/core/ExperimentalFunctionBufferingResourceReset.java
--- java/org/tensorflow/op/core/ExperimentalFunctionBufferingResourceReset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ExperimentalFunctionBufferingResourceReset.java	2018-10-16 20:18:38.272432353 +0900
@@ -0,0 +1,48 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Resets the FunctionBufferingResource.
+ */
+public final class ExperimentalFunctionBufferingResourceReset extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new ExperimentalFunctionBufferingResourceReset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param functionBufferResource The FunctionBufferingResource handle.
+   * @return a new instance of ExperimentalFunctionBufferingResourceReset
+   */
+  public static ExperimentalFunctionBufferingResourceReset create(Scope scope, Operand<?> functionBufferResource) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ExperimentalFunctionBufferingResourceReset", scope.makeOpName("ExperimentalFunctionBufferingResourceReset"));
+    opBuilder.addInput(functionBufferResource.asOutput());
+    return new ExperimentalFunctionBufferingResourceReset(opBuilder.build());
+  }
+  
+  
+  private ExperimentalFunctionBufferingResourceReset(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ExperimentalIdentityIndexedDataset.java java-ops/org/tensorflow/op/core/ExperimentalIdentityIndexedDataset.java
--- java/org/tensorflow/op/core/ExperimentalIdentityIndexedDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ExperimentalIdentityIndexedDataset.java	2018-10-16 20:18:38.273432352 +0900
@@ -0,0 +1,63 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ */
+public final class ExperimentalIdentityIndexedDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new ExperimentalIdentityIndexedDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param size 
+   * @return a new instance of ExperimentalIdentityIndexedDataset
+   */
+  public static ExperimentalIdentityIndexedDataset create(Scope scope, Operand<?> size) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ExperimentalIdentityIndexedDataset", scope.makeOpName("ExperimentalIdentityIndexedDataset"));
+    opBuilder.addInput(size.asOutput());
+    return new ExperimentalIdentityIndexedDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private ExperimentalIdentityIndexedDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ExperimentalIgnoreErrorsDataset.java java-ops/org/tensorflow/op/core/ExperimentalIgnoreErrorsDataset.java
--- java/org/tensorflow/op/core/ExperimentalIgnoreErrorsDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ExperimentalIgnoreErrorsDataset.java	2018-10-16 20:18:38.273432352 +0900
@@ -0,0 +1,79 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Creates a dataset that contains the elements of `input_dataset` ignoring errors.
+ */
+public final class ExperimentalIgnoreErrorsDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new ExperimentalIgnoreErrorsDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputDataset 
+   * @param outputTypes 
+   * @param outputShapes 
+   * @return a new instance of ExperimentalIgnoreErrorsDataset
+   */
+  public static ExperimentalIgnoreErrorsDataset create(Scope scope, Operand<?> inputDataset, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ExperimentalIgnoreErrorsDataset", scope.makeOpName("ExperimentalIgnoreErrorsDataset"));
+    opBuilder.addInput(inputDataset.asOutput());
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new ExperimentalIgnoreErrorsDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private ExperimentalIgnoreErrorsDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ExperimentalIndexedDatasetGet.java java-ops/org/tensorflow/op/core/ExperimentalIndexedDatasetGet.java
--- java/org/tensorflow/op/core/ExperimentalIndexedDatasetGet.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ExperimentalIndexedDatasetGet.java	2018-10-16 20:18:38.273432352 +0900
@@ -0,0 +1,84 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.Iterator;
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ */
+public final class ExperimentalIndexedDatasetGet extends PrimitiveOp implements Iterable<Operand<Object>> {
+  
+  /**
+   * Factory method to create a class to wrap a new ExperimentalIndexedDatasetGet operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param materialized 
+   * @param index 
+   * @param outputTypes 
+   * @param outputShapes 
+   * @return a new instance of ExperimentalIndexedDatasetGet
+   */
+  public static ExperimentalIndexedDatasetGet create(Scope scope, Operand<?> materialized, Operand<?> index, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ExperimentalIndexedDatasetGet", scope.makeOpName("ExperimentalIndexedDatasetGet"));
+    opBuilder.addInput(materialized.asOutput());
+    opBuilder.addInput(index.asOutput());
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new ExperimentalIndexedDatasetGet(opBuilder.build());
+  }
+  
+  /**
+   */
+  public List<Output<?>> components() {
+    return components;
+  }
+  
+  @Override
+  @SuppressWarnings({"rawtypes", "unchecked"})
+  public Iterator<Operand<Object>> iterator() {
+    return (Iterator) components.iterator();
+  }
+  
+  private List<Output<?>> components;
+  
+  private ExperimentalIndexedDatasetGet(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    int componentsLength = operation.outputListLength("components");
+    components = Arrays.asList(operation.outputList(outputIdx, componentsLength));
+    outputIdx += componentsLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/ExperimentalIndexedDatasetMaterialize.java java-ops/org/tensorflow/op/core/ExperimentalIndexedDatasetMaterialize.java
--- java/org/tensorflow/op/core/ExperimentalIndexedDatasetMaterialize.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ExperimentalIndexedDatasetMaterialize.java	2018-10-16 20:18:38.273432352 +0900
@@ -0,0 +1,49 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ */
+public final class ExperimentalIndexedDatasetMaterialize extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new ExperimentalIndexedDatasetMaterialize operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param dataset 
+   * @param materialized 
+   * @return a new instance of ExperimentalIndexedDatasetMaterialize
+   */
+  public static ExperimentalIndexedDatasetMaterialize create(Scope scope, Operand<?> dataset, Operand<?> materialized) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ExperimentalIndexedDatasetMaterialize", scope.makeOpName("ExperimentalIndexedDatasetMaterialize"));
+    opBuilder.addInput(dataset.asOutput());
+    opBuilder.addInput(materialized.asOutput());
+    return new ExperimentalIndexedDatasetMaterialize(opBuilder.build());
+  }
+  
+  
+  private ExperimentalIndexedDatasetMaterialize(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ExperimentalIteratorGetDevice.java java-ops/org/tensorflow/op/core/ExperimentalIteratorGetDevice.java
--- java/org/tensorflow/op/core/ExperimentalIteratorGetDevice.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ExperimentalIteratorGetDevice.java	2018-10-16 20:18:38.274432351 +0900
@@ -0,0 +1,63 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Returns the name of the device on which `resource` has been placed.
+ */
+public final class ExperimentalIteratorGetDevice extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Factory method to create a class to wrap a new ExperimentalIteratorGetDevice operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param resource 
+   * @return a new instance of ExperimentalIteratorGetDevice
+   */
+  public static ExperimentalIteratorGetDevice create(Scope scope, Operand<?> resource) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ExperimentalIteratorGetDevice", scope.makeOpName("ExperimentalIteratorGetDevice"));
+    opBuilder.addInput(resource.asOutput());
+    return new ExperimentalIteratorGetDevice(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<String> device() {
+    return device;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return device;
+  }
+  
+  private Output<String> device;
+  
+  private ExperimentalIteratorGetDevice(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    device = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ExperimentalLMDBDataset.java java-ops/org/tensorflow/op/core/ExperimentalLMDBDataset.java
--- java/org/tensorflow/op/core/ExperimentalLMDBDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ExperimentalLMDBDataset.java	2018-10-16 20:18:38.274432351 +0900
@@ -0,0 +1,78 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ */
+public final class ExperimentalLMDBDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new ExperimentalLMDBDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param filenames 
+   * @param outputTypes 
+   * @param outputShapes 
+   * @return a new instance of ExperimentalLMDBDataset
+   */
+  public static ExperimentalLMDBDataset create(Scope scope, Operand<String> filenames, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ExperimentalLMDBDataset", scope.makeOpName("ExperimentalLMDBDataset"));
+    opBuilder.addInput(filenames.asOutput());
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new ExperimentalLMDBDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private ExperimentalLMDBDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ExperimentalMaterializedIndexDatasetHandle.java java-ops/org/tensorflow/op/core/ExperimentalMaterializedIndexDatasetHandle.java
--- java/org/tensorflow/op/core/ExperimentalMaterializedIndexDatasetHandle.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ExperimentalMaterializedIndexDatasetHandle.java	2018-10-16 20:18:38.274432351 +0900
@@ -0,0 +1,80 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ */
+public final class ExperimentalMaterializedIndexDatasetHandle extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new ExperimentalMaterializedIndexDatasetHandle operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param container 
+   * @param sharedName 
+   * @param outputTypes 
+   * @param outputShapes 
+   * @return a new instance of ExperimentalMaterializedIndexDatasetHandle
+   */
+  public static ExperimentalMaterializedIndexDatasetHandle create(Scope scope, String container, String sharedName, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ExperimentalMaterializedIndexDatasetHandle", scope.makeOpName("ExperimentalMaterializedIndexDatasetHandle"));
+    opBuilder.setAttr("container", container);
+    opBuilder.setAttr("shared_name", sharedName);
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new ExperimentalMaterializedIndexDatasetHandle(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private ExperimentalMaterializedIndexDatasetHandle(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ExperimentalThreadPoolDataset.java java-ops/org/tensorflow/op/core/ExperimentalThreadPoolDataset.java
--- java/org/tensorflow/op/core/ExperimentalThreadPoolDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ExperimentalThreadPoolDataset.java	2018-10-16 20:18:38.274432351 +0900
@@ -0,0 +1,81 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Creates a dataset that uses a custom thread pool to compute `input_dataset`.
+ */
+public final class ExperimentalThreadPoolDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new ExperimentalThreadPoolDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputDataset 
+   * @param threadPool A resource produced by the ThreadPoolHandle op.
+   * @param outputTypes 
+   * @param outputShapes 
+   * @return a new instance of ExperimentalThreadPoolDataset
+   */
+  public static ExperimentalThreadPoolDataset create(Scope scope, Operand<?> inputDataset, Operand<?> threadPool, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ExperimentalThreadPoolDataset", scope.makeOpName("ExperimentalThreadPoolDataset"));
+    opBuilder.addInput(inputDataset.asOutput());
+    opBuilder.addInput(threadPool.asOutput());
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new ExperimentalThreadPoolDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private ExperimentalThreadPoolDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ExperimentalThreadPoolHandle.java java-ops/org/tensorflow/op/core/ExperimentalThreadPoolHandle.java
--- java/org/tensorflow/op/core/ExperimentalThreadPoolHandle.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ExperimentalThreadPoolHandle.java	2018-10-16 20:18:38.275432350 +0900
@@ -0,0 +1,144 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Creates a dataset that uses a custom thread pool to compute `input_dataset`.
+ */
+public final class ExperimentalThreadPoolHandle extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ExperimentalThreadPoolHandle}
+   */
+  public static class Options {
+    
+    /**
+     * @param maxIntraOpParallelism The maximum degree of parallelism to use within operations that execute on this
+     * threadpool.
+     */
+    public Options maxIntraOpParallelism(Long maxIntraOpParallelism) {
+      this.maxIntraOpParallelism = maxIntraOpParallelism;
+      return this;
+    }
+    
+    /**
+     * @param container 
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName 
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private Long maxIntraOpParallelism;
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ExperimentalThreadPoolHandle operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param numThreads The number of threads in the thread pool.
+   * @param displayName A human-readable name for the threads that may be visible in some
+   * visualizations.
+   * threadpool.
+   * @param options carries optional attributes values
+   * @return a new instance of ExperimentalThreadPoolHandle
+   */
+  public static ExperimentalThreadPoolHandle create(Scope scope, Long numThreads, String displayName, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ExperimentalThreadPoolHandle", scope.makeOpName("ExperimentalThreadPoolHandle"));
+    opBuilder.setAttr("num_threads", numThreads);
+    opBuilder.setAttr("display_name", displayName);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.maxIntraOpParallelism != null) {
+          opBuilder.setAttr("max_intra_op_parallelism", opts.maxIntraOpParallelism);
+        }
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new ExperimentalThreadPoolHandle(opBuilder.build());
+  }
+  
+  /**
+   * @param maxIntraOpParallelism The maximum degree of parallelism to use within operations that execute on this
+   * threadpool.
+   */
+  public static Options maxIntraOpParallelism(Long maxIntraOpParallelism) {
+    return new Options().maxIntraOpParallelism(maxIntraOpParallelism);
+  }
+  
+  /**
+   * @param container 
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName 
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   * A resource that can be consumed by one or more ExperimentalThreadPoolDataset
+   * ops.
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private ExperimentalThreadPoolHandle(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ExperimentalUniqueDataset.java java-ops/org/tensorflow/op/core/ExperimentalUniqueDataset.java
--- java/org/tensorflow/op/core/ExperimentalUniqueDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ExperimentalUniqueDataset.java	2018-10-16 20:18:38.275432350 +0900
@@ -0,0 +1,79 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Creates a dataset that contains the unique elements of `input_dataset`.
+ */
+public final class ExperimentalUniqueDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new ExperimentalUniqueDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputDataset 
+   * @param outputTypes 
+   * @param outputShapes 
+   * @return a new instance of ExperimentalUniqueDataset
+   */
+  public static ExperimentalUniqueDataset create(Scope scope, Operand<?> inputDataset, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ExperimentalUniqueDataset", scope.makeOpName("ExperimentalUniqueDataset"));
+    opBuilder.addInput(inputDataset.asOutput());
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new ExperimentalUniqueDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private ExperimentalUniqueDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Exp.java java-ops/org/tensorflow/op/core/Exp.java
--- java/org/tensorflow/op/core/Exp.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Exp.java	2018-10-16 20:18:38.270432354 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes exponential of x element-wise.  \\(y = e^x\\).
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class Exp<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Exp operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of Exp
+   */
+  public static <T> Exp<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Exp", scope.makeOpName("Exp"));
+    opBuilder.addInput(x.asOutput());
+    return new Exp<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private Exp(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Expm1.java java-ops/org/tensorflow/op/core/Expm1.java
--- java/org/tensorflow/op/core/Expm1.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Expm1.java	2018-10-16 20:18:38.275432350 +0900
@@ -0,0 +1,69 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes exponential of x - 1 element-wise.
+ * <p>
+ * I.e., \\(y = (\exp x) - 1\\).
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class Expm1<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Expm1 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of Expm1
+   */
+  public static <T> Expm1<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Expm1", scope.makeOpName("Expm1"));
+    opBuilder.addInput(x.asOutput());
+    return new Expm1<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private Expm1(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ExtractGlimpse.java java-ops/org/tensorflow/op/core/ExtractGlimpse.java
--- java/org/tensorflow/op/core/ExtractGlimpse.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ExtractGlimpse.java	2018-10-16 20:18:38.276432350 +0900
@@ -0,0 +1,181 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Extracts a glimpse from the input tensor.
+ * <p>
+ * Returns a set of windows called glimpses extracted at location
+ * `offsets` from the input tensor. If the windows only partially
+ * overlaps the inputs, the non overlapping areas will be filled with
+ * random noise.
+ * <p>
+ * The result is a 4-D tensor of shape `[batch_size, glimpse_height,
+ * glimpse_width, channels]`. The channels and batch dimensions are the
+ * same as that of the input tensor. The height and width of the output
+ * windows are specified in the `size` parameter.
+ * <p>
+ * The argument `normalized` and `centered` controls how the windows are built:
+ * <ul>
+ * <li>
+ * If the coordinates are normalized but not centered, 0.0 and 1.0
+ *   correspond to the minimum and maximum of each height and width
+ *   dimension.
+ * </li>
+ * <li>
+ * If the coordinates are both normalized and centered, they range from
+ *   -1.0 to 1.0. The coordinates (-1.0, -1.0) correspond to the upper
+ *   left corner, the lower right corner is located at (1.0, 1.0) and the
+ *   center is at (0, 0).
+ * </li>
+ * <li>
+ * If the coordinates are not normalized they are interpreted as
+ *   numbers of pixels.
+ */
+@Operator
+public final class ExtractGlimpse extends PrimitiveOp implements Operand<Float> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ExtractGlimpse}
+   */
+  public static class Options {
+    
+    /**
+     * @param centered indicates if the offset coordinates are centered relative to
+     * the image, in which case the (0, 0) offset is relative to the center
+     * of the input images. If false, the (0,0) offset corresponds to the
+     * upper left corner of the input images.
+     */
+    public Options centered(Boolean centered) {
+      this.centered = centered;
+      return this;
+    }
+    
+    /**
+     * @param normalized indicates if the offset coordinates are normalized.
+     */
+    public Options normalized(Boolean normalized) {
+      this.normalized = normalized;
+      return this;
+    }
+    
+    /**
+     * @param uniformNoise indicates if the noise should be generated using a
+     * uniform distribution or a Gaussian distribution.
+     */
+    public Options uniformNoise(Boolean uniformNoise) {
+      this.uniformNoise = uniformNoise;
+      return this;
+    }
+    
+    private Boolean centered;
+    private Boolean normalized;
+    private Boolean uniformNoise;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ExtractGlimpse operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input A 4-D float tensor of shape `[batch_size, height, width, channels]`.
+   * @param size A 1-D tensor of 2 elements containing the size of the glimpses
+   * to extract.  The glimpse height must be specified first, following
+   * by the glimpse width.
+   * @param offsets A 2-D integer tensor of shape `[batch_size, 2]` containing
+   * the y, x locations of the center of each window.
+   * @param options carries optional attributes values
+   * @return a new instance of ExtractGlimpse
+   */
+  public static ExtractGlimpse create(Scope scope, Operand<Float> input, Operand<Integer> size, Operand<Float> offsets, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ExtractGlimpse", scope.makeOpName("ExtractGlimpse"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(size.asOutput());
+    opBuilder.addInput(offsets.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.centered != null) {
+          opBuilder.setAttr("centered", opts.centered);
+        }
+        if (opts.normalized != null) {
+          opBuilder.setAttr("normalized", opts.normalized);
+        }
+        if (opts.uniformNoise != null) {
+          opBuilder.setAttr("uniform_noise", opts.uniformNoise);
+        }
+      }
+    }
+    return new ExtractGlimpse(opBuilder.build());
+  }
+  
+  /**
+   * @param centered indicates if the offset coordinates are centered relative to
+   * the image, in which case the (0, 0) offset is relative to the center
+   * of the input images. If false, the (0,0) offset corresponds to the
+   * upper left corner of the input images.
+   */
+  public static Options centered(Boolean centered) {
+    return new Options().centered(centered);
+  }
+  
+  /**
+   * @param normalized indicates if the offset coordinates are normalized.
+   */
+  public static Options normalized(Boolean normalized) {
+    return new Options().normalized(normalized);
+  }
+  
+  /**
+   * @param uniformNoise indicates if the noise should be generated using a
+   * uniform distribution or a Gaussian distribution.
+   */
+  public static Options uniformNoise(Boolean uniformNoise) {
+    return new Options().uniformNoise(uniformNoise);
+  }
+  
+  /**
+   * A tensor representing the glimpses `[batch_size,
+   * glimpse_height, glimpse_width, channels]`.
+   */
+  public Output<Float> glimpse() {
+    return glimpse;
+  }
+  
+  @Override
+  public Output<Float> asOutput() {
+    return glimpse;
+  }
+  
+  private Output<Float> glimpse;
+  
+  private ExtractGlimpse(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    glimpse = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ExtractImagePatches.java java-ops/org/tensorflow/op/core/ExtractImagePatches.java
--- java/org/tensorflow/op/core/ExtractImagePatches.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ExtractImagePatches.java	2018-10-16 20:18:38.277432349 +0900
@@ -0,0 +1,106 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Extract `patches` from `images` and put them in the "depth" output dimension.
+ * 
+ * @param <T> data type for {@code patches()} output
+ */
+@Operator
+public final class ExtractImagePatches<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new ExtractImagePatches operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param images 4-D Tensor with shape `[batch, in_rows, in_cols, depth]`.
+   * @param ksizes The size of the sliding window for each dimension of `images`.
+   * @param strides 1-D of length 4. How far the centers of two consecutive patches are in
+   * the images. Must be: `[1, stride_rows, stride_cols, 1]`.
+   * @param rates 1-D of length 4. Must be: `[1, rate_rows, rate_cols, 1]`. This is the
+   * input stride, specifying how far two consecutive patch samples are in the
+   * input. Equivalent to extracting patches with
+   * `patch_sizes_eff = patch_sizes + (patch_sizes - 1) * (rates - 1)`, followed by
+   * subsampling them spatially by a factor of `rates`. This is equivalent to
+   * `rate` in dilated (a.k.a. Atrous) convolutions.
+   * @param padding The type of padding algorithm to use.
+   * <p>
+   * We specify the size-related attributes as:
+   * <pre>{@code
+   *       ksizes = [1, ksize_rows, ksize_cols, 1]
+   *       strides = [1, strides_rows, strides_cols, 1]
+   *       rates = [1, rates_rows, rates_cols, 1]
+   * }</pre>
+   * 
+   * @return a new instance of ExtractImagePatches
+   */
+  public static <T extends Number> ExtractImagePatches<T> create(Scope scope, Operand<T> images, List<Long> ksizes, List<Long> strides, List<Long> rates, String padding) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ExtractImagePatches", scope.makeOpName("ExtractImagePatches"));
+    opBuilder.addInput(images.asOutput());
+    long[] ksizesArray = new long[ksizes.size()];
+    for (int i = 0; i < ksizesArray.length; ++i) {
+      ksizesArray[i] = ksizes.get(i);
+    }
+    opBuilder.setAttr("ksizes", ksizesArray);
+    long[] stridesArray = new long[strides.size()];
+    for (int i = 0; i < stridesArray.length; ++i) {
+      stridesArray[i] = strides.get(i);
+    }
+    opBuilder.setAttr("strides", stridesArray);
+    long[] ratesArray = new long[rates.size()];
+    for (int i = 0; i < ratesArray.length; ++i) {
+      ratesArray[i] = rates.get(i);
+    }
+    opBuilder.setAttr("rates", ratesArray);
+    opBuilder.setAttr("padding", padding);
+    return new ExtractImagePatches<T>(opBuilder.build());
+  }
+  
+  /**
+   * 4-D Tensor with shape `[batch, out_rows, out_cols, ksize_rows *
+   * ksize_cols * depth]` containing image patches with size
+   * `ksize_rows x ksize_cols x depth` vectorized in the "depth" dimension. Note
+   * `out_rows` and `out_cols` are the dimensions of the output patches.
+   */
+  public Output<T> patches() {
+    return patches;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return patches;
+  }
+  
+  private Output<T> patches;
+  
+  private ExtractImagePatches(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    patches = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ExtractJpegShape.java java-ops/org/tensorflow/op/core/ExtractJpegShape.java
--- java/org/tensorflow/op/core/ExtractJpegShape.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ExtractJpegShape.java	2018-10-16 20:18:38.277432349 +0900
@@ -0,0 +1,85 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Extract the shape information of a JPEG-encoded image.
+ * <p>
+ * This op only parses the image header, so it is much faster than DecodeJpeg.
+ * 
+ * @param <T> data type for {@code imageShape()} output
+ */
+@Operator
+public final class ExtractJpegShape<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new ExtractJpegShape operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param contents 0-D. The JPEG-encoded image.
+   * @param outputType (Optional) The output type of the operation (int32 or int64).
+   * Defaults to int32.
+   * @return a new instance of ExtractJpegShape
+   */
+  public static <T extends Number> ExtractJpegShape<T> create(Scope scope, Operand<String> contents, Class<T> outputType) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ExtractJpegShape", scope.makeOpName("ExtractJpegShape"));
+    opBuilder.addInput(contents.asOutput());
+    opBuilder.setAttr("output_type", DataType.fromClass(outputType));
+    return new ExtractJpegShape<T>(opBuilder.build());
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ExtractJpegShape operation to the graph, using default output types.
+   * 
+   * @param scope current graph scope
+   * @param contents 0-D. The JPEG-encoded image.
+   * @return a new instance of ExtractJpegShape
+   */
+  public static ExtractJpegShape<Integer> create(Scope scope, Operand<String> contents) {
+    return create(scope, contents, Integer.class);
+  }
+  
+  /**
+   * 1-D. The image shape with format [height, width, channels].
+   */
+  public Output<T> imageShape() {
+    return imageShape;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return imageShape;
+  }
+  
+  private Output<T> imageShape;
+  
+  private ExtractJpegShape(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    imageShape = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ExtractVolumePatches.java java-ops/org/tensorflow/op/core/ExtractVolumePatches.java
--- java/org/tensorflow/op/core/ExtractVolumePatches.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ExtractVolumePatches.java	2018-10-16 20:18:38.278432348 +0900
@@ -0,0 +1,96 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Extract `patches` from `input` and put them in the "depth" output
+ * dimension. 3D extension of `extract_image_patches`.
+ * 
+ * @param <T> data type for {@code patches()} output
+ */
+@Operator
+public final class ExtractVolumePatches<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new ExtractVolumePatches operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 5-D Tensor with shape `[batch, in_planes, in_rows, in_cols, depth]`.
+   * @param ksizes The size of the sliding window for each dimension of `input`.
+   * @param strides 1-D of length 5. How far the centers of two consecutive patches are in
+   * `input`. Must be: `[1, stride_planes, stride_rows, stride_cols, 1]`.
+   * @param padding The type of padding algorithm to use.
+   * <p>
+   * We specify the size-related attributes as:
+   * <pre>{@code
+   *       ksizes = [1, ksize_planes, ksize_rows, ksize_cols, 1]
+   *       strides = [1, stride_planes, strides_rows, strides_cols, 1]
+   * }</pre>
+   * 
+   * @return a new instance of ExtractVolumePatches
+   */
+  public static <T extends Number> ExtractVolumePatches<T> create(Scope scope, Operand<T> input, List<Long> ksizes, List<Long> strides, String padding) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ExtractVolumePatches", scope.makeOpName("ExtractVolumePatches"));
+    opBuilder.addInput(input.asOutput());
+    long[] ksizesArray = new long[ksizes.size()];
+    for (int i = 0; i < ksizesArray.length; ++i) {
+      ksizesArray[i] = ksizes.get(i);
+    }
+    opBuilder.setAttr("ksizes", ksizesArray);
+    long[] stridesArray = new long[strides.size()];
+    for (int i = 0; i < stridesArray.length; ++i) {
+      stridesArray[i] = strides.get(i);
+    }
+    opBuilder.setAttr("strides", stridesArray);
+    opBuilder.setAttr("padding", padding);
+    return new ExtractVolumePatches<T>(opBuilder.build());
+  }
+  
+  /**
+   * 5-D Tensor with shape `[batch, out_planes, out_rows, out_cols,
+   * ksize_planes * ksize_rows * ksize_cols * depth]` containing patches
+   * with size `ksize_planes x ksize_rows x ksize_cols x depth` vectorized
+   * in the "depth" dimension. Note `out_planes`, `out_rows` and `out_cols`
+   * are the dimensions of the output patches.
+   */
+  public Output<T> patches() {
+    return patches;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return patches;
+  }
+  
+  private Output<T> patches;
+  
+  private ExtractVolumePatches(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    patches = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Fact.java java-ops/org/tensorflow/op/core/Fact.java
--- java/org/tensorflow/op/core/Fact.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Fact.java	2018-10-16 20:18:38.280432347 +0900
@@ -0,0 +1,63 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Output a fact about factorials.
+ */
+@Operator
+public final class Fact extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Factory method to create a class to wrap a new Fact operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @return a new instance of Fact
+   */
+  public static Fact create(Scope scope) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Fact", scope.makeOpName("Fact"));
+    return new Fact(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<String> fact() {
+    return fact;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return fact;
+  }
+  
+  private Output<String> fact;
+  
+  private Fact(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    fact = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/FakeQuantWithMinMaxArgsGradient.java java-ops/org/tensorflow/op/core/FakeQuantWithMinMaxArgsGradient.java
--- java/org/tensorflow/op/core/FakeQuantWithMinMaxArgsGradient.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/FakeQuantWithMinMaxArgsGradient.java	2018-10-16 20:18:38.281432346 +0900
@@ -0,0 +1,160 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Compute gradients for a FakeQuantWithMinMaxArgs operation.
+ */
+@Operator
+public final class FakeQuantWithMinMaxArgsGradient extends PrimitiveOp implements Operand<Float> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.FakeQuantWithMinMaxArgsGradient}
+   */
+  public static class Options {
+    
+    /**
+     * @param min 
+     */
+    public Options min(Float min) {
+      this.min = min;
+      return this;
+    }
+    
+    /**
+     * @param max 
+     */
+    public Options max(Float max) {
+      this.max = max;
+      return this;
+    }
+    
+    /**
+     * @param numBits 
+     */
+    public Options numBits(Long numBits) {
+      this.numBits = numBits;
+      return this;
+    }
+    
+    /**
+     * @param narrowRange 
+     */
+    public Options narrowRange(Boolean narrowRange) {
+      this.narrowRange = narrowRange;
+      return this;
+    }
+    
+    private Float min;
+    private Float max;
+    private Long numBits;
+    private Boolean narrowRange;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new FakeQuantWithMinMaxArgsGradient operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param gradients Backpropagated gradients above the FakeQuantWithMinMaxArgs operation.
+   * @param inputs Values passed as inputs to the FakeQuantWithMinMaxArgs operation.
+   * @param options carries optional attributes values
+   * @return a new instance of FakeQuantWithMinMaxArgsGradient
+   */
+  public static FakeQuantWithMinMaxArgsGradient create(Scope scope, Operand<Float> gradients, Operand<Float> inputs, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("FakeQuantWithMinMaxArgsGradient", scope.makeOpName("FakeQuantWithMinMaxArgsGradient"));
+    opBuilder.addInput(gradients.asOutput());
+    opBuilder.addInput(inputs.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.min != null) {
+          opBuilder.setAttr("min", opts.min);
+        }
+        if (opts.max != null) {
+          opBuilder.setAttr("max", opts.max);
+        }
+        if (opts.numBits != null) {
+          opBuilder.setAttr("num_bits", opts.numBits);
+        }
+        if (opts.narrowRange != null) {
+          opBuilder.setAttr("narrow_range", opts.narrowRange);
+        }
+      }
+    }
+    return new FakeQuantWithMinMaxArgsGradient(opBuilder.build());
+  }
+  
+  /**
+   * @param min 
+   */
+  public static Options min(Float min) {
+    return new Options().min(min);
+  }
+  
+  /**
+   * @param max 
+   */
+  public static Options max(Float max) {
+    return new Options().max(max);
+  }
+  
+  /**
+   * @param numBits 
+   */
+  public static Options numBits(Long numBits) {
+    return new Options().numBits(numBits);
+  }
+  
+  /**
+   * @param narrowRange 
+   */
+  public static Options narrowRange(Boolean narrowRange) {
+    return new Options().narrowRange(narrowRange);
+  }
+  
+  /**
+   * Backpropagated gradients below the FakeQuantWithMinMaxArgs operation:
+   * `gradients * (inputs >= min && inputs <= max)`.
+   */
+  public Output<Float> backprops() {
+    return backprops;
+  }
+  
+  @Override
+  public Output<Float> asOutput() {
+    return backprops;
+  }
+  
+  private Output<Float> backprops;
+  
+  private FakeQuantWithMinMaxArgsGradient(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    backprops = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/FakeQuantWithMinMaxArgs.java java-ops/org/tensorflow/op/core/FakeQuantWithMinMaxArgs.java
--- java/org/tensorflow/op/core/FakeQuantWithMinMaxArgs.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/FakeQuantWithMinMaxArgs.java	2018-10-16 20:18:38.280432347 +0900
@@ -0,0 +1,164 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Fake-quantize the 'inputs' tensor, type float to 'outputs' tensor of same type.
+ * <p>
+ * Attributes `[min; max]` define the clamping range for the `inputs` data.
+ * `inputs` values are quantized into the quantization range (`[0; 2^num_bits - 1]`
+ * when `narrow_range` is false and `[1; 2^num_bits - 1]` when it is true) and
+ * then de-quantized and output as floats in `[min; max]` interval.
+ * `num_bits` is the bitwidth of the quantization; between 2 and 16, inclusive.
+ * <p>
+ * Quantization is called fake since the output is still in floating point.
+ */
+@Operator
+public final class FakeQuantWithMinMaxArgs extends PrimitiveOp implements Operand<Float> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.FakeQuantWithMinMaxArgs}
+   */
+  public static class Options {
+    
+    /**
+     * @param min 
+     */
+    public Options min(Float min) {
+      this.min = min;
+      return this;
+    }
+    
+    /**
+     * @param max 
+     */
+    public Options max(Float max) {
+      this.max = max;
+      return this;
+    }
+    
+    /**
+     * @param numBits 
+     */
+    public Options numBits(Long numBits) {
+      this.numBits = numBits;
+      return this;
+    }
+    
+    /**
+     * @param narrowRange 
+     */
+    public Options narrowRange(Boolean narrowRange) {
+      this.narrowRange = narrowRange;
+      return this;
+    }
+    
+    private Float min;
+    private Float max;
+    private Long numBits;
+    private Boolean narrowRange;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new FakeQuantWithMinMaxArgs operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputs 
+   * @param options carries optional attributes values
+   * @return a new instance of FakeQuantWithMinMaxArgs
+   */
+  public static FakeQuantWithMinMaxArgs create(Scope scope, Operand<Float> inputs, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("FakeQuantWithMinMaxArgs", scope.makeOpName("FakeQuantWithMinMaxArgs"));
+    opBuilder.addInput(inputs.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.min != null) {
+          opBuilder.setAttr("min", opts.min);
+        }
+        if (opts.max != null) {
+          opBuilder.setAttr("max", opts.max);
+        }
+        if (opts.numBits != null) {
+          opBuilder.setAttr("num_bits", opts.numBits);
+        }
+        if (opts.narrowRange != null) {
+          opBuilder.setAttr("narrow_range", opts.narrowRange);
+        }
+      }
+    }
+    return new FakeQuantWithMinMaxArgs(opBuilder.build());
+  }
+  
+  /**
+   * @param min 
+   */
+  public static Options min(Float min) {
+    return new Options().min(min);
+  }
+  
+  /**
+   * @param max 
+   */
+  public static Options max(Float max) {
+    return new Options().max(max);
+  }
+  
+  /**
+   * @param numBits 
+   */
+  public static Options numBits(Long numBits) {
+    return new Options().numBits(numBits);
+  }
+  
+  /**
+   * @param narrowRange 
+   */
+  public static Options narrowRange(Boolean narrowRange) {
+    return new Options().narrowRange(narrowRange);
+  }
+  
+  /**
+   */
+  public Output<Float> outputs() {
+    return outputs;
+  }
+  
+  @Override
+  public Output<Float> asOutput() {
+    return outputs;
+  }
+  
+  private Output<Float> outputs;
+  
+  private FakeQuantWithMinMaxArgs(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    outputs = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/FakeQuantWithMinMaxVarsGradient.java java-ops/org/tensorflow/op/core/FakeQuantWithMinMaxVarsGradient.java
--- java/org/tensorflow/op/core/FakeQuantWithMinMaxVarsGradient.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/FakeQuantWithMinMaxVarsGradient.java	2018-10-16 20:18:38.282432346 +0900
@@ -0,0 +1,142 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Compute gradients for a FakeQuantWithMinMaxVars operation.
+ */
+@Operator
+public final class FakeQuantWithMinMaxVarsGradient extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.FakeQuantWithMinMaxVarsGradient}
+   */
+  public static class Options {
+    
+    /**
+     * @param numBits The bitwidth of the quantization; between 2 and 8, inclusive.
+     */
+    public Options numBits(Long numBits) {
+      this.numBits = numBits;
+      return this;
+    }
+    
+    /**
+     * @param narrowRange Whether to quantize into 2^num_bits - 1 distinct values.
+     */
+    public Options narrowRange(Boolean narrowRange) {
+      this.narrowRange = narrowRange;
+      return this;
+    }
+    
+    private Long numBits;
+    private Boolean narrowRange;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new FakeQuantWithMinMaxVarsGradient operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param gradients Backpropagated gradients above the FakeQuantWithMinMaxVars operation.
+   * @param inputs Values passed as inputs to the FakeQuantWithMinMaxVars operation.
+   * min, max: Quantization interval, scalar floats.
+   * @param min 
+   * @param max 
+   * @param options carries optional attributes values
+   * @return a new instance of FakeQuantWithMinMaxVarsGradient
+   */
+  public static FakeQuantWithMinMaxVarsGradient create(Scope scope, Operand<Float> gradients, Operand<Float> inputs, Operand<Float> min, Operand<Float> max, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("FakeQuantWithMinMaxVarsGradient", scope.makeOpName("FakeQuantWithMinMaxVarsGradient"));
+    opBuilder.addInput(gradients.asOutput());
+    opBuilder.addInput(inputs.asOutput());
+    opBuilder.addInput(min.asOutput());
+    opBuilder.addInput(max.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.numBits != null) {
+          opBuilder.setAttr("num_bits", opts.numBits);
+        }
+        if (opts.narrowRange != null) {
+          opBuilder.setAttr("narrow_range", opts.narrowRange);
+        }
+      }
+    }
+    return new FakeQuantWithMinMaxVarsGradient(opBuilder.build());
+  }
+  
+  /**
+   * @param numBits The bitwidth of the quantization; between 2 and 8, inclusive.
+   */
+  public static Options numBits(Long numBits) {
+    return new Options().numBits(numBits);
+  }
+  
+  /**
+   * @param narrowRange Whether to quantize into 2^num_bits - 1 distinct values.
+   */
+  public static Options narrowRange(Boolean narrowRange) {
+    return new Options().narrowRange(narrowRange);
+  }
+  
+  /**
+   * Backpropagated gradients w.r.t. inputs:
+   * `gradients * (inputs >= min && inputs <= max)`.
+   */
+  public Output<Float> backpropsWrtInput() {
+    return backpropsWrtInput;
+  }
+  
+  /**
+   * Backpropagated gradients w.r.t. min parameter:
+   * `sum(gradients * (inputs < min))`.
+   */
+  public Output<Float> backpropWrtMin() {
+    return backpropWrtMin;
+  }
+  
+  /**
+   * Backpropagated gradients w.r.t. max parameter:
+   * `sum(gradients * (inputs > max))`.
+   */
+  public Output<Float> backpropWrtMax() {
+    return backpropWrtMax;
+  }
+  
+  private Output<Float> backpropsWrtInput;
+  private Output<Float> backpropWrtMin;
+  private Output<Float> backpropWrtMax;
+  
+  private FakeQuantWithMinMaxVarsGradient(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    backpropsWrtInput = operation.output(outputIdx++);
+    backpropWrtMin = operation.output(outputIdx++);
+    backpropWrtMax = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/FakeQuantWithMinMaxVars.java java-ops/org/tensorflow/op/core/FakeQuantWithMinMaxVars.java
--- java/org/tensorflow/op/core/FakeQuantWithMinMaxVars.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/FakeQuantWithMinMaxVars.java	2018-10-16 20:18:38.281432346 +0900
@@ -0,0 +1,133 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Fake-quantize the 'inputs' tensor of type float via global float scalars `min`
+ * <p>
+ * and `max` to 'outputs' tensor of same shape as `inputs`.
+ * <p>
+ * `[min; max]` define the clamping range for the `inputs` data.
+ * `inputs` values are quantized into the quantization range (`[0; 2^num_bits - 1]`
+ * when `narrow_range` is false and `[1; 2^num_bits - 1]` when it is true) and
+ * then de-quantized and output as floats in `[min; max]` interval.
+ * `num_bits` is the bitwidth of the quantization; between 2 and 16, inclusive.
+ * <p>
+ * This operation has a gradient and thus allows for training `min` and `max`
+ * values.
+ */
+@Operator
+public final class FakeQuantWithMinMaxVars extends PrimitiveOp implements Operand<Float> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.FakeQuantWithMinMaxVars}
+   */
+  public static class Options {
+    
+    /**
+     * @param numBits 
+     */
+    public Options numBits(Long numBits) {
+      this.numBits = numBits;
+      return this;
+    }
+    
+    /**
+     * @param narrowRange 
+     */
+    public Options narrowRange(Boolean narrowRange) {
+      this.narrowRange = narrowRange;
+      return this;
+    }
+    
+    private Long numBits;
+    private Boolean narrowRange;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new FakeQuantWithMinMaxVars operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputs 
+   * @param min 
+   * @param max 
+   * @param options carries optional attributes values
+   * @return a new instance of FakeQuantWithMinMaxVars
+   */
+  public static FakeQuantWithMinMaxVars create(Scope scope, Operand<Float> inputs, Operand<Float> min, Operand<Float> max, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("FakeQuantWithMinMaxVars", scope.makeOpName("FakeQuantWithMinMaxVars"));
+    opBuilder.addInput(inputs.asOutput());
+    opBuilder.addInput(min.asOutput());
+    opBuilder.addInput(max.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.numBits != null) {
+          opBuilder.setAttr("num_bits", opts.numBits);
+        }
+        if (opts.narrowRange != null) {
+          opBuilder.setAttr("narrow_range", opts.narrowRange);
+        }
+      }
+    }
+    return new FakeQuantWithMinMaxVars(opBuilder.build());
+  }
+  
+  /**
+   * @param numBits 
+   */
+  public static Options numBits(Long numBits) {
+    return new Options().numBits(numBits);
+  }
+  
+  /**
+   * @param narrowRange 
+   */
+  public static Options narrowRange(Boolean narrowRange) {
+    return new Options().narrowRange(narrowRange);
+  }
+  
+  /**
+   */
+  public Output<Float> outputs() {
+    return outputs;
+  }
+  
+  @Override
+  public Output<Float> asOutput() {
+    return outputs;
+  }
+  
+  private Output<Float> outputs;
+  
+  private FakeQuantWithMinMaxVars(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    outputs = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/FakeQuantWithMinMaxVarsPerChannelGradient.java java-ops/org/tensorflow/op/core/FakeQuantWithMinMaxVarsPerChannelGradient.java
--- java/org/tensorflow/op/core/FakeQuantWithMinMaxVarsPerChannelGradient.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/FakeQuantWithMinMaxVarsPerChannelGradient.java	2018-10-16 20:18:38.283432345 +0900
@@ -0,0 +1,145 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Compute gradients for a FakeQuantWithMinMaxVarsPerChannel operation.
+ */
+@Operator
+public final class FakeQuantWithMinMaxVarsPerChannelGradient extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.FakeQuantWithMinMaxVarsPerChannelGradient}
+   */
+  public static class Options {
+    
+    /**
+     * @param numBits The bitwidth of the quantization; between 2 and 16, inclusive.
+     */
+    public Options numBits(Long numBits) {
+      this.numBits = numBits;
+      return this;
+    }
+    
+    /**
+     * @param narrowRange Whether to quantize into 2^num_bits - 1 distinct values.
+     */
+    public Options narrowRange(Boolean narrowRange) {
+      this.narrowRange = narrowRange;
+      return this;
+    }
+    
+    private Long numBits;
+    private Boolean narrowRange;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new FakeQuantWithMinMaxVarsPerChannelGradient operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param gradients Backpropagated gradients above the FakeQuantWithMinMaxVars operation,
+   * shape one of: `[d]`, `[b, d]`,  `[b, h, w, d]`.
+   * @param inputs Values passed as inputs to the FakeQuantWithMinMaxVars operation, shape
+   *   same as `gradients`.
+   * min, max: Quantization interval, floats of shape `[d]`.
+   * @param min 
+   * @param max 
+   * @param options carries optional attributes values
+   * @return a new instance of FakeQuantWithMinMaxVarsPerChannelGradient
+   */
+  public static FakeQuantWithMinMaxVarsPerChannelGradient create(Scope scope, Operand<Float> gradients, Operand<Float> inputs, Operand<Float> min, Operand<Float> max, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("FakeQuantWithMinMaxVarsPerChannelGradient", scope.makeOpName("FakeQuantWithMinMaxVarsPerChannelGradient"));
+    opBuilder.addInput(gradients.asOutput());
+    opBuilder.addInput(inputs.asOutput());
+    opBuilder.addInput(min.asOutput());
+    opBuilder.addInput(max.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.numBits != null) {
+          opBuilder.setAttr("num_bits", opts.numBits);
+        }
+        if (opts.narrowRange != null) {
+          opBuilder.setAttr("narrow_range", opts.narrowRange);
+        }
+      }
+    }
+    return new FakeQuantWithMinMaxVarsPerChannelGradient(opBuilder.build());
+  }
+  
+  /**
+   * @param numBits The bitwidth of the quantization; between 2 and 16, inclusive.
+   */
+  public static Options numBits(Long numBits) {
+    return new Options().numBits(numBits);
+  }
+  
+  /**
+   * @param narrowRange Whether to quantize into 2^num_bits - 1 distinct values.
+   */
+  public static Options narrowRange(Boolean narrowRange) {
+    return new Options().narrowRange(narrowRange);
+  }
+  
+  /**
+   * Backpropagated gradients w.r.t. inputs, shape same as
+   * `inputs`:
+   *   `gradients * (inputs >= min && inputs <= max)`.
+   */
+  public Output<Float> backpropsWrtInput() {
+    return backpropsWrtInput;
+  }
+  
+  /**
+   * Backpropagated gradients w.r.t. min parameter, shape `[d]`:
+   * `sum_per_d(gradients * (inputs < min))`.
+   */
+  public Output<Float> backpropWrtMin() {
+    return backpropWrtMin;
+  }
+  
+  /**
+   * Backpropagated gradients w.r.t. max parameter, shape `[d]`:
+   * `sum_per_d(gradients * (inputs > max))`.
+   */
+  public Output<Float> backpropWrtMax() {
+    return backpropWrtMax;
+  }
+  
+  private Output<Float> backpropsWrtInput;
+  private Output<Float> backpropWrtMin;
+  private Output<Float> backpropWrtMax;
+  
+  private FakeQuantWithMinMaxVarsPerChannelGradient(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    backpropsWrtInput = operation.output(outputIdx++);
+    backpropWrtMin = operation.output(outputIdx++);
+    backpropWrtMax = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/FakeQuantWithMinMaxVarsPerChannel.java java-ops/org/tensorflow/op/core/FakeQuantWithMinMaxVarsPerChannel.java
--- java/org/tensorflow/op/core/FakeQuantWithMinMaxVarsPerChannel.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/FakeQuantWithMinMaxVarsPerChannel.java	2018-10-16 20:18:38.282432346 +0900
@@ -0,0 +1,134 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Fake-quantize the 'inputs' tensor of type float and one of the shapes: `[d]`,
+ * <p>
+ * `[b, d]` `[b, h, w, d]` via per-channel floats `min` and `max` of shape `[d]`
+ * to 'outputs' tensor of same shape as `inputs`.
+ * <p>
+ * `[min; max]` define the clamping range for the `inputs` data.
+ * `inputs` values are quantized into the quantization range (`[0; 2^num_bits - 1]`
+ * when `narrow_range` is false and `[1; 2^num_bits - 1]` when it is true) and
+ * then de-quantized and output as floats in `[min; max]` interval.
+ * `num_bits` is the bitwidth of the quantization; between 2 and 16, inclusive.
+ * <p>
+ * This operation has a gradient and thus allows for training `min` and `max`
+ * values.
+ */
+@Operator
+public final class FakeQuantWithMinMaxVarsPerChannel extends PrimitiveOp implements Operand<Float> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.FakeQuantWithMinMaxVarsPerChannel}
+   */
+  public static class Options {
+    
+    /**
+     * @param numBits 
+     */
+    public Options numBits(Long numBits) {
+      this.numBits = numBits;
+      return this;
+    }
+    
+    /**
+     * @param narrowRange 
+     */
+    public Options narrowRange(Boolean narrowRange) {
+      this.narrowRange = narrowRange;
+      return this;
+    }
+    
+    private Long numBits;
+    private Boolean narrowRange;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new FakeQuantWithMinMaxVarsPerChannel operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputs 
+   * @param min 
+   * @param max 
+   * @param options carries optional attributes values
+   * @return a new instance of FakeQuantWithMinMaxVarsPerChannel
+   */
+  public static FakeQuantWithMinMaxVarsPerChannel create(Scope scope, Operand<Float> inputs, Operand<Float> min, Operand<Float> max, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("FakeQuantWithMinMaxVarsPerChannel", scope.makeOpName("FakeQuantWithMinMaxVarsPerChannel"));
+    opBuilder.addInput(inputs.asOutput());
+    opBuilder.addInput(min.asOutput());
+    opBuilder.addInput(max.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.numBits != null) {
+          opBuilder.setAttr("num_bits", opts.numBits);
+        }
+        if (opts.narrowRange != null) {
+          opBuilder.setAttr("narrow_range", opts.narrowRange);
+        }
+      }
+    }
+    return new FakeQuantWithMinMaxVarsPerChannel(opBuilder.build());
+  }
+  
+  /**
+   * @param numBits 
+   */
+  public static Options numBits(Long numBits) {
+    return new Options().numBits(numBits);
+  }
+  
+  /**
+   * @param narrowRange 
+   */
+  public static Options narrowRange(Boolean narrowRange) {
+    return new Options().narrowRange(narrowRange);
+  }
+  
+  /**
+   */
+  public Output<Float> outputs() {
+    return outputs;
+  }
+  
+  @Override
+  public Output<Float> asOutput() {
+    return outputs;
+  }
+  
+  private Output<Float> outputs;
+  
+  private FakeQuantWithMinMaxVarsPerChannel(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    outputs = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/FFT2D.java java-ops/org/tensorflow/op/core/FFT2D.java
--- java/org/tensorflow/op/core/FFT2D.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/FFT2D.java	2018-10-16 20:18:38.279432348 +0900
@@ -0,0 +1,76 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * 2D fast Fourier transform.
+ * <p>
+ * Computes the 2-dimensional discrete Fourier transform over the inner-most
+ * 2 dimensions of `input`.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class FFT2D<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new FFT2D operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input A complex64 tensor.
+   * @return a new instance of FFT2D
+   */
+  public static <T> FFT2D<T> create(Scope scope, Operand<T> input) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("FFT2D", scope.makeOpName("FFT2D"));
+    opBuilder.addInput(input.asOutput());
+    return new FFT2D<T>(opBuilder.build());
+  }
+  
+  /**
+   * A complex64 tensor of the same shape as `input`. The inner-most 2
+   *   dimensions of `input` are replaced with their 2D Fourier transform.
+   * <p>
+   * @compatibility(numpy)
+   * Equivalent to np.fft.fft2
+   * @end_compatibility
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private FFT2D(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/FFT3D.java java-ops/org/tensorflow/op/core/FFT3D.java
--- java/org/tensorflow/op/core/FFT3D.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/FFT3D.java	2018-10-16 20:18:38.279432348 +0900
@@ -0,0 +1,76 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * 3D fast Fourier transform.
+ * <p>
+ * Computes the 3-dimensional discrete Fourier transform over the inner-most 3
+ * dimensions of `input`.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class FFT3D<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new FFT3D operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input A complex64 tensor.
+   * @return a new instance of FFT3D
+   */
+  public static <T> FFT3D<T> create(Scope scope, Operand<T> input) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("FFT3D", scope.makeOpName("FFT3D"));
+    opBuilder.addInput(input.asOutput());
+    return new FFT3D<T>(opBuilder.build());
+  }
+  
+  /**
+   * A complex64 tensor of the same shape as `input`. The inner-most 3
+   *   dimensions of `input` are replaced with their 3D Fourier transform.
+   * <p>
+   * @compatibility(numpy)
+   * Equivalent to np.fft.fftn with 3 dimensions.
+   * @end_compatibility
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private FFT3D(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/FFT.java java-ops/org/tensorflow/op/core/FFT.java
--- java/org/tensorflow/op/core/FFT.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/FFT.java	2018-10-16 20:18:38.278432348 +0900
@@ -0,0 +1,76 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Fast Fourier transform.
+ * <p>
+ * Computes the 1-dimensional discrete Fourier transform over the inner-most
+ * dimension of `input`.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class FFT<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new FFT operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input A complex64 tensor.
+   * @return a new instance of FFT
+   */
+  public static <T> FFT<T> create(Scope scope, Operand<T> input) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("FFT", scope.makeOpName("FFT"));
+    opBuilder.addInput(input.asOutput());
+    return new FFT<T>(opBuilder.build());
+  }
+  
+  /**
+   * A complex64 tensor of the same shape as `input`. The inner-most
+   *   dimension of `input` is replaced with its 1D Fourier transform.
+   * <p>
+   * @compatibility(numpy)
+   * Equivalent to np.fft.fft
+   * @end_compatibility
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private FFT(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/FIFOQueue.java java-ops/org/tensorflow/op/core/FIFOQueue.java
--- java/org/tensorflow/op/core/FIFOQueue.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/FIFOQueue.java	2018-10-16 20:18:38.279432348 +0900
@@ -0,0 +1,181 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * A queue that produces elements in first-in first-out order.
+ */
+@Operator
+public final class FIFOQueue extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.FIFOQueue}
+   */
+  public static class Options {
+    
+    /**
+     * @param shapes The shape of each component in a value. The length of this attr must
+     * be either 0 or the same as the length of component_types. If the length of
+     * this attr is 0, the shapes of queue elements are not constrained, and
+     * only one element may be dequeued at a time.
+     */
+    public Options shapes(List<Shape> shapes) {
+      this.shapes = shapes;
+      return this;
+    }
+    
+    /**
+     * @param capacity The upper bound on the number of elements in this queue.
+     * Negative numbers mean no limit.
+     */
+    public Options capacity(Long capacity) {
+      this.capacity = capacity;
+      return this;
+    }
+    
+    /**
+     * @param container If non-empty, this queue is placed in the given container.
+     * Otherwise, a default container is used.
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName If non-empty, this queue will be shared under the given name
+     * across multiple sessions.
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private List<Shape> shapes;
+    private Long capacity;
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new FIFOQueue operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param componentTypes The type of each component in a value.
+   * @param options carries optional attributes values
+   * @return a new instance of FIFOQueue
+   */
+  public static FIFOQueue create(Scope scope, List<Class<?>> componentTypes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("FIFOQueueV2", scope.makeOpName("FIFOQueue"));
+    DataType[] componentTypesArray = new DataType[componentTypes.size()];
+    for (int i = 0; i < componentTypesArray.length; ++i) {
+      componentTypesArray[i] = DataType.fromClass(componentTypes.get(i));
+    }
+    opBuilder.setAttr("component_types", componentTypesArray);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.shapes != null) {
+          Shape[] shapesArray = new Shape[opts.shapes.size()];
+          for (int i = 0; i < shapesArray.length; ++i) {
+            shapesArray[i] = opts.shapes.get(i);
+          }
+          opBuilder.setAttr("shapes", shapesArray);
+        }
+        if (opts.capacity != null) {
+          opBuilder.setAttr("capacity", opts.capacity);
+        }
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new FIFOQueue(opBuilder.build());
+  }
+  
+  /**
+   * @param shapes The shape of each component in a value. The length of this attr must
+   * be either 0 or the same as the length of component_types. If the length of
+   * this attr is 0, the shapes of queue elements are not constrained, and
+   * only one element may be dequeued at a time.
+   */
+  public static Options shapes(List<Shape> shapes) {
+    return new Options().shapes(shapes);
+  }
+  
+  /**
+   * @param capacity The upper bound on the number of elements in this queue.
+   * Negative numbers mean no limit.
+   */
+  public static Options capacity(Long capacity) {
+    return new Options().capacity(capacity);
+  }
+  
+  /**
+   * @param container If non-empty, this queue is placed in the given container.
+   * Otherwise, a default container is used.
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName If non-empty, this queue will be shared under the given name
+   * across multiple sessions.
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   * The handle to the queue.
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private FIFOQueue(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Fill.java java-ops/org/tensorflow/op/core/Fill.java
--- java/org/tensorflow/op/core/Fill.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Fill.java	2018-10-16 20:18:38.284432344 +0900
@@ -0,0 +1,96 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Creates a tensor filled with a scalar value.
+ * <p>
+ * This operation creates a tensor of shape `dims` and fills it with `value`.
+ * <p>
+ * For example:
+ * <pre>{@code
+ * # Output tensor has shape [2, 3].
+ * fill([2, 3], 9) ==> [[9, 9, 9]
+ *                      [9, 9, 9]]
+ * }</pre>
+ * `tf.fill` differs from `tf.constant` in a few ways:
+ * <ul>
+ * <li>
+ * `tf.fill` only supports scalar contents, whereas `tf.constant` supports
+ *     Tensor values.
+ * </li>
+ * <li>
+ * `tf.fill` creates an Op in the computation graph that constructs the actual
+ *     Tensor value at runtime. This is in contrast to `tf.constant` which embeds
+ *     the entire Tensor into the graph with a `Const` node.
+ * </li>
+ * <li>
+ * Because `tf.fill` evaluates at graph runtime, it supports dynamic shapes
+ *     based on other runtime Tensors, unlike `tf.constant`.
+ * 
+ * @param <U> data type for {@code output()} output
+ */
+@Operator
+public final class Fill<U> extends PrimitiveOp implements Operand<U> {
+  
+  /**
+   * Factory method to create a class to wrap a new Fill operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param dims 1-D. Represents the shape of the output tensor.
+   * @param value 0-D (scalar). Value to fill the returned tensor.
+   * <p>
+   * @compatibility(numpy)
+   * Equivalent to np.full
+   * @end_compatibility
+   * @return a new instance of Fill
+   */
+  public static <U, T extends Number> Fill<U> create(Scope scope, Operand<T> dims, Operand<U> value) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Fill", scope.makeOpName("Fill"));
+    opBuilder.addInput(dims.asOutput());
+    opBuilder.addInput(value.asOutput());
+    return new Fill<U>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<U> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<U> asOutput() {
+    return output;
+  }
+  
+  private Output<U> output;
+  
+  private Fill(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/FilterByLastComponentDataset.java java-ops/org/tensorflow/op/core/FilterByLastComponentDataset.java
--- java/org/tensorflow/op/core/FilterByLastComponentDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/FilterByLastComponentDataset.java	2018-10-16 20:18:38.284432344 +0900
@@ -0,0 +1,79 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Creates a dataset containing elements of first component of `input_dataset` having true in the last component.
+ */
+public final class FilterByLastComponentDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new FilterByLastComponentDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputDataset 
+   * @param outputTypes 
+   * @param outputShapes 
+   * @return a new instance of FilterByLastComponentDataset
+   */
+  public static FilterByLastComponentDataset create(Scope scope, Operand<?> inputDataset, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("FilterByLastComponentDataset", scope.makeOpName("FilterByLastComponentDataset"));
+    opBuilder.addInput(inputDataset.asOutput());
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new FilterByLastComponentDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> output() {
+    return output;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) output;
+  }
+  
+  private Output<?> output;
+  
+  private FilterByLastComponentDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/FixedLengthRecordDataset.java java-ops/org/tensorflow/op/core/FixedLengthRecordDataset.java
--- java/org/tensorflow/op/core/FixedLengthRecordDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/FixedLengthRecordDataset.java	2018-10-16 20:18:38.284432344 +0900
@@ -0,0 +1,77 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Creates a dataset that emits the records from one or more binary files.
+ */
+@Operator
+public final class FixedLengthRecordDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new FixedLengthRecordDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param filenames A scalar or a vector containing the name(s) of the file(s) to be
+   * read.
+   * @param headerBytes A scalar representing the number of bytes to skip at the
+   * beginning of a file.
+   * @param recordBytes A scalar representing the number of bytes in each record.
+   * @param footerBytes A scalar representing the number of bytes to skip at the end
+   * of a file.
+   * @param bufferSize A scalar representing the number of bytes to buffer. Must be > 0.
+   * @return a new instance of FixedLengthRecordDataset
+   */
+  public static FixedLengthRecordDataset create(Scope scope, Operand<String> filenames, Operand<Long> headerBytes, Operand<Long> recordBytes, Operand<Long> footerBytes, Operand<Long> bufferSize) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("FixedLengthRecordDataset", scope.makeOpName("FixedLengthRecordDataset"));
+    opBuilder.addInput(filenames.asOutput());
+    opBuilder.addInput(headerBytes.asOutput());
+    opBuilder.addInput(recordBytes.asOutput());
+    opBuilder.addInput(footerBytes.asOutput());
+    opBuilder.addInput(bufferSize.asOutput());
+    return new FixedLengthRecordDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private FixedLengthRecordDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/FixedLengthRecordReader.java java-ops/org/tensorflow/op/core/FixedLengthRecordReader.java
--- java/org/tensorflow/op/core/FixedLengthRecordReader.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/FixedLengthRecordReader.java	2018-10-16 20:18:38.285432344 +0900
@@ -0,0 +1,204 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * A Reader that outputs fixed-length records from a file.
+ */
+@Operator
+public final class FixedLengthRecordReader extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.FixedLengthRecordReader}
+   */
+  public static class Options {
+    
+    /**
+     * @param headerBytes Number of bytes in the header, defaults to 0.
+     */
+    public Options headerBytes(Long headerBytes) {
+      this.headerBytes = headerBytes;
+      return this;
+    }
+    
+    /**
+     * @param footerBytes Number of bytes in the footer, defaults to 0.
+     */
+    public Options footerBytes(Long footerBytes) {
+      this.footerBytes = footerBytes;
+      return this;
+    }
+    
+    /**
+     * @param hopBytes Number of bytes to hop before each read. Default of 0 means using
+     * record_bytes.
+     */
+    public Options hopBytes(Long hopBytes) {
+      this.hopBytes = hopBytes;
+      return this;
+    }
+    
+    /**
+     * @param container If non-empty, this reader is placed in the given container.
+     * Otherwise, a default container is used.
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName If non-empty, this reader is named in the given bucket
+     * with this shared_name. Otherwise, the node name is used instead.
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    /**
+     * @param encoding The type of encoding for the file. Currently ZLIB and GZIP
+     * are supported. Defaults to none.
+     */
+    public Options encoding(String encoding) {
+      this.encoding = encoding;
+      return this;
+    }
+    
+    private Long headerBytes;
+    private Long footerBytes;
+    private Long hopBytes;
+    private String container;
+    private String sharedName;
+    private String encoding;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new FixedLengthRecordReader operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param recordBytes Number of bytes in the record.
+   * @param options carries optional attributes values
+   * @return a new instance of FixedLengthRecordReader
+   */
+  public static FixedLengthRecordReader create(Scope scope, Long recordBytes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("FixedLengthRecordReaderV2", scope.makeOpName("FixedLengthRecordReader"));
+    opBuilder.setAttr("record_bytes", recordBytes);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.headerBytes != null) {
+          opBuilder.setAttr("header_bytes", opts.headerBytes);
+        }
+        if (opts.footerBytes != null) {
+          opBuilder.setAttr("footer_bytes", opts.footerBytes);
+        }
+        if (opts.hopBytes != null) {
+          opBuilder.setAttr("hop_bytes", opts.hopBytes);
+        }
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+        if (opts.encoding != null) {
+          opBuilder.setAttr("encoding", opts.encoding);
+        }
+      }
+    }
+    return new FixedLengthRecordReader(opBuilder.build());
+  }
+  
+  /**
+   * @param headerBytes Number of bytes in the header, defaults to 0.
+   */
+  public static Options headerBytes(Long headerBytes) {
+    return new Options().headerBytes(headerBytes);
+  }
+  
+  /**
+   * @param footerBytes Number of bytes in the footer, defaults to 0.
+   */
+  public static Options footerBytes(Long footerBytes) {
+    return new Options().footerBytes(footerBytes);
+  }
+  
+  /**
+   * @param hopBytes Number of bytes to hop before each read. Default of 0 means using
+   * record_bytes.
+   */
+  public static Options hopBytes(Long hopBytes) {
+    return new Options().hopBytes(hopBytes);
+  }
+  
+  /**
+   * @param container If non-empty, this reader is placed in the given container.
+   * Otherwise, a default container is used.
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName If non-empty, this reader is named in the given bucket
+   * with this shared_name. Otherwise, the node name is used instead.
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   * @param encoding The type of encoding for the file. Currently ZLIB and GZIP
+   * are supported. Defaults to none.
+   */
+  public static Options encoding(String encoding) {
+    return new Options().encoding(encoding);
+  }
+  
+  /**
+   * The handle to reference the Reader.
+   */
+  public Output<?> readerHandle() {
+    return readerHandle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) readerHandle;
+  }
+  
+  private Output<?> readerHandle;
+  
+  private FixedLengthRecordReader(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    readerHandle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/FixedUnigramCandidateSampler.java java-ops/org/tensorflow/op/core/FixedUnigramCandidateSampler.java
--- java/org/tensorflow/op/core/FixedUnigramCandidateSampler.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/FixedUnigramCandidateSampler.java	2018-10-16 20:18:38.286432343 +0900
@@ -0,0 +1,321 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Generates labels for candidate sampling with a learned unigram distribution.
+ * <p>
+ * A unigram sampler could use a fixed unigram distribution read from a
+ * file or passed in as an in-memory array instead of building up the distribution
+ * from data on the fly. There is also an option to skew the distribution by
+ * applying a distortion power to the weights.
+ * <p>
+ * The vocabulary file should be in CSV-like format, with the last field
+ * being the weight associated with the word.
+ * <p>
+ * For each batch, this op picks a single set of sampled candidate labels.
+ * <p>
+ * The advantages of sampling candidates per-batch are simplicity and the
+ * possibility of efficient dense matrix multiplication. The disadvantage is that
+ * the sampled candidates must be chosen independently of the context and of the
+ * true labels.
+ */
+@Operator
+public final class FixedUnigramCandidateSampler extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.FixedUnigramCandidateSampler}
+   */
+  public static class Options {
+    
+    /**
+     * @param vocabFile Each valid line in this file (which should have a CSV-like format)
+     * corresponds to a valid word ID. IDs are in sequential order, starting from
+     * num_reserved_ids. The last entry in each line is expected to be a value
+     * corresponding to the count or relative probability. Exactly one of vocab_file
+     * and unigrams needs to be passed to this op.
+     */
+    public Options vocabFile(String vocabFile) {
+      this.vocabFile = vocabFile;
+      return this;
+    }
+    
+    /**
+     * @param distortion The distortion is used to skew the unigram probability distribution.
+     * Each weight is first raised to the distortion's power before adding to the
+     * internal unigram distribution. As a result, distortion = 1.0 gives regular
+     * unigram sampling (as defined by the vocab file), and distortion = 0.0 gives
+     * a uniform distribution.
+     */
+    public Options distortion(Float distortion) {
+      this.distortion = distortion;
+      return this;
+    }
+    
+    /**
+     * @param numReservedIds Optionally some reserved IDs can be added in the range [0,
+     * ..., num_reserved_ids) by the users. One use case is that a special unknown
+     * word token is used as ID 0. These IDs will have a sampling probability of 0.
+     */
+    public Options numReservedIds(Long numReservedIds) {
+      this.numReservedIds = numReservedIds;
+      return this;
+    }
+    
+    /**
+     * @param numShards A sampler can be used to sample from a subset of the original range
+     * in order to speed up the whole computation through parallelism. This parameter
+     * (together with 'shard') indicates the number of partitions that are being
+     * used in the overall computation.
+     */
+    public Options numShards(Long numShards) {
+      this.numShards = numShards;
+      return this;
+    }
+    
+    /**
+     * @param shard A sampler can be used to sample from a subset of the original range
+     * in order to speed up the whole computation through parallelism. This parameter
+     * (together with 'num_shards') indicates the particular partition number of a
+     * sampler op, when partitioning is being used.
+     */
+    public Options shard(Long shard) {
+      this.shard = shard;
+      return this;
+    }
+    
+    /**
+     * @param unigrams A list of unigram counts or probabilities, one per ID in sequential
+     * order. Exactly one of vocab_file and unigrams should be passed to this op.
+     */
+    public Options unigrams(List<Float> unigrams) {
+      this.unigrams = unigrams;
+      return this;
+    }
+    
+    /**
+     * @param seed If either seed or seed2 are set to be non-zero, the random number
+     * generator is seeded by the given seed.  Otherwise, it is seeded by a
+     * random seed.
+     */
+    public Options seed(Long seed) {
+      this.seed = seed;
+      return this;
+    }
+    
+    /**
+     * @param seed2 An second seed to avoid seed collision.
+     */
+    public Options seed2(Long seed2) {
+      this.seed2 = seed2;
+      return this;
+    }
+    
+    private String vocabFile;
+    private Float distortion;
+    private Long numReservedIds;
+    private Long numShards;
+    private Long shard;
+    private List<Float> unigrams;
+    private Long seed;
+    private Long seed2;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new FixedUnigramCandidateSampler operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param trueClasses A batch_size * num_true matrix, in which each row contains the
+   * IDs of the num_true target_classes in the corresponding original label.
+   * @param numTrue Number of true labels per context.
+   * @param numSampled Number of candidates to randomly sample.
+   * @param unique If unique is true, we sample with rejection, so that all sampled
+   * candidates in a batch are unique. This requires some approximation to
+   * estimate the post-rejection sampling probabilities.
+   * @param rangeMax The sampler will sample integers from the interval [0, range_max).
+   * @param options carries optional attributes values
+   * @return a new instance of FixedUnigramCandidateSampler
+   */
+  public static FixedUnigramCandidateSampler create(Scope scope, Operand<Long> trueClasses, Long numTrue, Long numSampled, Boolean unique, Long rangeMax, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("FixedUnigramCandidateSampler", scope.makeOpName("FixedUnigramCandidateSampler"));
+    opBuilder.addInput(trueClasses.asOutput());
+    opBuilder.setAttr("num_true", numTrue);
+    opBuilder.setAttr("num_sampled", numSampled);
+    opBuilder.setAttr("unique", unique);
+    opBuilder.setAttr("range_max", rangeMax);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.vocabFile != null) {
+          opBuilder.setAttr("vocab_file", opts.vocabFile);
+        }
+        if (opts.distortion != null) {
+          opBuilder.setAttr("distortion", opts.distortion);
+        }
+        if (opts.numReservedIds != null) {
+          opBuilder.setAttr("num_reserved_ids", opts.numReservedIds);
+        }
+        if (opts.numShards != null) {
+          opBuilder.setAttr("num_shards", opts.numShards);
+        }
+        if (opts.shard != null) {
+          opBuilder.setAttr("shard", opts.shard);
+        }
+        if (opts.unigrams != null) {
+          float[] unigramsArray = new float[opts.unigrams.size()];
+          for (int i = 0; i < unigramsArray.length; ++i) {
+            unigramsArray[i] = opts.unigrams.get(i);
+          }
+          opBuilder.setAttr("unigrams", unigramsArray);
+        }
+        if (opts.seed != null) {
+          opBuilder.setAttr("seed", opts.seed);
+        }
+        if (opts.seed2 != null) {
+          opBuilder.setAttr("seed2", opts.seed2);
+        }
+      }
+    }
+    return new FixedUnigramCandidateSampler(opBuilder.build());
+  }
+  
+  /**
+   * @param vocabFile Each valid line in this file (which should have a CSV-like format)
+   * corresponds to a valid word ID. IDs are in sequential order, starting from
+   * num_reserved_ids. The last entry in each line is expected to be a value
+   * corresponding to the count or relative probability. Exactly one of vocab_file
+   * and unigrams needs to be passed to this op.
+   */
+  public static Options vocabFile(String vocabFile) {
+    return new Options().vocabFile(vocabFile);
+  }
+  
+  /**
+   * @param distortion The distortion is used to skew the unigram probability distribution.
+   * Each weight is first raised to the distortion's power before adding to the
+   * internal unigram distribution. As a result, distortion = 1.0 gives regular
+   * unigram sampling (as defined by the vocab file), and distortion = 0.0 gives
+   * a uniform distribution.
+   */
+  public static Options distortion(Float distortion) {
+    return new Options().distortion(distortion);
+  }
+  
+  /**
+   * @param numReservedIds Optionally some reserved IDs can be added in the range [0,
+   * ..., num_reserved_ids) by the users. One use case is that a special unknown
+   * word token is used as ID 0. These IDs will have a sampling probability of 0.
+   */
+  public static Options numReservedIds(Long numReservedIds) {
+    return new Options().numReservedIds(numReservedIds);
+  }
+  
+  /**
+   * @param numShards A sampler can be used to sample from a subset of the original range
+   * in order to speed up the whole computation through parallelism. This parameter
+   * (together with 'shard') indicates the number of partitions that are being
+   * used in the overall computation.
+   */
+  public static Options numShards(Long numShards) {
+    return new Options().numShards(numShards);
+  }
+  
+  /**
+   * @param shard A sampler can be used to sample from a subset of the original range
+   * in order to speed up the whole computation through parallelism. This parameter
+   * (together with 'num_shards') indicates the particular partition number of a
+   * sampler op, when partitioning is being used.
+   */
+  public static Options shard(Long shard) {
+    return new Options().shard(shard);
+  }
+  
+  /**
+   * @param unigrams A list of unigram counts or probabilities, one per ID in sequential
+   * order. Exactly one of vocab_file and unigrams should be passed to this op.
+   */
+  public static Options unigrams(List<Float> unigrams) {
+    return new Options().unigrams(unigrams);
+  }
+  
+  /**
+   * @param seed If either seed or seed2 are set to be non-zero, the random number
+   * generator is seeded by the given seed.  Otherwise, it is seeded by a
+   * random seed.
+   */
+  public static Options seed(Long seed) {
+    return new Options().seed(seed);
+  }
+  
+  /**
+   * @param seed2 An second seed to avoid seed collision.
+   */
+  public static Options seed2(Long seed2) {
+    return new Options().seed2(seed2);
+  }
+  
+  /**
+   * A vector of length num_sampled, in which each element is
+   * the ID of a sampled candidate.
+   */
+  public Output<Long> sampledCandidates() {
+    return sampledCandidates;
+  }
+  
+  /**
+   * A batch_size * num_true matrix, representing
+   * the number of times each candidate is expected to occur in a batch
+   * of sampled candidates. If unique=true, then this is a probability.
+   */
+  public Output<Float> trueExpectedCount() {
+    return trueExpectedCount;
+  }
+  
+  /**
+   * A vector of length num_sampled, for each sampled
+   * candidate representing the number of times the candidate is expected
+   * to occur in a batch of sampled candidates.  If unique=true, then this is a
+   * probability.
+   */
+  public Output<Float> sampledExpectedCount() {
+    return sampledExpectedCount;
+  }
+  
+  private Output<Long> sampledCandidates;
+  private Output<Float> trueExpectedCount;
+  private Output<Float> sampledExpectedCount;
+  
+  private FixedUnigramCandidateSampler(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    sampledCandidates = operation.output(outputIdx++);
+    trueExpectedCount = operation.output(outputIdx++);
+    sampledExpectedCount = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/FloorDiv.java java-ops/org/tensorflow/op/core/FloorDiv.java
--- java/org/tensorflow/op/core/FloorDiv.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/FloorDiv.java	2018-10-16 20:18:38.287432342 +0900
@@ -0,0 +1,72 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns x // y element-wise.
+ * <p>
+ * <i>NOTE</i>: `FloorDiv` supports broadcasting. More about broadcasting
+ * [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
+ * 
+ * @param <T> data type for {@code z()} output
+ */
+@Operator
+public final class FloorDiv<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new FloorDiv operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param y 
+   * @return a new instance of FloorDiv
+   */
+  public static <T> FloorDiv<T> create(Scope scope, Operand<T> x, Operand<T> y) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("FloorDiv", scope.makeOpName("FloorDiv"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(y.asOutput());
+    return new FloorDiv<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return z;
+  }
+  
+  private Output<T> z;
+  
+  private FloorDiv(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Floor.java java-ops/org/tensorflow/op/core/Floor.java
--- java/org/tensorflow/op/core/Floor.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Floor.java	2018-10-16 20:18:38.286432343 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns element-wise largest integer not greater than x.
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class Floor<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Floor operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of Floor
+   */
+  public static <T extends Number> Floor<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Floor", scope.makeOpName("Floor"));
+    opBuilder.addInput(x.asOutput());
+    return new Floor<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private Floor(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/FloorMod.java java-ops/org/tensorflow/op/core/FloorMod.java
--- java/org/tensorflow/op/core/FloorMod.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/FloorMod.java	2018-10-16 20:18:38.287432342 +0900
@@ -0,0 +1,75 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns element-wise remainder of division. When `x < 0` xor `y < 0` is
+ * <p>
+ * true, this follows Python semantics in that the result here is consistent
+ * with a flooring divide. E.g. `floor(x / y) * y + mod(x, y) = x`.
+ * <p>
+ * <i>NOTE</i>: `FloorMod` supports broadcasting. More about broadcasting
+ * [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
+ * 
+ * @param <T> data type for {@code z()} output
+ */
+@Operator
+public final class FloorMod<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new FloorMod operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param y 
+   * @return a new instance of FloorMod
+   */
+  public static <T extends Number> FloorMod<T> create(Scope scope, Operand<T> x, Operand<T> y) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("FloorMod", scope.makeOpName("FloorMod"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(y.asOutput());
+    return new FloorMod<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return z;
+  }
+  
+  private Output<T> z;
+  
+  private FloorMod(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/FlushSummaryWriter.java java-ops/org/tensorflow/op/core/FlushSummaryWriter.java
--- java/org/tensorflow/op/core/FlushSummaryWriter.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/FlushSummaryWriter.java	2018-10-16 20:18:38.287432342 +0900
@@ -0,0 +1,47 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ */
+public final class FlushSummaryWriter extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new FlushSummaryWriter operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param writer 
+   * @return a new instance of FlushSummaryWriter
+   */
+  public static FlushSummaryWriter create(Scope scope, Operand<?> writer) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("FlushSummaryWriter", scope.makeOpName("FlushSummaryWriter"));
+    opBuilder.addInput(writer.asOutput());
+    return new FlushSummaryWriter(opBuilder.build());
+  }
+  
+  
+  private FlushSummaryWriter(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/FractionalAvgPoolGrad.java java-ops/org/tensorflow/op/core/FractionalAvgPoolGrad.java
--- java/org/tensorflow/op/core/FractionalAvgPoolGrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/FractionalAvgPoolGrad.java	2018-10-16 20:18:38.289432341 +0900
@@ -0,0 +1,131 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Computes gradient of the FractionalAvgPool function.
+ * <p>
+ * Unlike FractionalMaxPoolGrad, we don't need to find arg_max for
+ * FractionalAvgPoolGrad, we just need to evenly back-propagate each element of
+ * out_backprop to those indices that form the same pooling cell. Therefore, we
+ * just need to know the shape of original input tensor, instead of the whole
+ * tensor.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+public final class FractionalAvgPoolGrad<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.FractionalAvgPoolGrad}
+   */
+  public static class Options {
+    
+    /**
+     * @param overlapping When set to True, it means when pooling, the values at the boundary
+     * of adjacent pooling cells are used by both cells. For example:
+     * <p>
+     * `index  0  1  2  3  4`
+     * <p>
+     * `value  20 5  16 3  7`
+     * <p>
+     * If the pooling sequence is [0, 2, 4], then 16, at index 2 will be used twice.
+     * The result would be [41/3, 26/3] for fractional avg pooling.
+     */
+    public Options overlapping(Boolean overlapping) {
+      this.overlapping = overlapping;
+      return this;
+    }
+    
+    private Boolean overlapping;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new FractionalAvgPoolGrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param origInputTensorShape Original input tensor shape for `fractional_avg_pool`
+   * @param outBackprop 4-D with shape `[batch, height, width, channels]`.  Gradients
+   * w.r.t. the output of `fractional_avg_pool`.
+   * @param rowPoolingSequence row pooling sequence, form pooling region with
+   * col_pooling_sequence.
+   * @param colPoolingSequence column pooling sequence, form pooling region with
+   * row_pooling sequence.
+   * @param options carries optional attributes values
+   * @return a new instance of FractionalAvgPoolGrad
+   */
+  public static <T extends Number> FractionalAvgPoolGrad<T> create(Scope scope, Operand<Long> origInputTensorShape, Operand<T> outBackprop, Operand<Long> rowPoolingSequence, Operand<Long> colPoolingSequence, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("FractionalAvgPoolGrad", scope.makeOpName("FractionalAvgPoolGrad"));
+    opBuilder.addInput(origInputTensorShape.asOutput());
+    opBuilder.addInput(outBackprop.asOutput());
+    opBuilder.addInput(rowPoolingSequence.asOutput());
+    opBuilder.addInput(colPoolingSequence.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.overlapping != null) {
+          opBuilder.setAttr("overlapping", opts.overlapping);
+        }
+      }
+    }
+    return new FractionalAvgPoolGrad<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param overlapping When set to True, it means when pooling, the values at the boundary
+   * of adjacent pooling cells are used by both cells. For example:
+   * <p>
+   * `index  0  1  2  3  4`
+   * <p>
+   * `value  20 5  16 3  7`
+   * <p>
+   * If the pooling sequence is [0, 2, 4], then 16, at index 2 will be used twice.
+   * The result would be [41/3, 26/3] for fractional avg pooling.
+   */
+  public static Options overlapping(Boolean overlapping) {
+    return new Options().overlapping(overlapping);
+  }
+  
+  /**
+   * 4-D.  Gradients w.r.t. the input of `fractional_avg_pool`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private FractionalAvgPoolGrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/FractionalAvgPool.java java-ops/org/tensorflow/op/core/FractionalAvgPool.java
--- java/org/tensorflow/op/core/FractionalAvgPool.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/FractionalAvgPool.java	2018-10-16 20:18:38.289432341 +0900
@@ -0,0 +1,238 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Performs fractional average pooling on the input.
+ * <p>
+ * Fractional average pooling is similar to Fractional max pooling in the pooling
+ * region generation step. The only difference is that after pooling regions are
+ * generated, a mean operation is performed instead of a max operation in each
+ * pooling region.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class FractionalAvgPool<T extends Number> extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.FractionalAvgPool}
+   */
+  public static class Options {
+    
+    /**
+     * @param pseudoRandom When set to True, generates the pooling sequence in a
+     * pseudorandom fashion, otherwise, in a random fashion. Check paper [Benjamin
+     * Graham, Fractional Max-Pooling](http://arxiv.org/abs/1412.6071) for
+     * difference between pseudorandom and random.
+     */
+    public Options pseudoRandom(Boolean pseudoRandom) {
+      this.pseudoRandom = pseudoRandom;
+      return this;
+    }
+    
+    /**
+     * @param overlapping When set to True, it means when pooling, the values at the boundary
+     * of adjacent pooling cells are used by both cells. For example:
+     * <p>
+     * `index  0  1  2  3  4`
+     * <p>
+     * `value  20 5  16 3  7`
+     * <p>
+     * If the pooling sequence is [0, 2, 4], then 16, at index 2 will be used twice.
+     * The result would be [41/3, 26/3] for fractional avg pooling.
+     */
+    public Options overlapping(Boolean overlapping) {
+      this.overlapping = overlapping;
+      return this;
+    }
+    
+    /**
+     * @param deterministic When set to True, a fixed pooling region will be used when
+     * iterating over a FractionalAvgPool node in the computation graph. Mainly used
+     * in unit test to make FractionalAvgPool deterministic.
+     */
+    public Options deterministic(Boolean deterministic) {
+      this.deterministic = deterministic;
+      return this;
+    }
+    
+    /**
+     * @param seed If either seed or seed2 are set to be non-zero, the random number
+     * generator is seeded by the given seed.  Otherwise, it is seeded by a
+     * random seed.
+     */
+    public Options seed(Long seed) {
+      this.seed = seed;
+      return this;
+    }
+    
+    /**
+     * @param seed2 An second seed to avoid seed collision.
+     */
+    public Options seed2(Long seed2) {
+      this.seed2 = seed2;
+      return this;
+    }
+    
+    private Boolean pseudoRandom;
+    private Boolean overlapping;
+    private Boolean deterministic;
+    private Long seed;
+    private Long seed2;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new FractionalAvgPool operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param value 4-D with shape `[batch, height, width, channels]`.
+   * @param poolingRatio Pooling ratio for each dimension of `value`, currently only
+   * supports row and col dimension and should be >= 1.0. For example, a valid
+   * pooling ratio looks like [1.0, 1.44, 1.73, 1.0]. The first and last elements
+   * must be 1.0 because we don't allow pooling on batch and channels
+   * dimensions. 1.44 and 1.73 are pooling ratio on height and width dimensions
+   * respectively.
+   * @param options carries optional attributes values
+   * @return a new instance of FractionalAvgPool
+   */
+  public static <T extends Number> FractionalAvgPool<T> create(Scope scope, Operand<T> value, List<Float> poolingRatio, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("FractionalAvgPool", scope.makeOpName("FractionalAvgPool"));
+    opBuilder.addInput(value.asOutput());
+    float[] poolingRatioArray = new float[poolingRatio.size()];
+    for (int i = 0; i < poolingRatioArray.length; ++i) {
+      poolingRatioArray[i] = poolingRatio.get(i);
+    }
+    opBuilder.setAttr("pooling_ratio", poolingRatioArray);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.pseudoRandom != null) {
+          opBuilder.setAttr("pseudo_random", opts.pseudoRandom);
+        }
+        if (opts.overlapping != null) {
+          opBuilder.setAttr("overlapping", opts.overlapping);
+        }
+        if (opts.deterministic != null) {
+          opBuilder.setAttr("deterministic", opts.deterministic);
+        }
+        if (opts.seed != null) {
+          opBuilder.setAttr("seed", opts.seed);
+        }
+        if (opts.seed2 != null) {
+          opBuilder.setAttr("seed2", opts.seed2);
+        }
+      }
+    }
+    return new FractionalAvgPool<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param pseudoRandom When set to True, generates the pooling sequence in a
+   * pseudorandom fashion, otherwise, in a random fashion. Check paper [Benjamin
+   * Graham, Fractional Max-Pooling](http://arxiv.org/abs/1412.6071) for
+   * difference between pseudorandom and random.
+   */
+  public static Options pseudoRandom(Boolean pseudoRandom) {
+    return new Options().pseudoRandom(pseudoRandom);
+  }
+  
+  /**
+   * @param overlapping When set to True, it means when pooling, the values at the boundary
+   * of adjacent pooling cells are used by both cells. For example:
+   * <p>
+   * `index  0  1  2  3  4`
+   * <p>
+   * `value  20 5  16 3  7`
+   * <p>
+   * If the pooling sequence is [0, 2, 4], then 16, at index 2 will be used twice.
+   * The result would be [41/3, 26/3] for fractional avg pooling.
+   */
+  public static Options overlapping(Boolean overlapping) {
+    return new Options().overlapping(overlapping);
+  }
+  
+  /**
+   * @param deterministic When set to True, a fixed pooling region will be used when
+   * iterating over a FractionalAvgPool node in the computation graph. Mainly used
+   * in unit test to make FractionalAvgPool deterministic.
+   */
+  public static Options deterministic(Boolean deterministic) {
+    return new Options().deterministic(deterministic);
+  }
+  
+  /**
+   * @param seed If either seed or seed2 are set to be non-zero, the random number
+   * generator is seeded by the given seed.  Otherwise, it is seeded by a
+   * random seed.
+   */
+  public static Options seed(Long seed) {
+    return new Options().seed(seed);
+  }
+  
+  /**
+   * @param seed2 An second seed to avoid seed collision.
+   */
+  public static Options seed2(Long seed2) {
+    return new Options().seed2(seed2);
+  }
+  
+  /**
+   * output tensor after fractional avg pooling.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  /**
+   * row pooling sequence, needed to calculate gradient.
+   */
+  public Output<Long> rowPoolingSequence() {
+    return rowPoolingSequence;
+  }
+  
+  /**
+   * column pooling sequence, needed to calculate gradient.
+   */
+  public Output<Long> colPoolingSequence() {
+    return colPoolingSequence;
+  }
+  
+  private Output<T> output;
+  private Output<Long> rowPoolingSequence;
+  private Output<Long> colPoolingSequence;
+  
+  private FractionalAvgPool(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+    rowPoolingSequence = operation.output(outputIdx++);
+    colPoolingSequence = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/FractionalMaxPoolGrad.java java-ops/org/tensorflow/op/core/FractionalMaxPoolGrad.java
--- java/org/tensorflow/op/core/FractionalMaxPoolGrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/FractionalMaxPoolGrad.java	2018-10-16 20:18:38.291432339 +0900
@@ -0,0 +1,127 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Computes gradient of the FractionalMaxPool function.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+public final class FractionalMaxPoolGrad<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.FractionalMaxPoolGrad}
+   */
+  public static class Options {
+    
+    /**
+     * @param overlapping When set to True, it means when pooling, the values at the boundary
+     * of adjacent pooling cells are used by both cells. For example:
+     * <p>
+     * `index  0  1  2  3  4`
+     * <p>
+     * `value  20 5  16 3  7`
+     * <p>
+     * If the pooling sequence is [0, 2, 4], then 16, at index 2 will be used twice.
+     * The result would be [20, 16] for fractional max pooling.
+     */
+    public Options overlapping(Boolean overlapping) {
+      this.overlapping = overlapping;
+      return this;
+    }
+    
+    private Boolean overlapping;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new FractionalMaxPoolGrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param origInput Original input for `fractional_max_pool`
+   * @param origOutput Original output for `fractional_max_pool`
+   * @param outBackprop 4-D with shape `[batch, height, width, channels]`.  Gradients
+   * w.r.t. the output of `fractional_max_pool`.
+   * @param rowPoolingSequence row pooling sequence, form pooling region with
+   * col_pooling_sequence.
+   * @param colPoolingSequence column pooling sequence, form pooling region with
+   * row_pooling sequence.
+   * @param options carries optional attributes values
+   * @return a new instance of FractionalMaxPoolGrad
+   */
+  public static <T extends Number> FractionalMaxPoolGrad<T> create(Scope scope, Operand<T> origInput, Operand<T> origOutput, Operand<T> outBackprop, Operand<Long> rowPoolingSequence, Operand<Long> colPoolingSequence, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("FractionalMaxPoolGrad", scope.makeOpName("FractionalMaxPoolGrad"));
+    opBuilder.addInput(origInput.asOutput());
+    opBuilder.addInput(origOutput.asOutput());
+    opBuilder.addInput(outBackprop.asOutput());
+    opBuilder.addInput(rowPoolingSequence.asOutput());
+    opBuilder.addInput(colPoolingSequence.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.overlapping != null) {
+          opBuilder.setAttr("overlapping", opts.overlapping);
+        }
+      }
+    }
+    return new FractionalMaxPoolGrad<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param overlapping When set to True, it means when pooling, the values at the boundary
+   * of adjacent pooling cells are used by both cells. For example:
+   * <p>
+   * `index  0  1  2  3  4`
+   * <p>
+   * `value  20 5  16 3  7`
+   * <p>
+   * If the pooling sequence is [0, 2, 4], then 16, at index 2 will be used twice.
+   * The result would be [20, 16] for fractional max pooling.
+   */
+  public static Options overlapping(Boolean overlapping) {
+    return new Options().overlapping(overlapping);
+  }
+  
+  /**
+   * 4-D.  Gradients w.r.t. the input of `fractional_max_pool`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private FractionalMaxPoolGrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/FractionalMaxPool.java java-ops/org/tensorflow/op/core/FractionalMaxPool.java
--- java/org/tensorflow/op/core/FractionalMaxPool.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/FractionalMaxPool.java	2018-10-16 20:18:38.291432339 +0900
@@ -0,0 +1,262 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Performs fractional max pooling on the input.
+ * <p>
+ * Fractional max pooling is slightly different than regular max pooling.  In
+ * regular max pooling, you downsize an input set by taking the maximum value of
+ * smaller N x N subsections of the set (often 2x2), and try to reduce the set by
+ * a factor of N, where N is an integer.  Fractional max pooling, as you might
+ * expect from the word "fractional", means that the overall reduction ratio N
+ * does not have to be an integer.
+ * <p>
+ * The sizes of the pooling regions are generated randomly but are fairly uniform.
+ * For example, let's look at the height dimension, and the constraints on the
+ * list of rows that will be pool boundaries.
+ * <p>
+ * First we define the following:
+ * <p>
+ * 1.  input_row_length : the number of rows from the input set
+ * 2.  output_row_length : which will be smaller than the input
+ * 3.  alpha = input_row_length / output_row_length : our reduction ratio
+ * 4.  K = floor(alpha)
+ * 5.  row_pooling_sequence : this is the result list of pool boundary rows
+ * <p>
+ * Then, row_pooling_sequence should satisfy:
+ * <p>
+ * 1.  a[0] = 0 : the first value of the sequence is 0
+ * 2.  a[end] = input_row_length : the last value of the sequence is the size
+ * 3.  K <= (a[i+1] - a[i]) <= K+1 : all intervals are K or K+1 size
+ * 4.  length(row_pooling_sequence) = output_row_length+1
+ * <p>
+ * For more details on fractional max pooling, see this paper:
+ * [Benjamin Graham, Fractional Max-Pooling](http://arxiv.org/abs/1412.6071)
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class FractionalMaxPool<T extends Number> extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.FractionalMaxPool}
+   */
+  public static class Options {
+    
+    /**
+     * @param pseudoRandom When set to True, generates the pooling sequence in a
+     * pseudorandom fashion, otherwise, in a random fashion. Check paper [Benjamin
+     * Graham, Fractional Max-Pooling](http://arxiv.org/abs/1412.6071) for
+     * difference between pseudorandom and random.
+     */
+    public Options pseudoRandom(Boolean pseudoRandom) {
+      this.pseudoRandom = pseudoRandom;
+      return this;
+    }
+    
+    /**
+     * @param overlapping When set to True, it means when pooling, the values at the boundary
+     * of adjacent pooling cells are used by both cells. For example:
+     * <p>
+     * `index  0  1  2  3  4`
+     * <p>
+     * `value  20 5  16 3  7`
+     * <p>
+     * If the pooling sequence is [0, 2, 4], then 16, at index 2 will be used twice.
+     * The result would be [20, 16] for fractional max pooling.
+     */
+    public Options overlapping(Boolean overlapping) {
+      this.overlapping = overlapping;
+      return this;
+    }
+    
+    /**
+     * @param deterministic When set to True, a fixed pooling region will be used when
+     * iterating over a FractionalMaxPool node in the computation graph. Mainly used
+     * in unit test to make FractionalMaxPool deterministic.
+     */
+    public Options deterministic(Boolean deterministic) {
+      this.deterministic = deterministic;
+      return this;
+    }
+    
+    /**
+     * @param seed If either seed or seed2 are set to be non-zero, the random number
+     * generator is seeded by the given seed.  Otherwise, it is seeded by a
+     * random seed.
+     */
+    public Options seed(Long seed) {
+      this.seed = seed;
+      return this;
+    }
+    
+    /**
+     * @param seed2 An second seed to avoid seed collision.
+     */
+    public Options seed2(Long seed2) {
+      this.seed2 = seed2;
+      return this;
+    }
+    
+    private Boolean pseudoRandom;
+    private Boolean overlapping;
+    private Boolean deterministic;
+    private Long seed;
+    private Long seed2;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new FractionalMaxPool operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param value 4-D with shape `[batch, height, width, channels]`.
+   * @param poolingRatio Pooling ratio for each dimension of `value`, currently only
+   * supports row and col dimension and should be >= 1.0. For example, a valid
+   * pooling ratio looks like [1.0, 1.44, 1.73, 1.0]. The first and last elements
+   * must be 1.0 because we don't allow pooling on batch and channels
+   * dimensions. 1.44 and 1.73 are pooling ratio on height and width dimensions
+   * respectively.
+   * @param options carries optional attributes values
+   * @return a new instance of FractionalMaxPool
+   */
+  public static <T extends Number> FractionalMaxPool<T> create(Scope scope, Operand<T> value, List<Float> poolingRatio, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("FractionalMaxPool", scope.makeOpName("FractionalMaxPool"));
+    opBuilder.addInput(value.asOutput());
+    float[] poolingRatioArray = new float[poolingRatio.size()];
+    for (int i = 0; i < poolingRatioArray.length; ++i) {
+      poolingRatioArray[i] = poolingRatio.get(i);
+    }
+    opBuilder.setAttr("pooling_ratio", poolingRatioArray);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.pseudoRandom != null) {
+          opBuilder.setAttr("pseudo_random", opts.pseudoRandom);
+        }
+        if (opts.overlapping != null) {
+          opBuilder.setAttr("overlapping", opts.overlapping);
+        }
+        if (opts.deterministic != null) {
+          opBuilder.setAttr("deterministic", opts.deterministic);
+        }
+        if (opts.seed != null) {
+          opBuilder.setAttr("seed", opts.seed);
+        }
+        if (opts.seed2 != null) {
+          opBuilder.setAttr("seed2", opts.seed2);
+        }
+      }
+    }
+    return new FractionalMaxPool<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param pseudoRandom When set to True, generates the pooling sequence in a
+   * pseudorandom fashion, otherwise, in a random fashion. Check paper [Benjamin
+   * Graham, Fractional Max-Pooling](http://arxiv.org/abs/1412.6071) for
+   * difference between pseudorandom and random.
+   */
+  public static Options pseudoRandom(Boolean pseudoRandom) {
+    return new Options().pseudoRandom(pseudoRandom);
+  }
+  
+  /**
+   * @param overlapping When set to True, it means when pooling, the values at the boundary
+   * of adjacent pooling cells are used by both cells. For example:
+   * <p>
+   * `index  0  1  2  3  4`
+   * <p>
+   * `value  20 5  16 3  7`
+   * <p>
+   * If the pooling sequence is [0, 2, 4], then 16, at index 2 will be used twice.
+   * The result would be [20, 16] for fractional max pooling.
+   */
+  public static Options overlapping(Boolean overlapping) {
+    return new Options().overlapping(overlapping);
+  }
+  
+  /**
+   * @param deterministic When set to True, a fixed pooling region will be used when
+   * iterating over a FractionalMaxPool node in the computation graph. Mainly used
+   * in unit test to make FractionalMaxPool deterministic.
+   */
+  public static Options deterministic(Boolean deterministic) {
+    return new Options().deterministic(deterministic);
+  }
+  
+  /**
+   * @param seed If either seed or seed2 are set to be non-zero, the random number
+   * generator is seeded by the given seed.  Otherwise, it is seeded by a
+   * random seed.
+   */
+  public static Options seed(Long seed) {
+    return new Options().seed(seed);
+  }
+  
+  /**
+   * @param seed2 An second seed to avoid seed collision.
+   */
+  public static Options seed2(Long seed2) {
+    return new Options().seed2(seed2);
+  }
+  
+  /**
+   * output tensor after fractional max pooling.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  /**
+   * row pooling sequence, needed to calculate gradient.
+   */
+  public Output<Long> rowPoolingSequence() {
+    return rowPoolingSequence;
+  }
+  
+  /**
+   * column pooling sequence, needed to calculate gradient.
+   */
+  public Output<Long> colPoolingSequence() {
+    return colPoolingSequence;
+  }
+  
+  private Output<T> output;
+  private Output<Long> rowPoolingSequence;
+  private Output<Long> colPoolingSequence;
+  
+  private FractionalMaxPool(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+    rowPoolingSequence = operation.output(outputIdx++);
+    colPoolingSequence = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/FusedBatchNormGrad.java java-ops/org/tensorflow/op/core/FusedBatchNormGrad.java
--- java/org/tensorflow/op/core/FusedBatchNormGrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/FusedBatchNormGrad.java	2018-10-16 20:18:38.292432339 +0900
@@ -0,0 +1,194 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Gradient for batch normalization.
+ * <p>
+ * Note that the size of 4D Tensors are defined by either "NHWC" or "NCHW".
+ * The size of 1D Tensors matches the dimension C of the 4D Tensors.
+ * 
+ * @param <T> data type for {@code xBackprop()} output
+ */
+@Operator
+public final class FusedBatchNormGrad<T extends Number> extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.FusedBatchNormGrad}
+   */
+  public static class Options {
+    
+    /**
+     * @param epsilon A small float number added to the variance of x.
+     */
+    public Options epsilon(Float epsilon) {
+      this.epsilon = epsilon;
+      return this;
+    }
+    
+    /**
+     * @param dataFormat The data format for y_backprop, x, x_backprop.
+     * Either "NHWC" (default) or "NCHW".
+     */
+    public Options dataFormat(String dataFormat) {
+      this.dataFormat = dataFormat;
+      return this;
+    }
+    
+    /**
+     * @param isTraining A bool value to indicate the operation is for training (default)
+     * or inference.
+     */
+    public Options isTraining(Boolean isTraining) {
+      this.isTraining = isTraining;
+      return this;
+    }
+    
+    private Float epsilon;
+    private String dataFormat;
+    private Boolean isTraining;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new FusedBatchNormGrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param yBackprop A 4D Tensor for the gradient with respect to y.
+   * @param x A 4D Tensor for input data.
+   * @param scale A 1D Tensor for scaling factor, to scale the normalized x.
+   * @param reserveSpace1 When is_training is True, a 1D Tensor for the computed batch
+   * mean to be reused in gradient computation. When is_training is
+   * False, a 1D Tensor for the population mean to be reused in both
+   * 1st and 2nd order gradient computation.
+   * @param reserveSpace2 When is_training is True, a 1D Tensor for the computed batch
+   * variance (inverted variance in the cuDNN case) to be reused in
+   * gradient computation. When is_training is False, a 1D Tensor
+   * for the population variance to be reused in both 1st and 2nd
+   * order gradient computation.
+   * @param options carries optional attributes values
+   * @return a new instance of FusedBatchNormGrad
+   */
+  public static <T extends Number> FusedBatchNormGrad<T> create(Scope scope, Operand<T> yBackprop, Operand<T> x, Operand<T> scale, Operand<T> reserveSpace1, Operand<T> reserveSpace2, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("FusedBatchNormGrad", scope.makeOpName("FusedBatchNormGrad"));
+    opBuilder.addInput(yBackprop.asOutput());
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(scale.asOutput());
+    opBuilder.addInput(reserveSpace1.asOutput());
+    opBuilder.addInput(reserveSpace2.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.epsilon != null) {
+          opBuilder.setAttr("epsilon", opts.epsilon);
+        }
+        if (opts.dataFormat != null) {
+          opBuilder.setAttr("data_format", opts.dataFormat);
+        }
+        if (opts.isTraining != null) {
+          opBuilder.setAttr("is_training", opts.isTraining);
+        }
+      }
+    }
+    return new FusedBatchNormGrad<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param epsilon A small float number added to the variance of x.
+   */
+  public static Options epsilon(Float epsilon) {
+    return new Options().epsilon(epsilon);
+  }
+  
+  /**
+   * @param dataFormat The data format for y_backprop, x, x_backprop.
+   * Either "NHWC" (default) or "NCHW".
+   */
+  public static Options dataFormat(String dataFormat) {
+    return new Options().dataFormat(dataFormat);
+  }
+  
+  /**
+   * @param isTraining A bool value to indicate the operation is for training (default)
+   * or inference.
+   */
+  public static Options isTraining(Boolean isTraining) {
+    return new Options().isTraining(isTraining);
+  }
+  
+  /**
+   * A 4D Tensor for the gradient with respect to x.
+   */
+  public Output<T> xBackprop() {
+    return xBackprop;
+  }
+  
+  /**
+   * A 1D Tensor for the gradient with respect to scale.
+   */
+  public Output<T> scaleBackprop() {
+    return scaleBackprop;
+  }
+  
+  /**
+   * A 1D Tensor for the gradient with respect to offset.
+   */
+  public Output<T> offsetBackprop() {
+    return offsetBackprop;
+  }
+  
+  /**
+   * Unused placeholder to match the mean input in FusedBatchNorm.
+   */
+  public Output<T> reserveSpace3() {
+    return reserveSpace3;
+  }
+  
+  /**
+   * Unused placeholder to match the variance input
+   * in FusedBatchNorm.
+   */
+  public Output<T> reserveSpace4() {
+    return reserveSpace4;
+  }
+  
+  private Output<T> xBackprop;
+  private Output<T> scaleBackprop;
+  private Output<T> offsetBackprop;
+  private Output<T> reserveSpace3;
+  private Output<T> reserveSpace4;
+  
+  private FusedBatchNormGrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    xBackprop = operation.output(outputIdx++);
+    scaleBackprop = operation.output(outputIdx++);
+    offsetBackprop = operation.output(outputIdx++);
+    reserveSpace3 = operation.output(outputIdx++);
+    reserveSpace4 = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/FusedBatchNormGradV2.java java-ops/org/tensorflow/op/core/FusedBatchNormGradV2.java
--- java/org/tensorflow/op/core/FusedBatchNormGradV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/FusedBatchNormGradV2.java	2018-10-16 20:18:38.293432338 +0900
@@ -0,0 +1,195 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Gradient for batch normalization.
+ * <p>
+ * Note that the size of 4D Tensors are defined by either "NHWC" or "NCHW".
+ * The size of 1D Tensors matches the dimension C of the 4D Tensors.
+ * 
+ * @param <T> data type for {@code xBackprop()} output
+ * @param <U> data type for {@code scaleBackprop()} output
+ */
+@Operator
+public final class FusedBatchNormGradV2<T extends Number, U extends Number> extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.FusedBatchNormGradV2}
+   */
+  public static class Options {
+    
+    /**
+     * @param epsilon A small float number added to the variance of x.
+     */
+    public Options epsilon(Float epsilon) {
+      this.epsilon = epsilon;
+      return this;
+    }
+    
+    /**
+     * @param dataFormat The data format for y_backprop, x, x_backprop.
+     * Either "NHWC" (default) or "NCHW".
+     */
+    public Options dataFormat(String dataFormat) {
+      this.dataFormat = dataFormat;
+      return this;
+    }
+    
+    /**
+     * @param isTraining A bool value to indicate the operation is for training (default)
+     * or inference.
+     */
+    public Options isTraining(Boolean isTraining) {
+      this.isTraining = isTraining;
+      return this;
+    }
+    
+    private Float epsilon;
+    private String dataFormat;
+    private Boolean isTraining;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new FusedBatchNormGradV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param yBackprop A 4D Tensor for the gradient with respect to y.
+   * @param x A 4D Tensor for input data.
+   * @param scale A 1D Tensor for scaling factor, to scale the normalized x.
+   * @param reserveSpace1 When is_training is True, a 1D Tensor for the computed batch
+   * mean to be reused in gradient computation. When is_training is
+   * False, a 1D Tensor for the population mean to be reused in both
+   * 1st and 2nd order gradient computation.
+   * @param reserveSpace2 When is_training is True, a 1D Tensor for the computed batch
+   * variance (inverted variance in the cuDNN case) to be reused in
+   * gradient computation. When is_training is False, a 1D Tensor
+   * for the population variance to be reused in both 1st and 2nd
+   * order gradient computation.
+   * @param options carries optional attributes values
+   * @return a new instance of FusedBatchNormGradV2
+   */
+  public static <T extends Number, U extends Number> FusedBatchNormGradV2<T, U> create(Scope scope, Operand<T> yBackprop, Operand<T> x, Operand<Float> scale, Operand<U> reserveSpace1, Operand<U> reserveSpace2, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("FusedBatchNormGradV2", scope.makeOpName("FusedBatchNormGradV2"));
+    opBuilder.addInput(yBackprop.asOutput());
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(scale.asOutput());
+    opBuilder.addInput(reserveSpace1.asOutput());
+    opBuilder.addInput(reserveSpace2.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.epsilon != null) {
+          opBuilder.setAttr("epsilon", opts.epsilon);
+        }
+        if (opts.dataFormat != null) {
+          opBuilder.setAttr("data_format", opts.dataFormat);
+        }
+        if (opts.isTraining != null) {
+          opBuilder.setAttr("is_training", opts.isTraining);
+        }
+      }
+    }
+    return new FusedBatchNormGradV2<T, U>(opBuilder.build());
+  }
+  
+  /**
+   * @param epsilon A small float number added to the variance of x.
+   */
+  public static Options epsilon(Float epsilon) {
+    return new Options().epsilon(epsilon);
+  }
+  
+  /**
+   * @param dataFormat The data format for y_backprop, x, x_backprop.
+   * Either "NHWC" (default) or "NCHW".
+   */
+  public static Options dataFormat(String dataFormat) {
+    return new Options().dataFormat(dataFormat);
+  }
+  
+  /**
+   * @param isTraining A bool value to indicate the operation is for training (default)
+   * or inference.
+   */
+  public static Options isTraining(Boolean isTraining) {
+    return new Options().isTraining(isTraining);
+  }
+  
+  /**
+   * A 4D Tensor for the gradient with respect to x.
+   */
+  public Output<T> xBackprop() {
+    return xBackprop;
+  }
+  
+  /**
+   * A 1D Tensor for the gradient with respect to scale.
+   */
+  public Output<U> scaleBackprop() {
+    return scaleBackprop;
+  }
+  
+  /**
+   * A 1D Tensor for the gradient with respect to offset.
+   */
+  public Output<U> offsetBackprop() {
+    return offsetBackprop;
+  }
+  
+  /**
+   * Unused placeholder to match the mean input in FusedBatchNorm.
+   */
+  public Output<U> reserveSpace3() {
+    return reserveSpace3;
+  }
+  
+  /**
+   * Unused placeholder to match the variance input
+   * in FusedBatchNorm.
+   */
+  public Output<U> reserveSpace4() {
+    return reserveSpace4;
+  }
+  
+  private Output<T> xBackprop;
+  private Output<U> scaleBackprop;
+  private Output<U> offsetBackprop;
+  private Output<U> reserveSpace3;
+  private Output<U> reserveSpace4;
+  
+  private FusedBatchNormGradV2(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    xBackprop = operation.output(outputIdx++);
+    scaleBackprop = operation.output(outputIdx++);
+    offsetBackprop = operation.output(outputIdx++);
+    reserveSpace3 = operation.output(outputIdx++);
+    reserveSpace4 = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/FusedBatchNorm.java java-ops/org/tensorflow/op/core/FusedBatchNorm.java
--- java/org/tensorflow/op/core/FusedBatchNorm.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/FusedBatchNorm.java	2018-10-16 20:18:38.292432339 +0900
@@ -0,0 +1,190 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Batch normalization.
+ * <p>
+ * Note that the size of 4D Tensors are defined by either "NHWC" or "NCHW".
+ * The size of 1D Tensors matches the dimension C of the 4D Tensors.
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class FusedBatchNorm<T extends Number> extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.FusedBatchNorm}
+   */
+  public static class Options {
+    
+    /**
+     * @param epsilon A small float number added to the variance of x.
+     */
+    public Options epsilon(Float epsilon) {
+      this.epsilon = epsilon;
+      return this;
+    }
+    
+    /**
+     * @param dataFormat The data format for x and y. Either "NHWC" (default) or "NCHW".
+     */
+    public Options dataFormat(String dataFormat) {
+      this.dataFormat = dataFormat;
+      return this;
+    }
+    
+    /**
+     * @param isTraining A bool value to indicate the operation is for training (default)
+     * or inference.
+     */
+    public Options isTraining(Boolean isTraining) {
+      this.isTraining = isTraining;
+      return this;
+    }
+    
+    private Float epsilon;
+    private String dataFormat;
+    private Boolean isTraining;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new FusedBatchNorm operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x A 4D Tensor for input data.
+   * @param scale A 1D Tensor for scaling factor, to scale the normalized x.
+   * @param offset A 1D Tensor for offset, to shift to the normalized x.
+   * @param mean A 1D Tensor for population mean. Used for inference only;
+   * must be empty for training.
+   * @param variance A 1D Tensor for population variance. Used for inference only;
+   * must be empty for training.
+   * @param options carries optional attributes values
+   * @return a new instance of FusedBatchNorm
+   */
+  public static <T extends Number> FusedBatchNorm<T> create(Scope scope, Operand<T> x, Operand<T> scale, Operand<T> offset, Operand<T> mean, Operand<T> variance, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("FusedBatchNorm", scope.makeOpName("FusedBatchNorm"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(scale.asOutput());
+    opBuilder.addInput(offset.asOutput());
+    opBuilder.addInput(mean.asOutput());
+    opBuilder.addInput(variance.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.epsilon != null) {
+          opBuilder.setAttr("epsilon", opts.epsilon);
+        }
+        if (opts.dataFormat != null) {
+          opBuilder.setAttr("data_format", opts.dataFormat);
+        }
+        if (opts.isTraining != null) {
+          opBuilder.setAttr("is_training", opts.isTraining);
+        }
+      }
+    }
+    return new FusedBatchNorm<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param epsilon A small float number added to the variance of x.
+   */
+  public static Options epsilon(Float epsilon) {
+    return new Options().epsilon(epsilon);
+  }
+  
+  /**
+   * @param dataFormat The data format for x and y. Either "NHWC" (default) or "NCHW".
+   */
+  public static Options dataFormat(String dataFormat) {
+    return new Options().dataFormat(dataFormat);
+  }
+  
+  /**
+   * @param isTraining A bool value to indicate the operation is for training (default)
+   * or inference.
+   */
+  public static Options isTraining(Boolean isTraining) {
+    return new Options().isTraining(isTraining);
+  }
+  
+  /**
+   * A 4D Tensor for output data.
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  /**
+   * A 1D Tensor for the computed batch mean, to be used by TensorFlow
+   * to compute the running mean.
+   */
+  public Output<T> batchMean() {
+    return batchMean;
+  }
+  
+  /**
+   * A 1D Tensor for the computed batch variance, to be used by
+   * TensorFlow to compute the running variance.
+   */
+  public Output<T> batchVariance() {
+    return batchVariance;
+  }
+  
+  /**
+   * A 1D Tensor for the computed batch mean, to be reused
+   * in the gradient computation.
+   */
+  public Output<T> reserveSpace1() {
+    return reserveSpace1;
+  }
+  
+  /**
+   * A 1D Tensor for the computed batch variance (inverted variance
+   * in the cuDNN case), to be reused in the gradient computation.
+   */
+  public Output<T> reserveSpace2() {
+    return reserveSpace2;
+  }
+  
+  private Output<T> y;
+  private Output<T> batchMean;
+  private Output<T> batchVariance;
+  private Output<T> reserveSpace1;
+  private Output<T> reserveSpace2;
+  
+  private FusedBatchNorm(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+    batchMean = operation.output(outputIdx++);
+    batchVariance = operation.output(outputIdx++);
+    reserveSpace1 = operation.output(outputIdx++);
+    reserveSpace2 = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/FusedBatchNormV2.java java-ops/org/tensorflow/op/core/FusedBatchNormV2.java
--- java/org/tensorflow/op/core/FusedBatchNormV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/FusedBatchNormV2.java	2018-10-16 20:18:38.294432337 +0900
@@ -0,0 +1,191 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Batch normalization.
+ * <p>
+ * Note that the size of 4D Tensors are defined by either "NHWC" or "NCHW".
+ * The size of 1D Tensors matches the dimension C of the 4D Tensors.
+ * 
+ * @param <T> data type for {@code y()} output
+ * @param <U> data type for {@code batchMean()} output
+ */
+@Operator
+public final class FusedBatchNormV2<T extends Number, U extends Number> extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.FusedBatchNormV2}
+   */
+  public static class Options {
+    
+    /**
+     * @param epsilon A small float number added to the variance of x.
+     */
+    public Options epsilon(Float epsilon) {
+      this.epsilon = epsilon;
+      return this;
+    }
+    
+    /**
+     * @param dataFormat The data format for x and y. Either "NHWC" (default) or "NCHW".
+     */
+    public Options dataFormat(String dataFormat) {
+      this.dataFormat = dataFormat;
+      return this;
+    }
+    
+    /**
+     * @param isTraining A bool value to indicate the operation is for training (default)
+     * or inference.
+     */
+    public Options isTraining(Boolean isTraining) {
+      this.isTraining = isTraining;
+      return this;
+    }
+    
+    private Float epsilon;
+    private String dataFormat;
+    private Boolean isTraining;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new FusedBatchNormV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x A 4D Tensor for input data.
+   * @param scale A 1D Tensor for scaling factor, to scale the normalized x.
+   * @param offset A 1D Tensor for offset, to shift to the normalized x.
+   * @param mean A 1D Tensor for population mean. Used for inference only;
+   * must be empty for training.
+   * @param variance A 1D Tensor for population variance. Used for inference only;
+   * must be empty for training.
+   * @param options carries optional attributes values
+   * @return a new instance of FusedBatchNormV2
+   */
+  public static <T extends Number, U extends Number> FusedBatchNormV2<T, U> create(Scope scope, Operand<T> x, Operand<U> scale, Operand<U> offset, Operand<U> mean, Operand<U> variance, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("FusedBatchNormV2", scope.makeOpName("FusedBatchNormV2"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(scale.asOutput());
+    opBuilder.addInput(offset.asOutput());
+    opBuilder.addInput(mean.asOutput());
+    opBuilder.addInput(variance.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.epsilon != null) {
+          opBuilder.setAttr("epsilon", opts.epsilon);
+        }
+        if (opts.dataFormat != null) {
+          opBuilder.setAttr("data_format", opts.dataFormat);
+        }
+        if (opts.isTraining != null) {
+          opBuilder.setAttr("is_training", opts.isTraining);
+        }
+      }
+    }
+    return new FusedBatchNormV2<T, U>(opBuilder.build());
+  }
+  
+  /**
+   * @param epsilon A small float number added to the variance of x.
+   */
+  public static Options epsilon(Float epsilon) {
+    return new Options().epsilon(epsilon);
+  }
+  
+  /**
+   * @param dataFormat The data format for x and y. Either "NHWC" (default) or "NCHW".
+   */
+  public static Options dataFormat(String dataFormat) {
+    return new Options().dataFormat(dataFormat);
+  }
+  
+  /**
+   * @param isTraining A bool value to indicate the operation is for training (default)
+   * or inference.
+   */
+  public static Options isTraining(Boolean isTraining) {
+    return new Options().isTraining(isTraining);
+  }
+  
+  /**
+   * A 4D Tensor for output data.
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  /**
+   * A 1D Tensor for the computed batch mean, to be used by TensorFlow
+   * to compute the running mean.
+   */
+  public Output<U> batchMean() {
+    return batchMean;
+  }
+  
+  /**
+   * A 1D Tensor for the computed batch variance, to be used by
+   * TensorFlow to compute the running variance.
+   */
+  public Output<U> batchVariance() {
+    return batchVariance;
+  }
+  
+  /**
+   * A 1D Tensor for the computed batch mean, to be reused
+   * in the gradient computation.
+   */
+  public Output<U> reserveSpace1() {
+    return reserveSpace1;
+  }
+  
+  /**
+   * A 1D Tensor for the computed batch variance (inverted variance
+   * in the cuDNN case), to be reused in the gradient computation.
+   */
+  public Output<U> reserveSpace2() {
+    return reserveSpace2;
+  }
+  
+  private Output<T> y;
+  private Output<U> batchMean;
+  private Output<U> batchVariance;
+  private Output<U> reserveSpace1;
+  private Output<U> reserveSpace2;
+  
+  private FusedBatchNormV2(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+    batchMean = operation.output(outputIdx++);
+    batchVariance = operation.output(outputIdx++);
+    reserveSpace1 = operation.output(outputIdx++);
+    reserveSpace2 = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/FusedPadConv2D.java java-ops/org/tensorflow/op/core/FusedPadConv2D.java
--- java/org/tensorflow/op/core/FusedPadConv2D.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/FusedPadConv2D.java	2018-10-16 20:18:38.294432337 +0900
@@ -0,0 +1,97 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Performs a padding as a preprocess during a convolution.
+ * <p>
+ * Similar to FusedResizeAndPadConv2d, this op allows for an optimized
+ * implementation where the spatial padding transformation stage is fused with the
+ * im2col lookup, but in this case without the bilinear filtering required for
+ * resizing. Fusing the padding prevents the need to write out the intermediate
+ * results as whole tensors, reducing memory pressure, and we can get some latency
+ * gains by merging the transformation calculations.
+ * The data_format attribute for Conv2D isn't supported by this op, and 'NHWC'
+ * order is used instead.
+ * Internally this op uses a single per-graph scratch buffer, which means that it
+ * will block if multiple versions are being run in parallel. This is because this
+ * operator is primarily an optimization to minimize memory usage.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class FusedPadConv2D<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new FusedPadConv2D operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 4-D with shape `[batch, in_height, in_width, in_channels]`.
+   * @param paddings A two-column matrix specifying the padding sizes. The number of
+   * rows must be the same as the rank of `input`.
+   * @param filter 4-D with shape
+   * `[filter_height, filter_width, in_channels, out_channels]`.
+   * @param mode 
+   * @param strides 1-D of length 4.  The stride of the sliding window for each dimension
+   * of `input`. Must be in the same order as the dimension specified with format.
+   * @param padding The type of padding algorithm to use.
+   * @return a new instance of FusedPadConv2D
+   */
+  public static <T extends Number> FusedPadConv2D<T> create(Scope scope, Operand<T> input, Operand<Integer> paddings, Operand<T> filter, String mode, List<Long> strides, String padding) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("FusedPadConv2D", scope.makeOpName("FusedPadConv2D"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(paddings.asOutput());
+    opBuilder.addInput(filter.asOutput());
+    opBuilder.setAttr("mode", mode);
+    long[] stridesArray = new long[strides.size()];
+    for (int i = 0; i < stridesArray.length; ++i) {
+      stridesArray[i] = strides.get(i);
+    }
+    opBuilder.setAttr("strides", stridesArray);
+    opBuilder.setAttr("padding", padding);
+    return new FusedPadConv2D<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private FusedPadConv2D(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/FusedResizeAndPadConv2D.java java-ops/org/tensorflow/op/core/FusedResizeAndPadConv2D.java
--- java/org/tensorflow/op/core/FusedResizeAndPadConv2D.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/FusedResizeAndPadConv2D.java	2018-10-16 20:18:38.295432336 +0900
@@ -0,0 +1,135 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Performs a resize and padding as a preprocess during a convolution.
+ * <p>
+ * It's often possible to do spatial transformations more efficiently as part of
+ * the packing stage of a convolution, so this op allows for an optimized
+ * implementation where these stages are fused together. This prevents the need to
+ * write out the intermediate results as whole tensors, reducing memory pressure,
+ * and we can get some latency gains by merging the transformation calculations.
+ * The data_format attribute for Conv2D isn't supported by this op, and defaults to
+ * 'NHWC' order.
+ * Internally this op uses a single per-graph scratch buffer, which means that it
+ * will block if multiple versions are being run in parallel. This is because this
+ * operator is primarily an optimization to minimize memory usage.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class FusedResizeAndPadConv2D<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.FusedResizeAndPadConv2D}
+   */
+  public static class Options {
+    
+    /**
+     * @param resizeAlignCorners If true, the centers of the 4 corner pixels of the input and output tensors are
+     * aligned, preserving the values at the corner pixels. Defaults to false.
+     */
+    public Options resizeAlignCorners(Boolean resizeAlignCorners) {
+      this.resizeAlignCorners = resizeAlignCorners;
+      return this;
+    }
+    
+    private Boolean resizeAlignCorners;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new FusedResizeAndPadConv2D operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 4-D with shape `[batch, in_height, in_width, in_channels]`.
+   * @param size A 1-D int32 Tensor of 2 elements: `new_height, new_width`.  The
+   * new size for the images.
+   * @param paddings A two-column matrix specifying the padding sizes. The number of
+   * rows must be the same as the rank of `input`.
+   * @param filter 4-D with shape
+   * `[filter_height, filter_width, in_channels, out_channels]`.
+   * @param mode 
+   * @param strides 1-D of length 4.  The stride of the sliding window for each dimension
+   * of `input`. Must be in the same order as the dimension specified with format.
+   * @param padding The type of padding algorithm to use.
+   * @param options carries optional attributes values
+   * @return a new instance of FusedResizeAndPadConv2D
+   */
+  public static <T extends Number> FusedResizeAndPadConv2D<T> create(Scope scope, Operand<T> input, Operand<Integer> size, Operand<Integer> paddings, Operand<T> filter, String mode, List<Long> strides, String padding, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("FusedResizeAndPadConv2D", scope.makeOpName("FusedResizeAndPadConv2D"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(size.asOutput());
+    opBuilder.addInput(paddings.asOutput());
+    opBuilder.addInput(filter.asOutput());
+    opBuilder.setAttr("mode", mode);
+    long[] stridesArray = new long[strides.size()];
+    for (int i = 0; i < stridesArray.length; ++i) {
+      stridesArray[i] = strides.get(i);
+    }
+    opBuilder.setAttr("strides", stridesArray);
+    opBuilder.setAttr("padding", padding);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.resizeAlignCorners != null) {
+          opBuilder.setAttr("resize_align_corners", opts.resizeAlignCorners);
+        }
+      }
+    }
+    return new FusedResizeAndPadConv2D<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param resizeAlignCorners If true, the centers of the 4 corner pixels of the input and output tensors are
+   * aligned, preserving the values at the corner pixels. Defaults to false.
+   */
+  public static Options resizeAlignCorners(Boolean resizeAlignCorners) {
+    return new Options().resizeAlignCorners(resizeAlignCorners);
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private FusedResizeAndPadConv2D(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Gather.java java-ops/org/tensorflow/op/core/Gather.java
--- java/org/tensorflow/op/core/Gather.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Gather.java	2018-10-16 20:18:38.296432336 +0900
@@ -0,0 +1,127 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Gather slices from `params` according to `indices`.
+ * <p>
+ * `indices` must be an integer tensor of any dimension (usually 0-D or 1-D).
+ * Produces an output tensor with shape `indices.shape + params.shape[1:]` where:
+ * <pre>{@code
+ *     # Scalar indices
+ *     output[:, ..., :] = params[indices, :, ... :]
+ * 
+ *     # Vector indices
+ *     output[i, :, ..., :] = params[indices[i], :, ... :]
+ * 
+ *     # Higher rank indices
+ *     output[i, ..., j, :, ... :] = params[indices[i, ..., j], :, ..., :]
+ * }</pre>
+ * If `indices` is a permutation and `len(indices) == params.shape[0]` then
+ * this operation will permute `params` accordingly.
+ * <p>
+ * `validate_indices`: DEPRECATED. If this operation is assigned to CPU, values in
+ * `indices` are always validated to be within range. If assigned to GPU,
+ * out-of-bound indices result in safe but unspecified behavior, which may include
+ * raising an error.
+ * <p>
+ * <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
+ * <img style="width:100%" src="https://www.tensorflow.org/images/Gather.png" alt>
+ * </div>
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class Gather<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Gather}
+   */
+  public static class Options {
+    
+    /**
+     * @param validateIndices 
+     */
+    public Options validateIndices(Boolean validateIndices) {
+      this.validateIndices = validateIndices;
+      return this;
+    }
+    
+    private Boolean validateIndices;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Gather operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param params 
+   * @param indices 
+   * @param options carries optional attributes values
+   * @return a new instance of Gather
+   */
+  public static <T, U extends Number> Gather<T> create(Scope scope, Operand<T> params, Operand<U> indices, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Gather", scope.makeOpName("Gather"));
+    opBuilder.addInput(params.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.validateIndices != null) {
+          opBuilder.setAttr("validate_indices", opts.validateIndices);
+        }
+      }
+    }
+    return new Gather<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param validateIndices 
+   */
+  public static Options validateIndices(Boolean validateIndices) {
+    return new Options().validateIndices(validateIndices);
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private Gather(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/GatherNd.java java-ops/org/tensorflow/op/core/GatherNd.java
--- java/org/tensorflow/op/core/GatherNd.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/GatherNd.java	2018-10-16 20:18:38.297432335 +0900
@@ -0,0 +1,164 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Gather slices from `params` into a Tensor with shape specified by `indices`.
+ * <p>
+ * `indices` is an K-dimensional integer tensor, best thought of as a
+ * (K-1)-dimensional tensor of indices into `params`, where each element defines a
+ * slice of `params`:
+ * <p>
+ *     output[\\(i_0, ..., i_{K-2}\\)] = params[indices[\\(i_0, ..., i_{K-2}\\)]]
+ * <p>
+ * Whereas in `tf.gather` `indices` defines slices into the first
+ * dimension of `params`, in `tf.gather_nd`, `indices` defines slices into the
+ * first `N` dimensions of `params`, where `N = indices.shape[-1]`.
+ * <p>
+ * The last dimension of `indices` can be at most the rank of
+ * `params`:
+ * <p>
+ *     indices.shape[-1] <= params.rank
+ * <p>
+ * The last dimension of `indices` corresponds to elements
+ * (if `indices.shape[-1] == params.rank`) or slices
+ * (if `indices.shape[-1] < params.rank`) along dimension `indices.shape[-1]`
+ * of `params`.  The output tensor has shape
+ * <p>
+ *     indices.shape[:-1] + params.shape[indices.shape[-1]:]
+ * <p>
+ * Note that on CPU, if an out of bound index is found, an error is returned.
+ * On GPU, if an out of bound index is found, a 0 is stored in the
+ * corresponding output value.
+ * <p>
+ * Some examples below.
+ * <p>
+ * Simple indexing into a matrix:
+ * <pre>{@code
+ *     indices = [[0, 0], [1, 1]]
+ *     params = [['a', 'b'], ['c', 'd']]
+ *     output = ['a', 'd']
+ * }</pre>
+ * Slice indexing into a matrix:
+ * <pre>{@code
+ *     indices = [[1], [0]]
+ *     params = [['a', 'b'], ['c', 'd']]
+ *     output = [['c', 'd'], ['a', 'b']]
+ * }</pre>
+ * Indexing into a 3-tensor:
+ * <pre>{@code
+ *     indices = [[1]]
+ *     params = [[['a0', 'b0'], ['c0', 'd0']],
+ *               [['a1', 'b1'], ['c1', 'd1']]]
+ *     output = [[['a1', 'b1'], ['c1', 'd1']]]
+ * 
+ * 
+ *     indices = [[0, 1], [1, 0]]
+ *     params = [[['a0', 'b0'], ['c0', 'd0']],
+ *               [['a1', 'b1'], ['c1', 'd1']]]
+ *     output = [['c0', 'd0'], ['a1', 'b1']]
+ * 
+ * 
+ *     indices = [[0, 0, 1], [1, 0, 1]]
+ *     params = [[['a0', 'b0'], ['c0', 'd0']],
+ *               [['a1', 'b1'], ['c1', 'd1']]]
+ *     output = ['b0', 'b1']
+ * }</pre>
+ * Batched indexing into a matrix:
+ * <pre>{@code
+ *     indices = [[[0, 0]], [[0, 1]]]
+ *     params = [['a', 'b'], ['c', 'd']]
+ *     output = [['a'], ['b']]
+ * }</pre>
+ * Batched slice indexing into a matrix:
+ * <pre>{@code
+ *     indices = [[[1]], [[0]]]
+ *     params = [['a', 'b'], ['c', 'd']]
+ *     output = [[['c', 'd']], [['a', 'b']]]
+ * }</pre>
+ * Batched indexing into a 3-tensor:
+ * <pre>{@code
+ *     indices = [[[1]], [[0]]]
+ *     params = [[['a0', 'b0'], ['c0', 'd0']],
+ *               [['a1', 'b1'], ['c1', 'd1']]]
+ *     output = [[[['a1', 'b1'], ['c1', 'd1']]],
+ *               [[['a0', 'b0'], ['c0', 'd0']]]]
+ * 
+ *     indices = [[[0, 1], [1, 0]], [[0, 0], [1, 1]]]
+ *     params = [[['a0', 'b0'], ['c0', 'd0']],
+ *               [['a1', 'b1'], ['c1', 'd1']]]
+ *     output = [[['c0', 'd0'], ['a1', 'b1']],
+ *               [['a0', 'b0'], ['c1', 'd1']]]
+ * 
+ * 
+ *     indices = [[[0, 0, 1], [1, 0, 1]], [[0, 1, 1], [1, 1, 0]]]
+ *     params = [[['a0', 'b0'], ['c0', 'd0']],
+ *               [['a1', 'b1'], ['c1', 'd1']]]
+ *     output = [['b0', 'b1'], ['d0', 'c1']]
+ * }</pre>
+ * See also `tf.gather` and `tf.batch_gather`.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class GatherNd<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new GatherNd operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param params The tensor from which to gather values.
+   * @param indices Index tensor.
+   * @return a new instance of GatherNd
+   */
+  public static <T, U extends Number> GatherNd<T> create(Scope scope, Operand<T> params, Operand<U> indices) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("GatherNd", scope.makeOpName("GatherNd"));
+    opBuilder.addInput(params.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    return new GatherNd<T>(opBuilder.build());
+  }
+  
+  /**
+   * Values from `params` gathered from indices given by `indices`, with
+   * shape `indices.shape[:-1] + params.shape[indices.shape[-1]:]`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private GatherNd(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/GatherV2.java java-ops/org/tensorflow/op/core/GatherV2.java
--- java/org/tensorflow/op/core/GatherV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/GatherV2.java	2018-10-16 20:18:38.297432335 +0900
@@ -0,0 +1,101 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Gather slices from `params` axis `axis` according to `indices`.
+ * <p>
+ * `indices` must be an integer tensor of any dimension (usually 0-D or 1-D).
+ * Produces an output tensor with shape `params.shape[:axis] + indices.shape +
+ * params.shape[axis + 1:]` where:
+ * <pre>{@code
+ *     # Scalar indices (output is rank(params) - 1).
+ *     output[a_0, ..., a_n, b_0, ..., b_n] =
+ *       params[a_0, ..., a_n, indices, b_0, ..., b_n]
+ * 
+ *     # Vector indices (output is rank(params)).
+ *     output[a_0, ..., a_n, i, b_0, ..., b_n] =
+ *       params[a_0, ..., a_n, indices[i], b_0, ..., b_n]
+ * 
+ *     # Higher rank indices (output is rank(params) + rank(indices) - 1).
+ *     output[a_0, ..., a_n, i, ..., j, b_0, ... b_n] =
+ *       params[a_0, ..., a_n, indices[i, ..., j], b_0, ..., b_n]
+ * }</pre>
+ * <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
+ * <img style="width:100%" src="https://www.tensorflow.org/images/Gather.png" alt>
+ * </div>
+ * <p>
+ * Note that on CPU, if an out of bound index is found, an error is returned.
+ * On GPU, if an out of bound index is found, a 0 is stored in the
+ * corresponding output value.
+ * <p>
+ * See also `tf.batch_gather` and `tf.gather_nd`.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class GatherV2<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new GatherV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param params The tensor from which to gather values. Must be at least rank
+   * `axis + 1`.
+   * @param indices Index tensor. Must be in range `[0, params.shape[axis])`.
+   * @param axis The axis in `params` to gather `indices` from. Defaults to the first
+   * dimension. Supports negative indexes.
+   * @return a new instance of GatherV2
+   */
+  public static <T, U extends Number, V extends Number> GatherV2<T> create(Scope scope, Operand<T> params, Operand<U> indices, Operand<V> axis) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("GatherV2", scope.makeOpName("GatherV2"));
+    opBuilder.addInput(params.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(axis.asOutput());
+    return new GatherV2<T>(opBuilder.build());
+  }
+  
+  /**
+   * Values from `params` gathered from indices given by `indices`, with
+   * shape `params.shape[:axis] + indices.shape + params.shape[axis + 1:]`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private GatherV2(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/GcsConfigureBlockCache.java java-ops/org/tensorflow/op/core/GcsConfigureBlockCache.java
--- java/org/tensorflow/op/core/GcsConfigureBlockCache.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/GcsConfigureBlockCache.java	2018-10-16 20:18:38.298432335 +0900
@@ -0,0 +1,58 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Re-configures the GCS block cache with the new configuration values.
+ * <p>
+ * If the values are the same as already configured values, this op is a no-op. If
+ * they are different, the current contents of the block cache is dropped, and a
+ * new block cache is created fresh.
+ */
+@Operator
+public final class GcsConfigureBlockCache extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new GcsConfigureBlockCache operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param maxCacheSize 
+   * @param blockSize 
+   * @param maxStaleness 
+   * @return a new instance of GcsConfigureBlockCache
+   */
+  public static GcsConfigureBlockCache create(Scope scope, Operand<?> maxCacheSize, Operand<?> blockSize, Operand<?> maxStaleness) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("GcsConfigureBlockCache", scope.makeOpName("GcsConfigureBlockCache"));
+    opBuilder.addInput(maxCacheSize.asOutput());
+    opBuilder.addInput(blockSize.asOutput());
+    opBuilder.addInput(maxStaleness.asOutput());
+    return new GcsConfigureBlockCache(opBuilder.build());
+  }
+  
+  
+  private GcsConfigureBlockCache(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/GcsConfigureCredentials.java java-ops/org/tensorflow/op/core/GcsConfigureCredentials.java
--- java/org/tensorflow/op/core/GcsConfigureCredentials.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/GcsConfigureCredentials.java	2018-10-16 20:18:38.298432335 +0900
@@ -0,0 +1,78 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Configures the credentials used by the GCS client of the local TF runtime.
+ * <p>
+ * The json input can be of the format:
+ * <p>
+ * 1. Refresh Token:
+ * {
+ *   "client_id": "<redacted>",
+ *   "client_secret": "<redacted>",
+ *   "refresh_token: "<redacted>",
+ *   "type": "authorized_user",
+ * }
+ * <p>
+ * 2. Service Account:
+ * {
+ *   "type": "service_account",
+ *   "project_id": "<redacted>",
+ *   "private_key_id": "<redacted>",
+ *   "private_key": "------BEGIN PRIVATE KEY-----\n<REDACTED>\n-----END PRIVATE KEY------\n",
+ *   "client_email": "<REDACTED>@<REDACTED>.iam.gserviceaccount.com",
+ *   "client_id": "<REDACTED>",
+ *   # Some additional fields elided
+ * }
+ * <p>
+ * Note the credentials established through this method are shared across all
+ * sessions run on this runtime.
+ * <p>
+ * Note be sure to feed the inputs to this op to ensure the credentials are not
+ * stored in a constant op within the graph that might accidentally be checkpointed
+ * or in other ways be persisted or exfiltrated.
+ */
+@Operator
+public final class GcsConfigureCredentials extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new GcsConfigureCredentials operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param json 
+   * @return a new instance of GcsConfigureCredentials
+   */
+  public static GcsConfigureCredentials create(Scope scope, Operand<String> json) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("GcsConfigureCredentials", scope.makeOpName("GcsConfigureCredentials"));
+    opBuilder.addInput(json.asOutput());
+    return new GcsConfigureCredentials(opBuilder.build());
+  }
+  
+  
+  private GcsConfigureCredentials(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/GenerateBigQueryReaderPartitions.java java-ops/org/tensorflow/op/core/GenerateBigQueryReaderPartitions.java
--- java/org/tensorflow/op/core/GenerateBigQueryReaderPartitions.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/GenerateBigQueryReaderPartitions.java	2018-10-16 20:18:38.298432335 +0900
@@ -0,0 +1,120 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Generates serialized partition messages suitable for batch reads.
+ * <p>
+ * This op should not be used directly by clients. Instead, the
+ * bigquery_reader_ops.py file defines a clean interface to the reader.
+ */
+@Operator
+public final class GenerateBigQueryReaderPartitions extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.GenerateBigQueryReaderPartitions}
+   */
+  public static class Options {
+    
+    /**
+     * @param testEndPoint Do not use. For testing purposes only.
+     */
+    public Options testEndPoint(String testEndPoint) {
+      this.testEndPoint = testEndPoint;
+      return this;
+    }
+    
+    private String testEndPoint;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new GenerateBigQueryReaderPartitions operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param projectId GCP project ID.
+   * @param datasetId BigQuery Dataset ID.
+   * @param tableId Table to read.
+   * @param columns List of columns to read. Leave empty to read all columns.
+   * @param timestampMillis Table snapshot timestamp in millis since epoch. Relative
+   * (negative or zero) snapshot times are not allowed. For more details, see
+   * 'Table Decorators' in BigQuery docs.
+   * @param numPartitions Number of partitions to split the table into.
+   * @param options carries optional attributes values
+   * @return a new instance of GenerateBigQueryReaderPartitions
+   */
+  public static GenerateBigQueryReaderPartitions create(Scope scope, String projectId, String datasetId, String tableId, List<String> columns, Long timestampMillis, Long numPartitions, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("GenerateBigQueryReaderPartitions", scope.makeOpName("GenerateBigQueryReaderPartitions"));
+    opBuilder.setAttr("project_id", projectId);
+    opBuilder.setAttr("dataset_id", datasetId);
+    opBuilder.setAttr("table_id", tableId);
+    String[] columnsArray = new String[columns.size()];
+    for (int i = 0; i < columnsArray.length; ++i) {
+      columnsArray[i] = columns.get(i);
+    }
+    opBuilder.setAttr("columns", columnsArray);
+    opBuilder.setAttr("timestamp_millis", timestampMillis);
+    opBuilder.setAttr("num_partitions", numPartitions);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.testEndPoint != null) {
+          opBuilder.setAttr("test_end_point", opts.testEndPoint);
+        }
+      }
+    }
+    return new GenerateBigQueryReaderPartitions(opBuilder.build());
+  }
+  
+  /**
+   * @param testEndPoint Do not use. For testing purposes only.
+   */
+  public static Options testEndPoint(String testEndPoint) {
+    return new Options().testEndPoint(testEndPoint);
+  }
+  
+  /**
+   * Serialized table partitions.
+   */
+  public Output<String> partitions() {
+    return partitions;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return partitions;
+  }
+  
+  private Output<String> partitions;
+  
+  private GenerateBigQueryReaderPartitions(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    partitions = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/GenerateVocabRemapping.java java-ops/org/tensorflow/op/core/GenerateVocabRemapping.java
--- java/org/tensorflow/op/core/GenerateVocabRemapping.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/GenerateVocabRemapping.java	2018-10-16 20:18:38.299432334 +0900
@@ -0,0 +1,143 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Given a path to new and old vocabulary files, returns a remapping Tensor of
+ * <p>
+ * length `num_new_vocab`, where `remapping[i]` contains the row number in the old
+ * vocabulary that corresponds to row `i` in the new vocabulary (starting at line
+ * `new_vocab_offset` and up to `num_new_vocab` entities), or `-1` if entry `i`
+ * in the new vocabulary is not in the old vocabulary.  The old vocabulary is
+ * constrained to the first `old_vocab_size` entries if `old_vocab_size` is not the
+ * default value of -1.
+ * <p>
+ * `num_vocab_offset` enables
+ * use in the partitioned variable case, and should generally be set through
+ * examining partitioning info.  The format of the files should be a text file,
+ * with each line containing a single entity within the vocabulary.
+ * <p>
+ * For example, with `new_vocab_file` a text file containing each of the following
+ * elements on a single line: `[f0, f1, f2, f3]`, old_vocab_file = [f1, f0, f3],
+ * `num_new_vocab = 3, new_vocab_offset = 1`, the returned remapping would be
+ * `[0, -1, 2]`.
+ * <p>
+ * The op also returns a count of how many entries in the new vocabulary
+ * were present in the old vocabulary, which is used to calculate the number of
+ * values to initialize in a weight matrix remapping
+ * <p>
+ * This functionality can be used to remap both row vocabularies (typically,
+ * features) and column vocabularies (typically, classes) from TensorFlow
+ * checkpoints.  Note that the partitioning logic relies on contiguous vocabularies
+ * corresponding to div-partitioned variables.  Moreover, the underlying remapping
+ * uses an IndexTable (as opposed to an inexact CuckooTable), so client code should
+ * use the corresponding index_table_from_file() as the FeatureColumn framework
+ * does (as opposed to tf.feature_to_id(), which uses a CuckooTable).
+ */
+@Operator
+public final class GenerateVocabRemapping extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.GenerateVocabRemapping}
+   */
+  public static class Options {
+    
+    /**
+     * @param oldVocabSize Number of entries in the old vocab file to consider.  If -1,
+     * use the entire old vocabulary.
+     */
+    public Options oldVocabSize(Long oldVocabSize) {
+      this.oldVocabSize = oldVocabSize;
+      return this;
+    }
+    
+    private Long oldVocabSize;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new GenerateVocabRemapping operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param newVocabFile Path to the new vocab file.
+   * @param oldVocabFile Path to the old vocab file.
+   * @param newVocabOffset How many entries into the new vocab file to start reading.
+   * @param numNewVocab Number of entries in the new vocab file to remap.
+   * @param options carries optional attributes values
+   * @return a new instance of GenerateVocabRemapping
+   */
+  public static GenerateVocabRemapping create(Scope scope, Operand<String> newVocabFile, Operand<String> oldVocabFile, Long newVocabOffset, Long numNewVocab, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("GenerateVocabRemapping", scope.makeOpName("GenerateVocabRemapping"));
+    opBuilder.addInput(newVocabFile.asOutput());
+    opBuilder.addInput(oldVocabFile.asOutput());
+    opBuilder.setAttr("new_vocab_offset", newVocabOffset);
+    opBuilder.setAttr("num_new_vocab", numNewVocab);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.oldVocabSize != null) {
+          opBuilder.setAttr("old_vocab_size", opts.oldVocabSize);
+        }
+      }
+    }
+    return new GenerateVocabRemapping(opBuilder.build());
+  }
+  
+  /**
+   * @param oldVocabSize Number of entries in the old vocab file to consider.  If -1,
+   * use the entire old vocabulary.
+   */
+  public static Options oldVocabSize(Long oldVocabSize) {
+    return new Options().oldVocabSize(oldVocabSize);
+  }
+  
+  /**
+   * A Tensor of length num_new_vocab where the element at index i
+   * is equal to the old ID that maps to the new ID i.  This element is -1 for any
+   * new ID that is not found in the old vocabulary.
+   */
+  public Output<Long> remapping() {
+    return remapping;
+  }
+  
+  /**
+   * Number of new vocab entries found in old vocab.
+   */
+  public Output<Integer> numPresent() {
+    return numPresent;
+  }
+  
+  private Output<Long> remapping;
+  private Output<Integer> numPresent;
+  
+  private GenerateVocabRemapping(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    remapping = operation.output(outputIdx++);
+    numPresent = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/GetSessionHandle.java java-ops/org/tensorflow/op/core/GetSessionHandle.java
--- java/org/tensorflow/op/core/GetSessionHandle.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/GetSessionHandle.java	2018-10-16 20:18:38.299432334 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Store the input tensor in the state of the current session.
+ */
+@Operator
+public final class GetSessionHandle extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Factory method to create a class to wrap a new GetSessionHandle operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param value The tensor to be stored.
+   * @return a new instance of GetSessionHandle
+   */
+  public static <T> GetSessionHandle create(Scope scope, Operand<T> value) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("GetSessionHandle", scope.makeOpName("GetSessionHandle"));
+    opBuilder.addInput(value.asOutput());
+    return new GetSessionHandle(opBuilder.build());
+  }
+  
+  /**
+   * The handle for the tensor stored in the session state, represented
+   * as a string.
+   */
+  public Output<String> handle() {
+    return handle;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return handle;
+  }
+  
+  private Output<String> handle;
+  
+  private GetSessionHandle(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/GetSessionHandleV2.java java-ops/org/tensorflow/op/core/GetSessionHandleV2.java
--- java/org/tensorflow/op/core/GetSessionHandleV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/GetSessionHandleV2.java	2018-10-16 20:18:38.299432334 +0900
@@ -0,0 +1,68 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Store the input tensor in the state of the current session.
+ */
+@Operator
+public final class GetSessionHandleV2 extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new GetSessionHandleV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param value The tensor to be stored.
+   * @return a new instance of GetSessionHandleV2
+   */
+  public static <T> GetSessionHandleV2 create(Scope scope, Operand<T> value) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("GetSessionHandleV2", scope.makeOpName("GetSessionHandleV2"));
+    opBuilder.addInput(value.asOutput());
+    return new GetSessionHandleV2(opBuilder.build());
+  }
+  
+  /**
+   * The handle for the tensor stored in the session state, represented
+   * as a ResourceHandle object.
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private GetSessionHandleV2(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/GetSessionTensor.java java-ops/org/tensorflow/op/core/GetSessionTensor.java
--- java/org/tensorflow/op/core/GetSessionTensor.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/GetSessionTensor.java	2018-10-16 20:18:38.300432333 +0900
@@ -0,0 +1,71 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Get the value of the tensor specified by its handle.
+ * 
+ * @param <T> data type for {@code value()} output
+ */
+@Operator
+public final class GetSessionTensor<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new GetSessionTensor operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param handle The handle for a tensor stored in the session state.
+   * @param dtype The type of the output value.
+   * @return a new instance of GetSessionTensor
+   */
+  public static <T> GetSessionTensor<T> create(Scope scope, Operand<String> handle, Class<T> dtype) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("GetSessionTensor", scope.makeOpName("GetSessionTensor"));
+    opBuilder.addInput(handle.asOutput());
+    opBuilder.setAttr("dtype", DataType.fromClass(dtype));
+    return new GetSessionTensor<T>(opBuilder.build());
+  }
+  
+  /**
+   * The tensor for the given handle.
+   */
+  public Output<T> value() {
+    return value;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return value;
+  }
+  
+  private Output<T> value;
+  
+  private GetSessionTensor(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    value = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/GreaterEqual.java java-ops/org/tensorflow/op/core/GreaterEqual.java
--- java/org/tensorflow/op/core/GreaterEqual.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/GreaterEqual.java	2018-10-16 20:18:38.300432333 +0900
@@ -0,0 +1,70 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns the truth value of (x >= y) element-wise.
+ * <p>
+ * <i>NOTE</i>: `GreaterEqual` supports broadcasting. More about broadcasting
+ * [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
+ */
+@Operator
+public final class GreaterEqual extends PrimitiveOp implements Operand<Boolean> {
+  
+  /**
+   * Factory method to create a class to wrap a new GreaterEqual operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param y 
+   * @return a new instance of GreaterEqual
+   */
+  public static <T extends Number> GreaterEqual create(Scope scope, Operand<T> x, Operand<T> y) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("GreaterEqual", scope.makeOpName("GreaterEqual"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(y.asOutput());
+    return new GreaterEqual(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<Boolean> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<Boolean> asOutput() {
+    return z;
+  }
+  
+  private Output<Boolean> z;
+  
+  private GreaterEqual(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Greater.java java-ops/org/tensorflow/op/core/Greater.java
--- java/org/tensorflow/op/core/Greater.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Greater.java	2018-10-16 20:18:38.300432333 +0900
@@ -0,0 +1,70 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns the truth value of (x > y) element-wise.
+ * <p>
+ * <i>NOTE</i>: `Greater` supports broadcasting. More about broadcasting
+ * [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
+ */
+@Operator
+public final class Greater extends PrimitiveOp implements Operand<Boolean> {
+  
+  /**
+   * Factory method to create a class to wrap a new Greater operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param y 
+   * @return a new instance of Greater
+   */
+  public static <T extends Number> Greater create(Scope scope, Operand<T> x, Operand<T> y) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Greater", scope.makeOpName("Greater"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(y.asOutput());
+    return new Greater(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<Boolean> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<Boolean> asOutput() {
+    return z;
+  }
+  
+  private Output<Boolean> z;
+  
+  private Greater(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/GuaranteeConst.java java-ops/org/tensorflow/op/core/GuaranteeConst.java
--- java/org/tensorflow/op/core/GuaranteeConst.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/GuaranteeConst.java	2018-10-16 20:18:38.301432332 +0900
@@ -0,0 +1,74 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Gives a guarantee to the TF runtime that the input tensor is a constant.
+ * <p>
+ * The runtime is then free to make optimizations based on this.
+ * <p>
+ * Only accepts value typed tensors as inputs and rejects resource variable handles
+ * as input.
+ * <p>
+ * Returns the input tensor without modification.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class GuaranteeConst<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new GuaranteeConst operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @return a new instance of GuaranteeConst
+   */
+  public static <T> GuaranteeConst<T> create(Scope scope, Operand<T> input) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("GuaranteeConst", scope.makeOpName("GuaranteeConst"));
+    opBuilder.addInput(input.asOutput());
+    return new GuaranteeConst<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private GuaranteeConst(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/HashTable.java java-ops/org/tensorflow/op/core/HashTable.java
--- java/org/tensorflow/op/core/HashTable.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/HashTable.java	2018-10-16 20:18:38.301432332 +0900
@@ -0,0 +1,152 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Creates a non-initialized hash table.
+ * <p>
+ * This op creates a hash table, specifying the type of its keys and values.
+ * Before using the table you will have to initialize it.  After initialization the
+ * table will be immutable.
+ */
+@Operator
+public final class HashTable extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.HashTable}
+   */
+  public static class Options {
+    
+    /**
+     * @param container If non-empty, this table is placed in the given container.
+     * Otherwise, a default container is used.
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName If non-empty, this table is shared under the given name across
+     * multiple sessions.
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    /**
+     * @param useNodeNameSharing If true and shared_name is empty, the table is shared
+     * using the node name.
+     */
+    public Options useNodeNameSharing(Boolean useNodeNameSharing) {
+      this.useNodeNameSharing = useNodeNameSharing;
+      return this;
+    }
+    
+    private String container;
+    private String sharedName;
+    private Boolean useNodeNameSharing;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new HashTable operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param keyDtype Type of the table keys.
+   * @param valueDtype Type of the table values.
+   * @param options carries optional attributes values
+   * @return a new instance of HashTable
+   */
+  public static <T, U> HashTable create(Scope scope, Class<T> keyDtype, Class<U> valueDtype, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("HashTableV2", scope.makeOpName("HashTable"));
+    opBuilder.setAttr("key_dtype", DataType.fromClass(keyDtype));
+    opBuilder.setAttr("value_dtype", DataType.fromClass(valueDtype));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+        if (opts.useNodeNameSharing != null) {
+          opBuilder.setAttr("use_node_name_sharing", opts.useNodeNameSharing);
+        }
+      }
+    }
+    return new HashTable(opBuilder.build());
+  }
+  
+  /**
+   * @param container If non-empty, this table is placed in the given container.
+   * Otherwise, a default container is used.
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName If non-empty, this table is shared under the given name across
+   * multiple sessions.
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   * @param useNodeNameSharing If true and shared_name is empty, the table is shared
+   * using the node name.
+   */
+  public static Options useNodeNameSharing(Boolean useNodeNameSharing) {
+    return new Options().useNodeNameSharing(useNodeNameSharing);
+  }
+  
+  /**
+   * Handle to a table.
+   */
+  public Output<?> tableHandle() {
+    return tableHandle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) tableHandle;
+  }
+  
+  private Output<?> tableHandle;
+  
+  private HashTable(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    tableHandle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/HistogramFixedWidth.java java-ops/org/tensorflow/op/core/HistogramFixedWidth.java
--- java/org/tensorflow/op/core/HistogramFixedWidth.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/HistogramFixedWidth.java	2018-10-16 20:18:38.302432332 +0900
@@ -0,0 +1,108 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Return histogram of values.
+ * <p>
+ * Given the tensor `values`, this operation returns a rank 1 histogram counting
+ * the number of entries in `values` that fall into every bin.  The bins are
+ * equal width and determined by the arguments `value_range` and `nbins`.
+ * <pre>{@code
+ * # Bins will be:  (-inf, 1), [1, 2), [2, 3), [3, 4), [4, inf)
+ * nbins = 5
+ * value_range = [0.0, 5.0]
+ * new_values = [-1.0, 0.0, 1.5, 2.0, 5.0, 15]
+ * 
+ * with tf.get_default_session() as sess:
+ *   hist = tf.histogram_fixed_width(new_values, value_range, nbins=5)
+ *   variables.global_variables_initializer().run()
+ *   sess.run(hist) => [2, 1, 1, 0, 2]
+ * }</pre>
+ * 
+ * 
+ * @param <U> data type for {@code out()} output
+ */
+@Operator
+public final class HistogramFixedWidth<U extends Number> extends PrimitiveOp implements Operand<U> {
+  
+  /**
+   * Factory method to create a class to wrap a new HistogramFixedWidth operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param values Numeric `Tensor`.
+   * @param valueRange Shape [2] `Tensor` of same `dtype` as `values`.
+   * values <= value_range[0] will be mapped to hist[0],
+   * values >= value_range[1] will be mapped to hist[-1].
+   * @param nbins Scalar `int32 Tensor`.  Number of histogram bins.
+   * @param dtype 
+   * @return a new instance of HistogramFixedWidth
+   */
+  public static <U extends Number, T extends Number> HistogramFixedWidth<U> create(Scope scope, Operand<T> values, Operand<T> valueRange, Operand<Integer> nbins, Class<U> dtype) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("HistogramFixedWidth", scope.makeOpName("HistogramFixedWidth"));
+    opBuilder.addInput(values.asOutput());
+    opBuilder.addInput(valueRange.asOutput());
+    opBuilder.addInput(nbins.asOutput());
+    opBuilder.setAttr("dtype", DataType.fromClass(dtype));
+    return new HistogramFixedWidth<U>(opBuilder.build());
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new HistogramFixedWidth operation to the graph, using default output types.
+   * 
+   * @param scope current graph scope
+   * @param values Numeric `Tensor`.
+   * @param valueRange Shape [2] `Tensor` of same `dtype` as `values`.
+   * values <= value_range[0] will be mapped to hist[0],
+   * values >= value_range[1] will be mapped to hist[-1].
+   * @param nbins Scalar `int32 Tensor`.  Number of histogram bins.
+   * @return a new instance of HistogramFixedWidth
+   */
+  public static <T extends Number> HistogramFixedWidth<Integer> create(Scope scope, Operand<T> values, Operand<T> valueRange, Operand<Integer> nbins) {
+    return create(scope, values, valueRange, nbins, Integer.class);
+  }
+  
+  /**
+   * A 1-D `Tensor` holding histogram of values.
+   */
+  public Output<U> out() {
+    return out;
+  }
+  
+  @Override
+  public Output<U> asOutput() {
+    return out;
+  }
+  
+  private Output<U> out;
+  
+  private HistogramFixedWidth(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    out = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/HistogramSummary.java java-ops/org/tensorflow/op/core/HistogramSummary.java
--- java/org/tensorflow/op/core/HistogramSummary.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/HistogramSummary.java	2018-10-16 20:18:38.303432331 +0900
@@ -0,0 +1,74 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Outputs a `Summary` protocol buffer with a histogram.
+ * <p>
+ * The generated
+ * [`Summary`](https://www.tensorflow.org/code/tensorflow/core/framework/summary.proto)
+ * has one summary value containing a histogram for `values`.
+ * <p>
+ * This op reports an `InvalidArgument` error if any value is not finite.
+ */
+@Operator
+public final class HistogramSummary extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Factory method to create a class to wrap a new HistogramSummary operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param tag Scalar.  Tag to use for the `Summary.Value`.
+   * @param values Any shape. Values to use to build the histogram.
+   * @return a new instance of HistogramSummary
+   */
+  public static <T extends Number> HistogramSummary create(Scope scope, Operand<String> tag, Operand<T> values) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("HistogramSummary", scope.makeOpName("HistogramSummary"));
+    opBuilder.addInput(tag.asOutput());
+    opBuilder.addInput(values.asOutput());
+    return new HistogramSummary(opBuilder.build());
+  }
+  
+  /**
+   * Scalar. Serialized `Summary` protocol buffer.
+   */
+  public Output<String> summary() {
+    return summary;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return summary;
+  }
+  
+  private Output<String> summary;
+  
+  private HistogramSummary(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    summary = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/HSVToRGB.java java-ops/org/tensorflow/op/core/HSVToRGB.java
--- java/org/tensorflow/op/core/HSVToRGB.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/HSVToRGB.java	2018-10-16 20:18:38.301432332 +0900
@@ -0,0 +1,74 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Convert one or more images from HSV to RGB.
+ * <p>
+ * Outputs a tensor of the same shape as the `images` tensor, containing the RGB
+ * value of the pixels. The output is only well defined if the value in `images`
+ * are in `[0,1]`.
+ * <p>
+ * See `rgb_to_hsv` for a description of the HSV encoding.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class HSVToRGB<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new HSVToRGB operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param images 1-D or higher rank. HSV data to convert. Last dimension must be size 3.
+   * @return a new instance of HSVToRGB
+   */
+  public static <T extends Number> HSVToRGB<T> create(Scope scope, Operand<T> images) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("HSVToRGB", scope.makeOpName("HSVToRGB"));
+    opBuilder.addInput(images.asOutput());
+    return new HSVToRGB<T>(opBuilder.build());
+  }
+  
+  /**
+   * `images` converted to RGB.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private HSVToRGB(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Identity.java java-ops/org/tensorflow/op/core/Identity.java
--- java/org/tensorflow/op/core/Identity.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Identity.java	2018-10-16 20:18:38.306432329 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Return a tensor with the same shape and contents as the input tensor or value.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class Identity<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Identity operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @return a new instance of Identity
+   */
+  public static <T> Identity<T> create(Scope scope, Operand<T> input) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Identity", scope.makeOpName("Identity"));
+    opBuilder.addInput(input.asOutput());
+    return new Identity<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private Identity(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/IdentityN.java java-ops/org/tensorflow/op/core/IdentityN.java
--- java/org/tensorflow/op/core/IdentityN.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/IdentityN.java	2018-10-16 20:18:38.307432328 +0900
@@ -0,0 +1,88 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.Iterator;
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns a list of tensors with the same shapes and contents as the input
+ * <p>
+ * tensors.
+ * <p>
+ * This op can be used to override the gradient for complicated functions. For
+ * example, suppose y = f(x) and we wish to apply a custom function g for backprop
+ * such that dx = g(dy). In Python,
+ * <pre>{@code
+ * with tf.get_default_graph().gradient_override_map(
+ *     {'IdentityN': 'OverrideGradientWithG'}):
+ *   y, _ = identity_n([f(x), x])
+ * 
+ * @tf.RegisterGradient('OverrideGradientWithG')
+ * def ApplyG(op, dy, _):
+ *   return [None, g(dy)]  # Do not backprop to f(x).
+ * }</pre>
+ * 
+ */
+@Operator
+public final class IdentityN extends PrimitiveOp implements Iterable<Operand<Object>> {
+  
+  /**
+   * Factory method to create a class to wrap a new IdentityN operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @return a new instance of IdentityN
+   */
+  public static IdentityN create(Scope scope, Iterable<Operand<?>> input) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("IdentityN", scope.makeOpName("IdentityN"));
+    opBuilder.addInputList(Operands.asOutputs(input));
+    return new IdentityN(opBuilder.build());
+  }
+  
+  /**
+   */
+  public List<Output<?>> output() {
+    return output;
+  }
+  
+  @Override
+  @SuppressWarnings({"rawtypes", "unchecked"})
+  public Iterator<Operand<Object>> iterator() {
+    return (Iterator) output.iterator();
+  }
+  
+  private List<Output<?>> output;
+  
+  private IdentityN(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    int outputLength = operation.outputListLength("output");
+    output = Arrays.asList(operation.outputList(outputIdx, outputLength));
+    outputIdx += outputLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/IdentityReader.java java-ops/org/tensorflow/op/core/IdentityReader.java
--- java/org/tensorflow/op/core/IdentityReader.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/IdentityReader.java	2018-10-16 20:18:38.307432328 +0900
@@ -0,0 +1,125 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * A Reader that outputs the queued work as both the key and value.
+ * <p>
+ * To use, enqueue strings in a Queue.  ReaderRead will take the front
+ * work string and output (work, work).
+ */
+@Operator
+public final class IdentityReader extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.IdentityReader}
+   */
+  public static class Options {
+    
+    /**
+     * @param container If non-empty, this reader is placed in the given container.
+     * Otherwise, a default container is used.
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName If non-empty, this reader is named in the given bucket
+     * with this shared_name. Otherwise, the node name is used instead.
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new IdentityReader operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param options carries optional attributes values
+   * @return a new instance of IdentityReader
+   */
+  public static IdentityReader create(Scope scope, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("IdentityReaderV2", scope.makeOpName("IdentityReader"));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new IdentityReader(opBuilder.build());
+  }
+  
+  /**
+   * @param container If non-empty, this reader is placed in the given container.
+   * Otherwise, a default container is used.
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName If non-empty, this reader is named in the given bucket
+   * with this shared_name. Otherwise, the node name is used instead.
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   * The handle to reference the Reader.
+   */
+  public Output<?> readerHandle() {
+    return readerHandle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) readerHandle;
+  }
+  
+  private Output<?> readerHandle;
+  
+  private IdentityReader(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    readerHandle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/IFFT2D.java java-ops/org/tensorflow/op/core/IFFT2D.java
--- java/org/tensorflow/op/core/IFFT2D.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/IFFT2D.java	2018-10-16 20:18:38.303432331 +0900
@@ -0,0 +1,76 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Inverse 2D fast Fourier transform.
+ * <p>
+ * Computes the inverse 2-dimensional discrete Fourier transform over the
+ * inner-most 2 dimensions of `input`.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class IFFT2D<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new IFFT2D operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input A complex64 tensor.
+   * @return a new instance of IFFT2D
+   */
+  public static <T> IFFT2D<T> create(Scope scope, Operand<T> input) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("IFFT2D", scope.makeOpName("IFFT2D"));
+    opBuilder.addInput(input.asOutput());
+    return new IFFT2D<T>(opBuilder.build());
+  }
+  
+  /**
+   * A complex64 tensor of the same shape as `input`. The inner-most 2
+   *   dimensions of `input` are replaced with their inverse 2D Fourier transform.
+   * <p>
+   * @compatibility(numpy)
+   * Equivalent to np.fft.ifft2
+   * @end_compatibility
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private IFFT2D(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/IFFT3D.java java-ops/org/tensorflow/op/core/IFFT3D.java
--- java/org/tensorflow/op/core/IFFT3D.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/IFFT3D.java	2018-10-16 20:18:38.304432330 +0900
@@ -0,0 +1,76 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Inverse 3D fast Fourier transform.
+ * <p>
+ * Computes the inverse 3-dimensional discrete Fourier transform over the
+ * inner-most 3 dimensions of `input`.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class IFFT3D<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new IFFT3D operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input A complex64 tensor.
+   * @return a new instance of IFFT3D
+   */
+  public static <T> IFFT3D<T> create(Scope scope, Operand<T> input) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("IFFT3D", scope.makeOpName("IFFT3D"));
+    opBuilder.addInput(input.asOutput());
+    return new IFFT3D<T>(opBuilder.build());
+  }
+  
+  /**
+   * A complex64 tensor of the same shape as `input`. The inner-most 3
+   *   dimensions of `input` are replaced with their inverse 3D Fourier transform.
+   * <p>
+   * @compatibility(numpy)
+   * Equivalent to np.fft.ifftn with 3 dimensions.
+   * @end_compatibility
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private IFFT3D(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/IFFT.java java-ops/org/tensorflow/op/core/IFFT.java
--- java/org/tensorflow/op/core/IFFT.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/IFFT.java	2018-10-16 20:18:38.303432331 +0900
@@ -0,0 +1,76 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Inverse fast Fourier transform.
+ * <p>
+ * Computes the inverse 1-dimensional discrete Fourier transform over the
+ * inner-most dimension of `input`.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class IFFT<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new IFFT operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input A complex64 tensor.
+   * @return a new instance of IFFT
+   */
+  public static <T> IFFT<T> create(Scope scope, Operand<T> input) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("IFFT", scope.makeOpName("IFFT"));
+    opBuilder.addInput(input.asOutput());
+    return new IFFT<T>(opBuilder.build());
+  }
+  
+  /**
+   * A complex64 tensor of the same shape as `input`. The inner-most
+   *   dimension of `input` is replaced with its inverse 1D Fourier transform.
+   * <p>
+   * @compatibility(numpy)
+   * Equivalent to np.fft.ifft
+   * @end_compatibility
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private IFFT(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Igammac.java java-ops/org/tensorflow/op/core/Igammac.java
--- java/org/tensorflow/op/core/Igammac.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Igammac.java	2018-10-16 20:18:38.309432327 +0900
@@ -0,0 +1,82 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Compute the upper regularized incomplete Gamma function `Q(a, x)`.
+ * <p>
+ * The upper regularized incomplete Gamma function is defined as:
+ * <p>
+ * \\(Q(a, x) = Gamma(a, x) / Gamma(a) = 1 - P(a, x)\\)
+ * <p>
+ * where
+ * <p>
+ * \\(Gamma(a, x) = int_{x}^{\infty} t^{a-1} exp(-t) dt\\)
+ * <p>
+ * is the upper incomplete Gama function.
+ * <p>
+ * Note, above `P(a, x)` (`Igamma`) is the lower regularized complete
+ * Gamma function.
+ * 
+ * @param <T> data type for {@code z()} output
+ */
+@Operator
+public final class Igammac<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Igammac operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param a 
+   * @param x 
+   * @return a new instance of Igammac
+   */
+  public static <T extends Number> Igammac<T> create(Scope scope, Operand<T> a, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Igammac", scope.makeOpName("Igammac"));
+    opBuilder.addInput(a.asOutput());
+    opBuilder.addInput(x.asOutput());
+    return new Igammac<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return z;
+  }
+  
+  private Output<T> z;
+  
+  private Igammac(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/IgammaGradA.java java-ops/org/tensorflow/op/core/IgammaGradA.java
--- java/org/tensorflow/op/core/IgammaGradA.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/IgammaGradA.java	2018-10-16 20:18:38.308432327 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Computes the gradient of `igamma(a, x)` wrt `a`.
+ * 
+ * @param <T> data type for {@code z()} output
+ */
+public final class IgammaGradA<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new IgammaGradA operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param a 
+   * @param x 
+   * @return a new instance of IgammaGradA
+   */
+  public static <T extends Number> IgammaGradA<T> create(Scope scope, Operand<T> a, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("IgammaGradA", scope.makeOpName("IgammaGradA"));
+    opBuilder.addInput(a.asOutput());
+    opBuilder.addInput(x.asOutput());
+    return new IgammaGradA<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return z;
+  }
+  
+  private Output<T> z;
+  
+  private IgammaGradA(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Igamma.java java-ops/org/tensorflow/op/core/Igamma.java
--- java/org/tensorflow/op/core/Igamma.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Igamma.java	2018-10-16 20:18:38.308432327 +0900
@@ -0,0 +1,82 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Compute the lower regularized incomplete Gamma function `P(a, x)`.
+ * <p>
+ * The lower regularized incomplete Gamma function is defined as:
+ * <p>
+ * \\(P(a, x) = gamma(a, x) / Gamma(a) = 1 - Q(a, x)\\)
+ * <p>
+ * where
+ * <p>
+ * \\(gamma(a, x) = \\int_{0}^{x} t^{a-1} exp(-t) dt\\)
+ * <p>
+ * is the lower incomplete Gamma function.
+ * <p>
+ * Note, above `Q(a, x)` (`Igammac`) is the upper regularized complete
+ * Gamma function.
+ * 
+ * @param <T> data type for {@code z()} output
+ */
+@Operator
+public final class Igamma<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Igamma operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param a 
+   * @param x 
+   * @return a new instance of Igamma
+   */
+  public static <T extends Number> Igamma<T> create(Scope scope, Operand<T> a, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Igamma", scope.makeOpName("Igamma"));
+    opBuilder.addInput(a.asOutput());
+    opBuilder.addInput(x.asOutput());
+    return new Igamma<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return z;
+  }
+  
+  private Output<T> z;
+  
+  private Igamma(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ImageSummary.java java-ops/org/tensorflow/op/core/ImageSummary.java
--- java/org/tensorflow/op/core/ImageSummary.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ImageSummary.java	2018-10-16 20:18:38.311432325 +0900
@@ -0,0 +1,170 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Tensor;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Outputs a `Summary` protocol buffer with images.
+ * <p>
+ * The summary has up to `max_images` summary values containing images. The
+ * images are built from `tensor` which must be 4-D with shape `[batch_size,
+ * height, width, channels]` and where `channels` can be:
+ * <ul>
+ * <li>
+ * 1: `tensor` is interpreted as Grayscale.
+ * </li>
+ * <li>
+ * 3: `tensor` is interpreted as RGB.
+ * </li>
+ * <li>
+ * 4: `tensor` is interpreted as RGBA.
+ * </li>
+ * </ul>
+ * The images have the same number of channels as the input tensor. For float
+ * input, the values are normalized one image at a time to fit in the range
+ * `[0, 255]`.  `uint8` values are unchanged.  The op uses two different
+ * normalization algorithms:
+ * <ul>
+ * <li>
+ * If the input values are all positive, they are rescaled so the largest one
+ *    is 255.
+ * </li>
+ * <li>
+ * If any input value is negative, the values are shifted so input value 0.0
+ *    is at 127.  They are then rescaled so that either the smallest value is 0,
+ *    or the largest one is 255.
+ * </li>
+ * </ul>
+ * The `tag` argument is a scalar `Tensor` of type `string`.  It is used to
+ * build the `tag` of the summary values:
+ * <ul>
+ * <li>
+ * If `max_images` is 1, the summary value tag is '<i>tag</i>/image'.
+ * </li>
+ * <li>
+ * If `max_images` is greater than 1, the summary value tags are
+ *    generated sequentially as '<i>tag</i>/image/0', '<i>tag</i>/image/1', etc.
+ * </li>
+ * </ul>
+ * The `bad_color` argument is the color to use in the generated images for
+ * non-finite input values.  It is a `uint8` 1-D tensor of length `channels`.
+ * Each element must be in the range `[0, 255]` (It represents the value of a
+ * pixel in the output image).  Non-finite values in the input tensor are
+ * replaced by this tensor in the output image.  The default value is the color
+ * red.
+ */
+@Operator
+public final class ImageSummary extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ImageSummary}
+   */
+  public static class Options {
+    
+    /**
+     * @param maxImages Max number of batch elements to generate images for.
+     */
+    public Options maxImages(Long maxImages) {
+      this.maxImages = maxImages;
+      return this;
+    }
+    
+    /**
+     * @param badColor Color to use for pixels with non-finite values.
+     */
+    public Options badColor(Tensor<?> badColor) {
+      this.badColor = badColor;
+      return this;
+    }
+    
+    private Long maxImages;
+    private Tensor<?> badColor;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ImageSummary operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param tag Scalar. Used to build the `tag` attribute of the summary values.
+   * @param tensor 4-D of shape `[batch_size, height, width, channels]` where
+   * `channels` is 1, 3, or 4.
+   * @param options carries optional attributes values
+   * @return a new instance of ImageSummary
+   */
+  public static <T extends Number> ImageSummary create(Scope scope, Operand<String> tag, Operand<T> tensor, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ImageSummary", scope.makeOpName("ImageSummary"));
+    opBuilder.addInput(tag.asOutput());
+    opBuilder.addInput(tensor.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.maxImages != null) {
+          opBuilder.setAttr("max_images", opts.maxImages);
+        }
+        if (opts.badColor != null) {
+          opBuilder.setAttr("bad_color", opts.badColor);
+        }
+      }
+    }
+    return new ImageSummary(opBuilder.build());
+  }
+  
+  /**
+   * @param maxImages Max number of batch elements to generate images for.
+   */
+  public static Options maxImages(Long maxImages) {
+    return new Options().maxImages(maxImages);
+  }
+  
+  /**
+   * @param badColor Color to use for pixels with non-finite values.
+   */
+  public static Options badColor(Tensor<?> badColor) {
+    return new Options().badColor(badColor);
+  }
+  
+  /**
+   * Scalar. Serialized `Summary` protocol buffer.
+   */
+  public Output<String> summary() {
+    return summary;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return summary;
+  }
+  
+  private Output<String> summary;
+  
+  private ImageSummary(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    summary = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Imag.java java-ops/org/tensorflow/op/core/Imag.java
--- java/org/tensorflow/op/core/Imag.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Imag.java	2018-10-16 20:18:38.309432327 +0900
@@ -0,0 +1,93 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns the imaginary part of a complex number.
+ * <p>
+ * Given a tensor `input` of complex numbers, this operation returns a tensor of
+ * type `float` that is the imaginary part of each element in `input`. All
+ * elements in `input` must be complex numbers of the form \\(a + bj\\), where <i>a</i>
+ * is the real part and <i>b</i> is the imaginary part returned by this operation.
+ * <p>
+ * For example:
+ * <pre>{@code
+ * # tensor 'input' is [-2.25 + 4.75j, 3.25 + 5.75j]
+ * tf.imag(input) ==> [4.75, 5.75]
+ * }</pre>
+ * 
+ * 
+ * @param <U> data type for {@code output()} output
+ */
+@Operator
+public final class Imag<U extends Number> extends PrimitiveOp implements Operand<U> {
+  
+  /**
+   * Factory method to create a class to wrap a new Imag operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param Tout 
+   * @return a new instance of Imag
+   */
+  public static <U extends Number, T> Imag<U> create(Scope scope, Operand<T> input, Class<U> Tout) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Imag", scope.makeOpName("Imag"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.setAttr("Tout", DataType.fromClass(Tout));
+    return new Imag<U>(opBuilder.build());
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Imag operation to the graph, using default output types.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @return a new instance of Imag
+   */
+  public static <T> Imag<Float> create(Scope scope, Operand<T> input) {
+    return create(scope, input, Float.class);
+  }
+  
+  /**
+   */
+  public Output<U> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<U> asOutput() {
+    return output;
+  }
+  
+  private Output<U> output;
+  
+  private Imag(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ImmutableConst.java java-ops/org/tensorflow/op/core/ImmutableConst.java
--- java/org/tensorflow/op/core/ImmutableConst.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ImmutableConst.java	2018-10-16 20:18:38.311432325 +0900
@@ -0,0 +1,76 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns immutable tensor from memory region.
+ * <p>
+ * The current implementation memmaps the tensor from a file.
+ * 
+ * @param <T> data type for {@code tensor()} output
+ */
+@Operator
+public final class ImmutableConst<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new ImmutableConst operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param dtype Type of the returned tensor.
+   * @param shape Shape of the returned tensor.
+   * @param memoryRegionName Name of readonly memory region used by the tensor, see
+   * NewReadOnlyMemoryRegionFromFile in tensorflow::Env.
+   * @return a new instance of ImmutableConst
+   */
+  public static <T> ImmutableConst<T> create(Scope scope, Class<T> dtype, Shape shape, String memoryRegionName) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ImmutableConst", scope.makeOpName("ImmutableConst"));
+    opBuilder.setAttr("dtype", DataType.fromClass(dtype));
+    opBuilder.setAttr("shape", shape);
+    opBuilder.setAttr("memory_region_name", memoryRegionName);
+    return new ImmutableConst<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> tensor() {
+    return tensor;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return tensor;
+  }
+  
+  private Output<T> tensor;
+  
+  private ImmutableConst(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    tensor = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ImportEvent.java java-ops/org/tensorflow/op/core/ImportEvent.java
--- java/org/tensorflow/op/core/ImportEvent.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ImportEvent.java	2018-10-16 20:18:38.311432325 +0900
@@ -0,0 +1,49 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ */
+public final class ImportEvent extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new ImportEvent operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param writer 
+   * @param event 
+   * @return a new instance of ImportEvent
+   */
+  public static ImportEvent create(Scope scope, Operand<?> writer, Operand<String> event) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ImportEvent", scope.makeOpName("ImportEvent"));
+    opBuilder.addInput(writer.asOutput());
+    opBuilder.addInput(event.asOutput());
+    return new ImportEvent(opBuilder.build());
+  }
+  
+  
+  private ImportEvent(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/InitializeTableFromTextFile.java java-ops/org/tensorflow/op/core/InitializeTableFromTextFile.java
--- java/org/tensorflow/op/core/InitializeTableFromTextFile.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/InitializeTableFromTextFile.java	2018-10-16 20:18:38.314432323 +0900
@@ -0,0 +1,121 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Initializes a table from a text file.
+ * <p>
+ * It inserts one key-value pair into the table for each line of the file.
+ * The key and value is extracted from the whole line content, elements from the
+ * split line based on `delimiter` or the line number (starting from zero).
+ * Where to extract the key and value from a line is specified by `key_index` and
+ * `value_index`.
+ * <p>
+ * - A value of -1 means use the line number(starting from zero), expects `int64`.
+ * - A value of -2 means use the whole line content, expects `string`.
+ * - A value >= 0 means use the index (starting at zero) of the split line based
+ *   on `delimiter`.
+ */
+@Operator
+public final class InitializeTableFromTextFile extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.InitializeTableFromTextFile}
+   */
+  public static class Options {
+    
+    /**
+     * @param vocabSize Number of elements of the file, use -1 if unknown.
+     */
+    public Options vocabSize(Long vocabSize) {
+      this.vocabSize = vocabSize;
+      return this;
+    }
+    
+    /**
+     * @param delimiter Delimiter to separate fields in a line.
+     */
+    public Options delimiter(String delimiter) {
+      this.delimiter = delimiter;
+      return this;
+    }
+    
+    private Long vocabSize;
+    private String delimiter;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new InitializeTableFromTextFile operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param tableHandle Handle to a table which will be initialized.
+   * @param filename Filename of a vocabulary text file.
+   * @param keyIndex Column index in a line to get the table `key` values from.
+   * @param valueIndex Column index that represents information of a line to get the table
+   * `value` values from.
+   * @param options carries optional attributes values
+   * @return a new instance of InitializeTableFromTextFile
+   */
+  public static InitializeTableFromTextFile create(Scope scope, Operand<?> tableHandle, Operand<String> filename, Long keyIndex, Long valueIndex, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("InitializeTableFromTextFileV2", scope.makeOpName("InitializeTableFromTextFile"));
+    opBuilder.addInput(tableHandle.asOutput());
+    opBuilder.addInput(filename.asOutput());
+    opBuilder.setAttr("key_index", keyIndex);
+    opBuilder.setAttr("value_index", valueIndex);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.vocabSize != null) {
+          opBuilder.setAttr("vocab_size", opts.vocabSize);
+        }
+        if (opts.delimiter != null) {
+          opBuilder.setAttr("delimiter", opts.delimiter);
+        }
+      }
+    }
+    return new InitializeTableFromTextFile(opBuilder.build());
+  }
+  
+  /**
+   * @param vocabSize Number of elements of the file, use -1 if unknown.
+   */
+  public static Options vocabSize(Long vocabSize) {
+    return new Options().vocabSize(vocabSize);
+  }
+  
+  /**
+   * @param delimiter Delimiter to separate fields in a line.
+   */
+  public static Options delimiter(String delimiter) {
+    return new Options().delimiter(delimiter);
+  }
+  
+  
+  private InitializeTableFromTextFile(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/InitializeTable.java java-ops/org/tensorflow/op/core/InitializeTable.java
--- java/org/tensorflow/op/core/InitializeTable.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/InitializeTable.java	2018-10-16 20:18:38.314432323 +0900
@@ -0,0 +1,54 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Table initializer that takes two tensors for keys and values respectively.
+ */
+@Operator
+public final class InitializeTable extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new InitializeTable operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param tableHandle Handle to a table which will be initialized.
+   * @param keys Keys of type Tkey.
+   * @param values Values of type Tval.
+   * @return a new instance of InitializeTable
+   */
+  public static <T, U> InitializeTable create(Scope scope, Operand<?> tableHandle, Operand<T> keys, Operand<U> values) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("InitializeTableV2", scope.makeOpName("InitializeTable"));
+    opBuilder.addInput(tableHandle.asOutput());
+    opBuilder.addInput(keys.asOutput());
+    opBuilder.addInput(values.asOutput());
+    return new InitializeTable(opBuilder.build());
+  }
+  
+  
+  private InitializeTable(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/InplaceAdd.java java-ops/org/tensorflow/op/core/InplaceAdd.java
--- java/org/tensorflow/op/core/InplaceAdd.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/InplaceAdd.java	2018-10-16 20:18:38.315432322 +0900
@@ -0,0 +1,74 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ *     Adds v into specified rows of x.
+ * <p>
+ *     Computes y = x; y[i, :] += v; return y.
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class InplaceAdd<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new InplaceAdd operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x A `Tensor` of type T.
+   * @param i A vector. Indices into the left-most dimension of `x`.
+   * @param v A `Tensor` of type T. Same dimension sizes as x except the first dimension, which must be the same as i's size.
+   * @return a new instance of InplaceAdd
+   */
+  public static <T> InplaceAdd<T> create(Scope scope, Operand<T> x, Operand<Integer> i, Operand<T> v) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("InplaceAdd", scope.makeOpName("InplaceAdd"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(i.asOutput());
+    opBuilder.addInput(v.asOutput());
+    return new InplaceAdd<T>(opBuilder.build());
+  }
+  
+  /**
+   * A `Tensor` of type T. An alias of `x`. The content of `y` is undefined if there are duplicates in `i`.
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private InplaceAdd(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/InplaceSub.java java-ops/org/tensorflow/op/core/InplaceSub.java
--- java/org/tensorflow/op/core/InplaceSub.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/InplaceSub.java	2018-10-16 20:18:38.315432322 +0900
@@ -0,0 +1,74 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ *     Subtracts `v` into specified rows of `x`.
+ * <p>
+ *     Computes y = x; y[i, :] -= v; return y.
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class InplaceSub<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new InplaceSub operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x A `Tensor` of type T.
+   * @param i A vector. Indices into the left-most dimension of `x`.
+   * @param v A `Tensor` of type T. Same dimension sizes as x except the first dimension, which must be the same as i's size.
+   * @return a new instance of InplaceSub
+   */
+  public static <T> InplaceSub<T> create(Scope scope, Operand<T> x, Operand<Integer> i, Operand<T> v) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("InplaceSub", scope.makeOpName("InplaceSub"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(i.asOutput());
+    opBuilder.addInput(v.asOutput());
+    return new InplaceSub<T>(opBuilder.build());
+  }
+  
+  /**
+   * A `Tensor` of type T. An alias of `x`. The content of `y` is undefined if there are duplicates in `i`.
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private InplaceSub(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/InplaceUpdate.java java-ops/org/tensorflow/op/core/InplaceUpdate.java
--- java/org/tensorflow/op/core/InplaceUpdate.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/InplaceUpdate.java	2018-10-16 20:18:38.316432322 +0900
@@ -0,0 +1,74 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ *     Updates specified rows with values in `v`.
+ * <p>
+ *     Computes `x[i, :] = v; return x`.
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class InplaceUpdate<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new InplaceUpdate operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x A tensor of type `T`.
+   * @param i A vector. Indices into the left-most dimension of `x`.
+   * @param v A `Tensor` of type T. Same dimension sizes as x except the first dimension, which must be the same as i's size.
+   * @return a new instance of InplaceUpdate
+   */
+  public static <T> InplaceUpdate<T> create(Scope scope, Operand<T> x, Operand<Integer> i, Operand<T> v) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("InplaceUpdate", scope.makeOpName("InplaceUpdate"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(i.asOutput());
+    opBuilder.addInput(v.asOutput());
+    return new InplaceUpdate<T>(opBuilder.build());
+  }
+  
+  /**
+   * A `Tensor` of type T. An alias of `x`. The content of `y` is undefined if there are duplicates in `i`.
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private InplaceUpdate(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/InTopK.java java-ops/org/tensorflow/op/core/InTopK.java
--- java/org/tensorflow/op/core/InTopK.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/InTopK.java	2018-10-16 20:18:38.312432324 +0900
@@ -0,0 +1,85 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Says whether the targets are in the top `K` predictions.
+ * <p>
+ * This outputs a `batch_size` bool array, an entry `out[i]` is `true` if the
+ * prediction for the target class is among the top `k` predictions among
+ * all predictions for example `i`. Note that the behavior of `InTopK` differs
+ * from the `TopK` op in its handling of ties; if multiple classes have the
+ * same prediction value and straddle the top-`k` boundary, all of those
+ * classes are considered to be in the top `k`.
+ * <p>
+ * More formally, let
+ * <p>
+ *   \\(predictions_i\\) be the predictions for all classes for example `i`,
+ *   \\(targets_i\\) be the target class for example `i`,
+ *   \\(out_i\\) be the output for example `i`,
+ * <p>
+ * $$out_i = predictions_{i, targets_i} \in TopKIncludingTies(predictions_i)$$
+ */
+@Operator
+public final class InTopK extends PrimitiveOp implements Operand<Boolean> {
+  
+  /**
+   * Factory method to create a class to wrap a new InTopK operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param predictions A `batch_size` x `classes` tensor.
+   * @param targets A `batch_size` vector of class ids.
+   * @param k Number of top elements to look at for computing precision.
+   * @return a new instance of InTopK
+   */
+  public static <T extends Number> InTopK create(Scope scope, Operand<Float> predictions, Operand<T> targets, Long k) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("InTopK", scope.makeOpName("InTopK"));
+    opBuilder.addInput(predictions.asOutput());
+    opBuilder.addInput(targets.asOutput());
+    opBuilder.setAttr("k", k);
+    return new InTopK(opBuilder.build());
+  }
+  
+  /**
+   * Computed Precision at `k` as a `bool Tensor`.
+   */
+  public Output<Boolean> precision() {
+    return precision;
+  }
+  
+  @Override
+  public Output<Boolean> asOutput() {
+    return precision;
+  }
+  
+  private Output<Boolean> precision;
+  
+  private InTopK(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    precision = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/InTopKV2.java java-ops/org/tensorflow/op/core/InTopKV2.java
--- java/org/tensorflow/op/core/InTopKV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/InTopKV2.java	2018-10-16 20:18:38.313432324 +0900
@@ -0,0 +1,85 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Says whether the targets are in the top `K` predictions.
+ * <p>
+ * This outputs a `batch_size` bool array, an entry `out[i]` is `true` if the
+ * prediction for the target class is among the top `k` predictions among
+ * all predictions for example `i`. Note that the behavior of `InTopK` differs
+ * from the `TopK` op in its handling of ties; if multiple classes have the
+ * same prediction value and straddle the top-`k` boundary, all of those
+ * classes are considered to be in the top `k`.
+ * <p>
+ * More formally, let
+ * <p>
+ *   \\(predictions_i\\) be the predictions for all classes for example `i`,
+ *   \\(targets_i\\) be the target class for example `i`,
+ *   \\(out_i\\) be the output for example `i`,
+ * <p>
+ * $$out_i = predictions_{i, targets_i} \in TopKIncludingTies(predictions_i)$$
+ */
+@Operator
+public final class InTopKV2 extends PrimitiveOp implements Operand<Boolean> {
+  
+  /**
+   * Factory method to create a class to wrap a new InTopKV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param predictions A `batch_size` x `classes` tensor.
+   * @param targets A `batch_size` vector of class ids.
+   * @param k Number of top elements to look at for computing precision.
+   * @return a new instance of InTopKV2
+   */
+  public static <T extends Number> InTopKV2 create(Scope scope, Operand<Float> predictions, Operand<T> targets, Operand<T> k) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("InTopKV2", scope.makeOpName("InTopKV2"));
+    opBuilder.addInput(predictions.asOutput());
+    opBuilder.addInput(targets.asOutput());
+    opBuilder.addInput(k.asOutput());
+    return new InTopKV2(opBuilder.build());
+  }
+  
+  /**
+   * Computed precision at `k` as a `bool Tensor`.
+   */
+  public Output<Boolean> precision() {
+    return precision;
+  }
+  
+  @Override
+  public Output<Boolean> asOutput() {
+    return precision;
+  }
+  
+  private Output<Boolean> precision;
+  
+  private InTopKV2(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    precision = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Invert.java java-ops/org/tensorflow/op/core/Invert.java
--- java/org/tensorflow/op/core/Invert.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Invert.java	2018-10-16 20:18:38.317432321 +0900
@@ -0,0 +1,70 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Flips all bits elementwise.
+ * <p>
+ * The result will have exactly those bits set, that are not set in `x`. The
+ * computation is performed on the underlying representation of x.
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class Invert<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Invert operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of Invert
+   */
+  public static <T extends Number> Invert<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Invert", scope.makeOpName("Invert"));
+    opBuilder.addInput(x.asOutput());
+    return new Invert<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private Invert(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/InvertPermutation.java java-ops/org/tensorflow/op/core/InvertPermutation.java
--- java/org/tensorflow/op/core/InvertPermutation.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/InvertPermutation.java	2018-10-16 20:18:38.317432321 +0900
@@ -0,0 +1,84 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the inverse permutation of a tensor.
+ * <p>
+ * This operation computes the inverse of an index permutation. It takes a 1-D
+ * integer tensor `x`, which represents the indices of a zero-based array, and
+ * swaps each value with its index position. In other words, for an output tensor
+ * `y` and an input tensor `x`, this operation computes the following:
+ * <p>
+ * `y[x[i]] = i for i in [0, 1, ..., len(x) - 1]`
+ * <p>
+ * The values must include 0. There can be no duplicate values or negative values.
+ * <p>
+ * For example:
+ * <pre>{@code
+ * # tensor `x` is [3, 4, 0, 2, 1]
+ * invert_permutation(x) ==> [2, 4, 3, 0, 1]
+ * }</pre>
+ * 
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class InvertPermutation<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new InvertPermutation operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 1-D.
+   * @return a new instance of InvertPermutation
+   */
+  public static <T extends Number> InvertPermutation<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("InvertPermutation", scope.makeOpName("InvertPermutation"));
+    opBuilder.addInput(x.asOutput());
+    return new InvertPermutation<T>(opBuilder.build());
+  }
+  
+  /**
+   * 1-D.
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private InvertPermutation(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/InvGrad.java java-ops/org/tensorflow/op/core/InvGrad.java
--- java/org/tensorflow/op/core/InvGrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/InvGrad.java	2018-10-16 20:18:38.317432321 +0900
@@ -0,0 +1,70 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Computes the gradient for the inverse of `x` wrt its input.
+ * <p>
+ * Specifically, `grad = -dy <i> y</i>y`, where `y = 1/x`, and `dy`
+ * is the corresponding input gradient.
+ * 
+ * @param <T> data type for {@code z()} output
+ */
+public final class InvGrad<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new InvGrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param y 
+   * @param dy 
+   * @return a new instance of InvGrad
+   */
+  public static <T> InvGrad<T> create(Scope scope, Operand<T> y, Operand<T> dy) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("InvGrad", scope.makeOpName("InvGrad"));
+    opBuilder.addInput(y.asOutput());
+    opBuilder.addInput(dy.asOutput());
+    return new InvGrad<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return z;
+  }
+  
+  private Output<T> z;
+  
+  private InvGrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Inv.java java-ops/org/tensorflow/op/core/Inv.java
--- java/org/tensorflow/op/core/Inv.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Inv.java	2018-10-16 20:18:38.316432322 +0900
@@ -0,0 +1,69 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the reciprocal of x element-wise.
+ * <p>
+ * I.e., \\(y = 1 / x\\).
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class Inv<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Inv operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of Inv
+   */
+  public static <T> Inv<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Inv", scope.makeOpName("Inv"));
+    opBuilder.addInput(x.asOutput());
+    return new Inv<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private Inv(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/IRFFT2D.java java-ops/org/tensorflow/op/core/IRFFT2D.java
--- java/org/tensorflow/op/core/IRFFT2D.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/IRFFT2D.java	2018-10-16 20:18:38.305432329 +0900
@@ -0,0 +1,89 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Inverse 2D real-valued fast Fourier transform.
+ * <p>
+ * Computes the inverse 2-dimensional discrete Fourier transform of a real-valued
+ * signal over the inner-most 2 dimensions of `input`.
+ * <p>
+ * The inner-most 2 dimensions of `input` are assumed to be the result of `RFFT2D`:
+ * The inner-most dimension contains the `fft_length / 2 + 1` unique components of
+ * the DFT of a real-valued signal. If `fft_length` is not provided, it is computed
+ * from the size of the inner-most 2 dimensions of `input`. If the FFT length used
+ * to compute `input` is odd, it should be provided since it cannot be inferred
+ * properly.
+ * <p>
+ * Along each axis `IRFFT2D` is computed on, if `fft_length` (or
+ * `fft_length / 2 + 1` for the inner-most dimension) is smaller than the
+ * corresponding dimension of `input`, the dimension is cropped. If it is larger,
+ * the dimension is padded with zeros.
+ */
+@Operator
+public final class IRFFT2D extends PrimitiveOp implements Operand<Float> {
+  
+  /**
+   * Factory method to create a class to wrap a new IRFFT2D operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input A complex64 tensor.
+   * @param fftLength An int32 tensor of shape [2]. The FFT length for each dimension.
+   * @return a new instance of IRFFT2D
+   */
+  public static IRFFT2D create(Scope scope, Operand<?> input, Operand<Integer> fftLength) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("IRFFT2D", scope.makeOpName("IRFFT2D"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(fftLength.asOutput());
+    return new IRFFT2D(opBuilder.build());
+  }
+  
+  /**
+   * A float32 tensor of the same rank as `input`. The inner-most 2
+   *   dimensions of `input` are replaced with the `fft_length` samples of their
+   *   inverse 2D Fourier transform.
+   * <p>
+   * @compatibility(numpy)
+   * Equivalent to np.fft.irfft2
+   * @end_compatibility
+   */
+  public Output<Float> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<Float> asOutput() {
+    return output;
+  }
+  
+  private Output<Float> output;
+  
+  private IRFFT2D(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/IRFFT3D.java java-ops/org/tensorflow/op/core/IRFFT3D.java
--- java/org/tensorflow/op/core/IRFFT3D.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/IRFFT3D.java	2018-10-16 20:18:38.306432329 +0900
@@ -0,0 +1,89 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Inverse 3D real-valued fast Fourier transform.
+ * <p>
+ * Computes the inverse 3-dimensional discrete Fourier transform of a real-valued
+ * signal over the inner-most 3 dimensions of `input`.
+ * <p>
+ * The inner-most 3 dimensions of `input` are assumed to be the result of `RFFT3D`:
+ * The inner-most dimension contains the `fft_length / 2 + 1` unique components of
+ * the DFT of a real-valued signal. If `fft_length` is not provided, it is computed
+ * from the size of the inner-most 3 dimensions of `input`. If the FFT length used
+ * to compute `input` is odd, it should be provided since it cannot be inferred
+ * properly.
+ * <p>
+ * Along each axis `IRFFT3D` is computed on, if `fft_length` (or
+ * `fft_length / 2 + 1` for the inner-most dimension) is smaller than the
+ * corresponding dimension of `input`, the dimension is cropped. If it is larger,
+ * the dimension is padded with zeros.
+ */
+@Operator
+public final class IRFFT3D extends PrimitiveOp implements Operand<Float> {
+  
+  /**
+   * Factory method to create a class to wrap a new IRFFT3D operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input A complex64 tensor.
+   * @param fftLength An int32 tensor of shape [3]. The FFT length for each dimension.
+   * @return a new instance of IRFFT3D
+   */
+  public static IRFFT3D create(Scope scope, Operand<?> input, Operand<Integer> fftLength) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("IRFFT3D", scope.makeOpName("IRFFT3D"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(fftLength.asOutput());
+    return new IRFFT3D(opBuilder.build());
+  }
+  
+  /**
+   * A float32 tensor of the same rank as `input`. The inner-most 3
+   *   dimensions of `input` are replaced with the `fft_length` samples of their
+   *   inverse 3D real Fourier transform.
+   * <p>
+   * @compatibility(numpy)
+   * Equivalent to np.irfftn with 3 dimensions.
+   * @end_compatibility
+   */
+  public Output<Float> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<Float> asOutput() {
+    return output;
+  }
+  
+  private Output<Float> output;
+  
+  private IRFFT3D(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/IRFFT.java java-ops/org/tensorflow/op/core/IRFFT.java
--- java/org/tensorflow/op/core/IRFFT.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/IRFFT.java	2018-10-16 20:18:38.304432330 +0900
@@ -0,0 +1,88 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Inverse real-valued fast Fourier transform.
+ * <p>
+ * Computes the inverse 1-dimensional discrete Fourier transform of a real-valued
+ * signal over the inner-most dimension of `input`.
+ * <p>
+ * The inner-most dimension of `input` is assumed to be the result of `RFFT`: the
+ * `fft_length / 2 + 1` unique components of the DFT of a real-valued signal. If
+ * `fft_length` is not provided, it is computed from the size of the inner-most
+ * dimension of `input` (`fft_length = 2 * (inner - 1)`). If the FFT length used to
+ * compute `input` is odd, it should be provided since it cannot be inferred
+ * properly.
+ * <p>
+ * Along the axis `IRFFT` is computed on, if `fft_length / 2 + 1` is smaller
+ * than the corresponding dimension of `input`, the dimension is cropped. If it is
+ * larger, the dimension is padded with zeros.
+ */
+@Operator
+public final class IRFFT extends PrimitiveOp implements Operand<Float> {
+  
+  /**
+   * Factory method to create a class to wrap a new IRFFT operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input A complex64 tensor.
+   * @param fftLength An int32 tensor of shape [1]. The FFT length.
+   * @return a new instance of IRFFT
+   */
+  public static IRFFT create(Scope scope, Operand<?> input, Operand<Integer> fftLength) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("IRFFT", scope.makeOpName("IRFFT"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(fftLength.asOutput());
+    return new IRFFT(opBuilder.build());
+  }
+  
+  /**
+   * A float32 tensor of the same rank as `input`. The inner-most
+   *   dimension of `input` is replaced with the `fft_length` samples of its inverse
+   *   1D Fourier transform.
+   * <p>
+   * @compatibility(numpy)
+   * Equivalent to np.fft.irfft
+   * @end_compatibility
+   */
+  public Output<Float> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<Float> asOutput() {
+    return output;
+  }
+  
+  private Output<Float> output;
+  
+  private IRFFT(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/IsBoostedTreesEnsembleInitialized.java java-ops/org/tensorflow/op/core/IsBoostedTreesEnsembleInitialized.java
--- java/org/tensorflow/op/core/IsBoostedTreesEnsembleInitialized.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/IsBoostedTreesEnsembleInitialized.java	2018-10-16 20:18:38.318432320 +0900
@@ -0,0 +1,64 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Checks whether a tree ensemble has been initialized.
+ */
+public final class IsBoostedTreesEnsembleInitialized extends PrimitiveOp implements Operand<Boolean> {
+  
+  /**
+   * Factory method to create a class to wrap a new IsBoostedTreesEnsembleInitialized operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param treeEnsembleHandle Handle to the tree ensemble resouce.
+   * @return a new instance of IsBoostedTreesEnsembleInitialized
+   */
+  public static IsBoostedTreesEnsembleInitialized create(Scope scope, Operand<?> treeEnsembleHandle) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("IsBoostedTreesEnsembleInitialized", scope.makeOpName("IsBoostedTreesEnsembleInitialized"));
+    opBuilder.addInput(treeEnsembleHandle.asOutput());
+    return new IsBoostedTreesEnsembleInitialized(opBuilder.build());
+  }
+  
+  /**
+   * output boolean on whether it is initialized or not.
+   */
+  public Output<Boolean> isInitialized() {
+    return isInitialized;
+  }
+  
+  @Override
+  public Output<Boolean> asOutput() {
+    return isInitialized;
+  }
+  
+  private Output<Boolean> isInitialized;
+  
+  private IsBoostedTreesEnsembleInitialized(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    isInitialized = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/IsBoostedTreesQuantileStreamResourceInitialized.java java-ops/org/tensorflow/op/core/IsBoostedTreesQuantileStreamResourceInitialized.java
--- java/org/tensorflow/op/core/IsBoostedTreesQuantileStreamResourceInitialized.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/IsBoostedTreesQuantileStreamResourceInitialized.java	2018-10-16 20:18:38.318432320 +0900
@@ -0,0 +1,66 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Checks whether a quantile stream has been initialized.
+ * <p>
+ * An Op that checks if quantile stream resource is initialized.
+ */
+public final class IsBoostedTreesQuantileStreamResourceInitialized extends PrimitiveOp implements Operand<Boolean> {
+  
+  /**
+   * Factory method to create a class to wrap a new IsBoostedTreesQuantileStreamResourceInitialized operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param quantileStreamResourceHandle resource; The reference to quantile stream resource handle.
+   * @return a new instance of IsBoostedTreesQuantileStreamResourceInitialized
+   */
+  public static IsBoostedTreesQuantileStreamResourceInitialized create(Scope scope, Operand<?> quantileStreamResourceHandle) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("IsBoostedTreesQuantileStreamResourceInitialized", scope.makeOpName("IsBoostedTreesQuantileStreamResourceInitialized"));
+    opBuilder.addInput(quantileStreamResourceHandle.asOutput());
+    return new IsBoostedTreesQuantileStreamResourceInitialized(opBuilder.build());
+  }
+  
+  /**
+   * bool; True if the resource is initialized, False otherwise.
+   */
+  public Output<Boolean> isInitialized() {
+    return isInitialized;
+  }
+  
+  @Override
+  public Output<Boolean> asOutput() {
+    return isInitialized;
+  }
+  
+  private Output<Boolean> isInitialized;
+  
+  private IsBoostedTreesQuantileStreamResourceInitialized(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    isInitialized = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/IsFinite.java java-ops/org/tensorflow/op/core/IsFinite.java
--- java/org/tensorflow/op/core/IsFinite.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/IsFinite.java	2018-10-16 20:18:38.318432320 +0900
@@ -0,0 +1,69 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns which elements of x are finite.
+ * <p>
+ * @compatibility(numpy)
+ * Equivalent to np.isfinite
+ * @end_compatibility
+ */
+@Operator
+public final class IsFinite extends PrimitiveOp implements Operand<Boolean> {
+  
+  /**
+   * Factory method to create a class to wrap a new IsFinite operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of IsFinite
+   */
+  public static <T extends Number> IsFinite create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("IsFinite", scope.makeOpName("IsFinite"));
+    opBuilder.addInput(x.asOutput());
+    return new IsFinite(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<Boolean> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<Boolean> asOutput() {
+    return y;
+  }
+  
+  private Output<Boolean> y;
+  
+  private IsFinite(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/IsInf.java java-ops/org/tensorflow/op/core/IsInf.java
--- java/org/tensorflow/op/core/IsInf.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/IsInf.java	2018-10-16 20:18:38.318432320 +0900
@@ -0,0 +1,69 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns which elements of x are Inf.
+ * <p>
+ * @compatibility(numpy)
+ * Equivalent to np.isinf
+ * @end_compatibility
+ */
+@Operator
+public final class IsInf extends PrimitiveOp implements Operand<Boolean> {
+  
+  /**
+   * Factory method to create a class to wrap a new IsInf operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of IsInf
+   */
+  public static <T extends Number> IsInf create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("IsInf", scope.makeOpName("IsInf"));
+    opBuilder.addInput(x.asOutput());
+    return new IsInf(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<Boolean> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<Boolean> asOutput() {
+    return y;
+  }
+  
+  private Output<Boolean> y;
+  
+  private IsInf(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/IsNan.java java-ops/org/tensorflow/op/core/IsNan.java
--- java/org/tensorflow/op/core/IsNan.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/IsNan.java	2018-10-16 20:18:38.318432320 +0900
@@ -0,0 +1,69 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns which elements of x are NaN.
+ * <p>
+ * @compatibility(numpy)
+ * Equivalent to np.isnan
+ * @end_compatibility
+ */
+@Operator
+public final class IsNan extends PrimitiveOp implements Operand<Boolean> {
+  
+  /**
+   * Factory method to create a class to wrap a new IsNan operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of IsNan
+   */
+  public static <T extends Number> IsNan create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("IsNan", scope.makeOpName("IsNan"));
+    opBuilder.addInput(x.asOutput());
+    return new IsNan(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<Boolean> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<Boolean> asOutput() {
+    return y;
+  }
+  
+  private Output<Boolean> y;
+  
+  private IsNan(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/IsVariableInitialized.java java-ops/org/tensorflow/op/core/IsVariableInitialized.java
--- java/org/tensorflow/op/core/IsVariableInitialized.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/IsVariableInitialized.java	2018-10-16 20:18:38.319432320 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Checks whether a tensor has been initialized.
+ * <p>
+ * Outputs boolean scalar indicating whether the tensor has been initialized.
+ */
+@Operator
+public final class IsVariableInitialized extends PrimitiveOp implements Operand<Boolean> {
+  
+  /**
+   * Factory method to create a class to wrap a new IsVariableInitialized operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param ref Should be from a `Variable` node. May be uninitialized.
+   * @return a new instance of IsVariableInitialized
+   */
+  public static <T> IsVariableInitialized create(Scope scope, Operand<T> ref) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("IsVariableInitialized", scope.makeOpName("IsVariableInitialized"));
+    opBuilder.addInput(ref.asOutput());
+    return new IsVariableInitialized(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<Boolean> isInitialized() {
+    return isInitialized;
+  }
+  
+  @Override
+  public Output<Boolean> asOutput() {
+    return isInitialized;
+  }
+  
+  private Output<Boolean> isInitialized;
+  
+  private IsVariableInitialized(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    isInitialized = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/IteratorFromStringHandle.java java-ops/org/tensorflow/op/core/IteratorFromStringHandle.java
--- java/org/tensorflow/op/core/IteratorFromStringHandle.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/IteratorFromStringHandle.java	2018-10-16 20:18:38.319432320 +0900
@@ -0,0 +1,117 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Converts the given string representing a handle to an iterator to a resource.
+ */
+@Operator
+public final class IteratorFromStringHandle extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.IteratorFromStringHandle}
+   */
+  public static class Options {
+    
+    /**
+     * @param outputShapes If specified, defines the shape of each tuple component in an
+     * element produced by the resulting iterator.
+     */
+    public Options outputShapes(List<Shape> outputShapes) {
+      this.outputShapes = outputShapes;
+      return this;
+    }
+    
+    private List<Shape> outputShapes;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new IteratorFromStringHandle operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param stringHandle A string representation of the given handle.
+   * @param outputTypes If specified, defines the type of each tuple component in an
+   * element produced by the resulting iterator.
+   * @param options carries optional attributes values
+   * @return a new instance of IteratorFromStringHandle
+   */
+  public static IteratorFromStringHandle create(Scope scope, Operand<String> stringHandle, List<Class<?>> outputTypes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("IteratorFromStringHandle", scope.makeOpName("IteratorFromStringHandle"));
+    opBuilder.addInput(stringHandle.asOutput());
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.outputShapes != null) {
+          Shape[] outputShapesArray = new Shape[opts.outputShapes.size()];
+          for (int i = 0; i < outputShapesArray.length; ++i) {
+            outputShapesArray[i] = opts.outputShapes.get(i);
+          }
+          opBuilder.setAttr("output_shapes", outputShapesArray);
+        }
+      }
+    }
+    return new IteratorFromStringHandle(opBuilder.build());
+  }
+  
+  /**
+   * @param outputShapes If specified, defines the shape of each tuple component in an
+   * element produced by the resulting iterator.
+   */
+  public static Options outputShapes(List<Shape> outputShapes) {
+    return new Options().outputShapes(outputShapes);
+  }
+  
+  /**
+   * A handle to an iterator resource.
+   */
+  public Output<?> resourceHandle() {
+    return resourceHandle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) resourceHandle;
+  }
+  
+  private Output<?> resourceHandle;
+  
+  private IteratorFromStringHandle(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    resourceHandle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/IteratorFromStringHandleV2.java java-ops/org/tensorflow/op/core/IteratorFromStringHandleV2.java
--- java/org/tensorflow/op/core/IteratorFromStringHandleV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/IteratorFromStringHandleV2.java	2018-10-16 20:18:38.319432320 +0900
@@ -0,0 +1,110 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ */
+public final class IteratorFromStringHandleV2 extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.IteratorFromStringHandleV2}
+   */
+  public static class Options {
+    
+    /**
+     * @param outputShapes 
+     */
+    public Options outputShapes(List<Shape> outputShapes) {
+      this.outputShapes = outputShapes;
+      return this;
+    }
+    
+    private List<Shape> outputShapes;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new IteratorFromStringHandleV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param stringHandle 
+   * @param outputTypes 
+   * @param options carries optional attributes values
+   * @return a new instance of IteratorFromStringHandleV2
+   */
+  public static IteratorFromStringHandleV2 create(Scope scope, Operand<String> stringHandle, List<Class<?>> outputTypes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("IteratorFromStringHandleV2", scope.makeOpName("IteratorFromStringHandleV2"));
+    opBuilder.addInput(stringHandle.asOutput());
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.outputShapes != null) {
+          Shape[] outputShapesArray = new Shape[opts.outputShapes.size()];
+          for (int i = 0; i < outputShapesArray.length; ++i) {
+            outputShapesArray[i] = opts.outputShapes.get(i);
+          }
+          opBuilder.setAttr("output_shapes", outputShapesArray);
+        }
+      }
+    }
+    return new IteratorFromStringHandleV2(opBuilder.build());
+  }
+  
+  /**
+   * @param outputShapes 
+   */
+  public static Options outputShapes(List<Shape> outputShapes) {
+    return new Options().outputShapes(outputShapes);
+  }
+  
+  /**
+   */
+  public Output<?> resourceHandle() {
+    return resourceHandle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) resourceHandle;
+  }
+  
+  private Output<?> resourceHandle;
+  
+  private IteratorFromStringHandleV2(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    resourceHandle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/IteratorGetNextAsOptional.java java-ops/org/tensorflow/op/core/IteratorGetNextAsOptional.java
--- java/org/tensorflow/op/core/IteratorGetNextAsOptional.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/IteratorGetNextAsOptional.java	2018-10-16 20:18:38.320432319 +0900
@@ -0,0 +1,81 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Gets the next output from the given iterator as an Optional variant.
+ */
+@Operator
+public final class IteratorGetNextAsOptional extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new IteratorGetNextAsOptional operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param iterator 
+   * @param outputTypes 
+   * @param outputShapes 
+   * @return a new instance of IteratorGetNextAsOptional
+   */
+  public static IteratorGetNextAsOptional create(Scope scope, Operand<?> iterator, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("IteratorGetNextAsOptional", scope.makeOpName("IteratorGetNextAsOptional"));
+    opBuilder.addInput(iterator.asOutput());
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new IteratorGetNextAsOptional(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> optional() {
+    return optional;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) optional;
+  }
+  
+  private Output<?> optional;
+  
+  private IteratorGetNextAsOptional(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    optional = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/IteratorGetNext.java java-ops/org/tensorflow/op/core/IteratorGetNext.java
--- java/org/tensorflow/op/core/IteratorGetNext.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/IteratorGetNext.java	2018-10-16 20:18:38.320432319 +0900
@@ -0,0 +1,85 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.Iterator;
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Gets the next output from the given iterator .
+ */
+@Operator
+public final class IteratorGetNext extends PrimitiveOp implements Iterable<Operand<Object>> {
+  
+  /**
+   * Factory method to create a class to wrap a new IteratorGetNext operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param iterator 
+   * @param outputTypes 
+   * @param outputShapes 
+   * @return a new instance of IteratorGetNext
+   */
+  public static IteratorGetNext create(Scope scope, Operand<?> iterator, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("IteratorGetNext", scope.makeOpName("IteratorGetNext"));
+    opBuilder.addInput(iterator.asOutput());
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new IteratorGetNext(opBuilder.build());
+  }
+  
+  /**
+   */
+  public List<Output<?>> components() {
+    return components;
+  }
+  
+  @Override
+  @SuppressWarnings({"rawtypes", "unchecked"})
+  public Iterator<Operand<Object>> iterator() {
+    return (Iterator) components.iterator();
+  }
+  
+  private List<Output<?>> components;
+  
+  private IteratorGetNext(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    int componentsLength = operation.outputListLength("components");
+    components = Arrays.asList(operation.outputList(outputIdx, componentsLength));
+    outputIdx += componentsLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/IteratorGetNextSync.java java-ops/org/tensorflow/op/core/IteratorGetNextSync.java
--- java/org/tensorflow/op/core/IteratorGetNextSync.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/IteratorGetNextSync.java	2018-10-16 20:18:38.320432319 +0900
@@ -0,0 +1,90 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.Iterator;
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Gets the next output from the given iterator.
+ * <p>
+ * This operation is a synchronous version IteratorGetNext. It should only be used
+ * in situations where the iterator does not block the calling thread, or where
+ * the calling thread is not a member of the thread pool used to execute parallel
+ * operations (e.g. in eager mode).
+ */
+@Operator
+public final class IteratorGetNextSync extends PrimitiveOp implements Iterable<Operand<Object>> {
+  
+  /**
+   * Factory method to create a class to wrap a new IteratorGetNextSync operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param iterator 
+   * @param outputTypes 
+   * @param outputShapes 
+   * @return a new instance of IteratorGetNextSync
+   */
+  public static IteratorGetNextSync create(Scope scope, Operand<?> iterator, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("IteratorGetNextSync", scope.makeOpName("IteratorGetNextSync"));
+    opBuilder.addInput(iterator.asOutput());
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new IteratorGetNextSync(opBuilder.build());
+  }
+  
+  /**
+   */
+  public List<Output<?>> components() {
+    return components;
+  }
+  
+  @Override
+  @SuppressWarnings({"rawtypes", "unchecked"})
+  public Iterator<Operand<Object>> iterator() {
+    return (Iterator) components.iterator();
+  }
+  
+  private List<Output<?>> components;
+  
+  private IteratorGetNextSync(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    int componentsLength = operation.outputListLength("components");
+    components = Arrays.asList(operation.outputList(outputIdx, componentsLength));
+    outputIdx += componentsLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/Iterator.java java-ops/org/tensorflow/op/core/Iterator.java
--- java/org/tensorflow/op/core/Iterator.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Iterator.java	2018-10-16 20:18:38.319432320 +0900
@@ -0,0 +1,85 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * A container for an iterator resource.
+ */
+@Operator
+public final class Iterator extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new Iterator operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param sharedName 
+   * @param container 
+   * @param outputTypes 
+   * @param outputShapes 
+   * @return a new instance of Iterator
+   */
+  public static Iterator create(Scope scope, String sharedName, String container, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Iterator", scope.makeOpName("Iterator"));
+    opBuilder.setAttr("shared_name", sharedName);
+    opBuilder.setAttr("container", container);
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new Iterator(opBuilder.build());
+  }
+  
+  /**
+   * A handle to the iterator that can be passed to a "MakeIterator"
+   * or "IteratorGetNext" op.
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private Iterator(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/IteratorToStringHandle.java java-ops/org/tensorflow/op/core/IteratorToStringHandle.java
--- java/org/tensorflow/op/core/IteratorToStringHandle.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/IteratorToStringHandle.java	2018-10-16 20:18:38.321432318 +0900
@@ -0,0 +1,66 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Converts the given `resource_handle` representing an iterator to a string.
+ */
+@Operator
+public final class IteratorToStringHandle extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Factory method to create a class to wrap a new IteratorToStringHandle operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param resourceHandle A handle to an iterator resource.
+   * @return a new instance of IteratorToStringHandle
+   */
+  public static IteratorToStringHandle create(Scope scope, Operand<?> resourceHandle) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("IteratorToStringHandle", scope.makeOpName("IteratorToStringHandle"));
+    opBuilder.addInput(resourceHandle.asOutput());
+    return new IteratorToStringHandle(opBuilder.build());
+  }
+  
+  /**
+   * A string representation of the given handle.
+   */
+  public Output<String> stringHandle() {
+    return stringHandle;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return stringHandle;
+  }
+  
+  private Output<String> stringHandle;
+  
+  private IteratorToStringHandle(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    stringHandle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/IteratorV2.java java-ops/org/tensorflow/op/core/IteratorV2.java
--- java/org/tensorflow/op/core/IteratorV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/IteratorV2.java	2018-10-16 20:18:38.321432318 +0900
@@ -0,0 +1,80 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ */
+public final class IteratorV2 extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new IteratorV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param sharedName 
+   * @param container 
+   * @param outputTypes 
+   * @param outputShapes 
+   * @return a new instance of IteratorV2
+   */
+  public static IteratorV2 create(Scope scope, String sharedName, String container, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("IteratorV2", scope.makeOpName("IteratorV2"));
+    opBuilder.setAttr("shared_name", sharedName);
+    opBuilder.setAttr("container", container);
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new IteratorV2(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private IteratorV2(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/L2Loss.java java-ops/org/tensorflow/op/core/L2Loss.java
--- java/org/tensorflow/op/core/L2Loss.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/L2Loss.java	2018-10-16 20:18:38.321432318 +0900
@@ -0,0 +1,72 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * L2 Loss.
+ * <p>
+ * Computes half the L2 norm of a tensor without the `sqrt`:
+ * <p>
+ *     output = sum(t ** 2) / 2
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class L2Loss<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new L2Loss operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param t Typically 2-D, but may have any dimensions.
+   * @return a new instance of L2Loss
+   */
+  public static <T extends Number> L2Loss<T> create(Scope scope, Operand<T> t) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("L2Loss", scope.makeOpName("L2Loss"));
+    opBuilder.addInput(t.asOutput());
+    return new L2Loss<T>(opBuilder.build());
+  }
+  
+  /**
+   * 0-D.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private L2Loss(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/LatencyStatsDataset.java java-ops/org/tensorflow/op/core/LatencyStatsDataset.java
--- java/org/tensorflow/op/core/LatencyStatsDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/LatencyStatsDataset.java	2018-10-16 20:18:38.323432317 +0900
@@ -0,0 +1,83 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Records the latency of producing `input_dataset` elements in a StatsAggregator.
+ */
+@Operator
+public final class LatencyStatsDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new LatencyStatsDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputDataset 
+   * @param tag 
+   * @param outputTypes 
+   * @param outputShapes 
+   * @return a new instance of LatencyStatsDataset
+   */
+  public static LatencyStatsDataset create(Scope scope, Operand<?> inputDataset, Operand<String> tag, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("LatencyStatsDataset", scope.makeOpName("LatencyStatsDataset"));
+    opBuilder.addInput(inputDataset.asOutput());
+    opBuilder.addInput(tag.asOutput());
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new LatencyStatsDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private LatencyStatsDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/LearnedUnigramCandidateSampler.java java-ops/org/tensorflow/op/core/LearnedUnigramCandidateSampler.java
--- java/org/tensorflow/op/core/LearnedUnigramCandidateSampler.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/LearnedUnigramCandidateSampler.java	2018-10-16 20:18:38.324432316 +0900
@@ -0,0 +1,163 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Generates labels for candidate sampling with a learned unigram distribution.
+ * <p>
+ * See explanations of candidate sampling and the data formats at
+ * go/candidate-sampling.
+ * <p>
+ * For each batch, this op picks a single set of sampled candidate labels.
+ * <p>
+ * The advantages of sampling candidates per-batch are simplicity and the
+ * possibility of efficient dense matrix multiplication. The disadvantage is that
+ * the sampled candidates must be chosen independently of the context and of the
+ * true labels.
+ */
+@Operator
+public final class LearnedUnigramCandidateSampler extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.LearnedUnigramCandidateSampler}
+   */
+  public static class Options {
+    
+    /**
+     * @param seed If either seed or seed2 are set to be non-zero, the random number
+     * generator is seeded by the given seed.  Otherwise, it is seeded by a
+     * random seed.
+     */
+    public Options seed(Long seed) {
+      this.seed = seed;
+      return this;
+    }
+    
+    /**
+     * @param seed2 An second seed to avoid seed collision.
+     */
+    public Options seed2(Long seed2) {
+      this.seed2 = seed2;
+      return this;
+    }
+    
+    private Long seed;
+    private Long seed2;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new LearnedUnigramCandidateSampler operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param trueClasses A batch_size * num_true matrix, in which each row contains the
+   * IDs of the num_true target_classes in the corresponding original label.
+   * @param numTrue Number of true labels per context.
+   * @param numSampled Number of candidates to randomly sample.
+   * @param unique If unique is true, we sample with rejection, so that all sampled
+   * candidates in a batch are unique. This requires some approximation to
+   * estimate the post-rejection sampling probabilities.
+   * @param rangeMax The sampler will sample integers from the interval [0, range_max).
+   * @param options carries optional attributes values
+   * @return a new instance of LearnedUnigramCandidateSampler
+   */
+  public static LearnedUnigramCandidateSampler create(Scope scope, Operand<Long> trueClasses, Long numTrue, Long numSampled, Boolean unique, Long rangeMax, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("LearnedUnigramCandidateSampler", scope.makeOpName("LearnedUnigramCandidateSampler"));
+    opBuilder.addInput(trueClasses.asOutput());
+    opBuilder.setAttr("num_true", numTrue);
+    opBuilder.setAttr("num_sampled", numSampled);
+    opBuilder.setAttr("unique", unique);
+    opBuilder.setAttr("range_max", rangeMax);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.seed != null) {
+          opBuilder.setAttr("seed", opts.seed);
+        }
+        if (opts.seed2 != null) {
+          opBuilder.setAttr("seed2", opts.seed2);
+        }
+      }
+    }
+    return new LearnedUnigramCandidateSampler(opBuilder.build());
+  }
+  
+  /**
+   * @param seed If either seed or seed2 are set to be non-zero, the random number
+   * generator is seeded by the given seed.  Otherwise, it is seeded by a
+   * random seed.
+   */
+  public static Options seed(Long seed) {
+    return new Options().seed(seed);
+  }
+  
+  /**
+   * @param seed2 An second seed to avoid seed collision.
+   */
+  public static Options seed2(Long seed2) {
+    return new Options().seed2(seed2);
+  }
+  
+  /**
+   * A vector of length num_sampled, in which each element is
+   * the ID of a sampled candidate.
+   */
+  public Output<Long> sampledCandidates() {
+    return sampledCandidates;
+  }
+  
+  /**
+   * A batch_size * num_true matrix, representing
+   * the number of times each candidate is expected to occur in a batch
+   * of sampled candidates. If unique=true, then this is a probability.
+   */
+  public Output<Float> trueExpectedCount() {
+    return trueExpectedCount;
+  }
+  
+  /**
+   * A vector of length num_sampled, for each sampled
+   * candidate representing the number of times the candidate is expected
+   * to occur in a batch of sampled candidates.  If unique=true, then this is a
+   * probability.
+   */
+  public Output<Float> sampledExpectedCount() {
+    return sampledExpectedCount;
+  }
+  
+  private Output<Long> sampledCandidates;
+  private Output<Float> trueExpectedCount;
+  private Output<Float> sampledExpectedCount;
+  
+  private LearnedUnigramCandidateSampler(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    sampledCandidates = operation.output(outputIdx++);
+    trueExpectedCount = operation.output(outputIdx++);
+    sampledExpectedCount = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/LeftShift.java java-ops/org/tensorflow/op/core/LeftShift.java
--- java/org/tensorflow/op/core/LeftShift.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/LeftShift.java	2018-10-16 20:18:38.324432316 +0900
@@ -0,0 +1,72 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Elementwise computes the bitwise left-shift of `x` and `y`.
+ * <p>
+ * If `y` is negative, or greater than or equal to the width of `x` in bits the
+ * result is implementation defined.
+ * 
+ * @param <T> data type for {@code z()} output
+ */
+@Operator
+public final class LeftShift<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new LeftShift operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param y 
+   * @return a new instance of LeftShift
+   */
+  public static <T extends Number> LeftShift<T> create(Scope scope, Operand<T> x, Operand<T> y) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("LeftShift", scope.makeOpName("LeftShift"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(y.asOutput());
+    return new LeftShift<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return z;
+  }
+  
+  private Output<T> z;
+  
+  private LeftShift(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/LessEqual.java java-ops/org/tensorflow/op/core/LessEqual.java
--- java/org/tensorflow/op/core/LessEqual.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/LessEqual.java	2018-10-16 20:18:38.325432315 +0900
@@ -0,0 +1,70 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns the truth value of (x <= y) element-wise.
+ * <p>
+ * <i>NOTE</i>: `LessEqual` supports broadcasting. More about broadcasting
+ * [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
+ */
+@Operator
+public final class LessEqual extends PrimitiveOp implements Operand<Boolean> {
+  
+  /**
+   * Factory method to create a class to wrap a new LessEqual operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param y 
+   * @return a new instance of LessEqual
+   */
+  public static <T extends Number> LessEqual create(Scope scope, Operand<T> x, Operand<T> y) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("LessEqual", scope.makeOpName("LessEqual"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(y.asOutput());
+    return new LessEqual(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<Boolean> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<Boolean> asOutput() {
+    return z;
+  }
+  
+  private Output<Boolean> z;
+  
+  private LessEqual(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Less.java java-ops/org/tensorflow/op/core/Less.java
--- java/org/tensorflow/op/core/Less.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Less.java	2018-10-16 20:18:38.324432316 +0900
@@ -0,0 +1,70 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns the truth value of (x < y) element-wise.
+ * <p>
+ * <i>NOTE</i>: `Less` supports broadcasting. More about broadcasting
+ * [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
+ */
+@Operator
+public final class Less extends PrimitiveOp implements Operand<Boolean> {
+  
+  /**
+   * Factory method to create a class to wrap a new Less operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param y 
+   * @return a new instance of Less
+   */
+  public static <T extends Number> Less create(Scope scope, Operand<T> x, Operand<T> y) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Less", scope.makeOpName("Less"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(y.asOutput());
+    return new Less(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<Boolean> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<Boolean> asOutput() {
+    return z;
+  }
+  
+  private Output<Boolean> z;
+  
+  private Less(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Lgamma.java java-ops/org/tensorflow/op/core/Lgamma.java
--- java/org/tensorflow/op/core/Lgamma.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Lgamma.java	2018-10-16 20:18:38.325432315 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the log of the absolute value of `Gamma(x)` element-wise.
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class Lgamma<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Lgamma operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of Lgamma
+   */
+  public static <T extends Number> Lgamma<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Lgamma", scope.makeOpName("Lgamma"));
+    opBuilder.addInput(x.asOutput());
+    return new Lgamma<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private Lgamma(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/LinSpace.java java-ops/org/tensorflow/op/core/LinSpace.java
--- java/org/tensorflow/op/core/LinSpace.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/LinSpace.java	2018-10-16 20:18:38.326432315 +0900
@@ -0,0 +1,82 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Generates values in an interval.
+ * <p>
+ * A sequence of `num` evenly-spaced values are generated beginning at `start`.
+ * If `num > 1`, the values in the sequence increase by `stop - start / num - 1`,
+ * so that the last one is exactly `stop`.
+ * <p>
+ * For example:
+ * <pre>{@code
+ * tf.linspace(10.0, 12.0, 3, name="linspace") => [ 10.0  11.0  12.0]
+ * }</pre>
+ * 
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class LinSpace<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new LinSpace operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param start 0-D tensor. First entry in the range.
+   * @param stop 0-D tensor. Last entry in the range.
+   * @param num 0-D tensor. Number of values to generate.
+   * @return a new instance of LinSpace
+   */
+  public static <T extends Number, U extends Number> LinSpace<T> create(Scope scope, Operand<T> start, Operand<T> stop, Operand<U> num) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("LinSpace", scope.makeOpName("LinSpace"));
+    opBuilder.addInput(start.asOutput());
+    opBuilder.addInput(stop.asOutput());
+    opBuilder.addInput(num.asOutput());
+    return new LinSpace<T>(opBuilder.build());
+  }
+  
+  /**
+   * 1-D. The generated values.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private LinSpace(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/LMDBReader.java java-ops/org/tensorflow/op/core/LMDBReader.java
--- java/org/tensorflow/op/core/LMDBReader.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/LMDBReader.java	2018-10-16 20:18:38.321432318 +0900
@@ -0,0 +1,121 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * A Reader that outputs the records from a LMDB file.
+ */
+@Operator
+public final class LMDBReader extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.LMDBReader}
+   */
+  public static class Options {
+    
+    /**
+     * @param container If non-empty, this reader is placed in the given container.
+     * Otherwise, a default container is used.
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName If non-empty, this reader is named in the given bucket
+     * with this shared_name. Otherwise, the node name is used instead.
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new LMDBReader operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param options carries optional attributes values
+   * @return a new instance of LMDBReader
+   */
+  public static LMDBReader create(Scope scope, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("LMDBReader", scope.makeOpName("LMDBReader"));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new LMDBReader(opBuilder.build());
+  }
+  
+  /**
+   * @param container If non-empty, this reader is placed in the given container.
+   * Otherwise, a default container is used.
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName If non-empty, this reader is named in the given bucket
+   * with this shared_name. Otherwise, the node name is used instead.
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   * The handle to reference the Reader.
+   */
+  public Output<String> readerHandle() {
+    return readerHandle;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return readerHandle;
+  }
+  
+  private Output<String> readerHandle;
+  
+  private LMDBReader(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    readerHandle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/LoadAndRemapMatrix.java java-ops/org/tensorflow/op/core/LoadAndRemapMatrix.java
--- java/org/tensorflow/op/core/LoadAndRemapMatrix.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/LoadAndRemapMatrix.java	2018-10-16 20:18:38.328432313 +0900
@@ -0,0 +1,166 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Loads a 2-D (matrix) `Tensor` with name `old_tensor_name` from the checkpoint
+ * <p>
+ * at `ckpt_path` and potentially reorders its rows and columns using the
+ * specified remappings.
+ * <p>
+ * Most users should use one of the wrapper initializers (such as
+ * `tf.contrib.framework.load_and_remap_matrix_initializer`) instead of this
+ * function directly.
+ * <p>
+ * The remappings are 1-D tensors with the following properties:
+ * <ul>
+ * <li>
+ * `row_remapping` must have exactly `num_rows` entries. Row `i` of the output
+ *   matrix will be initialized from the row corresponding to index
+ *   `row_remapping[i]` in the old `Tensor` from the checkpoint.
+ * </li>
+ * <li>
+ * `col_remapping` must have either 0 entries (indicating that no column
+ *   reordering is needed) or `num_cols` entries. If specified, column `j` of the
+ *   output matrix will be initialized from the column corresponding to index
+ *   `col_remapping[j]` in the old `Tensor` from the checkpoint.
+ * </li>
+ * <li>
+ * A value of -1 in either of the remappings signifies a "missing" entry. In that
+ *   case, values from the `initializing_values` tensor will be used to fill that
+ *   missing row or column. If `row_remapping` has `r` missing entries and
+ *   `col_remapping` has `c` missing entries, then the following condition must be
+ *   true:
+ * </li>
+ * </ul>
+ * `(r * num_cols) + (c * num_rows) - (r * c) == len(initializing_values)`
+ * <p>
+ * The remapping tensors can be generated using the GenerateVocabRemapping op.
+ * <p>
+ * As an example, with row_remapping = [1, 0, -1], col_remapping = [0, 2, -1],
+ * initializing_values = [0.5, -0.5, 0.25, -0.25, 42], and w(i, j) representing
+ * the value from row i, column j of the old tensor in the checkpoint, the output
+ * matrix will look like the following:
+ * <p>
+ * [[w(1, 0),  w(1, 2),  0.5],
+ *  [w(0, 0),  w(0, 2), -0.5],
+ *  [0.25,    -0.25,      42]]
+ */
+@Operator
+public final class LoadAndRemapMatrix extends PrimitiveOp implements Operand<Float> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.LoadAndRemapMatrix}
+   */
+  public static class Options {
+    
+    /**
+     * @param maxRowsInMemory The maximum number of rows to load from the checkpoint at
+     * once. If less than or equal to 0, the entire matrix will be loaded into
+     * memory. Setting this arg trades increased disk reads for lower memory usage.
+     */
+    public Options maxRowsInMemory(Long maxRowsInMemory) {
+      this.maxRowsInMemory = maxRowsInMemory;
+      return this;
+    }
+    
+    private Long maxRowsInMemory;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new LoadAndRemapMatrix operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param ckptPath Path to the TensorFlow checkpoint (version 2, `TensorBundle`) from
+   * which the old matrix `Tensor` will be loaded.
+   * @param oldTensorName Name of the 2-D `Tensor` to load from checkpoint.
+   * @param rowRemapping An int `Tensor` of row remappings (generally created by
+   * `generate_vocab_remapping`).  Even if no row remapping is needed, this must
+   * still be an index-valued Tensor (e.g. [0, 1, 2, ...]), or a shifted
+   * index-valued `Tensor` (e.g. [8, 9, 10, ...], for partitioned `Variables`).
+   * @param colRemapping An int `Tensor` of column remappings (generally created by
+   * `generate_vocab_remapping`).  May be a size-0 `Tensor` if only row remapping
+   * is to be done (e.g. column ordering is the same).
+   * @param initializingValues A float `Tensor` containing  values to fill in for cells
+   * in the output matrix that are not loaded from the checkpoint. Length must be
+   * exactly the same as the number of missing / new cells.
+   * @param numRows Number of rows (length of the 1st dimension) in the output matrix.
+   * @param numCols Number of columns (length of the 2nd dimension) in the output matrix.
+   * @param options carries optional attributes values
+   * @return a new instance of LoadAndRemapMatrix
+   */
+  public static LoadAndRemapMatrix create(Scope scope, Operand<String> ckptPath, Operand<String> oldTensorName, Operand<Long> rowRemapping, Operand<Long> colRemapping, Operand<Float> initializingValues, Long numRows, Long numCols, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("LoadAndRemapMatrix", scope.makeOpName("LoadAndRemapMatrix"));
+    opBuilder.addInput(ckptPath.asOutput());
+    opBuilder.addInput(oldTensorName.asOutput());
+    opBuilder.addInput(rowRemapping.asOutput());
+    opBuilder.addInput(colRemapping.asOutput());
+    opBuilder.addInput(initializingValues.asOutput());
+    opBuilder.setAttr("num_rows", numRows);
+    opBuilder.setAttr("num_cols", numCols);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.maxRowsInMemory != null) {
+          opBuilder.setAttr("max_rows_in_memory", opts.maxRowsInMemory);
+        }
+      }
+    }
+    return new LoadAndRemapMatrix(opBuilder.build());
+  }
+  
+  /**
+   * @param maxRowsInMemory The maximum number of rows to load from the checkpoint at
+   * once. If less than or equal to 0, the entire matrix will be loaded into
+   * memory. Setting this arg trades increased disk reads for lower memory usage.
+   */
+  public static Options maxRowsInMemory(Long maxRowsInMemory) {
+    return new Options().maxRowsInMemory(maxRowsInMemory);
+  }
+  
+  /**
+   * Output matrix containing existing values loaded from the
+   * checkpoint, and with any missing values filled in from initializing_values.
+   */
+  public Output<Float> outputMatrix() {
+    return outputMatrix;
+  }
+  
+  @Override
+  public Output<Float> asOutput() {
+    return outputMatrix;
+  }
+  
+  private Output<Float> outputMatrix;
+  
+  private LoadAndRemapMatrix(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    outputMatrix = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Log1p.java java-ops/org/tensorflow/op/core/Log1p.java
--- java/org/tensorflow/op/core/Log1p.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Log1p.java	2018-10-16 20:18:38.328432313 +0900
@@ -0,0 +1,69 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes natural logarithm of (1 + x) element-wise.
+ * <p>
+ * I.e., \\(y = \log_e (1 + x)\\).
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class Log1p<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Log1p operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of Log1p
+   */
+  public static <T> Log1p<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Log1p", scope.makeOpName("Log1p"));
+    opBuilder.addInput(x.asOutput());
+    return new Log1p<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private Log1p(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/LogicalAnd.java java-ops/org/tensorflow/op/core/LogicalAnd.java
--- java/org/tensorflow/op/core/LogicalAnd.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/LogicalAnd.java	2018-10-16 20:18:38.330432312 +0900
@@ -0,0 +1,70 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns the truth value of x AND y element-wise.
+ * <p>
+ * <i>NOTE</i>: `LogicalAnd` supports broadcasting. More about broadcasting
+ * [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
+ */
+@Operator
+public final class LogicalAnd extends PrimitiveOp implements Operand<Boolean> {
+  
+  /**
+   * Factory method to create a class to wrap a new LogicalAnd operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param y 
+   * @return a new instance of LogicalAnd
+   */
+  public static LogicalAnd create(Scope scope, Operand<Boolean> x, Operand<Boolean> y) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("LogicalAnd", scope.makeOpName("LogicalAnd"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(y.asOutput());
+    return new LogicalAnd(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<Boolean> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<Boolean> asOutput() {
+    return z;
+  }
+  
+  private Output<Boolean> z;
+  
+  private LogicalAnd(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/LogicalNot.java java-ops/org/tensorflow/op/core/LogicalNot.java
--- java/org/tensorflow/op/core/LogicalNot.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/LogicalNot.java	2018-10-16 20:18:38.330432312 +0900
@@ -0,0 +1,65 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns the truth value of NOT x element-wise.
+ */
+@Operator
+public final class LogicalNot extends PrimitiveOp implements Operand<Boolean> {
+  
+  /**
+   * Factory method to create a class to wrap a new LogicalNot operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of LogicalNot
+   */
+  public static LogicalNot create(Scope scope, Operand<Boolean> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("LogicalNot", scope.makeOpName("LogicalNot"));
+    opBuilder.addInput(x.asOutput());
+    return new LogicalNot(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<Boolean> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<Boolean> asOutput() {
+    return y;
+  }
+  
+  private Output<Boolean> y;
+  
+  private LogicalNot(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/LogicalOr.java java-ops/org/tensorflow/op/core/LogicalOr.java
--- java/org/tensorflow/op/core/LogicalOr.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/LogicalOr.java	2018-10-16 20:18:38.331432311 +0900
@@ -0,0 +1,70 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns the truth value of x OR y element-wise.
+ * <p>
+ * <i>NOTE</i>: `LogicalOr` supports broadcasting. More about broadcasting
+ * [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
+ */
+@Operator
+public final class LogicalOr extends PrimitiveOp implements Operand<Boolean> {
+  
+  /**
+   * Factory method to create a class to wrap a new LogicalOr operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param y 
+   * @return a new instance of LogicalOr
+   */
+  public static LogicalOr create(Scope scope, Operand<Boolean> x, Operand<Boolean> y) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("LogicalOr", scope.makeOpName("LogicalOr"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(y.asOutput());
+    return new LogicalOr(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<Boolean> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<Boolean> asOutput() {
+    return z;
+  }
+  
+  private Output<Boolean> z;
+  
+  private LogicalOr(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Log.java java-ops/org/tensorflow/op/core/Log.java
--- java/org/tensorflow/op/core/Log.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Log.java	2018-10-16 20:18:38.328432313 +0900
@@ -0,0 +1,69 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes natural logarithm of x element-wise.
+ * <p>
+ * I.e., \\(y = \log_e x\\).
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class Log<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Log operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of Log
+   */
+  public static <T> Log<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Log", scope.makeOpName("Log"));
+    opBuilder.addInput(x.asOutput());
+    return new Log<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private Log(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/LogMatrixDeterminant.java java-ops/org/tensorflow/op/core/LogMatrixDeterminant.java
--- java/org/tensorflow/op/core/LogMatrixDeterminant.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/LogMatrixDeterminant.java	2018-10-16 20:18:38.329432313 +0900
@@ -0,0 +1,83 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the sign and the log of the absolute value of the determinant of
+ * <p>
+ * one or more square matrices.
+ * <p>
+ * The input is a tensor of shape `[N, M, M]` whose inner-most 2 dimensions
+ * form square matrices. The outputs are two tensors containing the signs and
+ * absolute values of the log determinants for all N input submatrices
+ * `[..., :, :]` such that the determinant = sign*exp(log_abs_determinant).
+ * The log_abs_determinant is computed as det(P)*sum(log(diag(LU))) where LU
+ * is the LU decomposition of the input and P is the corresponding
+ * permutation matrix.
+ * 
+ * @param <T> data type for {@code sign()} output
+ */
+@Operator
+public final class LogMatrixDeterminant<T> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new LogMatrixDeterminant operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input Shape is `[N, M, M]`.
+   * @return a new instance of LogMatrixDeterminant
+   */
+  public static <T> LogMatrixDeterminant<T> create(Scope scope, Operand<T> input) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("LogMatrixDeterminant", scope.makeOpName("LogMatrixDeterminant"));
+    opBuilder.addInput(input.asOutput());
+    return new LogMatrixDeterminant<T>(opBuilder.build());
+  }
+  
+  /**
+   * The signs of the log determinants of the inputs. Shape is `[N]`.
+   */
+  public Output<T> sign() {
+    return sign;
+  }
+  
+  /**
+   * The logs of the absolute values of the determinants
+   * of the N input matrices.  Shape is `[N]`.
+   */
+  public Output<T> logAbsDeterminant() {
+    return logAbsDeterminant;
+  }
+  
+  private Output<T> sign;
+  private Output<T> logAbsDeterminant;
+  
+  private LogMatrixDeterminant(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    sign = operation.output(outputIdx++);
+    logAbsDeterminant = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/LogSoftmax.java java-ops/org/tensorflow/op/core/LogSoftmax.java
--- java/org/tensorflow/op/core/LogSoftmax.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/LogSoftmax.java	2018-10-16 20:18:38.329432313 +0900
@@ -0,0 +1,72 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes log softmax activations.
+ * <p>
+ * For each batch `i` and class `j` we have
+ * <p>
+ *     logsoftmax[i, j] = logits[i, j] - log(sum(exp(logits[i])))
+ * 
+ * @param <T> data type for {@code logsoftmax()} output
+ */
+@Operator
+public final class LogSoftmax<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new LogSoftmax operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param logits 2-D with shape `[batch_size, num_classes]`.
+   * @return a new instance of LogSoftmax
+   */
+  public static <T extends Number> LogSoftmax<T> create(Scope scope, Operand<T> logits) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("LogSoftmax", scope.makeOpName("LogSoftmax"));
+    opBuilder.addInput(logits.asOutput());
+    return new LogSoftmax<T>(opBuilder.build());
+  }
+  
+  /**
+   * Same shape as `logits`.
+   */
+  public Output<T> logsoftmax() {
+    return logsoftmax;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return logsoftmax;
+  }
+  
+  private Output<T> logsoftmax;
+  
+  private LogSoftmax(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    logsoftmax = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/LogUniformCandidateSampler.java java-ops/org/tensorflow/op/core/LogUniformCandidateSampler.java
--- java/org/tensorflow/op/core/LogUniformCandidateSampler.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/LogUniformCandidateSampler.java	2018-10-16 20:18:38.330432312 +0900
@@ -0,0 +1,163 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Generates labels for candidate sampling with a log-uniform distribution.
+ * <p>
+ * See explanations of candidate sampling and the data formats at
+ * go/candidate-sampling.
+ * <p>
+ * For each batch, this op picks a single set of sampled candidate labels.
+ * <p>
+ * The advantages of sampling candidates per-batch are simplicity and the
+ * possibility of efficient dense matrix multiplication. The disadvantage is that
+ * the sampled candidates must be chosen independently of the context and of the
+ * true labels.
+ */
+@Operator
+public final class LogUniformCandidateSampler extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.LogUniformCandidateSampler}
+   */
+  public static class Options {
+    
+    /**
+     * @param seed If either seed or seed2 are set to be non-zero, the random number
+     * generator is seeded by the given seed.  Otherwise, it is seeded by a
+     * random seed.
+     */
+    public Options seed(Long seed) {
+      this.seed = seed;
+      return this;
+    }
+    
+    /**
+     * @param seed2 An second seed to avoid seed collision.
+     */
+    public Options seed2(Long seed2) {
+      this.seed2 = seed2;
+      return this;
+    }
+    
+    private Long seed;
+    private Long seed2;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new LogUniformCandidateSampler operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param trueClasses A batch_size * num_true matrix, in which each row contains the
+   * IDs of the num_true target_classes in the corresponding original label.
+   * @param numTrue Number of true labels per context.
+   * @param numSampled Number of candidates to randomly sample.
+   * @param unique If unique is true, we sample with rejection, so that all sampled
+   * candidates in a batch are unique. This requires some approximation to
+   * estimate the post-rejection sampling probabilities.
+   * @param rangeMax The sampler will sample integers from the interval [0, range_max).
+   * @param options carries optional attributes values
+   * @return a new instance of LogUniformCandidateSampler
+   */
+  public static LogUniformCandidateSampler create(Scope scope, Operand<Long> trueClasses, Long numTrue, Long numSampled, Boolean unique, Long rangeMax, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("LogUniformCandidateSampler", scope.makeOpName("LogUniformCandidateSampler"));
+    opBuilder.addInput(trueClasses.asOutput());
+    opBuilder.setAttr("num_true", numTrue);
+    opBuilder.setAttr("num_sampled", numSampled);
+    opBuilder.setAttr("unique", unique);
+    opBuilder.setAttr("range_max", rangeMax);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.seed != null) {
+          opBuilder.setAttr("seed", opts.seed);
+        }
+        if (opts.seed2 != null) {
+          opBuilder.setAttr("seed2", opts.seed2);
+        }
+      }
+    }
+    return new LogUniformCandidateSampler(opBuilder.build());
+  }
+  
+  /**
+   * @param seed If either seed or seed2 are set to be non-zero, the random number
+   * generator is seeded by the given seed.  Otherwise, it is seeded by a
+   * random seed.
+   */
+  public static Options seed(Long seed) {
+    return new Options().seed(seed);
+  }
+  
+  /**
+   * @param seed2 An second seed to avoid seed collision.
+   */
+  public static Options seed2(Long seed2) {
+    return new Options().seed2(seed2);
+  }
+  
+  /**
+   * A vector of length num_sampled, in which each element is
+   * the ID of a sampled candidate.
+   */
+  public Output<Long> sampledCandidates() {
+    return sampledCandidates;
+  }
+  
+  /**
+   * A batch_size * num_true matrix, representing
+   * the number of times each candidate is expected to occur in a batch
+   * of sampled candidates. If unique=true, then this is a probability.
+   */
+  public Output<Float> trueExpectedCount() {
+    return trueExpectedCount;
+  }
+  
+  /**
+   * A vector of length num_sampled, for each sampled
+   * candidate representing the number of times the candidate is expected
+   * to occur in a batch of sampled candidates.  If unique=true, then this is a
+   * probability.
+   */
+  public Output<Float> sampledExpectedCount() {
+    return sampledExpectedCount;
+  }
+  
+  private Output<Long> sampledCandidates;
+  private Output<Float> trueExpectedCount;
+  private Output<Float> sampledExpectedCount;
+  
+  private LogUniformCandidateSampler(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    sampledCandidates = operation.output(outputIdx++);
+    trueExpectedCount = operation.output(outputIdx++);
+    sampledExpectedCount = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/LookupTableExport.java java-ops/org/tensorflow/op/core/LookupTableExport.java
--- java/org/tensorflow/op/core/LookupTableExport.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/LookupTableExport.java	2018-10-16 20:18:38.331432311 +0900
@@ -0,0 +1,78 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Outputs all keys and values in the table.
+ * 
+ * @param <T> data type for {@code keys()} output
+ * @param <U> data type for {@code values()} output
+ */
+@Operator
+public final class LookupTableExport<T, U> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new LookupTableExport operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param tableHandle Handle to the table.
+   * @param Tkeys 
+   * @param Tvalues 
+   * @return a new instance of LookupTableExport
+   */
+  public static <T, U> LookupTableExport<T, U> create(Scope scope, Operand<?> tableHandle, Class<T> Tkeys, Class<U> Tvalues) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("LookupTableExportV2", scope.makeOpName("LookupTableExport"));
+    opBuilder.addInput(tableHandle.asOutput());
+    opBuilder.setAttr("Tkeys", DataType.fromClass(Tkeys));
+    opBuilder.setAttr("Tvalues", DataType.fromClass(Tvalues));
+    return new LookupTableExport<T, U>(opBuilder.build());
+  }
+  
+  /**
+   * Vector of all keys present in the table.
+   */
+  public Output<T> keys() {
+    return keys;
+  }
+  
+  /**
+   * Tensor of all values in the table. Indexed in parallel with `keys`.
+   */
+  public Output<U> values() {
+    return values;
+  }
+  
+  private Output<T> keys;
+  private Output<U> values;
+  
+  private LookupTableExport(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    keys = operation.output(outputIdx++);
+    values = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/LookupTableFind.java java-ops/org/tensorflow/op/core/LookupTableFind.java
--- java/org/tensorflow/op/core/LookupTableFind.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/LookupTableFind.java	2018-10-16 20:18:38.332432311 +0900
@@ -0,0 +1,79 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Looks up keys in a table, outputs the corresponding values.
+ * <p>
+ * The tensor `keys` must of the same type as the keys of the table.
+ * The output `values` is of the type of the table values.
+ * <p>
+ * The scalar `default_value` is the value output for keys not present in the
+ * table. It must also be of the same type as the table values.
+ * 
+ * @param <U> data type for {@code values()} output
+ */
+@Operator
+public final class LookupTableFind<U> extends PrimitiveOp implements Operand<U> {
+  
+  /**
+   * Factory method to create a class to wrap a new LookupTableFind operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param tableHandle Handle to the table.
+   * @param keys Any shape.  Keys to look up.
+   * @param defaultValue 
+   * @return a new instance of LookupTableFind
+   */
+  public static <U, T> LookupTableFind<U> create(Scope scope, Operand<?> tableHandle, Operand<T> keys, Operand<U> defaultValue) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("LookupTableFindV2", scope.makeOpName("LookupTableFind"));
+    opBuilder.addInput(tableHandle.asOutput());
+    opBuilder.addInput(keys.asOutput());
+    opBuilder.addInput(defaultValue.asOutput());
+    return new LookupTableFind<U>(opBuilder.build());
+  }
+  
+  /**
+   * Same shape as `keys`.  Values found in the table, or `default_values`
+   * for missing keys.
+   */
+  public Output<U> values() {
+    return values;
+  }
+  
+  @Override
+  public Output<U> asOutput() {
+    return values;
+  }
+  
+  private Output<U> values;
+  
+  private LookupTableFind(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    values = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/LookupTableImport.java java-ops/org/tensorflow/op/core/LookupTableImport.java
--- java/org/tensorflow/op/core/LookupTableImport.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/LookupTableImport.java	2018-10-16 20:18:38.332432311 +0900
@@ -0,0 +1,57 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Replaces the contents of the table with the specified keys and values.
+ * <p>
+ * The tensor `keys` must be of the same type as the keys of the table.
+ * The tensor `values` must be of the type of the table values.
+ */
+@Operator
+public final class LookupTableImport extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new LookupTableImport operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param tableHandle Handle to the table.
+   * @param keys Any shape.  Keys to look up.
+   * @param values Values to associate with keys.
+   * @return a new instance of LookupTableImport
+   */
+  public static <T, U> LookupTableImport create(Scope scope, Operand<?> tableHandle, Operand<T> keys, Operand<U> values) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("LookupTableImportV2", scope.makeOpName("LookupTableImport"));
+    opBuilder.addInput(tableHandle.asOutput());
+    opBuilder.addInput(keys.asOutput());
+    opBuilder.addInput(values.asOutput());
+    return new LookupTableImport(opBuilder.build());
+  }
+  
+  
+  private LookupTableImport(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/LookupTableInsert.java java-ops/org/tensorflow/op/core/LookupTableInsert.java
--- java/org/tensorflow/op/core/LookupTableInsert.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/LookupTableInsert.java	2018-10-16 20:18:38.332432311 +0900
@@ -0,0 +1,57 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Updates the table to associates keys with values.
+ * <p>
+ * The tensor `keys` must be of the same type as the keys of the table.
+ * The tensor `values` must be of the type of the table values.
+ */
+@Operator
+public final class LookupTableInsert extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new LookupTableInsert operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param tableHandle Handle to the table.
+   * @param keys Any shape.  Keys to look up.
+   * @param values Values to associate with keys.
+   * @return a new instance of LookupTableInsert
+   */
+  public static <T, U> LookupTableInsert create(Scope scope, Operand<?> tableHandle, Operand<T> keys, Operand<U> values) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("LookupTableInsertV2", scope.makeOpName("LookupTableInsert"));
+    opBuilder.addInput(tableHandle.asOutput());
+    opBuilder.addInput(keys.asOutput());
+    opBuilder.addInput(values.asOutput());
+    return new LookupTableInsert(opBuilder.build());
+  }
+  
+  
+  private LookupTableInsert(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/LookupTableSize.java java-ops/org/tensorflow/op/core/LookupTableSize.java
--- java/org/tensorflow/op/core/LookupTableSize.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/LookupTableSize.java	2018-10-16 20:18:38.332432311 +0900
@@ -0,0 +1,66 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the number of elements in the given table.
+ */
+@Operator
+public final class LookupTableSize extends PrimitiveOp implements Operand<Long> {
+  
+  /**
+   * Factory method to create a class to wrap a new LookupTableSize operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param tableHandle Handle to the table.
+   * @return a new instance of LookupTableSize
+   */
+  public static LookupTableSize create(Scope scope, Operand<?> tableHandle) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("LookupTableSizeV2", scope.makeOpName("LookupTableSize"));
+    opBuilder.addInput(tableHandle.asOutput());
+    return new LookupTableSize(opBuilder.build());
+  }
+  
+  /**
+   * Scalar that contains number of elements in the table.
+   */
+  public Output<Long> size() {
+    return size;
+  }
+  
+  @Override
+  public Output<Long> asOutput() {
+    return size;
+  }
+  
+  private Output<Long> size;
+  
+  private LookupTableSize(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    size = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/LoopCond.java java-ops/org/tensorflow/op/core/LoopCond.java
--- java/org/tensorflow/op/core/LoopCond.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/LoopCond.java	2018-10-16 20:18:38.332432311 +0900
@@ -0,0 +1,69 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Forwards the input to the output.
+ * <p>
+ * This operator represents the loop termination condition used by the
+ * "pivot" switches of a loop.
+ */
+@Operator
+public final class LoopCond extends PrimitiveOp implements Operand<Boolean> {
+  
+  /**
+   * Factory method to create a class to wrap a new LoopCond operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input A boolean scalar, representing the branch predicate of the Switch op.
+   * @return a new instance of LoopCond
+   */
+  public static LoopCond create(Scope scope, Operand<Boolean> input) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("LoopCond", scope.makeOpName("LoopCond"));
+    opBuilder.addInput(input.asOutput());
+    return new LoopCond(opBuilder.build());
+  }
+  
+  /**
+   * The same tensor as `input`.
+   */
+  public Output<Boolean> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<Boolean> asOutput() {
+    return output;
+  }
+  
+  private Output<Boolean> output;
+  
+  private LoopCond(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/LowerBound.java java-ops/org/tensorflow/op/core/LowerBound.java
--- java/org/tensorflow/op/core/LowerBound.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/LowerBound.java	2018-10-16 20:18:38.333432310 +0900
@@ -0,0 +1,105 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Applies lower_bound(sorted_search_values, values) along each row.
+ * <p>
+ * Each set of rows with the same index in (sorted_inputs, values) is treated
+ * independently.  The resulting row is the equivalent of calling
+ * `np.searchsorted(sorted_inputs, values, side='left')`.
+ * <p>
+ * The result is not a global index to the entire 
+ * `Tensor`, but rather just the index in the last dimension.
+ * <p>
+ * A 2-D example:
+ *   sorted_sequence = [[0, 3, 9, 9, 10],
+ *                      [1, 2, 3, 4, 5]]
+ *   values = [[2, 4, 9],
+ *             [0, 2, 6]]
+ * <p>
+ *   result = LowerBound(sorted_sequence, values)
+ * <p>
+ *   result == [[1, 2, 2],
+ *              [0, 1, 5]]
+ * 
+ * @param <U> data type for {@code output()} output
+ */
+public final class LowerBound<U extends Number> extends PrimitiveOp implements Operand<U> {
+  
+  /**
+   * Factory method to create a class to wrap a new LowerBound operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param sortedInputs 2-D Tensor where each row is ordered.
+   * @param values 2-D Tensor with the same numbers of rows as `sorted_search_values`. Contains
+   * the values that will be searched for in `sorted_search_values`.
+   * @param outType 
+   * @return a new instance of LowerBound
+   */
+  public static <U extends Number, T> LowerBound<U> create(Scope scope, Operand<T> sortedInputs, Operand<T> values, Class<U> outType) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("LowerBound", scope.makeOpName("LowerBound"));
+    opBuilder.addInput(sortedInputs.asOutput());
+    opBuilder.addInput(values.asOutput());
+    opBuilder.setAttr("out_type", DataType.fromClass(outType));
+    return new LowerBound<U>(opBuilder.build());
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new LowerBound operation to the graph, using default output types.
+   * 
+   * @param scope current graph scope
+   * @param sortedInputs 2-D Tensor where each row is ordered.
+   * @param values 2-D Tensor with the same numbers of rows as `sorted_search_values`. Contains
+   * the values that will be searched for in `sorted_search_values`.
+   * @return a new instance of LowerBound
+   */
+  public static <T> LowerBound<Integer> create(Scope scope, Operand<T> sortedInputs, Operand<T> values) {
+    return create(scope, sortedInputs, values, Integer.class);
+  }
+  
+  /**
+   * A `Tensor` with the same shape as `values`.  It contains the first scalar index
+   * into the last dimension where values can be inserted without changing the
+   * ordered property.
+   */
+  public Output<U> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<U> asOutput() {
+    return output;
+  }
+  
+  private Output<U> output;
+  
+  private LowerBound(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/LRNGrad.java java-ops/org/tensorflow/op/core/LRNGrad.java
--- java/org/tensorflow/op/core/LRNGrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/LRNGrad.java	2018-10-16 20:18:38.323432317 +0900
@@ -0,0 +1,161 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Gradients for Local Response Normalization.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+public final class LRNGrad<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.LRNGrad}
+   */
+  public static class Options {
+    
+    /**
+     * @param depthRadius A depth radius.
+     */
+    public Options depthRadius(Long depthRadius) {
+      this.depthRadius = depthRadius;
+      return this;
+    }
+    
+    /**
+     * @param bias An offset (usually > 0 to avoid dividing by 0).
+     */
+    public Options bias(Float bias) {
+      this.bias = bias;
+      return this;
+    }
+    
+    /**
+     * @param alpha A scale factor, usually positive.
+     */
+    public Options alpha(Float alpha) {
+      this.alpha = alpha;
+      return this;
+    }
+    
+    /**
+     * @param beta An exponent.
+     */
+    public Options beta(Float beta) {
+      this.beta = beta;
+      return this;
+    }
+    
+    private Long depthRadius;
+    private Float bias;
+    private Float alpha;
+    private Float beta;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new LRNGrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputGrads 4-D with shape `[batch, height, width, channels]`.
+   * @param inputImage 4-D with shape `[batch, height, width, channels]`.
+   * @param outputImage 4-D with shape `[batch, height, width, channels]`.
+   * @param options carries optional attributes values
+   * @return a new instance of LRNGrad
+   */
+  public static <T extends Number> LRNGrad<T> create(Scope scope, Operand<T> inputGrads, Operand<T> inputImage, Operand<T> outputImage, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("LRNGrad", scope.makeOpName("LRNGrad"));
+    opBuilder.addInput(inputGrads.asOutput());
+    opBuilder.addInput(inputImage.asOutput());
+    opBuilder.addInput(outputImage.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.depthRadius != null) {
+          opBuilder.setAttr("depth_radius", opts.depthRadius);
+        }
+        if (opts.bias != null) {
+          opBuilder.setAttr("bias", opts.bias);
+        }
+        if (opts.alpha != null) {
+          opBuilder.setAttr("alpha", opts.alpha);
+        }
+        if (opts.beta != null) {
+          opBuilder.setAttr("beta", opts.beta);
+        }
+      }
+    }
+    return new LRNGrad<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param depthRadius A depth radius.
+   */
+  public static Options depthRadius(Long depthRadius) {
+    return new Options().depthRadius(depthRadius);
+  }
+  
+  /**
+   * @param bias An offset (usually > 0 to avoid dividing by 0).
+   */
+  public static Options bias(Float bias) {
+    return new Options().bias(bias);
+  }
+  
+  /**
+   * @param alpha A scale factor, usually positive.
+   */
+  public static Options alpha(Float alpha) {
+    return new Options().alpha(alpha);
+  }
+  
+  /**
+   * @param beta An exponent.
+   */
+  public static Options beta(Float beta) {
+    return new Options().beta(beta);
+  }
+  
+  /**
+   * The gradients for LRN.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private LRNGrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/LRN.java java-ops/org/tensorflow/op/core/LRN.java
--- java/org/tensorflow/op/core/LRN.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/LRN.java	2018-10-16 20:18:38.322432318 +0900
@@ -0,0 +1,170 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Local Response Normalization.
+ * <p>
+ * The 4-D `input` tensor is treated as a 3-D array of 1-D vectors (along the last
+ * dimension), and each vector is normalized independently.  Within a given vector,
+ * each component is divided by the weighted, squared sum of inputs within
+ * `depth_radius`.  In detail,
+ * <p>
+ *     sqr_sum[a, b, c, d] =
+ *         sum(input[a, b, c, d - depth_radius : d + depth_radius + 1] ** 2)
+ *     output = input / (bias + alpha * sqr_sum) ** beta
+ * <p>
+ * For details, see [Krizhevsky et al., ImageNet classification with deep
+ * convolutional neural networks (NIPS 2012)](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks).
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class LRN<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.LRN}
+   */
+  public static class Options {
+    
+    /**
+     * @param depthRadius 0-D.  Half-width of the 1-D normalization window.
+     */
+    public Options depthRadius(Long depthRadius) {
+      this.depthRadius = depthRadius;
+      return this;
+    }
+    
+    /**
+     * @param bias An offset (usually positive to avoid dividing by 0).
+     */
+    public Options bias(Float bias) {
+      this.bias = bias;
+      return this;
+    }
+    
+    /**
+     * @param alpha A scale factor, usually positive.
+     */
+    public Options alpha(Float alpha) {
+      this.alpha = alpha;
+      return this;
+    }
+    
+    /**
+     * @param beta An exponent.
+     */
+    public Options beta(Float beta) {
+      this.beta = beta;
+      return this;
+    }
+    
+    private Long depthRadius;
+    private Float bias;
+    private Float alpha;
+    private Float beta;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new LRN operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 4-D.
+   * @param options carries optional attributes values
+   * @return a new instance of LRN
+   */
+  public static <T extends Number> LRN<T> create(Scope scope, Operand<T> input, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("LRN", scope.makeOpName("LRN"));
+    opBuilder.addInput(input.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.depthRadius != null) {
+          opBuilder.setAttr("depth_radius", opts.depthRadius);
+        }
+        if (opts.bias != null) {
+          opBuilder.setAttr("bias", opts.bias);
+        }
+        if (opts.alpha != null) {
+          opBuilder.setAttr("alpha", opts.alpha);
+        }
+        if (opts.beta != null) {
+          opBuilder.setAttr("beta", opts.beta);
+        }
+      }
+    }
+    return new LRN<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param depthRadius 0-D.  Half-width of the 1-D normalization window.
+   */
+  public static Options depthRadius(Long depthRadius) {
+    return new Options().depthRadius(depthRadius);
+  }
+  
+  /**
+   * @param bias An offset (usually positive to avoid dividing by 0).
+   */
+  public static Options bias(Float bias) {
+    return new Options().bias(bias);
+  }
+  
+  /**
+   * @param alpha A scale factor, usually positive.
+   */
+  public static Options alpha(Float alpha) {
+    return new Options().alpha(alpha);
+  }
+  
+  /**
+   * @param beta An exponent.
+   */
+  public static Options beta(Float beta) {
+    return new Options().beta(beta);
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private LRN(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MakeIterator.java java-ops/org/tensorflow/op/core/MakeIterator.java
--- java/org/tensorflow/op/core/MakeIterator.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MakeIterator.java	2018-10-16 20:18:38.333432310 +0900
@@ -0,0 +1,55 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Makes a new iterator from the given `dataset` and stores it in `iterator`.
+ * <p>
+ * This operation may be executed multiple times. Each execution will reset the
+ * iterator in `iterator` to the first element of `dataset`.
+ */
+@Operator
+public final class MakeIterator extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new MakeIterator operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param dataset 
+   * @param iterator 
+   * @return a new instance of MakeIterator
+   */
+  public static MakeIterator create(Scope scope, Operand<?> dataset, Operand<?> iterator) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MakeIterator", scope.makeOpName("MakeIterator"));
+    opBuilder.addInput(dataset.asOutput());
+    opBuilder.addInput(iterator.asOutput());
+    return new MakeIterator(opBuilder.build());
+  }
+  
+  
+  private MakeIterator(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MapClear.java java-ops/org/tensorflow/op/core/MapClear.java
--- java/org/tensorflow/op/core/MapClear.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MapClear.java	2018-10-16 20:18:38.334432309 +0900
@@ -0,0 +1,146 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Op removes all elements in the underlying container.
+ */
+@Operator
+public final class MapClear extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.MapClear}
+   */
+  public static class Options {
+    
+    /**
+     * @param capacity 
+     */
+    public Options capacity(Long capacity) {
+      this.capacity = capacity;
+      return this;
+    }
+    
+    /**
+     * @param memoryLimit 
+     */
+    public Options memoryLimit(Long memoryLimit) {
+      this.memoryLimit = memoryLimit;
+      return this;
+    }
+    
+    /**
+     * @param container 
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName 
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private Long capacity;
+    private Long memoryLimit;
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new MapClear operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param dtypes 
+   * @param options carries optional attributes values
+   * @return a new instance of MapClear
+   */
+  public static MapClear create(Scope scope, List<Class<?>> dtypes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MapClear", scope.makeOpName("MapClear"));
+    DataType[] dtypesArray = new DataType[dtypes.size()];
+    for (int i = 0; i < dtypesArray.length; ++i) {
+      dtypesArray[i] = DataType.fromClass(dtypes.get(i));
+    }
+    opBuilder.setAttr("dtypes", dtypesArray);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.capacity != null) {
+          opBuilder.setAttr("capacity", opts.capacity);
+        }
+        if (opts.memoryLimit != null) {
+          opBuilder.setAttr("memory_limit", opts.memoryLimit);
+        }
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new MapClear(opBuilder.build());
+  }
+  
+  /**
+   * @param capacity 
+   */
+  public static Options capacity(Long capacity) {
+    return new Options().capacity(capacity);
+  }
+  
+  /**
+   * @param memoryLimit 
+   */
+  public static Options memoryLimit(Long memoryLimit) {
+    return new Options().memoryLimit(memoryLimit);
+  }
+  
+  /**
+   * @param container 
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName 
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  
+  private MapClear(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MapIncompleteSize.java java-ops/org/tensorflow/op/core/MapIncompleteSize.java
--- java/org/tensorflow/op/core/MapIncompleteSize.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MapIncompleteSize.java	2018-10-16 20:18:38.334432309 +0900
@@ -0,0 +1,162 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Op returns the number of incomplete elements in the underlying container.
+ */
+@Operator
+public final class MapIncompleteSize extends PrimitiveOp implements Operand<Integer> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.MapIncompleteSize}
+   */
+  public static class Options {
+    
+    /**
+     * @param capacity 
+     */
+    public Options capacity(Long capacity) {
+      this.capacity = capacity;
+      return this;
+    }
+    
+    /**
+     * @param memoryLimit 
+     */
+    public Options memoryLimit(Long memoryLimit) {
+      this.memoryLimit = memoryLimit;
+      return this;
+    }
+    
+    /**
+     * @param container 
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName 
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private Long capacity;
+    private Long memoryLimit;
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new MapIncompleteSize operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param dtypes 
+   * @param options carries optional attributes values
+   * @return a new instance of MapIncompleteSize
+   */
+  public static MapIncompleteSize create(Scope scope, List<Class<?>> dtypes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MapIncompleteSize", scope.makeOpName("MapIncompleteSize"));
+    DataType[] dtypesArray = new DataType[dtypes.size()];
+    for (int i = 0; i < dtypesArray.length; ++i) {
+      dtypesArray[i] = DataType.fromClass(dtypes.get(i));
+    }
+    opBuilder.setAttr("dtypes", dtypesArray);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.capacity != null) {
+          opBuilder.setAttr("capacity", opts.capacity);
+        }
+        if (opts.memoryLimit != null) {
+          opBuilder.setAttr("memory_limit", opts.memoryLimit);
+        }
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new MapIncompleteSize(opBuilder.build());
+  }
+  
+  /**
+   * @param capacity 
+   */
+  public static Options capacity(Long capacity) {
+    return new Options().capacity(capacity);
+  }
+  
+  /**
+   * @param memoryLimit 
+   */
+  public static Options memoryLimit(Long memoryLimit) {
+    return new Options().memoryLimit(memoryLimit);
+  }
+  
+  /**
+   * @param container 
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName 
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   */
+  public Output<Integer> size() {
+    return size;
+  }
+  
+  @Override
+  public Output<Integer> asOutput() {
+    return size;
+  }
+  
+  private Output<Integer> size;
+  
+  private MapIncompleteSize(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    size = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MapPeek.java java-ops/org/tensorflow/op/core/MapPeek.java
--- java/org/tensorflow/op/core/MapPeek.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MapPeek.java	2018-10-16 20:18:38.334432309 +0900
@@ -0,0 +1,174 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.Iterator;
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Op peeks at the values at the specified key.  If the
+ * <p>
+ * underlying container does not contain this key
+ * this op will block until it does.
+ */
+@Operator
+public final class MapPeek extends PrimitiveOp implements Iterable<Operand<Object>> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.MapPeek}
+   */
+  public static class Options {
+    
+    /**
+     * @param capacity 
+     */
+    public Options capacity(Long capacity) {
+      this.capacity = capacity;
+      return this;
+    }
+    
+    /**
+     * @param memoryLimit 
+     */
+    public Options memoryLimit(Long memoryLimit) {
+      this.memoryLimit = memoryLimit;
+      return this;
+    }
+    
+    /**
+     * @param container 
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName 
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private Long capacity;
+    private Long memoryLimit;
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new MapPeek operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param key 
+   * @param indices 
+   * @param dtypes 
+   * @param options carries optional attributes values
+   * @return a new instance of MapPeek
+   */
+  public static MapPeek create(Scope scope, Operand<Long> key, Operand<Integer> indices, List<Class<?>> dtypes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MapPeek", scope.makeOpName("MapPeek"));
+    opBuilder.addInput(key.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    DataType[] dtypesArray = new DataType[dtypes.size()];
+    for (int i = 0; i < dtypesArray.length; ++i) {
+      dtypesArray[i] = DataType.fromClass(dtypes.get(i));
+    }
+    opBuilder.setAttr("dtypes", dtypesArray);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.capacity != null) {
+          opBuilder.setAttr("capacity", opts.capacity);
+        }
+        if (opts.memoryLimit != null) {
+          opBuilder.setAttr("memory_limit", opts.memoryLimit);
+        }
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new MapPeek(opBuilder.build());
+  }
+  
+  /**
+   * @param capacity 
+   */
+  public static Options capacity(Long capacity) {
+    return new Options().capacity(capacity);
+  }
+  
+  /**
+   * @param memoryLimit 
+   */
+  public static Options memoryLimit(Long memoryLimit) {
+    return new Options().memoryLimit(memoryLimit);
+  }
+  
+  /**
+   * @param container 
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName 
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   */
+  public List<Output<?>> values() {
+    return values;
+  }
+  
+  @Override
+  @SuppressWarnings({"rawtypes", "unchecked"})
+  public Iterator<Operand<Object>> iterator() {
+    return (Iterator) values.iterator();
+  }
+  
+  private List<Output<?>> values;
+  
+  private MapPeek(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    int valuesLength = operation.outputListLength("values");
+    values = Arrays.asList(operation.outputList(outputIdx, valuesLength));
+    outputIdx += valuesLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/MapSize.java java-ops/org/tensorflow/op/core/MapSize.java
--- java/org/tensorflow/op/core/MapSize.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MapSize.java	2018-10-16 20:18:38.335432308 +0900
@@ -0,0 +1,162 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Op returns the number of elements in the underlying container.
+ */
+@Operator
+public final class MapSize extends PrimitiveOp implements Operand<Integer> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.MapSize}
+   */
+  public static class Options {
+    
+    /**
+     * @param capacity 
+     */
+    public Options capacity(Long capacity) {
+      this.capacity = capacity;
+      return this;
+    }
+    
+    /**
+     * @param memoryLimit 
+     */
+    public Options memoryLimit(Long memoryLimit) {
+      this.memoryLimit = memoryLimit;
+      return this;
+    }
+    
+    /**
+     * @param container 
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName 
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private Long capacity;
+    private Long memoryLimit;
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new MapSize operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param dtypes 
+   * @param options carries optional attributes values
+   * @return a new instance of MapSize
+   */
+  public static MapSize create(Scope scope, List<Class<?>> dtypes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MapSize", scope.makeOpName("MapSize"));
+    DataType[] dtypesArray = new DataType[dtypes.size()];
+    for (int i = 0; i < dtypesArray.length; ++i) {
+      dtypesArray[i] = DataType.fromClass(dtypes.get(i));
+    }
+    opBuilder.setAttr("dtypes", dtypesArray);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.capacity != null) {
+          opBuilder.setAttr("capacity", opts.capacity);
+        }
+        if (opts.memoryLimit != null) {
+          opBuilder.setAttr("memory_limit", opts.memoryLimit);
+        }
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new MapSize(opBuilder.build());
+  }
+  
+  /**
+   * @param capacity 
+   */
+  public static Options capacity(Long capacity) {
+    return new Options().capacity(capacity);
+  }
+  
+  /**
+   * @param memoryLimit 
+   */
+  public static Options memoryLimit(Long memoryLimit) {
+    return new Options().memoryLimit(memoryLimit);
+  }
+  
+  /**
+   * @param container 
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName 
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   */
+  public Output<Integer> size() {
+    return size;
+  }
+  
+  @Override
+  public Output<Integer> asOutput() {
+    return size;
+  }
+  
+  private Output<Integer> size;
+  
+  private MapSize(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    size = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MapStage.java java-ops/org/tensorflow/op/core/MapStage.java
--- java/org/tensorflow/op/core/MapStage.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MapStage.java	2018-10-16 20:18:38.335432308 +0900
@@ -0,0 +1,159 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Stage (key, values) in the underlying container which behaves like a hashtable.
+ */
+@Operator
+public final class MapStage extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.MapStage}
+   */
+  public static class Options {
+    
+    /**
+     * @param capacity Maximum number of elements in the Staging Area. If > 0, inserts
+     * on the container will block when the capacity is reached.
+     */
+    public Options capacity(Long capacity) {
+      this.capacity = capacity;
+      return this;
+    }
+    
+    /**
+     * @param memoryLimit 
+     */
+    public Options memoryLimit(Long memoryLimit) {
+      this.memoryLimit = memoryLimit;
+      return this;
+    }
+    
+    /**
+     * @param container If non-empty, this queue is placed in the given container. Otherwise,
+     * a default container is used.
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName It is necessary to match this name to the matching Unstage Op.
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private Long capacity;
+    private Long memoryLimit;
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new MapStage operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param key int64
+   * @param indices 
+   * @param values a list of tensors
+   * dtypes A list of data types that inserted values should adhere to.
+   * @param dtypes 
+   * @param options carries optional attributes values
+   * @return a new instance of MapStage
+   */
+  public static MapStage create(Scope scope, Operand<Long> key, Operand<Integer> indices, Iterable<Operand<?>> values, List<Class<?>> dtypes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MapStage", scope.makeOpName("MapStage"));
+    opBuilder.addInput(key.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInputList(Operands.asOutputs(values));
+    DataType[] dtypesArray = new DataType[dtypes.size()];
+    for (int i = 0; i < dtypesArray.length; ++i) {
+      dtypesArray[i] = DataType.fromClass(dtypes.get(i));
+    }
+    opBuilder.setAttr("dtypes", dtypesArray);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.capacity != null) {
+          opBuilder.setAttr("capacity", opts.capacity);
+        }
+        if (opts.memoryLimit != null) {
+          opBuilder.setAttr("memory_limit", opts.memoryLimit);
+        }
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new MapStage(opBuilder.build());
+  }
+  
+  /**
+   * @param capacity Maximum number of elements in the Staging Area. If > 0, inserts
+   * on the container will block when the capacity is reached.
+   */
+  public static Options capacity(Long capacity) {
+    return new Options().capacity(capacity);
+  }
+  
+  /**
+   * @param memoryLimit 
+   */
+  public static Options memoryLimit(Long memoryLimit) {
+    return new Options().memoryLimit(memoryLimit);
+  }
+  
+  /**
+   * @param container If non-empty, this queue is placed in the given container. Otherwise,
+   * a default container is used.
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName It is necessary to match this name to the matching Unstage Op.
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  
+  private MapStage(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MapUnstage.java java-ops/org/tensorflow/op/core/MapUnstage.java
--- java/org/tensorflow/op/core/MapUnstage.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MapUnstage.java	2018-10-16 20:18:38.336432308 +0900
@@ -0,0 +1,174 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.Iterator;
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Op removes and returns the values associated with the key
+ * <p>
+ * from the underlying container.   If the underlying container
+ * does not contain this key, the op will block until it does.
+ */
+@Operator
+public final class MapUnstage extends PrimitiveOp implements Iterable<Operand<Object>> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.MapUnstage}
+   */
+  public static class Options {
+    
+    /**
+     * @param capacity 
+     */
+    public Options capacity(Long capacity) {
+      this.capacity = capacity;
+      return this;
+    }
+    
+    /**
+     * @param memoryLimit 
+     */
+    public Options memoryLimit(Long memoryLimit) {
+      this.memoryLimit = memoryLimit;
+      return this;
+    }
+    
+    /**
+     * @param container 
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName 
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private Long capacity;
+    private Long memoryLimit;
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new MapUnstage operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param key 
+   * @param indices 
+   * @param dtypes 
+   * @param options carries optional attributes values
+   * @return a new instance of MapUnstage
+   */
+  public static MapUnstage create(Scope scope, Operand<Long> key, Operand<Integer> indices, List<Class<?>> dtypes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MapUnstage", scope.makeOpName("MapUnstage"));
+    opBuilder.addInput(key.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    DataType[] dtypesArray = new DataType[dtypes.size()];
+    for (int i = 0; i < dtypesArray.length; ++i) {
+      dtypesArray[i] = DataType.fromClass(dtypes.get(i));
+    }
+    opBuilder.setAttr("dtypes", dtypesArray);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.capacity != null) {
+          opBuilder.setAttr("capacity", opts.capacity);
+        }
+        if (opts.memoryLimit != null) {
+          opBuilder.setAttr("memory_limit", opts.memoryLimit);
+        }
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new MapUnstage(opBuilder.build());
+  }
+  
+  /**
+   * @param capacity 
+   */
+  public static Options capacity(Long capacity) {
+    return new Options().capacity(capacity);
+  }
+  
+  /**
+   * @param memoryLimit 
+   */
+  public static Options memoryLimit(Long memoryLimit) {
+    return new Options().memoryLimit(memoryLimit);
+  }
+  
+  /**
+   * @param container 
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName 
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   */
+  public List<Output<?>> values() {
+    return values;
+  }
+  
+  @Override
+  @SuppressWarnings({"rawtypes", "unchecked"})
+  public Iterator<Operand<Object>> iterator() {
+    return (Iterator) values.iterator();
+  }
+  
+  private List<Output<?>> values;
+  
+  private MapUnstage(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    int valuesLength = operation.outputListLength("values");
+    values = Arrays.asList(operation.outputList(outputIdx, valuesLength));
+    outputIdx += valuesLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/MapUnstageNoKey.java java-ops/org/tensorflow/op/core/MapUnstageNoKey.java
--- java/org/tensorflow/op/core/MapUnstageNoKey.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MapUnstageNoKey.java	2018-10-16 20:18:38.336432308 +0900
@@ -0,0 +1,173 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Op removes and returns a random (key, value)
+ * <p>
+ * from the underlying container.   If the underlying container
+ * does not contain elements, the op will block until it does.
+ */
+@Operator
+public final class MapUnstageNoKey extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.MapUnstageNoKey}
+   */
+  public static class Options {
+    
+    /**
+     * @param capacity 
+     */
+    public Options capacity(Long capacity) {
+      this.capacity = capacity;
+      return this;
+    }
+    
+    /**
+     * @param memoryLimit 
+     */
+    public Options memoryLimit(Long memoryLimit) {
+      this.memoryLimit = memoryLimit;
+      return this;
+    }
+    
+    /**
+     * @param container 
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName 
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private Long capacity;
+    private Long memoryLimit;
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new MapUnstageNoKey operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param indices 
+   * @param dtypes 
+   * @param options carries optional attributes values
+   * @return a new instance of MapUnstageNoKey
+   */
+  public static MapUnstageNoKey create(Scope scope, Operand<Integer> indices, List<Class<?>> dtypes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MapUnstageNoKey", scope.makeOpName("MapUnstageNoKey"));
+    opBuilder.addInput(indices.asOutput());
+    DataType[] dtypesArray = new DataType[dtypes.size()];
+    for (int i = 0; i < dtypesArray.length; ++i) {
+      dtypesArray[i] = DataType.fromClass(dtypes.get(i));
+    }
+    opBuilder.setAttr("dtypes", dtypesArray);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.capacity != null) {
+          opBuilder.setAttr("capacity", opts.capacity);
+        }
+        if (opts.memoryLimit != null) {
+          opBuilder.setAttr("memory_limit", opts.memoryLimit);
+        }
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new MapUnstageNoKey(opBuilder.build());
+  }
+  
+  /**
+   * @param capacity 
+   */
+  public static Options capacity(Long capacity) {
+    return new Options().capacity(capacity);
+  }
+  
+  /**
+   * @param memoryLimit 
+   */
+  public static Options memoryLimit(Long memoryLimit) {
+    return new Options().memoryLimit(memoryLimit);
+  }
+  
+  /**
+   * @param container 
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName 
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   */
+  public Output<Long> key() {
+    return key;
+  }
+  
+  /**
+   */
+  public List<Output<?>> values() {
+    return values;
+  }
+  
+  private Output<Long> key;
+  private List<Output<?>> values;
+  
+  private MapUnstageNoKey(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    key = operation.output(outputIdx++);
+    int valuesLength = operation.outputListLength("values");
+    values = Arrays.asList(operation.outputList(outputIdx, valuesLength));
+    outputIdx += valuesLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/MatchingFiles.java java-ops/org/tensorflow/op/core/MatchingFiles.java
--- java/org/tensorflow/op/core/MatchingFiles.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MatchingFiles.java	2018-10-16 20:18:38.337432307 +0900
@@ -0,0 +1,70 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns the set of files matching one or more glob patterns.
+ * <p>
+ * Note that this routine only supports wildcard characters in the
+ * basename portion of the pattern, not in the directory portion.
+ * Note also that the order of filenames returned can be non-deterministic.
+ */
+@Operator
+public final class MatchingFiles extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Factory method to create a class to wrap a new MatchingFiles operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param pattern Shell wildcard pattern(s). Scalar or vector of type string.
+   * @return a new instance of MatchingFiles
+   */
+  public static MatchingFiles create(Scope scope, Operand<String> pattern) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MatchingFiles", scope.makeOpName("MatchingFiles"));
+    opBuilder.addInput(pattern.asOutput());
+    return new MatchingFiles(opBuilder.build());
+  }
+  
+  /**
+   * A vector of matching filenames.
+   */
+  public Output<String> filenames() {
+    return filenames;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return filenames;
+  }
+  
+  private Output<String> filenames;
+  
+  private MatchingFiles(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    filenames = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MatMul.java java-ops/org/tensorflow/op/core/MatMul.java
--- java/org/tensorflow/op/core/MatMul.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MatMul.java	2018-10-16 20:18:38.336432308 +0900
@@ -0,0 +1,130 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Multiply the matrix "a" by the matrix "b".
+ * <p>
+ * The inputs must be two-dimensional matrices and the inner dimension of
+ * "a" (after being transposed if transpose_a is true) must match the
+ * outer dimension of "b" (after being transposed if transposed_b is
+ * true).
+ * <p>
+ * <i>Note</i>: The default kernel implementation for MatMul on GPUs uses
+ * cublas.
+ * 
+ * @param <T> data type for {@code product()} output
+ */
+@Operator
+public final class MatMul<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.MatMul}
+   */
+  public static class Options {
+    
+    /**
+     * @param transposeA If true, "a" is transposed before multiplication.
+     */
+    public Options transposeA(Boolean transposeA) {
+      this.transposeA = transposeA;
+      return this;
+    }
+    
+    /**
+     * @param transposeB If true, "b" is transposed before multiplication.
+     */
+    public Options transposeB(Boolean transposeB) {
+      this.transposeB = transposeB;
+      return this;
+    }
+    
+    private Boolean transposeA;
+    private Boolean transposeB;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new MatMul operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param a 
+   * @param b 
+   * @param options carries optional attributes values
+   * @return a new instance of MatMul
+   */
+  public static <T> MatMul<T> create(Scope scope, Operand<T> a, Operand<T> b, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MatMul", scope.makeOpName("MatMul"));
+    opBuilder.addInput(a.asOutput());
+    opBuilder.addInput(b.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.transposeA != null) {
+          opBuilder.setAttr("transpose_a", opts.transposeA);
+        }
+        if (opts.transposeB != null) {
+          opBuilder.setAttr("transpose_b", opts.transposeB);
+        }
+      }
+    }
+    return new MatMul<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param transposeA If true, "a" is transposed before multiplication.
+   */
+  public static Options transposeA(Boolean transposeA) {
+    return new Options().transposeA(transposeA);
+  }
+  
+  /**
+   * @param transposeB If true, "b" is transposed before multiplication.
+   */
+  public static Options transposeB(Boolean transposeB) {
+    return new Options().transposeB(transposeB);
+  }
+  
+  /**
+   */
+  public Output<T> product() {
+    return product;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return product;
+  }
+  
+  private Output<T> product;
+  
+  private MatMul(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    product = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MatrixBandPart.java java-ops/org/tensorflow/op/core/MatrixBandPart.java
--- java/org/tensorflow/op/core/MatrixBandPart.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MatrixBandPart.java	2018-10-16 20:18:38.337432307 +0900
@@ -0,0 +1,112 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Copy a tensor setting everything outside a central band in each innermost matrix
+ * <p>
+ * to zero.
+ * <p>
+ * The `band` part is computed as follows:
+ * Assume `input` has `k` dimensions `[I, J, K, ..., M, N]`, then the output is a
+ * tensor with the same shape where
+ * <p>
+ * `band[i, j, k, ..., m, n] = in_band(m, n) * input[i, j, k, ..., m, n]`.
+ * <p>
+ * The indicator function
+ * <p>
+ * `in_band(m, n) = (num_lower < 0 || (m-n) <= num_lower)) &&
+ *                  (num_upper < 0 || (n-m) <= num_upper)`.
+ * <p>
+ * For example:
+ * <pre>{@code
+ * # if 'input' is [[ 0,  1,  2, 3]
+ *                  [-1,  0,  1, 2]
+ *                  [-2, -1,  0, 1]
+ *                  [-3, -2, -1, 0]],
+ * 
+ * tf.matrix_band_part(input, 1, -1) ==> [[ 0,  1,  2, 3]
+ *                                        [-1,  0,  1, 2]
+ *                                        [ 0, -1,  0, 1]
+ *                                        [ 0,  0, -1, 0]],
+ * 
+ * tf.matrix_band_part(input, 2, 1) ==> [[ 0,  1,  0, 0]
+ *                                       [-1,  0,  1, 0]
+ *                                       [-2, -1,  0, 1]
+ *                                       [ 0, -2, -1, 0]]
+ * }</pre>
+ * Useful special cases:
+ * <pre>{@code
+ *  tf.matrix_band_part(input, 0, -1) ==> Upper triangular part.
+ *  tf.matrix_band_part(input, -1, 0) ==> Lower triangular part.
+ *  tf.matrix_band_part(input, 0, 0) ==> Diagonal.
+ * }</pre>
+ * 
+ * 
+ * @param <T> data type for {@code band()} output
+ */
+@Operator
+public final class MatrixBandPart<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new MatrixBandPart operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input Rank `k` tensor.
+   * @param numLower 0-D tensor. Number of subdiagonals to keep. If negative, keep entire
+   * lower triangle.
+   * @param numUpper 0-D tensor. Number of superdiagonals to keep. If negative, keep
+   * entire upper triangle.
+   * @return a new instance of MatrixBandPart
+   */
+  public static <T, U extends Number> MatrixBandPart<T> create(Scope scope, Operand<T> input, Operand<U> numLower, Operand<U> numUpper) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MatrixBandPart", scope.makeOpName("MatrixBandPart"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(numLower.asOutput());
+    opBuilder.addInput(numUpper.asOutput());
+    return new MatrixBandPart<T>(opBuilder.build());
+  }
+  
+  /**
+   * Rank `k` tensor of the same shape as input. The extracted banded tensor.
+   */
+  public Output<T> band() {
+    return band;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return band;
+  }
+  
+  private Output<T> band;
+  
+  private MatrixBandPart(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    band = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MatrixDeterminant.java java-ops/org/tensorflow/op/core/MatrixDeterminant.java
--- java/org/tensorflow/op/core/MatrixDeterminant.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MatrixDeterminant.java	2018-10-16 20:18:38.338432306 +0900
@@ -0,0 +1,72 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the determinant of one or more square matrices.
+ * <p>
+ * The input is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions
+ * form square matrices. The output is a tensor containing the determinants
+ * for all input submatrices `[..., :, :]`.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class MatrixDeterminant<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new MatrixDeterminant operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input Shape is `[..., M, M]`.
+   * @return a new instance of MatrixDeterminant
+   */
+  public static <T> MatrixDeterminant<T> create(Scope scope, Operand<T> input) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MatrixDeterminant", scope.makeOpName("MatrixDeterminant"));
+    opBuilder.addInput(input.asOutput());
+    return new MatrixDeterminant<T>(opBuilder.build());
+  }
+  
+  /**
+   * Shape is `[...]`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private MatrixDeterminant(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MatrixDiag.java java-ops/org/tensorflow/op/core/MatrixDiag.java
--- java/org/tensorflow/op/core/MatrixDiag.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MatrixDiag.java	2018-10-16 20:18:38.338432306 +0900
@@ -0,0 +1,95 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns a batched diagonal tensor with a given batched diagonal values.
+ * <p>
+ * Given a `diagonal`, this operation returns a tensor with the `diagonal` and
+ * everything else padded with zeros. The diagonal is computed as follows:
+ * <p>
+ * Assume `diagonal` has `k` dimensions `[I, J, K, ..., N]`, then the output is a
+ * tensor of rank `k+1` with dimensions [I, J, K, ..., N, N]` where:
+ * <p>
+ * `output[i, j, k, ..., m, n] = 1{m=n} * diagonal[i, j, k, ..., n]`.
+ * <p>
+ * For example:
+ * <pre>{@code
+ * # 'diagonal' is [[1, 2, 3, 4], [5, 6, 7, 8]]
+ * 
+ * and diagonal.shape = (2, 4)
+ * 
+ * tf.matrix_diag(diagonal) ==> [[[1, 0, 0, 0]
+ *                                      [0, 2, 0, 0]
+ *                                      [0, 0, 3, 0]
+ *                                      [0, 0, 0, 4]],
+ *                                     [[5, 0, 0, 0]
+ *                                      [0, 6, 0, 0]
+ *                                      [0, 0, 7, 0]
+ *                                      [0, 0, 0, 8]]]
+ * 
+ * which has shape (2, 4, 4)
+ * }</pre>
+ * 
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class MatrixDiag<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new MatrixDiag operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param diagonal Rank `k`, where `k >= 1`.
+   * @return a new instance of MatrixDiag
+   */
+  public static <T> MatrixDiag<T> create(Scope scope, Operand<T> diagonal) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MatrixDiag", scope.makeOpName("MatrixDiag"));
+    opBuilder.addInput(diagonal.asOutput());
+    return new MatrixDiag<T>(opBuilder.build());
+  }
+  
+  /**
+   * Rank `k+1`, with `output.shape = diagonal.shape + [diagonal.shape[-1]]`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private MatrixDiag(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MatrixDiagPart.java java-ops/org/tensorflow/op/core/MatrixDiagPart.java
--- java/org/tensorflow/op/core/MatrixDiagPart.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MatrixDiagPart.java	2018-10-16 20:18:38.339432306 +0900
@@ -0,0 +1,98 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns the batched diagonal part of a batched tensor.
+ * <p>
+ * This operation returns a tensor with the `diagonal` part
+ * of the batched `input`. The `diagonal` part is computed as follows:
+ * <p>
+ * Assume `input` has `k` dimensions `[I, J, K, ..., M, N]`, then the output is a
+ * tensor of rank `k - 1` with dimensions `[I, J, K, ..., min(M, N)]` where:
+ * <p>
+ * `diagonal[i, j, k, ..., n] = input[i, j, k, ..., n, n]`.
+ * <p>
+ * The input must be at least a matrix.
+ * <p>
+ * For example:
+ * <pre>{@code
+ * # 'input' is [[[1, 0, 0, 0]
+ *                [0, 2, 0, 0]
+ *                [0, 0, 3, 0]
+ *                [0, 0, 0, 4]],
+ *               [[5, 0, 0, 0]
+ *                [0, 6, 0, 0]
+ *                [0, 0, 7, 0]
+ *                [0, 0, 0, 8]]]
+ * 
+ * and input.shape = (2, 4, 4)
+ * 
+ * tf.matrix_diag_part(input) ==> [[1, 2, 3, 4], [5, 6, 7, 8]]
+ * 
+ * which has shape (2, 4)
+ * }</pre>
+ * 
+ * 
+ * @param <T> data type for {@code diagonal()} output
+ */
+@Operator
+public final class MatrixDiagPart<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new MatrixDiagPart operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input Rank `k` tensor where `k >= 2`.
+   * @return a new instance of MatrixDiagPart
+   */
+  public static <T> MatrixDiagPart<T> create(Scope scope, Operand<T> input) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MatrixDiagPart", scope.makeOpName("MatrixDiagPart"));
+    opBuilder.addInput(input.asOutput());
+    return new MatrixDiagPart<T>(opBuilder.build());
+  }
+  
+  /**
+   * The extracted diagonal(s) having shape
+   * `diagonal.shape = input.shape[:-2] + [min(input.shape[-2:])]`.
+   */
+  public Output<T> diagonal() {
+    return diagonal;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return diagonal;
+  }
+  
+  private Output<T> diagonal;
+  
+  private MatrixDiagPart(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    diagonal = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MatrixInverse.java java-ops/org/tensorflow/op/core/MatrixInverse.java
--- java/org/tensorflow/op/core/MatrixInverse.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MatrixInverse.java	2018-10-16 20:18:38.340432305 +0900
@@ -0,0 +1,118 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the inverse of one or more square invertible matrices or their
+ * <p>
+ * adjoints (conjugate transposes).
+ * <p>
+ * The input is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions
+ * form square matrices. The output is a tensor of the same shape as the input
+ * containing the inverse for all input submatrices `[..., :, :]`.
+ * <p>
+ * The op uses LU decomposition with partial pivoting to compute the inverses.
+ * <p>
+ * If a matrix is not invertible there is no guarantee what the op does. It
+ * may detect the condition and raise an exception or it may simply return a
+ * garbage result.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class MatrixInverse<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.MatrixInverse}
+   */
+  public static class Options {
+    
+    /**
+     * @param adjoint 
+     */
+    public Options adjoint(Boolean adjoint) {
+      this.adjoint = adjoint;
+      return this;
+    }
+    
+    private Boolean adjoint;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new MatrixInverse operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input Shape is `[..., M, M]`.
+   * @param options carries optional attributes values
+   * @return a new instance of MatrixInverse
+   */
+  public static <T> MatrixInverse<T> create(Scope scope, Operand<T> input, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MatrixInverse", scope.makeOpName("MatrixInverse"));
+    opBuilder.addInput(input.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.adjoint != null) {
+          opBuilder.setAttr("adjoint", opts.adjoint);
+        }
+      }
+    }
+    return new MatrixInverse<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param adjoint 
+   */
+  public static Options adjoint(Boolean adjoint) {
+    return new Options().adjoint(adjoint);
+  }
+  
+  /**
+   * Shape is `[..., M, M]`.
+   * <p>
+   * @compatibility(numpy)
+   * Equivalent to np.linalg.inv
+   * @end_compatibility
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private MatrixInverse(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MatrixLogarithm.java java-ops/org/tensorflow/op/core/MatrixLogarithm.java
--- java/org/tensorflow/op/core/MatrixLogarithm.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MatrixLogarithm.java	2018-10-16 20:18:38.340432305 +0900
@@ -0,0 +1,86 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Computes the matrix logarithm of one or more square matrices:
+ * <p>
+ * 
+ * \\(log(exp(A)) = A\\)
+ * <p>
+ * This op is only defined for complex matrices. If A is positive-definite and
+ * real, then casting to a complex matrix, taking the logarithm and casting back
+ * to a real matrix will give the correct result.
+ * <p>
+ * This function computes the matrix logarithm using the Schur-Parlett algorithm.
+ * Details of the algorithm can be found in Section 11.6.2 of:
+ * Nicholas J. Higham, Functions of Matrices: Theory and Computation, SIAM 2008.
+ * ISBN 978-0-898716-46-7.
+ * <p>
+ * The input is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions
+ * form square matrices. The output is a tensor of the same shape as the input
+ * containing the exponential for all input submatrices `[..., :, :]`.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+public final class MatrixLogarithm<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new MatrixLogarithm operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input Shape is `[..., M, M]`.
+   * @return a new instance of MatrixLogarithm
+   */
+  public static <T> MatrixLogarithm<T> create(Scope scope, Operand<T> input) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MatrixLogarithm", scope.makeOpName("MatrixLogarithm"));
+    opBuilder.addInput(input.asOutput());
+    return new MatrixLogarithm<T>(opBuilder.build());
+  }
+  
+  /**
+   * Shape is `[..., M, M]`.
+   * <p>
+   * @compatibility(scipy)
+   * Equivalent to scipy.linalg.logm
+   * @end_compatibility
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private MatrixLogarithm(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MatrixSetDiag.java java-ops/org/tensorflow/op/core/MatrixSetDiag.java
--- java/org/tensorflow/op/core/MatrixSetDiag.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MatrixSetDiag.java	2018-10-16 20:18:38.341432304 +0900
@@ -0,0 +1,83 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns a batched matrix tensor with new batched diagonal values.
+ * <p>
+ * Given `input` and `diagonal`, this operation returns a tensor with the
+ * same shape and values as `input`, except for the main diagonal of the
+ * innermost matrices.  These will be overwritten by the values in `diagonal`.
+ * <p>
+ * The output is computed as follows:
+ * <p>
+ * Assume `input` has `k+1` dimensions `[I, J, K, ..., M, N]` and `diagonal` has
+ * `k` dimensions `[I, J, K, ..., min(M, N)]`.  Then the output is a
+ * tensor of rank `k+1` with dimensions `[I, J, K, ..., M, N]` where:
+ * <p>
+ *   * `output[i, j, k, ..., m, n] = diagonal[i, j, k, ..., n]` for `m == n`.
+ *   * `output[i, j, k, ..., m, n] = input[i, j, k, ..., m, n]` for `m != n`.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class MatrixSetDiag<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new MatrixSetDiag operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input Rank `k+1`, where `k >= 1`.
+   * @param diagonal Rank `k`, where `k >= 1`.
+   * @return a new instance of MatrixSetDiag
+   */
+  public static <T> MatrixSetDiag<T> create(Scope scope, Operand<T> input, Operand<T> diagonal) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MatrixSetDiag", scope.makeOpName("MatrixSetDiag"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(diagonal.asOutput());
+    return new MatrixSetDiag<T>(opBuilder.build());
+  }
+  
+  /**
+   * Rank `k+1`, with `output.shape = input.shape`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private MatrixSetDiag(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MatrixSolve.java java-ops/org/tensorflow/op/core/MatrixSolve.java
--- java/org/tensorflow/op/core/MatrixSolve.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MatrixSolve.java	2018-10-16 20:18:38.342432303 +0900
@@ -0,0 +1,113 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Solves systems of linear equations.
+ * <p>
+ * `Matrix` is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions
+ * form square matrices. `Rhs` is a tensor of shape `[..., M, K]`. The `output` is
+ * a tensor shape `[..., M, K]`.  If `adjoint` is `False` then each output matrix
+ * satisfies `matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]`.
+ * If `adjoint` is `True` then each output matrix satisfies
+ * `adjoint(matrix[..., :, :]) * output[..., :, :] = rhs[..., :, :]`.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class MatrixSolve<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.MatrixSolve}
+   */
+  public static class Options {
+    
+    /**
+     * @param adjoint Boolean indicating whether to solve with `matrix` or its (block-wise)
+     * adjoint.
+     */
+    public Options adjoint(Boolean adjoint) {
+      this.adjoint = adjoint;
+      return this;
+    }
+    
+    private Boolean adjoint;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new MatrixSolve operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param matrix Shape is `[..., M, M]`.
+   * @param rhs Shape is `[..., M, K]`.
+   * @param options carries optional attributes values
+   * @return a new instance of MatrixSolve
+   */
+  public static <T> MatrixSolve<T> create(Scope scope, Operand<T> matrix, Operand<T> rhs, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MatrixSolve", scope.makeOpName("MatrixSolve"));
+    opBuilder.addInput(matrix.asOutput());
+    opBuilder.addInput(rhs.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.adjoint != null) {
+          opBuilder.setAttr("adjoint", opts.adjoint);
+        }
+      }
+    }
+    return new MatrixSolve<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param adjoint Boolean indicating whether to solve with `matrix` or its (block-wise)
+   * adjoint.
+   */
+  public static Options adjoint(Boolean adjoint) {
+    return new Options().adjoint(adjoint);
+  }
+  
+  /**
+   * Shape is `[..., M, K]`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private MatrixSolve(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MatrixSolveLs.java java-ops/org/tensorflow/op/core/MatrixSolveLs.java
--- java/org/tensorflow/op/core/MatrixSolveLs.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MatrixSolveLs.java	2018-10-16 20:18:38.342432303 +0900
@@ -0,0 +1,145 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Solves one or more linear least-squares problems.
+ * <p>
+ * `matrix` is a tensor of shape `[..., M, N]` whose inner-most 2 dimensions
+ * form real or complex matrices of size `[M, N]`. `Rhs` is a tensor of the same
+ * type as `matrix` and shape `[..., M, K]`.
+ * The output is a tensor shape `[..., N, K]` where each output matrix solves
+ * each of the equations
+ * `matrix[..., :, :]` * `output[..., :, :]` = `rhs[..., :, :]`
+ * in the least squares sense.
+ * <p>
+ * We use the following notation for (complex) matrix and right-hand sides
+ * in the batch:
+ * <p>
+ * `matrix`=\\(A \in \mathbb{C}^{m \times n}\\),
+ * `rhs`=\\(B  \in \mathbb{C}^{m \times k}\\),
+ * `output`=\\(X  \in \mathbb{C}^{n \times k}\\),
+ * `l2_regularizer`=\\(\lambda \in \mathbb{R}\\).
+ * <p>
+ * If `fast` is `True`, then the solution is computed by solving the normal
+ * equations using Cholesky decomposition. Specifically, if \\(m \ge n\\) then
+ * \\(X = (A^H A + \lambda I)^{-1} A^H B\\), which solves the least-squares
+ * problem \\(X = \mathrm{argmin}_{Z \in \Re^{n \times k} } ||A Z - B||_F^2 + \lambda ||Z||_F^2\\). 
+ * If \\(m \lt n\\) then `output` is computed as
+ * \\(X = A^H (A A^H + \lambda I)^{-1} B\\), which (for \\(\lambda = 0\\)) is the
+ * minimum-norm solution to the under-determined linear system, i.e.
+ * \\(X = \mathrm{argmin}_{Z \in \mathbb{C}^{n \times k} } ||Z||_F^2 \\),
+ * subject to \\(A Z = B\\). Notice that the fast path is only numerically stable
+ * when \\(A\\) is numerically full rank and has a condition number
+ * \\(\mathrm{cond}(A) \lt \frac{1}{\sqrt{\epsilon_{mach} } }\\) or \\(\lambda\\) is
+ * sufficiently large.
+ * <p>
+ * If `fast` is `False` an algorithm based on the numerically robust complete
+ * orthogonal decomposition is used. This computes the minimum-norm
+ * least-squares solution, even when \\(A\\) is rank deficient. This path is
+ * typically 6-7 times slower than the fast path. If `fast` is `False` then
+ * `l2_regularizer` is ignored.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class MatrixSolveLs<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.MatrixSolveLs}
+   */
+  public static class Options {
+    
+    /**
+     * @param fast 
+     */
+    public Options fast(Boolean fast) {
+      this.fast = fast;
+      return this;
+    }
+    
+    private Boolean fast;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new MatrixSolveLs operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param matrix Shape is `[..., M, N]`.
+   * @param rhs Shape is `[..., M, K]`.
+   * @param l2Regularizer Scalar tensor.
+   * <p>
+   * @compatibility(numpy)
+   * Equivalent to np.linalg.lstsq
+   * @end_compatibility
+   * @param options carries optional attributes values
+   * @return a new instance of MatrixSolveLs
+   */
+  public static <T> MatrixSolveLs<T> create(Scope scope, Operand<T> matrix, Operand<T> rhs, Operand<Double> l2Regularizer, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MatrixSolveLs", scope.makeOpName("MatrixSolveLs"));
+    opBuilder.addInput(matrix.asOutput());
+    opBuilder.addInput(rhs.asOutput());
+    opBuilder.addInput(l2Regularizer.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.fast != null) {
+          opBuilder.setAttr("fast", opts.fast);
+        }
+      }
+    }
+    return new MatrixSolveLs<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param fast 
+   */
+  public static Options fast(Boolean fast) {
+    return new Options().fast(fast);
+  }
+  
+  /**
+   * Shape is `[..., N, K]`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private MatrixSolveLs(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MatrixTriangularSolve.java java-ops/org/tensorflow/op/core/MatrixTriangularSolve.java
--- java/org/tensorflow/op/core/MatrixTriangularSolve.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MatrixTriangularSolve.java	2018-10-16 20:18:38.344432302 +0900
@@ -0,0 +1,151 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Solves systems of linear equations with upper or lower triangular matrices by
+ * <p>
+ * backsubstitution.
+ * <p>
+ * `matrix` is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions form
+ * square matrices. If `lower` is `True` then the strictly upper triangular part
+ * of each inner-most matrix is assumed to be zero and not accessed.
+ * If `lower` is False then the strictly lower triangular part of each inner-most
+ * matrix is assumed to be zero and not accessed.
+ * `rhs` is a tensor of shape `[..., M, K]`.
+ * <p>
+ * The output is a tensor of shape `[..., M, K]`. If `adjoint` is
+ * `True` then the innermost matrices in `output` satisfy matrix equations
+ * `matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]`.
+ * If `adjoint` is `False` then the strictly then the  innermost matrices in
+ * `output` satisfy matrix equations
+ * `adjoint(matrix[..., i, k]) * output[..., k, j] = rhs[..., i, j]`.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class MatrixTriangularSolve<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.MatrixTriangularSolve}
+   */
+  public static class Options {
+    
+    /**
+     * @param lower Boolean indicating whether the innermost matrices in `matrix` are
+     * lower or upper triangular.
+     */
+    public Options lower(Boolean lower) {
+      this.lower = lower;
+      return this;
+    }
+    
+    /**
+     * @param adjoint Boolean indicating whether to solve with `matrix` or its (block-wise)
+     *          adjoint.
+     * <p>
+     * @compatibility(numpy)
+     * Equivalent to scipy.linalg.solve_triangular
+     * @end_compatibility
+     */
+    public Options adjoint(Boolean adjoint) {
+      this.adjoint = adjoint;
+      return this;
+    }
+    
+    private Boolean lower;
+    private Boolean adjoint;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new MatrixTriangularSolve operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param matrix Shape is `[..., M, M]`.
+   * @param rhs Shape is `[..., M, K]`.
+   * @param options carries optional attributes values
+   * @return a new instance of MatrixTriangularSolve
+   */
+  public static <T> MatrixTriangularSolve<T> create(Scope scope, Operand<T> matrix, Operand<T> rhs, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MatrixTriangularSolve", scope.makeOpName("MatrixTriangularSolve"));
+    opBuilder.addInput(matrix.asOutput());
+    opBuilder.addInput(rhs.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.lower != null) {
+          opBuilder.setAttr("lower", opts.lower);
+        }
+        if (opts.adjoint != null) {
+          opBuilder.setAttr("adjoint", opts.adjoint);
+        }
+      }
+    }
+    return new MatrixTriangularSolve<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param lower Boolean indicating whether the innermost matrices in `matrix` are
+   * lower or upper triangular.
+   */
+  public static Options lower(Boolean lower) {
+    return new Options().lower(lower);
+  }
+  
+  /**
+   * @param adjoint Boolean indicating whether to solve with `matrix` or its (block-wise)
+   *          adjoint.
+   * <p>
+   * @compatibility(numpy)
+   * Equivalent to scipy.linalg.solve_triangular
+   * @end_compatibility
+   */
+  public static Options adjoint(Boolean adjoint) {
+    return new Options().adjoint(adjoint);
+  }
+  
+  /**
+   * Shape is `[..., M, K]`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private MatrixTriangularSolve(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Maximum.java java-ops/org/tensorflow/op/core/Maximum.java
--- java/org/tensorflow/op/core/Maximum.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Maximum.java	2018-10-16 20:18:38.352432297 +0900
@@ -0,0 +1,72 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns the max of x and y (i.e. x > y ? x : y) element-wise.
+ * <p>
+ * <i>NOTE</i>: `Maximum` supports broadcasting. More about broadcasting
+ * [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
+ * 
+ * @param <T> data type for {@code z()} output
+ */
+@Operator
+public final class Maximum<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Maximum operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param y 
+   * @return a new instance of Maximum
+   */
+  public static <T extends Number> Maximum<T> create(Scope scope, Operand<T> x, Operand<T> y) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Maximum", scope.makeOpName("Maximum"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(y.asOutput());
+    return new Maximum<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return z;
+  }
+  
+  private Output<T> z;
+  
+  private Maximum(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Max.java java-ops/org/tensorflow/op/core/Max.java
--- java/org/tensorflow/op/core/Max.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Max.java	2018-10-16 20:18:38.344432302 +0900
@@ -0,0 +1,110 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the maximum of elements across dimensions of a tensor.
+ * <p>
+ * Reduces `input` along the dimensions given in `axis`. Unless
+ * `keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
+ * `axis`. If `keep_dims` is true, the reduced dimensions are
+ * retained with length 1.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class Max<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Max}
+   */
+  public static class Options {
+    
+    /**
+     * @param keepDims If true, retain reduced dimensions with length 1.
+     */
+    public Options keepDims(Boolean keepDims) {
+      this.keepDims = keepDims;
+      return this;
+    }
+    
+    private Boolean keepDims;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Max operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input The tensor to reduce.
+   * @param axis The dimensions to reduce. Must be in the range
+   * `[-rank(input), rank(input))`.
+   * @param options carries optional attributes values
+   * @return a new instance of Max
+   */
+  public static <T, U extends Number> Max<T> create(Scope scope, Operand<T> input, Operand<U> axis, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Max", scope.makeOpName("Max"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(axis.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.keepDims != null) {
+          opBuilder.setAttr("keep_dims", opts.keepDims);
+        }
+      }
+    }
+    return new Max<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param keepDims If true, retain reduced dimensions with length 1.
+   */
+  public static Options keepDims(Boolean keepDims) {
+    return new Options().keepDims(keepDims);
+  }
+  
+  /**
+   * The reduced tensor.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private Max(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MaxPool3DGradGrad.java java-ops/org/tensorflow/op/core/MaxPool3DGradGrad.java
--- java/org/tensorflow/op/core/MaxPool3DGradGrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MaxPool3DGradGrad.java	2018-10-16 20:18:38.347432300 +0900
@@ -0,0 +1,131 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes second-order gradients of the maxpooling function.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class MaxPool3DGradGrad<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.MaxPool3DGradGrad}
+   */
+  public static class Options {
+    
+    /**
+     * @param dataFormat The data format of the input and output data. With the
+     * default format "NDHWC", the data is stored in the order of:
+     *     [batch, in_depth, in_height, in_width, in_channels].
+     * Alternatively, the format could be "NCDHW", the data storage order is:
+     *     [batch, in_channels, in_depth, in_height, in_width].
+     */
+    public Options dataFormat(String dataFormat) {
+      this.dataFormat = dataFormat;
+      return this;
+    }
+    
+    private String dataFormat;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new MaxPool3DGradGrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param origInput The original input tensor.
+   * @param origOutput The original output tensor.
+   * @param grad Output backprop of shape `[batch, depth, rows, cols, channels]`.
+   * @param ksize 1-D tensor of length 5. The size of the window for each dimension of
+   * the input tensor. Must have `ksize[0] = ksize[4] = 1`.
+   * @param strides 1-D tensor of length 5. The stride of the sliding window for each
+   * dimension of `input`. Must have `strides[0] = strides[4] = 1`.
+   * @param padding The type of padding algorithm to use.
+   * @param options carries optional attributes values
+   * @return a new instance of MaxPool3DGradGrad
+   */
+  public static <T extends Number> MaxPool3DGradGrad<T> create(Scope scope, Operand<T> origInput, Operand<T> origOutput, Operand<T> grad, List<Long> ksize, List<Long> strides, String padding, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MaxPool3DGradGrad", scope.makeOpName("MaxPool3DGradGrad"));
+    opBuilder.addInput(origInput.asOutput());
+    opBuilder.addInput(origOutput.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    long[] ksizeArray = new long[ksize.size()];
+    for (int i = 0; i < ksizeArray.length; ++i) {
+      ksizeArray[i] = ksize.get(i);
+    }
+    opBuilder.setAttr("ksize", ksizeArray);
+    long[] stridesArray = new long[strides.size()];
+    for (int i = 0; i < stridesArray.length; ++i) {
+      stridesArray[i] = strides.get(i);
+    }
+    opBuilder.setAttr("strides", stridesArray);
+    opBuilder.setAttr("padding", padding);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.dataFormat != null) {
+          opBuilder.setAttr("data_format", opts.dataFormat);
+        }
+      }
+    }
+    return new MaxPool3DGradGrad<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param dataFormat The data format of the input and output data. With the
+   * default format "NDHWC", the data is stored in the order of:
+   *     [batch, in_depth, in_height, in_width, in_channels].
+   * Alternatively, the format could be "NCDHW", the data storage order is:
+   *     [batch, in_channels, in_depth, in_height, in_width].
+   */
+  public static Options dataFormat(String dataFormat) {
+    return new Options().dataFormat(dataFormat);
+  }
+  
+  /**
+   * Gradients of gradients w.r.t. the input to `max_pool`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private MaxPool3DGradGrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MaxPool3DGrad.java java-ops/org/tensorflow/op/core/MaxPool3DGrad.java
--- java/org/tensorflow/op/core/MaxPool3DGrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MaxPool3DGrad.java	2018-10-16 20:18:38.346432301 +0900
@@ -0,0 +1,130 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes gradients of max pooling function.
+ * 
+ * @param <U> data type for {@code output()} output
+ */
+@Operator
+public final class MaxPool3DGrad<U extends Number> extends PrimitiveOp implements Operand<U> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.MaxPool3DGrad}
+   */
+  public static class Options {
+    
+    /**
+     * @param dataFormat The data format of the input and output data. With the
+     * default format "NDHWC", the data is stored in the order of:
+     *     [batch, in_depth, in_height, in_width, in_channels].
+     * Alternatively, the format could be "NCDHW", the data storage order is:
+     *     [batch, in_channels, in_depth, in_height, in_width].
+     */
+    public Options dataFormat(String dataFormat) {
+      this.dataFormat = dataFormat;
+      return this;
+    }
+    
+    private String dataFormat;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new MaxPool3DGrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param origInput The original input tensor.
+   * @param origOutput The original output tensor.
+   * @param grad Output backprop of shape `[batch, depth, rows, cols, channels]`.
+   * @param ksize 1-D tensor of length 5. The size of the window for each dimension of
+   * the input tensor. Must have `ksize[0] = ksize[4] = 1`.
+   * @param strides 1-D tensor of length 5. The stride of the sliding window for each
+   * dimension of `input`. Must have `strides[0] = strides[4] = 1`.
+   * @param padding The type of padding algorithm to use.
+   * @param options carries optional attributes values
+   * @return a new instance of MaxPool3DGrad
+   */
+  public static <U extends Number, T extends Number> MaxPool3DGrad<U> create(Scope scope, Operand<T> origInput, Operand<T> origOutput, Operand<U> grad, List<Long> ksize, List<Long> strides, String padding, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MaxPool3DGrad", scope.makeOpName("MaxPool3DGrad"));
+    opBuilder.addInput(origInput.asOutput());
+    opBuilder.addInput(origOutput.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    long[] ksizeArray = new long[ksize.size()];
+    for (int i = 0; i < ksizeArray.length; ++i) {
+      ksizeArray[i] = ksize.get(i);
+    }
+    opBuilder.setAttr("ksize", ksizeArray);
+    long[] stridesArray = new long[strides.size()];
+    for (int i = 0; i < stridesArray.length; ++i) {
+      stridesArray[i] = strides.get(i);
+    }
+    opBuilder.setAttr("strides", stridesArray);
+    opBuilder.setAttr("padding", padding);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.dataFormat != null) {
+          opBuilder.setAttr("data_format", opts.dataFormat);
+        }
+      }
+    }
+    return new MaxPool3DGrad<U>(opBuilder.build());
+  }
+  
+  /**
+   * @param dataFormat The data format of the input and output data. With the
+   * default format "NDHWC", the data is stored in the order of:
+   *     [batch, in_depth, in_height, in_width, in_channels].
+   * Alternatively, the format could be "NCDHW", the data storage order is:
+   *     [batch, in_channels, in_depth, in_height, in_width].
+   */
+  public static Options dataFormat(String dataFormat) {
+    return new Options().dataFormat(dataFormat);
+  }
+  
+  /**
+   */
+  public Output<U> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<U> asOutput() {
+    return output;
+  }
+  
+  private Output<U> output;
+  
+  private MaxPool3DGrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MaxPool3D.java java-ops/org/tensorflow/op/core/MaxPool3D.java
--- java/org/tensorflow/op/core/MaxPool3D.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MaxPool3D.java	2018-10-16 20:18:38.345432301 +0900
@@ -0,0 +1,127 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Performs 3D max pooling on the input.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class MaxPool3D<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.MaxPool3D}
+   */
+  public static class Options {
+    
+    /**
+     * @param dataFormat The data format of the input and output data. With the
+     * default format "NDHWC", the data is stored in the order of:
+     *     [batch, in_depth, in_height, in_width, in_channels].
+     * Alternatively, the format could be "NCDHW", the data storage order is:
+     *     [batch, in_channels, in_depth, in_height, in_width].
+     */
+    public Options dataFormat(String dataFormat) {
+      this.dataFormat = dataFormat;
+      return this;
+    }
+    
+    private String dataFormat;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new MaxPool3D operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input Shape `[batch, depth, rows, cols, channels]` tensor to pool over.
+   * @param ksize 1-D tensor of length 5. The size of the window for each dimension of
+   * the input tensor. Must have `ksize[0] = ksize[4] = 1`.
+   * @param strides 1-D tensor of length 5. The stride of the sliding window for each
+   * dimension of `input`. Must have `strides[0] = strides[4] = 1`.
+   * @param padding The type of padding algorithm to use.
+   * @param options carries optional attributes values
+   * @return a new instance of MaxPool3D
+   */
+  public static <T extends Number> MaxPool3D<T> create(Scope scope, Operand<T> input, List<Long> ksize, List<Long> strides, String padding, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MaxPool3D", scope.makeOpName("MaxPool3D"));
+    opBuilder.addInput(input.asOutput());
+    long[] ksizeArray = new long[ksize.size()];
+    for (int i = 0; i < ksizeArray.length; ++i) {
+      ksizeArray[i] = ksize.get(i);
+    }
+    opBuilder.setAttr("ksize", ksizeArray);
+    long[] stridesArray = new long[strides.size()];
+    for (int i = 0; i < stridesArray.length; ++i) {
+      stridesArray[i] = strides.get(i);
+    }
+    opBuilder.setAttr("strides", stridesArray);
+    opBuilder.setAttr("padding", padding);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.dataFormat != null) {
+          opBuilder.setAttr("data_format", opts.dataFormat);
+        }
+      }
+    }
+    return new MaxPool3D<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param dataFormat The data format of the input and output data. With the
+   * default format "NDHWC", the data is stored in the order of:
+   *     [batch, in_depth, in_height, in_width, in_channels].
+   * Alternatively, the format could be "NCDHW", the data storage order is:
+   *     [batch, in_channels, in_depth, in_height, in_width].
+   */
+  public static Options dataFormat(String dataFormat) {
+    return new Options().dataFormat(dataFormat);
+  }
+  
+  /**
+   * The max pooled output tensor.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private MaxPool3D(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MaxPoolGradGrad.java java-ops/org/tensorflow/op/core/MaxPoolGradGrad.java
--- java/org/tensorflow/op/core/MaxPoolGradGrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MaxPoolGradGrad.java	2018-10-16 20:18:38.348432299 +0900
@@ -0,0 +1,130 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes second-order gradients of the maxpooling function.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class MaxPoolGradGrad<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.MaxPoolGradGrad}
+   */
+  public static class Options {
+    
+    /**
+     * @param dataFormat Specify the data format of the input and output data. With the
+     * default format "NHWC", the data is stored in the order of:
+     *     [batch, in_height, in_width, in_channels].
+     * Alternatively, the format could be "NCHW", the data storage order of:
+     *     [batch, in_channels, in_height, in_width].
+     */
+    public Options dataFormat(String dataFormat) {
+      this.dataFormat = dataFormat;
+      return this;
+    }
+    
+    private String dataFormat;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new MaxPoolGradGrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param origInput The original input tensor.
+   * @param origOutput The original output tensor.
+   * @param grad 4-D.  Gradients of gradients w.r.t. the input of `max_pool`.
+   * @param ksize The size of the window for each dimension of the input tensor.
+   * @param strides The stride of the sliding window for each dimension of the
+   * input tensor.
+   * @param padding The type of padding algorithm to use.
+   * @param options carries optional attributes values
+   * @return a new instance of MaxPoolGradGrad
+   */
+  public static <T extends Number> MaxPoolGradGrad<T> create(Scope scope, Operand<T> origInput, Operand<T> origOutput, Operand<T> grad, List<Long> ksize, List<Long> strides, String padding, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MaxPoolGradGrad", scope.makeOpName("MaxPoolGradGrad"));
+    opBuilder.addInput(origInput.asOutput());
+    opBuilder.addInput(origOutput.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    long[] ksizeArray = new long[ksize.size()];
+    for (int i = 0; i < ksizeArray.length; ++i) {
+      ksizeArray[i] = ksize.get(i);
+    }
+    opBuilder.setAttr("ksize", ksizeArray);
+    long[] stridesArray = new long[strides.size()];
+    for (int i = 0; i < stridesArray.length; ++i) {
+      stridesArray[i] = strides.get(i);
+    }
+    opBuilder.setAttr("strides", stridesArray);
+    opBuilder.setAttr("padding", padding);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.dataFormat != null) {
+          opBuilder.setAttr("data_format", opts.dataFormat);
+        }
+      }
+    }
+    return new MaxPoolGradGrad<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param dataFormat Specify the data format of the input and output data. With the
+   * default format "NHWC", the data is stored in the order of:
+   *     [batch, in_height, in_width, in_channels].
+   * Alternatively, the format could be "NCHW", the data storage order of:
+   *     [batch, in_channels, in_height, in_width].
+   */
+  public static Options dataFormat(String dataFormat) {
+    return new Options().dataFormat(dataFormat);
+  }
+  
+  /**
+   * Gradients of gradients w.r.t. the input to `max_pool`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private MaxPoolGradGrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MaxPoolGradGradV2.java java-ops/org/tensorflow/op/core/MaxPoolGradGradV2.java
--- java/org/tensorflow/op/core/MaxPoolGradGradV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MaxPoolGradGradV2.java	2018-10-16 20:18:38.349432299 +0900
@@ -0,0 +1,121 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes second-order gradients of the maxpooling function.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class MaxPoolGradGradV2<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.MaxPoolGradGradV2}
+   */
+  public static class Options {
+    
+    /**
+     * @param dataFormat Specify the data format of the input and output data. With the
+     * default format "NHWC", the data is stored in the order of:
+     *     [batch, in_height, in_width, in_channels].
+     * Alternatively, the format could be "NCHW", the data storage order of:
+     *     [batch, in_channels, in_height, in_width].
+     */
+    public Options dataFormat(String dataFormat) {
+      this.dataFormat = dataFormat;
+      return this;
+    }
+    
+    private String dataFormat;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new MaxPoolGradGradV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param origInput The original input tensor.
+   * @param origOutput The original output tensor.
+   * @param grad 4-D.  Gradients of gradients w.r.t. the input of `max_pool`.
+   * @param ksize The size of the window for each dimension of the input tensor.
+   * @param strides The stride of the sliding window for each dimension of the
+   * input tensor.
+   * @param padding The type of padding algorithm to use.
+   * @param options carries optional attributes values
+   * @return a new instance of MaxPoolGradGradV2
+   */
+  public static <T extends Number> MaxPoolGradGradV2<T> create(Scope scope, Operand<T> origInput, Operand<T> origOutput, Operand<T> grad, Operand<Integer> ksize, Operand<Integer> strides, String padding, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MaxPoolGradGradV2", scope.makeOpName("MaxPoolGradGradV2"));
+    opBuilder.addInput(origInput.asOutput());
+    opBuilder.addInput(origOutput.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    opBuilder.addInput(ksize.asOutput());
+    opBuilder.addInput(strides.asOutput());
+    opBuilder.setAttr("padding", padding);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.dataFormat != null) {
+          opBuilder.setAttr("data_format", opts.dataFormat);
+        }
+      }
+    }
+    return new MaxPoolGradGradV2<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param dataFormat Specify the data format of the input and output data. With the
+   * default format "NHWC", the data is stored in the order of:
+   *     [batch, in_height, in_width, in_channels].
+   * Alternatively, the format could be "NCHW", the data storage order of:
+   *     [batch, in_channels, in_height, in_width].
+   */
+  public static Options dataFormat(String dataFormat) {
+    return new Options().dataFormat(dataFormat);
+  }
+  
+  /**
+   * Gradients of gradients w.r.t. the input to `max_pool`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private MaxPoolGradGradV2(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MaxPoolGradGradWithArgmax.java java-ops/org/tensorflow/op/core/MaxPoolGradGradWithArgmax.java
--- java/org/tensorflow/op/core/MaxPoolGradGradWithArgmax.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MaxPoolGradGradWithArgmax.java	2018-10-16 20:18:38.349432299 +0900
@@ -0,0 +1,89 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes second-order gradients of the maxpooling function.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class MaxPoolGradGradWithArgmax<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new MaxPoolGradGradWithArgmax operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input The original input.
+   * @param grad 4-D with shape `[batch, height, width, channels]`.  Gradients w.r.t. the
+   * input of `max_pool`.
+   * @param argmax The indices of the maximum values chosen for each output of `max_pool`.
+   * @param ksize The size of the window for each dimension of the input tensor.
+   * @param strides The stride of the sliding window for each dimension of the
+   * input tensor.
+   * @param padding The type of padding algorithm to use.
+   * @return a new instance of MaxPoolGradGradWithArgmax
+   */
+  public static <T extends Number, U extends Number> MaxPoolGradGradWithArgmax<T> create(Scope scope, Operand<T> input, Operand<T> grad, Operand<U> argmax, List<Long> ksize, List<Long> strides, String padding) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MaxPoolGradGradWithArgmax", scope.makeOpName("MaxPoolGradGradWithArgmax"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    opBuilder.addInput(argmax.asOutput());
+    long[] ksizeArray = new long[ksize.size()];
+    for (int i = 0; i < ksizeArray.length; ++i) {
+      ksizeArray[i] = ksize.get(i);
+    }
+    opBuilder.setAttr("ksize", ksizeArray);
+    long[] stridesArray = new long[strides.size()];
+    for (int i = 0; i < stridesArray.length; ++i) {
+      stridesArray[i] = strides.get(i);
+    }
+    opBuilder.setAttr("strides", stridesArray);
+    opBuilder.setAttr("padding", padding);
+    return new MaxPoolGradGradWithArgmax<T>(opBuilder.build());
+  }
+  
+  /**
+   * Gradients of gradients w.r.t. the input of `max_pool`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private MaxPoolGradGradWithArgmax(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MaxPoolGrad.java java-ops/org/tensorflow/op/core/MaxPoolGrad.java
--- java/org/tensorflow/op/core/MaxPoolGrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MaxPoolGrad.java	2018-10-16 20:18:38.348432299 +0900
@@ -0,0 +1,128 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Computes gradients of the maxpooling function.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+public final class MaxPoolGrad<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.MaxPoolGrad}
+   */
+  public static class Options {
+    
+    /**
+     * @param dataFormat Specify the data format of the input and output data. With the
+     * default format "NHWC", the data is stored in the order of:
+     *     [batch, in_height, in_width, in_channels].
+     * Alternatively, the format could be "NCHW", the data storage order of:
+     *     [batch, in_channels, in_height, in_width].
+     */
+    public Options dataFormat(String dataFormat) {
+      this.dataFormat = dataFormat;
+      return this;
+    }
+    
+    private String dataFormat;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new MaxPoolGrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param origInput The original input tensor.
+   * @param origOutput The original output tensor.
+   * @param grad 4-D.  Gradients w.r.t. the output of `max_pool`.
+   * @param ksize The size of the window for each dimension of the input tensor.
+   * @param strides The stride of the sliding window for each dimension of the
+   * input tensor.
+   * @param padding The type of padding algorithm to use.
+   * @param options carries optional attributes values
+   * @return a new instance of MaxPoolGrad
+   */
+  public static <T extends Number> MaxPoolGrad<T> create(Scope scope, Operand<T> origInput, Operand<T> origOutput, Operand<T> grad, List<Long> ksize, List<Long> strides, String padding, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MaxPoolGrad", scope.makeOpName("MaxPoolGrad"));
+    opBuilder.addInput(origInput.asOutput());
+    opBuilder.addInput(origOutput.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    long[] ksizeArray = new long[ksize.size()];
+    for (int i = 0; i < ksizeArray.length; ++i) {
+      ksizeArray[i] = ksize.get(i);
+    }
+    opBuilder.setAttr("ksize", ksizeArray);
+    long[] stridesArray = new long[strides.size()];
+    for (int i = 0; i < stridesArray.length; ++i) {
+      stridesArray[i] = strides.get(i);
+    }
+    opBuilder.setAttr("strides", stridesArray);
+    opBuilder.setAttr("padding", padding);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.dataFormat != null) {
+          opBuilder.setAttr("data_format", opts.dataFormat);
+        }
+      }
+    }
+    return new MaxPoolGrad<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param dataFormat Specify the data format of the input and output data. With the
+   * default format "NHWC", the data is stored in the order of:
+   *     [batch, in_height, in_width, in_channels].
+   * Alternatively, the format could be "NCHW", the data storage order of:
+   *     [batch, in_channels, in_height, in_width].
+   */
+  public static Options dataFormat(String dataFormat) {
+    return new Options().dataFormat(dataFormat);
+  }
+  
+  /**
+   * Gradients w.r.t. the input to `max_pool`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private MaxPoolGrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MaxPoolGradV2.java java-ops/org/tensorflow/op/core/MaxPoolGradV2.java
--- java/org/tensorflow/op/core/MaxPoolGradV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MaxPoolGradV2.java	2018-10-16 20:18:38.350432298 +0900
@@ -0,0 +1,121 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes gradients of the maxpooling function.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class MaxPoolGradV2<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.MaxPoolGradV2}
+   */
+  public static class Options {
+    
+    /**
+     * @param dataFormat Specify the data format of the input and output data. With the
+     * default format "NHWC", the data is stored in the order of:
+     *     [batch, in_height, in_width, in_channels].
+     * Alternatively, the format could be "NCHW", the data storage order of:
+     *     [batch, in_channels, in_height, in_width].
+     */
+    public Options dataFormat(String dataFormat) {
+      this.dataFormat = dataFormat;
+      return this;
+    }
+    
+    private String dataFormat;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new MaxPoolGradV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param origInput The original input tensor.
+   * @param origOutput The original output tensor.
+   * @param grad 4-D.  Gradients w.r.t. the output of `max_pool`.
+   * @param ksize The size of the window for each dimension of the input tensor.
+   * @param strides The stride of the sliding window for each dimension of the
+   * input tensor.
+   * @param padding The type of padding algorithm to use.
+   * @param options carries optional attributes values
+   * @return a new instance of MaxPoolGradV2
+   */
+  public static <T extends Number> MaxPoolGradV2<T> create(Scope scope, Operand<T> origInput, Operand<T> origOutput, Operand<T> grad, Operand<Integer> ksize, Operand<Integer> strides, String padding, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MaxPoolGradV2", scope.makeOpName("MaxPoolGradV2"));
+    opBuilder.addInput(origInput.asOutput());
+    opBuilder.addInput(origOutput.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    opBuilder.addInput(ksize.asOutput());
+    opBuilder.addInput(strides.asOutput());
+    opBuilder.setAttr("padding", padding);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.dataFormat != null) {
+          opBuilder.setAttr("data_format", opts.dataFormat);
+        }
+      }
+    }
+    return new MaxPoolGradV2<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param dataFormat Specify the data format of the input and output data. With the
+   * default format "NHWC", the data is stored in the order of:
+   *     [batch, in_height, in_width, in_channels].
+   * Alternatively, the format could be "NCHW", the data storage order of:
+   *     [batch, in_channels, in_height, in_width].
+   */
+  public static Options dataFormat(String dataFormat) {
+    return new Options().dataFormat(dataFormat);
+  }
+  
+  /**
+   * Gradients w.r.t. the input to `max_pool`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private MaxPoolGradV2(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MaxPoolGradWithArgmax.java java-ops/org/tensorflow/op/core/MaxPoolGradWithArgmax.java
--- java/org/tensorflow/op/core/MaxPoolGradWithArgmax.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MaxPoolGradWithArgmax.java	2018-10-16 20:18:38.351432297 +0900
@@ -0,0 +1,87 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Computes gradients of the maxpooling function.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+public final class MaxPoolGradWithArgmax<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new MaxPoolGradWithArgmax operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input The original input.
+   * @param grad 4-D with shape `[batch, height, width, channels]`.  Gradients w.r.t. the
+   * output of `max_pool`.
+   * @param argmax The indices of the maximum values chosen for each output of `max_pool`.
+   * @param ksize The size of the window for each dimension of the input tensor.
+   * @param strides The stride of the sliding window for each dimension of the
+   * input tensor.
+   * @param padding The type of padding algorithm to use.
+   * @return a new instance of MaxPoolGradWithArgmax
+   */
+  public static <T extends Number, U extends Number> MaxPoolGradWithArgmax<T> create(Scope scope, Operand<T> input, Operand<T> grad, Operand<U> argmax, List<Long> ksize, List<Long> strides, String padding) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MaxPoolGradWithArgmax", scope.makeOpName("MaxPoolGradWithArgmax"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    opBuilder.addInput(argmax.asOutput());
+    long[] ksizeArray = new long[ksize.size()];
+    for (int i = 0; i < ksizeArray.length; ++i) {
+      ksizeArray[i] = ksize.get(i);
+    }
+    opBuilder.setAttr("ksize", ksizeArray);
+    long[] stridesArray = new long[strides.size()];
+    for (int i = 0; i < stridesArray.length; ++i) {
+      stridesArray[i] = strides.get(i);
+    }
+    opBuilder.setAttr("strides", stridesArray);
+    opBuilder.setAttr("padding", padding);
+    return new MaxPoolGradWithArgmax<T>(opBuilder.build());
+  }
+  
+  /**
+   * Gradients w.r.t. the input of `max_pool`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private MaxPoolGradWithArgmax(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MaxPool.java java-ops/org/tensorflow/op/core/MaxPool.java
--- java/org/tensorflow/op/core/MaxPool.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MaxPool.java	2018-10-16 20:18:38.345432301 +0900
@@ -0,0 +1,126 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Performs max pooling on the input.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class MaxPool<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.MaxPool}
+   */
+  public static class Options {
+    
+    /**
+     * @param dataFormat Specify the data format of the input and output data. With the
+     * default format "NHWC", the data is stored in the order of:
+     *     [batch, in_height, in_width, in_channels].
+     * Alternatively, the format could be "NCHW", the data storage order of:
+     *     [batch, in_channels, in_height, in_width].
+     */
+    public Options dataFormat(String dataFormat) {
+      this.dataFormat = dataFormat;
+      return this;
+    }
+    
+    private String dataFormat;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new MaxPool operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 4-D input to pool over.
+   * @param ksize The size of the window for each dimension of the input tensor.
+   * @param strides The stride of the sliding window for each dimension of the
+   * input tensor.
+   * @param padding The type of padding algorithm to use.
+   * @param options carries optional attributes values
+   * @return a new instance of MaxPool
+   */
+  public static <T> MaxPool<T> create(Scope scope, Operand<T> input, List<Long> ksize, List<Long> strides, String padding, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MaxPool", scope.makeOpName("MaxPool"));
+    opBuilder.addInput(input.asOutput());
+    long[] ksizeArray = new long[ksize.size()];
+    for (int i = 0; i < ksizeArray.length; ++i) {
+      ksizeArray[i] = ksize.get(i);
+    }
+    opBuilder.setAttr("ksize", ksizeArray);
+    long[] stridesArray = new long[strides.size()];
+    for (int i = 0; i < stridesArray.length; ++i) {
+      stridesArray[i] = strides.get(i);
+    }
+    opBuilder.setAttr("strides", stridesArray);
+    opBuilder.setAttr("padding", padding);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.dataFormat != null) {
+          opBuilder.setAttr("data_format", opts.dataFormat);
+        }
+      }
+    }
+    return new MaxPool<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param dataFormat Specify the data format of the input and output data. With the
+   * default format "NHWC", the data is stored in the order of:
+   *     [batch, in_height, in_width, in_channels].
+   * Alternatively, the format could be "NCHW", the data storage order of:
+   *     [batch, in_channels, in_height, in_width].
+   */
+  public static Options dataFormat(String dataFormat) {
+    return new Options().dataFormat(dataFormat);
+  }
+  
+  /**
+   * The max pooled output tensor.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private MaxPool(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MaxPoolV2.java java-ops/org/tensorflow/op/core/MaxPoolV2.java
--- java/org/tensorflow/op/core/MaxPoolV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MaxPoolV2.java	2018-10-16 20:18:38.351432297 +0900
@@ -0,0 +1,117 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Performs max pooling on the input.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class MaxPoolV2<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.MaxPoolV2}
+   */
+  public static class Options {
+    
+    /**
+     * @param dataFormat Specify the data format of the input and output data. With the
+     * default format "NHWC", the data is stored in the order of:
+     *     [batch, in_height, in_width, in_channels].
+     * Alternatively, the format could be "NCHW", the data storage order of:
+     *     [batch, in_channels, in_height, in_width].
+     */
+    public Options dataFormat(String dataFormat) {
+      this.dataFormat = dataFormat;
+      return this;
+    }
+    
+    private String dataFormat;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new MaxPoolV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 4-D input to pool over.
+   * @param ksize The size of the window for each dimension of the input tensor.
+   * @param strides The stride of the sliding window for each dimension of the
+   * input tensor.
+   * @param padding The type of padding algorithm to use.
+   * @param options carries optional attributes values
+   * @return a new instance of MaxPoolV2
+   */
+  public static <T> MaxPoolV2<T> create(Scope scope, Operand<T> input, Operand<Integer> ksize, Operand<Integer> strides, String padding, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MaxPoolV2", scope.makeOpName("MaxPoolV2"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(ksize.asOutput());
+    opBuilder.addInput(strides.asOutput());
+    opBuilder.setAttr("padding", padding);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.dataFormat != null) {
+          opBuilder.setAttr("data_format", opts.dataFormat);
+        }
+      }
+    }
+    return new MaxPoolV2<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param dataFormat Specify the data format of the input and output data. With the
+   * default format "NHWC", the data is stored in the order of:
+   *     [batch, in_height, in_width, in_channels].
+   * Alternatively, the format could be "NCHW", the data storage order of:
+   *     [batch, in_channels, in_height, in_width].
+   */
+  public static Options dataFormat(String dataFormat) {
+    return new Options().dataFormat(dataFormat);
+  }
+  
+  /**
+   * The max pooled output tensor.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private MaxPoolV2(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MaxPoolWithArgmax.java java-ops/org/tensorflow/op/core/MaxPoolWithArgmax.java
--- java/org/tensorflow/op/core/MaxPoolWithArgmax.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MaxPoolWithArgmax.java	2018-10-16 20:18:38.352432297 +0900
@@ -0,0 +1,116 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Performs max pooling on the input and outputs both max values and indices.
+ * <p>
+ * The indices in `argmax` are flattened, so that a maximum value at position
+ * `[b, y, x, c]` becomes flattened index
+ * `((b * height + y) * width + x) * channels + c`.
+ * <p>
+ * The indices returned are always in `[0, height) x [0, width)` before flattening,
+ * even if padding is involved and the mathematically correct answer is outside
+ * (either negative or too large).  This is a bug, but fixing it is difficult to do
+ * in a safe backwards compatible way, especially due to flattening.
+ * 
+ * @param <T> data type for {@code output()} output
+ * @param <U> data type for {@code argmax()} output
+ */
+@Operator
+public final class MaxPoolWithArgmax<T extends Number, U extends Number> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new MaxPoolWithArgmax operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 4-D with shape `[batch, height, width, channels]`.  Input to pool over.
+   * @param ksize The size of the window for each dimension of the input tensor.
+   * @param strides The stride of the sliding window for each dimension of the
+   * input tensor.
+   * @param Targmax 
+   * @param padding The type of padding algorithm to use.
+   * @return a new instance of MaxPoolWithArgmax
+   */
+  public static <T extends Number, U extends Number> MaxPoolWithArgmax<T, U> create(Scope scope, Operand<T> input, List<Long> ksize, List<Long> strides, Class<U> Targmax, String padding) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MaxPoolWithArgmax", scope.makeOpName("MaxPoolWithArgmax"));
+    opBuilder.addInput(input.asOutput());
+    long[] ksizeArray = new long[ksize.size()];
+    for (int i = 0; i < ksizeArray.length; ++i) {
+      ksizeArray[i] = ksize.get(i);
+    }
+    opBuilder.setAttr("ksize", ksizeArray);
+    long[] stridesArray = new long[strides.size()];
+    for (int i = 0; i < stridesArray.length; ++i) {
+      stridesArray[i] = strides.get(i);
+    }
+    opBuilder.setAttr("strides", stridesArray);
+    opBuilder.setAttr("Targmax", DataType.fromClass(Targmax));
+    opBuilder.setAttr("padding", padding);
+    return new MaxPoolWithArgmax<T, U>(opBuilder.build());
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new MaxPoolWithArgmax operation to the graph, using default output types.
+   * 
+   * @param scope current graph scope
+   * @param input 4-D with shape `[batch, height, width, channels]`.  Input to pool over.
+   * @param ksize The size of the window for each dimension of the input tensor.
+   * @param strides The stride of the sliding window for each dimension of the
+   * input tensor.
+   * @param padding The type of padding algorithm to use.
+   * @return a new instance of MaxPoolWithArgmax
+   */
+  public static <T extends Number> MaxPoolWithArgmax<T, Long> create(Scope scope, Operand<T> input, List<Long> ksize, List<Long> strides, String padding) {
+    return create(scope, input, ksize, strides, Long.class, padding);
+  }
+  
+  /**
+   * The max pooled output tensor.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  /**
+   * 4-D.  The flattened indices of the max values chosen for each output.
+   */
+  public Output<U> argmax() {
+    return argmax;
+  }
+  
+  private Output<T> output;
+  private Output<U> argmax;
+  
+  private MaxPoolWithArgmax(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+    argmax = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Mean.java java-ops/org/tensorflow/op/core/Mean.java
--- java/org/tensorflow/op/core/Mean.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Mean.java	2018-10-16 20:18:38.353432296 +0900
@@ -0,0 +1,110 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the mean of elements across dimensions of a tensor.
+ * <p>
+ * Reduces `input` along the dimensions given in `axis`. Unless
+ * `keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
+ * `axis`. If `keep_dims` is true, the reduced dimensions are
+ * retained with length 1.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class Mean<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Mean}
+   */
+  public static class Options {
+    
+    /**
+     * @param keepDims If true, retain reduced dimensions with length 1.
+     */
+    public Options keepDims(Boolean keepDims) {
+      this.keepDims = keepDims;
+      return this;
+    }
+    
+    private Boolean keepDims;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Mean operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input The tensor to reduce.
+   * @param axis The dimensions to reduce. Must be in the range
+   * `[-rank(input), rank(input))`.
+   * @param options carries optional attributes values
+   * @return a new instance of Mean
+   */
+  public static <T, U extends Number> Mean<T> create(Scope scope, Operand<T> input, Operand<U> axis, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Mean", scope.makeOpName("Mean"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(axis.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.keepDims != null) {
+          opBuilder.setAttr("keep_dims", opts.keepDims);
+        }
+      }
+    }
+    return new Mean<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param keepDims If true, retain reduced dimensions with length 1.
+   */
+  public static Options keepDims(Boolean keepDims) {
+    return new Options().keepDims(keepDims);
+  }
+  
+  /**
+   * The reduced tensor.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private Mean(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Merge.java java-ops/org/tensorflow/op/core/Merge.java
--- java/org/tensorflow/op/core/Merge.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Merge.java	2018-10-16 20:18:38.353432296 +0900
@@ -0,0 +1,78 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Forwards the value of an available tensor from `inputs` to `output`.
+ * <p>
+ * `Merge` waits for at least one of the tensors in `inputs` to become available.
+ * It is usually combined with `Switch` to implement branching.
+ * <p>
+ * `Merge` forwards the first tensor to become available to `output`, and sets
+ * `value_index` to its index in `inputs`.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class Merge<T> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new Merge operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputs The input tensors, exactly one of which will become available.
+   * @return a new instance of Merge
+   */
+  public static <T> Merge<T> create(Scope scope, Operand<T> inputs) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Merge", scope.makeOpName("Merge"));
+    opBuilder.addInput(inputs.asOutput());
+    return new Merge<T>(opBuilder.build());
+  }
+  
+  /**
+   * Will be set to the available input tensor.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  /**
+   * The index of the chosen input tensor in `inputs`.
+   */
+  public Output<Integer> valueIndex() {
+    return valueIndex;
+  }
+  
+  private Output<T> output;
+  private Output<Integer> valueIndex;
+  
+  private Merge(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+    valueIndex = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MergeSummary.java java-ops/org/tensorflow/op/core/MergeSummary.java
--- java/org/tensorflow/op/core/MergeSummary.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MergeSummary.java	2018-10-16 20:18:38.353432296 +0900
@@ -0,0 +1,76 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Merges summaries.
+ * <p>
+ * This op creates a
+ * [`Summary`](https://www.tensorflow.org/code/tensorflow/core/framework/summary.proto)
+ * protocol buffer that contains the union of all the values in the input
+ * summaries.
+ * <p>
+ * When the Op is run, it reports an `InvalidArgument` error if multiple values
+ * in the summaries to merge use the same tag.
+ */
+@Operator
+public final class MergeSummary extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Factory method to create a class to wrap a new MergeSummary operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputs Can be of any shape.  Each must contain serialized `Summary` protocol
+   * buffers.
+   * @return a new instance of MergeSummary
+   */
+  public static MergeSummary create(Scope scope, Iterable<Operand<String>> inputs) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MergeSummary", scope.makeOpName("MergeSummary"));
+    opBuilder.addInputList(Operands.asOutputs(inputs));
+    return new MergeSummary(opBuilder.build());
+  }
+  
+  /**
+   * Scalar. Serialized `Summary` protocol buffer.
+   */
+  public Output<String> summary() {
+    return summary;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return summary;
+  }
+  
+  private Output<String> summary;
+  
+  private MergeSummary(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    summary = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MergeV2Checkpoints.java java-ops/org/tensorflow/op/core/MergeV2Checkpoints.java
--- java/org/tensorflow/op/core/MergeV2Checkpoints.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MergeV2Checkpoints.java	2018-10-16 20:18:38.354432295 +0900
@@ -0,0 +1,96 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * V2 format specific: merges the metadata files of sharded checkpoints.  The
+ * <p>
+ * result is one logical checkpoint, with one physical metadata file and renamed
+ * data files.
+ * <p>
+ * Intended for "grouping" multiple checkpoints in a sharded checkpoint setup.
+ * <p>
+ * If delete_old_dirs is true, attempts to delete recursively the dirname of each
+ * path in the input checkpoint_prefixes.  This is useful when those paths are non
+ * user-facing temporary locations.
+ */
+@Operator
+public final class MergeV2Checkpoints extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.MergeV2Checkpoints}
+   */
+  public static class Options {
+    
+    /**
+     * @param deleteOldDirs see above.
+     */
+    public Options deleteOldDirs(Boolean deleteOldDirs) {
+      this.deleteOldDirs = deleteOldDirs;
+      return this;
+    }
+    
+    private Boolean deleteOldDirs;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new MergeV2Checkpoints operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param checkpointPrefixes prefixes of V2 checkpoints to merge.
+   * @param destinationPrefix scalar.  The desired final prefix.  Allowed to be the same
+   * as one of the checkpoint_prefixes.
+   * @param options carries optional attributes values
+   * @return a new instance of MergeV2Checkpoints
+   */
+  public static MergeV2Checkpoints create(Scope scope, Operand<String> checkpointPrefixes, Operand<String> destinationPrefix, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MergeV2Checkpoints", scope.makeOpName("MergeV2Checkpoints"));
+    opBuilder.addInput(checkpointPrefixes.asOutput());
+    opBuilder.addInput(destinationPrefix.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.deleteOldDirs != null) {
+          opBuilder.setAttr("delete_old_dirs", opts.deleteOldDirs);
+        }
+      }
+    }
+    return new MergeV2Checkpoints(opBuilder.build());
+  }
+  
+  /**
+   * @param deleteOldDirs see above.
+   */
+  public static Options deleteOldDirs(Boolean deleteOldDirs) {
+    return new Options().deleteOldDirs(deleteOldDirs);
+  }
+  
+  
+  private MergeV2Checkpoints(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Mfcc.java java-ops/org/tensorflow/op/core/Mfcc.java
--- java/org/tensorflow/op/core/Mfcc.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Mfcc.java	2018-10-16 20:18:38.354432295 +0900
@@ -0,0 +1,170 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Transforms a spectrogram into a form that's useful for speech recognition.
+ * <p>
+ * Mel Frequency Cepstral Coefficients are a way of representing audio data that's
+ * been effective as an input feature for machine learning. They are created by
+ * taking the spectrum of a spectrogram (a 'cepstrum'), and discarding some of the
+ * higher frequencies that are less significant to the human ear. They have a long
+ * history in the speech recognition world, and https://en.wikipedia.org/wiki/Mel-frequency_cepstrum
+ * is a good resource to learn more.
+ */
+@Operator
+public final class Mfcc extends PrimitiveOp implements Operand<Float> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Mfcc}
+   */
+  public static class Options {
+    
+    /**
+     * @param upperFrequencyLimit The highest frequency to use when calculating the
+     * ceptstrum.
+     */
+    public Options upperFrequencyLimit(Float upperFrequencyLimit) {
+      this.upperFrequencyLimit = upperFrequencyLimit;
+      return this;
+    }
+    
+    /**
+     * @param lowerFrequencyLimit The lowest frequency to use when calculating the
+     * ceptstrum.
+     */
+    public Options lowerFrequencyLimit(Float lowerFrequencyLimit) {
+      this.lowerFrequencyLimit = lowerFrequencyLimit;
+      return this;
+    }
+    
+    /**
+     * @param filterbankChannelCount Resolution of the Mel bank used internally.
+     */
+    public Options filterbankChannelCount(Long filterbankChannelCount) {
+      this.filterbankChannelCount = filterbankChannelCount;
+      return this;
+    }
+    
+    /**
+     * @param dctCoefficientCount How many output channels to produce per time slice.
+     */
+    public Options dctCoefficientCount(Long dctCoefficientCount) {
+      this.dctCoefficientCount = dctCoefficientCount;
+      return this;
+    }
+    
+    private Float upperFrequencyLimit;
+    private Float lowerFrequencyLimit;
+    private Long filterbankChannelCount;
+    private Long dctCoefficientCount;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Mfcc operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param spectrogram Typically produced by the Spectrogram op, with magnitude_squared
+   * set to true.
+   * @param sampleRate How many samples per second the source audio used.
+   * @param options carries optional attributes values
+   * @return a new instance of Mfcc
+   */
+  public static Mfcc create(Scope scope, Operand<Float> spectrogram, Operand<Integer> sampleRate, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Mfcc", scope.makeOpName("Mfcc"));
+    opBuilder.addInput(spectrogram.asOutput());
+    opBuilder.addInput(sampleRate.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.upperFrequencyLimit != null) {
+          opBuilder.setAttr("upper_frequency_limit", opts.upperFrequencyLimit);
+        }
+        if (opts.lowerFrequencyLimit != null) {
+          opBuilder.setAttr("lower_frequency_limit", opts.lowerFrequencyLimit);
+        }
+        if (opts.filterbankChannelCount != null) {
+          opBuilder.setAttr("filterbank_channel_count", opts.filterbankChannelCount);
+        }
+        if (opts.dctCoefficientCount != null) {
+          opBuilder.setAttr("dct_coefficient_count", opts.dctCoefficientCount);
+        }
+      }
+    }
+    return new Mfcc(opBuilder.build());
+  }
+  
+  /**
+   * @param upperFrequencyLimit The highest frequency to use when calculating the
+   * ceptstrum.
+   */
+  public static Options upperFrequencyLimit(Float upperFrequencyLimit) {
+    return new Options().upperFrequencyLimit(upperFrequencyLimit);
+  }
+  
+  /**
+   * @param lowerFrequencyLimit The lowest frequency to use when calculating the
+   * ceptstrum.
+   */
+  public static Options lowerFrequencyLimit(Float lowerFrequencyLimit) {
+    return new Options().lowerFrequencyLimit(lowerFrequencyLimit);
+  }
+  
+  /**
+   * @param filterbankChannelCount Resolution of the Mel bank used internally.
+   */
+  public static Options filterbankChannelCount(Long filterbankChannelCount) {
+    return new Options().filterbankChannelCount(filterbankChannelCount);
+  }
+  
+  /**
+   * @param dctCoefficientCount How many output channels to produce per time slice.
+   */
+  public static Options dctCoefficientCount(Long dctCoefficientCount) {
+    return new Options().dctCoefficientCount(dctCoefficientCount);
+  }
+  
+  /**
+   */
+  public Output<Float> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<Float> asOutput() {
+    return output;
+  }
+  
+  private Output<Float> output;
+  
+  private Mfcc(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Minimum.java java-ops/org/tensorflow/op/core/Minimum.java
--- java/org/tensorflow/op/core/Minimum.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Minimum.java	2018-10-16 20:18:38.355432294 +0900
@@ -0,0 +1,72 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns the min of x and y (i.e. x < y ? x : y) element-wise.
+ * <p>
+ * <i>NOTE</i>: `Minimum` supports broadcasting. More about broadcasting
+ * [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
+ * 
+ * @param <T> data type for {@code z()} output
+ */
+@Operator
+public final class Minimum<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Minimum operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param y 
+   * @return a new instance of Minimum
+   */
+  public static <T extends Number> Minimum<T> create(Scope scope, Operand<T> x, Operand<T> y) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Minimum", scope.makeOpName("Minimum"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(y.asOutput());
+    return new Minimum<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return z;
+  }
+  
+  private Output<T> z;
+  
+  private Minimum(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Min.java java-ops/org/tensorflow/op/core/Min.java
--- java/org/tensorflow/op/core/Min.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Min.java	2018-10-16 20:18:38.355432294 +0900
@@ -0,0 +1,110 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the minimum of elements across dimensions of a tensor.
+ * <p>
+ * Reduces `input` along the dimensions given in `axis`. Unless
+ * `keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
+ * `axis`. If `keep_dims` is true, the reduced dimensions are
+ * retained with length 1.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class Min<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Min}
+   */
+  public static class Options {
+    
+    /**
+     * @param keepDims If true, retain reduced dimensions with length 1.
+     */
+    public Options keepDims(Boolean keepDims) {
+      this.keepDims = keepDims;
+      return this;
+    }
+    
+    private Boolean keepDims;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Min operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input The tensor to reduce.
+   * @param axis The dimensions to reduce. Must be in the range
+   * `[-rank(input), rank(input))`.
+   * @param options carries optional attributes values
+   * @return a new instance of Min
+   */
+  public static <T, U extends Number> Min<T> create(Scope scope, Operand<T> input, Operand<U> axis, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Min", scope.makeOpName("Min"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(axis.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.keepDims != null) {
+          opBuilder.setAttr("keep_dims", opts.keepDims);
+        }
+      }
+    }
+    return new Min<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param keepDims If true, retain reduced dimensions with length 1.
+   */
+  public static Options keepDims(Boolean keepDims) {
+    return new Options().keepDims(keepDims);
+  }
+  
+  /**
+   * The reduced tensor.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private Min(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MirrorPadGrad.java java-ops/org/tensorflow/op/core/MirrorPadGrad.java
--- java/org/tensorflow/op/core/MirrorPadGrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MirrorPadGrad.java	2018-10-16 20:18:38.357432293 +0900
@@ -0,0 +1,90 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Gradient op for `MirrorPad` op. This op folds a mirror-padded tensor.
+ * <p>
+ * This operation folds the padded areas of `input` by `MirrorPad` according to the
+ * `paddings` you specify. `paddings` must be the same as `paddings` argument
+ * given to the corresponding `MirrorPad` op.
+ * <p>
+ * The folded size of each dimension D of the output is:
+ * <p>
+ * `input.dim_size(D) - paddings(D, 0) - paddings(D, 1)`
+ * <p>
+ * For example:
+ * <pre>{@code
+ * # 't' is [[1, 2, 3], [4, 5, 6], [7, 8, 9]].
+ * # 'paddings' is [[0, 1]], [0, 1]].
+ * # 'mode' is SYMMETRIC.
+ * # rank of 't' is 2.
+ * pad(t, paddings) ==> [[ 1,  5]
+ *                       [11, 28]]
+ * }</pre>
+ * 
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+public final class MirrorPadGrad<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new MirrorPadGrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input The input tensor to be folded.
+   * @param paddings A two-column matrix specifying the padding sizes. The number of
+   * rows must be the same as the rank of `input`.
+   * @param mode The mode used in the `MirrorPad` op.
+   * @return a new instance of MirrorPadGrad
+   */
+  public static <T, U extends Number> MirrorPadGrad<T> create(Scope scope, Operand<T> input, Operand<U> paddings, String mode) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MirrorPadGrad", scope.makeOpName("MirrorPadGrad"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(paddings.asOutput());
+    opBuilder.setAttr("mode", mode);
+    return new MirrorPadGrad<T>(opBuilder.build());
+  }
+  
+  /**
+   * The folded tensor.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private MirrorPadGrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MirrorPad.java java-ops/org/tensorflow/op/core/MirrorPad.java
--- java/org/tensorflow/op/core/MirrorPad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MirrorPad.java	2018-10-16 20:18:38.356432294 +0900
@@ -0,0 +1,103 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Pads a tensor with mirrored values.
+ * <p>
+ * This operation pads a `input` with mirrored values according to the `paddings`
+ * you specify. `paddings` is an integer tensor with shape `[n, 2]`, where n is
+ * the rank of `input`. For each dimension D of `input`, `paddings[D, 0]` indicates
+ * how many values to add before the contents of `input` in that dimension, and
+ * `paddings[D, 1]` indicates how many values to add after the contents of `input`
+ * in that dimension. Both `paddings[D, 0]` and `paddings[D, 1]` must be no greater
+ * than `input.dim_size(D)` (or `input.dim_size(D) - 1`) if `copy_border` is true
+ * (if false, respectively).
+ * <p>
+ * The padded size of each dimension D of the output is:
+ * <p>
+ * `paddings(D, 0) + input.dim_size(D) + paddings(D, 1)`
+ * <p>
+ * For example:
+ * <pre>{@code
+ * # 't' is [[1, 2, 3], [4, 5, 6]].
+ * # 'paddings' is [[1, 1]], [2, 2]].
+ * # 'mode' is SYMMETRIC.
+ * # rank of 't' is 2.
+ * pad(t, paddings) ==> [[2, 1, 1, 2, 3, 3, 2]
+ *                       [2, 1, 1, 2, 3, 3, 2]
+ *                       [5, 4, 4, 5, 6, 6, 5]
+ *                       [5, 4, 4, 5, 6, 6, 5]]
+ * }</pre>
+ * 
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class MirrorPad<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new MirrorPad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input The input tensor to be padded.
+   * @param paddings A two-column matrix specifying the padding sizes. The number of
+   * rows must be the same as the rank of `input`.
+   * @param mode Either `REFLECT` or `SYMMETRIC`. In reflect mode the padded regions
+   * do not include the borders, while in symmetric mode the padded regions
+   * do include the borders. For example, if `input` is `[1, 2, 3]` and `paddings`
+   * is `[0, 2]`, then the output is `[1, 2, 3, 2, 1]` in reflect mode, and
+   * it is `[1, 2, 3, 3, 2]` in symmetric mode.
+   * @return a new instance of MirrorPad
+   */
+  public static <T, U extends Number> MirrorPad<T> create(Scope scope, Operand<T> input, Operand<U> paddings, String mode) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MirrorPad", scope.makeOpName("MirrorPad"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(paddings.asOutput());
+    opBuilder.setAttr("mode", mode);
+    return new MirrorPad<T>(opBuilder.build());
+  }
+  
+  /**
+   * The padded tensor.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private MirrorPad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ModelDataset.java java-ops/org/tensorflow/op/core/ModelDataset.java
--- java/org/tensorflow/op/core/ModelDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ModelDataset.java	2018-10-16 20:18:38.357432293 +0900
@@ -0,0 +1,81 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Identity transformation that models performance.
+ * <p>
+ * Identity transformation that models performance.
+ */
+public final class ModelDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new ModelDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputDataset A variant tensor representing the input dataset.
+   * @param outputTypes 
+   * @param outputShapes 
+   * @return a new instance of ModelDataset
+   */
+  public static ModelDataset create(Scope scope, Operand<?> inputDataset, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ModelDataset", scope.makeOpName("ModelDataset"));
+    opBuilder.addInput(inputDataset.asOutput());
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new ModelDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private ModelDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Mod.java java-ops/org/tensorflow/op/core/Mod.java
--- java/org/tensorflow/op/core/Mod.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Mod.java	2018-10-16 20:18:38.357432293 +0900
@@ -0,0 +1,75 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns element-wise remainder of division. This emulates C semantics in that
+ * <p>
+ * the result here is consistent with a truncating divide. E.g.
+ * `tf.truncatediv(x, y) * y + truncate_mod(x, y) = x`.
+ * <p>
+ * <i>NOTE</i>: `Mod` supports broadcasting. More about broadcasting
+ * [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
+ * 
+ * @param <T> data type for {@code z()} output
+ */
+@Operator
+public final class Mod<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Mod operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param y 
+   * @return a new instance of Mod
+   */
+  public static <T extends Number> Mod<T> create(Scope scope, Operand<T> x, Operand<T> y) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Mod", scope.makeOpName("Mod"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(y.asOutput());
+    return new Mod<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return z;
+  }
+  
+  private Output<T> z;
+  
+  private Mod(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Mul.java java-ops/org/tensorflow/op/core/Mul.java
--- java/org/tensorflow/op/core/Mul.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Mul.java	2018-10-16 20:18:38.358432292 +0900
@@ -0,0 +1,72 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns x * y element-wise.
+ * <p>
+ * <i>NOTE</i>: `Multiply` supports broadcasting. More about broadcasting
+ * [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
+ * 
+ * @param <T> data type for {@code z()} output
+ */
+@Operator
+public final class Mul<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Mul operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param y 
+   * @return a new instance of Mul
+   */
+  public static <T> Mul<T> create(Scope scope, Operand<T> x, Operand<T> y) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Mul", scope.makeOpName("Mul"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(y.asOutput());
+    return new Mul<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return z;
+  }
+  
+  private Output<T> z;
+  
+  private Mul(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MultiDeviceIteratorFromStringHandle.java java-ops/org/tensorflow/op/core/MultiDeviceIteratorFromStringHandle.java
--- java/org/tensorflow/op/core/MultiDeviceIteratorFromStringHandle.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MultiDeviceIteratorFromStringHandle.java	2018-10-16 20:18:38.359432292 +0900
@@ -0,0 +1,112 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Generates a MultiDeviceIterator resource from its provided string handle.
+ */
+public final class MultiDeviceIteratorFromStringHandle extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.MultiDeviceIteratorFromStringHandle}
+   */
+  public static class Options {
+    
+    /**
+     * @param outputShapes The list of shapes being produced.
+     */
+    public Options outputShapes(List<Shape> outputShapes) {
+      this.outputShapes = outputShapes;
+      return this;
+    }
+    
+    private List<Shape> outputShapes;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new MultiDeviceIteratorFromStringHandle operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param stringHandle String representing the resource.
+   * @param outputTypes The type list for the return values.
+   * @param options carries optional attributes values
+   * @return a new instance of MultiDeviceIteratorFromStringHandle
+   */
+  public static MultiDeviceIteratorFromStringHandle create(Scope scope, Operand<String> stringHandle, List<Class<?>> outputTypes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MultiDeviceIteratorFromStringHandle", scope.makeOpName("MultiDeviceIteratorFromStringHandle"));
+    opBuilder.addInput(stringHandle.asOutput());
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.outputShapes != null) {
+          Shape[] outputShapesArray = new Shape[opts.outputShapes.size()];
+          for (int i = 0; i < outputShapesArray.length; ++i) {
+            outputShapesArray[i] = opts.outputShapes.get(i);
+          }
+          opBuilder.setAttr("output_shapes", outputShapesArray);
+        }
+      }
+    }
+    return new MultiDeviceIteratorFromStringHandle(opBuilder.build());
+  }
+  
+  /**
+   * @param outputShapes The list of shapes being produced.
+   */
+  public static Options outputShapes(List<Shape> outputShapes) {
+    return new Options().outputShapes(outputShapes);
+  }
+  
+  /**
+   * A MultiDeviceIterator resource.
+   */
+  public Output<?> multiDeviceIterator() {
+    return multiDeviceIterator;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) multiDeviceIterator;
+  }
+  
+  private Output<?> multiDeviceIterator;
+  
+  private MultiDeviceIteratorFromStringHandle(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    multiDeviceIterator = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MultiDeviceIteratorGetNextFromShard.java java-ops/org/tensorflow/op/core/MultiDeviceIteratorGetNextFromShard.java
--- java/org/tensorflow/op/core/MultiDeviceIteratorGetNextFromShard.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MultiDeviceIteratorGetNextFromShard.java	2018-10-16 20:18:38.359432292 +0900
@@ -0,0 +1,88 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.Iterator;
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Gets next element for the provided shard number.
+ */
+public final class MultiDeviceIteratorGetNextFromShard extends PrimitiveOp implements Iterable<Operand<Object>> {
+  
+  /**
+   * Factory method to create a class to wrap a new MultiDeviceIteratorGetNextFromShard operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param multiDeviceIterator A MultiDeviceIterator resource.
+   * @param shardNum Integer representing which shard to fetch data for.
+   * @param incarnationId Which incarnation of the MultiDeviceIterator is running.
+   * @param outputTypes The type list for the return values.
+   * @param outputShapes The list of shapes being produced.
+   * @return a new instance of MultiDeviceIteratorGetNextFromShard
+   */
+  public static MultiDeviceIteratorGetNextFromShard create(Scope scope, Operand<?> multiDeviceIterator, Operand<Integer> shardNum, Operand<Long> incarnationId, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MultiDeviceIteratorGetNextFromShard", scope.makeOpName("MultiDeviceIteratorGetNextFromShard"));
+    opBuilder.addInput(multiDeviceIterator.asOutput());
+    opBuilder.addInput(shardNum.asOutput());
+    opBuilder.addInput(incarnationId.asOutput());
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new MultiDeviceIteratorGetNextFromShard(opBuilder.build());
+  }
+  
+  /**
+   * Result of the get_next on the dataset.
+   */
+  public List<Output<?>> components() {
+    return components;
+  }
+  
+  @Override
+  @SuppressWarnings({"rawtypes", "unchecked"})
+  public Iterator<Operand<Object>> iterator() {
+    return (Iterator) components.iterator();
+  }
+  
+  private List<Output<?>> components;
+  
+  private MultiDeviceIteratorGetNextFromShard(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    int componentsLength = operation.outputListLength("components");
+    components = Arrays.asList(operation.outputList(outputIdx, componentsLength));
+    outputIdx += componentsLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/MultiDeviceIteratorInit.java java-ops/org/tensorflow/op/core/MultiDeviceIteratorInit.java
--- java/org/tensorflow/op/core/MultiDeviceIteratorInit.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MultiDeviceIteratorInit.java	2018-10-16 20:18:38.359432292 +0900
@@ -0,0 +1,69 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Initializes the multi device iterator with the given dataset.
+ */
+public final class MultiDeviceIteratorInit extends PrimitiveOp implements Operand<Long> {
+  
+  /**
+   * Factory method to create a class to wrap a new MultiDeviceIteratorInit operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param dataset Dataset to be iterated upon.
+   * @param multiDeviceIterator A MultiDeviceIteratorResource.
+   * @param maxBufferSize The maximum size of the host side per device buffer to keep.
+   * @return a new instance of MultiDeviceIteratorInit
+   */
+  public static MultiDeviceIteratorInit create(Scope scope, Operand<?> dataset, Operand<?> multiDeviceIterator, Operand<Long> maxBufferSize) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MultiDeviceIteratorInit", scope.makeOpName("MultiDeviceIteratorInit"));
+    opBuilder.addInput(dataset.asOutput());
+    opBuilder.addInput(multiDeviceIterator.asOutput());
+    opBuilder.addInput(maxBufferSize.asOutput());
+    return new MultiDeviceIteratorInit(opBuilder.build());
+  }
+  
+  /**
+   * An int64 indicating which incarnation of the MultiDeviceIterator
+   * is running.
+   */
+  public Output<Long> incarnationId() {
+    return incarnationId;
+  }
+  
+  @Override
+  public Output<Long> asOutput() {
+    return incarnationId;
+  }
+  
+  private Output<Long> incarnationId;
+  
+  private MultiDeviceIteratorInit(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    incarnationId = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MultiDeviceIterator.java java-ops/org/tensorflow/op/core/MultiDeviceIterator.java
--- java/org/tensorflow/op/core/MultiDeviceIterator.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MultiDeviceIterator.java	2018-10-16 20:18:38.359432292 +0900
@@ -0,0 +1,90 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Creates a MultiDeviceIterator resource.
+ */
+public final class MultiDeviceIterator extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new MultiDeviceIterator operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param devices A list of devices the iterator works across.
+   * @param sharedName If non-empty, this resource will be shared under the given name
+   * across multiple sessions.
+   * @param container If non-empty, this resource is placed in the given container.
+   * Otherwise, a default container is used.
+   * @param outputTypes The type list for the return values.
+   * @param outputShapes The list of shapes being produced.
+   * @return a new instance of MultiDeviceIterator
+   */
+  public static MultiDeviceIterator create(Scope scope, List<String> devices, String sharedName, String container, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MultiDeviceIterator", scope.makeOpName("MultiDeviceIterator"));
+    String[] devicesArray = new String[devices.size()];
+    for (int i = 0; i < devicesArray.length; ++i) {
+      devicesArray[i] = devices.get(i);
+    }
+    opBuilder.setAttr("devices", devicesArray);
+    opBuilder.setAttr("shared_name", sharedName);
+    opBuilder.setAttr("container", container);
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new MultiDeviceIterator(opBuilder.build());
+  }
+  
+  /**
+   * Handle to the resource created.
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private MultiDeviceIterator(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MultiDeviceIteratorToStringHandle.java java-ops/org/tensorflow/op/core/MultiDeviceIteratorToStringHandle.java
--- java/org/tensorflow/op/core/MultiDeviceIteratorToStringHandle.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MultiDeviceIteratorToStringHandle.java	2018-10-16 20:18:38.360432291 +0900
@@ -0,0 +1,64 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Produces a string handle for the given MultiDeviceIterator.
+ */
+public final class MultiDeviceIteratorToStringHandle extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Factory method to create a class to wrap a new MultiDeviceIteratorToStringHandle operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param multiDeviceIterator A MultiDeviceIterator resource.
+   * @return a new instance of MultiDeviceIteratorToStringHandle
+   */
+  public static MultiDeviceIteratorToStringHandle create(Scope scope, Operand<?> multiDeviceIterator) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MultiDeviceIteratorToStringHandle", scope.makeOpName("MultiDeviceIteratorToStringHandle"));
+    opBuilder.addInput(multiDeviceIterator.asOutput());
+    return new MultiDeviceIteratorToStringHandle(opBuilder.build());
+  }
+  
+  /**
+   * A string representing the resource.
+   */
+  public Output<String> stringHandle() {
+    return stringHandle;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return stringHandle;
+  }
+  
+  private Output<String> stringHandle;
+  
+  private MultiDeviceIteratorToStringHandle(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    stringHandle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Multinomial.java java-ops/org/tensorflow/op/core/Multinomial.java
--- java/org/tensorflow/op/core/Multinomial.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Multinomial.java	2018-10-16 20:18:38.360432291 +0900
@@ -0,0 +1,144 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Draws samples from a multinomial distribution.
+ * 
+ * @param <U> data type for {@code output()} output
+ */
+@Operator
+public final class Multinomial<U extends Number> extends PrimitiveOp implements Operand<U> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Multinomial}
+   */
+  public static class Options {
+    
+    /**
+     * @param seed If either seed or seed2 is set to be non-zero, the internal random number
+     * generator is seeded by the given seed.  Otherwise, a random seed is used.
+     */
+    public Options seed(Long seed) {
+      this.seed = seed;
+      return this;
+    }
+    
+    /**
+     * @param seed2 A second seed to avoid seed collision.
+     */
+    public Options seed2(Long seed2) {
+      this.seed2 = seed2;
+      return this;
+    }
+    
+    private Long seed;
+    private Long seed2;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Multinomial operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param logits 2-D Tensor with shape `[batch_size, num_classes]`.  Each slice `[i, :]`
+   * represents the unnormalized log probabilities for all classes.
+   * @param numSamples 0-D.  Number of independent samples to draw for each row slice.
+   * @param outputDtype 
+   * @param options carries optional attributes values
+   * @return a new instance of Multinomial
+   */
+  public static <U extends Number, T extends Number> Multinomial<U> create(Scope scope, Operand<T> logits, Operand<Integer> numSamples, Class<U> outputDtype, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Multinomial", scope.makeOpName("Multinomial"));
+    opBuilder.addInput(logits.asOutput());
+    opBuilder.addInput(numSamples.asOutput());
+    opBuilder.setAttr("output_dtype", DataType.fromClass(outputDtype));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.seed != null) {
+          opBuilder.setAttr("seed", opts.seed);
+        }
+        if (opts.seed2 != null) {
+          opBuilder.setAttr("seed2", opts.seed2);
+        }
+      }
+    }
+    return new Multinomial<U>(opBuilder.build());
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Multinomial operation to the graph, using default output types.
+   * 
+   * @param scope current graph scope
+   * @param logits 2-D Tensor with shape `[batch_size, num_classes]`.  Each slice `[i, :]`
+   * represents the unnormalized log probabilities for all classes.
+   * @param numSamples 0-D.  Number of independent samples to draw for each row slice.
+   * @param options carries optional attributes values
+   * @return a new instance of Multinomial
+   */
+  public static <T extends Number> Multinomial<Long> create(Scope scope, Operand<T> logits, Operand<Integer> numSamples, Options... options) {
+    return create(scope, logits, numSamples, Long.class, options);
+  }
+  
+  /**
+   * @param seed If either seed or seed2 is set to be non-zero, the internal random number
+   * generator is seeded by the given seed.  Otherwise, a random seed is used.
+   */
+  public static Options seed(Long seed) {
+    return new Options().seed(seed);
+  }
+  
+  /**
+   * @param seed2 A second seed to avoid seed collision.
+   */
+  public static Options seed2(Long seed2) {
+    return new Options().seed2(seed2);
+  }
+  
+  /**
+   * 2-D Tensor with shape `[batch_size, num_samples]`.  Each slice `[i, :]`
+   * contains the drawn class labels with range `[0, num_classes)`.
+   */
+  public Output<U> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<U> asOutput() {
+    return output;
+  }
+  
+  private Output<U> output;
+  
+  private Multinomial(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Multiply.java java-ops/org/tensorflow/op/core/Multiply.java
--- java/org/tensorflow/op/core/Multiply.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Multiply.java	2018-10-16 20:18:38.358432292 +0900
@@ -0,0 +1,72 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns x * y element-wise.
+ * <p>
+ * <i>NOTE</i>: `Multiply` supports broadcasting. More about broadcasting
+ * [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
+ * 
+ * @param <T> data type for {@code z()} output
+ */
+@Operator
+public final class Multiply<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Multiply operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param y 
+   * @return a new instance of Multiply
+   */
+  public static <T> Multiply<T> create(Scope scope, Operand<T> x, Operand<T> y) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Mul", scope.makeOpName("Multiply"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(y.asOutput());
+    return new Multiply<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return z;
+  }
+  
+  private Output<T> z;
+  
+  private Multiply(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MutableDenseHashTable.java java-ops/org/tensorflow/op/core/MutableDenseHashTable.java
--- java/org/tensorflow/op/core/MutableDenseHashTable.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MutableDenseHashTable.java	2018-10-16 20:18:38.361432290 +0900
@@ -0,0 +1,216 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Creates an empty hash table that uses tensors as the backing store.
+ * <p>
+ * It uses "open addressing" with quadratic reprobing to resolve
+ * collisions.
+ * <p>
+ * This op creates a mutable hash table, specifying the type of its keys and
+ * values. Each value must be a scalar. Data can be inserted into the table using
+ * the insert operations. It does not support the initialization operation.
+ */
+@Operator
+public final class MutableDenseHashTable extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.MutableDenseHashTable}
+   */
+  public static class Options {
+    
+    /**
+     * @param container If non-empty, this table is placed in the given container.
+     * Otherwise, a default container is used.
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName If non-empty, this table is shared under the given name across
+     * multiple sessions.
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    /**
+     * @param useNodeNameSharing 
+     */
+    public Options useNodeNameSharing(Boolean useNodeNameSharing) {
+      this.useNodeNameSharing = useNodeNameSharing;
+      return this;
+    }
+    
+    /**
+     * @param valueShape The shape of each value.
+     */
+    public Options valueShape(Shape valueShape) {
+      this.valueShape = valueShape;
+      return this;
+    }
+    
+    /**
+     * @param initialNumBuckets The initial number of hash table buckets. Must be a power
+     * to 2.
+     */
+    public Options initialNumBuckets(Long initialNumBuckets) {
+      this.initialNumBuckets = initialNumBuckets;
+      return this;
+    }
+    
+    /**
+     * @param maxLoadFactor The maximum ratio between number of entries and number of
+     * buckets before growing the table. Must be between 0 and 1.
+     */
+    public Options maxLoadFactor(Float maxLoadFactor) {
+      this.maxLoadFactor = maxLoadFactor;
+      return this;
+    }
+    
+    private String container;
+    private String sharedName;
+    private Boolean useNodeNameSharing;
+    private Shape valueShape;
+    private Long initialNumBuckets;
+    private Float maxLoadFactor;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new MutableDenseHashTable operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param emptyKey The key used to represent empty key buckets internally. Must not
+   * be used in insert or lookup operations.
+   * @param valueDtype Type of the table values.
+   * @param options carries optional attributes values
+   * @return a new instance of MutableDenseHashTable
+   */
+  public static <T, U> MutableDenseHashTable create(Scope scope, Operand<T> emptyKey, Class<U> valueDtype, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MutableDenseHashTableV2", scope.makeOpName("MutableDenseHashTable"));
+    opBuilder.addInput(emptyKey.asOutput());
+    opBuilder.setAttr("value_dtype", DataType.fromClass(valueDtype));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+        if (opts.useNodeNameSharing != null) {
+          opBuilder.setAttr("use_node_name_sharing", opts.useNodeNameSharing);
+        }
+        if (opts.valueShape != null) {
+          opBuilder.setAttr("value_shape", opts.valueShape);
+        }
+        if (opts.initialNumBuckets != null) {
+          opBuilder.setAttr("initial_num_buckets", opts.initialNumBuckets);
+        }
+        if (opts.maxLoadFactor != null) {
+          opBuilder.setAttr("max_load_factor", opts.maxLoadFactor);
+        }
+      }
+    }
+    return new MutableDenseHashTable(opBuilder.build());
+  }
+  
+  /**
+   * @param container If non-empty, this table is placed in the given container.
+   * Otherwise, a default container is used.
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName If non-empty, this table is shared under the given name across
+   * multiple sessions.
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   * @param useNodeNameSharing 
+   */
+  public static Options useNodeNameSharing(Boolean useNodeNameSharing) {
+    return new Options().useNodeNameSharing(useNodeNameSharing);
+  }
+  
+  /**
+   * @param valueShape The shape of each value.
+   */
+  public static Options valueShape(Shape valueShape) {
+    return new Options().valueShape(valueShape);
+  }
+  
+  /**
+   * @param initialNumBuckets The initial number of hash table buckets. Must be a power
+   * to 2.
+   */
+  public static Options initialNumBuckets(Long initialNumBuckets) {
+    return new Options().initialNumBuckets(initialNumBuckets);
+  }
+  
+  /**
+   * @param maxLoadFactor The maximum ratio between number of entries and number of
+   * buckets before growing the table. Must be between 0 and 1.
+   */
+  public static Options maxLoadFactor(Float maxLoadFactor) {
+    return new Options().maxLoadFactor(maxLoadFactor);
+  }
+  
+  /**
+   * Handle to a table.
+   */
+  public Output<?> tableHandle() {
+    return tableHandle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) tableHandle;
+  }
+  
+  private Output<?> tableHandle;
+  
+  private MutableDenseHashTable(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    tableHandle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MutableHashTable.java java-ops/org/tensorflow/op/core/MutableHashTable.java
--- java/org/tensorflow/op/core/MutableHashTable.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MutableHashTable.java	2018-10-16 20:18:38.362432289 +0900
@@ -0,0 +1,152 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Creates an empty hash table.
+ * <p>
+ * This op creates a mutable hash table, specifying the type of its keys and
+ * values. Each value must be a scalar. Data can be inserted into the table using
+ * the insert operations. It does not support the initialization operation.
+ */
+@Operator
+public final class MutableHashTable extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.MutableHashTable}
+   */
+  public static class Options {
+    
+    /**
+     * @param container If non-empty, this table is placed in the given container.
+     * Otherwise, a default container is used.
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName If non-empty, this table is shared under the given name across
+     * multiple sessions.
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    /**
+     * @param useNodeNameSharing If true and shared_name is empty, the table is shared
+     * using the node name.
+     */
+    public Options useNodeNameSharing(Boolean useNodeNameSharing) {
+      this.useNodeNameSharing = useNodeNameSharing;
+      return this;
+    }
+    
+    private String container;
+    private String sharedName;
+    private Boolean useNodeNameSharing;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new MutableHashTable operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param keyDtype Type of the table keys.
+   * @param valueDtype Type of the table values.
+   * @param options carries optional attributes values
+   * @return a new instance of MutableHashTable
+   */
+  public static <T, U> MutableHashTable create(Scope scope, Class<T> keyDtype, Class<U> valueDtype, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MutableHashTableV2", scope.makeOpName("MutableHashTable"));
+    opBuilder.setAttr("key_dtype", DataType.fromClass(keyDtype));
+    opBuilder.setAttr("value_dtype", DataType.fromClass(valueDtype));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+        if (opts.useNodeNameSharing != null) {
+          opBuilder.setAttr("use_node_name_sharing", opts.useNodeNameSharing);
+        }
+      }
+    }
+    return new MutableHashTable(opBuilder.build());
+  }
+  
+  /**
+   * @param container If non-empty, this table is placed in the given container.
+   * Otherwise, a default container is used.
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName If non-empty, this table is shared under the given name across
+   * multiple sessions.
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   * @param useNodeNameSharing If true and shared_name is empty, the table is shared
+   * using the node name.
+   */
+  public static Options useNodeNameSharing(Boolean useNodeNameSharing) {
+    return new Options().useNodeNameSharing(useNodeNameSharing);
+  }
+  
+  /**
+   * Handle to a table.
+   */
+  public Output<?> tableHandle() {
+    return tableHandle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) tableHandle;
+  }
+  
+  private Output<?> tableHandle;
+  
+  private MutableHashTable(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    tableHandle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MutableHashTableOfTensors.java java-ops/org/tensorflow/op/core/MutableHashTableOfTensors.java
--- java/org/tensorflow/op/core/MutableHashTableOfTensors.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MutableHashTableOfTensors.java	2018-10-16 20:18:38.361432290 +0900
@@ -0,0 +1,170 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Creates an empty hash table.
+ * <p>
+ * This op creates a mutable hash table, specifying the type of its keys and
+ * values. Each value must be a vector. Data can be inserted into the table using
+ * the insert operations. It does not support the initialization operation.
+ */
+@Operator
+public final class MutableHashTableOfTensors extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.MutableHashTableOfTensors}
+   */
+  public static class Options {
+    
+    /**
+     * @param container If non-empty, this table is placed in the given container.
+     * Otherwise, a default container is used.
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName If non-empty, this table is shared under the given name across
+     * multiple sessions.
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    /**
+     * @param useNodeNameSharing 
+     */
+    public Options useNodeNameSharing(Boolean useNodeNameSharing) {
+      this.useNodeNameSharing = useNodeNameSharing;
+      return this;
+    }
+    
+    /**
+     * @param valueShape 
+     */
+    public Options valueShape(Shape valueShape) {
+      this.valueShape = valueShape;
+      return this;
+    }
+    
+    private String container;
+    private String sharedName;
+    private Boolean useNodeNameSharing;
+    private Shape valueShape;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new MutableHashTableOfTensors operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param keyDtype Type of the table keys.
+   * @param valueDtype Type of the table values.
+   * @param options carries optional attributes values
+   * @return a new instance of MutableHashTableOfTensors
+   */
+  public static <T, U> MutableHashTableOfTensors create(Scope scope, Class<T> keyDtype, Class<U> valueDtype, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MutableHashTableOfTensorsV2", scope.makeOpName("MutableHashTableOfTensors"));
+    opBuilder.setAttr("key_dtype", DataType.fromClass(keyDtype));
+    opBuilder.setAttr("value_dtype", DataType.fromClass(valueDtype));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+        if (opts.useNodeNameSharing != null) {
+          opBuilder.setAttr("use_node_name_sharing", opts.useNodeNameSharing);
+        }
+        if (opts.valueShape != null) {
+          opBuilder.setAttr("value_shape", opts.valueShape);
+        }
+      }
+    }
+    return new MutableHashTableOfTensors(opBuilder.build());
+  }
+  
+  /**
+   * @param container If non-empty, this table is placed in the given container.
+   * Otherwise, a default container is used.
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName If non-empty, this table is shared under the given name across
+   * multiple sessions.
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   * @param useNodeNameSharing 
+   */
+  public static Options useNodeNameSharing(Boolean useNodeNameSharing) {
+    return new Options().useNodeNameSharing(useNodeNameSharing);
+  }
+  
+  /**
+   * @param valueShape 
+   */
+  public static Options valueShape(Shape valueShape) {
+    return new Options().valueShape(valueShape);
+  }
+  
+  /**
+   * Handle to a table.
+   */
+  public Output<?> tableHandle() {
+    return tableHandle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) tableHandle;
+  }
+  
+  private Output<?> tableHandle;
+  
+  private MutableHashTableOfTensors(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    tableHandle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MutexLock.java java-ops/org/tensorflow/op/core/MutexLock.java
--- java/org/tensorflow/op/core/MutexLock.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MutexLock.java	2018-10-16 20:18:38.362432289 +0900
@@ -0,0 +1,105 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Locks a mutex resource.  The output is the lock.  So long as the lock tensor
+ * <p>
+ * is alive, any other request to use `MutexLock` with this mutex will wait.
+ * <p>
+ * This is particularly useful for creating a critical section when used in
+ * conjunction with `MutexLockIdentity`:
+ * <pre>{@code
+ * mutex = mutex_v2(
+ *   shared_name=handle_name, container=container, name=name)
+ * 
+ * def execute_in_critical_section(fn, *args, **kwargs):
+ *   lock = gen_resource_variable_ops.mutex_lock(mutex)
+ * 
+ *   with ops.control_dependencies([lock]):
+ *     r = fn(*args, **kwargs)
+ * 
+ *   with ops.control_dependencies(nest.flatten(r)):
+ *     with ops.colocate_with(mutex):
+ *       ensure_lock_exists = mutex_lock_identity(lock)
+ * 
+ *     # Make sure that if any element of r is accessed, all of
+ *     # them are executed together.
+ *     r = nest.map_structure(tf.identity, r)
+ * 
+ *   with ops.control_dependencies([ensure_lock_exists]):
+ *     return nest.map_structure(tf.identity, r)
+ * }</pre>
+ * While `fn` is running in the critical section, no other functions which wish to
+ * use this critical section may run.
+ * <p>
+ * Often the use case is that two executions of the same graph, in parallel,
+ * wish to run `fn`; and we wish to ensure that only one of them executes
+ * at a time.  This is especially important if `fn` modifies one or more
+ * variables at a time.
+ * <p>
+ * It is also useful if two separate functions must share a resource, but we
+ * wish to ensure the usage is exclusive.
+ */
+@Operator
+public final class MutexLock extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new MutexLock operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param mutex The mutex resource to lock.
+   * @return a new instance of MutexLock
+   */
+  public static MutexLock create(Scope scope, Operand<?> mutex) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MutexLock", scope.makeOpName("MutexLock"));
+    opBuilder.addInput(mutex.asOutput());
+    return new MutexLock(opBuilder.build());
+  }
+  
+  /**
+   * A tensor that keeps a shared pointer to a lock on the mutex;
+   * when the Tensor is destroyed, the use count on the shared pointer is decreased
+   * by 1.  When it reaches 0, the lock is released.
+   */
+  public Output<?> mutexLock() {
+    return mutexLock;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) mutexLock;
+  }
+  
+  private Output<?> mutexLock;
+  
+  private MutexLock(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    mutexLock = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/MutexV2.java java-ops/org/tensorflow/op/core/MutexV2.java
--- java/org/tensorflow/op/core/MutexV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/MutexV2.java	2018-10-16 20:18:38.362432289 +0900
@@ -0,0 +1,122 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Creates a Mutex resource that can be locked by `MutexLock`.
+ */
+@Operator
+public final class MutexV2 extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.MutexV2}
+   */
+  public static class Options {
+    
+    /**
+     * @param container If non-empty, this variable is placed in the given container.
+     * Otherwise, a default container is used.
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName If non-empty, this variable is named in the given bucket
+     * with this shared_name. Otherwise, the node name is used instead.
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new MutexV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param options carries optional attributes values
+   * @return a new instance of MutexV2
+   */
+  public static MutexV2 create(Scope scope, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("MutexV2", scope.makeOpName("MutexV2"));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new MutexV2(opBuilder.build());
+  }
+  
+  /**
+   * @param container If non-empty, this variable is placed in the given container.
+   * Otherwise, a default container is used.
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName If non-empty, this variable is named in the given bucket
+   * with this shared_name. Otherwise, the node name is used instead.
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   * The mutex resource.
+   */
+  public Output<?> resource() {
+    return resource;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) resource;
+  }
+  
+  private Output<?> resource;
+  
+  private MutexV2(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    resource = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Negate.java java-ops/org/tensorflow/op/core/Negate.java
--- java/org/tensorflow/op/core/Negate.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Negate.java	2018-10-16 20:18:38.362432289 +0900
@@ -0,0 +1,69 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes numerical negative value element-wise.
+ * <p>
+ * I.e., \\(y = -x\\).
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class Negate<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Negate operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of Negate
+   */
+  public static <T> Negate<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Neg", scope.makeOpName("Negate"));
+    opBuilder.addInput(x.asOutput());
+    return new Negate<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private Negate(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Neg.java java-ops/org/tensorflow/op/core/Neg.java
--- java/org/tensorflow/op/core/Neg.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Neg.java	2018-10-16 20:18:38.363432289 +0900
@@ -0,0 +1,69 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes numerical negative value element-wise.
+ * <p>
+ * I.e., \\(y = -x\\).
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class Neg<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Neg operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of Neg
+   */
+  public static <T> Neg<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Neg", scope.makeOpName("Neg"));
+    opBuilder.addInput(x.asOutput());
+    return new Neg<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private Neg(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/NegTrain.java java-ops/org/tensorflow/op/core/NegTrain.java
--- java/org/tensorflow/op/core/NegTrain.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/NegTrain.java	2018-10-16 20:18:38.363432289 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Training via negative sampling.
+ */
+@Operator
+public final class NegTrain extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new NegTrain operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param wIn input word embedding.
+   * @param wOut output word embedding.
+   * @param examples A vector of word ids.
+   * @param labels A vector of word ids.
+   * @param lr 
+   * @param vocabCount Count of words in the vocabulary.
+   * @param numNegativeSamples Number of negative samples per example.
+   * @return a new instance of NegTrain
+   */
+  public static NegTrain create(Scope scope, Operand<Float> wIn, Operand<Float> wOut, Operand<Integer> examples, Operand<Integer> labels, Operand<Float> lr, List<Long> vocabCount, Long numNegativeSamples) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("NegTrain", scope.makeOpName("NegTrain"));
+    opBuilder.addInput(wIn.asOutput());
+    opBuilder.addInput(wOut.asOutput());
+    opBuilder.addInput(examples.asOutput());
+    opBuilder.addInput(labels.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    long[] vocabCountArray = new long[vocabCount.size()];
+    for (int i = 0; i < vocabCountArray.length; ++i) {
+      vocabCountArray[i] = vocabCount.get(i);
+    }
+    opBuilder.setAttr("vocab_count", vocabCountArray);
+    opBuilder.setAttr("num_negative_samples", numNegativeSamples);
+    return new NegTrain(opBuilder.build());
+  }
+  
+  
+  private NegTrain(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/NextIteration.java java-ops/org/tensorflow/op/core/NextIteration.java
--- java/org/tensorflow/op/core/NextIteration.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/NextIteration.java	2018-10-16 20:18:38.363432289 +0900
@@ -0,0 +1,68 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Makes its input available to the next iteration.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class NextIteration<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new NextIteration operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param data The tensor to be made available to the next iteration.
+   * @return a new instance of NextIteration
+   */
+  public static <T> NextIteration<T> create(Scope scope, Operand<T> data) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("NextIteration", scope.makeOpName("NextIteration"));
+    opBuilder.addInput(data.asOutput());
+    return new NextIteration<T>(opBuilder.build());
+  }
+  
+  /**
+   * The same tensor as `data`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private NextIteration(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/NonMaxSuppression.java java-ops/org/tensorflow/op/core/NonMaxSuppression.java
--- java/org/tensorflow/op/core/NonMaxSuppression.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/NonMaxSuppression.java	2018-10-16 20:18:38.364432288 +0900
@@ -0,0 +1,126 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Greedily selects a subset of bounding boxes in descending order of score,
+ * <p>
+ * pruning away boxes that have high intersection-over-union (IOU) overlap
+ * with previously selected boxes.  Bounding boxes are supplied as
+ * [y1, x1, y2, x2], where (y1, x1) and (y2, x2) are the coordinates of any
+ * diagonal pair of box corners and the coordinates can be provided as normalized
+ * (i.e., lying in the interval [0, 1]) or absolute.  Note that this algorithm
+ * is agnostic to where the origin is in the coordinate system.  Note that this
+ * algorithm is invariant to orthogonal transformations and translations
+ * of the coordinate system; thus translating or reflections of the coordinate
+ * system result in the same boxes being selected by the algorithm.
+ * The output of this operation is a set of integers indexing into the input
+ * collection of bounding boxes representing the selected boxes.  The bounding
+ * box coordinates corresponding to the selected indices can then be obtained
+ * using the `tf.gather operation`.  For example:
+ *   selected_indices = tf.image.non_max_suppression(
+ *       boxes, scores, max_output_size, iou_threshold)
+ *   selected_boxes = tf.gather(boxes, selected_indices)
+ */
+@Operator
+public final class NonMaxSuppression extends PrimitiveOp implements Operand<Integer> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.NonMaxSuppression}
+   */
+  public static class Options {
+    
+    /**
+     * @param iouThreshold A float representing the threshold for deciding whether boxes
+     * overlap too much with respect to IOU.
+     */
+    public Options iouThreshold(Float iouThreshold) {
+      this.iouThreshold = iouThreshold;
+      return this;
+    }
+    
+    private Float iouThreshold;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new NonMaxSuppression operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param boxes A 2-D float tensor of shape `[num_boxes, 4]`.
+   * @param scores A 1-D float tensor of shape `[num_boxes]` representing a single
+   * score corresponding to each box (each row of boxes).
+   * @param maxOutputSize A scalar integer tensor representing the maximum number of
+   * boxes to be selected by non max suppression.
+   * @param options carries optional attributes values
+   * @return a new instance of NonMaxSuppression
+   */
+  public static NonMaxSuppression create(Scope scope, Operand<Float> boxes, Operand<Float> scores, Operand<Integer> maxOutputSize, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("NonMaxSuppression", scope.makeOpName("NonMaxSuppression"));
+    opBuilder.addInput(boxes.asOutput());
+    opBuilder.addInput(scores.asOutput());
+    opBuilder.addInput(maxOutputSize.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.iouThreshold != null) {
+          opBuilder.setAttr("iou_threshold", opts.iouThreshold);
+        }
+      }
+    }
+    return new NonMaxSuppression(opBuilder.build());
+  }
+  
+  /**
+   * @param iouThreshold A float representing the threshold for deciding whether boxes
+   * overlap too much with respect to IOU.
+   */
+  public static Options iouThreshold(Float iouThreshold) {
+    return new Options().iouThreshold(iouThreshold);
+  }
+  
+  /**
+   * A 1-D integer tensor of shape `[M]` representing the selected
+   * indices from the boxes tensor, where `M <= max_output_size`.
+   */
+  public Output<Integer> selectedIndices() {
+    return selectedIndices;
+  }
+  
+  @Override
+  public Output<Integer> asOutput() {
+    return selectedIndices;
+  }
+  
+  private Output<Integer> selectedIndices;
+  
+  private NonMaxSuppression(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    selectedIndices = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/NonMaxSuppressionV2.java java-ops/org/tensorflow/op/core/NonMaxSuppressionV2.java
--- java/org/tensorflow/op/core/NonMaxSuppressionV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/NonMaxSuppressionV2.java	2018-10-16 20:18:38.364432288 +0900
@@ -0,0 +1,95 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Greedily selects a subset of bounding boxes in descending order of score,
+ * <p>
+ * pruning away boxes that have high intersection-over-union (IOU) overlap
+ * with previously selected boxes.  Bounding boxes are supplied as
+ * [y1, x1, y2, x2], where (y1, x1) and (y2, x2) are the coordinates of any
+ * diagonal pair of box corners and the coordinates can be provided as normalized
+ * (i.e., lying in the interval [0, 1]) or absolute.  Note that this algorithm
+ * is agnostic to where the origin is in the coordinate system.  Note that this
+ * algorithm is invariant to orthogonal transformations and translations
+ * of the coordinate system; thus translating or reflections of the coordinate
+ * system result in the same boxes being selected by the algorithm.
+ * <p>
+ * The output of this operation is a set of integers indexing into the input
+ * collection of bounding boxes representing the selected boxes.  The bounding
+ * box coordinates corresponding to the selected indices can then be obtained
+ * using the `tf.gather operation`.  For example:
+ * <p>
+ *   selected_indices = tf.image.non_max_suppression_v2(
+ *       boxes, scores, max_output_size, iou_threshold)
+ *   selected_boxes = tf.gather(boxes, selected_indices)
+ */
+@Operator
+public final class NonMaxSuppressionV2 extends PrimitiveOp implements Operand<Integer> {
+  
+  /**
+   * Factory method to create a class to wrap a new NonMaxSuppressionV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param boxes A 2-D float tensor of shape `[num_boxes, 4]`.
+   * @param scores A 1-D float tensor of shape `[num_boxes]` representing a single
+   * score corresponding to each box (each row of boxes).
+   * @param maxOutputSize A scalar integer tensor representing the maximum number of
+   * boxes to be selected by non max suppression.
+   * @param iouThreshold A 0-D float tensor representing the threshold for deciding whether
+   * boxes overlap too much with respect to IOU.
+   * @return a new instance of NonMaxSuppressionV2
+   */
+  public static <T extends Number> NonMaxSuppressionV2 create(Scope scope, Operand<T> boxes, Operand<T> scores, Operand<Integer> maxOutputSize, Operand<Float> iouThreshold) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("NonMaxSuppressionV2", scope.makeOpName("NonMaxSuppressionV2"));
+    opBuilder.addInput(boxes.asOutput());
+    opBuilder.addInput(scores.asOutput());
+    opBuilder.addInput(maxOutputSize.asOutput());
+    opBuilder.addInput(iouThreshold.asOutput());
+    return new NonMaxSuppressionV2(opBuilder.build());
+  }
+  
+  /**
+   * A 1-D integer tensor of shape `[M]` representing the selected
+   * indices from the boxes tensor, where `M <= max_output_size`.
+   */
+  public Output<Integer> selectedIndices() {
+    return selectedIndices;
+  }
+  
+  @Override
+  public Output<Integer> asOutput() {
+    return selectedIndices;
+  }
+  
+  private Output<Integer> selectedIndices;
+  
+  private NonMaxSuppressionV2(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    selectedIndices = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/NonMaxSuppressionV3.java java-ops/org/tensorflow/op/core/NonMaxSuppressionV3.java
--- java/org/tensorflow/op/core/NonMaxSuppressionV3.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/NonMaxSuppressionV3.java	2018-10-16 20:18:38.365432288 +0900
@@ -0,0 +1,97 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Greedily selects a subset of bounding boxes in descending order of score,
+ * <p>
+ * pruning away boxes that have high intersection-over-union (IOU) overlap
+ * with previously selected boxes.  Bounding boxes with score less than
+ * `score_threshold` are removed.  Bounding boxes are supplied as
+ * [y1, x1, y2, x2], where (y1, x1) and (y2, x2) are the coordinates of any
+ * diagonal pair of box corners and the coordinates can be provided as normalized
+ * (i.e., lying in the interval [0, 1]) or absolute.  Note that this algorithm
+ * is agnostic to where the origin is in the coordinate system and more
+ * generally is invariant to orthogonal transformations and translations
+ * of the coordinate system; thus translating or reflections of the coordinate
+ * system result in the same boxes being selected by the algorithm.
+ * The output of this operation is a set of integers indexing into the input
+ * collection of bounding boxes representing the selected boxes.  The bounding
+ * box coordinates corresponding to the selected indices can then be obtained
+ * using the `tf.gather operation`.  For example:
+ *   selected_indices = tf.image.non_max_suppression_v2(
+ *       boxes, scores, max_output_size, iou_threshold, score_threshold)
+ *   selected_boxes = tf.gather(boxes, selected_indices)
+ */
+@Operator
+public final class NonMaxSuppressionV3 extends PrimitiveOp implements Operand<Integer> {
+  
+  /**
+   * Factory method to create a class to wrap a new NonMaxSuppressionV3 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param boxes A 2-D float tensor of shape `[num_boxes, 4]`.
+   * @param scores A 1-D float tensor of shape `[num_boxes]` representing a single
+   * score corresponding to each box (each row of boxes).
+   * @param maxOutputSize A scalar integer tensor representing the maximum number of
+   * boxes to be selected by non max suppression.
+   * @param iouThreshold A 0-D float tensor representing the threshold for deciding whether
+   * boxes overlap too much with respect to IOU.
+   * @param scoreThreshold A 0-D float tensor representing the threshold for deciding when to remove
+   * boxes based on score.
+   * @return a new instance of NonMaxSuppressionV3
+   */
+  public static <T extends Number> NonMaxSuppressionV3 create(Scope scope, Operand<T> boxes, Operand<T> scores, Operand<Integer> maxOutputSize, Operand<Float> iouThreshold, Operand<Float> scoreThreshold) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("NonMaxSuppressionV3", scope.makeOpName("NonMaxSuppressionV3"));
+    opBuilder.addInput(boxes.asOutput());
+    opBuilder.addInput(scores.asOutput());
+    opBuilder.addInput(maxOutputSize.asOutput());
+    opBuilder.addInput(iouThreshold.asOutput());
+    opBuilder.addInput(scoreThreshold.asOutput());
+    return new NonMaxSuppressionV3(opBuilder.build());
+  }
+  
+  /**
+   * A 1-D integer tensor of shape `[M]` representing the selected
+   * indices from the boxes tensor, where `M <= max_output_size`.
+   */
+  public Output<Integer> selectedIndices() {
+    return selectedIndices;
+  }
+  
+  @Override
+  public Output<Integer> asOutput() {
+    return selectedIndices;
+  }
+  
+  private Output<Integer> selectedIndices;
+  
+  private NonMaxSuppressionV3(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    selectedIndices = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/NonMaxSuppressionV4.java java-ops/org/tensorflow/op/core/NonMaxSuppressionV4.java
--- java/org/tensorflow/op/core/NonMaxSuppressionV4.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/NonMaxSuppressionV4.java	2018-10-16 20:18:38.366432287 +0900
@@ -0,0 +1,138 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Greedily selects a subset of bounding boxes in descending order of score,
+ * <p>
+ * pruning away boxes that have high intersection-over-union (IOU) overlap
+ * with previously selected boxes.  Bounding boxes with score less than
+ * `score_threshold` are removed.  Bounding boxes are supplied as
+ * [y1, x1, y2, x2], where (y1, x1) and (y2, x2) are the coordinates of any
+ * diagonal pair of box corners and the coordinates can be provided as normalized
+ * (i.e., lying in the interval [0, 1]) or absolute.  Note that this algorithm
+ * is agnostic to where the origin is in the coordinate system and more
+ * generally is invariant to orthogonal transformations and translations
+ * of the coordinate system; thus translating or reflections of the coordinate
+ * system result in the same boxes being selected by the algorithm.
+ * The output of this operation is a set of integers indexing into the input
+ * collection of bounding boxes representing the selected boxes.  The bounding
+ * box coordinates corresponding to the selected indices can then be obtained
+ * using the `tf.gather operation`.  For example:
+ *   selected_indices = tf.image.non_max_suppression_v2(
+ *       boxes, scores, max_output_size, iou_threshold, score_threshold)
+ *   selected_boxes = tf.gather(boxes, selected_indices)
+ */
+@Operator
+public final class NonMaxSuppressionV4 extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.NonMaxSuppressionV4}
+   */
+  public static class Options {
+    
+    /**
+     * @param padToMaxOutputSize If true, the output `selected_indices` is padded to be of length
+     * `max_output_size`. Defaults to false.
+     */
+    public Options padToMaxOutputSize(Boolean padToMaxOutputSize) {
+      this.padToMaxOutputSize = padToMaxOutputSize;
+      return this;
+    }
+    
+    private Boolean padToMaxOutputSize;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new NonMaxSuppressionV4 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param boxes A 2-D float tensor of shape `[num_boxes, 4]`.
+   * @param scores A 1-D float tensor of shape `[num_boxes]` representing a single
+   * score corresponding to each box (each row of boxes).
+   * @param maxOutputSize A scalar integer tensor representing the maximum number of
+   * boxes to be selected by non max suppression.
+   * @param iouThreshold A 0-D float tensor representing the threshold for deciding whether
+   * boxes overlap too much with respect to IOU.
+   * @param scoreThreshold A 0-D float tensor representing the threshold for deciding when to remove
+   * boxes based on score.
+   * @param options carries optional attributes values
+   * @return a new instance of NonMaxSuppressionV4
+   */
+  public static <T extends Number> NonMaxSuppressionV4 create(Scope scope, Operand<T> boxes, Operand<T> scores, Operand<Integer> maxOutputSize, Operand<Float> iouThreshold, Operand<Float> scoreThreshold, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("NonMaxSuppressionV4", scope.makeOpName("NonMaxSuppressionV4"));
+    opBuilder.addInput(boxes.asOutput());
+    opBuilder.addInput(scores.asOutput());
+    opBuilder.addInput(maxOutputSize.asOutput());
+    opBuilder.addInput(iouThreshold.asOutput());
+    opBuilder.addInput(scoreThreshold.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.padToMaxOutputSize != null) {
+          opBuilder.setAttr("pad_to_max_output_size", opts.padToMaxOutputSize);
+        }
+      }
+    }
+    return new NonMaxSuppressionV4(opBuilder.build());
+  }
+  
+  /**
+   * @param padToMaxOutputSize If true, the output `selected_indices` is padded to be of length
+   * `max_output_size`. Defaults to false.
+   */
+  public static Options padToMaxOutputSize(Boolean padToMaxOutputSize) {
+    return new Options().padToMaxOutputSize(padToMaxOutputSize);
+  }
+  
+  /**
+   * A 1-D integer tensor of shape `[M]` representing the selected
+   * indices from the boxes tensor, where `M <= max_output_size`.
+   */
+  public Output<Integer> selectedIndices() {
+    return selectedIndices;
+  }
+  
+  /**
+   * A 0-D integer tensor representing the number of valid elements in
+   * `selected_indices`, with the valid elements appearing first.
+   */
+  public Output<Integer> validOutputs() {
+    return validOutputs;
+  }
+  
+  private Output<Integer> selectedIndices;
+  private Output<Integer> validOutputs;
+  
+  private NonMaxSuppressionV4(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    selectedIndices = operation.output(outputIdx++);
+    validOutputs = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/NonMaxSuppressionWithOverlaps.java java-ops/org/tensorflow/op/core/NonMaxSuppressionWithOverlaps.java
--- java/org/tensorflow/op/core/NonMaxSuppressionWithOverlaps.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/NonMaxSuppressionWithOverlaps.java	2018-10-16 20:18:38.367432286 +0900
@@ -0,0 +1,95 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Greedily selects a subset of bounding boxes in descending order of score,
+ * <p>
+ * pruning away boxes that have high overlaps
+ * with previously selected boxes.  Bounding boxes with score less than
+ * `score_threshold` are removed. N-by-n overlap values are supplied as square matrix,
+ * which allows for defining a custom overlap criterium (eg. intersection over union,
+ * intersection over area, etc.).
+ * <p>
+ * The output of this operation is a set of integers indexing into the input
+ * collection of bounding boxes representing the selected boxes.  The bounding
+ * box coordinates corresponding to the selected indices can then be obtained
+ * using the `tf.gather operation`.  For example:
+ * <p>
+ *   selected_indices = tf.image.non_max_suppression_with_overlaps(
+ *       overlaps, scores, max_output_size, overlap_threshold, score_threshold)
+ *   selected_boxes = tf.gather(boxes, selected_indices)
+ */
+@Operator
+public final class NonMaxSuppressionWithOverlaps extends PrimitiveOp implements Operand<Integer> {
+  
+  /**
+   * Factory method to create a class to wrap a new NonMaxSuppressionWithOverlaps operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param overlaps A 2-D float tensor of shape `[num_boxes, num_boxes]` representing
+   * the n-by-n box overlap values.
+   * @param scores A 1-D float tensor of shape `[num_boxes]` representing a single
+   * score corresponding to each box (each row of boxes).
+   * @param maxOutputSize A scalar integer tensor representing the maximum number of
+   * boxes to be selected by non max suppression.
+   * @param overlapThreshold A 0-D float tensor representing the threshold for deciding whether
+   * boxes overlap too.
+   * @param scoreThreshold A 0-D float tensor representing the threshold for deciding when to remove
+   * boxes based on score.
+   * @return a new instance of NonMaxSuppressionWithOverlaps
+   */
+  public static NonMaxSuppressionWithOverlaps create(Scope scope, Operand<Float> overlaps, Operand<Float> scores, Operand<Integer> maxOutputSize, Operand<Float> overlapThreshold, Operand<Float> scoreThreshold) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("NonMaxSuppressionWithOverlaps", scope.makeOpName("NonMaxSuppressionWithOverlaps"));
+    opBuilder.addInput(overlaps.asOutput());
+    opBuilder.addInput(scores.asOutput());
+    opBuilder.addInput(maxOutputSize.asOutput());
+    opBuilder.addInput(overlapThreshold.asOutput());
+    opBuilder.addInput(scoreThreshold.asOutput());
+    return new NonMaxSuppressionWithOverlaps(opBuilder.build());
+  }
+  
+  /**
+   * A 1-D integer tensor of shape `[M]` representing the selected
+   * indices from the boxes tensor, where `M <= max_output_size`.
+   */
+  public Output<Integer> selectedIndices() {
+    return selectedIndices;
+  }
+  
+  @Override
+  public Output<Integer> asOutput() {
+    return selectedIndices;
+  }
+  
+  private Output<Integer> selectedIndices;
+  
+  private NonMaxSuppressionWithOverlaps(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    selectedIndices = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/NoOp.java java-ops/org/tensorflow/op/core/NoOp.java
--- java/org/tensorflow/op/core/NoOp.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/NoOp.java	2018-10-16 20:18:38.363432289 +0900
@@ -0,0 +1,47 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Does nothing. Only useful as a placeholder for control edges.
+ */
+@Operator
+public final class NoOp extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new NoOp operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @return a new instance of NoOp
+   */
+  public static NoOp create(Scope scope) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("NoOp", scope.makeOpName("NoOp"));
+    return new NoOp(opBuilder.build());
+  }
+  
+  
+  private NoOp(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/NotEqual.java java-ops/org/tensorflow/op/core/NotEqual.java
--- java/org/tensorflow/op/core/NotEqual.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/NotEqual.java	2018-10-16 20:18:38.367432286 +0900
@@ -0,0 +1,70 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns the truth value of (x != y) element-wise.
+ * <p>
+ * <i>NOTE</i>: `NotEqual` supports broadcasting. More about broadcasting
+ * [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
+ */
+@Operator
+public final class NotEqual extends PrimitiveOp implements Operand<Boolean> {
+  
+  /**
+   * Factory method to create a class to wrap a new NotEqual operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param y 
+   * @return a new instance of NotEqual
+   */
+  public static <T> NotEqual create(Scope scope, Operand<T> x, Operand<T> y) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("NotEqual", scope.makeOpName("NotEqual"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(y.asOutput());
+    return new NotEqual(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<Boolean> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<Boolean> asOutput() {
+    return z;
+  }
+  
+  private Output<Boolean> z;
+  
+  private NotEqual(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/NthElement.java java-ops/org/tensorflow/op/core/NthElement.java
--- java/org/tensorflow/op/core/NthElement.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/NthElement.java	2018-10-16 20:18:38.368432285 +0900
@@ -0,0 +1,115 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Finds values of the `n`-th order statistic for the last dimension.
+ * <p>
+ * If the input is a vector (rank-1), finds the entries which is the nth-smallest
+ * value in the vector and outputs their values as scalar tensor.
+ * <p>
+ * For matrices (resp. higher rank input), computes the entries which is the
+ * nth-smallest value in each row (resp. vector along the last dimension). Thus,
+ * <p>
+ *     values.shape = input.shape[:-1]
+ * 
+ * @param <T> data type for {@code values()} output
+ */
+@Operator
+public final class NthElement<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.NthElement}
+   */
+  public static class Options {
+    
+    /**
+     * @param reverse When set to True, find the nth-largest value in the vector and vice
+     * versa.
+     */
+    public Options reverse(Boolean reverse) {
+      this.reverse = reverse;
+      return this;
+    }
+    
+    private Boolean reverse;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new NthElement operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 1-D or higher with last dimension at least `n+1`.
+   * @param n 0-D. Position of sorted vector to select along the last dimension (along
+   * each row for matrices). Valid range of n is `[0, input.shape[:-1])`
+   * @param options carries optional attributes values
+   * @return a new instance of NthElement
+   */
+  public static <T extends Number> NthElement<T> create(Scope scope, Operand<T> input, Operand<Integer> n, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("NthElement", scope.makeOpName("NthElement"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(n.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.reverse != null) {
+          opBuilder.setAttr("reverse", opts.reverse);
+        }
+      }
+    }
+    return new NthElement<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param reverse When set to True, find the nth-largest value in the vector and vice
+   * versa.
+   */
+  public static Options reverse(Boolean reverse) {
+    return new Options().reverse(reverse);
+  }
+  
+  /**
+   * The `n`-th order statistic along each last dimensional slice.
+   */
+  public Output<T> values() {
+    return values;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return values;
+  }
+  
+  private Output<T> values;
+  
+  private NthElement(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    values = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/OneHot.java java-ops/org/tensorflow/op/core/OneHot.java
--- java/org/tensorflow/op/core/OneHot.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/OneHot.java	2018-10-16 20:18:38.369432285 +0900
@@ -0,0 +1,191 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns a one-hot tensor.
+ * <p>
+ * The locations represented by indices in `indices` take value `on_value`,
+ * while all other locations take value `off_value`.
+ * <p>
+ * If the input `indices` is rank `N`, the output will have rank `N+1`,
+ * The new axis is created at dimension `axis` (default: the new axis is
+ * appended at the end).
+ * <p>
+ * If `indices` is a scalar the output shape will be a vector of length `depth`.
+ * <p>
+ * If `indices` is a vector of length `features`, the output shape will be:
+ * <pre>{@code
+ *   features x depth if axis == -1
+ *   depth x features if axis == 0
+ * }</pre>
+ * If `indices` is a matrix (batch) with shape `[batch, features]`,
+ * the output shape will be:
+ * <pre>{@code
+ *   batch x features x depth if axis == -1
+ *   batch x depth x features if axis == 1
+ *   depth x batch x features if axis == 0
+ * }</pre>
+ * Examples
+ * =========
+ * <p>
+ * Suppose that
+ * <pre>{@code
+ *   indices = [0, 2, -1, 1]
+ *   depth = 3
+ *   on_value = 5.0
+ *   off_value = 0.0
+ *   axis = -1
+ * }</pre>
+ * Then output is `[4 x 3]`:
+ * <p>
+ *     <pre>{@code
+ * output =
+ *       [5.0 0.0 0.0]  // one_hot(0)
+ *       [0.0 0.0 5.0]  // one_hot(2)
+ *       [0.0 0.0 0.0]  // one_hot(-1)
+ *       [0.0 5.0 0.0]  // one_hot(1)
+ *     }</pre>
+ * Suppose that
+ * <pre>{@code
+ *   indices = [0, 2, -1, 1]
+ *   depth = 3
+ *   on_value = 0.0
+ *   off_value = 3.0
+ *   axis = 0
+ * }</pre>
+ * Then output is `[3 x 4]`:
+ * <p>
+ *     <pre>{@code
+ * output =
+ *       [0.0 3.0 3.0 3.0]
+ *       [3.0 3.0 3.0 0.0]
+ *       [3.0 3.0 3.0 3.0]
+ *       [3.0 0.0 3.0 3.0]
+ *     //  ^                one_hot(0)
+ *     //      ^            one_hot(2)
+ *     //          ^        one_hot(-1)
+ *     //              ^    one_hot(1)
+ *     }</pre>
+ * Suppose that
+ * <pre>{@code
+ *   indices = [[0, 2], [1, -1]]
+ *   depth = 3
+ *   on_value = 1.0
+ *   off_value = 0.0
+ *   axis = -1
+ * }</pre>
+ * Then output is `[2 x 2 x 3]`:
+ * <p>
+ *     <pre>{@code
+ * output =
+ *       [
+ *         [1.0, 0.0, 0.0]  // one_hot(0)
+ *         [0.0, 0.0, 1.0]  // one_hot(2)
+ *       ][
+ *         [0.0, 1.0, 0.0]  // one_hot(1)
+ *         [0.0, 0.0, 0.0]  // one_hot(-1)
+ *       ]}</pre>
+ * 
+ * 
+ * @param <U> data type for {@code output()} output
+ */
+@Operator
+public final class OneHot<U> extends PrimitiveOp implements Operand<U> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.OneHot}
+   */
+  public static class Options {
+    
+    /**
+     * @param axis The axis to fill (default: -1, a new inner-most axis).
+     */
+    public Options axis(Long axis) {
+      this.axis = axis;
+      return this;
+    }
+    
+    private Long axis;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new OneHot operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param indices A tensor of indices.
+   * @param depth A scalar defining the depth of the one hot dimension.
+   * @param onValue A scalar defining the value to fill in output when `indices[j] = i`.
+   * @param offValue A scalar defining the value to fill in output when `indices[j] != i`.
+   * @param options carries optional attributes values
+   * @return a new instance of OneHot
+   */
+  public static <U, T extends Number> OneHot<U> create(Scope scope, Operand<T> indices, Operand<Integer> depth, Operand<U> onValue, Operand<U> offValue, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("OneHot", scope.makeOpName("OneHot"));
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(depth.asOutput());
+    opBuilder.addInput(onValue.asOutput());
+    opBuilder.addInput(offValue.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.axis != null) {
+          opBuilder.setAttr("axis", opts.axis);
+        }
+      }
+    }
+    return new OneHot<U>(opBuilder.build());
+  }
+  
+  /**
+   * @param axis The axis to fill (default: -1, a new inner-most axis).
+   */
+  public static Options axis(Long axis) {
+    return new Options().axis(axis);
+  }
+  
+  /**
+   * The one-hot tensor.
+   */
+  public Output<U> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<U> asOutput() {
+    return output;
+  }
+  
+  private Output<U> output;
+  
+  private OneHot(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/OnesLike.java java-ops/org/tensorflow/op/core/OnesLike.java
--- java/org/tensorflow/op/core/OnesLike.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/OnesLike.java	2018-10-16 20:18:38.369432285 +0900
@@ -0,0 +1,68 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns a tensor of ones with the same shape and type as x.
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class OnesLike<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new OnesLike operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x a tensor of type T.
+   * @return a new instance of OnesLike
+   */
+  public static <T> OnesLike<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("OnesLike", scope.makeOpName("OnesLike"));
+    opBuilder.addInput(x.asOutput());
+    return new OnesLike<T>(opBuilder.build());
+  }
+  
+  /**
+   * a tensor of the same shape and type as x but filled with ones.
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private OnesLike(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/OptimizeDataset.java java-ops/org/tensorflow/op/core/OptimizeDataset.java
--- java/org/tensorflow/op/core/OptimizeDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/OptimizeDataset.java	2018-10-16 20:18:38.369432285 +0900
@@ -0,0 +1,83 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Creates a dataset by applying optimizations to `input_dataset`.
+ * <p>
+ * Creates a dataset by applying optimizations to `input_dataset`.
+ */
+public final class OptimizeDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new OptimizeDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputDataset A variant tensor representing the input dataset.
+   * @param optimizations A `tf.string` vector `tf.Tensor` identifying optimizations to use.
+   * @param outputTypes 
+   * @param outputShapes 
+   * @return a new instance of OptimizeDataset
+   */
+  public static OptimizeDataset create(Scope scope, Operand<?> inputDataset, Operand<String> optimizations, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("OptimizeDataset", scope.makeOpName("OptimizeDataset"));
+    opBuilder.addInput(inputDataset.asOutput());
+    opBuilder.addInput(optimizations.asOutput());
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new OptimizeDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private OptimizeDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/OptionalFromValue.java java-ops/org/tensorflow/op/core/OptionalFromValue.java
--- java/org/tensorflow/op/core/OptionalFromValue.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/OptionalFromValue.java	2018-10-16 20:18:38.370432284 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Constructs an Optional variant from a tuple of tensors.
+ */
+@Operator
+public final class OptionalFromValue extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new OptionalFromValue operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param components 
+   * @return a new instance of OptionalFromValue
+   */
+  public static OptionalFromValue create(Scope scope, Iterable<Operand<?>> components) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("OptionalFromValue", scope.makeOpName("OptionalFromValue"));
+    opBuilder.addInputList(Operands.asOutputs(components));
+    return new OptionalFromValue(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> optional() {
+    return optional;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) optional;
+  }
+  
+  private Output<?> optional;
+  
+  private OptionalFromValue(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    optional = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/OptionalGetValue.java java-ops/org/tensorflow/op/core/OptionalGetValue.java
--- java/org/tensorflow/op/core/OptionalGetValue.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/OptionalGetValue.java	2018-10-16 20:18:38.370432284 +0900
@@ -0,0 +1,85 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.Iterator;
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns the value stored in an Optional variant or raises an error if none exists.
+ */
+@Operator
+public final class OptionalGetValue extends PrimitiveOp implements Iterable<Operand<Object>> {
+  
+  /**
+   * Factory method to create a class to wrap a new OptionalGetValue operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param optional 
+   * @param outputTypes 
+   * @param outputShapes 
+   * @return a new instance of OptionalGetValue
+   */
+  public static OptionalGetValue create(Scope scope, Operand<?> optional, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("OptionalGetValue", scope.makeOpName("OptionalGetValue"));
+    opBuilder.addInput(optional.asOutput());
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new OptionalGetValue(opBuilder.build());
+  }
+  
+  /**
+   */
+  public List<Output<?>> components() {
+    return components;
+  }
+  
+  @Override
+  @SuppressWarnings({"rawtypes", "unchecked"})
+  public Iterator<Operand<Object>> iterator() {
+    return (Iterator) components.iterator();
+  }
+  
+  private List<Output<?>> components;
+  
+  private OptionalGetValue(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    int componentsLength = operation.outputListLength("components");
+    components = Arrays.asList(operation.outputList(outputIdx, componentsLength));
+    outputIdx += componentsLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/OptionalHasValue.java java-ops/org/tensorflow/op/core/OptionalHasValue.java
--- java/org/tensorflow/op/core/OptionalHasValue.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/OptionalHasValue.java	2018-10-16 20:18:38.370432284 +0900
@@ -0,0 +1,65 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns true if and only if the given Optional variant has a value.
+ */
+@Operator
+public final class OptionalHasValue extends PrimitiveOp implements Operand<Boolean> {
+  
+  /**
+   * Factory method to create a class to wrap a new OptionalHasValue operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param optional 
+   * @return a new instance of OptionalHasValue
+   */
+  public static OptionalHasValue create(Scope scope, Operand<?> optional) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("OptionalHasValue", scope.makeOpName("OptionalHasValue"));
+    opBuilder.addInput(optional.asOutput());
+    return new OptionalHasValue(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<Boolean> hasValue() {
+    return hasValue;
+  }
+  
+  @Override
+  public Output<Boolean> asOutput() {
+    return hasValue;
+  }
+  
+  private Output<Boolean> hasValue;
+  
+  private OptionalHasValue(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    hasValue = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/OptionalNone.java java-ops/org/tensorflow/op/core/OptionalNone.java
--- java/org/tensorflow/op/core/OptionalNone.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/OptionalNone.java	2018-10-16 20:18:38.370432284 +0900
@@ -0,0 +1,64 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Creates an Optional variant with no value.
+ */
+@Operator
+public final class OptionalNone extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new OptionalNone operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @return a new instance of OptionalNone
+   */
+  public static OptionalNone create(Scope scope) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("OptionalNone", scope.makeOpName("OptionalNone"));
+    return new OptionalNone(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> optional() {
+    return optional;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) optional;
+  }
+  
+  private Output<?> optional;
+  
+  private OptionalNone(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    optional = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/OrderedMapClear.java java-ops/org/tensorflow/op/core/OrderedMapClear.java
--- java/org/tensorflow/op/core/OrderedMapClear.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/OrderedMapClear.java	2018-10-16 20:18:38.370432284 +0900
@@ -0,0 +1,146 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Op removes all elements in the underlying container.
+ */
+@Operator
+public final class OrderedMapClear extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.OrderedMapClear}
+   */
+  public static class Options {
+    
+    /**
+     * @param capacity 
+     */
+    public Options capacity(Long capacity) {
+      this.capacity = capacity;
+      return this;
+    }
+    
+    /**
+     * @param memoryLimit 
+     */
+    public Options memoryLimit(Long memoryLimit) {
+      this.memoryLimit = memoryLimit;
+      return this;
+    }
+    
+    /**
+     * @param container 
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName 
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private Long capacity;
+    private Long memoryLimit;
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new OrderedMapClear operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param dtypes 
+   * @param options carries optional attributes values
+   * @return a new instance of OrderedMapClear
+   */
+  public static OrderedMapClear create(Scope scope, List<Class<?>> dtypes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("OrderedMapClear", scope.makeOpName("OrderedMapClear"));
+    DataType[] dtypesArray = new DataType[dtypes.size()];
+    for (int i = 0; i < dtypesArray.length; ++i) {
+      dtypesArray[i] = DataType.fromClass(dtypes.get(i));
+    }
+    opBuilder.setAttr("dtypes", dtypesArray);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.capacity != null) {
+          opBuilder.setAttr("capacity", opts.capacity);
+        }
+        if (opts.memoryLimit != null) {
+          opBuilder.setAttr("memory_limit", opts.memoryLimit);
+        }
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new OrderedMapClear(opBuilder.build());
+  }
+  
+  /**
+   * @param capacity 
+   */
+  public static Options capacity(Long capacity) {
+    return new Options().capacity(capacity);
+  }
+  
+  /**
+   * @param memoryLimit 
+   */
+  public static Options memoryLimit(Long memoryLimit) {
+    return new Options().memoryLimit(memoryLimit);
+  }
+  
+  /**
+   * @param container 
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName 
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  
+  private OrderedMapClear(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/OrderedMapIncompleteSize.java java-ops/org/tensorflow/op/core/OrderedMapIncompleteSize.java
--- java/org/tensorflow/op/core/OrderedMapIncompleteSize.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/OrderedMapIncompleteSize.java	2018-10-16 20:18:38.371432283 +0900
@@ -0,0 +1,162 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Op returns the number of incomplete elements in the underlying container.
+ */
+@Operator
+public final class OrderedMapIncompleteSize extends PrimitiveOp implements Operand<Integer> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.OrderedMapIncompleteSize}
+   */
+  public static class Options {
+    
+    /**
+     * @param capacity 
+     */
+    public Options capacity(Long capacity) {
+      this.capacity = capacity;
+      return this;
+    }
+    
+    /**
+     * @param memoryLimit 
+     */
+    public Options memoryLimit(Long memoryLimit) {
+      this.memoryLimit = memoryLimit;
+      return this;
+    }
+    
+    /**
+     * @param container 
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName 
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private Long capacity;
+    private Long memoryLimit;
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new OrderedMapIncompleteSize operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param dtypes 
+   * @param options carries optional attributes values
+   * @return a new instance of OrderedMapIncompleteSize
+   */
+  public static OrderedMapIncompleteSize create(Scope scope, List<Class<?>> dtypes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("OrderedMapIncompleteSize", scope.makeOpName("OrderedMapIncompleteSize"));
+    DataType[] dtypesArray = new DataType[dtypes.size()];
+    for (int i = 0; i < dtypesArray.length; ++i) {
+      dtypesArray[i] = DataType.fromClass(dtypes.get(i));
+    }
+    opBuilder.setAttr("dtypes", dtypesArray);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.capacity != null) {
+          opBuilder.setAttr("capacity", opts.capacity);
+        }
+        if (opts.memoryLimit != null) {
+          opBuilder.setAttr("memory_limit", opts.memoryLimit);
+        }
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new OrderedMapIncompleteSize(opBuilder.build());
+  }
+  
+  /**
+   * @param capacity 
+   */
+  public static Options capacity(Long capacity) {
+    return new Options().capacity(capacity);
+  }
+  
+  /**
+   * @param memoryLimit 
+   */
+  public static Options memoryLimit(Long memoryLimit) {
+    return new Options().memoryLimit(memoryLimit);
+  }
+  
+  /**
+   * @param container 
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName 
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   */
+  public Output<Integer> size() {
+    return size;
+  }
+  
+  @Override
+  public Output<Integer> asOutput() {
+    return size;
+  }
+  
+  private Output<Integer> size;
+  
+  private OrderedMapIncompleteSize(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    size = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/OrderedMapPeek.java java-ops/org/tensorflow/op/core/OrderedMapPeek.java
--- java/org/tensorflow/op/core/OrderedMapPeek.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/OrderedMapPeek.java	2018-10-16 20:18:38.371432283 +0900
@@ -0,0 +1,175 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.Iterator;
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Op peeks at the values at the specified key.  If the
+ * <p>
+ * underlying container does not contain this key
+ * this op will block until it does.   This Op is optimized for
+ * performance.
+ */
+@Operator
+public final class OrderedMapPeek extends PrimitiveOp implements Iterable<Operand<Object>> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.OrderedMapPeek}
+   */
+  public static class Options {
+    
+    /**
+     * @param capacity 
+     */
+    public Options capacity(Long capacity) {
+      this.capacity = capacity;
+      return this;
+    }
+    
+    /**
+     * @param memoryLimit 
+     */
+    public Options memoryLimit(Long memoryLimit) {
+      this.memoryLimit = memoryLimit;
+      return this;
+    }
+    
+    /**
+     * @param container 
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName 
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private Long capacity;
+    private Long memoryLimit;
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new OrderedMapPeek operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param key 
+   * @param indices 
+   * @param dtypes 
+   * @param options carries optional attributes values
+   * @return a new instance of OrderedMapPeek
+   */
+  public static OrderedMapPeek create(Scope scope, Operand<Long> key, Operand<Integer> indices, List<Class<?>> dtypes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("OrderedMapPeek", scope.makeOpName("OrderedMapPeek"));
+    opBuilder.addInput(key.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    DataType[] dtypesArray = new DataType[dtypes.size()];
+    for (int i = 0; i < dtypesArray.length; ++i) {
+      dtypesArray[i] = DataType.fromClass(dtypes.get(i));
+    }
+    opBuilder.setAttr("dtypes", dtypesArray);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.capacity != null) {
+          opBuilder.setAttr("capacity", opts.capacity);
+        }
+        if (opts.memoryLimit != null) {
+          opBuilder.setAttr("memory_limit", opts.memoryLimit);
+        }
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new OrderedMapPeek(opBuilder.build());
+  }
+  
+  /**
+   * @param capacity 
+   */
+  public static Options capacity(Long capacity) {
+    return new Options().capacity(capacity);
+  }
+  
+  /**
+   * @param memoryLimit 
+   */
+  public static Options memoryLimit(Long memoryLimit) {
+    return new Options().memoryLimit(memoryLimit);
+  }
+  
+  /**
+   * @param container 
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName 
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   */
+  public List<Output<?>> values() {
+    return values;
+  }
+  
+  @Override
+  @SuppressWarnings({"rawtypes", "unchecked"})
+  public Iterator<Operand<Object>> iterator() {
+    return (Iterator) values.iterator();
+  }
+  
+  private List<Output<?>> values;
+  
+  private OrderedMapPeek(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    int valuesLength = operation.outputListLength("values");
+    values = Arrays.asList(operation.outputList(outputIdx, valuesLength));
+    outputIdx += valuesLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/OrderedMapSize.java java-ops/org/tensorflow/op/core/OrderedMapSize.java
--- java/org/tensorflow/op/core/OrderedMapSize.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/OrderedMapSize.java	2018-10-16 20:18:38.372432282 +0900
@@ -0,0 +1,162 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Op returns the number of elements in the underlying container.
+ */
+@Operator
+public final class OrderedMapSize extends PrimitiveOp implements Operand<Integer> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.OrderedMapSize}
+   */
+  public static class Options {
+    
+    /**
+     * @param capacity 
+     */
+    public Options capacity(Long capacity) {
+      this.capacity = capacity;
+      return this;
+    }
+    
+    /**
+     * @param memoryLimit 
+     */
+    public Options memoryLimit(Long memoryLimit) {
+      this.memoryLimit = memoryLimit;
+      return this;
+    }
+    
+    /**
+     * @param container 
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName 
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private Long capacity;
+    private Long memoryLimit;
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new OrderedMapSize operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param dtypes 
+   * @param options carries optional attributes values
+   * @return a new instance of OrderedMapSize
+   */
+  public static OrderedMapSize create(Scope scope, List<Class<?>> dtypes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("OrderedMapSize", scope.makeOpName("OrderedMapSize"));
+    DataType[] dtypesArray = new DataType[dtypes.size()];
+    for (int i = 0; i < dtypesArray.length; ++i) {
+      dtypesArray[i] = DataType.fromClass(dtypes.get(i));
+    }
+    opBuilder.setAttr("dtypes", dtypesArray);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.capacity != null) {
+          opBuilder.setAttr("capacity", opts.capacity);
+        }
+        if (opts.memoryLimit != null) {
+          opBuilder.setAttr("memory_limit", opts.memoryLimit);
+        }
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new OrderedMapSize(opBuilder.build());
+  }
+  
+  /**
+   * @param capacity 
+   */
+  public static Options capacity(Long capacity) {
+    return new Options().capacity(capacity);
+  }
+  
+  /**
+   * @param memoryLimit 
+   */
+  public static Options memoryLimit(Long memoryLimit) {
+    return new Options().memoryLimit(memoryLimit);
+  }
+  
+  /**
+   * @param container 
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName 
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   */
+  public Output<Integer> size() {
+    return size;
+  }
+  
+  @Override
+  public Output<Integer> asOutput() {
+    return size;
+  }
+  
+  private Output<Integer> size;
+  
+  private OrderedMapSize(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    size = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/OrderedMapStage.java java-ops/org/tensorflow/op/core/OrderedMapStage.java
--- java/org/tensorflow/op/core/OrderedMapStage.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/OrderedMapStage.java	2018-10-16 20:18:38.372432282 +0900
@@ -0,0 +1,161 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Stage (key, values) in the underlying container which behaves like a ordered
+ * <p>
+ * associative container.   Elements are ordered by key.
+ */
+@Operator
+public final class OrderedMapStage extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.OrderedMapStage}
+   */
+  public static class Options {
+    
+    /**
+     * @param capacity Maximum number of elements in the Staging Area. If > 0, inserts
+     * on the container will block when the capacity is reached.
+     */
+    public Options capacity(Long capacity) {
+      this.capacity = capacity;
+      return this;
+    }
+    
+    /**
+     * @param memoryLimit 
+     */
+    public Options memoryLimit(Long memoryLimit) {
+      this.memoryLimit = memoryLimit;
+      return this;
+    }
+    
+    /**
+     * @param container If non-empty, this queue is placed in the given container. Otherwise,
+     * a default container is used.
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName It is necessary to match this name to the matching Unstage Op.
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private Long capacity;
+    private Long memoryLimit;
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new OrderedMapStage operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param key int64
+   * @param indices 
+   * @param values a list of tensors
+   * dtypes A list of data types that inserted values should adhere to.
+   * @param dtypes 
+   * @param options carries optional attributes values
+   * @return a new instance of OrderedMapStage
+   */
+  public static OrderedMapStage create(Scope scope, Operand<Long> key, Operand<Integer> indices, Iterable<Operand<?>> values, List<Class<?>> dtypes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("OrderedMapStage", scope.makeOpName("OrderedMapStage"));
+    opBuilder.addInput(key.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInputList(Operands.asOutputs(values));
+    DataType[] dtypesArray = new DataType[dtypes.size()];
+    for (int i = 0; i < dtypesArray.length; ++i) {
+      dtypesArray[i] = DataType.fromClass(dtypes.get(i));
+    }
+    opBuilder.setAttr("dtypes", dtypesArray);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.capacity != null) {
+          opBuilder.setAttr("capacity", opts.capacity);
+        }
+        if (opts.memoryLimit != null) {
+          opBuilder.setAttr("memory_limit", opts.memoryLimit);
+        }
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new OrderedMapStage(opBuilder.build());
+  }
+  
+  /**
+   * @param capacity Maximum number of elements in the Staging Area. If > 0, inserts
+   * on the container will block when the capacity is reached.
+   */
+  public static Options capacity(Long capacity) {
+    return new Options().capacity(capacity);
+  }
+  
+  /**
+   * @param memoryLimit 
+   */
+  public static Options memoryLimit(Long memoryLimit) {
+    return new Options().memoryLimit(memoryLimit);
+  }
+  
+  /**
+   * @param container If non-empty, this queue is placed in the given container. Otherwise,
+   * a default container is used.
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName It is necessary to match this name to the matching Unstage Op.
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  
+  private OrderedMapStage(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/OrderedMapUnstage.java java-ops/org/tensorflow/op/core/OrderedMapUnstage.java
--- java/org/tensorflow/op/core/OrderedMapUnstage.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/OrderedMapUnstage.java	2018-10-16 20:18:38.372432282 +0900
@@ -0,0 +1,174 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.Iterator;
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Op removes and returns the values associated with the key
+ * <p>
+ * from the underlying container.   If the underlying container
+ * does not contain this key, the op will block until it does.
+ */
+@Operator
+public final class OrderedMapUnstage extends PrimitiveOp implements Iterable<Operand<Object>> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.OrderedMapUnstage}
+   */
+  public static class Options {
+    
+    /**
+     * @param capacity 
+     */
+    public Options capacity(Long capacity) {
+      this.capacity = capacity;
+      return this;
+    }
+    
+    /**
+     * @param memoryLimit 
+     */
+    public Options memoryLimit(Long memoryLimit) {
+      this.memoryLimit = memoryLimit;
+      return this;
+    }
+    
+    /**
+     * @param container 
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName 
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private Long capacity;
+    private Long memoryLimit;
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new OrderedMapUnstage operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param key 
+   * @param indices 
+   * @param dtypes 
+   * @param options carries optional attributes values
+   * @return a new instance of OrderedMapUnstage
+   */
+  public static OrderedMapUnstage create(Scope scope, Operand<Long> key, Operand<Integer> indices, List<Class<?>> dtypes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("OrderedMapUnstage", scope.makeOpName("OrderedMapUnstage"));
+    opBuilder.addInput(key.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    DataType[] dtypesArray = new DataType[dtypes.size()];
+    for (int i = 0; i < dtypesArray.length; ++i) {
+      dtypesArray[i] = DataType.fromClass(dtypes.get(i));
+    }
+    opBuilder.setAttr("dtypes", dtypesArray);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.capacity != null) {
+          opBuilder.setAttr("capacity", opts.capacity);
+        }
+        if (opts.memoryLimit != null) {
+          opBuilder.setAttr("memory_limit", opts.memoryLimit);
+        }
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new OrderedMapUnstage(opBuilder.build());
+  }
+  
+  /**
+   * @param capacity 
+   */
+  public static Options capacity(Long capacity) {
+    return new Options().capacity(capacity);
+  }
+  
+  /**
+   * @param memoryLimit 
+   */
+  public static Options memoryLimit(Long memoryLimit) {
+    return new Options().memoryLimit(memoryLimit);
+  }
+  
+  /**
+   * @param container 
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName 
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   */
+  public List<Output<?>> values() {
+    return values;
+  }
+  
+  @Override
+  @SuppressWarnings({"rawtypes", "unchecked"})
+  public Iterator<Operand<Object>> iterator() {
+    return (Iterator) values.iterator();
+  }
+  
+  private List<Output<?>> values;
+  
+  private OrderedMapUnstage(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    int valuesLength = operation.outputListLength("values");
+    values = Arrays.asList(operation.outputList(outputIdx, valuesLength));
+    outputIdx += valuesLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/OrderedMapUnstageNoKey.java java-ops/org/tensorflow/op/core/OrderedMapUnstageNoKey.java
--- java/org/tensorflow/op/core/OrderedMapUnstageNoKey.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/OrderedMapUnstageNoKey.java	2018-10-16 20:18:38.373432282 +0900
@@ -0,0 +1,173 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Op removes and returns the (key, value) element with the smallest
+ * <p>
+ * key from the underlying container.   If the underlying container
+ * does not contain elements, the op will block until it does.
+ */
+@Operator
+public final class OrderedMapUnstageNoKey extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.OrderedMapUnstageNoKey}
+   */
+  public static class Options {
+    
+    /**
+     * @param capacity 
+     */
+    public Options capacity(Long capacity) {
+      this.capacity = capacity;
+      return this;
+    }
+    
+    /**
+     * @param memoryLimit 
+     */
+    public Options memoryLimit(Long memoryLimit) {
+      this.memoryLimit = memoryLimit;
+      return this;
+    }
+    
+    /**
+     * @param container 
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName 
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private Long capacity;
+    private Long memoryLimit;
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new OrderedMapUnstageNoKey operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param indices 
+   * @param dtypes 
+   * @param options carries optional attributes values
+   * @return a new instance of OrderedMapUnstageNoKey
+   */
+  public static OrderedMapUnstageNoKey create(Scope scope, Operand<Integer> indices, List<Class<?>> dtypes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("OrderedMapUnstageNoKey", scope.makeOpName("OrderedMapUnstageNoKey"));
+    opBuilder.addInput(indices.asOutput());
+    DataType[] dtypesArray = new DataType[dtypes.size()];
+    for (int i = 0; i < dtypesArray.length; ++i) {
+      dtypesArray[i] = DataType.fromClass(dtypes.get(i));
+    }
+    opBuilder.setAttr("dtypes", dtypesArray);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.capacity != null) {
+          opBuilder.setAttr("capacity", opts.capacity);
+        }
+        if (opts.memoryLimit != null) {
+          opBuilder.setAttr("memory_limit", opts.memoryLimit);
+        }
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new OrderedMapUnstageNoKey(opBuilder.build());
+  }
+  
+  /**
+   * @param capacity 
+   */
+  public static Options capacity(Long capacity) {
+    return new Options().capacity(capacity);
+  }
+  
+  /**
+   * @param memoryLimit 
+   */
+  public static Options memoryLimit(Long memoryLimit) {
+    return new Options().memoryLimit(memoryLimit);
+  }
+  
+  /**
+   * @param container 
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName 
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   */
+  public Output<Long> key() {
+    return key;
+  }
+  
+  /**
+   */
+  public List<Output<?>> values() {
+    return values;
+  }
+  
+  private Output<Long> key;
+  private List<Output<?>> values;
+  
+  private OrderedMapUnstageNoKey(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    key = operation.output(outputIdx++);
+    int valuesLength = operation.outputListLength("values");
+    values = Arrays.asList(operation.outputList(outputIdx, valuesLength));
+    outputIdx += valuesLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/PaddedBatchDataset.java java-ops/org/tensorflow/op/core/PaddedBatchDataset.java
--- java/org/tensorflow/op/core/PaddedBatchDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/PaddedBatchDataset.java	2018-10-16 20:18:38.375432280 +0900
@@ -0,0 +1,86 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Creates a dataset that batches and pads `batch_size` elements from the input.
+ */
+@Operator
+public final class PaddedBatchDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new PaddedBatchDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputDataset 
+   * @param batchSize A scalar representing the number of elements to accumulate in a
+   * batch.
+   * @param paddedShapes A list of int64 tensors representing the desired padded shapes
+   * of the corresponding output components. These shapes may be partially
+   * specified, using `-1` to indicate that a particular dimension should be
+   * padded to the maximum size of all batch elements.
+   * @param paddingValues A list of scalars containing the padding value to use for
+   * each of the outputs.
+   * @param outputShapes 
+   * @return a new instance of PaddedBatchDataset
+   */
+  public static PaddedBatchDataset create(Scope scope, Operand<?> inputDataset, Operand<Long> batchSize, Iterable<Operand<Long>> paddedShapes, Iterable<Operand<?>> paddingValues, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("PaddedBatchDataset", scope.makeOpName("PaddedBatchDataset"));
+    opBuilder.addInput(inputDataset.asOutput());
+    opBuilder.addInput(batchSize.asOutput());
+    opBuilder.addInputList(Operands.asOutputs(paddedShapes));
+    opBuilder.addInputList(Operands.asOutputs(paddingValues));
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new PaddedBatchDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private PaddedBatchDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/PaddedBatchDatasetV2.java java-ops/org/tensorflow/op/core/PaddedBatchDatasetV2.java
--- java/org/tensorflow/op/core/PaddedBatchDatasetV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/PaddedBatchDatasetV2.java	2018-10-16 20:18:38.375432280 +0900
@@ -0,0 +1,87 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Creates a dataset that batches and pads `batch_size` elements from the input.
+ */
+public final class PaddedBatchDatasetV2 extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new PaddedBatchDatasetV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputDataset 
+   * @param batchSize A scalar representing the number of elements to accumulate in a
+   * batch.
+   * @param paddedShapes A list of int64 tensors representing the desired padded shapes
+   * of the corresponding output components. These shapes may be partially
+   * specified, using `-1` to indicate that a particular dimension should be
+   * padded to the maximum size of all batch elements.
+   * @param paddingValues A list of scalars containing the padding value to use for
+   * each of the outputs.
+   * @param dropRemainder A scalar representing whether the last batch should be dropped in case its size
+   * is smaller than desired.
+   * @param outputShapes 
+   * @return a new instance of PaddedBatchDatasetV2
+   */
+  public static PaddedBatchDatasetV2 create(Scope scope, Operand<?> inputDataset, Operand<Long> batchSize, Iterable<Operand<Long>> paddedShapes, Iterable<Operand<?>> paddingValues, Operand<Boolean> dropRemainder, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("PaddedBatchDatasetV2", scope.makeOpName("PaddedBatchDatasetV2"));
+    opBuilder.addInput(inputDataset.asOutput());
+    opBuilder.addInput(batchSize.asOutput());
+    opBuilder.addInputList(Operands.asOutputs(paddedShapes));
+    opBuilder.addInputList(Operands.asOutputs(paddingValues));
+    opBuilder.addInput(dropRemainder.asOutput());
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new PaddedBatchDatasetV2(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private PaddedBatchDatasetV2(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/PaddingFIFOQueue.java java-ops/org/tensorflow/op/core/PaddingFIFOQueue.java
--- java/org/tensorflow/op/core/PaddingFIFOQueue.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/PaddingFIFOQueue.java	2018-10-16 20:18:38.375432280 +0900
@@ -0,0 +1,193 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * A queue that produces elements in first-in first-out order.
+ * <p>
+ * Variable-size shapes are allowed by setting the corresponding shape dimensions
+ * to 0 in the shape attr.  In this case DequeueMany will pad up to the maximum
+ * size of any given element in the minibatch.  See below for details.
+ */
+@Operator
+public final class PaddingFIFOQueue extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.PaddingFIFOQueue}
+   */
+  public static class Options {
+    
+    /**
+     * @param shapes The shape of each component in a value. The length of this attr must
+     * be either 0 or the same as the length of component_types.
+     * Shapes of fixed rank but variable size are allowed by setting
+     * any shape dimension to -1.  In this case, the inputs' shape may vary along
+     * the given dimension, and DequeueMany will pad the given dimension with
+     * zeros up to the maximum shape of all elements in the given batch.
+     * If the length of this attr is 0, different queue elements may have
+     * different ranks and shapes, but only one element may be dequeued at a time.
+     */
+    public Options shapes(List<Shape> shapes) {
+      this.shapes = shapes;
+      return this;
+    }
+    
+    /**
+     * @param capacity The upper bound on the number of elements in this queue.
+     * Negative numbers mean no limit.
+     */
+    public Options capacity(Long capacity) {
+      this.capacity = capacity;
+      return this;
+    }
+    
+    /**
+     * @param container If non-empty, this queue is placed in the given container.
+     * Otherwise, a default container is used.
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName If non-empty, this queue will be shared under the given name
+     * across multiple sessions.
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private List<Shape> shapes;
+    private Long capacity;
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new PaddingFIFOQueue operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param componentTypes The type of each component in a value.
+   * @param options carries optional attributes values
+   * @return a new instance of PaddingFIFOQueue
+   */
+  public static PaddingFIFOQueue create(Scope scope, List<Class<?>> componentTypes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("PaddingFIFOQueueV2", scope.makeOpName("PaddingFIFOQueue"));
+    DataType[] componentTypesArray = new DataType[componentTypes.size()];
+    for (int i = 0; i < componentTypesArray.length; ++i) {
+      componentTypesArray[i] = DataType.fromClass(componentTypes.get(i));
+    }
+    opBuilder.setAttr("component_types", componentTypesArray);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.shapes != null) {
+          Shape[] shapesArray = new Shape[opts.shapes.size()];
+          for (int i = 0; i < shapesArray.length; ++i) {
+            shapesArray[i] = opts.shapes.get(i);
+          }
+          opBuilder.setAttr("shapes", shapesArray);
+        }
+        if (opts.capacity != null) {
+          opBuilder.setAttr("capacity", opts.capacity);
+        }
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new PaddingFIFOQueue(opBuilder.build());
+  }
+  
+  /**
+   * @param shapes The shape of each component in a value. The length of this attr must
+   * be either 0 or the same as the length of component_types.
+   * Shapes of fixed rank but variable size are allowed by setting
+   * any shape dimension to -1.  In this case, the inputs' shape may vary along
+   * the given dimension, and DequeueMany will pad the given dimension with
+   * zeros up to the maximum shape of all elements in the given batch.
+   * If the length of this attr is 0, different queue elements may have
+   * different ranks and shapes, but only one element may be dequeued at a time.
+   */
+  public static Options shapes(List<Shape> shapes) {
+    return new Options().shapes(shapes);
+  }
+  
+  /**
+   * @param capacity The upper bound on the number of elements in this queue.
+   * Negative numbers mean no limit.
+   */
+  public static Options capacity(Long capacity) {
+    return new Options().capacity(capacity);
+  }
+  
+  /**
+   * @param container If non-empty, this queue is placed in the given container.
+   * Otherwise, a default container is used.
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName If non-empty, this queue will be shared under the given name
+   * across multiple sessions.
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   * The handle to the queue.
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private PaddingFIFOQueue(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Pad.java java-ops/org/tensorflow/op/core/Pad.java
--- java/org/tensorflow/op/core/Pad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Pad.java	2018-10-16 20:18:38.374432281 +0900
@@ -0,0 +1,92 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Pads a tensor with zeros.
+ * <p>
+ * This operation pads a `input` with zeros according to the `paddings` you
+ * specify. `paddings` is an integer tensor with shape `[Dn, 2]`, where n is the
+ * rank of `input`. For each dimension D of `input`, `paddings[D, 0]` indicates
+ * how many zeros to add before the contents of `input` in that dimension, and
+ * `paddings[D, 1]` indicates how many zeros to add after the contents of `input`
+ * in that dimension.
+ * <p>
+ * The padded size of each dimension D of the output is:
+ * <p>
+ * `paddings(D, 0) + input.dim_size(D) + paddings(D, 1)`
+ * <p>
+ * For example:
+ * <pre>{@code
+ * # 't' is [[1, 1], [2, 2]]
+ * # 'paddings' is [[1, 1], [2, 2]]
+ * # rank of 't' is 2
+ * pad(t, paddings) ==> [[0, 0, 0, 0, 0, 0]
+ *                       [0, 0, 1, 1, 0, 0]
+ *                       [0, 0, 2, 2, 0, 0]
+ *                       [0, 0, 0, 0, 0, 0]]
+ * }</pre>
+ * 
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class Pad<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Pad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param paddings 
+   * @return a new instance of Pad
+   */
+  public static <T, U extends Number> Pad<T> create(Scope scope, Operand<T> input, Operand<U> paddings) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Pad", scope.makeOpName("Pad"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(paddings.asOutput());
+    return new Pad<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private Pad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/PadV2.java java-ops/org/tensorflow/op/core/PadV2.java
--- java/org/tensorflow/op/core/PadV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/PadV2.java	2018-10-16 20:18:38.374432281 +0900
@@ -0,0 +1,96 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Pads a tensor.
+ * <p>
+ * This operation pads `input` according to the `paddings` and `constant_values`
+ * you specify. `paddings` is an integer tensor with shape `[Dn, 2]`, where n is
+ * the rank of `input`. For each dimension D of `input`, `paddings[D, 0]` indicates
+ * how many padding values to add before the contents of `input` in that dimension,
+ * and `paddings[D, 1]` indicates how many padding values to add after the contents
+ * of `input` in that dimension. `constant_values` is a scalar tensor of the same
+ * type as `input` that indicates the value to use for padding `input`.
+ * <p>
+ * The padded size of each dimension D of the output is:
+ * <p>
+ * `paddings(D, 0) + input.dim_size(D) + paddings(D, 1)`
+ * <p>
+ * For example:
+ * <pre>{@code
+ * # 't' is [[1, 1], [2, 2]]
+ * # 'paddings' is [[1, 1], [2, 2]]
+ * # 'constant_values' is 0
+ * # rank of 't' is 2
+ * pad(t, paddings) ==> [[0, 0, 0, 0, 0, 0]
+ *                       [0, 0, 1, 1, 0, 0]
+ *                       [0, 0, 2, 2, 0, 0]
+ *                       [0, 0, 0, 0, 0, 0]]
+ * }</pre>
+ * 
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class PadV2<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new PadV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param paddings 
+   * @param constantValues 
+   * @return a new instance of PadV2
+   */
+  public static <T, U extends Number> PadV2<T> create(Scope scope, Operand<T> input, Operand<U> paddings, Operand<T> constantValues) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("PadV2", scope.makeOpName("PadV2"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(paddings.asOutput());
+    opBuilder.addInput(constantValues.asOutput());
+    return new PadV2<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private PadV2(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ParallelConcat.java java-ops/org/tensorflow/op/core/ParallelConcat.java
--- java/org/tensorflow/op/core/ParallelConcat.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ParallelConcat.java	2018-10-16 20:18:38.376432280 +0900
@@ -0,0 +1,88 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Concatenates a list of `N` tensors along the first dimension.
+ * <p>
+ * The input tensors are all required to have size 1 in the first dimension.
+ * <p>
+ * For example:
+ * <pre>{@code
+ * # 'x' is [[1, 4]]
+ * # 'y' is [[2, 5]]
+ * # 'z' is [[3, 6]]
+ * parallel_concat([x, y, z]) => [[1, 4], [2, 5], [3, 6]]  # Pack along first dim.
+ * }</pre>
+ * The difference between concat and parallel_concat is that concat requires all
+ * of the inputs be computed before the operation will begin but doesn't require
+ * that the input shapes be known during graph construction.  Parallel concat
+ * will copy pieces of the input into the output as they become available, in
+ * some situations this can provide a performance benefit.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class ParallelConcat<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new ParallelConcat operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param values Tensors to be concatenated. All must have size 1 in the first dimension
+   * and same shape.
+   * @param shape the final shape of the result; should be equal to the shapes of any input
+   * but with the number of input values in the first dimension.
+   * @return a new instance of ParallelConcat
+   */
+  public static <T> ParallelConcat<T> create(Scope scope, Operand<T> values, Shape shape) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ParallelConcat", scope.makeOpName("ParallelConcat"));
+    opBuilder.addInput(values.asOutput());
+    opBuilder.setAttr("shape", shape);
+    return new ParallelConcat<T>(opBuilder.build());
+  }
+  
+  /**
+   * The concatenated tensor.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private ParallelConcat(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ParallelDynamicStitch.java java-ops/org/tensorflow/op/core/ParallelDynamicStitch.java
--- java/org/tensorflow/op/core/ParallelDynamicStitch.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ParallelDynamicStitch.java	2018-10-16 20:18:38.377432279 +0900
@@ -0,0 +1,124 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Interleave the values from the `data` tensors into a single tensor.
+ * <p>
+ * Builds a merged tensor such that
+ * <pre>{@code
+ *     merged[indices[m][i, ..., j], ...] = data[m][i, ..., j, ...]
+ * }</pre>
+ * For example, if each `indices[m]` is scalar or vector, we have
+ * <pre>{@code
+ *     # Scalar indices:
+ *     merged[indices[m], ...] = data[m][...]
+ * 
+ *     # Vector indices:
+ *     merged[indices[m][i], ...] = data[m][i, ...]
+ * }</pre>
+ * Each `data[i].shape` must start with the corresponding `indices[i].shape`,
+ * and the rest of `data[i].shape` must be constant w.r.t. `i`.  That is, we
+ * must have `data[i].shape = indices[i].shape + constant`.  In terms of this
+ * `constant`, the output shape is
+ * <p>
+ *     merged.shape = [max(indices)] + constant
+ * <p>
+ * Values may be merged in parallel, so if an index appears in both `indices[m][i]`
+ * and `indices[n][j]`, the result may be invalid. This differs from the normal
+ * DynamicStitch operator that defines the behavior in that case.
+ * <p>
+ * For example:
+ * <pre>{@code
+ *     indices[0] = 6
+ *     indices[1] = [4, 1]
+ *     indices[2] = [[5, 2], [0, 3]]
+ *     data[0] = [61, 62]
+ *     data[1] = [[41, 42], [11, 12]]
+ *     data[2] = [[[51, 52], [21, 22]], [[1, 2], [31, 32]]]
+ *     merged = [[1, 2], [11, 12], [21, 22], [31, 32], [41, 42],
+ *               [51, 52], [61, 62]]
+ * }</pre>
+ * This method can be used to merge partitions created by `dynamic_partition`
+ * as illustrated on the following example:
+ * <pre>{@code
+ *     # Apply function (increments x_i) on elements for which a certain condition
+ *     # apply (x_i != -1 in this example).
+ *     x=tf.constant([0.1, -1., 5.2, 4.3, -1., 7.4])
+ *     condition_mask=tf.not_equal(x,tf.constant(-1.))
+ *     partitioned_data = tf.dynamic_partition(
+ *         x, tf.cast(condition_mask, tf.int32) , 2)
+ *     partitioned_data[1] = partitioned_data[1] + 1.0
+ *     condition_indices = tf.dynamic_partition(
+ *         tf.range(tf.shape(x)[0]), tf.cast(condition_mask, tf.int32) , 2)
+ *     x = tf.dynamic_stitch(condition_indices, partitioned_data)
+ *     # Here x=[1.1, -1., 6.2, 5.3, -1, 8.4], the -1. values remain
+ *     # unchanged.
+ * }</pre>
+ * <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
+ * <img style="width:100%" src="https://www.tensorflow.org/images/DynamicStitch.png" alt>
+ * </div>
+ * 
+ * @param <T> data type for {@code merged()} output
+ */
+@Operator
+public final class ParallelDynamicStitch<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new ParallelDynamicStitch operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param indices 
+   * @param data 
+   * @return a new instance of ParallelDynamicStitch
+   */
+  public static <T> ParallelDynamicStitch<T> create(Scope scope, Iterable<Operand<Integer>> indices, Operand<T> data) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ParallelDynamicStitch", scope.makeOpName("ParallelDynamicStitch"));
+    opBuilder.addInputList(Operands.asOutputs(indices));
+    opBuilder.addInput(data.asOutput());
+    return new ParallelDynamicStitch<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> merged() {
+    return merged;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return merged;
+  }
+  
+  private Output<T> merged;
+  
+  private ParallelDynamicStitch(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    merged = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ParameterizedTruncatedNormal.java java-ops/org/tensorflow/op/core/ParameterizedTruncatedNormal.java
--- java/org/tensorflow/op/core/ParameterizedTruncatedNormal.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ParameterizedTruncatedNormal.java	2018-10-16 20:18:38.377432279 +0900
@@ -0,0 +1,138 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Outputs random values from a normal distribution. The parameters may each be a
+ * <p>
+ * scalar which applies to the entire output, or a vector of length shape[0] which
+ * stores the parameters for each batch.
+ * 
+ * @param <U> data type for {@code output()} output
+ */
+@Operator
+public final class ParameterizedTruncatedNormal<U extends Number> extends PrimitiveOp implements Operand<U> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ParameterizedTruncatedNormal}
+   */
+  public static class Options {
+    
+    /**
+     * @param seed If either `seed` or `seed2` are set to be non-zero, the random number
+     * generator is seeded by the given seed.  Otherwise, it is seeded by a
+     * random seed.
+     */
+    public Options seed(Long seed) {
+      this.seed = seed;
+      return this;
+    }
+    
+    /**
+     * @param seed2 A second seed to avoid seed collision.
+     */
+    public Options seed2(Long seed2) {
+      this.seed2 = seed2;
+      return this;
+    }
+    
+    private Long seed;
+    private Long seed2;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ParameterizedTruncatedNormal operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param shape The shape of the output tensor. Batches are indexed by the 0th dimension.
+   * @param means The mean parameter of each batch.
+   * @param stdevs The standard deviation parameter of each batch. Must be greater than 0.
+   * @param minvals The minimum cutoff. May be -infinity.
+   * @param maxvals The maximum cutoff. May be +infinity, and must be more than the minval
+   * for each batch.
+   * @param options carries optional attributes values
+   * @return a new instance of ParameterizedTruncatedNormal
+   */
+  public static <U extends Number, T extends Number> ParameterizedTruncatedNormal<U> create(Scope scope, Operand<T> shape, Operand<U> means, Operand<U> stdevs, Operand<U> minvals, Operand<U> maxvals, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ParameterizedTruncatedNormal", scope.makeOpName("ParameterizedTruncatedNormal"));
+    opBuilder.addInput(shape.asOutput());
+    opBuilder.addInput(means.asOutput());
+    opBuilder.addInput(stdevs.asOutput());
+    opBuilder.addInput(minvals.asOutput());
+    opBuilder.addInput(maxvals.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.seed != null) {
+          opBuilder.setAttr("seed", opts.seed);
+        }
+        if (opts.seed2 != null) {
+          opBuilder.setAttr("seed2", opts.seed2);
+        }
+      }
+    }
+    return new ParameterizedTruncatedNormal<U>(opBuilder.build());
+  }
+  
+  /**
+   * @param seed If either `seed` or `seed2` are set to be non-zero, the random number
+   * generator is seeded by the given seed.  Otherwise, it is seeded by a
+   * random seed.
+   */
+  public static Options seed(Long seed) {
+    return new Options().seed(seed);
+  }
+  
+  /**
+   * @param seed2 A second seed to avoid seed collision.
+   */
+  public static Options seed2(Long seed2) {
+    return new Options().seed2(seed2);
+  }
+  
+  /**
+   * A matrix of shape num_batches x samples_per_batch, filled with random
+   * truncated normal values using the parameters for each row.
+   */
+  public Output<U> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<U> asOutput() {
+    return output;
+  }
+  
+  private Output<U> output;
+  
+  private ParameterizedTruncatedNormal(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ParseExampleDataset.java java-ops/org/tensorflow/op/core/ParseExampleDataset.java
--- java/org/tensorflow/op/core/ParseExampleDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ParseExampleDataset.java	2018-10-16 20:18:38.379432278 +0900
@@ -0,0 +1,123 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Transforms `input_dataset` containing `Example` protos as vectors of DT_STRING into a dataset of `Tensor` or `SparseTensor` objects representing the parsed features.
+ */
+@Operator
+public final class ParseExampleDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new ParseExampleDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputDataset 
+   * @param numParallelCalls 
+   * @param denseDefaults A dict mapping string keys to `Tensor`s.
+   * The keys of the dict must match the dense_keys of the feature.
+   * @param sparseKeys A list of string keys in the examples features.
+   * The results for these keys will be returned as `SparseTensor` objects.
+   * @param denseKeys A list of Ndense string Tensors (scalars).
+   * The keys expected in the Examples features associated with dense values.
+   * @param sparseTypes A list of `DTypes` of the same length as `sparse_keys`.
+   * Only `tf.float32` (`FloatList`), `tf.int64` (`Int64List`),
+   * and `tf.string` (`BytesList`) are supported.
+   * @param denseShapes List of tuples with the same length as `dense_keys`.
+   * The shape of the data for each dense feature referenced by `dense_keys`.
+   * Required for any input tensors identified by `dense_keys`.  Must be
+   * either fully defined, or may contain an unknown first dimension.
+   * An unknown first dimension means the feature is treated as having
+   * a variable number of blocks, and the output shape along this dimension
+   * is considered unknown at graph build time.  Padding is applied for
+   * minibatch elements smaller than the maximum number of blocks for the
+   * given feature along this dimension.
+   * @param outputTypes The type list for the return values.
+   * @param outputShapes The list of shapes being produced.
+   * @return a new instance of ParseExampleDataset
+   */
+  public static ParseExampleDataset create(Scope scope, Operand<?> inputDataset, Operand<Long> numParallelCalls, Iterable<Operand<?>> denseDefaults, List<String> sparseKeys, List<String> denseKeys, List<Class<?>> sparseTypes, List<Shape> denseShapes, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ParseExampleDataset", scope.makeOpName("ParseExampleDataset"));
+    opBuilder.addInput(inputDataset.asOutput());
+    opBuilder.addInput(numParallelCalls.asOutput());
+    opBuilder.addInputList(Operands.asOutputs(denseDefaults));
+    String[] sparseKeysArray = new String[sparseKeys.size()];
+    for (int i = 0; i < sparseKeysArray.length; ++i) {
+      sparseKeysArray[i] = sparseKeys.get(i);
+    }
+    opBuilder.setAttr("sparse_keys", sparseKeysArray);
+    String[] denseKeysArray = new String[denseKeys.size()];
+    for (int i = 0; i < denseKeysArray.length; ++i) {
+      denseKeysArray[i] = denseKeys.get(i);
+    }
+    opBuilder.setAttr("dense_keys", denseKeysArray);
+    DataType[] sparseTypesArray = new DataType[sparseTypes.size()];
+    for (int i = 0; i < sparseTypesArray.length; ++i) {
+      sparseTypesArray[i] = DataType.fromClass(sparseTypes.get(i));
+    }
+    opBuilder.setAttr("sparse_types", sparseTypesArray);
+    Shape[] denseShapesArray = new Shape[denseShapes.size()];
+    for (int i = 0; i < denseShapesArray.length; ++i) {
+      denseShapesArray[i] = denseShapes.get(i);
+    }
+    opBuilder.setAttr("dense_shapes", denseShapesArray);
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new ParseExampleDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private ParseExampleDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ParseExample.java java-ops/org/tensorflow/op/core/ParseExample.java
--- java/org/tensorflow/op/core/ParseExample.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ParseExample.java	2018-10-16 20:18:38.378432278 +0900
@@ -0,0 +1,150 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Transforms a vector of brain.Example protos (as strings) into typed tensors.
+ */
+@Operator
+public final class ParseExample extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new ParseExample operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param serialized A vector containing a batch of binary serialized Example protos.
+   * @param names A vector containing the names of the serialized protos.
+   * May contain, for example, table key (descriptive) names for the
+   * corresponding serialized protos.  These are purely useful for debugging
+   * purposes, and the presence of values here has no effect on the output.
+   * May also be an empty vector if no names are available.
+   * If non-empty, this vector must be the same length as "serialized".
+   * @param sparseKeys A list of Nsparse string Tensors (scalars).
+   * The keys expected in the Examples' features associated with sparse values.
+   * @param denseKeys A list of Ndense string Tensors (scalars).
+   * The keys expected in the Examples' features associated with dense values.
+   * @param denseDefaults A list of Ndense Tensors (some may be empty).
+   * dense_defaults[j] provides default values
+   * when the example's feature_map lacks dense_key[j].  If an empty Tensor is
+   * provided for dense_defaults[j], then the Feature dense_keys[j] is required.
+   * The input type is inferred from dense_defaults[j], even when it's empty.
+   * If dense_defaults[j] is not empty, and dense_shapes[j] is fully defined,
+   * then the shape of dense_defaults[j] must match that of dense_shapes[j].
+   * If dense_shapes[j] has an undefined major dimension (variable strides dense
+   * feature), dense_defaults[j] must contain a single element:
+   * the padding element.
+   * @param sparseTypes A list of Nsparse types; the data types of data in each Feature
+   * given in sparse_keys.
+   * Currently the ParseExample supports DT_FLOAT (FloatList),
+   * DT_INT64 (Int64List), and DT_STRING (BytesList).
+   * @param denseShapes A list of Ndense shapes; the shapes of data in each Feature
+   * given in dense_keys.
+   * The number of elements in the Feature corresponding to dense_key[j]
+   * must always equal dense_shapes[j].NumEntries().
+   * If dense_shapes[j] == (D0, D1, ..., DN) then the shape of output
+   * Tensor dense_values[j] will be (|serialized|, D0, D1, ..., DN):
+   * The dense outputs are just the inputs row-stacked by batch.
+   * This works for dense_shapes[j] = (-1, D1, ..., DN).  In this case
+   * the shape of the output Tensor dense_values[j] will be
+   * (|serialized|, M, D1, .., DN), where M is the maximum number of blocks
+   * of elements of length D1 * .... * DN, across all minibatch entries
+   * in the input.  Any minibatch entry with less than M blocks of elements of
+   * length D1 * ... * DN will be padded with the corresponding default_value
+   * scalar element along the second dimension.
+   * @return a new instance of ParseExample
+   */
+  public static ParseExample create(Scope scope, Operand<String> serialized, Operand<String> names, Iterable<Operand<String>> sparseKeys, Iterable<Operand<String>> denseKeys, Iterable<Operand<?>> denseDefaults, List<Class<?>> sparseTypes, List<Shape> denseShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ParseExample", scope.makeOpName("ParseExample"));
+    opBuilder.addInput(serialized.asOutput());
+    opBuilder.addInput(names.asOutput());
+    opBuilder.addInputList(Operands.asOutputs(sparseKeys));
+    opBuilder.addInputList(Operands.asOutputs(denseKeys));
+    opBuilder.addInputList(Operands.asOutputs(denseDefaults));
+    DataType[] sparseTypesArray = new DataType[sparseTypes.size()];
+    for (int i = 0; i < sparseTypesArray.length; ++i) {
+      sparseTypesArray[i] = DataType.fromClass(sparseTypes.get(i));
+    }
+    opBuilder.setAttr("sparse_types", sparseTypesArray);
+    Shape[] denseShapesArray = new Shape[denseShapes.size()];
+    for (int i = 0; i < denseShapesArray.length; ++i) {
+      denseShapesArray[i] = denseShapes.get(i);
+    }
+    opBuilder.setAttr("dense_shapes", denseShapesArray);
+    return new ParseExample(opBuilder.build());
+  }
+  
+  /**
+   */
+  public List<Output<Long>> sparseIndices() {
+    return sparseIndices;
+  }
+  
+  /**
+   */
+  public List<Output<?>> sparseValues() {
+    return sparseValues;
+  }
+  
+  /**
+   */
+  public List<Output<Long>> sparseShapes() {
+    return sparseShapes;
+  }
+  
+  /**
+   */
+  public List<Output<?>> denseValues() {
+    return denseValues;
+  }
+  
+  private List<Output<Long>> sparseIndices;
+  private List<Output<?>> sparseValues;
+  private List<Output<Long>> sparseShapes;
+  private List<Output<?>> denseValues;
+  
+  @SuppressWarnings("unchecked")
+  private ParseExample(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    int sparseIndicesLength = operation.outputListLength("sparse_indices");
+    sparseIndices = Arrays.asList((Output<Long>[])operation.outputList(outputIdx, sparseIndicesLength));
+    outputIdx += sparseIndicesLength;
+    int sparseValuesLength = operation.outputListLength("sparse_values");
+    sparseValues = Arrays.asList(operation.outputList(outputIdx, sparseValuesLength));
+    outputIdx += sparseValuesLength;
+    int sparseShapesLength = operation.outputListLength("sparse_shapes");
+    sparseShapes = Arrays.asList((Output<Long>[])operation.outputList(outputIdx, sparseShapesLength));
+    outputIdx += sparseShapesLength;
+    int denseValuesLength = operation.outputListLength("dense_values");
+    denseValues = Arrays.asList(operation.outputList(outputIdx, denseValuesLength));
+    outputIdx += denseValuesLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/ParseSequenceExample.java java-ops/org/tensorflow/op/core/ParseSequenceExample.java
--- java/org/tensorflow/op/core/ParseSequenceExample.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ParseSequenceExample.java	2018-10-16 20:18:38.381432276 +0900
@@ -0,0 +1,381 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Transforms a vector of brain.SequenceExample protos (as strings) into typed tensors.
+ */
+@Operator
+public final class ParseSequenceExample extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ParseSequenceExample}
+   */
+  public static class Options {
+    
+    /**
+     * @param NcontextSparse 
+     */
+    public Options NcontextSparse(Long NcontextSparse) {
+      this.NcontextSparse = NcontextSparse;
+      return this;
+    }
+    
+    /**
+     * @param NcontextDense 
+     */
+    public Options NcontextDense(Long NcontextDense) {
+      this.NcontextDense = NcontextDense;
+      return this;
+    }
+    
+    /**
+     * @param NfeatureListSparse 
+     */
+    public Options NfeatureListSparse(Long NfeatureListSparse) {
+      this.NfeatureListSparse = NfeatureListSparse;
+      return this;
+    }
+    
+    /**
+     * @param NfeatureListDense 
+     */
+    public Options NfeatureListDense(Long NfeatureListDense) {
+      this.NfeatureListDense = NfeatureListDense;
+      return this;
+    }
+    
+    /**
+     * @param contextDenseShapes A list of Ncontext_dense shapes; the shapes of data in
+     * each context Feature given in context_dense_keys.
+     * The number of elements in the Feature corresponding to context_dense_key[j]
+     * must always equal context_dense_shapes[j].NumEntries().
+     * The shape of context_dense_values[j] will match context_dense_shapes[j].
+     */
+    public Options contextDenseShapes(List<Shape> contextDenseShapes) {
+      this.contextDenseShapes = contextDenseShapes;
+      return this;
+    }
+    
+    /**
+     * @param featureListDenseShapes A list of Nfeature_list_dense shapes; the shapes of
+     * data in each FeatureList given in feature_list_dense_keys.
+     * The shape of each Feature in the FeatureList corresponding to
+     * feature_list_dense_key[j] must always equal
+     * feature_list_dense_shapes[j].NumEntries().
+     */
+    public Options featureListDenseShapes(List<Shape> featureListDenseShapes) {
+      this.featureListDenseShapes = featureListDenseShapes;
+      return this;
+    }
+    
+    private Long NcontextSparse;
+    private Long NcontextDense;
+    private Long NfeatureListSparse;
+    private Long NfeatureListDense;
+    private List<Shape> contextDenseShapes;
+    private List<Shape> featureListDenseShapes;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ParseSequenceExample operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param serialized A vector containing binary serialized SequenceExample protos.
+   * @param debugName A vector containing the names of the serialized protos.
+   * May contain, for example, table key (descriptive) name for the
+   * corresponding serialized proto.  This is purely useful for debugging
+   * purposes, and the presence of values here has no effect on the output.
+   * May also be an empty vector if no name is available.
+   * @param contextDenseDefaults A list of Ncontext_dense Tensors (some may be empty).
+   * context_dense_defaults[j] provides default values
+   * when the SequenceExample's context map lacks context_dense_key[j].
+   * If an empty Tensor is provided for context_dense_defaults[j],
+   * then the Feature context_dense_keys[j] is required.
+   * The input type is inferred from context_dense_defaults[j], even when it's
+   * empty.  If context_dense_defaults[j] is not empty, its shape must match
+   * context_dense_shapes[j].
+   * @param featureListDenseMissingAssumedEmpty A vector listing the
+   * FeatureList keys which may be missing from the SequenceExamples.  If the
+   * associated FeatureList is missing, it is treated as empty.  By default,
+   * any FeatureList not listed in this vector must exist in the SequenceExamples.
+   * @param contextSparseKeys A list of Ncontext_sparse string Tensors (scalars).
+   * The keys expected in the Examples' features associated with context_sparse
+   * values.
+   * @param contextDenseKeys A list of Ncontext_dense string Tensors (scalars).
+   * The keys expected in the SequenceExamples' context features associated with
+   * dense values.
+   * @param featureListSparseKeys A list of Nfeature_list_sparse string Tensors
+   * (scalars).  The keys expected in the FeatureLists associated with sparse
+   * values.
+   * @param featureListDenseKeys A list of Nfeature_list_dense string Tensors (scalars).
+   * The keys expected in the SequenceExamples' feature_lists associated
+   * with lists of dense values.
+   * @param contextSparseTypes A list of Ncontext_sparse types; the data types of data in
+   * each context Feature given in context_sparse_keys.
+   * Currently the ParseSingleSequenceExample supports DT_FLOAT (FloatList),
+   * DT_INT64 (Int64List), and DT_STRING (BytesList).
+   * @param featureListDenseTypes 
+   * @param featureListSparseTypes A list of Nfeature_list_sparse types; the data types
+   * of data in each FeatureList given in feature_list_sparse_keys.
+   * Currently the ParseSingleSequenceExample supports DT_FLOAT (FloatList),
+   * DT_INT64 (Int64List), and DT_STRING (BytesList).
+   * @param options carries optional attributes values
+   * @return a new instance of ParseSequenceExample
+   */
+  public static ParseSequenceExample create(Scope scope, Operand<String> serialized, Operand<String> debugName, Iterable<Operand<?>> contextDenseDefaults, List<String> featureListDenseMissingAssumedEmpty, List<String> contextSparseKeys, List<String> contextDenseKeys, List<String> featureListSparseKeys, List<String> featureListDenseKeys, List<Class<?>> contextSparseTypes, List<Class<?>> featureListDenseTypes, List<Class<?>> featureListSparseTypes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ParseSequenceExample", scope.makeOpName("ParseSequenceExample"));
+    opBuilder.addInput(serialized.asOutput());
+    opBuilder.addInput(debugName.asOutput());
+    opBuilder.addInputList(Operands.asOutputs(contextDenseDefaults));
+    String[] featureListDenseMissingAssumedEmptyArray = new String[featureListDenseMissingAssumedEmpty.size()];
+    for (int i = 0; i < featureListDenseMissingAssumedEmptyArray.length; ++i) {
+      featureListDenseMissingAssumedEmptyArray[i] = featureListDenseMissingAssumedEmpty.get(i);
+    }
+    opBuilder.setAttr("feature_list_dense_missing_assumed_empty", featureListDenseMissingAssumedEmptyArray);
+    String[] contextSparseKeysArray = new String[contextSparseKeys.size()];
+    for (int i = 0; i < contextSparseKeysArray.length; ++i) {
+      contextSparseKeysArray[i] = contextSparseKeys.get(i);
+    }
+    opBuilder.setAttr("context_sparse_keys", contextSparseKeysArray);
+    String[] contextDenseKeysArray = new String[contextDenseKeys.size()];
+    for (int i = 0; i < contextDenseKeysArray.length; ++i) {
+      contextDenseKeysArray[i] = contextDenseKeys.get(i);
+    }
+    opBuilder.setAttr("context_dense_keys", contextDenseKeysArray);
+    String[] featureListSparseKeysArray = new String[featureListSparseKeys.size()];
+    for (int i = 0; i < featureListSparseKeysArray.length; ++i) {
+      featureListSparseKeysArray[i] = featureListSparseKeys.get(i);
+    }
+    opBuilder.setAttr("feature_list_sparse_keys", featureListSparseKeysArray);
+    String[] featureListDenseKeysArray = new String[featureListDenseKeys.size()];
+    for (int i = 0; i < featureListDenseKeysArray.length; ++i) {
+      featureListDenseKeysArray[i] = featureListDenseKeys.get(i);
+    }
+    opBuilder.setAttr("feature_list_dense_keys", featureListDenseKeysArray);
+    DataType[] contextSparseTypesArray = new DataType[contextSparseTypes.size()];
+    for (int i = 0; i < contextSparseTypesArray.length; ++i) {
+      contextSparseTypesArray[i] = DataType.fromClass(contextSparseTypes.get(i));
+    }
+    opBuilder.setAttr("context_sparse_types", contextSparseTypesArray);
+    DataType[] featureListDenseTypesArray = new DataType[featureListDenseTypes.size()];
+    for (int i = 0; i < featureListDenseTypesArray.length; ++i) {
+      featureListDenseTypesArray[i] = DataType.fromClass(featureListDenseTypes.get(i));
+    }
+    opBuilder.setAttr("feature_list_dense_types", featureListDenseTypesArray);
+    DataType[] featureListSparseTypesArray = new DataType[featureListSparseTypes.size()];
+    for (int i = 0; i < featureListSparseTypesArray.length; ++i) {
+      featureListSparseTypesArray[i] = DataType.fromClass(featureListSparseTypes.get(i));
+    }
+    opBuilder.setAttr("feature_list_sparse_types", featureListSparseTypesArray);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.NcontextSparse != null) {
+          opBuilder.setAttr("Ncontext_sparse", opts.NcontextSparse);
+        }
+        if (opts.NcontextDense != null) {
+          opBuilder.setAttr("Ncontext_dense", opts.NcontextDense);
+        }
+        if (opts.NfeatureListSparse != null) {
+          opBuilder.setAttr("Nfeature_list_sparse", opts.NfeatureListSparse);
+        }
+        if (opts.NfeatureListDense != null) {
+          opBuilder.setAttr("Nfeature_list_dense", opts.NfeatureListDense);
+        }
+        if (opts.contextDenseShapes != null) {
+          Shape[] contextDenseShapesArray = new Shape[opts.contextDenseShapes.size()];
+          for (int i = 0; i < contextDenseShapesArray.length; ++i) {
+            contextDenseShapesArray[i] = opts.contextDenseShapes.get(i);
+          }
+          opBuilder.setAttr("context_dense_shapes", contextDenseShapesArray);
+        }
+        if (opts.featureListDenseShapes != null) {
+          Shape[] featureListDenseShapesArray = new Shape[opts.featureListDenseShapes.size()];
+          for (int i = 0; i < featureListDenseShapesArray.length; ++i) {
+            featureListDenseShapesArray[i] = opts.featureListDenseShapes.get(i);
+          }
+          opBuilder.setAttr("feature_list_dense_shapes", featureListDenseShapesArray);
+        }
+      }
+    }
+    return new ParseSequenceExample(opBuilder.build());
+  }
+  
+  /**
+   * @param NcontextSparse 
+   */
+  public static Options NcontextSparse(Long NcontextSparse) {
+    return new Options().NcontextSparse(NcontextSparse);
+  }
+  
+  /**
+   * @param NcontextDense 
+   */
+  public static Options NcontextDense(Long NcontextDense) {
+    return new Options().NcontextDense(NcontextDense);
+  }
+  
+  /**
+   * @param NfeatureListSparse 
+   */
+  public static Options NfeatureListSparse(Long NfeatureListSparse) {
+    return new Options().NfeatureListSparse(NfeatureListSparse);
+  }
+  
+  /**
+   * @param NfeatureListDense 
+   */
+  public static Options NfeatureListDense(Long NfeatureListDense) {
+    return new Options().NfeatureListDense(NfeatureListDense);
+  }
+  
+  /**
+   * @param contextDenseShapes A list of Ncontext_dense shapes; the shapes of data in
+   * each context Feature given in context_dense_keys.
+   * The number of elements in the Feature corresponding to context_dense_key[j]
+   * must always equal context_dense_shapes[j].NumEntries().
+   * The shape of context_dense_values[j] will match context_dense_shapes[j].
+   */
+  public static Options contextDenseShapes(List<Shape> contextDenseShapes) {
+    return new Options().contextDenseShapes(contextDenseShapes);
+  }
+  
+  /**
+   * @param featureListDenseShapes A list of Nfeature_list_dense shapes; the shapes of
+   * data in each FeatureList given in feature_list_dense_keys.
+   * The shape of each Feature in the FeatureList corresponding to
+   * feature_list_dense_key[j] must always equal
+   * feature_list_dense_shapes[j].NumEntries().
+   */
+  public static Options featureListDenseShapes(List<Shape> featureListDenseShapes) {
+    return new Options().featureListDenseShapes(featureListDenseShapes);
+  }
+  
+  /**
+   */
+  public List<Output<Long>> contextSparseIndices() {
+    return contextSparseIndices;
+  }
+  
+  /**
+   */
+  public List<Output<?>> contextSparseValues() {
+    return contextSparseValues;
+  }
+  
+  /**
+   */
+  public List<Output<Long>> contextSparseShapes() {
+    return contextSparseShapes;
+  }
+  
+  /**
+   */
+  public List<Output<?>> contextDenseValues() {
+    return contextDenseValues;
+  }
+  
+  /**
+   */
+  public List<Output<Long>> featureListSparseIndices() {
+    return featureListSparseIndices;
+  }
+  
+  /**
+   */
+  public List<Output<?>> featureListSparseValues() {
+    return featureListSparseValues;
+  }
+  
+  /**
+   */
+  public List<Output<Long>> featureListSparseShapes() {
+    return featureListSparseShapes;
+  }
+  
+  /**
+   */
+  public List<Output<?>> featureListDenseValues() {
+    return featureListDenseValues;
+  }
+  
+  /**
+   */
+  public List<Output<Long>> featureListDenseLengths() {
+    return featureListDenseLengths;
+  }
+  
+  private List<Output<Long>> contextSparseIndices;
+  private List<Output<?>> contextSparseValues;
+  private List<Output<Long>> contextSparseShapes;
+  private List<Output<?>> contextDenseValues;
+  private List<Output<Long>> featureListSparseIndices;
+  private List<Output<?>> featureListSparseValues;
+  private List<Output<Long>> featureListSparseShapes;
+  private List<Output<?>> featureListDenseValues;
+  private List<Output<Long>> featureListDenseLengths;
+  
+  @SuppressWarnings("unchecked")
+  private ParseSequenceExample(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    int contextSparseIndicesLength = operation.outputListLength("context_sparse_indices");
+    contextSparseIndices = Arrays.asList((Output<Long>[])operation.outputList(outputIdx, contextSparseIndicesLength));
+    outputIdx += contextSparseIndicesLength;
+    int contextSparseValuesLength = operation.outputListLength("context_sparse_values");
+    contextSparseValues = Arrays.asList(operation.outputList(outputIdx, contextSparseValuesLength));
+    outputIdx += contextSparseValuesLength;
+    int contextSparseShapesLength = operation.outputListLength("context_sparse_shapes");
+    contextSparseShapes = Arrays.asList((Output<Long>[])operation.outputList(outputIdx, contextSparseShapesLength));
+    outputIdx += contextSparseShapesLength;
+    int contextDenseValuesLength = operation.outputListLength("context_dense_values");
+    contextDenseValues = Arrays.asList(operation.outputList(outputIdx, contextDenseValuesLength));
+    outputIdx += contextDenseValuesLength;
+    int featureListSparseIndicesLength = operation.outputListLength("feature_list_sparse_indices");
+    featureListSparseIndices = Arrays.asList((Output<Long>[])operation.outputList(outputIdx, featureListSparseIndicesLength));
+    outputIdx += featureListSparseIndicesLength;
+    int featureListSparseValuesLength = operation.outputListLength("feature_list_sparse_values");
+    featureListSparseValues = Arrays.asList(operation.outputList(outputIdx, featureListSparseValuesLength));
+    outputIdx += featureListSparseValuesLength;
+    int featureListSparseShapesLength = operation.outputListLength("feature_list_sparse_shapes");
+    featureListSparseShapes = Arrays.asList((Output<Long>[])operation.outputList(outputIdx, featureListSparseShapesLength));
+    outputIdx += featureListSparseShapesLength;
+    int featureListDenseValuesLength = operation.outputListLength("feature_list_dense_values");
+    featureListDenseValues = Arrays.asList(operation.outputList(outputIdx, featureListDenseValuesLength));
+    outputIdx += featureListDenseValuesLength;
+    int featureListDenseLengthsLength = operation.outputListLength("feature_list_dense_lengths");
+    featureListDenseLengths = Arrays.asList((Output<Long>[])operation.outputList(outputIdx, featureListDenseLengthsLength));
+    outputIdx += featureListDenseLengthsLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/ParseSingleExample.java java-ops/org/tensorflow/op/core/ParseSingleExample.java
--- java/org/tensorflow/op/core/ParseSingleExample.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ParseSingleExample.java	2018-10-16 20:18:38.382432276 +0900
@@ -0,0 +1,149 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Transforms a tf.Example proto (as a string) into typed tensors.
+ */
+@Operator
+public final class ParseSingleExample extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new ParseSingleExample operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param serialized A vector containing a batch of binary serialized Example protos.
+   * @param denseDefaults A list of Tensors (some may be empty), whose length matches
+   * the length of `dense_keys`. dense_defaults[j] provides default values
+   * when the example's feature_map lacks dense_key[j].  If an empty Tensor is
+   * provided for dense_defaults[j], then the Feature dense_keys[j] is required.
+   * The input type is inferred from dense_defaults[j], even when it's empty.
+   * If dense_defaults[j] is not empty, and dense_shapes[j] is fully defined,
+   * then the shape of dense_defaults[j] must match that of dense_shapes[j].
+   * If dense_shapes[j] has an undefined major dimension (variable strides dense
+   * feature), dense_defaults[j] must contain a single element:
+   * the padding element.
+   * @param numSparse The number of sparse features to be parsed from the example. This
+   * must match the lengths of `sparse_keys` and `sparse_types`.
+   * @param sparseKeys A list of `num_sparse` strings.
+   * The keys expected in the Examples' features associated with sparse values.
+   * @param denseKeys The keys expected in the Examples' features associated with dense
+   * values.
+   * @param sparseTypes A list of `num_sparse` types; the data types of data in each
+   * Feature given in sparse_keys.
+   * Currently the ParseSingleExample op supports DT_FLOAT (FloatList),
+   * DT_INT64 (Int64List), and DT_STRING (BytesList).
+   * @param denseShapes The shapes of data in each Feature given in dense_keys.
+   * The length of this list must match the length of `dense_keys`.  The
+   * number of elements in the Feature corresponding to dense_key[j] must
+   * always equal dense_shapes[j].NumEntries().  If dense_shapes[j] ==
+   * (D0, D1, ..., DN) then the shape of output Tensor dense_values[j]
+   * will be (D0, D1, ..., DN): In the case dense_shapes[j] = (-1, D1,
+   * ..., DN), the shape of the output Tensor dense_values[j] will be (M,
+   * D1, .., DN), where M is the number of blocks of elements of length
+   * D1 * .... * DN, in the input.
+   * @return a new instance of ParseSingleExample
+   */
+  public static ParseSingleExample create(Scope scope, Operand<String> serialized, Iterable<Operand<?>> denseDefaults, Long numSparse, List<String> sparseKeys, List<String> denseKeys, List<Class<?>> sparseTypes, List<Shape> denseShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ParseSingleExample", scope.makeOpName("ParseSingleExample"));
+    opBuilder.addInput(serialized.asOutput());
+    opBuilder.addInputList(Operands.asOutputs(denseDefaults));
+    opBuilder.setAttr("num_sparse", numSparse);
+    String[] sparseKeysArray = new String[sparseKeys.size()];
+    for (int i = 0; i < sparseKeysArray.length; ++i) {
+      sparseKeysArray[i] = sparseKeys.get(i);
+    }
+    opBuilder.setAttr("sparse_keys", sparseKeysArray);
+    String[] denseKeysArray = new String[denseKeys.size()];
+    for (int i = 0; i < denseKeysArray.length; ++i) {
+      denseKeysArray[i] = denseKeys.get(i);
+    }
+    opBuilder.setAttr("dense_keys", denseKeysArray);
+    DataType[] sparseTypesArray = new DataType[sparseTypes.size()];
+    for (int i = 0; i < sparseTypesArray.length; ++i) {
+      sparseTypesArray[i] = DataType.fromClass(sparseTypes.get(i));
+    }
+    opBuilder.setAttr("sparse_types", sparseTypesArray);
+    Shape[] denseShapesArray = new Shape[denseShapes.size()];
+    for (int i = 0; i < denseShapesArray.length; ++i) {
+      denseShapesArray[i] = denseShapes.get(i);
+    }
+    opBuilder.setAttr("dense_shapes", denseShapesArray);
+    return new ParseSingleExample(opBuilder.build());
+  }
+  
+  /**
+   */
+  public List<Output<Long>> sparseIndices() {
+    return sparseIndices;
+  }
+  
+  /**
+   */
+  public List<Output<?>> sparseValues() {
+    return sparseValues;
+  }
+  
+  /**
+   */
+  public List<Output<Long>> sparseShapes() {
+    return sparseShapes;
+  }
+  
+  /**
+   */
+  public List<Output<?>> denseValues() {
+    return denseValues;
+  }
+  
+  private List<Output<Long>> sparseIndices;
+  private List<Output<?>> sparseValues;
+  private List<Output<Long>> sparseShapes;
+  private List<Output<?>> denseValues;
+  
+  @SuppressWarnings("unchecked")
+  private ParseSingleExample(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    int sparseIndicesLength = operation.outputListLength("sparse_indices");
+    sparseIndices = Arrays.asList((Output<Long>[])operation.outputList(outputIdx, sparseIndicesLength));
+    outputIdx += sparseIndicesLength;
+    int sparseValuesLength = operation.outputListLength("sparse_values");
+    sparseValues = Arrays.asList(operation.outputList(outputIdx, sparseValuesLength));
+    outputIdx += sparseValuesLength;
+    int sparseShapesLength = operation.outputListLength("sparse_shapes");
+    sparseShapes = Arrays.asList((Output<Long>[])operation.outputList(outputIdx, sparseShapesLength));
+    outputIdx += sparseShapesLength;
+    int denseValuesLength = operation.outputListLength("dense_values");
+    denseValues = Arrays.asList(operation.outputList(outputIdx, denseValuesLength));
+    outputIdx += denseValuesLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/ParseSingleSequenceExample.java java-ops/org/tensorflow/op/core/ParseSingleSequenceExample.java
--- java/org/tensorflow/op/core/ParseSingleSequenceExample.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ParseSingleSequenceExample.java	2018-10-16 20:18:38.383432275 +0900
@@ -0,0 +1,275 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Transforms a scalar brain.SequenceExample proto (as strings) into typed tensors.
+ */
+@Operator
+public final class ParseSingleSequenceExample extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ParseSingleSequenceExample}
+   */
+  public static class Options {
+    
+    /**
+     * @param contextDenseShapes A list of Ncontext_dense shapes; the shapes of data in
+     * each context Feature given in context_dense_keys.
+     * The number of elements in the Feature corresponding to context_dense_key[j]
+     * must always equal context_dense_shapes[j].NumEntries().
+     * The shape of context_dense_values[j] will match context_dense_shapes[j].
+     */
+    public Options contextDenseShapes(List<Shape> contextDenseShapes) {
+      this.contextDenseShapes = contextDenseShapes;
+      return this;
+    }
+    
+    /**
+     * @param featureListDenseShapes A list of Nfeature_list_dense shapes; the shapes of
+     * data in each FeatureList given in feature_list_dense_keys.
+     * The shape of each Feature in the FeatureList corresponding to
+     * feature_list_dense_key[j] must always equal
+     * feature_list_dense_shapes[j].NumEntries().
+     */
+    public Options featureListDenseShapes(List<Shape> featureListDenseShapes) {
+      this.featureListDenseShapes = featureListDenseShapes;
+      return this;
+    }
+    
+    private List<Shape> contextDenseShapes;
+    private List<Shape> featureListDenseShapes;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ParseSingleSequenceExample operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param serialized A scalar containing a binary serialized SequenceExample proto.
+   * @param featureListDenseMissingAssumedEmpty A vector listing the
+   * FeatureList keys which may be missing from the SequenceExample.  If the
+   * associated FeatureList is missing, it is treated as empty.  By default,
+   * any FeatureList not listed in this vector must exist in the SequenceExample.
+   * @param contextSparseKeys A list of Ncontext_sparse string Tensors (scalars).
+   * The keys expected in the Examples' features associated with context_sparse
+   * values.
+   * @param contextDenseKeys A list of Ncontext_dense string Tensors (scalars).
+   * The keys expected in the SequenceExamples' context features associated with
+   * dense values.
+   * @param featureListSparseKeys A list of Nfeature_list_sparse string Tensors
+   * (scalars).  The keys expected in the FeatureLists associated with sparse
+   * values.
+   * @param featureListDenseKeys A list of Nfeature_list_dense string Tensors (scalars).
+   * The keys expected in the SequenceExamples' feature_lists associated
+   * with lists of dense values.
+   * @param contextDenseDefaults A list of Ncontext_dense Tensors (some may be empty).
+   * context_dense_defaults[j] provides default values
+   * when the SequenceExample's context map lacks context_dense_key[j].
+   * If an empty Tensor is provided for context_dense_defaults[j],
+   * then the Feature context_dense_keys[j] is required.
+   * The input type is inferred from context_dense_defaults[j], even when it's
+   * empty.  If context_dense_defaults[j] is not empty, its shape must match
+   * context_dense_shapes[j].
+   * @param debugName A scalar containing the name of the serialized proto.
+   * May contain, for example, table key (descriptive) name for the
+   * corresponding serialized proto.  This is purely useful for debugging
+   * purposes, and the presence of values here has no effect on the output.
+   * May also be an empty scalar if no name is available.
+   * @param contextSparseTypes A list of Ncontext_sparse types; the data types of data in
+   * each context Feature given in context_sparse_keys.
+   * Currently the ParseSingleSequenceExample supports DT_FLOAT (FloatList),
+   * DT_INT64 (Int64List), and DT_STRING (BytesList).
+   * @param featureListDenseTypes 
+   * @param featureListSparseTypes A list of Nfeature_list_sparse types; the data types
+   * of data in each FeatureList given in feature_list_sparse_keys.
+   * Currently the ParseSingleSequenceExample supports DT_FLOAT (FloatList),
+   * DT_INT64 (Int64List), and DT_STRING (BytesList).
+   * @param options carries optional attributes values
+   * @return a new instance of ParseSingleSequenceExample
+   */
+  public static ParseSingleSequenceExample create(Scope scope, Operand<String> serialized, Operand<String> featureListDenseMissingAssumedEmpty, Iterable<Operand<String>> contextSparseKeys, Iterable<Operand<String>> contextDenseKeys, Iterable<Operand<String>> featureListSparseKeys, Iterable<Operand<String>> featureListDenseKeys, Iterable<Operand<?>> contextDenseDefaults, Operand<String> debugName, List<Class<?>> contextSparseTypes, List<Class<?>> featureListDenseTypes, List<Class<?>> featureListSparseTypes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ParseSingleSequenceExample", scope.makeOpName("ParseSingleSequenceExample"));
+    opBuilder.addInput(serialized.asOutput());
+    opBuilder.addInput(featureListDenseMissingAssumedEmpty.asOutput());
+    opBuilder.addInputList(Operands.asOutputs(contextSparseKeys));
+    opBuilder.addInputList(Operands.asOutputs(contextDenseKeys));
+    opBuilder.addInputList(Operands.asOutputs(featureListSparseKeys));
+    opBuilder.addInputList(Operands.asOutputs(featureListDenseKeys));
+    opBuilder.addInputList(Operands.asOutputs(contextDenseDefaults));
+    opBuilder.addInput(debugName.asOutput());
+    DataType[] contextSparseTypesArray = new DataType[contextSparseTypes.size()];
+    for (int i = 0; i < contextSparseTypesArray.length; ++i) {
+      contextSparseTypesArray[i] = DataType.fromClass(contextSparseTypes.get(i));
+    }
+    opBuilder.setAttr("context_sparse_types", contextSparseTypesArray);
+    DataType[] featureListDenseTypesArray = new DataType[featureListDenseTypes.size()];
+    for (int i = 0; i < featureListDenseTypesArray.length; ++i) {
+      featureListDenseTypesArray[i] = DataType.fromClass(featureListDenseTypes.get(i));
+    }
+    opBuilder.setAttr("feature_list_dense_types", featureListDenseTypesArray);
+    DataType[] featureListSparseTypesArray = new DataType[featureListSparseTypes.size()];
+    for (int i = 0; i < featureListSparseTypesArray.length; ++i) {
+      featureListSparseTypesArray[i] = DataType.fromClass(featureListSparseTypes.get(i));
+    }
+    opBuilder.setAttr("feature_list_sparse_types", featureListSparseTypesArray);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.contextDenseShapes != null) {
+          Shape[] contextDenseShapesArray = new Shape[opts.contextDenseShapes.size()];
+          for (int i = 0; i < contextDenseShapesArray.length; ++i) {
+            contextDenseShapesArray[i] = opts.contextDenseShapes.get(i);
+          }
+          opBuilder.setAttr("context_dense_shapes", contextDenseShapesArray);
+        }
+        if (opts.featureListDenseShapes != null) {
+          Shape[] featureListDenseShapesArray = new Shape[opts.featureListDenseShapes.size()];
+          for (int i = 0; i < featureListDenseShapesArray.length; ++i) {
+            featureListDenseShapesArray[i] = opts.featureListDenseShapes.get(i);
+          }
+          opBuilder.setAttr("feature_list_dense_shapes", featureListDenseShapesArray);
+        }
+      }
+    }
+    return new ParseSingleSequenceExample(opBuilder.build());
+  }
+  
+  /**
+   * @param contextDenseShapes A list of Ncontext_dense shapes; the shapes of data in
+   * each context Feature given in context_dense_keys.
+   * The number of elements in the Feature corresponding to context_dense_key[j]
+   * must always equal context_dense_shapes[j].NumEntries().
+   * The shape of context_dense_values[j] will match context_dense_shapes[j].
+   */
+  public static Options contextDenseShapes(List<Shape> contextDenseShapes) {
+    return new Options().contextDenseShapes(contextDenseShapes);
+  }
+  
+  /**
+   * @param featureListDenseShapes A list of Nfeature_list_dense shapes; the shapes of
+   * data in each FeatureList given in feature_list_dense_keys.
+   * The shape of each Feature in the FeatureList corresponding to
+   * feature_list_dense_key[j] must always equal
+   * feature_list_dense_shapes[j].NumEntries().
+   */
+  public static Options featureListDenseShapes(List<Shape> featureListDenseShapes) {
+    return new Options().featureListDenseShapes(featureListDenseShapes);
+  }
+  
+  /**
+   */
+  public List<Output<Long>> contextSparseIndices() {
+    return contextSparseIndices;
+  }
+  
+  /**
+   */
+  public List<Output<?>> contextSparseValues() {
+    return contextSparseValues;
+  }
+  
+  /**
+   */
+  public List<Output<Long>> contextSparseShapes() {
+    return contextSparseShapes;
+  }
+  
+  /**
+   */
+  public List<Output<?>> contextDenseValues() {
+    return contextDenseValues;
+  }
+  
+  /**
+   */
+  public List<Output<Long>> featureListSparseIndices() {
+    return featureListSparseIndices;
+  }
+  
+  /**
+   */
+  public List<Output<?>> featureListSparseValues() {
+    return featureListSparseValues;
+  }
+  
+  /**
+   */
+  public List<Output<Long>> featureListSparseShapes() {
+    return featureListSparseShapes;
+  }
+  
+  /**
+   */
+  public List<Output<?>> featureListDenseValues() {
+    return featureListDenseValues;
+  }
+  
+  private List<Output<Long>> contextSparseIndices;
+  private List<Output<?>> contextSparseValues;
+  private List<Output<Long>> contextSparseShapes;
+  private List<Output<?>> contextDenseValues;
+  private List<Output<Long>> featureListSparseIndices;
+  private List<Output<?>> featureListSparseValues;
+  private List<Output<Long>> featureListSparseShapes;
+  private List<Output<?>> featureListDenseValues;
+  
+  @SuppressWarnings("unchecked")
+  private ParseSingleSequenceExample(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    int contextSparseIndicesLength = operation.outputListLength("context_sparse_indices");
+    contextSparseIndices = Arrays.asList((Output<Long>[])operation.outputList(outputIdx, contextSparseIndicesLength));
+    outputIdx += contextSparseIndicesLength;
+    int contextSparseValuesLength = operation.outputListLength("context_sparse_values");
+    contextSparseValues = Arrays.asList(operation.outputList(outputIdx, contextSparseValuesLength));
+    outputIdx += contextSparseValuesLength;
+    int contextSparseShapesLength = operation.outputListLength("context_sparse_shapes");
+    contextSparseShapes = Arrays.asList((Output<Long>[])operation.outputList(outputIdx, contextSparseShapesLength));
+    outputIdx += contextSparseShapesLength;
+    int contextDenseValuesLength = operation.outputListLength("context_dense_values");
+    contextDenseValues = Arrays.asList(operation.outputList(outputIdx, contextDenseValuesLength));
+    outputIdx += contextDenseValuesLength;
+    int featureListSparseIndicesLength = operation.outputListLength("feature_list_sparse_indices");
+    featureListSparseIndices = Arrays.asList((Output<Long>[])operation.outputList(outputIdx, featureListSparseIndicesLength));
+    outputIdx += featureListSparseIndicesLength;
+    int featureListSparseValuesLength = operation.outputListLength("feature_list_sparse_values");
+    featureListSparseValues = Arrays.asList(operation.outputList(outputIdx, featureListSparseValuesLength));
+    outputIdx += featureListSparseValuesLength;
+    int featureListSparseShapesLength = operation.outputListLength("feature_list_sparse_shapes");
+    featureListSparseShapes = Arrays.asList((Output<Long>[])operation.outputList(outputIdx, featureListSparseShapesLength));
+    outputIdx += featureListSparseShapesLength;
+    int featureListDenseValuesLength = operation.outputListLength("feature_list_dense_values");
+    featureListDenseValues = Arrays.asList(operation.outputList(outputIdx, featureListDenseValuesLength));
+    outputIdx += featureListDenseValuesLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/ParseTensor.java java-ops/org/tensorflow/op/core/ParseTensor.java
--- java/org/tensorflow/op/core/ParseTensor.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ParseTensor.java	2018-10-16 20:18:38.383432275 +0900
@@ -0,0 +1,72 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Transforms a serialized tensorflow.TensorProto proto into a Tensor.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class ParseTensor<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new ParseTensor operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param serialized A scalar string containing a serialized TensorProto proto.
+   * @param outType The type of the serialized tensor.  The provided type must match the
+   * type of the serialized tensor and no implicit conversion will take place.
+   * @return a new instance of ParseTensor
+   */
+  public static <T> ParseTensor<T> create(Scope scope, Operand<String> serialized, Class<T> outType) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ParseTensor", scope.makeOpName("ParseTensor"));
+    opBuilder.addInput(serialized.asOutput());
+    opBuilder.setAttr("out_type", DataType.fromClass(outType));
+    return new ParseTensor<T>(opBuilder.build());
+  }
+  
+  /**
+   * A Tensor of type `out_type`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private ParseTensor(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Placeholder.java java-ops/org/tensorflow/op/core/Placeholder.java
--- java/org/tensorflow/op/core/Placeholder.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Placeholder.java	2018-10-16 20:18:38.384432274 +0900
@@ -0,0 +1,110 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * A placeholder op for a value that will be fed into the computation.
+ * <p>
+ * N.B. This operation will fail with an error if it is executed. It is
+ * intended as a way to represent a value that will always be fed, and to
+ * provide attrs that enable the fed value to be checked at runtime.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class Placeholder<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Placeholder}
+   */
+  public static class Options {
+    
+    /**
+     * @param shape (Optional) The shape of the tensor. If the shape has 0 dimensions, the
+     * shape is unconstrained.
+     */
+    public Options shape(Shape shape) {
+      this.shape = shape;
+      return this;
+    }
+    
+    private Shape shape;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Placeholder operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param dtype The type of elements in the tensor.
+   * @param options carries optional attributes values
+   * @return a new instance of Placeholder
+   */
+  public static <T> Placeholder<T> create(Scope scope, Class<T> dtype, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Placeholder", scope.makeOpName("Placeholder"));
+    opBuilder.setAttr("dtype", DataType.fromClass(dtype));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.shape != null) {
+          opBuilder.setAttr("shape", opts.shape);
+        }
+      }
+    }
+    return new Placeholder<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param shape (Optional) The shape of the tensor. If the shape has 0 dimensions, the
+   * shape is unconstrained.
+   */
+  public static Options shape(Shape shape) {
+    return new Options().shape(shape);
+  }
+  
+  /**
+   * A placeholder tensor that must be replaced using the feed mechanism.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private Placeholder(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/PlaceholderV2.java java-ops/org/tensorflow/op/core/PlaceholderV2.java
--- java/org/tensorflow/op/core/PlaceholderV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/PlaceholderV2.java	2018-10-16 20:18:38.384432274 +0900
@@ -0,0 +1,77 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * A placeholder op for a value that will be fed into the computation.
+ * <p>
+ * N.B. This operation will fail with an error if it is executed. It is
+ * intended as a way to represent a value that will always be fed, and to
+ * provide attrs that enable the fed value to be checked at runtime.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class PlaceholderV2<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new PlaceholderV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param dtype The type of elements in the tensor.
+   * @param shape The shape of the tensor. The shape can be any partially-specified
+   * shape.  To be unconstrained, pass in a shape with unknown rank.
+   * @return a new instance of PlaceholderV2
+   */
+  public static <T> PlaceholderV2<T> create(Scope scope, Class<T> dtype, Shape shape) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("PlaceholderV2", scope.makeOpName("PlaceholderV2"));
+    opBuilder.setAttr("dtype", DataType.fromClass(dtype));
+    opBuilder.setAttr("shape", shape);
+    return new PlaceholderV2<T>(opBuilder.build());
+  }
+  
+  /**
+   * A placeholder tensor that must be replaced using the feed mechanism.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private PlaceholderV2(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/PlaceholderWithDefault.java java-ops/org/tensorflow/op/core/PlaceholderWithDefault.java
--- java/org/tensorflow/op/core/PlaceholderWithDefault.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/PlaceholderWithDefault.java	2018-10-16 20:18:38.384432274 +0900
@@ -0,0 +1,71 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * A placeholder op that passes through `input` when its output is not fed.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class PlaceholderWithDefault<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new PlaceholderWithDefault operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input The default value to produce when `output` is not fed.
+   * @param shape The (possibly partial) shape of the tensor.
+   * @return a new instance of PlaceholderWithDefault
+   */
+  public static <T> PlaceholderWithDefault<T> create(Scope scope, Operand<T> input, Shape shape) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("PlaceholderWithDefault", scope.makeOpName("PlaceholderWithDefault"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.setAttr("shape", shape);
+    return new PlaceholderWithDefault<T>(opBuilder.build());
+  }
+  
+  /**
+   * A placeholder tensor that defaults to `input` if it is not fed.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private PlaceholderWithDefault(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Polygamma.java java-ops/org/tensorflow/op/core/Polygamma.java
--- java/org/tensorflow/op/core/Polygamma.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Polygamma.java	2018-10-16 20:18:38.385432273 +0900
@@ -0,0 +1,75 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Compute the polygamma function \\(\psi^{(n)}(x)\\).
+ * <p>
+ * The polygamma function is defined as:
+ * <p>
+ * \\(\psi^{(n)}(x) = \frac{d^n}{dx^n} \psi(x)\\)
+ * <p>
+ * where \\(\psi(x)\\) is the digamma function.
+ * 
+ * @param <T> data type for {@code z()} output
+ */
+@Operator
+public final class Polygamma<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Polygamma operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param a 
+   * @param x 
+   * @return a new instance of Polygamma
+   */
+  public static <T extends Number> Polygamma<T> create(Scope scope, Operand<T> a, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Polygamma", scope.makeOpName("Polygamma"));
+    opBuilder.addInput(a.asOutput());
+    opBuilder.addInput(x.asOutput());
+    return new Polygamma<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return z;
+  }
+  
+  private Output<T> z;
+  
+  private Polygamma(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/PopulationCount.java java-ops/org/tensorflow/op/core/PopulationCount.java
--- java/org/tensorflow/op/core/PopulationCount.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/PopulationCount.java	2018-10-16 20:18:38.385432273 +0900
@@ -0,0 +1,73 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+import org.tensorflow.types.UInt8;
+
+/**
+ * Computes element-wise population count (a.k.a. popcount, bitsum, bitcount).
+ * <p>
+ * For each entry in `x`, calculates the number of `1` (on) bits in the binary
+ * representation of that entry.
+ * <p>
+ * <b>NOTE</b>: It is more efficient to first `tf.bitcast` your tensors into
+ * `int32` or `int64` and perform the bitcount on the result, than to feed in
+ * 8- or 16-bit inputs and then aggregate the resulting counts.
+ */
+@Operator
+public final class PopulationCount extends PrimitiveOp implements Operand<UInt8> {
+  
+  /**
+   * Factory method to create a class to wrap a new PopulationCount operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of PopulationCount
+   */
+  public static <T extends Number> PopulationCount create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("PopulationCount", scope.makeOpName("PopulationCount"));
+    opBuilder.addInput(x.asOutput());
+    return new PopulationCount(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<UInt8> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<UInt8> asOutput() {
+    return y;
+  }
+  
+  private Output<UInt8> y;
+  
+  private PopulationCount(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Pow.java java-ops/org/tensorflow/op/core/Pow.java
--- java/org/tensorflow/op/core/Pow.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Pow.java	2018-10-16 20:18:38.385432273 +0900
@@ -0,0 +1,78 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the power of one value to another.
+ * <p>
+ * Given a tensor `x` and a tensor `y`, this operation computes \\(x^y\\) for
+ * corresponding elements in `x` and `y`. For example:
+ * <pre>{@code
+ * # tensor 'x' is [[2, 2]], [3, 3]]
+ * # tensor 'y' is [[8, 16], [2, 3]]
+ * tf.pow(x, y) ==> [[256, 65536], [9, 27]]
+ * }</pre>
+ * 
+ * 
+ * @param <T> data type for {@code z()} output
+ */
+@Operator
+public final class Pow<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Pow operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param y 
+   * @return a new instance of Pow
+   */
+  public static <T> Pow<T> create(Scope scope, Operand<T> x, Operand<T> y) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Pow", scope.makeOpName("Pow"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(y.asOutput());
+    return new Pow<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return z;
+  }
+  
+  private Output<T> z;
+  
+  private Pow(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/PrefetchDataset.java java-ops/org/tensorflow/op/core/PrefetchDataset.java
--- java/org/tensorflow/op/core/PrefetchDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/PrefetchDataset.java	2018-10-16 20:18:38.386432273 +0900
@@ -0,0 +1,84 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Creates a dataset that asynchronously prefetches elements from `input_dataset`.
+ */
+@Operator
+public final class PrefetchDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new PrefetchDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputDataset 
+   * @param bufferSize The maximum number of elements to buffer in an iterator over
+   * this dataset.
+   * @param outputTypes 
+   * @param outputShapes 
+   * @return a new instance of PrefetchDataset
+   */
+  public static PrefetchDataset create(Scope scope, Operand<?> inputDataset, Operand<Long> bufferSize, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("PrefetchDataset", scope.makeOpName("PrefetchDataset"));
+    opBuilder.addInput(inputDataset.asOutput());
+    opBuilder.addInput(bufferSize.asOutput());
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new PrefetchDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private PrefetchDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/PrependFromQueueAndPaddedBatchDataset.java java-ops/org/tensorflow/op/core/PrependFromQueueAndPaddedBatchDataset.java
--- java/org/tensorflow/op/core/PrependFromQueueAndPaddedBatchDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/PrependFromQueueAndPaddedBatchDataset.java	2018-10-16 20:18:38.386432273 +0900
@@ -0,0 +1,80 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ */
+@Operator
+public final class PrependFromQueueAndPaddedBatchDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new PrependFromQueueAndPaddedBatchDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputDataset 
+   * @param batchSize 
+   * @param paddedShapes 
+   * @param paddingValues 
+   * @param outputShapes 
+   * @return a new instance of PrependFromQueueAndPaddedBatchDataset
+   */
+  public static PrependFromQueueAndPaddedBatchDataset create(Scope scope, Operand<?> inputDataset, Operand<Long> batchSize, Iterable<Operand<Long>> paddedShapes, Iterable<Operand<?>> paddingValues, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("PrependFromQueueAndPaddedBatchDataset", scope.makeOpName("PrependFromQueueAndPaddedBatchDataset"));
+    opBuilder.addInput(inputDataset.asOutput());
+    opBuilder.addInput(batchSize.asOutput());
+    opBuilder.addInputList(Operands.asOutputs(paddedShapes));
+    opBuilder.addInputList(Operands.asOutputs(paddingValues));
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new PrependFromQueueAndPaddedBatchDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private PrependFromQueueAndPaddedBatchDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/PreventGradient.java java-ops/org/tensorflow/op/core/PreventGradient.java
--- java/org/tensorflow/op/core/PreventGradient.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/PreventGradient.java	2018-10-16 20:18:38.386432273 +0900
@@ -0,0 +1,112 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * An identity op that triggers an error if a gradient is requested.
+ * <p>
+ * When executed in a graph, this op outputs its input tensor as-is.
+ * <p>
+ * When building ops to compute gradients, the TensorFlow gradient system
+ * will return an error when trying to lookup the gradient of this op,
+ * because no gradient must ever be registered for this function.  This
+ * op exists to prevent subtle bugs from silently returning unimplemented
+ * gradients in some corner cases.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class PreventGradient<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.PreventGradient}
+   */
+  public static class Options {
+    
+    /**
+     * @param message Will be printed in the error when anyone tries to differentiate
+     * this operation.
+     */
+    public Options message(String message) {
+      this.message = message;
+      return this;
+    }
+    
+    private String message;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new PreventGradient operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input any tensor.
+   * @param options carries optional attributes values
+   * @return a new instance of PreventGradient
+   */
+  public static <T> PreventGradient<T> create(Scope scope, Operand<T> input, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("PreventGradient", scope.makeOpName("PreventGradient"));
+    opBuilder.addInput(input.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.message != null) {
+          opBuilder.setAttr("message", opts.message);
+        }
+      }
+    }
+    return new PreventGradient<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param message Will be printed in the error when anyone tries to differentiate
+   * this operation.
+   */
+  public static Options message(String message) {
+    return new Options().message(message);
+  }
+  
+  /**
+   * the same input tensor.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private PreventGradient(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Print.java java-ops/org/tensorflow/op/core/Print.java
--- java/org/tensorflow/op/core/Print.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Print.java	2018-10-16 20:18:38.387432272 +0900
@@ -0,0 +1,145 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Prints a list of tensors.
+ * <p>
+ * Passes `input` through to `output` and prints `data` when evaluating.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class Print<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Print}
+   */
+  public static class Options {
+    
+    /**
+     * @param message A string, prefix of the error message.
+     */
+    public Options message(String message) {
+      this.message = message;
+      return this;
+    }
+    
+    /**
+     * @param firstN Only log `first_n` number of times. -1 disables logging.
+     */
+    public Options firstN(Long firstN) {
+      this.firstN = firstN;
+      return this;
+    }
+    
+    /**
+     * @param summarize Only print this many entries of each tensor.
+     */
+    public Options summarize(Long summarize) {
+      this.summarize = summarize;
+      return this;
+    }
+    
+    private String message;
+    private Long firstN;
+    private Long summarize;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Print operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input The tensor passed to `output`
+   * @param data A list of tensors to print out when op is evaluated.
+   * @param options carries optional attributes values
+   * @return a new instance of Print
+   */
+  public static <T> Print<T> create(Scope scope, Operand<T> input, Iterable<Operand<?>> data, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Print", scope.makeOpName("Print"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInputList(Operands.asOutputs(data));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.message != null) {
+          opBuilder.setAttr("message", opts.message);
+        }
+        if (opts.firstN != null) {
+          opBuilder.setAttr("first_n", opts.firstN);
+        }
+        if (opts.summarize != null) {
+          opBuilder.setAttr("summarize", opts.summarize);
+        }
+      }
+    }
+    return new Print<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param message A string, prefix of the error message.
+   */
+  public static Options message(String message) {
+    return new Options().message(message);
+  }
+  
+  /**
+   * @param firstN Only log `first_n` number of times. -1 disables logging.
+   */
+  public static Options firstN(Long firstN) {
+    return new Options().firstN(firstN);
+  }
+  
+  /**
+   * @param summarize Only print this many entries of each tensor.
+   */
+  public static Options summarize(Long summarize) {
+    return new Options().summarize(summarize);
+  }
+  
+  /**
+   * = The unmodified `input` tensor
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private Print(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/PrintV2.java java-ops/org/tensorflow/op/core/PrintV2.java
--- java/org/tensorflow/op/core/PrintV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/PrintV2.java	2018-10-16 20:18:38.387432272 +0900
@@ -0,0 +1,86 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Prints a string scalar.
+ * <p>
+ * Prints a string scalar to the desired output_stream.
+ */
+@Operator
+public final class PrintV2 extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.PrintV2}
+   */
+  public static class Options {
+    
+    /**
+     * @param outputStream A string specifying the output stream or logging level to print to.
+     */
+    public Options outputStream(String outputStream) {
+      this.outputStream = outputStream;
+      return this;
+    }
+    
+    private String outputStream;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new PrintV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input The string scalar to print.
+   * @param options carries optional attributes values
+   * @return a new instance of PrintV2
+   */
+  public static PrintV2 create(Scope scope, Operand<String> input, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("PrintV2", scope.makeOpName("PrintV2"));
+    opBuilder.addInput(input.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.outputStream != null) {
+          opBuilder.setAttr("output_stream", opts.outputStream);
+        }
+      }
+    }
+    return new PrintV2(opBuilder.build());
+  }
+  
+  /**
+   * @param outputStream A string specifying the output stream or logging level to print to.
+   */
+  public static Options outputStream(String outputStream) {
+    return new Options().outputStream(outputStream);
+  }
+  
+  
+  private PrintV2(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/PriorityQueue.java java-ops/org/tensorflow/op/core/PriorityQueue.java
--- java/org/tensorflow/op/core/PriorityQueue.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/PriorityQueue.java	2018-10-16 20:18:38.387432272 +0900
@@ -0,0 +1,167 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * A queue that produces elements sorted by the first component value.
+ * <p>
+ * Note that the PriorityQueue requires the first component of any element
+ * to be a scalar int64, in addition to the other elements declared by
+ * component_types.  Therefore calls to Enqueue and EnqueueMany (resp. Dequeue
+ * and DequeueMany) on a PriorityQueue will all require (resp. output) one extra
+ * entry in their input (resp. output) lists.
+ */
+@Operator
+public final class PriorityQueue extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.PriorityQueue}
+   */
+  public static class Options {
+    
+    /**
+     * @param capacity The upper bound on the number of elements in this queue.
+     * Negative numbers mean no limit.
+     */
+    public Options capacity(Long capacity) {
+      this.capacity = capacity;
+      return this;
+    }
+    
+    /**
+     * @param container If non-empty, this queue is placed in the given container.
+     * Otherwise, a default container is used.
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName If non-empty, this queue will be shared under the given name
+     * across multiple sessions.
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private Long capacity;
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new PriorityQueue operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param componentTypes The type of each component in a value.
+   * @param shapes The shape of each component in a value. The length of this attr must
+   * be either 0 or the same as the length of component_types. If the length of
+   * this attr is 0, the shapes of queue elements are not constrained, and
+   * only one element may be dequeued at a time.
+   * @param options carries optional attributes values
+   * @return a new instance of PriorityQueue
+   */
+  public static PriorityQueue create(Scope scope, List<Class<?>> componentTypes, List<Shape> shapes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("PriorityQueueV2", scope.makeOpName("PriorityQueue"));
+    DataType[] componentTypesArray = new DataType[componentTypes.size()];
+    for (int i = 0; i < componentTypesArray.length; ++i) {
+      componentTypesArray[i] = DataType.fromClass(componentTypes.get(i));
+    }
+    opBuilder.setAttr("component_types", componentTypesArray);
+    Shape[] shapesArray = new Shape[shapes.size()];
+    for (int i = 0; i < shapesArray.length; ++i) {
+      shapesArray[i] = shapes.get(i);
+    }
+    opBuilder.setAttr("shapes", shapesArray);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.capacity != null) {
+          opBuilder.setAttr("capacity", opts.capacity);
+        }
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new PriorityQueue(opBuilder.build());
+  }
+  
+  /**
+   * @param capacity The upper bound on the number of elements in this queue.
+   * Negative numbers mean no limit.
+   */
+  public static Options capacity(Long capacity) {
+    return new Options().capacity(capacity);
+  }
+  
+  /**
+   * @param container If non-empty, this queue is placed in the given container.
+   * Otherwise, a default container is used.
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName If non-empty, this queue will be shared under the given name
+   * across multiple sessions.
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   * The handle to the queue.
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private PriorityQueue(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Prod.java java-ops/org/tensorflow/op/core/Prod.java
--- java/org/tensorflow/op/core/Prod.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Prod.java	2018-10-16 20:18:38.388432271 +0900
@@ -0,0 +1,110 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the product of elements across dimensions of a tensor.
+ * <p>
+ * Reduces `input` along the dimensions given in `axis`. Unless
+ * `keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
+ * `axis`. If `keep_dims` is true, the reduced dimensions are
+ * retained with length 1.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class Prod<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Prod}
+   */
+  public static class Options {
+    
+    /**
+     * @param keepDims If true, retain reduced dimensions with length 1.
+     */
+    public Options keepDims(Boolean keepDims) {
+      this.keepDims = keepDims;
+      return this;
+    }
+    
+    private Boolean keepDims;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Prod operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input The tensor to reduce.
+   * @param axis The dimensions to reduce. Must be in the range
+   * `[-rank(input), rank(input))`.
+   * @param options carries optional attributes values
+   * @return a new instance of Prod
+   */
+  public static <T, U extends Number> Prod<T> create(Scope scope, Operand<T> input, Operand<U> axis, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Prod", scope.makeOpName("Prod"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(axis.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.keepDims != null) {
+          opBuilder.setAttr("keep_dims", opts.keepDims);
+        }
+      }
+    }
+    return new Prod<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param keepDims If true, retain reduced dimensions with length 1.
+   */
+  public static Options keepDims(Boolean keepDims) {
+    return new Options().keepDims(keepDims);
+  }
+  
+  /**
+   * The reduced tensor.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private Prod(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Qr.java java-ops/org/tensorflow/op/core/Qr.java
--- java/org/tensorflow/op/core/Qr.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Qr.java	2018-10-16 20:18:38.389432271 +0900
@@ -0,0 +1,123 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the QR decompositions of one or more matrices.
+ * <p>
+ * Computes the QR decomposition of each inner matrix in `tensor` such that
+ * `tensor[..., :, :] = q[..., :, :] * r[..., :,:])`
+ * <pre>{@code
+ * # a is a tensor.
+ * # q is a tensor of orthonormal matrices.
+ * # r is a tensor of upper triangular matrices.
+ * q, r = qr(a)
+ * q_full, r_full = qr(a, full_matrices=True)
+ * }</pre>
+ * 
+ * 
+ * @param <T> data type for {@code q()} output
+ */
+@Operator
+public final class Qr<T> extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Qr}
+   */
+  public static class Options {
+    
+    /**
+     * @param fullMatrices If true, compute full-sized `q` and `r`. If false
+     * (the default), compute only the leading `P` columns of `q`.
+     */
+    public Options fullMatrices(Boolean fullMatrices) {
+      this.fullMatrices = fullMatrices;
+      return this;
+    }
+    
+    private Boolean fullMatrices;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Qr operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input A tensor of shape `[..., M, N]` whose inner-most 2 dimensions
+   * form matrices of size `[M, N]`. Let `P` be the minimum of `M` and `N`.
+   * @param options carries optional attributes values
+   * @return a new instance of Qr
+   */
+  public static <T> Qr<T> create(Scope scope, Operand<T> input, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Qr", scope.makeOpName("Qr"));
+    opBuilder.addInput(input.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.fullMatrices != null) {
+          opBuilder.setAttr("full_matrices", opts.fullMatrices);
+        }
+      }
+    }
+    return new Qr<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param fullMatrices If true, compute full-sized `q` and `r`. If false
+   * (the default), compute only the leading `P` columns of `q`.
+   */
+  public static Options fullMatrices(Boolean fullMatrices) {
+    return new Options().fullMatrices(fullMatrices);
+  }
+  
+  /**
+   * Orthonormal basis for range of `a`. If `full_matrices` is `False` then
+   * shape is `[..., M, P]`; if `full_matrices` is `True` then shape is
+   * `[..., M, M]`.
+   */
+  public Output<T> q() {
+    return q;
+  }
+  
+  /**
+   * Triangular factor. If `full_matrices` is `False` then shape is
+   * `[..., P, N]`. If `full_matrices` is `True` then shape is `[..., M, N]`.
+   */
+  public Output<T> r() {
+    return r;
+  }
+  
+  private Output<T> q;
+  private Output<T> r;
+  
+  private Qr(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    q = operation.output(outputIdx++);
+    r = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/QuantizeAndDequantize.java java-ops/org/tensorflow/op/core/QuantizeAndDequantize.java
--- java/org/tensorflow/op/core/QuantizeAndDequantize.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/QuantizeAndDequantize.java	2018-10-16 20:18:38.389432271 +0900
@@ -0,0 +1,177 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Use QuantizeAndDequantizeV2 instead.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class QuantizeAndDequantize<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.QuantizeAndDequantize}
+   */
+  public static class Options {
+    
+    /**
+     * @param signedInput 
+     */
+    public Options signedInput(Boolean signedInput) {
+      this.signedInput = signedInput;
+      return this;
+    }
+    
+    /**
+     * @param numBits 
+     */
+    public Options numBits(Long numBits) {
+      this.numBits = numBits;
+      return this;
+    }
+    
+    /**
+     * @param rangeGiven 
+     */
+    public Options rangeGiven(Boolean rangeGiven) {
+      this.rangeGiven = rangeGiven;
+      return this;
+    }
+    
+    /**
+     * @param inputMin 
+     */
+    public Options inputMin(Float inputMin) {
+      this.inputMin = inputMin;
+      return this;
+    }
+    
+    /**
+     * @param inputMax 
+     */
+    public Options inputMax(Float inputMax) {
+      this.inputMax = inputMax;
+      return this;
+    }
+    
+    private Boolean signedInput;
+    private Long numBits;
+    private Boolean rangeGiven;
+    private Float inputMin;
+    private Float inputMax;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new QuantizeAndDequantize operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param options carries optional attributes values
+   * @return a new instance of QuantizeAndDequantize
+   */
+  public static <T extends Number> QuantizeAndDequantize<T> create(Scope scope, Operand<T> input, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("QuantizeAndDequantize", scope.makeOpName("QuantizeAndDequantize"));
+    opBuilder.addInput(input.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.signedInput != null) {
+          opBuilder.setAttr("signed_input", opts.signedInput);
+        }
+        if (opts.numBits != null) {
+          opBuilder.setAttr("num_bits", opts.numBits);
+        }
+        if (opts.rangeGiven != null) {
+          opBuilder.setAttr("range_given", opts.rangeGiven);
+        }
+        if (opts.inputMin != null) {
+          opBuilder.setAttr("input_min", opts.inputMin);
+        }
+        if (opts.inputMax != null) {
+          opBuilder.setAttr("input_max", opts.inputMax);
+        }
+      }
+    }
+    return new QuantizeAndDequantize<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param signedInput 
+   */
+  public static Options signedInput(Boolean signedInput) {
+    return new Options().signedInput(signedInput);
+  }
+  
+  /**
+   * @param numBits 
+   */
+  public static Options numBits(Long numBits) {
+    return new Options().numBits(numBits);
+  }
+  
+  /**
+   * @param rangeGiven 
+   */
+  public static Options rangeGiven(Boolean rangeGiven) {
+    return new Options().rangeGiven(rangeGiven);
+  }
+  
+  /**
+   * @param inputMin 
+   */
+  public static Options inputMin(Float inputMin) {
+    return new Options().inputMin(inputMin);
+  }
+  
+  /**
+   * @param inputMax 
+   */
+  public static Options inputMax(Float inputMax) {
+    return new Options().inputMax(inputMax);
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private QuantizeAndDequantize(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/QuantizeAndDequantizeV2.java java-ops/org/tensorflow/op/core/QuantizeAndDequantizeV2.java
--- java/org/tensorflow/op/core/QuantizeAndDequantizeV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/QuantizeAndDequantizeV2.java	2018-10-16 20:18:38.390432270 +0900
@@ -0,0 +1,210 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Quantizes then dequantizes a tensor.
+ * <p>
+ * This op simulates the precision loss from the quantized forward pass by:
+ * <p>
+ * 1. Quantizing the tensor to fixed point numbers, which should match the target
+ *    quantization method when it is used in inference.
+ * 2. Dequantizing it back to floating point numbers for the following ops, most
+ *    likely matmul.
+ * <p>
+ * There are different ways to quantize. This version uses only scaling, so 0.0
+ * maps to 0.
+ * <p>
+ * From the specified 'num_bits' in the quantized output type, it determines
+ * minimum and maximum representable quantized values.
+ * <p>
+ * e.g.
+ * <ul>
+ * <li>
+ * [-128, 127] for signed, num_bits = 8, or
+ * </li>
+ * <li>
+ * [0, 255] for unsigned, num_bits = 8.
+ * </li>
+ * </ul>
+ * If range_given == False, the initial input_min, input_max will be determined
+ * automatically as the minimum and maximum values in the input tensor, otherwise
+ * the specified values of input_min, input_max are used.
+ * <p>
+ * Note: If the input_min, input_max are specified, they do not need to equal the
+ * actual minimum and maximum values in the tensor. e.g. in some cases it may be
+ * beneficial to specify these values such that the low probability extremes of the
+ * input distribution are clipped.
+ * <p>
+ * This op determines the maximum scale_factor that would map the initial
+ * [input_min, input_max] range to a range that lies within the representable
+ * quantized range.
+ * <p>
+ * It determines the scale from one of input_min and input_max, then updates the
+ * other one to maximize the respresentable range.
+ * <p>
+ * e.g.
+ * <ul>
+ * <li>
+ * if the output is signed, num_bits = 8, [input_min, input_max] = [-10.0,
+ *     5.0]: it would use a scale_factor of -128 / -10.0 = 12.8 In this case, it
+ *     would update input_max to be 127 / 12.8 = 9.921875
+ * </li>
+ * <li>
+ * if the output is signed, num_bits = 8, [input_min, input_max] = [-10.0,
+ *     10.0]: it would use a scale_factor of 127 / 10.0 = 12.7 In this case, it
+ *     would update input_min to be 128.0 / 12.7 = -10.07874
+ * </li>
+ * <li>
+ * if the output is unsigned, input_min is forced to be 0, and only the
+ *     specified input_max is used.
+ * </li>
+ * </ul>
+ * After determining the scale_factor and updating the input range, it applies the
+ * following to each value in the 'input' tensor.
+ * <p>
+ * output = round(clamp(value, input_min, input_max) * scale_factor) / scale_factor.
+ * 
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class QuantizeAndDequantizeV2<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.QuantizeAndDequantizeV2}
+   */
+  public static class Options {
+    
+    /**
+     * @param signedInput Whether the quantization is signed or unsigned. (actually this parameter should
+     * have been called <b>`signed_output`</b>)
+     */
+    public Options signedInput(Boolean signedInput) {
+      this.signedInput = signedInput;
+      return this;
+    }
+    
+    /**
+     * @param numBits The bitwidth of the quantization.
+     */
+    public Options numBits(Long numBits) {
+      this.numBits = numBits;
+      return this;
+    }
+    
+    /**
+     * @param rangeGiven Whether the range is given or should be determined from the `input` tensor.
+     */
+    public Options rangeGiven(Boolean rangeGiven) {
+      this.rangeGiven = rangeGiven;
+      return this;
+    }
+    
+    private Boolean signedInput;
+    private Long numBits;
+    private Boolean rangeGiven;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new QuantizeAndDequantizeV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input Tensor to quantize and then dequantize.
+   * @param inputMin If `range_given == True`, this specifies the minimum input value that needs to
+   * be represented, otherwise it is determined from the min value of the `input`
+   * tensor.
+   * @param inputMax If `range_given == True`, this specifies the maximum input value that needs to
+   * be represented, otherwise it is determined from the max value of the `input`
+   * tensor.
+   * @param options carries optional attributes values
+   * @return a new instance of QuantizeAndDequantizeV2
+   */
+  public static <T extends Number> QuantizeAndDequantizeV2<T> create(Scope scope, Operand<T> input, Operand<T> inputMin, Operand<T> inputMax, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("QuantizeAndDequantizeV2", scope.makeOpName("QuantizeAndDequantizeV2"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(inputMin.asOutput());
+    opBuilder.addInput(inputMax.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.signedInput != null) {
+          opBuilder.setAttr("signed_input", opts.signedInput);
+        }
+        if (opts.numBits != null) {
+          opBuilder.setAttr("num_bits", opts.numBits);
+        }
+        if (opts.rangeGiven != null) {
+          opBuilder.setAttr("range_given", opts.rangeGiven);
+        }
+      }
+    }
+    return new QuantizeAndDequantizeV2<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param signedInput Whether the quantization is signed or unsigned. (actually this parameter should
+   * have been called <b>`signed_output`</b>)
+   */
+  public static Options signedInput(Boolean signedInput) {
+    return new Options().signedInput(signedInput);
+  }
+  
+  /**
+   * @param numBits The bitwidth of the quantization.
+   */
+  public static Options numBits(Long numBits) {
+    return new Options().numBits(numBits);
+  }
+  
+  /**
+   * @param rangeGiven Whether the range is given or should be determined from the `input` tensor.
+   */
+  public static Options rangeGiven(Boolean rangeGiven) {
+    return new Options().rangeGiven(rangeGiven);
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private QuantizeAndDequantizeV2(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/QuantizeAndDequantizeV3.java java-ops/org/tensorflow/op/core/QuantizeAndDequantizeV3.java
--- java/org/tensorflow/op/core/QuantizeAndDequantizeV3.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/QuantizeAndDequantizeV3.java	2018-10-16 20:18:38.390432270 +0900
@@ -0,0 +1,129 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Quantizes then dequantizes a tensor.
+ * <p>
+ * This is almost identical to QuantizeAndDequantizeV2, except that num_bits is a
+ * tensor, so its value can change during training.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class QuantizeAndDequantizeV3<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.QuantizeAndDequantizeV3}
+   */
+  public static class Options {
+    
+    /**
+     * @param signedInput 
+     */
+    public Options signedInput(Boolean signedInput) {
+      this.signedInput = signedInput;
+      return this;
+    }
+    
+    /**
+     * @param rangeGiven 
+     */
+    public Options rangeGiven(Boolean rangeGiven) {
+      this.rangeGiven = rangeGiven;
+      return this;
+    }
+    
+    private Boolean signedInput;
+    private Boolean rangeGiven;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new QuantizeAndDequantizeV3 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param inputMin 
+   * @param inputMax 
+   * @param numBits 
+   * @param options carries optional attributes values
+   * @return a new instance of QuantizeAndDequantizeV3
+   */
+  public static <T extends Number> QuantizeAndDequantizeV3<T> create(Scope scope, Operand<T> input, Operand<T> inputMin, Operand<T> inputMax, Operand<Integer> numBits, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("QuantizeAndDequantizeV3", scope.makeOpName("QuantizeAndDequantizeV3"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(inputMin.asOutput());
+    opBuilder.addInput(inputMax.asOutput());
+    opBuilder.addInput(numBits.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.signedInput != null) {
+          opBuilder.setAttr("signed_input", opts.signedInput);
+        }
+        if (opts.rangeGiven != null) {
+          opBuilder.setAttr("range_given", opts.rangeGiven);
+        }
+      }
+    }
+    return new QuantizeAndDequantizeV3<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param signedInput 
+   */
+  public static Options signedInput(Boolean signedInput) {
+    return new Options().signedInput(signedInput);
+  }
+  
+  /**
+   * @param rangeGiven 
+   */
+  public static Options rangeGiven(Boolean rangeGiven) {
+    return new Options().rangeGiven(rangeGiven);
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private QuantizeAndDequantizeV3(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/QuantizedAdd.java java-ops/org/tensorflow/op/core/QuantizedAdd.java
--- java/org/tensorflow/op/core/QuantizedAdd.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/QuantizedAdd.java	2018-10-16 20:18:38.393432268 +0900
@@ -0,0 +1,96 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns x + y element-wise, working on quantized buffers.
+ * 
+ * @param <V> data type for {@code z()} output
+ */
+@Operator
+public final class QuantizedAdd<V> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new QuantizedAdd operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param y 
+   * @param minX The float value that the lowest quantized `x` value represents.
+   * @param maxX The float value that the highest quantized `x` value represents.
+   * @param minY The float value that the lowest quantized `y` value represents.
+   * @param maxY The float value that the highest quantized `y` value represents.
+   * @param Toutput 
+   * @return a new instance of QuantizedAdd
+   */
+  public static <V, T, U> QuantizedAdd<V> create(Scope scope, Operand<T> x, Operand<U> y, Operand<Float> minX, Operand<Float> maxX, Operand<Float> minY, Operand<Float> maxY, Class<V> Toutput) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("QuantizedAdd", scope.makeOpName("QuantizedAdd"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(y.asOutput());
+    opBuilder.addInput(minX.asOutput());
+    opBuilder.addInput(maxX.asOutput());
+    opBuilder.addInput(minY.asOutput());
+    opBuilder.addInput(maxY.asOutput());
+    opBuilder.setAttr("Toutput", DataType.fromClass(Toutput));
+    return new QuantizedAdd<V>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<V> z() {
+    return z;
+  }
+  
+  /**
+   * The float value that the lowest quantized output value represents.
+   */
+  public Output<Float> minZ() {
+    return minZ;
+  }
+  
+  /**
+   * The float value that the highest quantized output value represents.
+   * <p>
+   * <i>NOTE</i>: `QuantizedAdd` supports limited forms of broadcasting. More about
+   * broadcasting [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
+   */
+  public Output<Float> maxZ() {
+    return maxZ;
+  }
+  
+  private Output<V> z;
+  private Output<Float> minZ;
+  private Output<Float> maxZ;
+  
+  private QuantizedAdd(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+    minZ = operation.output(outputIdx++);
+    maxZ = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/QuantizedAvgPool.java java-ops/org/tensorflow/op/core/QuantizedAvgPool.java
--- java/org/tensorflow/op/core/QuantizedAvgPool.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/QuantizedAvgPool.java	2018-10-16 20:18:38.393432268 +0900
@@ -0,0 +1,101 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Produces the average pool of the input tensor for quantized types.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class QuantizedAvgPool<T> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new QuantizedAvgPool operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 4-D with shape `[batch, height, width, channels]`.
+   * @param minInput The float value that the lowest quantized input value represents.
+   * @param maxInput The float value that the highest quantized input value represents.
+   * @param ksize The size of the window for each dimension of the input tensor.
+   * The length must be 4 to match the number of dimensions of the input.
+   * @param strides The stride of the sliding window for each dimension of the input
+   * tensor.  The length must be 4 to match the number of dimensions of the input.
+   * @param padding The type of padding algorithm to use.
+   * @return a new instance of QuantizedAvgPool
+   */
+  public static <T> QuantizedAvgPool<T> create(Scope scope, Operand<T> input, Operand<Float> minInput, Operand<Float> maxInput, List<Long> ksize, List<Long> strides, String padding) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("QuantizedAvgPool", scope.makeOpName("QuantizedAvgPool"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(minInput.asOutput());
+    opBuilder.addInput(maxInput.asOutput());
+    long[] ksizeArray = new long[ksize.size()];
+    for (int i = 0; i < ksizeArray.length; ++i) {
+      ksizeArray[i] = ksize.get(i);
+    }
+    opBuilder.setAttr("ksize", ksizeArray);
+    long[] stridesArray = new long[strides.size()];
+    for (int i = 0; i < stridesArray.length; ++i) {
+      stridesArray[i] = strides.get(i);
+    }
+    opBuilder.setAttr("strides", stridesArray);
+    opBuilder.setAttr("padding", padding);
+    return new QuantizedAvgPool<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  /**
+   * The float value that the lowest quantized output value represents.
+   */
+  public Output<Float> minOutput() {
+    return minOutput;
+  }
+  
+  /**
+   * The float value that the highest quantized output value represents.
+   */
+  public Output<Float> maxOutput() {
+    return maxOutput;
+  }
+  
+  private Output<T> output;
+  private Output<Float> minOutput;
+  private Output<Float> maxOutput;
+  
+  private QuantizedAvgPool(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+    minOutput = operation.output(outputIdx++);
+    maxOutput = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/QuantizedBatchNormWithGlobalNormalization.java java-ops/org/tensorflow/op/core/QuantizedBatchNormWithGlobalNormalization.java
--- java/org/tensorflow/op/core/QuantizedBatchNormWithGlobalNormalization.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/QuantizedBatchNormWithGlobalNormalization.java	2018-10-16 20:18:38.394432267 +0900
@@ -0,0 +1,124 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Quantized Batch normalization.
+ * <p>
+ * This op is deprecated and will be removed in the future. Prefer
+ * `tf.nn.batch_normalization`.
+ * 
+ * @param <U> data type for {@code result()} output
+ */
+@Operator
+public final class QuantizedBatchNormWithGlobalNormalization<U> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new QuantizedBatchNormWithGlobalNormalization operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param t A 4D input Tensor.
+   * @param tMin The value represented by the lowest quantized input.
+   * @param tMax The value represented by the highest quantized input.
+   * @param m A 1D mean Tensor with size matching the last dimension of t.
+   * This is the first output from tf.nn.moments,
+   * or a saved moving average thereof.
+   * @param mMin The value represented by the lowest quantized mean.
+   * @param mMax The value represented by the highest quantized mean.
+   * @param v A 1D variance Tensor with size matching the last dimension of t.
+   * This is the second output from tf.nn.moments,
+   * or a saved moving average thereof.
+   * @param vMin The value represented by the lowest quantized variance.
+   * @param vMax The value represented by the highest quantized variance.
+   * @param beta A 1D beta Tensor with size matching the last dimension of t.
+   * An offset to be added to the normalized tensor.
+   * @param betaMin The value represented by the lowest quantized offset.
+   * @param betaMax The value represented by the highest quantized offset.
+   * @param gamma A 1D gamma Tensor with size matching the last dimension of t.
+   * If "scale_after_normalization" is true, this tensor will be multiplied
+   * with the normalized tensor.
+   * @param gammaMin The value represented by the lowest quantized gamma.
+   * @param gammaMax The value represented by the highest quantized gamma.
+   * @param outType 
+   * @param varianceEpsilon A small float number to avoid dividing by 0.
+   * @param scaleAfterNormalization A bool indicating whether the resulted tensor
+   * needs to be multiplied with gamma.
+   * @return a new instance of QuantizedBatchNormWithGlobalNormalization
+   */
+  public static <U, T> QuantizedBatchNormWithGlobalNormalization<U> create(Scope scope, Operand<T> t, Operand<Float> tMin, Operand<Float> tMax, Operand<T> m, Operand<Float> mMin, Operand<Float> mMax, Operand<T> v, Operand<Float> vMin, Operand<Float> vMax, Operand<T> beta, Operand<Float> betaMin, Operand<Float> betaMax, Operand<T> gamma, Operand<Float> gammaMin, Operand<Float> gammaMax, Class<U> outType, Float varianceEpsilon, Boolean scaleAfterNormalization) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("QuantizedBatchNormWithGlobalNormalization", scope.makeOpName("QuantizedBatchNormWithGlobalNormalization"));
+    opBuilder.addInput(t.asOutput());
+    opBuilder.addInput(tMin.asOutput());
+    opBuilder.addInput(tMax.asOutput());
+    opBuilder.addInput(m.asOutput());
+    opBuilder.addInput(mMin.asOutput());
+    opBuilder.addInput(mMax.asOutput());
+    opBuilder.addInput(v.asOutput());
+    opBuilder.addInput(vMin.asOutput());
+    opBuilder.addInput(vMax.asOutput());
+    opBuilder.addInput(beta.asOutput());
+    opBuilder.addInput(betaMin.asOutput());
+    opBuilder.addInput(betaMax.asOutput());
+    opBuilder.addInput(gamma.asOutput());
+    opBuilder.addInput(gammaMin.asOutput());
+    opBuilder.addInput(gammaMax.asOutput());
+    opBuilder.setAttr("out_type", DataType.fromClass(outType));
+    opBuilder.setAttr("variance_epsilon", varianceEpsilon);
+    opBuilder.setAttr("scale_after_normalization", scaleAfterNormalization);
+    return new QuantizedBatchNormWithGlobalNormalization<U>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<U> result() {
+    return result;
+  }
+  
+  /**
+   */
+  public Output<Float> resultMin() {
+    return resultMin;
+  }
+  
+  /**
+   */
+  public Output<Float> resultMax() {
+    return resultMax;
+  }
+  
+  private Output<U> result;
+  private Output<Float> resultMin;
+  private Output<Float> resultMax;
+  
+  private QuantizedBatchNormWithGlobalNormalization(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    result = operation.output(outputIdx++);
+    resultMin = operation.output(outputIdx++);
+    resultMax = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/QuantizedBiasAdd.java java-ops/org/tensorflow/op/core/QuantizedBiasAdd.java
--- java/org/tensorflow/op/core/QuantizedBiasAdd.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/QuantizedBiasAdd.java	2018-10-16 20:18:38.395432267 +0900
@@ -0,0 +1,95 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Adds Tensor 'bias' to Tensor 'input' for Quantized types.
+ * <p>
+ * Broadcasts the values of bias on dimensions 0..N-2 of 'input'.
+ * 
+ * @param <V> data type for {@code output()} output
+ */
+@Operator
+public final class QuantizedBiasAdd<V> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new QuantizedBiasAdd operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param bias A 1D bias Tensor with size matching the last dimension of 'input'.
+   * @param minInput The float value that the lowest quantized input value represents.
+   * @param maxInput The float value that the highest quantized input value represents.
+   * @param minBias The float value that the lowest quantized bias value represents.
+   * @param maxBias The float value that the highest quantized bias value represents.
+   * @param outType 
+   * @return a new instance of QuantizedBiasAdd
+   */
+  public static <V, T, U> QuantizedBiasAdd<V> create(Scope scope, Operand<T> input, Operand<U> bias, Operand<Float> minInput, Operand<Float> maxInput, Operand<Float> minBias, Operand<Float> maxBias, Class<V> outType) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("QuantizedBiasAdd", scope.makeOpName("QuantizedBiasAdd"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(bias.asOutput());
+    opBuilder.addInput(minInput.asOutput());
+    opBuilder.addInput(maxInput.asOutput());
+    opBuilder.addInput(minBias.asOutput());
+    opBuilder.addInput(maxBias.asOutput());
+    opBuilder.setAttr("out_type", DataType.fromClass(outType));
+    return new QuantizedBiasAdd<V>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<V> output() {
+    return output;
+  }
+  
+  /**
+   * The float value that the lowest quantized output value represents.
+   */
+  public Output<Float> minOut() {
+    return minOut;
+  }
+  
+  /**
+   * The float value that the highest quantized output value represents.
+   */
+  public Output<Float> maxOut() {
+    return maxOut;
+  }
+  
+  private Output<V> output;
+  private Output<Float> minOut;
+  private Output<Float> maxOut;
+  
+  private QuantizedBiasAdd(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+    minOut = operation.output(outputIdx++);
+    maxOut = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/QuantizedConcat.java java-ops/org/tensorflow/op/core/QuantizedConcat.java
--- java/org/tensorflow/op/core/QuantizedConcat.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/QuantizedConcat.java	2018-10-16 20:18:38.395432267 +0900
@@ -0,0 +1,92 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Concatenates quantized tensors along one dimension.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class QuantizedConcat<T> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new QuantizedConcat operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param concatDim 0-D.  The dimension along which to concatenate.  Must be in the
+   * range [0, rank(values)).
+   * @param values The `N` Tensors to concatenate. Their ranks and types must match,
+   * and their sizes must match in all dimensions except `concat_dim`.
+   * @param inputMins The minimum scalar values for each of the input tensors.
+   * @param inputMaxes The maximum scalar values for each of the input tensors.
+   * @return a new instance of QuantizedConcat
+   */
+  public static <T> QuantizedConcat<T> create(Scope scope, Operand<Integer> concatDim, Operand<T> values, Iterable<Operand<Float>> inputMins, Iterable<Operand<Float>> inputMaxes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("QuantizedConcat", scope.makeOpName("QuantizedConcat"));
+    opBuilder.addInput(concatDim.asOutput());
+    opBuilder.addInput(values.asOutput());
+    opBuilder.addInputList(Operands.asOutputs(inputMins));
+    opBuilder.addInputList(Operands.asOutputs(inputMaxes));
+    return new QuantizedConcat<T>(opBuilder.build());
+  }
+  
+  /**
+   * A `Tensor` with the concatenation of values stacked along the
+   * `concat_dim` dimension.  This tensor's shape matches that of `values` except
+   * in `concat_dim` where it has the sum of the sizes.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  /**
+   * The float value that the minimum quantized output value represents.
+   */
+  public Output<Float> outputMin() {
+    return outputMin;
+  }
+  
+  /**
+   * The float value that the maximum quantized output value represents.
+   */
+  public Output<Float> outputMax() {
+    return outputMax;
+  }
+  
+  private Output<T> output;
+  private Output<Float> outputMin;
+  private Output<Float> outputMax;
+  
+  private QuantizedConcat(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+    outputMin = operation.output(outputIdx++);
+    outputMax = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/QuantizedConv2D.java java-ops/org/tensorflow/op/core/QuantizedConv2D.java
--- java/org/tensorflow/op/core/QuantizedConv2D.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/QuantizedConv2D.java	2018-10-16 20:18:38.396432266 +0900
@@ -0,0 +1,154 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes a 2D convolution given quantized 4D input and filter tensors.
+ * <p>
+ * The inputs are quantized tensors where the lowest value represents the real
+ * number of the associated minimum, and the highest represents the maximum.
+ * This means that you can only interpret the quantized output in the same way, by
+ * taking the returned minimum and maximum values into account.
+ * 
+ * @param <V> data type for {@code output()} output
+ */
+@Operator
+public final class QuantizedConv2D<V> extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.QuantizedConv2D}
+   */
+  public static class Options {
+    
+    /**
+     * @param dilations 1-D tensor of length 4.  The dilation factor for each dimension of
+     * `input`. If set to k > 1, there will be k-1 skipped cells between each
+     * filter element on that dimension. The dimension order is determined by the
+     * value of `data_format`, see above for details. Dilations in the batch and
+     * depth dimensions must be 1.
+     */
+    public Options dilations(List<Long> dilations) {
+      this.dilations = dilations;
+      return this;
+    }
+    
+    private List<Long> dilations;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new QuantizedConv2D operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param filter filter's input_depth dimension must match input's depth dimensions.
+   * @param minInput The float value that the lowest quantized input value represents.
+   * @param maxInput The float value that the highest quantized input value represents.
+   * @param minFilter The float value that the lowest quantized filter value represents.
+   * @param maxFilter The float value that the highest quantized filter value represents.
+   * @param outType 
+   * @param strides The stride of the sliding window for each dimension of the input
+   * tensor.
+   * @param padding The type of padding algorithm to use.
+   * @param options carries optional attributes values
+   * @return a new instance of QuantizedConv2D
+   */
+  public static <V, T, U> QuantizedConv2D<V> create(Scope scope, Operand<T> input, Operand<U> filter, Operand<Float> minInput, Operand<Float> maxInput, Operand<Float> minFilter, Operand<Float> maxFilter, Class<V> outType, List<Long> strides, String padding, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("QuantizedConv2D", scope.makeOpName("QuantizedConv2D"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(filter.asOutput());
+    opBuilder.addInput(minInput.asOutput());
+    opBuilder.addInput(maxInput.asOutput());
+    opBuilder.addInput(minFilter.asOutput());
+    opBuilder.addInput(maxFilter.asOutput());
+    opBuilder.setAttr("out_type", DataType.fromClass(outType));
+    long[] stridesArray = new long[strides.size()];
+    for (int i = 0; i < stridesArray.length; ++i) {
+      stridesArray[i] = strides.get(i);
+    }
+    opBuilder.setAttr("strides", stridesArray);
+    opBuilder.setAttr("padding", padding);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.dilations != null) {
+          long[] dilationsArray = new long[opts.dilations.size()];
+          for (int i = 0; i < dilationsArray.length; ++i) {
+            dilationsArray[i] = opts.dilations.get(i);
+          }
+          opBuilder.setAttr("dilations", dilationsArray);
+        }
+      }
+    }
+    return new QuantizedConv2D<V>(opBuilder.build());
+  }
+  
+  /**
+   * @param dilations 1-D tensor of length 4.  The dilation factor for each dimension of
+   * `input`. If set to k > 1, there will be k-1 skipped cells between each
+   * filter element on that dimension. The dimension order is determined by the
+   * value of `data_format`, see above for details. Dilations in the batch and
+   * depth dimensions must be 1.
+   */
+  public static Options dilations(List<Long> dilations) {
+    return new Options().dilations(dilations);
+  }
+  
+  /**
+   */
+  public Output<V> output() {
+    return output;
+  }
+  
+  /**
+   * The float value that the lowest quantized output value represents.
+   */
+  public Output<Float> minOutput() {
+    return minOutput;
+  }
+  
+  /**
+   * The float value that the highest quantized output value represents.
+   */
+  public Output<Float> maxOutput() {
+    return maxOutput;
+  }
+  
+  private Output<V> output;
+  private Output<Float> minOutput;
+  private Output<Float> maxOutput;
+  
+  private QuantizedConv2D(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+    minOutput = operation.output(outputIdx++);
+    maxOutput = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/QuantizedInstanceNorm.java java-ops/org/tensorflow/op/core/QuantizedInstanceNorm.java
--- java/org/tensorflow/op/core/QuantizedInstanceNorm.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/QuantizedInstanceNorm.java	2018-10-16 20:18:38.397432265 +0900
@@ -0,0 +1,199 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Quantized Instance normalization.
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class QuantizedInstanceNorm<T> extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.QuantizedInstanceNorm}
+   */
+  public static class Options {
+    
+    /**
+     * @param outputRangeGiven If True, `given_y_min` and `given_y_min`
+     * and `given_y_max` are used as the output range. Otherwise,
+     * the implementation computes the output range.
+     */
+    public Options outputRangeGiven(Boolean outputRangeGiven) {
+      this.outputRangeGiven = outputRangeGiven;
+      return this;
+    }
+    
+    /**
+     * @param givenYMin Output in `y_min` if `output_range_given` is True.
+     */
+    public Options givenYMin(Float givenYMin) {
+      this.givenYMin = givenYMin;
+      return this;
+    }
+    
+    /**
+     * @param givenYMax Output in `y_max` if `output_range_given` is True.
+     */
+    public Options givenYMax(Float givenYMax) {
+      this.givenYMax = givenYMax;
+      return this;
+    }
+    
+    /**
+     * @param varianceEpsilon A small float number to avoid dividing by 0.
+     */
+    public Options varianceEpsilon(Float varianceEpsilon) {
+      this.varianceEpsilon = varianceEpsilon;
+      return this;
+    }
+    
+    /**
+     * @param minSeparation Minimum value of `y_max - y_min`
+     */
+    public Options minSeparation(Float minSeparation) {
+      this.minSeparation = minSeparation;
+      return this;
+    }
+    
+    private Boolean outputRangeGiven;
+    private Float givenYMin;
+    private Float givenYMax;
+    private Float varianceEpsilon;
+    private Float minSeparation;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new QuantizedInstanceNorm operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x A 4D input Tensor.
+   * @param xMin The value represented by the lowest quantized input.
+   * @param xMax The value represented by the highest quantized input.
+   * @param options carries optional attributes values
+   * @return a new instance of QuantizedInstanceNorm
+   */
+  public static <T> QuantizedInstanceNorm<T> create(Scope scope, Operand<T> x, Operand<Float> xMin, Operand<Float> xMax, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("QuantizedInstanceNorm", scope.makeOpName("QuantizedInstanceNorm"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(xMin.asOutput());
+    opBuilder.addInput(xMax.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.outputRangeGiven != null) {
+          opBuilder.setAttr("output_range_given", opts.outputRangeGiven);
+        }
+        if (opts.givenYMin != null) {
+          opBuilder.setAttr("given_y_min", opts.givenYMin);
+        }
+        if (opts.givenYMax != null) {
+          opBuilder.setAttr("given_y_max", opts.givenYMax);
+        }
+        if (opts.varianceEpsilon != null) {
+          opBuilder.setAttr("variance_epsilon", opts.varianceEpsilon);
+        }
+        if (opts.minSeparation != null) {
+          opBuilder.setAttr("min_separation", opts.minSeparation);
+        }
+      }
+    }
+    return new QuantizedInstanceNorm<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param outputRangeGiven If True, `given_y_min` and `given_y_min`
+   * and `given_y_max` are used as the output range. Otherwise,
+   * the implementation computes the output range.
+   */
+  public static Options outputRangeGiven(Boolean outputRangeGiven) {
+    return new Options().outputRangeGiven(outputRangeGiven);
+  }
+  
+  /**
+   * @param givenYMin Output in `y_min` if `output_range_given` is True.
+   */
+  public static Options givenYMin(Float givenYMin) {
+    return new Options().givenYMin(givenYMin);
+  }
+  
+  /**
+   * @param givenYMax Output in `y_max` if `output_range_given` is True.
+   */
+  public static Options givenYMax(Float givenYMax) {
+    return new Options().givenYMax(givenYMax);
+  }
+  
+  /**
+   * @param varianceEpsilon A small float number to avoid dividing by 0.
+   */
+  public static Options varianceEpsilon(Float varianceEpsilon) {
+    return new Options().varianceEpsilon(varianceEpsilon);
+  }
+  
+  /**
+   * @param minSeparation Minimum value of `y_max - y_min`
+   */
+  public static Options minSeparation(Float minSeparation) {
+    return new Options().minSeparation(minSeparation);
+  }
+  
+  /**
+   * A 4D Tensor.
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  /**
+   * The value represented by the lowest quantized output.
+   */
+  public Output<Float> yMin() {
+    return yMin;
+  }
+  
+  /**
+   * The value represented by the highest quantized output.
+   */
+  public Output<Float> yMax() {
+    return yMax;
+  }
+  
+  private Output<T> y;
+  private Output<Float> yMin;
+  private Output<Float> yMax;
+  
+  private QuantizedInstanceNorm(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+    yMin = operation.output(outputIdx++);
+    yMax = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/QuantizedMatMul.java java-ops/org/tensorflow/op/core/QuantizedMatMul.java
--- java/org/tensorflow/op/core/QuantizedMatMul.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/QuantizedMatMul.java	2018-10-16 20:18:38.397432265 +0900
@@ -0,0 +1,154 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Perform a quantized matrix multiplication of  `a` by the matrix `b`.
+ * <p>
+ * The inputs must be two-dimensional matrices and the inner dimension of
+ * `a` (after being transposed if `transpose_a` is non-zero) must match the
+ * outer dimension of `b` (after being transposed if `transposed_b` is
+ * non-zero).
+ * 
+ * @param <V> data type for {@code out()} output
+ */
+@Operator
+public final class QuantizedMatMul<V> extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.QuantizedMatMul}
+   */
+  public static class Options {
+    
+    /**
+     * @param transposeA If true, `a` is transposed before multiplication.
+     */
+    public Options transposeA(Boolean transposeA) {
+      this.transposeA = transposeA;
+      return this;
+    }
+    
+    /**
+     * @param transposeB If true, `b` is transposed before multiplication.
+     */
+    public Options transposeB(Boolean transposeB) {
+      this.transposeB = transposeB;
+      return this;
+    }
+    
+    private Boolean transposeA;
+    private Boolean transposeB;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new QuantizedMatMul operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param a Must be a two-dimensional tensor.
+   * @param b Must be a two-dimensional tensor.
+   * @param minA The float value that the lowest quantized `a` value represents.
+   * @param maxA The float value that the highest quantized `a` value represents.
+   * @param minB The float value that the lowest quantized `b` value represents.
+   * @param maxB The float value that the highest quantized `b` value represents.
+   * @param Toutput 
+   * @param Tactivation The type of output produced by activation function
+   * following this operation.
+   * @param options carries optional attributes values
+   * @return a new instance of QuantizedMatMul
+   */
+  public static <V, T, U, W> QuantizedMatMul<V> create(Scope scope, Operand<T> a, Operand<U> b, Operand<Float> minA, Operand<Float> maxA, Operand<Float> minB, Operand<Float> maxB, Class<V> Toutput, Class<W> Tactivation, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("QuantizedMatMul", scope.makeOpName("QuantizedMatMul"));
+    opBuilder.addInput(a.asOutput());
+    opBuilder.addInput(b.asOutput());
+    opBuilder.addInput(minA.asOutput());
+    opBuilder.addInput(maxA.asOutput());
+    opBuilder.addInput(minB.asOutput());
+    opBuilder.addInput(maxB.asOutput());
+    opBuilder.setAttr("Toutput", DataType.fromClass(Toutput));
+    opBuilder.setAttr("Tactivation", DataType.fromClass(Tactivation));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.transposeA != null) {
+          opBuilder.setAttr("transpose_a", opts.transposeA);
+        }
+        if (opts.transposeB != null) {
+          opBuilder.setAttr("transpose_b", opts.transposeB);
+        }
+      }
+    }
+    return new QuantizedMatMul<V>(opBuilder.build());
+  }
+  
+  /**
+   * @param transposeA If true, `a` is transposed before multiplication.
+   */
+  public static Options transposeA(Boolean transposeA) {
+    return new Options().transposeA(transposeA);
+  }
+  
+  /**
+   * @param transposeB If true, `b` is transposed before multiplication.
+   */
+  public static Options transposeB(Boolean transposeB) {
+    return new Options().transposeB(transposeB);
+  }
+  
+  /**
+   */
+  public Output<V> out() {
+    return out;
+  }
+  
+  /**
+   * The float value that the lowest quantized output value represents.
+   */
+  public Output<Float> minOut() {
+    return minOut;
+  }
+  
+  /**
+   * The float value that the highest quantized output value represents.
+   */
+  public Output<Float> maxOut() {
+    return maxOut;
+  }
+  
+  private Output<V> out;
+  private Output<Float> minOut;
+  private Output<Float> maxOut;
+  
+  private QuantizedMatMul(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    out = operation.output(outputIdx++);
+    minOut = operation.output(outputIdx++);
+    maxOut = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/QuantizedMaxPool.java java-ops/org/tensorflow/op/core/QuantizedMaxPool.java
--- java/org/tensorflow/op/core/QuantizedMaxPool.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/QuantizedMaxPool.java	2018-10-16 20:18:38.398432264 +0900
@@ -0,0 +1,101 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Produces the max pool of the input tensor for quantized types.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class QuantizedMaxPool<T> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new QuantizedMaxPool operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input The 4D (batch x rows x cols x depth) Tensor to MaxReduce over.
+   * @param minInput The float value that the lowest quantized input value represents.
+   * @param maxInput The float value that the highest quantized input value represents.
+   * @param ksize The size of the window for each dimension of the input tensor.
+   * The length must be 4 to match the number of dimensions of the input.
+   * @param strides The stride of the sliding window for each dimension of the input
+   * tensor. The length must be 4 to match the number of dimensions of the input.
+   * @param padding The type of padding algorithm to use.
+   * @return a new instance of QuantizedMaxPool
+   */
+  public static <T> QuantizedMaxPool<T> create(Scope scope, Operand<T> input, Operand<Float> minInput, Operand<Float> maxInput, List<Long> ksize, List<Long> strides, String padding) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("QuantizedMaxPool", scope.makeOpName("QuantizedMaxPool"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(minInput.asOutput());
+    opBuilder.addInput(maxInput.asOutput());
+    long[] ksizeArray = new long[ksize.size()];
+    for (int i = 0; i < ksizeArray.length; ++i) {
+      ksizeArray[i] = ksize.get(i);
+    }
+    opBuilder.setAttr("ksize", ksizeArray);
+    long[] stridesArray = new long[strides.size()];
+    for (int i = 0; i < stridesArray.length; ++i) {
+      stridesArray[i] = strides.get(i);
+    }
+    opBuilder.setAttr("strides", stridesArray);
+    opBuilder.setAttr("padding", padding);
+    return new QuantizedMaxPool<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  /**
+   * The float value that the lowest quantized output value represents.
+   */
+  public Output<Float> minOutput() {
+    return minOutput;
+  }
+  
+  /**
+   * The float value that the highest quantized output value represents.
+   */
+  public Output<Float> maxOutput() {
+    return maxOutput;
+  }
+  
+  private Output<T> output;
+  private Output<Float> minOutput;
+  private Output<Float> maxOutput;
+  
+  private QuantizedMaxPool(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+    minOutput = operation.output(outputIdx++);
+    maxOutput = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/QuantizedMul.java java-ops/org/tensorflow/op/core/QuantizedMul.java
--- java/org/tensorflow/op/core/QuantizedMul.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/QuantizedMul.java	2018-10-16 20:18:38.399432264 +0900
@@ -0,0 +1,96 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns x * y element-wise, working on quantized buffers.
+ * 
+ * @param <V> data type for {@code z()} output
+ */
+@Operator
+public final class QuantizedMul<V> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new QuantizedMul operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param y 
+   * @param minX The float value that the lowest quantized `x` value represents.
+   * @param maxX The float value that the highest quantized `x` value represents.
+   * @param minY The float value that the lowest quantized `y` value represents.
+   * @param maxY The float value that the highest quantized `y` value represents.
+   * @param Toutput 
+   * @return a new instance of QuantizedMul
+   */
+  public static <V, T, U> QuantizedMul<V> create(Scope scope, Operand<T> x, Operand<U> y, Operand<Float> minX, Operand<Float> maxX, Operand<Float> minY, Operand<Float> maxY, Class<V> Toutput) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("QuantizedMul", scope.makeOpName("QuantizedMul"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(y.asOutput());
+    opBuilder.addInput(minX.asOutput());
+    opBuilder.addInput(maxX.asOutput());
+    opBuilder.addInput(minY.asOutput());
+    opBuilder.addInput(maxY.asOutput());
+    opBuilder.setAttr("Toutput", DataType.fromClass(Toutput));
+    return new QuantizedMul<V>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<V> z() {
+    return z;
+  }
+  
+  /**
+   * The float value that the lowest quantized output value represents.
+   */
+  public Output<Float> minZ() {
+    return minZ;
+  }
+  
+  /**
+   * The float value that the highest quantized output value represents.
+   * <p>
+   * <i>NOTE</i>: `QuantizedMul` supports limited forms of broadcasting. More about
+   * broadcasting [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
+   */
+  public Output<Float> maxZ() {
+    return maxZ;
+  }
+  
+  private Output<V> z;
+  private Output<Float> minZ;
+  private Output<Float> maxZ;
+  
+  private QuantizedMul(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+    minZ = operation.output(outputIdx++);
+    maxZ = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/QuantizeDownAndShrinkRange.java java-ops/org/tensorflow/op/core/QuantizeDownAndShrinkRange.java
--- java/org/tensorflow/op/core/QuantizeDownAndShrinkRange.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/QuantizeDownAndShrinkRange.java	2018-10-16 20:18:38.391432269 +0900
@@ -0,0 +1,110 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Convert the quantized 'input' tensor into a lower-precision 'output', using the
+ * <p>
+ * actual distribution of the values to maximize the usage of the lower bit depth
+ * and adjusting the output min and max ranges accordingly.
+ * <p>
+ * [input_min, input_max] are scalar floats that specify the range for the float
+ * interpretation of the 'input' data. For example, if input_min is -1.0f and
+ * input_max is 1.0f, and we are dealing with quint16 quantized data, then a 0
+ * value in the 16-bit data should be interpreted as -1.0f, and a 65535 means 1.0f.
+ * <p>
+ * This operator tries to squeeze as much precision as possible into an output with
+ * a lower bit depth by calculating the actual min and max values found in the
+ * data. For example, maybe that quint16 input has no values lower than 16,384 and
+ * none higher than 49,152. That means only half the range is actually needed, all
+ * the float interpretations are between -0.5f and 0.5f, so if we want to compress
+ * the data into a quint8 output, we can use that range rather than the theoretical
+ * -1.0f to 1.0f that is suggested by the input min and max.
+ * <p>
+ * In practice, this is most useful for taking output from operations like
+ * QuantizedMatMul that can produce higher bit-depth outputs than their inputs and
+ * may have large potential output ranges, but in practice have a distribution of
+ * input values that only uses a small fraction of the possible range. By feeding
+ * that output into this operator, we can reduce it from 32 bits down to 8 with
+ * minimal loss of accuracy.
+ * 
+ * @param <U> data type for {@code output()} output
+ */
+@Operator
+public final class QuantizeDownAndShrinkRange<U> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new QuantizeDownAndShrinkRange operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param inputMin The float value that the minimum quantized input value represents.
+   * @param inputMax The float value that the maximum quantized input value represents.
+   * @param outType The type of the output. Should be a lower bit depth than Tinput.
+   * @return a new instance of QuantizeDownAndShrinkRange
+   */
+  public static <U, T> QuantizeDownAndShrinkRange<U> create(Scope scope, Operand<T> input, Operand<Float> inputMin, Operand<Float> inputMax, Class<U> outType) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("QuantizeDownAndShrinkRange", scope.makeOpName("QuantizeDownAndShrinkRange"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(inputMin.asOutput());
+    opBuilder.addInput(inputMax.asOutput());
+    opBuilder.setAttr("out_type", DataType.fromClass(outType));
+    return new QuantizeDownAndShrinkRange<U>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<U> output() {
+    return output;
+  }
+  
+  /**
+   * The float value that the minimum quantized output value represents.
+   */
+  public Output<Float> outputMin() {
+    return outputMin;
+  }
+  
+  /**
+   * The float value that the maximum quantized output value represents.
+   */
+  public Output<Float> outputMax() {
+    return outputMax;
+  }
+  
+  private Output<U> output;
+  private Output<Float> outputMin;
+  private Output<Float> outputMax;
+  
+  private QuantizeDownAndShrinkRange(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+    outputMin = operation.output(outputIdx++);
+    outputMax = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/QuantizedRelu6.java java-ops/org/tensorflow/op/core/QuantizedRelu6.java
--- java/org/tensorflow/op/core/QuantizedRelu6.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/QuantizedRelu6.java	2018-10-16 20:18:38.400432263 +0900
@@ -0,0 +1,88 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes Quantized Rectified Linear 6: `min(max(features, 0), 6)`
+ * 
+ * @param <U> data type for {@code activations()} output
+ */
+@Operator
+public final class QuantizedRelu6<U> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new QuantizedRelu6 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param features 
+   * @param minFeatures The float value that the lowest quantized value represents.
+   * @param maxFeatures The float value that the highest quantized value represents.
+   * @param outType 
+   * @return a new instance of QuantizedRelu6
+   */
+  public static <U, T> QuantizedRelu6<U> create(Scope scope, Operand<T> features, Operand<Float> minFeatures, Operand<Float> maxFeatures, Class<U> outType) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("QuantizedRelu6", scope.makeOpName("QuantizedRelu6"));
+    opBuilder.addInput(features.asOutput());
+    opBuilder.addInput(minFeatures.asOutput());
+    opBuilder.addInput(maxFeatures.asOutput());
+    opBuilder.setAttr("out_type", DataType.fromClass(outType));
+    return new QuantizedRelu6<U>(opBuilder.build());
+  }
+  
+  /**
+   * Has the same output shape as "features".
+   */
+  public Output<U> activations() {
+    return activations;
+  }
+  
+  /**
+   * The float value that the lowest quantized value represents.
+   */
+  public Output<Float> minActivations() {
+    return minActivations;
+  }
+  
+  /**
+   * The float value that the highest quantized value represents.
+   */
+  public Output<Float> maxActivations() {
+    return maxActivations;
+  }
+  
+  private Output<U> activations;
+  private Output<Float> minActivations;
+  private Output<Float> maxActivations;
+  
+  private QuantizedRelu6(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    activations = operation.output(outputIdx++);
+    minActivations = operation.output(outputIdx++);
+    maxActivations = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/QuantizedRelu.java java-ops/org/tensorflow/op/core/QuantizedRelu.java
--- java/org/tensorflow/op/core/QuantizedRelu.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/QuantizedRelu.java	2018-10-16 20:18:38.400432263 +0900
@@ -0,0 +1,88 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes Quantized Rectified Linear: `max(features, 0)`
+ * 
+ * @param <U> data type for {@code activations()} output
+ */
+@Operator
+public final class QuantizedRelu<U> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new QuantizedRelu operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param features 
+   * @param minFeatures The float value that the lowest quantized value represents.
+   * @param maxFeatures The float value that the highest quantized value represents.
+   * @param outType 
+   * @return a new instance of QuantizedRelu
+   */
+  public static <U, T> QuantizedRelu<U> create(Scope scope, Operand<T> features, Operand<Float> minFeatures, Operand<Float> maxFeatures, Class<U> outType) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("QuantizedRelu", scope.makeOpName("QuantizedRelu"));
+    opBuilder.addInput(features.asOutput());
+    opBuilder.addInput(minFeatures.asOutput());
+    opBuilder.addInput(maxFeatures.asOutput());
+    opBuilder.setAttr("out_type", DataType.fromClass(outType));
+    return new QuantizedRelu<U>(opBuilder.build());
+  }
+  
+  /**
+   * Has the same output shape as "features".
+   */
+  public Output<U> activations() {
+    return activations;
+  }
+  
+  /**
+   * The float value that the lowest quantized value represents.
+   */
+  public Output<Float> minActivations() {
+    return minActivations;
+  }
+  
+  /**
+   * The float value that the highest quantized value represents.
+   */
+  public Output<Float> maxActivations() {
+    return maxActivations;
+  }
+  
+  private Output<U> activations;
+  private Output<Float> minActivations;
+  private Output<Float> maxActivations;
+  
+  private QuantizedRelu(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    activations = operation.output(outputIdx++);
+    minActivations = operation.output(outputIdx++);
+    maxActivations = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/QuantizedReluX.java java-ops/org/tensorflow/op/core/QuantizedReluX.java
--- java/org/tensorflow/op/core/QuantizedReluX.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/QuantizedReluX.java	2018-10-16 20:18:38.401432262 +0900
@@ -0,0 +1,90 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes Quantized Rectified Linear X: `min(max(features, 0), max_value)`
+ * 
+ * @param <U> data type for {@code activations()} output
+ */
+@Operator
+public final class QuantizedReluX<U> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new QuantizedReluX operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param features 
+   * @param maxValue 
+   * @param minFeatures The float value that the lowest quantized value represents.
+   * @param maxFeatures The float value that the highest quantized value represents.
+   * @param outType 
+   * @return a new instance of QuantizedReluX
+   */
+  public static <U, T> QuantizedReluX<U> create(Scope scope, Operand<T> features, Operand<Float> maxValue, Operand<Float> minFeatures, Operand<Float> maxFeatures, Class<U> outType) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("QuantizedReluX", scope.makeOpName("QuantizedReluX"));
+    opBuilder.addInput(features.asOutput());
+    opBuilder.addInput(maxValue.asOutput());
+    opBuilder.addInput(minFeatures.asOutput());
+    opBuilder.addInput(maxFeatures.asOutput());
+    opBuilder.setAttr("out_type", DataType.fromClass(outType));
+    return new QuantizedReluX<U>(opBuilder.build());
+  }
+  
+  /**
+   * Has the same output shape as "features".
+   */
+  public Output<U> activations() {
+    return activations;
+  }
+  
+  /**
+   * The float value that the lowest quantized value represents.
+   */
+  public Output<Float> minActivations() {
+    return minActivations;
+  }
+  
+  /**
+   * The float value that the highest quantized value represents.
+   */
+  public Output<Float> maxActivations() {
+    return maxActivations;
+  }
+  
+  private Output<U> activations;
+  private Output<Float> minActivations;
+  private Output<Float> maxActivations;
+  
+  private QuantizedReluX(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    activations = operation.output(outputIdx++);
+    minActivations = operation.output(outputIdx++);
+    maxActivations = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/QuantizedReshape.java java-ops/org/tensorflow/op/core/QuantizedReshape.java
--- java/org/tensorflow/op/core/QuantizedReshape.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/QuantizedReshape.java	2018-10-16 20:18:38.401432262 +0900
@@ -0,0 +1,88 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Reshapes a quantized tensor as per the Reshape op.
+ * <p>
+ * ```
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class QuantizedReshape<T> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new QuantizedReshape operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param tensor 
+   * @param shape Defines the shape of the output tensor.
+   * @param inputMin The minimum value of the input.
+   * @param inputMax The maximum value of the input.
+   * @return a new instance of QuantizedReshape
+   */
+  public static <T, U extends Number> QuantizedReshape<T> create(Scope scope, Operand<T> tensor, Operand<U> shape, Operand<Float> inputMin, Operand<Float> inputMax) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("QuantizedReshape", scope.makeOpName("QuantizedReshape"));
+    opBuilder.addInput(tensor.asOutput());
+    opBuilder.addInput(shape.asOutput());
+    opBuilder.addInput(inputMin.asOutput());
+    opBuilder.addInput(inputMax.asOutput());
+    return new QuantizedReshape<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  /**
+   * This value is copied from input_min.
+   */
+  public Output<Float> outputMin() {
+    return outputMin;
+  }
+  
+  /**
+   * This value is copied from input_max.
+   */
+  public Output<Float> outputMax() {
+    return outputMax;
+  }
+  
+  private Output<T> output;
+  private Output<Float> outputMin;
+  private Output<Float> outputMax;
+  
+  private QuantizedReshape(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+    outputMin = operation.output(outputIdx++);
+    outputMax = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/QuantizedResizeBilinear.java java-ops/org/tensorflow/op/core/QuantizedResizeBilinear.java
--- java/org/tensorflow/op/core/QuantizedResizeBilinear.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/QuantizedResizeBilinear.java	2018-10-16 20:18:38.402432261 +0900
@@ -0,0 +1,125 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Resize quantized `images` to `size` using quantized bilinear interpolation.
+ * <p>
+ * Input images and output images must be quantized types.
+ * 
+ * @param <T> data type for {@code resizedImages()} output
+ */
+@Operator
+public final class QuantizedResizeBilinear<T> extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.QuantizedResizeBilinear}
+   */
+  public static class Options {
+    
+    /**
+     * @param alignCorners If true, the centers of the 4 corner pixels of the input and output tensors are
+     * aligned, preserving the values at the corner pixels. Defaults to false.
+     */
+    public Options alignCorners(Boolean alignCorners) {
+      this.alignCorners = alignCorners;
+      return this;
+    }
+    
+    private Boolean alignCorners;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new QuantizedResizeBilinear operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param images 4-D with shape `[batch, height, width, channels]`.
+   * @param size = A 1-D int32 Tensor of 2 elements: `new_height, new_width`.  The
+   * new size for the images.
+   * @param min 
+   * @param max 
+   * @param options carries optional attributes values
+   * @return a new instance of QuantizedResizeBilinear
+   */
+  public static <T> QuantizedResizeBilinear<T> create(Scope scope, Operand<T> images, Operand<Integer> size, Operand<Float> min, Operand<Float> max, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("QuantizedResizeBilinear", scope.makeOpName("QuantizedResizeBilinear"));
+    opBuilder.addInput(images.asOutput());
+    opBuilder.addInput(size.asOutput());
+    opBuilder.addInput(min.asOutput());
+    opBuilder.addInput(max.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.alignCorners != null) {
+          opBuilder.setAttr("align_corners", opts.alignCorners);
+        }
+      }
+    }
+    return new QuantizedResizeBilinear<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param alignCorners If true, the centers of the 4 corner pixels of the input and output tensors are
+   * aligned, preserving the values at the corner pixels. Defaults to false.
+   */
+  public static Options alignCorners(Boolean alignCorners) {
+    return new Options().alignCorners(alignCorners);
+  }
+  
+  /**
+   * 4-D with shape
+   * `[batch, new_height, new_width, channels]`.
+   */
+  public Output<T> resizedImages() {
+    return resizedImages;
+  }
+  
+  /**
+   */
+  public Output<Float> outMin() {
+    return outMin;
+  }
+  
+  /**
+   */
+  public Output<Float> outMax() {
+    return outMax;
+  }
+  
+  private Output<T> resizedImages;
+  private Output<Float> outMin;
+  private Output<Float> outMax;
+  
+  private QuantizedResizeBilinear(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    resizedImages = operation.output(outputIdx++);
+    outMin = operation.output(outputIdx++);
+    outMax = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/QuantizeV2.java java-ops/org/tensorflow/op/core/QuantizeV2.java
--- java/org/tensorflow/op/core/QuantizeV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/QuantizeV2.java	2018-10-16 20:18:38.392432268 +0900
@@ -0,0 +1,226 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Quantize the 'input' tensor of type float to 'output' tensor of type 'T'.
+ * <p>
+ * [min_range, max_range] are scalar floats that specify the range for
+ * the 'input' data. The 'mode' attribute controls exactly which calculations are
+ * used to convert the float values to their quantized equivalents.  The
+ * 'round_mode' attribute controls which rounding tie-breaking algorithm is used
+ * when rounding float values to their quantized equivalents.
+ * <p>
+ * In 'MIN_COMBINED' mode, each value of the tensor will undergo the following:
+ * <pre>{@code
+ * out[i] = (in[i] - min_range) * range(T) / (max_range - min_range)
+ * if T == qint8, out[i] -= (range(T) + 1) / 2.0
+ * }</pre>
+ * here `range(T) = numeric_limits<T>::max() - numeric_limits<T>::min()`
+ * <p>
+ * <i>MIN_COMBINED Mode Example</i>
+ * <p>
+ * Assume the input is type float and has a possible range of [0.0, 6.0] and the
+ * output type is quint8 ([0, 255]). The min_range and max_range values should be
+ * specified as 0.0 and 6.0. Quantizing from float to quint8 will multiply each
+ * value of the input by 255/6 and cast to quint8.
+ * <p>
+ * If the output type was qint8 ([-128, 127]), the operation will additionally
+ * subtract each value by 128 prior to casting, so that the range of values aligns
+ * with the range of qint8.
+ * <p>
+ * If the mode is 'MIN_FIRST', then this approach is used:
+ * <pre>{@code
+ * num_discrete_values = 1 << (# of bits in T)
+ * range_adjust = num_discrete_values / (num_discrete_values - 1)
+ * range = (range_max - range_min) * range_adjust
+ * range_scale = num_discrete_values / range
+ * quantized = round(input * range_scale) - round(range_min * range_scale) +
+ *   numeric_limits<T>::min()
+ * quantized = max(quantized, numeric_limits<T>::min())
+ * quantized = min(quantized, numeric_limits<T>::max())
+ * }</pre>
+ * The biggest difference between this and MIN_COMBINED is that the minimum range
+ * is rounded first, before it's subtracted from the rounded value. With
+ * MIN_COMBINED, a small bias is introduced where repeated iterations of quantizing
+ * and dequantizing will introduce a larger and larger error.
+ * <p>
+ * <i>SCALED mode Example</i>
+ * <p>
+ * `SCALED` mode matches the quantization approach used in
+ * `QuantizeAndDequantize{V2|V3}`.
+ * <p>
+ * If the mode is `SCALED`, we do not use the full range of the output type,
+ * choosing to elide the lowest possible value for symmetry (e.g., output range is
+ * -127 to 127, not -128 to 127 for signed 8 bit quantization), so that 0.0 maps to
+ * 0.
+ * <p>
+ * We first find the range of values in our tensor. The
+ * range we use is always centered on 0, so we find m such that
+ * <pre>{@code
+ *   m = max(abs(input_min), abs(input_max))
+ * }</pre>
+ * Our input tensor range is then `[-m, m]`.
+ * <p>
+ * Next, we choose our fixed-point quantization buckets, `[min_fixed, max_fixed]`.
+ * If T is signed, this is
+ * <pre>{@code
+ *   num_bits = sizeof(T) * 8
+ *   [min_fixed, max_fixed] =
+ *       [-(1 << (num_bits - 1) - 1), (1 << (num_bits - 1)) - 1]
+ * }</pre>
+ * Otherwise, if T is unsigned, the fixed-point range is
+ * <pre>{@code
+ *   [min_fixed, max_fixed] = [0, (1 << num_bits) - 1]
+ * }</pre>
+ * From this we compute our scaling factor, s:
+ * <pre>{@code
+ *   s = (max_fixed - min_fixed) / (2 * m)
+ * }</pre>
+ * Now we can quantize the elements of our tensor:
+ * <pre>{@code
+ * result = round(input * s)
+ * }</pre>
+ * One thing to watch out for is that the operator may choose to adjust the
+ * requested minimum and maximum values slightly during the quantization process,
+ * so you should always use the output ports as the range for further calculations.
+ * For example, if the requested minimum and maximum values are close to equal,
+ * they will be separated by a small epsilon value to prevent ill-formed quantized
+ * buffers from being created. Otherwise, you can end up with buffers where all the
+ * quantized values map to the same float value, which causes problems for
+ * operations that have to perform further calculations on them.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class QuantizeV2<T> extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.QuantizeV2}
+   */
+  public static class Options {
+    
+    /**
+     * @param mode 
+     */
+    public Options mode(String mode) {
+      this.mode = mode;
+      return this;
+    }
+    
+    /**
+     * @param roundMode 
+     */
+    public Options roundMode(String roundMode) {
+      this.roundMode = roundMode;
+      return this;
+    }
+    
+    private String mode;
+    private String roundMode;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new QuantizeV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param minRange The minimum scalar value possibly produced for the input.
+   * @param maxRange The maximum scalar value possibly produced for the input.
+   * @param T 
+   * @param options carries optional attributes values
+   * @return a new instance of QuantizeV2
+   */
+  public static <T> QuantizeV2<T> create(Scope scope, Operand<Float> input, Operand<Float> minRange, Operand<Float> maxRange, Class<T> T, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("QuantizeV2", scope.makeOpName("QuantizeV2"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(minRange.asOutput());
+    opBuilder.addInput(maxRange.asOutput());
+    opBuilder.setAttr("T", DataType.fromClass(T));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.mode != null) {
+          opBuilder.setAttr("mode", opts.mode);
+        }
+        if (opts.roundMode != null) {
+          opBuilder.setAttr("round_mode", opts.roundMode);
+        }
+      }
+    }
+    return new QuantizeV2<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param mode 
+   */
+  public static Options mode(String mode) {
+    return new Options().mode(mode);
+  }
+  
+  /**
+   * @param roundMode 
+   */
+  public static Options roundMode(String roundMode) {
+    return new Options().roundMode(roundMode);
+  }
+  
+  /**
+   * The quantized data produced from the float input.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  /**
+   * The actual minimum scalar value used for the output.
+   */
+  public Output<Float> outputMin() {
+    return outputMin;
+  }
+  
+  /**
+   * The actual maximum scalar value used for the output.
+   */
+  public Output<Float> outputMax() {
+    return outputMax;
+  }
+  
+  private Output<T> output;
+  private Output<Float> outputMin;
+  private Output<Float> outputMax;
+  
+  private QuantizeV2(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+    outputMin = operation.output(outputIdx++);
+    outputMax = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/QueueClose.java java-ops/org/tensorflow/op/core/QueueClose.java
--- java/org/tensorflow/op/core/QueueClose.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/QueueClose.java	2018-10-16 20:18:38.402432261 +0900
@@ -0,0 +1,92 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Closes the given queue.
+ * <p>
+ * This operation signals that no more elements will be enqueued in the
+ * given queue. Subsequent Enqueue(Many) operations will fail.
+ * Subsequent Dequeue(Many) operations will continue to succeed if
+ * sufficient elements remain in the queue. Subsequent Dequeue(Many)
+ * operations that would block will fail immediately.
+ */
+@Operator
+public final class QueueClose extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.QueueClose}
+   */
+  public static class Options {
+    
+    /**
+     * @param cancelPendingEnqueues If true, all pending enqueue requests that are
+     * blocked on the given queue will be canceled.
+     */
+    public Options cancelPendingEnqueues(Boolean cancelPendingEnqueues) {
+      this.cancelPendingEnqueues = cancelPendingEnqueues;
+      return this;
+    }
+    
+    private Boolean cancelPendingEnqueues;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new QueueClose operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param handle The handle to a queue.
+   * @param options carries optional attributes values
+   * @return a new instance of QueueClose
+   */
+  public static QueueClose create(Scope scope, Operand<?> handle, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("QueueCloseV2", scope.makeOpName("QueueClose"));
+    opBuilder.addInput(handle.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.cancelPendingEnqueues != null) {
+          opBuilder.setAttr("cancel_pending_enqueues", opts.cancelPendingEnqueues);
+        }
+      }
+    }
+    return new QueueClose(opBuilder.build());
+  }
+  
+  /**
+   * @param cancelPendingEnqueues If true, all pending enqueue requests that are
+   * blocked on the given queue will be canceled.
+   */
+  public static Options cancelPendingEnqueues(Boolean cancelPendingEnqueues) {
+    return new Options().cancelPendingEnqueues(cancelPendingEnqueues);
+  }
+  
+  
+  private QueueClose(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/QueueDequeue.java java-ops/org/tensorflow/op/core/QueueDequeue.java
--- java/org/tensorflow/op/core/QueueDequeue.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/QueueDequeue.java	2018-10-16 20:18:38.403432261 +0900
@@ -0,0 +1,124 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.Iterator;
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Dequeues a tuple of one or more tensors from the given queue.
+ * <p>
+ * This operation has k outputs, where k is the number of components
+ * in the tuples stored in the given queue, and output i is the ith
+ * component of the dequeued tuple.
+ * <p>
+ * N.B. If the queue is empty, this operation will block until an element
+ * has been dequeued (or 'timeout_ms' elapses, if specified).
+ */
+@Operator
+public final class QueueDequeue extends PrimitiveOp implements Iterable<Operand<Object>> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.QueueDequeue}
+   */
+  public static class Options {
+    
+    /**
+     * @param timeoutMs If the queue is empty, this operation will block for up to
+     * timeout_ms milliseconds.
+     * Note: This option is not supported yet.
+     */
+    public Options timeoutMs(Long timeoutMs) {
+      this.timeoutMs = timeoutMs;
+      return this;
+    }
+    
+    private Long timeoutMs;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new QueueDequeue operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param handle The handle to a queue.
+   * @param componentTypes The type of each component in a tuple.
+   * @param options carries optional attributes values
+   * @return a new instance of QueueDequeue
+   */
+  public static QueueDequeue create(Scope scope, Operand<?> handle, List<Class<?>> componentTypes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("QueueDequeueV2", scope.makeOpName("QueueDequeue"));
+    opBuilder.addInput(handle.asOutput());
+    DataType[] componentTypesArray = new DataType[componentTypes.size()];
+    for (int i = 0; i < componentTypesArray.length; ++i) {
+      componentTypesArray[i] = DataType.fromClass(componentTypes.get(i));
+    }
+    opBuilder.setAttr("component_types", componentTypesArray);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.timeoutMs != null) {
+          opBuilder.setAttr("timeout_ms", opts.timeoutMs);
+        }
+      }
+    }
+    return new QueueDequeue(opBuilder.build());
+  }
+  
+  /**
+   * @param timeoutMs If the queue is empty, this operation will block for up to
+   * timeout_ms milliseconds.
+   * Note: This option is not supported yet.
+   */
+  public static Options timeoutMs(Long timeoutMs) {
+    return new Options().timeoutMs(timeoutMs);
+  }
+  
+  /**
+   * One or more tensors that were dequeued as a tuple.
+   */
+  public List<Output<?>> components() {
+    return components;
+  }
+  
+  @Override
+  @SuppressWarnings({"rawtypes", "unchecked"})
+  public Iterator<Operand<Object>> iterator() {
+    return (Iterator) components.iterator();
+  }
+  
+  private List<Output<?>> components;
+  
+  private QueueDequeue(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    int componentsLength = operation.outputListLength("components");
+    components = Arrays.asList(operation.outputList(outputIdx, componentsLength));
+    outputIdx += componentsLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/QueueDequeueMany.java java-ops/org/tensorflow/op/core/QueueDequeueMany.java
--- java/org/tensorflow/op/core/QueueDequeueMany.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/QueueDequeueMany.java	2018-10-16 20:18:38.402432261 +0900
@@ -0,0 +1,133 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.Iterator;
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Dequeues `n` tuples of one or more tensors from the given queue.
+ * <p>
+ * If the queue is closed and there are fewer than `n` elements, then an
+ * OutOfRange error is returned.
+ * <p>
+ * This operation concatenates queue-element component tensors along the
+ * 0th dimension to make a single component tensor.  All of the components
+ * in the dequeued tuple will have size `n` in the 0th dimension.
+ * <p>
+ * This operation has `k` outputs, where `k` is the number of components in
+ * the tuples stored in the given queue, and output `i` is the ith
+ * component of the dequeued tuple.
+ * <p>
+ * N.B. If the queue is empty, this operation will block until `n` elements
+ * have been dequeued (or 'timeout_ms' elapses, if specified).
+ */
+@Operator
+public final class QueueDequeueMany extends PrimitiveOp implements Iterable<Operand<Object>> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.QueueDequeueMany}
+   */
+  public static class Options {
+    
+    /**
+     * @param timeoutMs If the queue has fewer than n elements, this operation
+     * will block for up to timeout_ms milliseconds.
+     * Note: This option is not supported yet.
+     */
+    public Options timeoutMs(Long timeoutMs) {
+      this.timeoutMs = timeoutMs;
+      return this;
+    }
+    
+    private Long timeoutMs;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new QueueDequeueMany operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param handle The handle to a queue.
+   * @param n The number of tuples to dequeue.
+   * @param componentTypes The type of each component in a tuple.
+   * @param options carries optional attributes values
+   * @return a new instance of QueueDequeueMany
+   */
+  public static QueueDequeueMany create(Scope scope, Operand<?> handle, Operand<Integer> n, List<Class<?>> componentTypes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("QueueDequeueManyV2", scope.makeOpName("QueueDequeueMany"));
+    opBuilder.addInput(handle.asOutput());
+    opBuilder.addInput(n.asOutput());
+    DataType[] componentTypesArray = new DataType[componentTypes.size()];
+    for (int i = 0; i < componentTypesArray.length; ++i) {
+      componentTypesArray[i] = DataType.fromClass(componentTypes.get(i));
+    }
+    opBuilder.setAttr("component_types", componentTypesArray);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.timeoutMs != null) {
+          opBuilder.setAttr("timeout_ms", opts.timeoutMs);
+        }
+      }
+    }
+    return new QueueDequeueMany(opBuilder.build());
+  }
+  
+  /**
+   * @param timeoutMs If the queue has fewer than n elements, this operation
+   * will block for up to timeout_ms milliseconds.
+   * Note: This option is not supported yet.
+   */
+  public static Options timeoutMs(Long timeoutMs) {
+    return new Options().timeoutMs(timeoutMs);
+  }
+  
+  /**
+   * One or more tensors that were dequeued as a tuple.
+   */
+  public List<Output<?>> components() {
+    return components;
+  }
+  
+  @Override
+  @SuppressWarnings({"rawtypes", "unchecked"})
+  public Iterator<Operand<Object>> iterator() {
+    return (Iterator) components.iterator();
+  }
+  
+  private List<Output<?>> components;
+  
+  private QueueDequeueMany(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    int componentsLength = operation.outputListLength("components");
+    components = Arrays.asList(operation.outputList(outputIdx, componentsLength));
+    outputIdx += componentsLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/QueueDequeueUpTo.java java-ops/org/tensorflow/op/core/QueueDequeueUpTo.java
--- java/org/tensorflow/op/core/QueueDequeueUpTo.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/QueueDequeueUpTo.java	2018-10-16 20:18:38.403432261 +0900
@@ -0,0 +1,137 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.Iterator;
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Dequeues `n` tuples of one or more tensors from the given queue.
+ * <p>
+ * This operation is not supported by all queues.  If a queue does not support
+ * DequeueUpTo, then an Unimplemented error is returned.
+ * <p>
+ * If the queue is closed and there are more than 0 but less than `n`
+ * elements remaining, then instead of returning an OutOfRange error like
+ * QueueDequeueMany, less than `n` elements are returned immediately.  If
+ * the queue is closed and there are 0 elements left in the queue, then
+ * an OutOfRange error is returned just like in QueueDequeueMany.
+ * Otherwise the behavior is identical to QueueDequeueMany:
+ * <p>
+ * This operation concatenates queue-element component tensors along the
+ * 0th dimension to make a single component tensor.  All of the components
+ * in the dequeued tuple will have size n in the 0th dimension.
+ * <p>
+ * This operation has `k` outputs, where `k` is the number of components in
+ * the tuples stored in the given queue, and output `i` is the ith
+ * component of the dequeued tuple.
+ */
+@Operator
+public final class QueueDequeueUpTo extends PrimitiveOp implements Iterable<Operand<Object>> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.QueueDequeueUpTo}
+   */
+  public static class Options {
+    
+    /**
+     * @param timeoutMs If the queue has fewer than n elements, this operation
+     * will block for up to timeout_ms milliseconds.
+     * Note: This option is not supported yet.
+     */
+    public Options timeoutMs(Long timeoutMs) {
+      this.timeoutMs = timeoutMs;
+      return this;
+    }
+    
+    private Long timeoutMs;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new QueueDequeueUpTo operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param handle The handle to a queue.
+   * @param n The number of tuples to dequeue.
+   * @param componentTypes The type of each component in a tuple.
+   * @param options carries optional attributes values
+   * @return a new instance of QueueDequeueUpTo
+   */
+  public static QueueDequeueUpTo create(Scope scope, Operand<?> handle, Operand<Integer> n, List<Class<?>> componentTypes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("QueueDequeueUpToV2", scope.makeOpName("QueueDequeueUpTo"));
+    opBuilder.addInput(handle.asOutput());
+    opBuilder.addInput(n.asOutput());
+    DataType[] componentTypesArray = new DataType[componentTypes.size()];
+    for (int i = 0; i < componentTypesArray.length; ++i) {
+      componentTypesArray[i] = DataType.fromClass(componentTypes.get(i));
+    }
+    opBuilder.setAttr("component_types", componentTypesArray);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.timeoutMs != null) {
+          opBuilder.setAttr("timeout_ms", opts.timeoutMs);
+        }
+      }
+    }
+    return new QueueDequeueUpTo(opBuilder.build());
+  }
+  
+  /**
+   * @param timeoutMs If the queue has fewer than n elements, this operation
+   * will block for up to timeout_ms milliseconds.
+   * Note: This option is not supported yet.
+   */
+  public static Options timeoutMs(Long timeoutMs) {
+    return new Options().timeoutMs(timeoutMs);
+  }
+  
+  /**
+   * One or more tensors that were dequeued as a tuple.
+   */
+  public List<Output<?>> components() {
+    return components;
+  }
+  
+  @Override
+  @SuppressWarnings({"rawtypes", "unchecked"})
+  public Iterator<Operand<Object>> iterator() {
+    return (Iterator) components.iterator();
+  }
+  
+  private List<Output<?>> components;
+  
+  private QueueDequeueUpTo(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    int componentsLength = operation.outputListLength("components");
+    components = Arrays.asList(operation.outputList(outputIdx, componentsLength));
+    outputIdx += componentsLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/QueueEnqueue.java java-ops/org/tensorflow/op/core/QueueEnqueue.java
--- java/org/tensorflow/op/core/QueueEnqueue.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/QueueEnqueue.java	2018-10-16 20:18:38.404432260 +0900
@@ -0,0 +1,97 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Enqueues a tuple of one or more tensors in the given queue.
+ * <p>
+ * The components input has k elements, which correspond to the components of
+ * tuples stored in the given queue.
+ * <p>
+ * N.B. If the queue is full, this operation will block until the given
+ * element has been enqueued (or 'timeout_ms' elapses, if specified).
+ */
+@Operator
+public final class QueueEnqueue extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.QueueEnqueue}
+   */
+  public static class Options {
+    
+    /**
+     * @param timeoutMs If the queue is full, this operation will block for up to
+     * timeout_ms milliseconds.
+     * Note: This option is not supported yet.
+     */
+    public Options timeoutMs(Long timeoutMs) {
+      this.timeoutMs = timeoutMs;
+      return this;
+    }
+    
+    private Long timeoutMs;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new QueueEnqueue operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param handle The handle to a queue.
+   * @param components One or more tensors from which the enqueued tensors should be taken.
+   * @param options carries optional attributes values
+   * @return a new instance of QueueEnqueue
+   */
+  public static QueueEnqueue create(Scope scope, Operand<?> handle, Iterable<Operand<?>> components, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("QueueEnqueueV2", scope.makeOpName("QueueEnqueue"));
+    opBuilder.addInput(handle.asOutput());
+    opBuilder.addInputList(Operands.asOutputs(components));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.timeoutMs != null) {
+          opBuilder.setAttr("timeout_ms", opts.timeoutMs);
+        }
+      }
+    }
+    return new QueueEnqueue(opBuilder.build());
+  }
+  
+  /**
+   * @param timeoutMs If the queue is full, this operation will block for up to
+   * timeout_ms milliseconds.
+   * Note: This option is not supported yet.
+   */
+  public static Options timeoutMs(Long timeoutMs) {
+    return new Options().timeoutMs(timeoutMs);
+  }
+  
+  
+  private QueueEnqueue(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/QueueEnqueueMany.java java-ops/org/tensorflow/op/core/QueueEnqueueMany.java
--- java/org/tensorflow/op/core/QueueEnqueueMany.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/QueueEnqueueMany.java	2018-10-16 20:18:38.404432260 +0900
@@ -0,0 +1,102 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Enqueues zero or more tuples of one or more tensors in the given queue.
+ * <p>
+ * This operation slices each component tensor along the 0th dimension to
+ * make multiple queue elements. All of the tuple components must have the
+ * same size in the 0th dimension.
+ * <p>
+ * The components input has k elements, which correspond to the components of
+ * tuples stored in the given queue.
+ * <p>
+ * N.B. If the queue is full, this operation will block until the given
+ * elements have been enqueued (or 'timeout_ms' elapses, if specified).
+ */
+@Operator
+public final class QueueEnqueueMany extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.QueueEnqueueMany}
+   */
+  public static class Options {
+    
+    /**
+     * @param timeoutMs If the queue is too full, this operation will block for up
+     * to timeout_ms milliseconds.
+     * Note: This option is not supported yet.
+     */
+    public Options timeoutMs(Long timeoutMs) {
+      this.timeoutMs = timeoutMs;
+      return this;
+    }
+    
+    private Long timeoutMs;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new QueueEnqueueMany operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param handle The handle to a queue.
+   * @param components One or more tensors from which the enqueued tensors should
+   * be taken.
+   * @param options carries optional attributes values
+   * @return a new instance of QueueEnqueueMany
+   */
+  public static QueueEnqueueMany create(Scope scope, Operand<?> handle, Iterable<Operand<?>> components, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("QueueEnqueueManyV2", scope.makeOpName("QueueEnqueueMany"));
+    opBuilder.addInput(handle.asOutput());
+    opBuilder.addInputList(Operands.asOutputs(components));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.timeoutMs != null) {
+          opBuilder.setAttr("timeout_ms", opts.timeoutMs);
+        }
+      }
+    }
+    return new QueueEnqueueMany(opBuilder.build());
+  }
+  
+  /**
+   * @param timeoutMs If the queue is too full, this operation will block for up
+   * to timeout_ms milliseconds.
+   * Note: This option is not supported yet.
+   */
+  public static Options timeoutMs(Long timeoutMs) {
+    return new Options().timeoutMs(timeoutMs);
+  }
+  
+  
+  private QueueEnqueueMany(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/QueueIsClosed.java java-ops/org/tensorflow/op/core/QueueIsClosed.java
--- java/org/tensorflow/op/core/QueueIsClosed.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/QueueIsClosed.java	2018-10-16 20:18:38.404432260 +0900
@@ -0,0 +1,68 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns true if queue is closed.
+ * <p>
+ * This operation returns true if the queue is closed and false if the queue
+ * is open.
+ */
+@Operator
+public final class QueueIsClosed extends PrimitiveOp implements Operand<Boolean> {
+  
+  /**
+   * Factory method to create a class to wrap a new QueueIsClosed operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param handle The handle to a queue.
+   * @return a new instance of QueueIsClosed
+   */
+  public static QueueIsClosed create(Scope scope, Operand<String> handle) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("QueueIsClosed", scope.makeOpName("QueueIsClosed"));
+    opBuilder.addInput(handle.asOutput());
+    return new QueueIsClosed(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<Boolean> isClosed() {
+    return isClosed;
+  }
+  
+  @Override
+  public Output<Boolean> asOutput() {
+    return isClosed;
+  }
+  
+  private Output<Boolean> isClosed;
+  
+  private QueueIsClosed(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    isClosed = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/QueueIsClosedV2.java java-ops/org/tensorflow/op/core/QueueIsClosedV2.java
--- java/org/tensorflow/op/core/QueueIsClosedV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/QueueIsClosedV2.java	2018-10-16 20:18:38.404432260 +0900
@@ -0,0 +1,68 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns true if queue is closed.
+ * <p>
+ * This operation returns true if the queue is closed and false if the queue
+ * is open.
+ */
+@Operator
+public final class QueueIsClosedV2 extends PrimitiveOp implements Operand<Boolean> {
+  
+  /**
+   * Factory method to create a class to wrap a new QueueIsClosedV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param handle The handle to a queue.
+   * @return a new instance of QueueIsClosedV2
+   */
+  public static QueueIsClosedV2 create(Scope scope, Operand<?> handle) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("QueueIsClosedV2", scope.makeOpName("QueueIsClosedV2"));
+    opBuilder.addInput(handle.asOutput());
+    return new QueueIsClosedV2(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<Boolean> isClosed() {
+    return isClosed;
+  }
+  
+  @Override
+  public Output<Boolean> asOutput() {
+    return isClosed;
+  }
+  
+  private Output<Boolean> isClosed;
+  
+  private QueueIsClosedV2(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    isClosed = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/QueueSize.java java-ops/org/tensorflow/op/core/QueueSize.java
--- java/org/tensorflow/op/core/QueueSize.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/QueueSize.java	2018-10-16 20:18:38.405432259 +0900
@@ -0,0 +1,66 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the number of elements in the given queue.
+ */
+@Operator
+public final class QueueSize extends PrimitiveOp implements Operand<Integer> {
+  
+  /**
+   * Factory method to create a class to wrap a new QueueSize operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param handle The handle to a queue.
+   * @return a new instance of QueueSize
+   */
+  public static QueueSize create(Scope scope, Operand<?> handle) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("QueueSizeV2", scope.makeOpName("QueueSize"));
+    opBuilder.addInput(handle.asOutput());
+    return new QueueSize(opBuilder.build());
+  }
+  
+  /**
+   * The number of elements in the given queue.
+   */
+  public Output<Integer> size() {
+    return size;
+  }
+  
+  @Override
+  public Output<Integer> asOutput() {
+    return size;
+  }
+  
+  private Output<Integer> size;
+  
+  private QueueSize(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    size = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/RandomCrop.java java-ops/org/tensorflow/op/core/RandomCrop.java
--- java/org/tensorflow/op/core/RandomCrop.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/RandomCrop.java	2018-10-16 20:18:38.407432258 +0900
@@ -0,0 +1,134 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Randomly crop `image`.
+ * <p>
+ * `size` is a 1-D int64 tensor with 2 elements representing the crop height and
+ * width.  The values must be non negative.
+ * <p>
+ * This Op picks a random location in `image` and crops a `height` by `width`
+ * rectangle from that location.  The random location is picked so the cropped
+ * area will fit inside the original image.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class RandomCrop<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.RandomCrop}
+   */
+  public static class Options {
+    
+    /**
+     * @param seed If either seed or seed2 are set to be non-zero, the random number
+     * generator is seeded by the given seed.  Otherwise, it is seeded by a
+     * random seed.
+     */
+    public Options seed(Long seed) {
+      this.seed = seed;
+      return this;
+    }
+    
+    /**
+     * @param seed2 An second seed to avoid seed collision.
+     */
+    public Options seed2(Long seed2) {
+      this.seed2 = seed2;
+      return this;
+    }
+    
+    private Long seed;
+    private Long seed2;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new RandomCrop operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param image 3-D of shape `[height, width, channels]`.
+   * @param size 1-D of length 2 containing: `crop_height`, `crop_width`..
+   * @param options carries optional attributes values
+   * @return a new instance of RandomCrop
+   */
+  public static <T extends Number> RandomCrop<T> create(Scope scope, Operand<T> image, Operand<Long> size, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("RandomCrop", scope.makeOpName("RandomCrop"));
+    opBuilder.addInput(image.asOutput());
+    opBuilder.addInput(size.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.seed != null) {
+          opBuilder.setAttr("seed", opts.seed);
+        }
+        if (opts.seed2 != null) {
+          opBuilder.setAttr("seed2", opts.seed2);
+        }
+      }
+    }
+    return new RandomCrop<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param seed If either seed or seed2 are set to be non-zero, the random number
+   * generator is seeded by the given seed.  Otherwise, it is seeded by a
+   * random seed.
+   */
+  public static Options seed(Long seed) {
+    return new Options().seed(seed);
+  }
+  
+  /**
+   * @param seed2 An second seed to avoid seed collision.
+   */
+  public static Options seed2(Long seed2) {
+    return new Options().seed2(seed2);
+  }
+  
+  /**
+   * 3-D of shape `[crop_height, crop_width, channels].`
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private RandomCrop(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/RandomDataset.java java-ops/org/tensorflow/op/core/RandomDataset.java
--- java/org/tensorflow/op/core/RandomDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/RandomDataset.java	2018-10-16 20:18:38.408432257 +0900
@@ -0,0 +1,85 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Creates a Dataset that returns pseudorandom numbers.
+ */
+@Operator
+public final class RandomDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new RandomDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param seed A scalar seed for the random number generator. If either seed or
+   * seed2 is set to be non-zero, the random number generator is seeded
+   * by the given seed.  Otherwise, a random seed is used.
+   * @param seed2 A second scalar seed to avoid seed collision.
+   * @param outputTypes 
+   * @param outputShapes 
+   * @return a new instance of RandomDataset
+   */
+  public static RandomDataset create(Scope scope, Operand<Long> seed, Operand<Long> seed2, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("RandomDataset", scope.makeOpName("RandomDataset"));
+    opBuilder.addInput(seed.asOutput());
+    opBuilder.addInput(seed2.asOutput());
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new RandomDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private RandomDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/RandomGammaGrad.java java-ops/org/tensorflow/op/core/RandomGammaGrad.java
--- java/org/tensorflow/op/core/RandomGammaGrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/RandomGammaGrad.java	2018-10-16 20:18:38.408432257 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Computes the derivative of a Gamma random sample w.r.t. `alpha`.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+public final class RandomGammaGrad<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new RandomGammaGrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param alpha 
+   * @param sample 
+   * @return a new instance of RandomGammaGrad
+   */
+  public static <T extends Number> RandomGammaGrad<T> create(Scope scope, Operand<T> alpha, Operand<T> sample) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("RandomGammaGrad", scope.makeOpName("RandomGammaGrad"));
+    opBuilder.addInput(alpha.asOutput());
+    opBuilder.addInput(sample.asOutput());
+    return new RandomGammaGrad<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private RandomGammaGrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/RandomGamma.java java-ops/org/tensorflow/op/core/RandomGamma.java
--- java/org/tensorflow/op/core/RandomGamma.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/RandomGamma.java	2018-10-16 20:18:38.408432257 +0900
@@ -0,0 +1,135 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Outputs random values from the Gamma distribution(s) described by alpha.
+ * <p>
+ * This op uses the algorithm by Marsaglia et al. to acquire samples via
+ * transformation-rejection from pairs of uniform and normal random variables.
+ * See http://dl.acm.org/citation.cfm?id=358414
+ * 
+ * @param <U> data type for {@code output()} output
+ */
+@Operator
+public final class RandomGamma<U extends Number> extends PrimitiveOp implements Operand<U> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.RandomGamma}
+   */
+  public static class Options {
+    
+    /**
+     * @param seed If either `seed` or `seed2` are set to be non-zero, the random number
+     * generator is seeded by the given seed.  Otherwise, it is seeded by a
+     * random seed.
+     */
+    public Options seed(Long seed) {
+      this.seed = seed;
+      return this;
+    }
+    
+    /**
+     * @param seed2 A second seed to avoid seed collision.
+     */
+    public Options seed2(Long seed2) {
+      this.seed2 = seed2;
+      return this;
+    }
+    
+    private Long seed;
+    private Long seed2;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new RandomGamma operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param shape 1-D integer tensor. Shape of independent samples to draw from each
+   * distribution described by the shape parameters given in alpha.
+   * @param alpha A tensor in which each scalar is a "shape" parameter describing the
+   * associated gamma distribution.
+   * @param options carries optional attributes values
+   * @return a new instance of RandomGamma
+   */
+  public static <U extends Number, T extends Number> RandomGamma<U> create(Scope scope, Operand<T> shape, Operand<U> alpha, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("RandomGamma", scope.makeOpName("RandomGamma"));
+    opBuilder.addInput(shape.asOutput());
+    opBuilder.addInput(alpha.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.seed != null) {
+          opBuilder.setAttr("seed", opts.seed);
+        }
+        if (opts.seed2 != null) {
+          opBuilder.setAttr("seed2", opts.seed2);
+        }
+      }
+    }
+    return new RandomGamma<U>(opBuilder.build());
+  }
+  
+  /**
+   * @param seed If either `seed` or `seed2` are set to be non-zero, the random number
+   * generator is seeded by the given seed.  Otherwise, it is seeded by a
+   * random seed.
+   */
+  public static Options seed(Long seed) {
+    return new Options().seed(seed);
+  }
+  
+  /**
+   * @param seed2 A second seed to avoid seed collision.
+   */
+  public static Options seed2(Long seed2) {
+    return new Options().seed2(seed2);
+  }
+  
+  /**
+   * A tensor with shape `shape + shape(alpha)`. Each slice
+   * `[:, ..., :, i0, i1, ...iN]` contains the samples drawn for
+   * `alpha[i0, i1, ...iN]`. The dtype of the output matches the dtype of alpha.
+   */
+  public Output<U> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<U> asOutput() {
+    return output;
+  }
+  
+  private Output<U> output;
+  
+  private RandomGamma(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/RandomNormal.java java-ops/org/tensorflow/op/core/RandomNormal.java
--- java/org/tensorflow/op/core/RandomNormal.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/RandomNormal.java	2018-10-16 20:18:38.411432255 +0900
@@ -0,0 +1,130 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Outputs random values from a normal distribution.
+ * <p>
+ * The generated values will have mean 0 and standard deviation 1.
+ * 
+ * @param <U> data type for {@code output()} output
+ */
+@Operator
+public final class RandomNormal<U extends Number> extends PrimitiveOp implements Operand<U> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.RandomNormal}
+   */
+  public static class Options {
+    
+    /**
+     * @param seed If either `seed` or `seed2` are set to be non-zero, the random number
+     * generator is seeded by the given seed.  Otherwise, it is seeded by a
+     * random seed.
+     */
+    public Options seed(Long seed) {
+      this.seed = seed;
+      return this;
+    }
+    
+    /**
+     * @param seed2 A second seed to avoid seed collision.
+     */
+    public Options seed2(Long seed2) {
+      this.seed2 = seed2;
+      return this;
+    }
+    
+    private Long seed;
+    private Long seed2;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new RandomNormal operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param shape The shape of the output tensor.
+   * @param dtype The type of the output.
+   * @param options carries optional attributes values
+   * @return a new instance of RandomNormal
+   */
+  public static <U extends Number, T extends Number> RandomNormal<U> create(Scope scope, Operand<T> shape, Class<U> dtype, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("RandomStandardNormal", scope.makeOpName("RandomNormal"));
+    opBuilder.addInput(shape.asOutput());
+    opBuilder.setAttr("dtype", DataType.fromClass(dtype));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.seed != null) {
+          opBuilder.setAttr("seed", opts.seed);
+        }
+        if (opts.seed2 != null) {
+          opBuilder.setAttr("seed2", opts.seed2);
+        }
+      }
+    }
+    return new RandomNormal<U>(opBuilder.build());
+  }
+  
+  /**
+   * @param seed If either `seed` or `seed2` are set to be non-zero, the random number
+   * generator is seeded by the given seed.  Otherwise, it is seeded by a
+   * random seed.
+   */
+  public static Options seed(Long seed) {
+    return new Options().seed(seed);
+  }
+  
+  /**
+   * @param seed2 A second seed to avoid seed collision.
+   */
+  public static Options seed2(Long seed2) {
+    return new Options().seed2(seed2);
+  }
+  
+  /**
+   * A tensor of the specified shape filled with random normal values.
+   */
+  public Output<U> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<U> asOutput() {
+    return output;
+  }
+  
+  private Output<U> output;
+  
+  private RandomNormal(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/RandomPoisson.java java-ops/org/tensorflow/op/core/RandomPoisson.java
--- java/org/tensorflow/op/core/RandomPoisson.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/RandomPoisson.java	2018-10-16 20:18:38.409432256 +0900
@@ -0,0 +1,122 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Use RandomPoissonV2 instead.
+ * 
+ * @param <U> data type for {@code output()} output
+ */
+@Operator
+public final class RandomPoisson<U extends Number> extends PrimitiveOp implements Operand<U> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.RandomPoisson}
+   */
+  public static class Options {
+    
+    /**
+     * @param seed 
+     */
+    public Options seed(Long seed) {
+      this.seed = seed;
+      return this;
+    }
+    
+    /**
+     * @param seed2 
+     */
+    public Options seed2(Long seed2) {
+      this.seed2 = seed2;
+      return this;
+    }
+    
+    private Long seed;
+    private Long seed2;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new RandomPoisson operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param shape 
+   * @param rate 
+   * @param options carries optional attributes values
+   * @return a new instance of RandomPoisson
+   */
+  public static <U extends Number, T extends Number> RandomPoisson<U> create(Scope scope, Operand<T> shape, Operand<U> rate, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("RandomPoisson", scope.makeOpName("RandomPoisson"));
+    opBuilder.addInput(shape.asOutput());
+    opBuilder.addInput(rate.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.seed != null) {
+          opBuilder.setAttr("seed", opts.seed);
+        }
+        if (opts.seed2 != null) {
+          opBuilder.setAttr("seed2", opts.seed2);
+        }
+      }
+    }
+    return new RandomPoisson<U>(opBuilder.build());
+  }
+  
+  /**
+   * @param seed 
+   */
+  public static Options seed(Long seed) {
+    return new Options().seed(seed);
+  }
+  
+  /**
+   * @param seed2 
+   */
+  public static Options seed2(Long seed2) {
+    return new Options().seed2(seed2);
+  }
+  
+  /**
+   */
+  public Output<U> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<U> asOutput() {
+    return output;
+  }
+  
+  private Output<U> output;
+  
+  private RandomPoisson(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/RandomPoissonV2.java java-ops/org/tensorflow/op/core/RandomPoissonV2.java
--- java/org/tensorflow/op/core/RandomPoissonV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/RandomPoissonV2.java	2018-10-16 20:18:38.409432256 +0900
@@ -0,0 +1,159 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Outputs random values from the Poisson distribution(s) described by rate.
+ * <p>
+ * This op uses two algorithms, depending on rate. If rate >= 10, then
+ * the algorithm by Hormann is used to acquire samples via
+ * transformation-rejection.
+ * See http://www.sciencedirect.com/science/article/pii/0167668793909974.
+ * <p>
+ * Otherwise, Knuth's algorithm is used to acquire samples via multiplying uniform
+ * random variables.
+ * See Donald E. Knuth (1969). Seminumerical Algorithms. The Art of Computer
+ * Programming, Volume 2. Addison Wesley
+ * 
+ * @param <V> data type for {@code output()} output
+ */
+@Operator
+public final class RandomPoissonV2<V extends Number> extends PrimitiveOp implements Operand<V> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.RandomPoissonV2}
+   */
+  public static class Options {
+    
+    /**
+     * @param seed If either `seed` or `seed2` are set to be non-zero, the random number
+     * generator is seeded by the given seed.  Otherwise, it is seeded by a
+     * random seed.
+     */
+    public Options seed(Long seed) {
+      this.seed = seed;
+      return this;
+    }
+    
+    /**
+     * @param seed2 A second seed to avoid seed collision.
+     */
+    public Options seed2(Long seed2) {
+      this.seed2 = seed2;
+      return this;
+    }
+    
+    private Long seed;
+    private Long seed2;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new RandomPoissonV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param shape 1-D integer tensor. Shape of independent samples to draw from each
+   * distribution described by the shape parameters given in rate.
+   * @param rate A tensor in which each scalar is a "rate" parameter describing the
+   * associated poisson distribution.
+   * @param dtype 
+   * @param options carries optional attributes values
+   * @return a new instance of RandomPoissonV2
+   */
+  public static <V extends Number, T extends Number, U extends Number> RandomPoissonV2<V> create(Scope scope, Operand<T> shape, Operand<U> rate, Class<V> dtype, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("RandomPoissonV2", scope.makeOpName("RandomPoissonV2"));
+    opBuilder.addInput(shape.asOutput());
+    opBuilder.addInput(rate.asOutput());
+    opBuilder.setAttr("dtype", DataType.fromClass(dtype));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.seed != null) {
+          opBuilder.setAttr("seed", opts.seed);
+        }
+        if (opts.seed2 != null) {
+          opBuilder.setAttr("seed2", opts.seed2);
+        }
+      }
+    }
+    return new RandomPoissonV2<V>(opBuilder.build());
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new RandomPoissonV2 operation to the graph, using default output types.
+   * 
+   * @param scope current graph scope
+   * @param shape 1-D integer tensor. Shape of independent samples to draw from each
+   * distribution described by the shape parameters given in rate.
+   * @param rate A tensor in which each scalar is a "rate" parameter describing the
+   * associated poisson distribution.
+   * @param options carries optional attributes values
+   * @return a new instance of RandomPoissonV2
+   */
+  public static <T extends Number, U extends Number> RandomPoissonV2<Long> create(Scope scope, Operand<T> shape, Operand<U> rate, Options... options) {
+    return create(scope, shape, rate, Long.class, options);
+  }
+  
+  /**
+   * @param seed If either `seed` or `seed2` are set to be non-zero, the random number
+   * generator is seeded by the given seed.  Otherwise, it is seeded by a
+   * random seed.
+   */
+  public static Options seed(Long seed) {
+    return new Options().seed(seed);
+  }
+  
+  /**
+   * @param seed2 A second seed to avoid seed collision.
+   */
+  public static Options seed2(Long seed2) {
+    return new Options().seed2(seed2);
+  }
+  
+  /**
+   * A tensor with shape `shape + shape(rate)`. Each slice
+   * `[:, ..., :, i0, i1, ...iN]` contains the samples drawn for
+   * `rate[i0, i1, ...iN]`.
+   */
+  public Output<V> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<V> asOutput() {
+    return output;
+  }
+  
+  private Output<V> output;
+  
+  private RandomPoissonV2(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/RandomShuffle.java java-ops/org/tensorflow/op/core/RandomShuffle.java
--- java/org/tensorflow/op/core/RandomShuffle.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/RandomShuffle.java	2018-10-16 20:18:38.410432256 +0900
@@ -0,0 +1,136 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Randomly shuffles a tensor along its first dimension.
+ * <p>
+ *   The tensor is shuffled along dimension 0, such that each `value[j]` is mapped
+ *   to one and only one `output[i]`. For example, a mapping that might occur for a
+ *   3x2 tensor is:
+ * <pre>{@code
+ * [[1, 2],       [[5, 6],
+ *  [3, 4],  ==>   [1, 2],
+ *  [5, 6]]        [3, 4]]
+ * }</pre>
+ * 
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class RandomShuffle<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.RandomShuffle}
+   */
+  public static class Options {
+    
+    /**
+     * @param seed If either `seed` or `seed2` are set to be non-zero, the random number
+     * generator is seeded by the given seed.  Otherwise, it is seeded by a
+     * random seed.
+     */
+    public Options seed(Long seed) {
+      this.seed = seed;
+      return this;
+    }
+    
+    /**
+     * @param seed2 A second seed to avoid seed collision.
+     */
+    public Options seed2(Long seed2) {
+      this.seed2 = seed2;
+      return this;
+    }
+    
+    private Long seed;
+    private Long seed2;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new RandomShuffle operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param value The tensor to be shuffled.
+   * @param options carries optional attributes values
+   * @return a new instance of RandomShuffle
+   */
+  public static <T> RandomShuffle<T> create(Scope scope, Operand<T> value, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("RandomShuffle", scope.makeOpName("RandomShuffle"));
+    opBuilder.addInput(value.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.seed != null) {
+          opBuilder.setAttr("seed", opts.seed);
+        }
+        if (opts.seed2 != null) {
+          opBuilder.setAttr("seed2", opts.seed2);
+        }
+      }
+    }
+    return new RandomShuffle<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param seed If either `seed` or `seed2` are set to be non-zero, the random number
+   * generator is seeded by the given seed.  Otherwise, it is seeded by a
+   * random seed.
+   */
+  public static Options seed(Long seed) {
+    return new Options().seed(seed);
+  }
+  
+  /**
+   * @param seed2 A second seed to avoid seed collision.
+   */
+  public static Options seed2(Long seed2) {
+    return new Options().seed2(seed2);
+  }
+  
+  /**
+   * A tensor of same shape and type as `value`, shuffled along its first
+   * dimension.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private RandomShuffle(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/RandomShuffleQueue.java java-ops/org/tensorflow/op/core/RandomShuffleQueue.java
--- java/org/tensorflow/op/core/RandomShuffleQueue.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/RandomShuffleQueue.java	2018-10-16 20:18:38.411432255 +0900
@@ -0,0 +1,244 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * A queue that randomizes the order of elements.
+ */
+@Operator
+public final class RandomShuffleQueue extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.RandomShuffleQueue}
+   */
+  public static class Options {
+    
+    /**
+     * @param shapes The shape of each component in a value. The length of this attr must
+     * be either 0 or the same as the length of component_types. If the length of
+     * this attr is 0, the shapes of queue elements are not constrained, and
+     * only one element may be dequeued at a time.
+     */
+    public Options shapes(List<Shape> shapes) {
+      this.shapes = shapes;
+      return this;
+    }
+    
+    /**
+     * @param capacity The upper bound on the number of elements in this queue.
+     * Negative numbers mean no limit.
+     */
+    public Options capacity(Long capacity) {
+      this.capacity = capacity;
+      return this;
+    }
+    
+    /**
+     * @param minAfterDequeue Dequeue will block unless there would be this
+     * many elements after the dequeue or the queue is closed. This
+     * ensures a minimum level of mixing of elements.
+     */
+    public Options minAfterDequeue(Long minAfterDequeue) {
+      this.minAfterDequeue = minAfterDequeue;
+      return this;
+    }
+    
+    /**
+     * @param seed If either seed or seed2 is set to be non-zero, the random number
+     * generator is seeded by the given seed.  Otherwise, a random seed is used.
+     */
+    public Options seed(Long seed) {
+      this.seed = seed;
+      return this;
+    }
+    
+    /**
+     * @param seed2 A second seed to avoid seed collision.
+     */
+    public Options seed2(Long seed2) {
+      this.seed2 = seed2;
+      return this;
+    }
+    
+    /**
+     * @param container If non-empty, this queue is placed in the given container.
+     * Otherwise, a default container is used.
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName If non-empty, this queue will be shared under the given name
+     * across multiple sessions.
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private List<Shape> shapes;
+    private Long capacity;
+    private Long minAfterDequeue;
+    private Long seed;
+    private Long seed2;
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new RandomShuffleQueue operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param componentTypes The type of each component in a value.
+   * @param options carries optional attributes values
+   * @return a new instance of RandomShuffleQueue
+   */
+  public static RandomShuffleQueue create(Scope scope, List<Class<?>> componentTypes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("RandomShuffleQueueV2", scope.makeOpName("RandomShuffleQueue"));
+    DataType[] componentTypesArray = new DataType[componentTypes.size()];
+    for (int i = 0; i < componentTypesArray.length; ++i) {
+      componentTypesArray[i] = DataType.fromClass(componentTypes.get(i));
+    }
+    opBuilder.setAttr("component_types", componentTypesArray);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.shapes != null) {
+          Shape[] shapesArray = new Shape[opts.shapes.size()];
+          for (int i = 0; i < shapesArray.length; ++i) {
+            shapesArray[i] = opts.shapes.get(i);
+          }
+          opBuilder.setAttr("shapes", shapesArray);
+        }
+        if (opts.capacity != null) {
+          opBuilder.setAttr("capacity", opts.capacity);
+        }
+        if (opts.minAfterDequeue != null) {
+          opBuilder.setAttr("min_after_dequeue", opts.minAfterDequeue);
+        }
+        if (opts.seed != null) {
+          opBuilder.setAttr("seed", opts.seed);
+        }
+        if (opts.seed2 != null) {
+          opBuilder.setAttr("seed2", opts.seed2);
+        }
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new RandomShuffleQueue(opBuilder.build());
+  }
+  
+  /**
+   * @param shapes The shape of each component in a value. The length of this attr must
+   * be either 0 or the same as the length of component_types. If the length of
+   * this attr is 0, the shapes of queue elements are not constrained, and
+   * only one element may be dequeued at a time.
+   */
+  public static Options shapes(List<Shape> shapes) {
+    return new Options().shapes(shapes);
+  }
+  
+  /**
+   * @param capacity The upper bound on the number of elements in this queue.
+   * Negative numbers mean no limit.
+   */
+  public static Options capacity(Long capacity) {
+    return new Options().capacity(capacity);
+  }
+  
+  /**
+   * @param minAfterDequeue Dequeue will block unless there would be this
+   * many elements after the dequeue or the queue is closed. This
+   * ensures a minimum level of mixing of elements.
+   */
+  public static Options minAfterDequeue(Long minAfterDequeue) {
+    return new Options().minAfterDequeue(minAfterDequeue);
+  }
+  
+  /**
+   * @param seed If either seed or seed2 is set to be non-zero, the random number
+   * generator is seeded by the given seed.  Otherwise, a random seed is used.
+   */
+  public static Options seed(Long seed) {
+    return new Options().seed(seed);
+  }
+  
+  /**
+   * @param seed2 A second seed to avoid seed collision.
+   */
+  public static Options seed2(Long seed2) {
+    return new Options().seed2(seed2);
+  }
+  
+  /**
+   * @param container If non-empty, this queue is placed in the given container.
+   * Otherwise, a default container is used.
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName If non-empty, this queue will be shared under the given name
+   * across multiple sessions.
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   * The handle to the queue.
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private RandomShuffleQueue(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/RandomUniformInt.java java-ops/org/tensorflow/op/core/RandomUniformInt.java
--- java/org/tensorflow/op/core/RandomUniformInt.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/RandomUniformInt.java	2018-10-16 20:18:38.412432254 +0900
@@ -0,0 +1,137 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Outputs random integers from a uniform distribution.
+ * <p>
+ * The generated values are uniform integers in the range `[minval, maxval)`.
+ * The lower bound `minval` is included in the range, while the upper bound
+ * `maxval` is excluded.
+ * <p>
+ * The random integers are slightly biased unless `maxval - minval` is an exact
+ * power of two.  The bias is small for values of `maxval - minval` significantly
+ * smaller than the range of the output (either `2^32` or `2^64`).
+ * 
+ * @param <U> data type for {@code output()} output
+ */
+@Operator
+public final class RandomUniformInt<U extends Number> extends PrimitiveOp implements Operand<U> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.RandomUniformInt}
+   */
+  public static class Options {
+    
+    /**
+     * @param seed If either `seed` or `seed2` are set to be non-zero, the random number
+     * generator is seeded by the given seed.  Otherwise, it is seeded by a
+     * random seed.
+     */
+    public Options seed(Long seed) {
+      this.seed = seed;
+      return this;
+    }
+    
+    /**
+     * @param seed2 A second seed to avoid seed collision.
+     */
+    public Options seed2(Long seed2) {
+      this.seed2 = seed2;
+      return this;
+    }
+    
+    private Long seed;
+    private Long seed2;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new RandomUniformInt operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param shape The shape of the output tensor.
+   * @param minval 0-D.  Inclusive lower bound on the generated integers.
+   * @param maxval 0-D.  Exclusive upper bound on the generated integers.
+   * @param options carries optional attributes values
+   * @return a new instance of RandomUniformInt
+   */
+  public static <U extends Number, T extends Number> RandomUniformInt<U> create(Scope scope, Operand<T> shape, Operand<U> minval, Operand<U> maxval, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("RandomUniformInt", scope.makeOpName("RandomUniformInt"));
+    opBuilder.addInput(shape.asOutput());
+    opBuilder.addInput(minval.asOutput());
+    opBuilder.addInput(maxval.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.seed != null) {
+          opBuilder.setAttr("seed", opts.seed);
+        }
+        if (opts.seed2 != null) {
+          opBuilder.setAttr("seed2", opts.seed2);
+        }
+      }
+    }
+    return new RandomUniformInt<U>(opBuilder.build());
+  }
+  
+  /**
+   * @param seed If either `seed` or `seed2` are set to be non-zero, the random number
+   * generator is seeded by the given seed.  Otherwise, it is seeded by a
+   * random seed.
+   */
+  public static Options seed(Long seed) {
+    return new Options().seed(seed);
+  }
+  
+  /**
+   * @param seed2 A second seed to avoid seed collision.
+   */
+  public static Options seed2(Long seed2) {
+    return new Options().seed2(seed2);
+  }
+  
+  /**
+   * A tensor of the specified shape filled with uniform random integers.
+   */
+  public Output<U> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<U> asOutput() {
+    return output;
+  }
+  
+  private Output<U> output;
+  
+  private RandomUniformInt(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/RandomUniform.java java-ops/org/tensorflow/op/core/RandomUniform.java
--- java/org/tensorflow/op/core/RandomUniform.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/RandomUniform.java	2018-10-16 20:18:38.411432255 +0900
@@ -0,0 +1,131 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Outputs random values from a uniform distribution.
+ * <p>
+ * The generated values follow a uniform distribution in the range `[0, 1)`. The
+ * lower bound 0 is included in the range, while the upper bound 1 is excluded.
+ * 
+ * @param <U> data type for {@code output()} output
+ */
+@Operator
+public final class RandomUniform<U extends Number> extends PrimitiveOp implements Operand<U> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.RandomUniform}
+   */
+  public static class Options {
+    
+    /**
+     * @param seed If either `seed` or `seed2` are set to be non-zero, the random number
+     * generator is seeded by the given seed.  Otherwise, it is seeded by a
+     * random seed.
+     */
+    public Options seed(Long seed) {
+      this.seed = seed;
+      return this;
+    }
+    
+    /**
+     * @param seed2 A second seed to avoid seed collision.
+     */
+    public Options seed2(Long seed2) {
+      this.seed2 = seed2;
+      return this;
+    }
+    
+    private Long seed;
+    private Long seed2;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new RandomUniform operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param shape The shape of the output tensor.
+   * @param dtype The type of the output.
+   * @param options carries optional attributes values
+   * @return a new instance of RandomUniform
+   */
+  public static <U extends Number, T extends Number> RandomUniform<U> create(Scope scope, Operand<T> shape, Class<U> dtype, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("RandomUniform", scope.makeOpName("RandomUniform"));
+    opBuilder.addInput(shape.asOutput());
+    opBuilder.setAttr("dtype", DataType.fromClass(dtype));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.seed != null) {
+          opBuilder.setAttr("seed", opts.seed);
+        }
+        if (opts.seed2 != null) {
+          opBuilder.setAttr("seed2", opts.seed2);
+        }
+      }
+    }
+    return new RandomUniform<U>(opBuilder.build());
+  }
+  
+  /**
+   * @param seed If either `seed` or `seed2` are set to be non-zero, the random number
+   * generator is seeded by the given seed.  Otherwise, it is seeded by a
+   * random seed.
+   */
+  public static Options seed(Long seed) {
+    return new Options().seed(seed);
+  }
+  
+  /**
+   * @param seed2 A second seed to avoid seed collision.
+   */
+  public static Options seed2(Long seed2) {
+    return new Options().seed2(seed2);
+  }
+  
+  /**
+   * A tensor of the specified shape filled with uniform random values.
+   */
+  public Output<U> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<U> asOutput() {
+    return output;
+  }
+  
+  private Output<U> output;
+  
+  private RandomUniform(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/RangeDataset.java java-ops/org/tensorflow/op/core/RangeDataset.java
--- java/org/tensorflow/op/core/RangeDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/RangeDataset.java	2018-10-16 20:18:38.413432254 +0900
@@ -0,0 +1,85 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Creates a dataset with a range of values. Corresponds to python's xrange.
+ */
+@Operator
+public final class RangeDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new RangeDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param start corresponds to start in python's xrange().
+   * @param stop corresponds to stop in python's xrange().
+   * @param step corresponds to step in python's xrange().
+   * @param outputTypes 
+   * @param outputShapes 
+   * @return a new instance of RangeDataset
+   */
+  public static RangeDataset create(Scope scope, Operand<Long> start, Operand<Long> stop, Operand<Long> step, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("RangeDataset", scope.makeOpName("RangeDataset"));
+    opBuilder.addInput(start.asOutput());
+    opBuilder.addInput(stop.asOutput());
+    opBuilder.addInput(step.asOutput());
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new RangeDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private RangeDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Range.java java-ops/org/tensorflow/op/core/Range.java
--- java/org/tensorflow/op/core/Range.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Range.java	2018-10-16 20:18:38.412432254 +0900
@@ -0,0 +1,84 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Creates a sequence of numbers.
+ * <p>
+ * This operation creates a sequence of numbers that begins at `start` and
+ * extends by increments of `delta` up to but not including `limit`.
+ * <p>
+ * For example:
+ * <pre>{@code
+ * # 'start' is 3
+ * # 'limit' is 18
+ * # 'delta' is 3
+ * tf.range(start, limit, delta) ==> [3, 6, 9, 12, 15]
+ * }</pre>
+ * 
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class Range<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Range operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param start 0-D (scalar). First entry in the sequence.
+   * @param limit 0-D (scalar). Upper limit of sequence, exclusive.
+   * @param delta 0-D (scalar). Optional. Default is 1. Number that increments `start`.
+   * @return a new instance of Range
+   */
+  public static <T extends Number> Range<T> create(Scope scope, Operand<T> start, Operand<T> limit, Operand<T> delta) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Range", scope.makeOpName("Range"));
+    opBuilder.addInput(start.asOutput());
+    opBuilder.addInput(limit.asOutput());
+    opBuilder.addInput(delta.asOutput());
+    return new Range<T>(opBuilder.build());
+  }
+  
+  /**
+   * 1-D.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private Range(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Rank.java java-ops/org/tensorflow/op/core/Rank.java
--- java/org/tensorflow/op/core/Rank.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Rank.java	2018-10-16 20:18:38.413432254 +0900
@@ -0,0 +1,77 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns the rank of a tensor.
+ * <p>
+ * This operation returns an integer representing the rank of `input`.
+ * <p>
+ * For example:
+ * <pre>{@code
+ * # 't' is [[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]]
+ * # shape of tensor 't' is [2, 2, 3]
+ * rank(t) ==> 3
+ * }</pre>
+ * <b>Note</b>: The rank of a tensor is not the same as the rank of a matrix. The rank
+ * of a tensor is the number of indices required to uniquely select each element
+ * of the tensor. Rank is also known as "order", "degree", or "ndims."
+ */
+@Operator
+public final class Rank extends PrimitiveOp implements Operand<Integer> {
+  
+  /**
+   * Factory method to create a class to wrap a new Rank operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @return a new instance of Rank
+   */
+  public static <T> Rank create(Scope scope, Operand<T> input) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Rank", scope.makeOpName("Rank"));
+    opBuilder.addInput(input.asOutput());
+    return new Rank(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<Integer> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<Integer> asOutput() {
+    return output;
+  }
+  
+  private Output<Integer> output;
+  
+  private Rank(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ReaderNumRecordsProduced.java java-ops/org/tensorflow/op/core/ReaderNumRecordsProduced.java
--- java/org/tensorflow/op/core/ReaderNumRecordsProduced.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ReaderNumRecordsProduced.java	2018-10-16 20:18:38.414432253 +0900
@@ -0,0 +1,68 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns the number of records this Reader has produced.
+ * <p>
+ * This is the same as the number of ReaderRead executions that have
+ * succeeded.
+ */
+@Operator
+public final class ReaderNumRecordsProduced extends PrimitiveOp implements Operand<Long> {
+  
+  /**
+   * Factory method to create a class to wrap a new ReaderNumRecordsProduced operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param readerHandle Handle to a Reader.
+   * @return a new instance of ReaderNumRecordsProduced
+   */
+  public static ReaderNumRecordsProduced create(Scope scope, Operand<?> readerHandle) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ReaderNumRecordsProducedV2", scope.makeOpName("ReaderNumRecordsProduced"));
+    opBuilder.addInput(readerHandle.asOutput());
+    return new ReaderNumRecordsProduced(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<Long> recordsProduced() {
+    return recordsProduced;
+  }
+  
+  @Override
+  public Output<Long> asOutput() {
+    return recordsProduced;
+  }
+  
+  private Output<Long> recordsProduced;
+  
+  private ReaderNumRecordsProduced(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    recordsProduced = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ReaderNumWorkUnitsCompleted.java java-ops/org/tensorflow/op/core/ReaderNumWorkUnitsCompleted.java
--- java/org/tensorflow/op/core/ReaderNumWorkUnitsCompleted.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ReaderNumWorkUnitsCompleted.java	2018-10-16 20:18:38.414432253 +0900
@@ -0,0 +1,65 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns the number of work units this Reader has finished processing.
+ */
+@Operator
+public final class ReaderNumWorkUnitsCompleted extends PrimitiveOp implements Operand<Long> {
+  
+  /**
+   * Factory method to create a class to wrap a new ReaderNumWorkUnitsCompleted operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param readerHandle Handle to a Reader.
+   * @return a new instance of ReaderNumWorkUnitsCompleted
+   */
+  public static ReaderNumWorkUnitsCompleted create(Scope scope, Operand<?> readerHandle) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ReaderNumWorkUnitsCompletedV2", scope.makeOpName("ReaderNumWorkUnitsCompleted"));
+    opBuilder.addInput(readerHandle.asOutput());
+    return new ReaderNumWorkUnitsCompleted(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<Long> unitsCompleted() {
+    return unitsCompleted;
+  }
+  
+  @Override
+  public Output<Long> asOutput() {
+    return unitsCompleted;
+  }
+  
+  private Output<Long> unitsCompleted;
+  
+  private ReaderNumWorkUnitsCompleted(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    unitsCompleted = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ReaderRead.java java-ops/org/tensorflow/op/core/ReaderRead.java
--- java/org/tensorflow/op/core/ReaderRead.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ReaderRead.java	2018-10-16 20:18:38.416432252 +0900
@@ -0,0 +1,76 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns the next record (key, value pair) produced by a Reader.
+ * <p>
+ * Will dequeue from the input queue if necessary (e.g. when the
+ * Reader needs to start reading from a new file since it has finished
+ * with the previous file).
+ */
+@Operator
+public final class ReaderRead extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new ReaderRead operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param readerHandle Handle to a Reader.
+   * @param queueHandle Handle to a Queue, with string work items.
+   * @return a new instance of ReaderRead
+   */
+  public static ReaderRead create(Scope scope, Operand<?> readerHandle, Operand<?> queueHandle) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ReaderReadV2", scope.makeOpName("ReaderRead"));
+    opBuilder.addInput(readerHandle.asOutput());
+    opBuilder.addInput(queueHandle.asOutput());
+    return new ReaderRead(opBuilder.build());
+  }
+  
+  /**
+   * A scalar.
+   */
+  public Output<String> key() {
+    return key;
+  }
+  
+  /**
+   * A scalar.
+   */
+  public Output<String> value() {
+    return value;
+  }
+  
+  private Output<String> key;
+  private Output<String> value;
+  
+  private ReaderRead(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    key = operation.output(outputIdx++);
+    value = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ReaderReadUpTo.java java-ops/org/tensorflow/op/core/ReaderReadUpTo.java
--- java/org/tensorflow/op/core/ReaderReadUpTo.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ReaderReadUpTo.java	2018-10-16 20:18:38.415432252 +0900
@@ -0,0 +1,79 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns up to `num_records` (key, value) pairs produced by a Reader.
+ * <p>
+ * Will dequeue from the input queue if necessary (e.g. when the
+ * Reader needs to start reading from a new file since it has finished
+ * with the previous file).
+ * It may return less than `num_records` even before the last batch.
+ */
+@Operator
+public final class ReaderReadUpTo extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new ReaderReadUpTo operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param readerHandle Handle to a `Reader`.
+   * @param queueHandle Handle to a `Queue`, with string work items.
+   * @param numRecords number of records to read from `Reader`.
+   * @return a new instance of ReaderReadUpTo
+   */
+  public static ReaderReadUpTo create(Scope scope, Operand<?> readerHandle, Operand<?> queueHandle, Operand<Long> numRecords) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ReaderReadUpToV2", scope.makeOpName("ReaderReadUpTo"));
+    opBuilder.addInput(readerHandle.asOutput());
+    opBuilder.addInput(queueHandle.asOutput());
+    opBuilder.addInput(numRecords.asOutput());
+    return new ReaderReadUpTo(opBuilder.build());
+  }
+  
+  /**
+   * A 1-D tensor.
+   */
+  public Output<String> keys() {
+    return keys;
+  }
+  
+  /**
+   * A 1-D tensor.
+   */
+  public Output<String> values() {
+    return values;
+  }
+  
+  private Output<String> keys;
+  private Output<String> values;
+  
+  private ReaderReadUpTo(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    keys = operation.output(outputIdx++);
+    values = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ReaderReset.java java-ops/org/tensorflow/op/core/ReaderReset.java
--- java/org/tensorflow/op/core/ReaderReset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ReaderReset.java	2018-10-16 20:18:38.416432252 +0900
@@ -0,0 +1,50 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Restore a Reader to its initial clean state.
+ */
+@Operator
+public final class ReaderReset extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new ReaderReset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param readerHandle Handle to a Reader.
+   * @return a new instance of ReaderReset
+   */
+  public static ReaderReset create(Scope scope, Operand<?> readerHandle) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ReaderResetV2", scope.makeOpName("ReaderReset"));
+    opBuilder.addInput(readerHandle.asOutput());
+    return new ReaderReset(opBuilder.build());
+  }
+  
+  
+  private ReaderReset(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ReaderRestoreState.java java-ops/org/tensorflow/op/core/ReaderRestoreState.java
--- java/org/tensorflow/op/core/ReaderRestoreState.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ReaderRestoreState.java	2018-10-16 20:18:38.416432252 +0900
@@ -0,0 +1,56 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Restore a reader to a previously saved state.
+ * <p>
+ * Not all Readers support being restored, so this can produce an
+ * Unimplemented error.
+ */
+@Operator
+public final class ReaderRestoreState extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new ReaderRestoreState operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param readerHandle Handle to a Reader.
+   * @param state Result of a ReaderSerializeState of a Reader with type
+   * matching reader_handle.
+   * @return a new instance of ReaderRestoreState
+   */
+  public static ReaderRestoreState create(Scope scope, Operand<?> readerHandle, Operand<String> state) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ReaderRestoreStateV2", scope.makeOpName("ReaderRestoreState"));
+    opBuilder.addInput(readerHandle.asOutput());
+    opBuilder.addInput(state.asOutput());
+    return new ReaderRestoreState(opBuilder.build());
+  }
+  
+  
+  private ReaderRestoreState(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ReaderSerializeState.java java-ops/org/tensorflow/op/core/ReaderSerializeState.java
--- java/org/tensorflow/op/core/ReaderSerializeState.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ReaderSerializeState.java	2018-10-16 20:18:38.417432251 +0900
@@ -0,0 +1,68 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Produce a string tensor that encodes the state of a Reader.
+ * <p>
+ * Not all Readers support being serialized, so this can produce an
+ * Unimplemented error.
+ */
+@Operator
+public final class ReaderSerializeState extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Factory method to create a class to wrap a new ReaderSerializeState operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param readerHandle Handle to a Reader.
+   * @return a new instance of ReaderSerializeState
+   */
+  public static ReaderSerializeState create(Scope scope, Operand<?> readerHandle) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ReaderSerializeStateV2", scope.makeOpName("ReaderSerializeState"));
+    opBuilder.addInput(readerHandle.asOutput());
+    return new ReaderSerializeState(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<String> state() {
+    return state;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return state;
+  }
+  
+  private Output<String> state;
+  
+  private ReaderSerializeState(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    state = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ReadFile.java java-ops/org/tensorflow/op/core/ReadFile.java
--- java/org/tensorflow/op/core/ReadFile.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ReadFile.java	2018-10-16 20:18:38.413432254 +0900
@@ -0,0 +1,65 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Reads and outputs the entire contents of the input filename.
+ */
+@Operator
+public final class ReadFile extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Factory method to create a class to wrap a new ReadFile operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param filename 
+   * @return a new instance of ReadFile
+   */
+  public static ReadFile create(Scope scope, Operand<String> filename) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ReadFile", scope.makeOpName("ReadFile"));
+    opBuilder.addInput(filename.asOutput());
+    return new ReadFile(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<String> contents() {
+    return contents;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return contents;
+  }
+  
+  private Output<String> contents;
+  
+  private ReadFile(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    contents = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ReadVariableOp.java java-ops/org/tensorflow/op/core/ReadVariableOp.java
--- java/org/tensorflow/op/core/ReadVariableOp.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ReadVariableOp.java	2018-10-16 20:18:38.414432253 +0900
@@ -0,0 +1,77 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Reads the value of a variable.
+ * <p>
+ * The tensor returned by this operation is immutable.
+ * <p>
+ * The value returned by this operation is guaranteed to be influenced by all the
+ * writes on which this operation depends directly or indirectly, and to not be
+ * influenced by any of the writes which depend directly or indirectly on this
+ * operation.
+ * 
+ * @param <T> data type for {@code value()} output
+ */
+@Operator
+public final class ReadVariableOp<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new ReadVariableOp operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param resource handle to the resource in which to store the variable.
+   * @param dtype the dtype of the value.
+   * @return a new instance of ReadVariableOp
+   */
+  public static <T> ReadVariableOp<T> create(Scope scope, Operand<?> resource, Class<T> dtype) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ReadVariableOp", scope.makeOpName("ReadVariableOp"));
+    opBuilder.addInput(resource.asOutput());
+    opBuilder.setAttr("dtype", DataType.fromClass(dtype));
+    return new ReadVariableOp<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> value() {
+    return value;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return value;
+  }
+  
+  private Output<T> value;
+  
+  private ReadVariableOp(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    value = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/RealDiv.java java-ops/org/tensorflow/op/core/RealDiv.java
--- java/org/tensorflow/op/core/RealDiv.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/RealDiv.java	2018-10-16 20:18:38.418432250 +0900
@@ -0,0 +1,74 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns x / y element-wise for real types.
+ * <p>
+ * If `x` and `y` are reals, this will return the floating-point division.
+ * <p>
+ * <i>NOTE</i>: `Div` supports broadcasting. More about broadcasting
+ * [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
+ * 
+ * @param <T> data type for {@code z()} output
+ */
+@Operator
+public final class RealDiv<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new RealDiv operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param y 
+   * @return a new instance of RealDiv
+   */
+  public static <T> RealDiv<T> create(Scope scope, Operand<T> x, Operand<T> y) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("RealDiv", scope.makeOpName("RealDiv"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(y.asOutput());
+    return new RealDiv<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return z;
+  }
+  
+  private Output<T> z;
+  
+  private RealDiv(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Real.java java-ops/org/tensorflow/op/core/Real.java
--- java/org/tensorflow/op/core/Real.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Real.java	2018-10-16 20:18:38.418432250 +0900
@@ -0,0 +1,93 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns the real part of a complex number.
+ * <p>
+ * Given a tensor `input` of complex numbers, this operation returns a tensor of
+ * type `float` that is the real part of each element in `input`. All elements in
+ * `input` must be complex numbers of the form \\(a + bj\\), where <i>a</i> is the real
+ *  part returned by this operation and <i>b</i> is the imaginary part.
+ * <p>
+ * For example:
+ * <pre>{@code
+ * # tensor 'input' is [-2.25 + 4.75j, 3.25 + 5.75j]
+ * tf.real(input) ==> [-2.25, 3.25]
+ * }</pre>
+ * 
+ * 
+ * @param <U> data type for {@code output()} output
+ */
+@Operator
+public final class Real<U extends Number> extends PrimitiveOp implements Operand<U> {
+  
+  /**
+   * Factory method to create a class to wrap a new Real operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param Tout 
+   * @return a new instance of Real
+   */
+  public static <U extends Number, T> Real<U> create(Scope scope, Operand<T> input, Class<U> Tout) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Real", scope.makeOpName("Real"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.setAttr("Tout", DataType.fromClass(Tout));
+    return new Real<U>(opBuilder.build());
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Real operation to the graph, using default output types.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @return a new instance of Real
+   */
+  public static <T> Real<Float> create(Scope scope, Operand<T> input) {
+    return create(scope, input, Float.class);
+  }
+  
+  /**
+   */
+  public Output<U> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<U> asOutput() {
+    return output;
+  }
+  
+  private Output<U> output;
+  
+  private Real(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ReciprocalGrad.java java-ops/org/tensorflow/op/core/ReciprocalGrad.java
--- java/org/tensorflow/op/core/ReciprocalGrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ReciprocalGrad.java	2018-10-16 20:18:38.419432250 +0900
@@ -0,0 +1,70 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Computes the gradient for the inverse of `x` wrt its input.
+ * <p>
+ * Specifically, `grad = -dy <i> y</i>y`, where `y = 1/x`, and `dy`
+ * is the corresponding input gradient.
+ * 
+ * @param <T> data type for {@code z()} output
+ */
+public final class ReciprocalGrad<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new ReciprocalGrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param y 
+   * @param dy 
+   * @return a new instance of ReciprocalGrad
+   */
+  public static <T> ReciprocalGrad<T> create(Scope scope, Operand<T> y, Operand<T> dy) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ReciprocalGrad", scope.makeOpName("ReciprocalGrad"));
+    opBuilder.addInput(y.asOutput());
+    opBuilder.addInput(dy.asOutput());
+    return new ReciprocalGrad<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return z;
+  }
+  
+  private Output<T> z;
+  
+  private ReciprocalGrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Reciprocal.java java-ops/org/tensorflow/op/core/Reciprocal.java
--- java/org/tensorflow/op/core/Reciprocal.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Reciprocal.java	2018-10-16 20:18:38.419432250 +0900
@@ -0,0 +1,69 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the reciprocal of x element-wise.
+ * <p>
+ * I.e., \\(y = 1 / x\\).
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class Reciprocal<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Reciprocal operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of Reciprocal
+   */
+  public static <T> Reciprocal<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Reciprocal", scope.makeOpName("Reciprocal"));
+    opBuilder.addInput(x.asOutput());
+    return new Reciprocal<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private Reciprocal(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/RecordInput.java java-ops/org/tensorflow/op/core/RecordInput.java
--- java/org/tensorflow/op/core/RecordInput.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/RecordInput.java	2018-10-16 20:18:38.420432249 +0900
@@ -0,0 +1,199 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Emits randomized records.
+ */
+@Operator
+public final class RecordInput extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.RecordInput}
+   */
+  public static class Options {
+    
+    /**
+     * @param fileRandomSeed Random seeds used to produce randomized records.
+     */
+    public Options fileRandomSeed(Long fileRandomSeed) {
+      this.fileRandomSeed = fileRandomSeed;
+      return this;
+    }
+    
+    /**
+     * @param fileShuffleShiftRatio Shifts the list of files after the list is randomly
+     * shuffled.
+     */
+    public Options fileShuffleShiftRatio(Float fileShuffleShiftRatio) {
+      this.fileShuffleShiftRatio = fileShuffleShiftRatio;
+      return this;
+    }
+    
+    /**
+     * @param fileBufferSize The randomization shuffling buffer.
+     */
+    public Options fileBufferSize(Long fileBufferSize) {
+      this.fileBufferSize = fileBufferSize;
+      return this;
+    }
+    
+    /**
+     * @param fileParallelism How many sstables are opened and concurrently iterated over.
+     */
+    public Options fileParallelism(Long fileParallelism) {
+      this.fileParallelism = fileParallelism;
+      return this;
+    }
+    
+    /**
+     * @param batchSize The batch size.
+     */
+    public Options batchSize(Long batchSize) {
+      this.batchSize = batchSize;
+      return this;
+    }
+    
+    /**
+     * @param compressionType The type of compression for the file. Currently ZLIB and
+     * GZIP are supported. Defaults to none.
+     */
+    public Options compressionType(String compressionType) {
+      this.compressionType = compressionType;
+      return this;
+    }
+    
+    private Long fileRandomSeed;
+    private Float fileShuffleShiftRatio;
+    private Long fileBufferSize;
+    private Long fileParallelism;
+    private Long batchSize;
+    private String compressionType;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new RecordInput operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param filePattern Glob pattern for the data files.
+   * @param options carries optional attributes values
+   * @return a new instance of RecordInput
+   */
+  public static RecordInput create(Scope scope, String filePattern, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("RecordInput", scope.makeOpName("RecordInput"));
+    opBuilder.setAttr("file_pattern", filePattern);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.fileRandomSeed != null) {
+          opBuilder.setAttr("file_random_seed", opts.fileRandomSeed);
+        }
+        if (opts.fileShuffleShiftRatio != null) {
+          opBuilder.setAttr("file_shuffle_shift_ratio", opts.fileShuffleShiftRatio);
+        }
+        if (opts.fileBufferSize != null) {
+          opBuilder.setAttr("file_buffer_size", opts.fileBufferSize);
+        }
+        if (opts.fileParallelism != null) {
+          opBuilder.setAttr("file_parallelism", opts.fileParallelism);
+        }
+        if (opts.batchSize != null) {
+          opBuilder.setAttr("batch_size", opts.batchSize);
+        }
+        if (opts.compressionType != null) {
+          opBuilder.setAttr("compression_type", opts.compressionType);
+        }
+      }
+    }
+    return new RecordInput(opBuilder.build());
+  }
+  
+  /**
+   * @param fileRandomSeed Random seeds used to produce randomized records.
+   */
+  public static Options fileRandomSeed(Long fileRandomSeed) {
+    return new Options().fileRandomSeed(fileRandomSeed);
+  }
+  
+  /**
+   * @param fileShuffleShiftRatio Shifts the list of files after the list is randomly
+   * shuffled.
+   */
+  public static Options fileShuffleShiftRatio(Float fileShuffleShiftRatio) {
+    return new Options().fileShuffleShiftRatio(fileShuffleShiftRatio);
+  }
+  
+  /**
+   * @param fileBufferSize The randomization shuffling buffer.
+   */
+  public static Options fileBufferSize(Long fileBufferSize) {
+    return new Options().fileBufferSize(fileBufferSize);
+  }
+  
+  /**
+   * @param fileParallelism How many sstables are opened and concurrently iterated over.
+   */
+  public static Options fileParallelism(Long fileParallelism) {
+    return new Options().fileParallelism(fileParallelism);
+  }
+  
+  /**
+   * @param batchSize The batch size.
+   */
+  public static Options batchSize(Long batchSize) {
+    return new Options().batchSize(batchSize);
+  }
+  
+  /**
+   * @param compressionType The type of compression for the file. Currently ZLIB and
+   * GZIP are supported. Defaults to none.
+   */
+  public static Options compressionType(String compressionType) {
+    return new Options().compressionType(compressionType);
+  }
+  
+  /**
+   * A tensor of shape [batch_size].
+   */
+  public Output<String> records() {
+    return records;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return records;
+  }
+  
+  private Output<String> records;
+  
+  private RecordInput(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    records = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ReduceAll.java java-ops/org/tensorflow/op/core/ReduceAll.java
--- java/org/tensorflow/op/core/ReduceAll.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ReduceAll.java	2018-10-16 20:18:38.156432434 +0900
@@ -0,0 +1,108 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the "logical and" of elements across dimensions of a tensor.
+ * <p>
+ * Reduces `input` along the dimensions given in `axis`. Unless
+ * `keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
+ * `axis`. If `keep_dims` is true, the reduced dimensions are
+ * retained with length 1.
+ */
+@Operator
+public final class ReduceAll extends PrimitiveOp implements Operand<Boolean> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ReduceAll}
+   */
+  public static class Options {
+    
+    /**
+     * @param keepDims If true, retain reduced dimensions with length 1.
+     */
+    public Options keepDims(Boolean keepDims) {
+      this.keepDims = keepDims;
+      return this;
+    }
+    
+    private Boolean keepDims;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ReduceAll operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input The tensor to reduce.
+   * @param axis The dimensions to reduce. Must be in the range
+   * `[-rank(input), rank(input))`.
+   * @param options carries optional attributes values
+   * @return a new instance of ReduceAll
+   */
+  public static <T extends Number> ReduceAll create(Scope scope, Operand<Boolean> input, Operand<T> axis, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("All", scope.makeOpName("ReduceAll"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(axis.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.keepDims != null) {
+          opBuilder.setAttr("keep_dims", opts.keepDims);
+        }
+      }
+    }
+    return new ReduceAll(opBuilder.build());
+  }
+  
+  /**
+   * @param keepDims If true, retain reduced dimensions with length 1.
+   */
+  public static Options keepDims(Boolean keepDims) {
+    return new Options().keepDims(keepDims);
+  }
+  
+  /**
+   * The reduced tensor.
+   */
+  public Output<Boolean> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<Boolean> asOutput() {
+    return output;
+  }
+  
+  private Output<Boolean> output;
+  
+  private ReduceAll(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ReduceAny.java java-ops/org/tensorflow/op/core/ReduceAny.java
--- java/org/tensorflow/op/core/ReduceAny.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ReduceAny.java	2018-10-16 20:18:38.158432433 +0900
@@ -0,0 +1,108 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the "logical or" of elements across dimensions of a tensor.
+ * <p>
+ * Reduces `input` along the dimensions given in `axis`. Unless
+ * `keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
+ * `axis`. If `keep_dims` is true, the reduced dimensions are
+ * retained with length 1.
+ */
+@Operator
+public final class ReduceAny extends PrimitiveOp implements Operand<Boolean> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ReduceAny}
+   */
+  public static class Options {
+    
+    /**
+     * @param keepDims If true, retain reduced dimensions with length 1.
+     */
+    public Options keepDims(Boolean keepDims) {
+      this.keepDims = keepDims;
+      return this;
+    }
+    
+    private Boolean keepDims;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ReduceAny operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input The tensor to reduce.
+   * @param axis The dimensions to reduce. Must be in the range
+   * `[-rank(input), rank(input))`.
+   * @param options carries optional attributes values
+   * @return a new instance of ReduceAny
+   */
+  public static <T extends Number> ReduceAny create(Scope scope, Operand<Boolean> input, Operand<T> axis, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Any", scope.makeOpName("ReduceAny"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(axis.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.keepDims != null) {
+          opBuilder.setAttr("keep_dims", opts.keepDims);
+        }
+      }
+    }
+    return new ReduceAny(opBuilder.build());
+  }
+  
+  /**
+   * @param keepDims If true, retain reduced dimensions with length 1.
+   */
+  public static Options keepDims(Boolean keepDims) {
+    return new Options().keepDims(keepDims);
+  }
+  
+  /**
+   * The reduced tensor.
+   */
+  public Output<Boolean> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<Boolean> asOutput() {
+    return output;
+  }
+  
+  private Output<Boolean> output;
+  
+  private ReduceAny(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ReduceJoin.java java-ops/org/tensorflow/op/core/ReduceJoin.java
--- java/org/tensorflow/op/core/ReduceJoin.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ReduceJoin.java	2018-10-16 20:18:38.421432248 +0900
@@ -0,0 +1,148 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Joins a string Tensor across the given dimensions.
+ * <p>
+ * Computes the string join across dimensions in the given string Tensor of shape
+ * `[\\(d_0, d_1, ..., d_{n-1}\\)]`.  Returns a new Tensor created by joining the input
+ * strings with the given separator (default: empty string).  Negative indices are
+ * counted backwards from the end, with `-1` being equivalent to `n - 1`.  If
+ * indices are not specified, joins across all dimensions beginning from `n - 1`
+ * through `0`.
+ * <p>
+ * For example:
+ * <pre>{@code
+ * # tensor `a` is [["a", "b"], ["c", "d"]]
+ * tf.reduce_join(a, 0) ==> ["ac", "bd"]
+ * tf.reduce_join(a, 1) ==> ["ab", "cd"]
+ * tf.reduce_join(a, -2) = tf.reduce_join(a, 0) ==> ["ac", "bd"]
+ * tf.reduce_join(a, -1) = tf.reduce_join(a, 1) ==> ["ab", "cd"]
+ * tf.reduce_join(a, 0, keep_dims=True) ==> [["ac", "bd"]]
+ * tf.reduce_join(a, 1, keep_dims=True) ==> [["ab"], ["cd"]]
+ * tf.reduce_join(a, 0, separator=".") ==> ["a.c", "b.d"]
+ * tf.reduce_join(a, [0, 1]) ==> "acbd"
+ * tf.reduce_join(a, [1, 0]) ==> "abcd"
+ * tf.reduce_join(a, []) ==> [["a", "b"], ["c", "d"]]
+ * tf.reduce_join(a) = tf.reduce_join(a, [1, 0]) ==> "abcd"
+ * }</pre>
+ * 
+ */
+@Operator
+public final class ReduceJoin extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ReduceJoin}
+   */
+  public static class Options {
+    
+    /**
+     * @param keepDims If `True`, retain reduced dimensions with length `1`.
+     */
+    public Options keepDims(Boolean keepDims) {
+      this.keepDims = keepDims;
+      return this;
+    }
+    
+    /**
+     * @param separator The separator to use when joining.
+     */
+    public Options separator(String separator) {
+      this.separator = separator;
+      return this;
+    }
+    
+    private Boolean keepDims;
+    private String separator;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ReduceJoin operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputs The input to be joined.  All reduced indices must have non-zero size.
+   * @param reductionIndices The dimensions to reduce over.  Dimensions are reduced in the
+   * order specified.  Omitting `reduction_indices` is equivalent to passing
+   * `[n-1, n-2, ..., 0]`.  Negative indices from `-n` to `-1` are supported.
+   * @param options carries optional attributes values
+   * @return a new instance of ReduceJoin
+   */
+  public static ReduceJoin create(Scope scope, Operand<String> inputs, Operand<Integer> reductionIndices, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ReduceJoin", scope.makeOpName("ReduceJoin"));
+    opBuilder.addInput(inputs.asOutput());
+    opBuilder.addInput(reductionIndices.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.keepDims != null) {
+          opBuilder.setAttr("keep_dims", opts.keepDims);
+        }
+        if (opts.separator != null) {
+          opBuilder.setAttr("separator", opts.separator);
+        }
+      }
+    }
+    return new ReduceJoin(opBuilder.build());
+  }
+  
+  /**
+   * @param keepDims If `True`, retain reduced dimensions with length `1`.
+   */
+  public static Options keepDims(Boolean keepDims) {
+    return new Options().keepDims(keepDims);
+  }
+  
+  /**
+   * @param separator The separator to use when joining.
+   */
+  public static Options separator(String separator) {
+    return new Options().separator(separator);
+  }
+  
+  /**
+   * Has shape equal to that of the input with reduced dimensions removed or
+   * set to `1` depending on `keep_dims`.
+   */
+  public Output<String> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return output;
+  }
+  
+  private Output<String> output;
+  
+  private ReduceJoin(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ReduceMax.java java-ops/org/tensorflow/op/core/ReduceMax.java
--- java/org/tensorflow/op/core/ReduceMax.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ReduceMax.java	2018-10-16 20:18:38.344432302 +0900
@@ -0,0 +1,110 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the maximum of elements across dimensions of a tensor.
+ * <p>
+ * Reduces `input` along the dimensions given in `axis`. Unless
+ * `keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
+ * `axis`. If `keep_dims` is true, the reduced dimensions are
+ * retained with length 1.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class ReduceMax<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ReduceMax}
+   */
+  public static class Options {
+    
+    /**
+     * @param keepDims If true, retain reduced dimensions with length 1.
+     */
+    public Options keepDims(Boolean keepDims) {
+      this.keepDims = keepDims;
+      return this;
+    }
+    
+    private Boolean keepDims;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ReduceMax operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input The tensor to reduce.
+   * @param axis The dimensions to reduce. Must be in the range
+   * `[-rank(input), rank(input))`.
+   * @param options carries optional attributes values
+   * @return a new instance of ReduceMax
+   */
+  public static <T, U extends Number> ReduceMax<T> create(Scope scope, Operand<T> input, Operand<U> axis, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Max", scope.makeOpName("ReduceMax"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(axis.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.keepDims != null) {
+          opBuilder.setAttr("keep_dims", opts.keepDims);
+        }
+      }
+    }
+    return new ReduceMax<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param keepDims If true, retain reduced dimensions with length 1.
+   */
+  public static Options keepDims(Boolean keepDims) {
+    return new Options().keepDims(keepDims);
+  }
+  
+  /**
+   * The reduced tensor.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private ReduceMax(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ReduceMean.java java-ops/org/tensorflow/op/core/ReduceMean.java
--- java/org/tensorflow/op/core/ReduceMean.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ReduceMean.java	2018-10-16 20:18:38.353432296 +0900
@@ -0,0 +1,110 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the mean of elements across dimensions of a tensor.
+ * <p>
+ * Reduces `input` along the dimensions given in `axis`. Unless
+ * `keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
+ * `axis`. If `keep_dims` is true, the reduced dimensions are
+ * retained with length 1.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class ReduceMean<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ReduceMean}
+   */
+  public static class Options {
+    
+    /**
+     * @param keepDims If true, retain reduced dimensions with length 1.
+     */
+    public Options keepDims(Boolean keepDims) {
+      this.keepDims = keepDims;
+      return this;
+    }
+    
+    private Boolean keepDims;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ReduceMean operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input The tensor to reduce.
+   * @param axis The dimensions to reduce. Must be in the range
+   * `[-rank(input), rank(input))`.
+   * @param options carries optional attributes values
+   * @return a new instance of ReduceMean
+   */
+  public static <T, U extends Number> ReduceMean<T> create(Scope scope, Operand<T> input, Operand<U> axis, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Mean", scope.makeOpName("ReduceMean"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(axis.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.keepDims != null) {
+          opBuilder.setAttr("keep_dims", opts.keepDims);
+        }
+      }
+    }
+    return new ReduceMean<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param keepDims If true, retain reduced dimensions with length 1.
+   */
+  public static Options keepDims(Boolean keepDims) {
+    return new Options().keepDims(keepDims);
+  }
+  
+  /**
+   * The reduced tensor.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private ReduceMean(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ReduceMin.java java-ops/org/tensorflow/op/core/ReduceMin.java
--- java/org/tensorflow/op/core/ReduceMin.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ReduceMin.java	2018-10-16 20:18:38.355432294 +0900
@@ -0,0 +1,110 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the minimum of elements across dimensions of a tensor.
+ * <p>
+ * Reduces `input` along the dimensions given in `axis`. Unless
+ * `keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
+ * `axis`. If `keep_dims` is true, the reduced dimensions are
+ * retained with length 1.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class ReduceMin<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ReduceMin}
+   */
+  public static class Options {
+    
+    /**
+     * @param keepDims If true, retain reduced dimensions with length 1.
+     */
+    public Options keepDims(Boolean keepDims) {
+      this.keepDims = keepDims;
+      return this;
+    }
+    
+    private Boolean keepDims;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ReduceMin operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input The tensor to reduce.
+   * @param axis The dimensions to reduce. Must be in the range
+   * `[-rank(input), rank(input))`.
+   * @param options carries optional attributes values
+   * @return a new instance of ReduceMin
+   */
+  public static <T, U extends Number> ReduceMin<T> create(Scope scope, Operand<T> input, Operand<U> axis, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Min", scope.makeOpName("ReduceMin"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(axis.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.keepDims != null) {
+          opBuilder.setAttr("keep_dims", opts.keepDims);
+        }
+      }
+    }
+    return new ReduceMin<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param keepDims If true, retain reduced dimensions with length 1.
+   */
+  public static Options keepDims(Boolean keepDims) {
+    return new Options().keepDims(keepDims);
+  }
+  
+  /**
+   * The reduced tensor.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private ReduceMin(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ReduceProd.java java-ops/org/tensorflow/op/core/ReduceProd.java
--- java/org/tensorflow/op/core/ReduceProd.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ReduceProd.java	2018-10-16 20:18:38.388432271 +0900
@@ -0,0 +1,110 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the product of elements across dimensions of a tensor.
+ * <p>
+ * Reduces `input` along the dimensions given in `axis`. Unless
+ * `keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
+ * `axis`. If `keep_dims` is true, the reduced dimensions are
+ * retained with length 1.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class ReduceProd<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ReduceProd}
+   */
+  public static class Options {
+    
+    /**
+     * @param keepDims If true, retain reduced dimensions with length 1.
+     */
+    public Options keepDims(Boolean keepDims) {
+      this.keepDims = keepDims;
+      return this;
+    }
+    
+    private Boolean keepDims;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ReduceProd operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input The tensor to reduce.
+   * @param axis The dimensions to reduce. Must be in the range
+   * `[-rank(input), rank(input))`.
+   * @param options carries optional attributes values
+   * @return a new instance of ReduceProd
+   */
+  public static <T, U extends Number> ReduceProd<T> create(Scope scope, Operand<T> input, Operand<U> axis, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Prod", scope.makeOpName("ReduceProd"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(axis.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.keepDims != null) {
+          opBuilder.setAttr("keep_dims", opts.keepDims);
+        }
+      }
+    }
+    return new ReduceProd<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param keepDims If true, retain reduced dimensions with length 1.
+   */
+  public static Options keepDims(Boolean keepDims) {
+    return new Options().keepDims(keepDims);
+  }
+  
+  /**
+   * The reduced tensor.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private ReduceProd(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ReduceSum.java java-ops/org/tensorflow/op/core/ReduceSum.java
--- java/org/tensorflow/op/core/ReduceSum.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ReduceSum.java	2018-10-16 20:18:38.583432135 +0900
@@ -0,0 +1,110 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the sum of elements across dimensions of a tensor.
+ * <p>
+ * Reduces `input` along the dimensions given in `axis`. Unless
+ * `keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
+ * `axis`. If `keep_dims` is true, the reduced dimensions are
+ * retained with length 1.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class ReduceSum<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ReduceSum}
+   */
+  public static class Options {
+    
+    /**
+     * @param keepDims If true, retain reduced dimensions with length 1.
+     */
+    public Options keepDims(Boolean keepDims) {
+      this.keepDims = keepDims;
+      return this;
+    }
+    
+    private Boolean keepDims;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ReduceSum operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input The tensor to reduce.
+   * @param axis The dimensions to reduce. Must be in the range
+   * `[-rank(input), rank(input))`.
+   * @param options carries optional attributes values
+   * @return a new instance of ReduceSum
+   */
+  public static <T, U extends Number> ReduceSum<T> create(Scope scope, Operand<T> input, Operand<U> axis, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Sum", scope.makeOpName("ReduceSum"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(axis.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.keepDims != null) {
+          opBuilder.setAttr("keep_dims", opts.keepDims);
+        }
+      }
+    }
+    return new ReduceSum<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param keepDims If true, retain reduced dimensions with length 1.
+   */
+  public static Options keepDims(Boolean keepDims) {
+    return new Options().keepDims(keepDims);
+  }
+  
+  /**
+   * The reduced tensor.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private ReduceSum(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/RefEnter.java java-ops/org/tensorflow/op/core/RefEnter.java
--- java/org/tensorflow/op/core/RefEnter.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/RefEnter.java	2018-10-16 20:18:38.421432248 +0900
@@ -0,0 +1,126 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Creates or finds a child frame, and makes `data` available to the child frame.
+ * <p>
+ * The unique `frame_name` is used by the `Executor` to identify frames. If
+ * `is_constant` is true, `output` is a constant in the child frame; otherwise
+ * it may be changed in the child frame. At most `parallel_iterations` iterations
+ * are run in parallel in the child frame.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+public final class RefEnter<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.RefEnter}
+   */
+  public static class Options {
+    
+    /**
+     * @param isConstant If true, the output is constant within the child frame.
+     */
+    public Options isConstant(Boolean isConstant) {
+      this.isConstant = isConstant;
+      return this;
+    }
+    
+    /**
+     * @param parallelIterations The number of iterations allowed to run in parallel.
+     */
+    public Options parallelIterations(Long parallelIterations) {
+      this.parallelIterations = parallelIterations;
+      return this;
+    }
+    
+    private Boolean isConstant;
+    private Long parallelIterations;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new RefEnter operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param data The tensor to be made available to the child frame.
+   * @param frameName The name of the child frame.
+   * @param options carries optional attributes values
+   * @return a new instance of RefEnter
+   */
+  public static <T> RefEnter<T> create(Scope scope, Operand<T> data, String frameName, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("RefEnter", scope.makeOpName("RefEnter"));
+    opBuilder.addInput(data.asOutput());
+    opBuilder.setAttr("frame_name", frameName);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.isConstant != null) {
+          opBuilder.setAttr("is_constant", opts.isConstant);
+        }
+        if (opts.parallelIterations != null) {
+          opBuilder.setAttr("parallel_iterations", opts.parallelIterations);
+        }
+      }
+    }
+    return new RefEnter<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param isConstant If true, the output is constant within the child frame.
+   */
+  public static Options isConstant(Boolean isConstant) {
+    return new Options().isConstant(isConstant);
+  }
+  
+  /**
+   * @param parallelIterations The number of iterations allowed to run in parallel.
+   */
+  public static Options parallelIterations(Long parallelIterations) {
+    return new Options().parallelIterations(parallelIterations);
+  }
+  
+  /**
+   * The same tensor as `data`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private RefEnter(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/RefExit.java java-ops/org/tensorflow/op/core/RefExit.java
--- java/org/tensorflow/op/core/RefExit.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/RefExit.java	2018-10-16 20:18:38.421432248 +0900
@@ -0,0 +1,68 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Exits the current frame to its parent frame.
+ * <p>
+ * Exit makes its input `data` available to the parent frame.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+public final class RefExit<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new RefExit operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param data The tensor to be made available to the parent frame.
+   * @return a new instance of RefExit
+   */
+  public static <T> RefExit<T> create(Scope scope, Operand<T> data) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("RefExit", scope.makeOpName("RefExit"));
+    opBuilder.addInput(data.asOutput());
+    return new RefExit<T>(opBuilder.build());
+  }
+  
+  /**
+   * The same tensor as `data`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private RefExit(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/RefIdentity.java java-ops/org/tensorflow/op/core/RefIdentity.java
--- java/org/tensorflow/op/core/RefIdentity.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/RefIdentity.java	2018-10-16 20:18:38.422432247 +0900
@@ -0,0 +1,65 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Return the same ref tensor as the input ref tensor.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+public final class RefIdentity<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new RefIdentity operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @return a new instance of RefIdentity
+   */
+  public static <T> RefIdentity<T> create(Scope scope, Operand<T> input) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("RefIdentity", scope.makeOpName("RefIdentity"));
+    opBuilder.addInput(input.asOutput());
+    return new RefIdentity<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private RefIdentity(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/RefMerge.java java-ops/org/tensorflow/op/core/RefMerge.java
--- java/org/tensorflow/op/core/RefMerge.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/RefMerge.java	2018-10-16 20:18:38.422432247 +0900
@@ -0,0 +1,76 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Forwards the value of an available tensor from `inputs` to `output`.
+ * <p>
+ * `Merge` waits for at least one of the tensors in `inputs` to become available.
+ * It is usually combined with `Switch` to implement branching.
+ * <p>
+ * `Merge` forwards the first tensor for become available to `output`, and sets
+ * `value_index` to its index in `inputs`.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+public final class RefMerge<T> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new RefMerge operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputs The input tensors, exactly one of which will become available.
+   * @return a new instance of RefMerge
+   */
+  public static <T> RefMerge<T> create(Scope scope, Operand<T> inputs) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("RefMerge", scope.makeOpName("RefMerge"));
+    opBuilder.addInput(inputs.asOutput());
+    return new RefMerge<T>(opBuilder.build());
+  }
+  
+  /**
+   * Will be set to the available input tensor.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  /**
+   * The index of the chosen input tensor in `inputs`.
+   */
+  public Output<Integer> valueIndex() {
+    return valueIndex;
+  }
+  
+  private Output<T> output;
+  private Output<Integer> valueIndex;
+  
+  private RefMerge(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+    valueIndex = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/RefNextIteration.java java-ops/org/tensorflow/op/core/RefNextIteration.java
--- java/org/tensorflow/op/core/RefNextIteration.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/RefNextIteration.java	2018-10-16 20:18:38.422432247 +0900
@@ -0,0 +1,68 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Makes its input available to the next iteration.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class RefNextIteration<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new RefNextIteration operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param data The tensor to be made available to the next iteration.
+   * @return a new instance of RefNextIteration
+   */
+  public static <T> RefNextIteration<T> create(Scope scope, Operand<T> data) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("RefNextIteration", scope.makeOpName("RefNextIteration"));
+    opBuilder.addInput(data.asOutput());
+    return new RefNextIteration<T>(opBuilder.build());
+  }
+  
+  /**
+   * The same tensor as `data`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private RefNextIteration(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/RefSelect.java java-ops/org/tensorflow/op/core/RefSelect.java
--- java/org/tensorflow/op/core/RefSelect.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/RefSelect.java	2018-10-16 20:18:38.423432247 +0900
@@ -0,0 +1,70 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Forwards the `index`th element of `inputs` to `output`.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class RefSelect<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new RefSelect operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param index A scalar that determines the input that gets selected.
+   * @param inputs A list of ref tensors, one of which will be forwarded to `output`.
+   * @return a new instance of RefSelect
+   */
+  public static <T> RefSelect<T> create(Scope scope, Operand<Integer> index, Operand<T> inputs) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("RefSelect", scope.makeOpName("RefSelect"));
+    opBuilder.addInput(index.asOutput());
+    opBuilder.addInput(inputs.asOutput());
+    return new RefSelect<T>(opBuilder.build());
+  }
+  
+  /**
+   * The forwarded tensor.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private RefSelect(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/RefSwitch.java java-ops/org/tensorflow/op/core/RefSwitch.java
--- java/org/tensorflow/op/core/RefSwitch.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/RefSwitch.java	2018-10-16 20:18:38.423432247 +0900
@@ -0,0 +1,79 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Forwards the ref tensor `data` to the output port determined by `pred`.
+ * <p>
+ * If `pred` is true, the `data` input is forwarded to `output_true`. Otherwise,
+ * the data goes to `output_false`.
+ * <p>
+ * See also `Switch` and `Merge`.
+ * 
+ * @param <T> data type for {@code outputFalse()} output
+ */
+@Operator
+public final class RefSwitch<T> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new RefSwitch operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param data The ref tensor to be forwarded to the appropriate output.
+   * @param pred A scalar that specifies which output port will receive data.
+   * @return a new instance of RefSwitch
+   */
+  public static <T> RefSwitch<T> create(Scope scope, Operand<T> data, Operand<Boolean> pred) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("RefSwitch", scope.makeOpName("RefSwitch"));
+    opBuilder.addInput(data.asOutput());
+    opBuilder.addInput(pred.asOutput());
+    return new RefSwitch<T>(opBuilder.build());
+  }
+  
+  /**
+   * If `pred` is false, data will be forwarded to this output.
+   */
+  public Output<T> outputFalse() {
+    return outputFalse;
+  }
+  
+  /**
+   * If `pred` is true, data will be forwarded to this output.
+   */
+  public Output<T> outputTrue() {
+    return outputTrue;
+  }
+  
+  private Output<T> outputFalse;
+  private Output<T> outputTrue;
+  
+  private RefSwitch(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    outputFalse = operation.output(outputIdx++);
+    outputTrue = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/RegexFullMatch.java java-ops/org/tensorflow/op/core/RegexFullMatch.java
--- java/org/tensorflow/op/core/RegexFullMatch.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/RegexFullMatch.java	2018-10-16 20:18:38.423432247 +0900
@@ -0,0 +1,75 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Check if the input matches the regex pattern.
+ * <p>
+ * The input is a string tensor of any shape. The pattern is a scalar
+ * string tensor which is applied to every element of the input tensor.
+ * The boolean values (True or False) of the output tensor indicate
+ * if the input matches the regex pattern provided.
+ * <p>
+ * The pattern follows the re2 syntax (https://github.com/google/re2/wiki/Syntax)
+ */
+@Operator
+public final class RegexFullMatch extends PrimitiveOp implements Operand<Boolean> {
+  
+  /**
+   * Factory method to create a class to wrap a new RegexFullMatch operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input A string tensor of the text to be processed.
+   * @param pattern A scalar string tensor containing the regular expression to match the input.
+   * @return a new instance of RegexFullMatch
+   */
+  public static RegexFullMatch create(Scope scope, Operand<String> input, Operand<String> pattern) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("RegexFullMatch", scope.makeOpName("RegexFullMatch"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(pattern.asOutput());
+    return new RegexFullMatch(opBuilder.build());
+  }
+  
+  /**
+   * A bool tensor with the same shape as `input`.
+   */
+  public Output<Boolean> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<Boolean> asOutput() {
+    return output;
+  }
+  
+  private Output<Boolean> output;
+  
+  private RegexFullMatch(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/RegexReplace.java java-ops/org/tensorflow/op/core/RegexReplace.java
--- java/org/tensorflow/op/core/RegexReplace.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/RegexReplace.java	2018-10-16 20:18:38.424432246 +0900
@@ -0,0 +1,108 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Replaces the match of pattern in input with rewrite.
+ * <p>
+ * It follows the re2 syntax (https://github.com/google/re2/wiki/Syntax)
+ */
+@Operator
+public final class RegexReplace extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.RegexReplace}
+   */
+  public static class Options {
+    
+    /**
+     * @param replaceGlobal If True, the replacement is global, otherwise the replacement
+     * is done only on the first match.
+     */
+    public Options replaceGlobal(Boolean replaceGlobal) {
+      this.replaceGlobal = replaceGlobal;
+      return this;
+    }
+    
+    private Boolean replaceGlobal;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new RegexReplace operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input The text to be processed.
+   * @param pattern The regular expression to match the input.
+   * @param rewrite The rewrite to be applied to the matched expresion.
+   * @param options carries optional attributes values
+   * @return a new instance of RegexReplace
+   */
+  public static RegexReplace create(Scope scope, Operand<String> input, Operand<String> pattern, Operand<String> rewrite, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("RegexReplace", scope.makeOpName("RegexReplace"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(pattern.asOutput());
+    opBuilder.addInput(rewrite.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.replaceGlobal != null) {
+          opBuilder.setAttr("replace_global", opts.replaceGlobal);
+        }
+      }
+    }
+    return new RegexReplace(opBuilder.build());
+  }
+  
+  /**
+   * @param replaceGlobal If True, the replacement is global, otherwise the replacement
+   * is done only on the first match.
+   */
+  public static Options replaceGlobal(Boolean replaceGlobal) {
+    return new Options().replaceGlobal(replaceGlobal);
+  }
+  
+  /**
+   * The text after applying pattern and rewrite.
+   */
+  public Output<String> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return output;
+  }
+  
+  private Output<String> output;
+  
+  private RegexReplace(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Relu6Grad.java java-ops/org/tensorflow/op/core/Relu6Grad.java
--- java/org/tensorflow/op/core/Relu6Grad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Relu6Grad.java	2018-10-16 20:18:38.425432245 +0900
@@ -0,0 +1,70 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Computes rectified linear 6 gradients for a Relu6 operation.
+ * 
+ * @param <T> data type for {@code backprops()} output
+ */
+public final class Relu6Grad<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Relu6Grad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param gradients The backpropagated gradients to the corresponding Relu6 operation.
+   * @param features The features passed as input to the corresponding Relu6 operation, or
+   * its output; using either one produces the same result.
+   * @return a new instance of Relu6Grad
+   */
+  public static <T extends Number> Relu6Grad<T> create(Scope scope, Operand<T> gradients, Operand<T> features) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Relu6Grad", scope.makeOpName("Relu6Grad"));
+    opBuilder.addInput(gradients.asOutput());
+    opBuilder.addInput(features.asOutput());
+    return new Relu6Grad<T>(opBuilder.build());
+  }
+  
+  /**
+   * The gradients:
+   * `gradients * (features > 0) * (features < 6)`.
+   */
+  public Output<T> backprops() {
+    return backprops;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return backprops;
+  }
+  
+  private Output<T> backprops;
+  
+  private Relu6Grad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    backprops = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Relu6.java java-ops/org/tensorflow/op/core/Relu6.java
--- java/org/tensorflow/op/core/Relu6.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Relu6.java	2018-10-16 20:18:38.424432246 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes rectified linear 6: `min(max(features, 0), 6)`.
+ * 
+ * @param <T> data type for {@code activations()} output
+ */
+@Operator
+public final class Relu6<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Relu6 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param features 
+   * @return a new instance of Relu6
+   */
+  public static <T extends Number> Relu6<T> create(Scope scope, Operand<T> features) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Relu6", scope.makeOpName("Relu6"));
+    opBuilder.addInput(features.asOutput());
+    return new Relu6<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> activations() {
+    return activations;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return activations;
+  }
+  
+  private Output<T> activations;
+  
+  private Relu6(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    activations = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ReluGrad.java java-ops/org/tensorflow/op/core/ReluGrad.java
--- java/org/tensorflow/op/core/ReluGrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ReluGrad.java	2018-10-16 20:18:38.425432245 +0900
@@ -0,0 +1,69 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Computes rectified linear gradients for a Relu operation.
+ * 
+ * @param <T> data type for {@code backprops()} output
+ */
+public final class ReluGrad<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new ReluGrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param gradients The backpropagated gradients to the corresponding Relu operation.
+   * @param features The features passed as input to the corresponding Relu operation, OR
+   * the outputs of that operation (both work equivalently).
+   * @return a new instance of ReluGrad
+   */
+  public static <T extends Number> ReluGrad<T> create(Scope scope, Operand<T> gradients, Operand<T> features) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ReluGrad", scope.makeOpName("ReluGrad"));
+    opBuilder.addInput(gradients.asOutput());
+    opBuilder.addInput(features.asOutput());
+    return new ReluGrad<T>(opBuilder.build());
+  }
+  
+  /**
+   * `gradients * (features > 0)`.
+   */
+  public Output<T> backprops() {
+    return backprops;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return backprops;
+  }
+  
+  private Output<T> backprops;
+  
+  private ReluGrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    backprops = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Relu.java java-ops/org/tensorflow/op/core/Relu.java
--- java/org/tensorflow/op/core/Relu.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Relu.java	2018-10-16 20:18:38.424432246 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes rectified linear: `max(features, 0)`.
+ * 
+ * @param <T> data type for {@code activations()} output
+ */
+@Operator
+public final class Relu<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Relu operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param features 
+   * @return a new instance of Relu
+   */
+  public static <T> Relu<T> create(Scope scope, Operand<T> features) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Relu", scope.makeOpName("Relu"));
+    opBuilder.addInput(features.asOutput());
+    return new Relu<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> activations() {
+    return activations;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return activations;
+  }
+  
+  private Output<T> activations;
+  
+  private Relu(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    activations = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/RemoteFusedGraphExecute.java java-ops/org/tensorflow/op/core/RemoteFusedGraphExecute.java
--- java/org/tensorflow/op/core/RemoteFusedGraphExecute.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/RemoteFusedGraphExecute.java	2018-10-16 20:18:38.425432245 +0900
@@ -0,0 +1,91 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.Iterator;
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Execute a sub graph on a remote processor.
+ * <p>
+ * The graph specifications(such as graph itself, input tensors and output names)
+ * are stored as a serialized protocol buffer of RemoteFusedGraphExecuteInfo
+ * as serialized_remote_fused_graph_execute_info.
+ * The specifications will be passed to a dedicated registered
+ * remote fused graph executor.  The executor will send the graph specifications
+ * to a remote processor and execute that graph.  The execution results
+ * will be passed to consumer nodes as outputs of this node.
+ */
+@Operator
+public final class RemoteFusedGraphExecute extends PrimitiveOp implements Iterable<Operand<Object>> {
+  
+  /**
+   * Factory method to create a class to wrap a new RemoteFusedGraphExecute operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputs Arbitrary number of tensors with arbitrary data types
+   * @param Toutputs 
+   * @param serializedRemoteFusedGraphExecuteInfo Serialized protocol buffer
+   * of RemoteFusedGraphExecuteInfo which contains graph specifications.
+   * @return a new instance of RemoteFusedGraphExecute
+   */
+  public static RemoteFusedGraphExecute create(Scope scope, Iterable<Operand<?>> inputs, List<Class<?>> Toutputs, String serializedRemoteFusedGraphExecuteInfo) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("RemoteFusedGraphExecute", scope.makeOpName("RemoteFusedGraphExecute"));
+    opBuilder.addInputList(Operands.asOutputs(inputs));
+    DataType[] ToutputsArray = new DataType[Toutputs.size()];
+    for (int i = 0; i < ToutputsArray.length; ++i) {
+      ToutputsArray[i] = DataType.fromClass(Toutputs.get(i));
+    }
+    opBuilder.setAttr("Toutputs", ToutputsArray);
+    opBuilder.setAttr("serialized_remote_fused_graph_execute_info", serializedRemoteFusedGraphExecuteInfo);
+    return new RemoteFusedGraphExecute(opBuilder.build());
+  }
+  
+  /**
+   * Arbitrary number of tensors with arbitrary data types
+   */
+  public List<Output<?>> outputs() {
+    return outputs;
+  }
+  
+  @Override
+  @SuppressWarnings({"rawtypes", "unchecked"})
+  public Iterator<Operand<Object>> iterator() {
+    return (Iterator) outputs.iterator();
+  }
+  
+  private List<Output<?>> outputs;
+  
+  private RemoteFusedGraphExecute(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    int outputsLength = operation.outputListLength("outputs");
+    outputs = Arrays.asList(operation.outputList(outputIdx, outputsLength));
+    outputIdx += outputsLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/RepeatDataset.java java-ops/org/tensorflow/op/core/RepeatDataset.java
--- java/org/tensorflow/op/core/RepeatDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/RepeatDataset.java	2018-10-16 20:18:38.426432245 +0900
@@ -0,0 +1,84 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Creates a dataset that emits the outputs of `input_dataset` `count` times.
+ */
+@Operator
+public final class RepeatDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new RepeatDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputDataset 
+   * @param count A scalar representing the number of times that `input_dataset` should
+   * be repeated. A value of `-1` indicates that it should be repeated infinitely.
+   * @param outputTypes 
+   * @param outputShapes 
+   * @return a new instance of RepeatDataset
+   */
+  public static RepeatDataset create(Scope scope, Operand<?> inputDataset, Operand<Long> count, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("RepeatDataset", scope.makeOpName("RepeatDataset"));
+    opBuilder.addInput(inputDataset.asOutput());
+    opBuilder.addInput(count.asOutput());
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new RepeatDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private RepeatDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/RequantizationRange.java java-ops/org/tensorflow/op/core/RequantizationRange.java
--- java/org/tensorflow/op/core/RequantizationRange.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/RequantizationRange.java	2018-10-16 20:18:38.426432245 +0900
@@ -0,0 +1,78 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Given a quantized tensor described by (input, input_min, input_max), outputs a
+ * <p>
+ * range that covers the actual values present in that tensor.  This op is
+ * typically used to produce the requested_output_min and requested_output_max for
+ * Requantize.
+ */
+@Operator
+public final class RequantizationRange extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new RequantizationRange operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param inputMin The float value that the minimum quantized input value represents.
+   * @param inputMax The float value that the maximum quantized input value represents.
+   * @return a new instance of RequantizationRange
+   */
+  public static <T> RequantizationRange create(Scope scope, Operand<T> input, Operand<Float> inputMin, Operand<Float> inputMax) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("RequantizationRange", scope.makeOpName("RequantizationRange"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(inputMin.asOutput());
+    opBuilder.addInput(inputMax.asOutput());
+    return new RequantizationRange(opBuilder.build());
+  }
+  
+  /**
+   * The computed min output.
+   */
+  public Output<Float> outputMin() {
+    return outputMin;
+  }
+  
+  /**
+   * the computed max output.
+   */
+  public Output<Float> outputMax() {
+    return outputMax;
+  }
+  
+  private Output<Float> outputMin;
+  private Output<Float> outputMax;
+  
+  private RequantizationRange(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    outputMin = operation.output(outputIdx++);
+    outputMax = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Requantize.java java-ops/org/tensorflow/op/core/Requantize.java
--- java/org/tensorflow/op/core/Requantize.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Requantize.java	2018-10-16 20:18:38.427432244 +0900
@@ -0,0 +1,98 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Convert the quantized 'input' tensor into a lower-precision 'output', using the
+ * <p>
+ * output range specified with 'requested_output_min' and 'requested_output_max'.
+ * <p>
+ * [input_min, input_max] are scalar floats that specify the range for the float
+ * interpretation of the 'input' data. For example, if input_min is -1.0f and
+ * input_max is 1.0f, and we are dealing with quint16 quantized data, then a 0
+ * value in the 16-bit data should be interpreted as -1.0f, and a 65535 means 1.0f.
+ * 
+ * @param <U> data type for {@code output()} output
+ */
+@Operator
+public final class Requantize<U> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new Requantize operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param inputMin The float value that the minimum quantized input value represents.
+   * @param inputMax The float value that the maximum quantized input value represents.
+   * @param requestedOutputMin The float value that the minimum quantized output value represents.
+   * @param requestedOutputMax The float value that the maximum quantized output value represents.
+   * @param outType The type of the output. Should be a lower bit depth than Tinput.
+   * @return a new instance of Requantize
+   */
+  public static <U, T> Requantize<U> create(Scope scope, Operand<T> input, Operand<Float> inputMin, Operand<Float> inputMax, Operand<Float> requestedOutputMin, Operand<Float> requestedOutputMax, Class<U> outType) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Requantize", scope.makeOpName("Requantize"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(inputMin.asOutput());
+    opBuilder.addInput(inputMax.asOutput());
+    opBuilder.addInput(requestedOutputMin.asOutput());
+    opBuilder.addInput(requestedOutputMax.asOutput());
+    opBuilder.setAttr("out_type", DataType.fromClass(outType));
+    return new Requantize<U>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<U> output() {
+    return output;
+  }
+  
+  /**
+   * The requested_output_min value is copied into this output.
+   */
+  public Output<Float> outputMin() {
+    return outputMin;
+  }
+  
+  /**
+   * The requested_output_max value is copied into this output.
+   */
+  public Output<Float> outputMax() {
+    return outputMax;
+  }
+  
+  private Output<U> output;
+  private Output<Float> outputMin;
+  private Output<Float> outputMax;
+  
+  private Requantize(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+    outputMin = operation.output(outputIdx++);
+    outputMax = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Reshape.java java-ops/org/tensorflow/op/core/Reshape.java
--- java/org/tensorflow/op/core/Reshape.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Reshape.java	2018-10-16 20:18:38.427432244 +0900
@@ -0,0 +1,126 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Reshapes a tensor.
+ * <p>
+ * Given `tensor`, this operation returns a tensor that has the same values
+ * as `tensor` with shape `shape`.
+ * <p>
+ * If one component of `shape` is the special value -1, the size of that dimension
+ * is computed so that the total size remains constant.  In particular, a `shape`
+ * of `[-1]` flattens into 1-D.  At most one component of `shape` can be -1.
+ * <p>
+ * If `shape` is 1-D or higher, then the operation returns a tensor with shape
+ * `shape` filled with the values of `tensor`. In this case, the number of elements
+ * implied by `shape` must be the same as the number of elements in `tensor`.
+ * <p>
+ * For example:
+ * <pre>{@code
+ * # tensor 't' is [1, 2, 3, 4, 5, 6, 7, 8, 9]
+ * # tensor 't' has shape [9]
+ * reshape(t, [3, 3]) ==> [[1, 2, 3],
+ *                         [4, 5, 6],
+ *                         [7, 8, 9]]
+ * 
+ * # tensor 't' is [[[1, 1], [2, 2]],
+ * #                [[3, 3], [4, 4]]]
+ * # tensor 't' has shape [2, 2, 2]
+ * reshape(t, [2, 4]) ==> [[1, 1, 2, 2],
+ *                         [3, 3, 4, 4]]
+ * 
+ * # tensor 't' is [[[1, 1, 1],
+ * #                 [2, 2, 2]],
+ * #                [[3, 3, 3],
+ * #                 [4, 4, 4]],
+ * #                [[5, 5, 5],
+ * #                 [6, 6, 6]]]
+ * # tensor 't' has shape [3, 2, 3]
+ * # pass '[-1]' to flatten 't'
+ * reshape(t, [-1]) ==> [1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6]
+ * 
+ * # -1 can also be used to infer the shape
+ * 
+ * # -1 is inferred to be 9:
+ * reshape(t, [2, -1]) ==> [[1, 1, 1, 2, 2, 2, 3, 3, 3],
+ *                          [4, 4, 4, 5, 5, 5, 6, 6, 6]]
+ * # -1 is inferred to be 2:
+ * reshape(t, [-1, 9]) ==> [[1, 1, 1, 2, 2, 2, 3, 3, 3],
+ *                          [4, 4, 4, 5, 5, 5, 6, 6, 6]]
+ * # -1 is inferred to be 3:
+ * reshape(t, [ 2, -1, 3]) ==> [[[1, 1, 1],
+ *                               [2, 2, 2],
+ *                               [3, 3, 3]],
+ *                              [[4, 4, 4],
+ *                               [5, 5, 5],
+ *                               [6, 6, 6]]]
+ * 
+ * # tensor 't' is [7]
+ * # shape `[]` reshapes to a scalar
+ * reshape(t, []) ==> 7
+ * }</pre>
+ * 
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class Reshape<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Reshape operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param tensor 
+   * @param shape Defines the shape of the output tensor.
+   * @return a new instance of Reshape
+   */
+  public static <T, U extends Number> Reshape<T> create(Scope scope, Operand<T> tensor, Operand<U> shape) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Reshape", scope.makeOpName("Reshape"));
+    opBuilder.addInput(tensor.asOutput());
+    opBuilder.addInput(shape.asOutput());
+    return new Reshape<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private Reshape(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResizeArea.java java-ops/org/tensorflow/op/core/ResizeArea.java
--- java/org/tensorflow/op/core/ResizeArea.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResizeArea.java	2018-10-16 20:18:38.428432243 +0900
@@ -0,0 +1,118 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Resize `images` to `size` using area interpolation.
+ * <p>
+ * Input images can be of different types but output images are always float.
+ * <p>
+ * The range of pixel values for the output image might be slightly different
+ * from the range for the input image because of limited numerical precision.
+ * To guarantee an output range, for example `[0.0, 1.0]`, apply
+ * `tf.clip_by_value` to the output.
+ * <p>
+ * Each output pixel is computed by first transforming the pixel's footprint into
+ * the input tensor and then averaging the pixels that intersect the footprint. An
+ * input pixel's contribution to the average is weighted by the fraction of its
+ * area that intersects the footprint.  This is the same as OpenCV's INTER_AREA.
+ */
+@Operator
+public final class ResizeArea extends PrimitiveOp implements Operand<Float> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ResizeArea}
+   */
+  public static class Options {
+    
+    /**
+     * @param alignCorners If true, the centers of the 4 corner pixels of the input and output tensors are
+     * aligned, preserving the values at the corner pixels. Defaults to false.
+     */
+    public Options alignCorners(Boolean alignCorners) {
+      this.alignCorners = alignCorners;
+      return this;
+    }
+    
+    private Boolean alignCorners;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ResizeArea operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param images 4-D with shape `[batch, height, width, channels]`.
+   * @param size = A 1-D int32 Tensor of 2 elements: `new_height, new_width`.  The
+   * new size for the images.
+   * @param options carries optional attributes values
+   * @return a new instance of ResizeArea
+   */
+  public static <T extends Number> ResizeArea create(Scope scope, Operand<T> images, Operand<Integer> size, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResizeArea", scope.makeOpName("ResizeArea"));
+    opBuilder.addInput(images.asOutput());
+    opBuilder.addInput(size.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.alignCorners != null) {
+          opBuilder.setAttr("align_corners", opts.alignCorners);
+        }
+      }
+    }
+    return new ResizeArea(opBuilder.build());
+  }
+  
+  /**
+   * @param alignCorners If true, the centers of the 4 corner pixels of the input and output tensors are
+   * aligned, preserving the values at the corner pixels. Defaults to false.
+   */
+  public static Options alignCorners(Boolean alignCorners) {
+    return new Options().alignCorners(alignCorners);
+  }
+  
+  /**
+   * 4-D with shape
+   * `[batch, new_height, new_width, channels]`.
+   */
+  public Output<Float> resizedImages() {
+    return resizedImages;
+  }
+  
+  @Override
+  public Output<Float> asOutput() {
+    return resizedImages;
+  }
+  
+  private Output<Float> resizedImages;
+  
+  private ResizeArea(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    resizedImages = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResizeBicubicGrad.java java-ops/org/tensorflow/op/core/ResizeBicubicGrad.java
--- java/org/tensorflow/op/core/ResizeBicubicGrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResizeBicubicGrad.java	2018-10-16 20:18:38.430432242 +0900
@@ -0,0 +1,107 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Computes the gradient of bicubic interpolation.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+public final class ResizeBicubicGrad<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ResizeBicubicGrad}
+   */
+  public static class Options {
+    
+    /**
+     * @param alignCorners If true, the centers of the 4 corner pixels of the input and grad tensors are
+     * aligned. Defaults to false.
+     */
+    public Options alignCorners(Boolean alignCorners) {
+      this.alignCorners = alignCorners;
+      return this;
+    }
+    
+    private Boolean alignCorners;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ResizeBicubicGrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param grads 4-D with shape `[batch, height, width, channels]`.
+   * @param originalImage 4-D with shape `[batch, orig_height, orig_width, channels]`,
+   * The image tensor that was resized.
+   * @param options carries optional attributes values
+   * @return a new instance of ResizeBicubicGrad
+   */
+  public static <T extends Number> ResizeBicubicGrad<T> create(Scope scope, Operand<Float> grads, Operand<T> originalImage, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResizeBicubicGrad", scope.makeOpName("ResizeBicubicGrad"));
+    opBuilder.addInput(grads.asOutput());
+    opBuilder.addInput(originalImage.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.alignCorners != null) {
+          opBuilder.setAttr("align_corners", opts.alignCorners);
+        }
+      }
+    }
+    return new ResizeBicubicGrad<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param alignCorners If true, the centers of the 4 corner pixels of the input and grad tensors are
+   * aligned. Defaults to false.
+   */
+  public static Options alignCorners(Boolean alignCorners) {
+    return new Options().alignCorners(alignCorners);
+  }
+  
+  /**
+   * 4-D with shape `[batch, orig_height, orig_width, channels]`.
+   * Gradients with respect to the input image. Input image must have been
+   * float or double.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private ResizeBicubicGrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResizeBicubic.java java-ops/org/tensorflow/op/core/ResizeBicubic.java
--- java/org/tensorflow/op/core/ResizeBicubic.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResizeBicubic.java	2018-10-16 20:18:38.429432243 +0900
@@ -0,0 +1,108 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Resize `images` to `size` using bicubic interpolation.
+ * <p>
+ * Input images can be of different types but output images are always float.
+ */
+@Operator
+public final class ResizeBicubic extends PrimitiveOp implements Operand<Float> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ResizeBicubic}
+   */
+  public static class Options {
+    
+    /**
+     * @param alignCorners If true, the centers of the 4 corner pixels of the input and output tensors are
+     * aligned, preserving the values at the corner pixels. Defaults to false.
+     */
+    public Options alignCorners(Boolean alignCorners) {
+      this.alignCorners = alignCorners;
+      return this;
+    }
+    
+    private Boolean alignCorners;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ResizeBicubic operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param images 4-D with shape `[batch, height, width, channels]`.
+   * @param size = A 1-D int32 Tensor of 2 elements: `new_height, new_width`.  The
+   * new size for the images.
+   * @param options carries optional attributes values
+   * @return a new instance of ResizeBicubic
+   */
+  public static <T extends Number> ResizeBicubic create(Scope scope, Operand<T> images, Operand<Integer> size, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResizeBicubic", scope.makeOpName("ResizeBicubic"));
+    opBuilder.addInput(images.asOutput());
+    opBuilder.addInput(size.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.alignCorners != null) {
+          opBuilder.setAttr("align_corners", opts.alignCorners);
+        }
+      }
+    }
+    return new ResizeBicubic(opBuilder.build());
+  }
+  
+  /**
+   * @param alignCorners If true, the centers of the 4 corner pixels of the input and output tensors are
+   * aligned, preserving the values at the corner pixels. Defaults to false.
+   */
+  public static Options alignCorners(Boolean alignCorners) {
+    return new Options().alignCorners(alignCorners);
+  }
+  
+  /**
+   * 4-D with shape
+   * `[batch, new_height, new_width, channels]`.
+   */
+  public Output<Float> resizedImages() {
+    return resizedImages;
+  }
+  
+  @Override
+  public Output<Float> asOutput() {
+    return resizedImages;
+  }
+  
+  private Output<Float> resizedImages;
+  
+  private ResizeBicubic(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    resizedImages = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResizeBilinearGrad.java java-ops/org/tensorflow/op/core/ResizeBilinearGrad.java
--- java/org/tensorflow/op/core/ResizeBilinearGrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResizeBilinearGrad.java	2018-10-16 20:18:38.431432241 +0900
@@ -0,0 +1,107 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Computes the gradient of bilinear interpolation.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+public final class ResizeBilinearGrad<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ResizeBilinearGrad}
+   */
+  public static class Options {
+    
+    /**
+     * @param alignCorners If true, the centers of the 4 corner pixels of the input and grad tensors are
+     * aligned. Defaults to false.
+     */
+    public Options alignCorners(Boolean alignCorners) {
+      this.alignCorners = alignCorners;
+      return this;
+    }
+    
+    private Boolean alignCorners;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ResizeBilinearGrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param grads 4-D with shape `[batch, height, width, channels]`.
+   * @param originalImage 4-D with shape `[batch, orig_height, orig_width, channels]`,
+   * The image tensor that was resized.
+   * @param options carries optional attributes values
+   * @return a new instance of ResizeBilinearGrad
+   */
+  public static <T extends Number> ResizeBilinearGrad<T> create(Scope scope, Operand<Float> grads, Operand<T> originalImage, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResizeBilinearGrad", scope.makeOpName("ResizeBilinearGrad"));
+    opBuilder.addInput(grads.asOutput());
+    opBuilder.addInput(originalImage.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.alignCorners != null) {
+          opBuilder.setAttr("align_corners", opts.alignCorners);
+        }
+      }
+    }
+    return new ResizeBilinearGrad<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param alignCorners If true, the centers of the 4 corner pixels of the input and grad tensors are
+   * aligned. Defaults to false.
+   */
+  public static Options alignCorners(Boolean alignCorners) {
+    return new Options().alignCorners(alignCorners);
+  }
+  
+  /**
+   * 4-D with shape `[batch, orig_height, orig_width, channels]`.
+   * Gradients with respect to the input image. Input image must have been
+   * float or double.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private ResizeBilinearGrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResizeBilinear.java java-ops/org/tensorflow/op/core/ResizeBilinear.java
--- java/org/tensorflow/op/core/ResizeBilinear.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResizeBilinear.java	2018-10-16 20:18:38.430432242 +0900
@@ -0,0 +1,108 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Resize `images` to `size` using bilinear interpolation.
+ * <p>
+ * Input images can be of different types but output images are always float.
+ */
+@Operator
+public final class ResizeBilinear extends PrimitiveOp implements Operand<Float> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ResizeBilinear}
+   */
+  public static class Options {
+    
+    /**
+     * @param alignCorners If true, the centers of the 4 corner pixels of the input and output tensors are
+     * aligned, preserving the values at the corner pixels. Defaults to false.
+     */
+    public Options alignCorners(Boolean alignCorners) {
+      this.alignCorners = alignCorners;
+      return this;
+    }
+    
+    private Boolean alignCorners;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ResizeBilinear operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param images 4-D with shape `[batch, height, width, channels]`.
+   * @param size = A 1-D int32 Tensor of 2 elements: `new_height, new_width`.  The
+   * new size for the images.
+   * @param options carries optional attributes values
+   * @return a new instance of ResizeBilinear
+   */
+  public static <T extends Number> ResizeBilinear create(Scope scope, Operand<T> images, Operand<Integer> size, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResizeBilinear", scope.makeOpName("ResizeBilinear"));
+    opBuilder.addInput(images.asOutput());
+    opBuilder.addInput(size.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.alignCorners != null) {
+          opBuilder.setAttr("align_corners", opts.alignCorners);
+        }
+      }
+    }
+    return new ResizeBilinear(opBuilder.build());
+  }
+  
+  /**
+   * @param alignCorners If true, the centers of the 4 corner pixels of the input and output tensors are
+   * aligned, preserving the values at the corner pixels. Defaults to false.
+   */
+  public static Options alignCorners(Boolean alignCorners) {
+    return new Options().alignCorners(alignCorners);
+  }
+  
+  /**
+   * 4-D with shape
+   * `[batch, new_height, new_width, channels]`.
+   */
+  public Output<Float> resizedImages() {
+    return resizedImages;
+  }
+  
+  @Override
+  public Output<Float> asOutput() {
+    return resizedImages;
+  }
+  
+  private Output<Float> resizedImages;
+  
+  private ResizeBilinear(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    resizedImages = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResizeNearestNeighborGrad.java java-ops/org/tensorflow/op/core/ResizeNearestNeighborGrad.java
--- java/org/tensorflow/op/core/ResizeNearestNeighborGrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResizeNearestNeighborGrad.java	2018-10-16 20:18:38.434432239 +0900
@@ -0,0 +1,106 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Computes the gradient of nearest neighbor interpolation.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+public final class ResizeNearestNeighborGrad<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ResizeNearestNeighborGrad}
+   */
+  public static class Options {
+    
+    /**
+     * @param alignCorners If true, the centers of the 4 corner pixels of the input and grad tensors are
+     * aligned. Defaults to false.
+     */
+    public Options alignCorners(Boolean alignCorners) {
+      this.alignCorners = alignCorners;
+      return this;
+    }
+    
+    private Boolean alignCorners;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ResizeNearestNeighborGrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param grads 4-D with shape `[batch, height, width, channels]`.
+   * @param size = A 1-D int32 Tensor of 2 elements: `orig_height, orig_width`. The
+   * original input size.
+   * @param options carries optional attributes values
+   * @return a new instance of ResizeNearestNeighborGrad
+   */
+  public static <T extends Number> ResizeNearestNeighborGrad<T> create(Scope scope, Operand<T> grads, Operand<Integer> size, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResizeNearestNeighborGrad", scope.makeOpName("ResizeNearestNeighborGrad"));
+    opBuilder.addInput(grads.asOutput());
+    opBuilder.addInput(size.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.alignCorners != null) {
+          opBuilder.setAttr("align_corners", opts.alignCorners);
+        }
+      }
+    }
+    return new ResizeNearestNeighborGrad<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param alignCorners If true, the centers of the 4 corner pixels of the input and grad tensors are
+   * aligned. Defaults to false.
+   */
+  public static Options alignCorners(Boolean alignCorners) {
+    return new Options().alignCorners(alignCorners);
+  }
+  
+  /**
+   * 4-D with shape `[batch, orig_height, orig_width, channels]`. Gradients
+   * with respect to the input image.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private ResizeNearestNeighborGrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResizeNearestNeighbor.java java-ops/org/tensorflow/op/core/ResizeNearestNeighbor.java
--- java/org/tensorflow/op/core/ResizeNearestNeighbor.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResizeNearestNeighbor.java	2018-10-16 20:18:38.433432240 +0900
@@ -0,0 +1,108 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Resize `images` to `size` using nearest neighbor interpolation.
+ * 
+ * @param <T> data type for {@code resizedImages()} output
+ */
+@Operator
+public final class ResizeNearestNeighbor<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ResizeNearestNeighbor}
+   */
+  public static class Options {
+    
+    /**
+     * @param alignCorners If true, the centers of the 4 corner pixels of the input and output tensors are
+     * aligned, preserving the values at the corner pixels. Defaults to false.
+     */
+    public Options alignCorners(Boolean alignCorners) {
+      this.alignCorners = alignCorners;
+      return this;
+    }
+    
+    private Boolean alignCorners;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ResizeNearestNeighbor operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param images 4-D with shape `[batch, height, width, channels]`.
+   * @param size = A 1-D int32 Tensor of 2 elements: `new_height, new_width`.  The
+   * new size for the images.
+   * @param options carries optional attributes values
+   * @return a new instance of ResizeNearestNeighbor
+   */
+  public static <T extends Number> ResizeNearestNeighbor<T> create(Scope scope, Operand<T> images, Operand<Integer> size, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResizeNearestNeighbor", scope.makeOpName("ResizeNearestNeighbor"));
+    opBuilder.addInput(images.asOutput());
+    opBuilder.addInput(size.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.alignCorners != null) {
+          opBuilder.setAttr("align_corners", opts.alignCorners);
+        }
+      }
+    }
+    return new ResizeNearestNeighbor<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param alignCorners If true, the centers of the 4 corner pixels of the input and output tensors are
+   * aligned, preserving the values at the corner pixels. Defaults to false.
+   */
+  public static Options alignCorners(Boolean alignCorners) {
+    return new Options().alignCorners(alignCorners);
+  }
+  
+  /**
+   * 4-D with shape
+   * `[batch, new_height, new_width, channels]`.
+   */
+  public Output<T> resizedImages() {
+    return resizedImages;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return resizedImages;
+  }
+  
+  private Output<T> resizedImages;
+  
+  private ResizeNearestNeighbor(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    resizedImages = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResourceApplyAdadelta.java java-ops/org/tensorflow/op/core/ResourceApplyAdadelta.java
--- java/org/tensorflow/op/core/ResourceApplyAdadelta.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResourceApplyAdadelta.java	2018-10-16 20:18:38.436432238 +0900
@@ -0,0 +1,103 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update '*var' according to the adadelta scheme.
+ * <p>
+ * accum = rho() * accum + (1 - rho()) * grad.square();
+ * update = (update_accum + epsilon).sqrt() * (accum + epsilon()).rsqrt() * grad;
+ * update_accum = rho() * update_accum + (1 - rho()) * update.square();
+ * var -= update;
+ */
+@Operator
+public final class ResourceApplyAdadelta extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ResourceApplyAdadelta}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If True, updating of the var, accum and update_accum tensors will be protected by
+     * a lock; otherwise the behavior is undefined, but may exhibit less contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ResourceApplyAdadelta operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param accum Should be from a Variable().
+   * @param accumUpdate Should be from a Variable().
+   * @param lr Scaling factor. Must be a scalar.
+   * @param rho Decay factor. Must be a scalar.
+   * @param epsilon Constant factor. Must be a scalar.
+   * @param grad The gradient.
+   * @param options carries optional attributes values
+   * @return a new instance of ResourceApplyAdadelta
+   */
+  public static <T> ResourceApplyAdadelta create(Scope scope, Operand<?> var, Operand<?> accum, Operand<?> accumUpdate, Operand<T> lr, Operand<T> rho, Operand<T> epsilon, Operand<T> grad, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResourceApplyAdadelta", scope.makeOpName("ResourceApplyAdadelta"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(accum.asOutput());
+    opBuilder.addInput(accumUpdate.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(rho.asOutput());
+    opBuilder.addInput(epsilon.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ResourceApplyAdadelta(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If True, updating of the var, accum and update_accum tensors will be protected by
+   * a lock; otherwise the behavior is undefined, but may exhibit less contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  
+  private ResourceApplyAdadelta(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResourceApplyAdagradDA.java java-ops/org/tensorflow/op/core/ResourceApplyAdagradDA.java
--- java/org/tensorflow/op/core/ResourceApplyAdagradDA.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResourceApplyAdagradDA.java	2018-10-16 20:18:38.438432236 +0900
@@ -0,0 +1,100 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update '*var' according to the proximal adagrad scheme.
+ */
+@Operator
+public final class ResourceApplyAdagradDA extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ResourceApplyAdagradDA}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If True, updating of the var and accum tensors will be protected by
+     * a lock; otherwise the behavior is undefined, but may exhibit less contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ResourceApplyAdagradDA operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param gradientAccumulator Should be from a Variable().
+   * @param gradientSquaredAccumulator Should be from a Variable().
+   * @param grad The gradient.
+   * @param lr Scaling factor. Must be a scalar.
+   * @param l1 L1 regularization. Must be a scalar.
+   * @param l2 L2 regularization. Must be a scalar.
+   * @param globalStep Training step number. Must be a scalar.
+   * @param options carries optional attributes values
+   * @return a new instance of ResourceApplyAdagradDA
+   */
+  public static <T> ResourceApplyAdagradDA create(Scope scope, Operand<?> var, Operand<?> gradientAccumulator, Operand<?> gradientSquaredAccumulator, Operand<T> grad, Operand<T> lr, Operand<T> l1, Operand<T> l2, Operand<Long> globalStep, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResourceApplyAdagradDA", scope.makeOpName("ResourceApplyAdagradDA"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(gradientAccumulator.asOutput());
+    opBuilder.addInput(gradientSquaredAccumulator.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(l1.asOutput());
+    opBuilder.addInput(l2.asOutput());
+    opBuilder.addInput(globalStep.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ResourceApplyAdagradDA(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If True, updating of the var and accum tensors will be protected by
+   * a lock; otherwise the behavior is undefined, but may exhibit less contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  
+  private ResourceApplyAdagradDA(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResourceApplyAdagrad.java java-ops/org/tensorflow/op/core/ResourceApplyAdagrad.java
--- java/org/tensorflow/op/core/ResourceApplyAdagrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResourceApplyAdagrad.java	2018-10-16 20:18:38.437432237 +0900
@@ -0,0 +1,116 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update '*var' according to the adagrad scheme.
+ * <p>
+ * accum += grad * grad
+ * var -= lr * grad * (1 / sqrt(accum))
+ */
+@Operator
+public final class ResourceApplyAdagrad extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ResourceApplyAdagrad}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If `True`, updating of the var and accum tensors will be protected
+     * by a lock; otherwise the behavior is undefined, but may exhibit less
+     * contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    /**
+     * @param updateSlots 
+     */
+    public Options updateSlots(Boolean updateSlots) {
+      this.updateSlots = updateSlots;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    private Boolean updateSlots;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ResourceApplyAdagrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param accum Should be from a Variable().
+   * @param lr Scaling factor. Must be a scalar.
+   * @param grad The gradient.
+   * @param options carries optional attributes values
+   * @return a new instance of ResourceApplyAdagrad
+   */
+  public static <T> ResourceApplyAdagrad create(Scope scope, Operand<?> var, Operand<?> accum, Operand<T> lr, Operand<T> grad, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResourceApplyAdagrad", scope.makeOpName("ResourceApplyAdagrad"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(accum.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+        if (opts.updateSlots != null) {
+          opBuilder.setAttr("update_slots", opts.updateSlots);
+        }
+      }
+    }
+    return new ResourceApplyAdagrad(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If `True`, updating of the var and accum tensors will be protected
+   * by a lock; otherwise the behavior is undefined, but may exhibit less
+   * contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * @param updateSlots 
+   */
+  public static Options updateSlots(Boolean updateSlots) {
+    return new Options().updateSlots(updateSlots);
+  }
+  
+  
+  private ResourceApplyAdagrad(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResourceApplyAdaMax.java java-ops/org/tensorflow/op/core/ResourceApplyAdaMax.java
--- java/org/tensorflow/op/core/ResourceApplyAdaMax.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResourceApplyAdaMax.java	2018-10-16 20:18:38.435432238 +0900
@@ -0,0 +1,106 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Update '*var' according to the AdaMax algorithm.
+ * <p>
+ * m_t <- beta1 * m_{t-1} + (1 - beta1) * g
+ * v_t <- max(beta2 * v_{t-1}, abs(g))
+ * variable <- variable - learning_rate / (1 - beta1^t) * m_t / (v_t + epsilon)
+ */
+public final class ResourceApplyAdaMax extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ResourceApplyAdaMax}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If `True`, updating of the var, m, and v tensors will be protected
+     * by a lock; otherwise the behavior is undefined, but may exhibit less
+     * contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ResourceApplyAdaMax operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param m Should be from a Variable().
+   * @param v Should be from a Variable().
+   * @param beta1Power Must be a scalar.
+   * @param lr Scaling factor. Must be a scalar.
+   * @param beta1 Momentum factor. Must be a scalar.
+   * @param beta2 Momentum factor. Must be a scalar.
+   * @param epsilon Ridge term. Must be a scalar.
+   * @param grad The gradient.
+   * @param options carries optional attributes values
+   * @return a new instance of ResourceApplyAdaMax
+   */
+  public static <T> ResourceApplyAdaMax create(Scope scope, Operand<?> var, Operand<?> m, Operand<?> v, Operand<T> beta1Power, Operand<T> lr, Operand<T> beta1, Operand<T> beta2, Operand<T> epsilon, Operand<T> grad, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResourceApplyAdaMax", scope.makeOpName("ResourceApplyAdaMax"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(m.asOutput());
+    opBuilder.addInput(v.asOutput());
+    opBuilder.addInput(beta1Power.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(beta1.asOutput());
+    opBuilder.addInput(beta2.asOutput());
+    opBuilder.addInput(epsilon.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ResourceApplyAdaMax(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If `True`, updating of the var, m, and v tensors will be protected
+   * by a lock; otherwise the behavior is undefined, but may exhibit less
+   * contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  
+  private ResourceApplyAdaMax(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResourceApplyAdam.java java-ops/org/tensorflow/op/core/ResourceApplyAdam.java
--- java/org/tensorflow/op/core/ResourceApplyAdam.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResourceApplyAdam.java	2018-10-16 20:18:38.439432235 +0900
@@ -0,0 +1,130 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update '*var' according to the Adam algorithm.
+ * <p>
+ * $$lr_t := \text{learning\_rate} * \sqrt{1 - beta_2^t} / (1 - beta_1^t)$$
+ * $$m_t := beta_1 * m_{t-1} + (1 - beta_1) * g$$
+ * $$v_t := beta_2 * v_{t-1} + (1 - beta_2) * g * g$$
+ * $$variable := variable - lr_t * m_t / (\sqrt{v_t} + \epsilon)$$
+ */
+@Operator
+public final class ResourceApplyAdam extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ResourceApplyAdam}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If `True`, updating of the var, m, and v tensors will be protected
+     * by a lock; otherwise the behavior is undefined, but may exhibit less
+     * contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    /**
+     * @param useNesterov If `True`, uses the nesterov update.
+     */
+    public Options useNesterov(Boolean useNesterov) {
+      this.useNesterov = useNesterov;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    private Boolean useNesterov;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ResourceApplyAdam operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param m Should be from a Variable().
+   * @param v Should be from a Variable().
+   * @param beta1Power Must be a scalar.
+   * @param beta2Power Must be a scalar.
+   * @param lr Scaling factor. Must be a scalar.
+   * @param beta1 Momentum factor. Must be a scalar.
+   * @param beta2 Momentum factor. Must be a scalar.
+   * @param epsilon Ridge term. Must be a scalar.
+   * @param grad The gradient.
+   * @param options carries optional attributes values
+   * @return a new instance of ResourceApplyAdam
+   */
+  public static <T> ResourceApplyAdam create(Scope scope, Operand<?> var, Operand<?> m, Operand<?> v, Operand<T> beta1Power, Operand<T> beta2Power, Operand<T> lr, Operand<T> beta1, Operand<T> beta2, Operand<T> epsilon, Operand<T> grad, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResourceApplyAdam", scope.makeOpName("ResourceApplyAdam"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(m.asOutput());
+    opBuilder.addInput(v.asOutput());
+    opBuilder.addInput(beta1Power.asOutput());
+    opBuilder.addInput(beta2Power.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(beta1.asOutput());
+    opBuilder.addInput(beta2.asOutput());
+    opBuilder.addInput(epsilon.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+        if (opts.useNesterov != null) {
+          opBuilder.setAttr("use_nesterov", opts.useNesterov);
+        }
+      }
+    }
+    return new ResourceApplyAdam(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If `True`, updating of the var, m, and v tensors will be protected
+   * by a lock; otherwise the behavior is undefined, but may exhibit less
+   * contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * @param useNesterov If `True`, uses the nesterov update.
+   */
+  public static Options useNesterov(Boolean useNesterov) {
+    return new Options().useNesterov(useNesterov);
+  }
+  
+  
+  private ResourceApplyAdam(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResourceApplyAddSign.java java-ops/org/tensorflow/op/core/ResourceApplyAddSign.java
--- java/org/tensorflow/op/core/ResourceApplyAddSign.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResourceApplyAddSign.java	2018-10-16 20:18:38.440432235 +0900
@@ -0,0 +1,104 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update '*var' according to the AddSign update.
+ * <p>
+ * m_t <- beta1 * m_{t-1} + (1 - beta1) * g
+ * update <- (alpha + sign_decay * sign(g) *sign(m)) * g
+ * variable <- variable - lr_t * update
+ */
+@Operator
+public final class ResourceApplyAddSign extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ResourceApplyAddSign}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If `True`, updating of the var and m tensors is
+     * protected by a lock; otherwise the behavior is undefined, but may exhibit less
+     * contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ResourceApplyAddSign operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param m Should be from a Variable().
+   * @param lr Scaling factor. Must be a scalar.
+   * @param alpha Must be a scalar.
+   * @param signDecay Must be a scalar.
+   * @param beta Must be a scalar.
+   * @param grad The gradient.
+   * @param options carries optional attributes values
+   * @return a new instance of ResourceApplyAddSign
+   */
+  public static <T> ResourceApplyAddSign create(Scope scope, Operand<?> var, Operand<?> m, Operand<T> lr, Operand<T> alpha, Operand<T> signDecay, Operand<T> beta, Operand<T> grad, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResourceApplyAddSign", scope.makeOpName("ResourceApplyAddSign"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(m.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(alpha.asOutput());
+    opBuilder.addInput(signDecay.asOutput());
+    opBuilder.addInput(beta.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ResourceApplyAddSign(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If `True`, updating of the var and m tensors is
+   * protected by a lock; otherwise the behavior is undefined, but may exhibit less
+   * contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  
+  private ResourceApplyAddSign(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResourceApplyCenteredRMSProp.java java-ops/org/tensorflow/op/core/ResourceApplyCenteredRMSProp.java
--- java/org/tensorflow/op/core/ResourceApplyCenteredRMSProp.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResourceApplyCenteredRMSProp.java	2018-10-16 20:18:38.442432233 +0900
@@ -0,0 +1,123 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update '*var' according to the centered RMSProp algorithm.
+ * <p>
+ * The centered RMSProp algorithm uses an estimate of the centered second moment
+ * (i.e., the variance) for normalization, as opposed to regular RMSProp, which
+ * uses the (uncentered) second moment. This often helps with training, but is
+ * slightly more expensive in terms of computation and memory.
+ * <p>
+ * Note that in dense implementation of this algorithm, mg, ms, and mom will
+ * update even if the grad is zero, but in this sparse implementation, mg, ms,
+ * and mom will not update in iterations during which the grad is zero.
+ * <p>
+ * mean_square = decay * mean_square + (1-decay) * gradient ** 2
+ * mean_grad = decay * mean_grad + (1-decay) * gradient
+ * <p>
+ * Delta = learning_rate * gradient / sqrt(mean_square + epsilon - mean_grad ** 2)
+ * <p>
+ * mg <- rho * mg_{t-1} + (1-rho) * grad
+ * ms <- rho * ms_{t-1} + (1-rho) * grad * grad
+ * mom <- momentum * mom_{t-1} + lr * grad / sqrt(ms - mg * mg + epsilon)
+ * var <- var - mom
+ */
+@Operator
+public final class ResourceApplyCenteredRMSProp extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ResourceApplyCenteredRMSProp}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If `True`, updating of the var, mg, ms, and mom tensors is
+     * protected by a lock; otherwise the behavior is undefined, but may exhibit less
+     * contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ResourceApplyCenteredRMSProp operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param mg Should be from a Variable().
+   * @param ms Should be from a Variable().
+   * @param mom Should be from a Variable().
+   * @param lr Scaling factor. Must be a scalar.
+   * @param rho Decay rate. Must be a scalar.
+   * @param momentum 
+   * @param epsilon Ridge term. Must be a scalar.
+   * @param grad The gradient.
+   * @param options carries optional attributes values
+   * @return a new instance of ResourceApplyCenteredRMSProp
+   */
+  public static <T> ResourceApplyCenteredRMSProp create(Scope scope, Operand<?> var, Operand<?> mg, Operand<?> ms, Operand<?> mom, Operand<T> lr, Operand<T> rho, Operand<T> momentum, Operand<T> epsilon, Operand<T> grad, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResourceApplyCenteredRMSProp", scope.makeOpName("ResourceApplyCenteredRMSProp"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(mg.asOutput());
+    opBuilder.addInput(ms.asOutput());
+    opBuilder.addInput(mom.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(rho.asOutput());
+    opBuilder.addInput(momentum.asOutput());
+    opBuilder.addInput(epsilon.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ResourceApplyCenteredRMSProp(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If `True`, updating of the var, mg, ms, and mom tensors is
+   * protected by a lock; otherwise the behavior is undefined, but may exhibit less
+   * contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  
+  private ResourceApplyCenteredRMSProp(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResourceApplyFtrl.java java-ops/org/tensorflow/op/core/ResourceApplyFtrl.java
--- java/org/tensorflow/op/core/ResourceApplyFtrl.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResourceApplyFtrl.java	2018-10-16 20:18:38.443432233 +0900
@@ -0,0 +1,108 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update '*var' according to the Ftrl-proximal scheme.
+ * <p>
+ * accum_new = accum + grad * grad
+ * linear += grad - (accum_new^(-lr_power) - accum^(-lr_power)) / lr * var
+ * quadratic = 1.0 / (accum_new^(lr_power) * lr) + 2 * l2
+ * var = (sign(linear) * l1 - linear) / quadratic if |linear| > l1 else 0.0
+ * accum = accum_new
+ */
+@Operator
+public final class ResourceApplyFtrl extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ResourceApplyFtrl}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If `True`, updating of the var and accum tensors will be protected
+     * by a lock; otherwise the behavior is undefined, but may exhibit less
+     * contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ResourceApplyFtrl operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param accum Should be from a Variable().
+   * @param linear Should be from a Variable().
+   * @param grad The gradient.
+   * @param lr Scaling factor. Must be a scalar.
+   * @param l1 L1 regulariation. Must be a scalar.
+   * @param l2 L2 regulariation. Must be a scalar.
+   * @param lrPower Scaling factor. Must be a scalar.
+   * @param options carries optional attributes values
+   * @return a new instance of ResourceApplyFtrl
+   */
+  public static <T> ResourceApplyFtrl create(Scope scope, Operand<?> var, Operand<?> accum, Operand<?> linear, Operand<T> grad, Operand<T> lr, Operand<T> l1, Operand<T> l2, Operand<T> lrPower, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResourceApplyFtrl", scope.makeOpName("ResourceApplyFtrl"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(accum.asOutput());
+    opBuilder.addInput(linear.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(l1.asOutput());
+    opBuilder.addInput(l2.asOutput());
+    opBuilder.addInput(lrPower.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ResourceApplyFtrl(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If `True`, updating of the var and accum tensors will be protected
+   * by a lock; otherwise the behavior is undefined, but may exhibit less
+   * contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  
+  private ResourceApplyFtrl(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResourceApplyFtrlV2.java java-ops/org/tensorflow/op/core/ResourceApplyFtrlV2.java
--- java/org/tensorflow/op/core/ResourceApplyFtrlV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResourceApplyFtrlV2.java	2018-10-16 20:18:38.444432232 +0900
@@ -0,0 +1,112 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update '*var' according to the Ftrl-proximal scheme.
+ * <p>
+ * grad_with_shrinkage = grad + 2 * l2_shrinkage * var
+ * accum_new = accum + grad_with_shrinkage * grad_with_shrinkage
+ * linear += grad_with_shrinkage +
+ *     (accum_new^(-lr_power) - accum^(-lr_power)) / lr * var
+ * quadratic = 1.0 / (accum_new^(lr_power) * lr) + 2 * l2
+ * var = (sign(linear) * l1 - linear) / quadratic if |linear| > l1 else 0.0
+ * accum = accum_new
+ */
+@Operator
+public final class ResourceApplyFtrlV2 extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ResourceApplyFtrlV2}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If `True`, updating of the var and accum tensors will be protected
+     * by a lock; otherwise the behavior is undefined, but may exhibit less
+     * contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ResourceApplyFtrlV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param accum Should be from a Variable().
+   * @param linear Should be from a Variable().
+   * @param grad The gradient.
+   * @param lr Scaling factor. Must be a scalar.
+   * @param l1 L1 regulariation. Must be a scalar.
+   * @param l2 L2 shrinkage regulariation. Must be a scalar.
+   * @param l2Shrinkage 
+   * @param lrPower Scaling factor. Must be a scalar.
+   * @param options carries optional attributes values
+   * @return a new instance of ResourceApplyFtrlV2
+   */
+  public static <T> ResourceApplyFtrlV2 create(Scope scope, Operand<?> var, Operand<?> accum, Operand<?> linear, Operand<T> grad, Operand<T> lr, Operand<T> l1, Operand<T> l2, Operand<T> l2Shrinkage, Operand<T> lrPower, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResourceApplyFtrlV2", scope.makeOpName("ResourceApplyFtrlV2"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(accum.asOutput());
+    opBuilder.addInput(linear.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(l1.asOutput());
+    opBuilder.addInput(l2.asOutput());
+    opBuilder.addInput(l2Shrinkage.asOutput());
+    opBuilder.addInput(lrPower.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ResourceApplyFtrlV2(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If `True`, updating of the var and accum tensors will be protected
+   * by a lock; otherwise the behavior is undefined, but may exhibit less
+   * contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  
+  private ResourceApplyFtrlV2(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResourceApplyGradientDescent.java java-ops/org/tensorflow/op/core/ResourceApplyGradientDescent.java
--- java/org/tensorflow/op/core/ResourceApplyGradientDescent.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResourceApplyGradientDescent.java	2018-10-16 20:18:38.445432231 +0900
@@ -0,0 +1,90 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update '*var' by subtracting 'alpha' * 'delta' from it.
+ */
+@Operator
+public final class ResourceApplyGradientDescent extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ResourceApplyGradientDescent}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If `True`, the subtraction will be protected by a lock;
+     * otherwise the behavior is undefined, but may exhibit less contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ResourceApplyGradientDescent operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param alpha Scaling factor. Must be a scalar.
+   * @param delta The change.
+   * @param options carries optional attributes values
+   * @return a new instance of ResourceApplyGradientDescent
+   */
+  public static <T> ResourceApplyGradientDescent create(Scope scope, Operand<?> var, Operand<T> alpha, Operand<T> delta, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResourceApplyGradientDescent", scope.makeOpName("ResourceApplyGradientDescent"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(alpha.asOutput());
+    opBuilder.addInput(delta.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ResourceApplyGradientDescent(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If `True`, the subtraction will be protected by a lock;
+   * otherwise the behavior is undefined, but may exhibit less contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  
+  private ResourceApplyGradientDescent(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResourceApplyMomentum.java java-ops/org/tensorflow/op/core/ResourceApplyMomentum.java
--- java/org/tensorflow/op/core/ResourceApplyMomentum.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResourceApplyMomentum.java	2018-10-16 20:18:38.446432231 +0900
@@ -0,0 +1,124 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update '*var' according to the momentum scheme. Set use_nesterov = True if you
+ * <p>
+ * want to use Nesterov momentum.
+ * <p>
+ * accum = accum * momentum + grad
+ * var -= lr * accum
+ */
+@Operator
+public final class ResourceApplyMomentum extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ResourceApplyMomentum}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If `True`, updating of the var and accum tensors will be protected
+     * by a lock; otherwise the behavior is undefined, but may exhibit less
+     * contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    /**
+     * @param useNesterov If `True`, the tensor passed to compute grad will be
+     * var - lr * momentum * accum, so in the end, the var you get is actually
+     * var - lr * momentum * accum.
+     */
+    public Options useNesterov(Boolean useNesterov) {
+      this.useNesterov = useNesterov;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    private Boolean useNesterov;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ResourceApplyMomentum operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param accum Should be from a Variable().
+   * @param lr Scaling factor. Must be a scalar.
+   * @param grad The gradient.
+   * @param momentum Momentum. Must be a scalar.
+   * @param options carries optional attributes values
+   * @return a new instance of ResourceApplyMomentum
+   */
+  public static <T> ResourceApplyMomentum create(Scope scope, Operand<?> var, Operand<?> accum, Operand<T> lr, Operand<T> grad, Operand<T> momentum, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResourceApplyMomentum", scope.makeOpName("ResourceApplyMomentum"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(accum.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    opBuilder.addInput(momentum.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+        if (opts.useNesterov != null) {
+          opBuilder.setAttr("use_nesterov", opts.useNesterov);
+        }
+      }
+    }
+    return new ResourceApplyMomentum(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If `True`, updating of the var and accum tensors will be protected
+   * by a lock; otherwise the behavior is undefined, but may exhibit less
+   * contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * @param useNesterov If `True`, the tensor passed to compute grad will be
+   * var - lr * momentum * accum, so in the end, the var you get is actually
+   * var - lr * momentum * accum.
+   */
+  public static Options useNesterov(Boolean useNesterov) {
+    return new Options().useNesterov(useNesterov);
+  }
+  
+  
+  private ResourceApplyMomentum(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResourceApplyPowerSign.java java-ops/org/tensorflow/op/core/ResourceApplyPowerSign.java
--- java/org/tensorflow/op/core/ResourceApplyPowerSign.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResourceApplyPowerSign.java	2018-10-16 20:18:38.447432230 +0900
@@ -0,0 +1,104 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update '*var' according to the AddSign update.
+ * <p>
+ * m_t <- beta1 * m_{t-1} + (1 - beta1) * g
+ * update <- exp(logbase * sign_decay * sign(g) * sign(m_t)) * g
+ * variable <- variable - lr_t * update
+ */
+@Operator
+public final class ResourceApplyPowerSign extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ResourceApplyPowerSign}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If `True`, updating of the var and m tensors is
+     * protected by a lock; otherwise the behavior is undefined, but may exhibit less
+     * contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ResourceApplyPowerSign operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param m Should be from a Variable().
+   * @param lr Scaling factor. Must be a scalar.
+   * @param logbase Must be a scalar.
+   * @param signDecay Must be a scalar.
+   * @param beta Must be a scalar.
+   * @param grad The gradient.
+   * @param options carries optional attributes values
+   * @return a new instance of ResourceApplyPowerSign
+   */
+  public static <T> ResourceApplyPowerSign create(Scope scope, Operand<?> var, Operand<?> m, Operand<T> lr, Operand<T> logbase, Operand<T> signDecay, Operand<T> beta, Operand<T> grad, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResourceApplyPowerSign", scope.makeOpName("ResourceApplyPowerSign"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(m.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(logbase.asOutput());
+    opBuilder.addInput(signDecay.asOutput());
+    opBuilder.addInput(beta.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ResourceApplyPowerSign(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If `True`, updating of the var and m tensors is
+   * protected by a lock; otherwise the behavior is undefined, but may exhibit less
+   * contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  
+  private ResourceApplyPowerSign(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResourceApplyProximalAdagrad.java java-ops/org/tensorflow/op/core/ResourceApplyProximalAdagrad.java
--- java/org/tensorflow/op/core/ResourceApplyProximalAdagrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResourceApplyProximalAdagrad.java	2018-10-16 20:18:38.448432229 +0900
@@ -0,0 +1,100 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update '*var' and '*accum' according to FOBOS with Adagrad learning rate.
+ * <p>
+ * accum += grad <i> grad
+ * prox_v = var - lr </i> grad <i> (1 / sqrt(accum))
+ * var = sign(prox_v)/(1+lr</i>l2) <i> max{|prox_v|-lr</i>l1,0}
+ */
+@Operator
+public final class ResourceApplyProximalAdagrad extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ResourceApplyProximalAdagrad}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If True, updating of the var and accum tensors will be protected by
+     * a lock; otherwise the behavior is undefined, but may exhibit less contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ResourceApplyProximalAdagrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param accum Should be from a Variable().
+   * @param lr Scaling factor. Must be a scalar.
+   * @param l1 L1 regularization. Must be a scalar.
+   * @param l2 L2 regularization. Must be a scalar.
+   * @param grad The gradient.
+   * @param options carries optional attributes values
+   * @return a new instance of ResourceApplyProximalAdagrad
+   */
+  public static <T> ResourceApplyProximalAdagrad create(Scope scope, Operand<?> var, Operand<?> accum, Operand<T> lr, Operand<T> l1, Operand<T> l2, Operand<T> grad, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResourceApplyProximalAdagrad", scope.makeOpName("ResourceApplyProximalAdagrad"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(accum.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(l1.asOutput());
+    opBuilder.addInput(l2.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ResourceApplyProximalAdagrad(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If True, updating of the var and accum tensors will be protected by
+   * a lock; otherwise the behavior is undefined, but may exhibit less contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  
+  private ResourceApplyProximalAdagrad(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResourceApplyProximalGradientDescent.java java-ops/org/tensorflow/op/core/ResourceApplyProximalGradientDescent.java
--- java/org/tensorflow/op/core/ResourceApplyProximalGradientDescent.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResourceApplyProximalGradientDescent.java	2018-10-16 20:18:38.450432228 +0900
@@ -0,0 +1,97 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update '*var' as FOBOS algorithm with fixed learning rate.
+ * <p>
+ * prox_v = var - alpha <i> delta
+ * var = sign(prox_v)/(1+alpha</i>l2) <i> max{|prox_v|-alpha</i>l1,0}
+ */
+@Operator
+public final class ResourceApplyProximalGradientDescent extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ResourceApplyProximalGradientDescent}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If True, the subtraction will be protected by a lock;
+     * otherwise the behavior is undefined, but may exhibit less contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ResourceApplyProximalGradientDescent operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param alpha Scaling factor. Must be a scalar.
+   * @param l1 L1 regularization. Must be a scalar.
+   * @param l2 L2 regularization. Must be a scalar.
+   * @param delta The change.
+   * @param options carries optional attributes values
+   * @return a new instance of ResourceApplyProximalGradientDescent
+   */
+  public static <T> ResourceApplyProximalGradientDescent create(Scope scope, Operand<?> var, Operand<T> alpha, Operand<T> l1, Operand<T> l2, Operand<T> delta, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResourceApplyProximalGradientDescent", scope.makeOpName("ResourceApplyProximalGradientDescent"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(alpha.asOutput());
+    opBuilder.addInput(l1.asOutput());
+    opBuilder.addInput(l2.asOutput());
+    opBuilder.addInput(delta.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ResourceApplyProximalGradientDescent(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If True, the subtraction will be protected by a lock;
+   * otherwise the behavior is undefined, but may exhibit less contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  
+  private ResourceApplyProximalGradientDescent(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResourceApplyRMSProp.java java-ops/org/tensorflow/op/core/ResourceApplyRMSProp.java
--- java/org/tensorflow/op/core/ResourceApplyRMSProp.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResourceApplyRMSProp.java	2018-10-16 20:18:38.451432227 +0900
@@ -0,0 +1,113 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update '*var' according to the RMSProp algorithm.
+ * <p>
+ * Note that in dense implementation of this algorithm, ms and mom will
+ * update even if the grad is zero, but in this sparse implementation, ms
+ * and mom will not update in iterations during which the grad is zero.
+ * <p>
+ * mean_square = decay * mean_square + (1-decay) * gradient ** 2
+ * Delta = learning_rate * gradient / sqrt(mean_square + epsilon)
+ * <p>
+ * ms <- rho * ms_{t-1} + (1-rho) * grad * grad
+ * mom <- momentum * mom_{t-1} + lr * grad / sqrt(ms + epsilon)
+ * var <- var - mom
+ */
+@Operator
+public final class ResourceApplyRMSProp extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ResourceApplyRMSProp}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If `True`, updating of the var, ms, and mom tensors is protected
+     * by a lock; otherwise the behavior is undefined, but may exhibit less
+     * contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ResourceApplyRMSProp operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param ms Should be from a Variable().
+   * @param mom Should be from a Variable().
+   * @param lr Scaling factor. Must be a scalar.
+   * @param rho Decay rate. Must be a scalar.
+   * @param momentum 
+   * @param epsilon Ridge term. Must be a scalar.
+   * @param grad The gradient.
+   * @param options carries optional attributes values
+   * @return a new instance of ResourceApplyRMSProp
+   */
+  public static <T> ResourceApplyRMSProp create(Scope scope, Operand<?> var, Operand<?> ms, Operand<?> mom, Operand<T> lr, Operand<T> rho, Operand<T> momentum, Operand<T> epsilon, Operand<T> grad, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResourceApplyRMSProp", scope.makeOpName("ResourceApplyRMSProp"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(ms.asOutput());
+    opBuilder.addInput(mom.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(rho.asOutput());
+    opBuilder.addInput(momentum.asOutput());
+    opBuilder.addInput(epsilon.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ResourceApplyRMSProp(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If `True`, updating of the var, ms, and mom tensors is protected
+   * by a lock; otherwise the behavior is undefined, but may exhibit less
+   * contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  
+  private ResourceApplyRMSProp(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResourceCountUpTo.java java-ops/org/tensorflow/op/core/ResourceCountUpTo.java
--- java/org/tensorflow/op/core/ResourceCountUpTo.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResourceCountUpTo.java	2018-10-16 20:18:38.452432226 +0900
@@ -0,0 +1,75 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Increments variable pointed to by 'resource' until it reaches 'limit'.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class ResourceCountUpTo<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new ResourceCountUpTo operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param resource Should be from a scalar `Variable` node.
+   * @param limit If incrementing ref would bring it above limit, instead generates an
+   * 'OutOfRange' error.
+   * @param T 
+   * @return a new instance of ResourceCountUpTo
+   */
+  public static <T extends Number> ResourceCountUpTo<T> create(Scope scope, Operand<?> resource, Long limit, Class<T> T) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResourceCountUpTo", scope.makeOpName("ResourceCountUpTo"));
+    opBuilder.addInput(resource.asOutput());
+    opBuilder.setAttr("limit", limit);
+    opBuilder.setAttr("T", DataType.fromClass(T));
+    return new ResourceCountUpTo<T>(opBuilder.build());
+  }
+  
+  /**
+   * A copy of the input before increment. If nothing else modifies the
+   * input, the values produced will all be distinct.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private ResourceCountUpTo(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResourceGather.java java-ops/org/tensorflow/op/core/ResourceGather.java
--- java/org/tensorflow/op/core/ResourceGather.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResourceGather.java	2018-10-16 20:18:38.453432226 +0900
@@ -0,0 +1,120 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Gather slices from the variable pointed to by `resource` according to `indices`.
+ * <p>
+ * `indices` must be an integer tensor of any dimension (usually 0-D or 1-D).
+ * Produces an output tensor with shape `indices.shape + params.shape[1:]` where:
+ * <pre>{@code
+ *     # Scalar indices
+ *     output[:, ..., :] = params[indices, :, ... :]
+ * 
+ *     # Vector indices
+ *     output[i, :, ..., :] = params[indices[i], :, ... :]
+ * 
+ *     # Higher rank indices
+ *     output[i, ..., j, :, ... :] = params[indices[i, ..., j], :, ..., :]
+ * }</pre>
+ * 
+ * 
+ * @param <U> data type for {@code output()} output
+ */
+@Operator
+public final class ResourceGather<U> extends PrimitiveOp implements Operand<U> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ResourceGather}
+   */
+  public static class Options {
+    
+    /**
+     * @param validateIndices 
+     */
+    public Options validateIndices(Boolean validateIndices) {
+      this.validateIndices = validateIndices;
+      return this;
+    }
+    
+    private Boolean validateIndices;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ResourceGather operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param resource 
+   * @param indices 
+   * @param dtype 
+   * @param options carries optional attributes values
+   * @return a new instance of ResourceGather
+   */
+  public static <U, T extends Number> ResourceGather<U> create(Scope scope, Operand<?> resource, Operand<T> indices, Class<U> dtype, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResourceGather", scope.makeOpName("ResourceGather"));
+    opBuilder.addInput(resource.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.setAttr("dtype", DataType.fromClass(dtype));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.validateIndices != null) {
+          opBuilder.setAttr("validate_indices", opts.validateIndices);
+        }
+      }
+    }
+    return new ResourceGather<U>(opBuilder.build());
+  }
+  
+  /**
+   * @param validateIndices 
+   */
+  public static Options validateIndices(Boolean validateIndices) {
+    return new Options().validateIndices(validateIndices);
+  }
+  
+  /**
+   */
+  public Output<U> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<U> asOutput() {
+    return output;
+  }
+  
+  private Output<U> output;
+  
+  private ResourceGather(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResourceScatterAdd.java java-ops/org/tensorflow/op/core/ResourceScatterAdd.java
--- java/org/tensorflow/op/core/ResourceScatterAdd.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResourceScatterAdd.java	2018-10-16 20:18:38.454432225 +0900
@@ -0,0 +1,74 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Adds sparse updates to the variable referenced by `resource`.
+ * <p>
+ * This operation computes
+ * <p>
+ *     # Scalar indices
+ *     ref[indices, ...] += updates[...]
+ * <p>
+ *     # Vector indices (for each i)
+ *     ref[indices[i], ...] += updates[i, ...]
+ * <p>
+ *     # High rank indices (for each i, ..., j)
+ *     ref[indices[i, ..., j], ...] += updates[i, ..., j, ...]
+ * <p>
+ * Duplicate entries are handled correctly: if multiple `indices` reference
+ * the same location, their contributions add.
+ * <p>
+ * Requires `updates.shape = indices.shape + ref.shape[1:]` or `updates.shape = []`.
+ * <p>
+ * <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
+ * <img style="width:100%" src='https://www.tensorflow.org/images/ScatterAdd.png' alt>
+ * </div>
+ */
+@Operator
+public final class ResourceScatterAdd extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new ResourceScatterAdd operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param resource Should be from a `Variable` node.
+   * @param indices A tensor of indices into the first dimension of `ref`.
+   * @param updates A tensor of updated values to add to `ref`.
+   * @return a new instance of ResourceScatterAdd
+   */
+  public static <T extends Number, U> ResourceScatterAdd create(Scope scope, Operand<?> resource, Operand<T> indices, Operand<U> updates) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResourceScatterAdd", scope.makeOpName("ResourceScatterAdd"));
+    opBuilder.addInput(resource.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(updates.asOutput());
+    return new ResourceScatterAdd(opBuilder.build());
+  }
+  
+  
+  private ResourceScatterAdd(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResourceScatterDiv.java java-ops/org/tensorflow/op/core/ResourceScatterDiv.java
--- java/org/tensorflow/op/core/ResourceScatterDiv.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResourceScatterDiv.java	2018-10-16 20:18:38.455432224 +0900
@@ -0,0 +1,74 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Divides sparse updates into the variable referenced by `resource`.
+ * <p>
+ * This operation computes
+ * <p>
+ *     # Scalar indices
+ *     ref[indices, ...] /= updates[...]
+ * <p>
+ *     # Vector indices (for each i)
+ *     ref[indices[i], ...] /= updates[i, ...]
+ * <p>
+ *     # High rank indices (for each i, ..., j)
+ *     ref[indices[i, ..., j], ...] /= updates[i, ..., j, ...]
+ * <p>
+ * Duplicate entries are handled correctly: if multiple `indices` reference
+ * the same location, their contributions multiply.
+ * <p>
+ * Requires `updates.shape = indices.shape + ref.shape[1:]` or `updates.shape = []`.
+ * <p>
+ * <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
+ * <img style="width:100%" src='https://www.tensorflow.org/images/ScatterAdd.png' alt>
+ * </div>
+ */
+@Operator
+public final class ResourceScatterDiv extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new ResourceScatterDiv operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param resource Should be from a `Variable` node.
+   * @param indices A tensor of indices into the first dimension of `ref`.
+   * @param updates A tensor of updated values to add to `ref`.
+   * @return a new instance of ResourceScatterDiv
+   */
+  public static <T extends Number, U> ResourceScatterDiv create(Scope scope, Operand<?> resource, Operand<T> indices, Operand<U> updates) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResourceScatterDiv", scope.makeOpName("ResourceScatterDiv"));
+    opBuilder.addInput(resource.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(updates.asOutput());
+    return new ResourceScatterDiv(opBuilder.build());
+  }
+  
+  
+  private ResourceScatterDiv(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResourceScatterMax.java java-ops/org/tensorflow/op/core/ResourceScatterMax.java
--- java/org/tensorflow/op/core/ResourceScatterMax.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResourceScatterMax.java	2018-10-16 20:18:38.456432224 +0900
@@ -0,0 +1,74 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Reduces sparse updates into the variable referenced by `resource` using the `max` operation.
+ * <p>
+ * This operation computes
+ * <p>
+ *     # Scalar indices
+ *     ref[indices, ...] = max(ref[indices, ...], updates[...])
+ * <p>
+ *     # Vector indices (for each i)
+ *     ref[indices[i], ...] = max(ref[indices[i], ...], updates[i, ...])
+ * <p>
+ *     # High rank indices (for each i, ..., j)
+ *     ref[indices[i, ..., j], ...] = max(ref[indices[i, ..., j], ...], updates[i, ..., j, ...])
+ * <p>
+ * Duplicate entries are handled correctly: if multiple `indices` reference
+ * the same location, their contributions are combined.
+ * <p>
+ * Requires `updates.shape = indices.shape + ref.shape[1:]` or `updates.shape = []`.
+ * <p>
+ * <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
+ * <img style="width:100%" src='https://www.tensorflow.org/images/ScatterAdd.png' alt>
+ * </div>
+ */
+@Operator
+public final class ResourceScatterMax extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new ResourceScatterMax operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param resource Should be from a `Variable` node.
+   * @param indices A tensor of indices into the first dimension of `ref`.
+   * @param updates A tensor of updated values to add to `ref`.
+   * @return a new instance of ResourceScatterMax
+   */
+  public static <T extends Number, U> ResourceScatterMax create(Scope scope, Operand<?> resource, Operand<T> indices, Operand<U> updates) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResourceScatterMax", scope.makeOpName("ResourceScatterMax"));
+    opBuilder.addInput(resource.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(updates.asOutput());
+    return new ResourceScatterMax(opBuilder.build());
+  }
+  
+  
+  private ResourceScatterMax(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResourceScatterMin.java java-ops/org/tensorflow/op/core/ResourceScatterMin.java
--- java/org/tensorflow/op/core/ResourceScatterMin.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResourceScatterMin.java	2018-10-16 20:18:38.458432222 +0900
@@ -0,0 +1,74 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Reduces sparse updates into the variable referenced by `resource` using the `min` operation.
+ * <p>
+ * This operation computes
+ * <p>
+ *     # Scalar indices
+ *     ref[indices, ...] = min(ref[indices, ...], updates[...])
+ * <p>
+ *     # Vector indices (for each i)
+ *     ref[indices[i], ...] = min(ref[indices[i], ...], updates[i, ...])
+ * <p>
+ *     # High rank indices (for each i, ..., j)
+ *     ref[indices[i, ..., j], ...] = min(ref[indices[i, ..., j], ...], updates[i, ..., j, ...])
+ * <p>
+ * Duplicate entries are handled correctly: if multiple `indices` reference
+ * the same location, their contributions are combined.
+ * <p>
+ * Requires `updates.shape = indices.shape + ref.shape[1:]` or `updates.shape = []`.
+ * <p>
+ * <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
+ * <img style="width:100%" src='https://www.tensorflow.org/images/ScatterAdd.png' alt>
+ * </div>
+ */
+@Operator
+public final class ResourceScatterMin extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new ResourceScatterMin operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param resource Should be from a `Variable` node.
+   * @param indices A tensor of indices into the first dimension of `ref`.
+   * @param updates A tensor of updated values to add to `ref`.
+   * @return a new instance of ResourceScatterMin
+   */
+  public static <T extends Number, U> ResourceScatterMin create(Scope scope, Operand<?> resource, Operand<T> indices, Operand<U> updates) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResourceScatterMin", scope.makeOpName("ResourceScatterMin"));
+    opBuilder.addInput(resource.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(updates.asOutput());
+    return new ResourceScatterMin(opBuilder.build());
+  }
+  
+  
+  private ResourceScatterMin(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResourceScatterMul.java java-ops/org/tensorflow/op/core/ResourceScatterMul.java
--- java/org/tensorflow/op/core/ResourceScatterMul.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResourceScatterMul.java	2018-10-16 20:18:38.459432221 +0900
@@ -0,0 +1,74 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Multiplies sparse updates into the variable referenced by `resource`.
+ * <p>
+ * This operation computes
+ * <p>
+ *     # Scalar indices
+ *     ref[indices, ...] *= updates[...]
+ * <p>
+ *     # Vector indices (for each i)
+ *     ref[indices[i], ...] *= updates[i, ...]
+ * <p>
+ *     # High rank indices (for each i, ..., j)
+ *     ref[indices[i, ..., j], ...] *= updates[i, ..., j, ...]
+ * <p>
+ * Duplicate entries are handled correctly: if multiple `indices` reference
+ * the same location, their contributions multiply.
+ * <p>
+ * Requires `updates.shape = indices.shape + ref.shape[1:]` or `updates.shape = []`.
+ * <p>
+ * <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
+ * <img style="width:100%" src='https://www.tensorflow.org/images/ScatterAdd.png' alt>
+ * </div>
+ */
+@Operator
+public final class ResourceScatterMul extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new ResourceScatterMul operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param resource Should be from a `Variable` node.
+   * @param indices A tensor of indices into the first dimension of `ref`.
+   * @param updates A tensor of updated values to add to `ref`.
+   * @return a new instance of ResourceScatterMul
+   */
+  public static <T extends Number, U> ResourceScatterMul create(Scope scope, Operand<?> resource, Operand<T> indices, Operand<U> updates) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResourceScatterMul", scope.makeOpName("ResourceScatterMul"));
+    opBuilder.addInput(resource.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(updates.asOutput());
+    return new ResourceScatterMul(opBuilder.build());
+  }
+  
+  
+  private ResourceScatterMul(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResourceScatterNdAdd.java java-ops/org/tensorflow/op/core/ResourceScatterNdAdd.java
--- java/org/tensorflow/op/core/ResourceScatterNdAdd.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResourceScatterNdAdd.java	2018-10-16 20:18:38.459432221 +0900
@@ -0,0 +1,126 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Adds sparse `updates` to individual values or slices within a given
+ * <p>
+ * variable according to `indices`.
+ * <p>
+ * `ref` is a `Tensor` with rank `P` and `indices` is a `Tensor` of rank `Q`.
+ * <p>
+ * `indices` must be integer tensor, containing indices into `ref`.
+ * It must be shape `[d_0, ..., d_{Q-2}, K]` where `0 < K <= P`.
+ * <p>
+ * The innermost dimension of `indices` (with length `K`) corresponds to
+ * indices into elements (if `K = P`) or slices (if `K < P`) along the `K`th
+ * dimension of `ref`.
+ * <p>
+ * `updates` is `Tensor` of rank `Q-1+P-K` with shape:
+ * <pre>{@code
+ * [d_0, ..., d_{Q-2}, ref.shape[K], ..., ref.shape[P-1]].
+ * }</pre>
+ * For example, say we want to update 4 scattered elements to a rank-1 tensor to
+ * 8 elements. In Python, that update would look like this:
+ * <pre>{@code
+ *     ref = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8], use_resource=True)
+ *     indices = tf.constant([[4], [3], [1] ,[7]])
+ *     updates = tf.constant([9, 10, 11, 12])
+ *     update = tf.scatter_nd_add(ref, indices, updates)
+ *     with tf.Session() as sess:
+ *       print sess.run(update)
+ * }</pre>
+ * The resulting update to ref would look like this:
+ * <p>
+ *     [1, 12, 3, 14, 14, 6, 7, 20]
+ * <p>
+ * See `tf.scatter_nd` for more details about how to make updates to
+ * slices.
+ */
+@Operator
+public final class ResourceScatterNdAdd extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ResourceScatterNdAdd}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking An optional bool. Defaults to True. If True, the assignment will
+     * be protected by a lock; otherwise the behavior is undefined,
+     * but may exhibit less contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ResourceScatterNdAdd operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param ref A resource handle. Must be from a VarHandleOp.
+   * @param indices A Tensor. Must be one of the following types: int32, int64.
+   * A tensor of indices into ref.
+   * @param updates A Tensor. Must have the same type as ref. A tensor of
+   * values to add to ref.
+   * @param options carries optional attributes values
+   * @return a new instance of ResourceScatterNdAdd
+   */
+  public static <T extends Number, U> ResourceScatterNdAdd create(Scope scope, Operand<?> ref, Operand<T> indices, Operand<U> updates, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResourceScatterNdAdd", scope.makeOpName("ResourceScatterNdAdd"));
+    opBuilder.addInput(ref.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(updates.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ResourceScatterNdAdd(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking An optional bool. Defaults to True. If True, the assignment will
+   * be protected by a lock; otherwise the behavior is undefined,
+   * but may exhibit less contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  
+  private ResourceScatterNdAdd(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResourceScatterNdUpdate.java java-ops/org/tensorflow/op/core/ResourceScatterNdUpdate.java
--- java/org/tensorflow/op/core/ResourceScatterNdUpdate.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResourceScatterNdUpdate.java	2018-10-16 20:18:38.460432221 +0900
@@ -0,0 +1,126 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Applies sparse `updates` to individual values or slices within a given
+ * <p>
+ * variable according to `indices`.
+ * <p>
+ * `ref` is a `Tensor` with rank `P` and `indices` is a `Tensor` of rank `Q`.
+ * <p>
+ * `indices` must be integer tensor, containing indices into `ref`.
+ * It must be shape `[d_0, ..., d_{Q-2}, K]` where `0 < K <= P`.
+ * <p>
+ * The innermost dimension of `indices` (with length `K`) corresponds to
+ * indices into elements (if `K = P`) or slices (if `K < P`) along the `K`th
+ * dimension of `ref`.
+ * <p>
+ * `updates` is `Tensor` of rank `Q-1+P-K` with shape:
+ * <pre>{@code
+ * [d_0, ..., d_{Q-2}, ref.shape[K], ..., ref.shape[P-1]].
+ * }</pre>
+ * For example, say we want to update 4 scattered elements to a rank-1 tensor to
+ * 8 elements. In Python, that update would look like this:
+ * <pre>{@code
+ *     ref = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])
+ *     indices = tf.constant([[4], [3], [1] ,[7]])
+ *     updates = tf.constant([9, 10, 11, 12])
+ *     update = tf.scatter_nd_update(ref, indices, updates)
+ *     with tf.Session() as sess:
+ *       print sess.run(update)
+ * }</pre>
+ * The resulting update to ref would look like this:
+ * <p>
+ *     [1, 11, 3, 10, 9, 6, 7, 12]
+ * <p>
+ * See `tf.scatter_nd` for more details about how to make updates to
+ * slices.
+ */
+@Operator
+public final class ResourceScatterNdUpdate extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ResourceScatterNdUpdate}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking An optional bool. Defaults to True. If True, the assignment will
+     * be protected by a lock; otherwise the behavior is undefined,
+     * but may exhibit less contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ResourceScatterNdUpdate operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param ref A resource handle. Must be from a VarHandleOp.
+   * @param indices A Tensor. Must be one of the following types: int32, int64.
+   * A tensor of indices into ref.
+   * @param updates A Tensor. Must have the same type as ref. A tensor of updated
+   * values to add to ref.
+   * @param options carries optional attributes values
+   * @return a new instance of ResourceScatterNdUpdate
+   */
+  public static <T extends Number, U> ResourceScatterNdUpdate create(Scope scope, Operand<?> ref, Operand<T> indices, Operand<U> updates, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResourceScatterNdUpdate", scope.makeOpName("ResourceScatterNdUpdate"));
+    opBuilder.addInput(ref.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(updates.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ResourceScatterNdUpdate(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking An optional bool. Defaults to True. If True, the assignment will
+   * be protected by a lock; otherwise the behavior is undefined,
+   * but may exhibit less contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  
+  private ResourceScatterNdUpdate(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResourceScatterSub.java java-ops/org/tensorflow/op/core/ResourceScatterSub.java
--- java/org/tensorflow/op/core/ResourceScatterSub.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResourceScatterSub.java	2018-10-16 20:18:38.461432220 +0900
@@ -0,0 +1,74 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Subtracts sparse updates from the variable referenced by `resource`.
+ * <p>
+ * This operation computes
+ * <p>
+ *     # Scalar indices
+ *     ref[indices, ...] -= updates[...]
+ * <p>
+ *     # Vector indices (for each i)
+ *     ref[indices[i], ...] -= updates[i, ...]
+ * <p>
+ *     # High rank indices (for each i, ..., j)
+ *     ref[indices[i, ..., j], ...] -= updates[i, ..., j, ...]
+ * <p>
+ * Duplicate entries are handled correctly: if multiple `indices` reference
+ * the same location, their contributions add.
+ * <p>
+ * Requires `updates.shape = indices.shape + ref.shape[1:]` or `updates.shape = []`.
+ * <p>
+ * <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
+ * <img style="width:100%" src='https://www.tensorflow.org/images/ScatterAdd.png' alt>
+ * </div>
+ */
+@Operator
+public final class ResourceScatterSub extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new ResourceScatterSub operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param resource Should be from a `Variable` node.
+   * @param indices A tensor of indices into the first dimension of `ref`.
+   * @param updates A tensor of updated values to add to `ref`.
+   * @return a new instance of ResourceScatterSub
+   */
+  public static <T extends Number, U> ResourceScatterSub create(Scope scope, Operand<?> resource, Operand<T> indices, Operand<U> updates) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResourceScatterSub", scope.makeOpName("ResourceScatterSub"));
+    opBuilder.addInput(resource.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(updates.asOutput());
+    return new ResourceScatterSub(opBuilder.build());
+  }
+  
+  
+  private ResourceScatterSub(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResourceScatterUpdate.java java-ops/org/tensorflow/op/core/ResourceScatterUpdate.java
--- java/org/tensorflow/op/core/ResourceScatterUpdate.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResourceScatterUpdate.java	2018-10-16 20:18:38.462432220 +0900
@@ -0,0 +1,65 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Assigns sparse updates to the variable referenced by `resource`.
+ * <p>
+ * This operation computes
+ * <p>
+ *     # Scalar indices
+ *     ref[indices, ...] = updates[...]
+ * <p>
+ *     # Vector indices (for each i)
+ *     ref[indices[i], ...] = updates[i, ...]
+ * <p>
+ *     # High rank indices (for each i, ..., j)
+ *     ref[indices[i, ..., j], ...] = updates[i, ..., j, ...]
+ */
+@Operator
+public final class ResourceScatterUpdate extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new ResourceScatterUpdate operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param resource Should be from a `Variable` node.
+   * @param indices A tensor of indices into the first dimension of `ref`.
+   * @param updates A tensor of updated values to add to `ref`.
+   * @return a new instance of ResourceScatterUpdate
+   */
+  public static <T extends Number, U> ResourceScatterUpdate create(Scope scope, Operand<?> resource, Operand<T> indices, Operand<U> updates) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResourceScatterUpdate", scope.makeOpName("ResourceScatterUpdate"));
+    opBuilder.addInput(resource.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(updates.asOutput());
+    return new ResourceScatterUpdate(opBuilder.build());
+  }
+  
+  
+  private ResourceScatterUpdate(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResourceSparseApplyAdadelta.java java-ops/org/tensorflow/op/core/ResourceSparseApplyAdadelta.java
--- java/org/tensorflow/op/core/ResourceSparseApplyAdadelta.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResourceSparseApplyAdadelta.java	2018-10-16 20:18:38.463432219 +0900
@@ -0,0 +1,100 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * var: Should be from a Variable().
+ */
+@Operator
+public final class ResourceSparseApplyAdadelta extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ResourceSparseApplyAdadelta}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If True, updating of the var and accum tensors will be protected by
+     * a lock; otherwise the behavior is undefined, but may exhibit less contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ResourceSparseApplyAdadelta operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var 
+   * @param accum Should be from a Variable().
+   * @param accumUpdate : Should be from a Variable().
+   * @param lr Learning rate. Must be a scalar.
+   * @param rho Decay factor. Must be a scalar.
+   * @param epsilon Constant factor. Must be a scalar.
+   * @param grad The gradient.
+   * @param indices A vector of indices into the first dimension of var and accum.
+   * @param options carries optional attributes values
+   * @return a new instance of ResourceSparseApplyAdadelta
+   */
+  public static <T, U extends Number> ResourceSparseApplyAdadelta create(Scope scope, Operand<?> var, Operand<?> accum, Operand<?> accumUpdate, Operand<T> lr, Operand<T> rho, Operand<T> epsilon, Operand<T> grad, Operand<U> indices, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResourceSparseApplyAdadelta", scope.makeOpName("ResourceSparseApplyAdadelta"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(accum.asOutput());
+    opBuilder.addInput(accumUpdate.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(rho.asOutput());
+    opBuilder.addInput(epsilon.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ResourceSparseApplyAdadelta(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If True, updating of the var and accum tensors will be protected by
+   * a lock; otherwise the behavior is undefined, but may exhibit less contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  
+  private ResourceSparseApplyAdadelta(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResourceSparseApplyAdagradDA.java java-ops/org/tensorflow/op/core/ResourceSparseApplyAdagradDA.java
--- java/org/tensorflow/op/core/ResourceSparseApplyAdagradDA.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResourceSparseApplyAdagradDA.java	2018-10-16 20:18:38.465432217 +0900
@@ -0,0 +1,102 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update entries in '*var' and '*accum' according to the proximal adagrad scheme.
+ */
+@Operator
+public final class ResourceSparseApplyAdagradDA extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ResourceSparseApplyAdagradDA}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If True, updating of the var and accum tensors will be protected by
+     * a lock; otherwise the behavior is undefined, but may exhibit less contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ResourceSparseApplyAdagradDA operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param gradientAccumulator Should be from a Variable().
+   * @param gradientSquaredAccumulator Should be from a Variable().
+   * @param grad The gradient.
+   * @param indices A vector of indices into the first dimension of var and accum.
+   * @param lr Learning rate. Must be a scalar.
+   * @param l1 L1 regularization. Must be a scalar.
+   * @param l2 L2 regularization. Must be a scalar.
+   * @param globalStep Training step number. Must be a scalar.
+   * @param options carries optional attributes values
+   * @return a new instance of ResourceSparseApplyAdagradDA
+   */
+  public static <T, U extends Number> ResourceSparseApplyAdagradDA create(Scope scope, Operand<?> var, Operand<?> gradientAccumulator, Operand<?> gradientSquaredAccumulator, Operand<T> grad, Operand<U> indices, Operand<T> lr, Operand<T> l1, Operand<T> l2, Operand<Long> globalStep, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResourceSparseApplyAdagradDA", scope.makeOpName("ResourceSparseApplyAdagradDA"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(gradientAccumulator.asOutput());
+    opBuilder.addInput(gradientSquaredAccumulator.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(l1.asOutput());
+    opBuilder.addInput(l2.asOutput());
+    opBuilder.addInput(globalStep.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ResourceSparseApplyAdagradDA(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If True, updating of the var and accum tensors will be protected by
+   * a lock; otherwise the behavior is undefined, but may exhibit less contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  
+  private ResourceSparseApplyAdagradDA(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResourceSparseApplyAdagrad.java java-ops/org/tensorflow/op/core/ResourceSparseApplyAdagrad.java
--- java/org/tensorflow/op/core/ResourceSparseApplyAdagrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResourceSparseApplyAdagrad.java	2018-10-16 20:18:38.464432218 +0900
@@ -0,0 +1,119 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update relevant entries in '*var' and '*accum' according to the adagrad scheme.
+ * <p>
+ * That is for rows we have grad for, we update var and accum as follows:
+ * accum += grad * grad
+ * var -= lr * grad * (1 / sqrt(accum))
+ */
+@Operator
+public final class ResourceSparseApplyAdagrad extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ResourceSparseApplyAdagrad}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If `True`, updating of the var and accum tensors will be protected
+     * by a lock; otherwise the behavior is undefined, but may exhibit less
+     * contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    /**
+     * @param updateSlots 
+     */
+    public Options updateSlots(Boolean updateSlots) {
+      this.updateSlots = updateSlots;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    private Boolean updateSlots;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ResourceSparseApplyAdagrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param accum Should be from a Variable().
+   * @param lr Learning rate. Must be a scalar.
+   * @param grad The gradient.
+   * @param indices A vector of indices into the first dimension of var and accum.
+   * @param options carries optional attributes values
+   * @return a new instance of ResourceSparseApplyAdagrad
+   */
+  public static <T, U extends Number> ResourceSparseApplyAdagrad create(Scope scope, Operand<?> var, Operand<?> accum, Operand<T> lr, Operand<T> grad, Operand<U> indices, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResourceSparseApplyAdagrad", scope.makeOpName("ResourceSparseApplyAdagrad"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(accum.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+        if (opts.updateSlots != null) {
+          opBuilder.setAttr("update_slots", opts.updateSlots);
+        }
+      }
+    }
+    return new ResourceSparseApplyAdagrad(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If `True`, updating of the var and accum tensors will be protected
+   * by a lock; otherwise the behavior is undefined, but may exhibit less
+   * contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * @param updateSlots 
+   */
+  public static Options updateSlots(Boolean updateSlots) {
+    return new Options().updateSlots(updateSlots);
+  }
+  
+  
+  private ResourceSparseApplyAdagrad(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResourceSparseApplyCenteredRMSProp.java java-ops/org/tensorflow/op/core/ResourceSparseApplyCenteredRMSProp.java
--- java/org/tensorflow/op/core/ResourceSparseApplyCenteredRMSProp.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResourceSparseApplyCenteredRMSProp.java	2018-10-16 20:18:38.466432217 +0900
@@ -0,0 +1,123 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update '*var' according to the centered RMSProp algorithm.
+ * <p>
+ * The centered RMSProp algorithm uses an estimate of the centered second moment
+ * (i.e., the variance) for normalization, as opposed to regular RMSProp, which
+ * uses the (uncentered) second moment. This often helps with training, but is
+ * slightly more expensive in terms of computation and memory.
+ * <p>
+ * Note that in dense implementation of this algorithm, mg, ms, and mom will
+ * update even if the grad is zero, but in this sparse implementation, mg, ms,
+ * and mom will not update in iterations during which the grad is zero.
+ * <p>
+ * mean_square = decay * mean_square + (1-decay) * gradient ** 2
+ * mean_grad = decay * mean_grad + (1-decay) * gradient
+ * Delta = learning_rate * gradient / sqrt(mean_square + epsilon - mean_grad ** 2)
+ * <p>
+ * ms <- rho * ms_{t-1} + (1-rho) * grad * grad
+ * mom <- momentum * mom_{t-1} + lr * grad / sqrt(ms + epsilon)
+ * var <- var - mom
+ */
+@Operator
+public final class ResourceSparseApplyCenteredRMSProp extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ResourceSparseApplyCenteredRMSProp}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If `True`, updating of the var, mg, ms, and mom tensors is
+     * protected by a lock; otherwise the behavior is undefined, but may exhibit less
+     * contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ResourceSparseApplyCenteredRMSProp operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param mg Should be from a Variable().
+   * @param ms Should be from a Variable().
+   * @param mom Should be from a Variable().
+   * @param lr Scaling factor. Must be a scalar.
+   * @param rho Decay rate. Must be a scalar.
+   * @param momentum 
+   * @param epsilon Ridge term. Must be a scalar.
+   * @param grad The gradient.
+   * @param indices A vector of indices into the first dimension of var, ms and mom.
+   * @param options carries optional attributes values
+   * @return a new instance of ResourceSparseApplyCenteredRMSProp
+   */
+  public static <T, U extends Number> ResourceSparseApplyCenteredRMSProp create(Scope scope, Operand<?> var, Operand<?> mg, Operand<?> ms, Operand<?> mom, Operand<T> lr, Operand<T> rho, Operand<T> momentum, Operand<T> epsilon, Operand<T> grad, Operand<U> indices, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResourceSparseApplyCenteredRMSProp", scope.makeOpName("ResourceSparseApplyCenteredRMSProp"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(mg.asOutput());
+    opBuilder.addInput(ms.asOutput());
+    opBuilder.addInput(mom.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(rho.asOutput());
+    opBuilder.addInput(momentum.asOutput());
+    opBuilder.addInput(epsilon.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ResourceSparseApplyCenteredRMSProp(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If `True`, updating of the var, mg, ms, and mom tensors is
+   * protected by a lock; otherwise the behavior is undefined, but may exhibit less
+   * contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  
+  private ResourceSparseApplyCenteredRMSProp(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResourceSparseApplyFtrl.java java-ops/org/tensorflow/op/core/ResourceSparseApplyFtrl.java
--- java/org/tensorflow/op/core/ResourceSparseApplyFtrl.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResourceSparseApplyFtrl.java	2018-10-16 20:18:38.467432216 +0900
@@ -0,0 +1,111 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update relevant entries in '*var' according to the Ftrl-proximal scheme.
+ * <p>
+ * That is for rows we have grad for, we update var, accum and linear as follows:
+ * accum_new = accum + grad * grad
+ * linear += grad + (accum_new^(-lr_power) - accum^(-lr_power)) / lr * var
+ * quadratic = 1.0 / (accum_new^(lr_power) * lr) + 2 * l2
+ * var = (sign(linear) * l1 - linear) / quadratic if |linear| > l1 else 0.0
+ * accum = accum_new
+ */
+@Operator
+public final class ResourceSparseApplyFtrl extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ResourceSparseApplyFtrl}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If `True`, updating of the var and accum tensors will be protected
+     * by a lock; otherwise the behavior is undefined, but may exhibit less
+     * contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ResourceSparseApplyFtrl operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param accum Should be from a Variable().
+   * @param linear Should be from a Variable().
+   * @param grad The gradient.
+   * @param indices A vector of indices into the first dimension of var and accum.
+   * @param lr Scaling factor. Must be a scalar.
+   * @param l1 L1 regularization. Must be a scalar.
+   * @param l2 L2 regularization. Must be a scalar.
+   * @param lrPower Scaling factor. Must be a scalar.
+   * @param options carries optional attributes values
+   * @return a new instance of ResourceSparseApplyFtrl
+   */
+  public static <T, U extends Number> ResourceSparseApplyFtrl create(Scope scope, Operand<?> var, Operand<?> accum, Operand<?> linear, Operand<T> grad, Operand<U> indices, Operand<T> lr, Operand<T> l1, Operand<T> l2, Operand<T> lrPower, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResourceSparseApplyFtrl", scope.makeOpName("ResourceSparseApplyFtrl"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(accum.asOutput());
+    opBuilder.addInput(linear.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(l1.asOutput());
+    opBuilder.addInput(l2.asOutput());
+    opBuilder.addInput(lrPower.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ResourceSparseApplyFtrl(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If `True`, updating of the var and accum tensors will be protected
+   * by a lock; otherwise the behavior is undefined, but may exhibit less
+   * contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  
+  private ResourceSparseApplyFtrl(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResourceSparseApplyFtrlV2.java java-ops/org/tensorflow/op/core/ResourceSparseApplyFtrlV2.java
--- java/org/tensorflow/op/core/ResourceSparseApplyFtrlV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResourceSparseApplyFtrlV2.java	2018-10-16 20:18:38.468432215 +0900
@@ -0,0 +1,115 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update relevant entries in '*var' according to the Ftrl-proximal scheme.
+ * <p>
+ * That is for rows we have grad for, we update var, accum and linear as follows:
+ * grad_with_shrinkage = grad + 2 * l2_shrinkage * var
+ * accum_new = accum + grad_with_shrinkage * grad_with_shrinkage
+ * linear += grad_with_shrinkage +
+ *     (accum_new^(-lr_power) - accum^(-lr_power)) / lr * var
+ * quadratic = 1.0 / (accum_new^(lr_power) * lr) + 2 * l2
+ * var = (sign(linear) * l1 - linear) / quadratic if |linear| > l1 else 0.0
+ * accum = accum_new
+ */
+@Operator
+public final class ResourceSparseApplyFtrlV2 extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ResourceSparseApplyFtrlV2}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If `True`, updating of the var and accum tensors will be protected
+     * by a lock; otherwise the behavior is undefined, but may exhibit less
+     * contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ResourceSparseApplyFtrlV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param accum Should be from a Variable().
+   * @param linear Should be from a Variable().
+   * @param grad The gradient.
+   * @param indices A vector of indices into the first dimension of var and accum.
+   * @param lr Scaling factor. Must be a scalar.
+   * @param l1 L1 regularization. Must be a scalar.
+   * @param l2 L2 shrinkage regulariation. Must be a scalar.
+   * @param l2Shrinkage 
+   * @param lrPower Scaling factor. Must be a scalar.
+   * @param options carries optional attributes values
+   * @return a new instance of ResourceSparseApplyFtrlV2
+   */
+  public static <T, U extends Number> ResourceSparseApplyFtrlV2 create(Scope scope, Operand<?> var, Operand<?> accum, Operand<?> linear, Operand<T> grad, Operand<U> indices, Operand<T> lr, Operand<T> l1, Operand<T> l2, Operand<T> l2Shrinkage, Operand<T> lrPower, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResourceSparseApplyFtrlV2", scope.makeOpName("ResourceSparseApplyFtrlV2"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(accum.asOutput());
+    opBuilder.addInput(linear.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(l1.asOutput());
+    opBuilder.addInput(l2.asOutput());
+    opBuilder.addInput(l2Shrinkage.asOutput());
+    opBuilder.addInput(lrPower.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ResourceSparseApplyFtrlV2(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If `True`, updating of the var and accum tensors will be protected
+   * by a lock; otherwise the behavior is undefined, but may exhibit less
+   * contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  
+  private ResourceSparseApplyFtrlV2(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResourceSparseApplyMomentum.java java-ops/org/tensorflow/op/core/ResourceSparseApplyMomentum.java
--- java/org/tensorflow/op/core/ResourceSparseApplyMomentum.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResourceSparseApplyMomentum.java	2018-10-16 20:18:38.469432214 +0900
@@ -0,0 +1,128 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update relevant entries in '*var' and '*accum' according to the momentum scheme.
+ * <p>
+ * Set use_nesterov = True if you want to use Nesterov momentum.
+ * <p>
+ * That is for rows we have grad for, we update var and accum as follows:
+ * <p>
+ * accum = accum * momentum + grad
+ * var -= lr * accum
+ */
+@Operator
+public final class ResourceSparseApplyMomentum extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ResourceSparseApplyMomentum}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If `True`, updating of the var and accum tensors will be protected
+     * by a lock; otherwise the behavior is undefined, but may exhibit less
+     * contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    /**
+     * @param useNesterov If `True`, the tensor passed to compute grad will be
+     * var - lr * momentum * accum, so in the end, the var you get is actually
+     * var - lr * momentum * accum.
+     */
+    public Options useNesterov(Boolean useNesterov) {
+      this.useNesterov = useNesterov;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    private Boolean useNesterov;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ResourceSparseApplyMomentum operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param accum Should be from a Variable().
+   * @param lr Learning rate. Must be a scalar.
+   * @param grad The gradient.
+   * @param indices A vector of indices into the first dimension of var and accum.
+   * @param momentum Momentum. Must be a scalar.
+   * @param options carries optional attributes values
+   * @return a new instance of ResourceSparseApplyMomentum
+   */
+  public static <T, U extends Number> ResourceSparseApplyMomentum create(Scope scope, Operand<?> var, Operand<?> accum, Operand<T> lr, Operand<T> grad, Operand<U> indices, Operand<T> momentum, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResourceSparseApplyMomentum", scope.makeOpName("ResourceSparseApplyMomentum"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(accum.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(momentum.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+        if (opts.useNesterov != null) {
+          opBuilder.setAttr("use_nesterov", opts.useNesterov);
+        }
+      }
+    }
+    return new ResourceSparseApplyMomentum(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If `True`, updating of the var and accum tensors will be protected
+   * by a lock; otherwise the behavior is undefined, but may exhibit less
+   * contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * @param useNesterov If `True`, the tensor passed to compute grad will be
+   * var - lr * momentum * accum, so in the end, the var you get is actually
+   * var - lr * momentum * accum.
+   */
+  public static Options useNesterov(Boolean useNesterov) {
+    return new Options().useNesterov(useNesterov);
+  }
+  
+  
+  private ResourceSparseApplyMomentum(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResourceSparseApplyProximalAdagrad.java java-ops/org/tensorflow/op/core/ResourceSparseApplyProximalAdagrad.java
--- java/org/tensorflow/op/core/ResourceSparseApplyProximalAdagrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResourceSparseApplyProximalAdagrad.java	2018-10-16 20:18:38.470432214 +0900
@@ -0,0 +1,104 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Sparse update entries in '*var' and '*accum' according to FOBOS algorithm.
+ * <p>
+ * That is for rows we have grad for, we update var and accum as follows:
+ * accum += grad <i> grad
+ * prox_v = var
+ * prox_v -= lr </i> grad <i> (1 / sqrt(accum))
+ * var = sign(prox_v)/(1+lr</i>l2) <i> max{|prox_v|-lr</i>l1,0}
+ */
+@Operator
+public final class ResourceSparseApplyProximalAdagrad extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ResourceSparseApplyProximalAdagrad}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If True, updating of the var and accum tensors will be protected by
+     * a lock; otherwise the behavior is undefined, but may exhibit less contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ResourceSparseApplyProximalAdagrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param accum Should be from a Variable().
+   * @param lr Learning rate. Must be a scalar.
+   * @param l1 L1 regularization. Must be a scalar.
+   * @param l2 L2 regularization. Must be a scalar.
+   * @param grad The gradient.
+   * @param indices A vector of indices into the first dimension of var and accum.
+   * @param options carries optional attributes values
+   * @return a new instance of ResourceSparseApplyProximalAdagrad
+   */
+  public static <T, U extends Number> ResourceSparseApplyProximalAdagrad create(Scope scope, Operand<?> var, Operand<?> accum, Operand<T> lr, Operand<T> l1, Operand<T> l2, Operand<T> grad, Operand<U> indices, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResourceSparseApplyProximalAdagrad", scope.makeOpName("ResourceSparseApplyProximalAdagrad"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(accum.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(l1.asOutput());
+    opBuilder.addInput(l2.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ResourceSparseApplyProximalAdagrad(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If True, updating of the var and accum tensors will be protected by
+   * a lock; otherwise the behavior is undefined, but may exhibit less contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  
+  private ResourceSparseApplyProximalAdagrad(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResourceSparseApplyProximalGradientDescent.java java-ops/org/tensorflow/op/core/ResourceSparseApplyProximalGradientDescent.java
--- java/org/tensorflow/op/core/ResourceSparseApplyProximalGradientDescent.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResourceSparseApplyProximalGradientDescent.java	2018-10-16 20:18:38.471432213 +0900
@@ -0,0 +1,100 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Sparse update '*var' as FOBOS algorithm with fixed learning rate.
+ * <p>
+ * That is for rows we have grad for, we update var as follows:
+ * prox_v = var - alpha <i> grad
+ * var = sign(prox_v)/(1+alpha</i>l2) <i> max{|prox_v|-alpha</i>l1,0}
+ */
+@Operator
+public final class ResourceSparseApplyProximalGradientDescent extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ResourceSparseApplyProximalGradientDescent}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If True, the subtraction will be protected by a lock;
+     * otherwise the behavior is undefined, but may exhibit less contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ResourceSparseApplyProximalGradientDescent operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param alpha Scaling factor. Must be a scalar.
+   * @param l1 L1 regularization. Must be a scalar.
+   * @param l2 L2 regularization. Must be a scalar.
+   * @param grad The gradient.
+   * @param indices A vector of indices into the first dimension of var and accum.
+   * @param options carries optional attributes values
+   * @return a new instance of ResourceSparseApplyProximalGradientDescent
+   */
+  public static <T, U extends Number> ResourceSparseApplyProximalGradientDescent create(Scope scope, Operand<?> var, Operand<T> alpha, Operand<T> l1, Operand<T> l2, Operand<T> grad, Operand<U> indices, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResourceSparseApplyProximalGradientDescent", scope.makeOpName("ResourceSparseApplyProximalGradientDescent"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(alpha.asOutput());
+    opBuilder.addInput(l1.asOutput());
+    opBuilder.addInput(l2.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ResourceSparseApplyProximalGradientDescent(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If True, the subtraction will be protected by a lock;
+   * otherwise the behavior is undefined, but may exhibit less contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  
+  private ResourceSparseApplyProximalGradientDescent(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResourceSparseApplyRMSProp.java java-ops/org/tensorflow/op/core/ResourceSparseApplyRMSProp.java
--- java/org/tensorflow/op/core/ResourceSparseApplyRMSProp.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResourceSparseApplyRMSProp.java	2018-10-16 20:18:38.471432213 +0900
@@ -0,0 +1,115 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update '*var' according to the RMSProp algorithm.
+ * <p>
+ * Note that in dense implementation of this algorithm, ms and mom will
+ * update even if the grad is zero, but in this sparse implementation, ms
+ * and mom will not update in iterations during which the grad is zero.
+ * <p>
+ * mean_square = decay * mean_square + (1-decay) * gradient ** 2
+ * Delta = learning_rate * gradient / sqrt(mean_square + epsilon)
+ * <p>
+ * ms <- rho * ms_{t-1} + (1-rho) * grad * grad
+ * mom <- momentum * mom_{t-1} + lr * grad / sqrt(ms + epsilon)
+ * var <- var - mom
+ */
+@Operator
+public final class ResourceSparseApplyRMSProp extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ResourceSparseApplyRMSProp}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If `True`, updating of the var, ms, and mom tensors is protected
+     * by a lock; otherwise the behavior is undefined, but may exhibit less
+     * contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ResourceSparseApplyRMSProp operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param ms Should be from a Variable().
+   * @param mom Should be from a Variable().
+   * @param lr Scaling factor. Must be a scalar.
+   * @param rho Decay rate. Must be a scalar.
+   * @param momentum 
+   * @param epsilon Ridge term. Must be a scalar.
+   * @param grad The gradient.
+   * @param indices A vector of indices into the first dimension of var, ms and mom.
+   * @param options carries optional attributes values
+   * @return a new instance of ResourceSparseApplyRMSProp
+   */
+  public static <T, U extends Number> ResourceSparseApplyRMSProp create(Scope scope, Operand<?> var, Operand<?> ms, Operand<?> mom, Operand<T> lr, Operand<T> rho, Operand<T> momentum, Operand<T> epsilon, Operand<T> grad, Operand<U> indices, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResourceSparseApplyRMSProp", scope.makeOpName("ResourceSparseApplyRMSProp"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(ms.asOutput());
+    opBuilder.addInput(mom.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(rho.asOutput());
+    opBuilder.addInput(momentum.asOutput());
+    opBuilder.addInput(epsilon.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ResourceSparseApplyRMSProp(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If `True`, updating of the var, ms, and mom tensors is protected
+   * by a lock; otherwise the behavior is undefined, but may exhibit less
+   * contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  
+  private ResourceSparseApplyRMSProp(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ResourceStridedSliceAssign.java java-ops/org/tensorflow/op/core/ResourceStridedSliceAssign.java
--- java/org/tensorflow/op/core/ResourceStridedSliceAssign.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ResourceStridedSliceAssign.java	2018-10-16 20:18:38.472432212 +0900
@@ -0,0 +1,175 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Assign `value` to the sliced l-value reference of `ref`.
+ * <p>
+ * The values of `value` are assigned to the positions in the variable
+ * `ref` that are selected by the slice parameters. The slice parameters
+ * `begin, `end`, `strides`, etc. work exactly as in `StridedSlice`.
+ * <p>
+ * NOTE this op currently does not support broadcasting and so `value`'s
+ * shape must be exactly the shape produced by the slice of `ref`.
+ */
+@Operator
+public final class ResourceStridedSliceAssign extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ResourceStridedSliceAssign}
+   */
+  public static class Options {
+    
+    /**
+     * @param beginMask 
+     */
+    public Options beginMask(Long beginMask) {
+      this.beginMask = beginMask;
+      return this;
+    }
+    
+    /**
+     * @param endMask 
+     */
+    public Options endMask(Long endMask) {
+      this.endMask = endMask;
+      return this;
+    }
+    
+    /**
+     * @param ellipsisMask 
+     */
+    public Options ellipsisMask(Long ellipsisMask) {
+      this.ellipsisMask = ellipsisMask;
+      return this;
+    }
+    
+    /**
+     * @param newAxisMask 
+     */
+    public Options newAxisMask(Long newAxisMask) {
+      this.newAxisMask = newAxisMask;
+      return this;
+    }
+    
+    /**
+     * @param shrinkAxisMask 
+     */
+    public Options shrinkAxisMask(Long shrinkAxisMask) {
+      this.shrinkAxisMask = shrinkAxisMask;
+      return this;
+    }
+    
+    private Long beginMask;
+    private Long endMask;
+    private Long ellipsisMask;
+    private Long newAxisMask;
+    private Long shrinkAxisMask;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ResourceStridedSliceAssign operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param ref 
+   * @param begin 
+   * @param end 
+   * @param strides 
+   * @param value 
+   * @param options carries optional attributes values
+   * @return a new instance of ResourceStridedSliceAssign
+   */
+  public static <T extends Number, U> ResourceStridedSliceAssign create(Scope scope, Operand<?> ref, Operand<T> begin, Operand<T> end, Operand<T> strides, Operand<U> value, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ResourceStridedSliceAssign", scope.makeOpName("ResourceStridedSliceAssign"));
+    opBuilder.addInput(ref.asOutput());
+    opBuilder.addInput(begin.asOutput());
+    opBuilder.addInput(end.asOutput());
+    opBuilder.addInput(strides.asOutput());
+    opBuilder.addInput(value.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.beginMask != null) {
+          opBuilder.setAttr("begin_mask", opts.beginMask);
+        }
+        if (opts.endMask != null) {
+          opBuilder.setAttr("end_mask", opts.endMask);
+        }
+        if (opts.ellipsisMask != null) {
+          opBuilder.setAttr("ellipsis_mask", opts.ellipsisMask);
+        }
+        if (opts.newAxisMask != null) {
+          opBuilder.setAttr("new_axis_mask", opts.newAxisMask);
+        }
+        if (opts.shrinkAxisMask != null) {
+          opBuilder.setAttr("shrink_axis_mask", opts.shrinkAxisMask);
+        }
+      }
+    }
+    return new ResourceStridedSliceAssign(opBuilder.build());
+  }
+  
+  /**
+   * @param beginMask 
+   */
+  public static Options beginMask(Long beginMask) {
+    return new Options().beginMask(beginMask);
+  }
+  
+  /**
+   * @param endMask 
+   */
+  public static Options endMask(Long endMask) {
+    return new Options().endMask(endMask);
+  }
+  
+  /**
+   * @param ellipsisMask 
+   */
+  public static Options ellipsisMask(Long ellipsisMask) {
+    return new Options().ellipsisMask(ellipsisMask);
+  }
+  
+  /**
+   * @param newAxisMask 
+   */
+  public static Options newAxisMask(Long newAxisMask) {
+    return new Options().newAxisMask(newAxisMask);
+  }
+  
+  /**
+   * @param shrinkAxisMask 
+   */
+  public static Options shrinkAxisMask(Long shrinkAxisMask) {
+    return new Options().shrinkAxisMask(shrinkAxisMask);
+  }
+  
+  
+  private ResourceStridedSliceAssign(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Restore.java java-ops/org/tensorflow/op/core/Restore.java
--- java/org/tensorflow/op/core/Restore.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Restore.java	2018-10-16 20:18:38.472432212 +0900
@@ -0,0 +1,128 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Restores a tensor from checkpoint files.
+ * <p>
+ * Reads a tensor stored in one or several files. If there are several files (for
+ * instance because a tensor was saved as slices), `file_pattern` may contain
+ * wildcard symbols (`*` and `?`) in the filename portion only, not in the
+ * directory portion.
+ * <p>
+ * If a `file_pattern` matches several files, `preferred_shard` can be used to hint
+ * in which file the requested tensor is likely to be found. This op will first
+ * open the file at index `preferred_shard` in the list of matching files and try
+ * to restore tensors from that file.  Only if some tensors or tensor slices are
+ * not found in that first file, then the Op opens all the files. Setting
+ * `preferred_shard` to match the value passed as the `shard` input
+ * of a matching `Save` Op may speed up Restore.  This attribute only affects
+ * performance, not correctness.  The default value -1 means files are processed in
+ * order.
+ * <p>
+ * See also `RestoreSlice`.
+ * 
+ * @param <T> data type for {@code tensor()} output
+ */
+@Operator
+public final class Restore<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Restore}
+   */
+  public static class Options {
+    
+    /**
+     * @param preferredShard Index of file to open first if multiple files match
+     * `file_pattern`.
+     */
+    public Options preferredShard(Long preferredShard) {
+      this.preferredShard = preferredShard;
+      return this;
+    }
+    
+    private Long preferredShard;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Restore operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param filePattern Must have a single element. The pattern of the files from
+   * which we read the tensor.
+   * @param tensorName Must have a single element. The name of the tensor to be
+   * restored.
+   * @param dt The type of the tensor to be restored.
+   * @param options carries optional attributes values
+   * @return a new instance of Restore
+   */
+  public static <T> Restore<T> create(Scope scope, Operand<String> filePattern, Operand<String> tensorName, Class<T> dt, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Restore", scope.makeOpName("Restore"));
+    opBuilder.addInput(filePattern.asOutput());
+    opBuilder.addInput(tensorName.asOutput());
+    opBuilder.setAttr("dt", DataType.fromClass(dt));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.preferredShard != null) {
+          opBuilder.setAttr("preferred_shard", opts.preferredShard);
+        }
+      }
+    }
+    return new Restore<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param preferredShard Index of file to open first if multiple files match
+   * `file_pattern`.
+   */
+  public static Options preferredShard(Long preferredShard) {
+    return new Options().preferredShard(preferredShard);
+  }
+  
+  /**
+   * The restored tensor.
+   */
+  public Output<T> tensor() {
+    return tensor;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return tensor;
+  }
+  
+  private Output<T> tensor;
+  
+  private Restore(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    tensor = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/RestoreSlice.java java-ops/org/tensorflow/op/core/RestoreSlice.java
--- java/org/tensorflow/op/core/RestoreSlice.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/RestoreSlice.java	2018-10-16 20:18:38.473432212 +0900
@@ -0,0 +1,121 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Restores a tensor from checkpoint files.
+ * <p>
+ * This is like `Restore` except that restored tensor can be listed as filling
+ * only a slice of a larger tensor.  `shape_and_slice` specifies the shape of the
+ * larger tensor and the slice that the restored tensor covers.
+ * <p>
+ * The `shape_and_slice` input has the same format as the
+ * elements of the `shapes_and_slices` input of the `SaveSlices` op.
+ * 
+ * @param <T> data type for {@code tensor()} output
+ */
+@Operator
+public final class RestoreSlice<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.RestoreSlice}
+   */
+  public static class Options {
+    
+    /**
+     * @param preferredShard Index of file to open first if multiple files match
+     * `file_pattern`. See the documentation for `Restore`.
+     */
+    public Options preferredShard(Long preferredShard) {
+      this.preferredShard = preferredShard;
+      return this;
+    }
+    
+    private Long preferredShard;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new RestoreSlice operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param filePattern Must have a single element. The pattern of the files from
+   * which we read the tensor.
+   * @param tensorName Must have a single element. The name of the tensor to be
+   * restored.
+   * @param shapeAndSlice Scalar. The shapes and slice specifications to use when
+   * restoring a tensors.
+   * @param dt The type of the tensor to be restored.
+   * @param options carries optional attributes values
+   * @return a new instance of RestoreSlice
+   */
+  public static <T> RestoreSlice<T> create(Scope scope, Operand<String> filePattern, Operand<String> tensorName, Operand<String> shapeAndSlice, Class<T> dt, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("RestoreSlice", scope.makeOpName("RestoreSlice"));
+    opBuilder.addInput(filePattern.asOutput());
+    opBuilder.addInput(tensorName.asOutput());
+    opBuilder.addInput(shapeAndSlice.asOutput());
+    opBuilder.setAttr("dt", DataType.fromClass(dt));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.preferredShard != null) {
+          opBuilder.setAttr("preferred_shard", opts.preferredShard);
+        }
+      }
+    }
+    return new RestoreSlice<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param preferredShard Index of file to open first if multiple files match
+   * `file_pattern`. See the documentation for `Restore`.
+   */
+  public static Options preferredShard(Long preferredShard) {
+    return new Options().preferredShard(preferredShard);
+  }
+  
+  /**
+   * The restored tensor.
+   */
+  public Output<T> tensor() {
+    return tensor;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return tensor;
+  }
+  
+  private Output<T> tensor;
+  
+  private RestoreSlice(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    tensor = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/RestoreV2.java java-ops/org/tensorflow/op/core/RestoreV2.java
--- java/org/tensorflow/op/core/RestoreV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/RestoreV2.java	2018-10-16 20:18:38.473432212 +0900
@@ -0,0 +1,100 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.Iterator;
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Restores tensors from a V2 checkpoint.
+ * <p>
+ * For backward compatibility with the V1 format, this Op currently allows
+ * restoring from a V1 checkpoint as well:
+ *   - This Op first attempts to find the V2 index file pointed to by "prefix", and
+ *     if found proceed to read it as a V2 checkpoint;
+ *   - Otherwise the V1 read path is invoked.
+ * Relying on this behavior is not recommended, as the ability to fall back to read
+ * V1 might be deprecated and eventually removed.
+ * <p>
+ * By default, restores the named tensors in full.  If the caller wishes to restore
+ * specific slices of stored tensors, "shape_and_slices" should be non-empty
+ * strings and correspondingly well-formed.
+ * <p>
+ * Callers must ensure all the named tensors are indeed stored in the checkpoint.
+ */
+@Operator
+public final class RestoreV2 extends PrimitiveOp implements Iterable<Operand<Object>> {
+  
+  /**
+   * Factory method to create a class to wrap a new RestoreV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param prefix Must have a single element.  The prefix of a V2 checkpoint.
+   * @param tensorNames shape {N}.  The names of the tensors to be restored.
+   * @param shapeAndSlices shape {N}.  The slice specs of the tensors to be restored.
+   * Empty strings indicate that they are non-partitioned tensors.
+   * @param dtypes shape {N}.  The list of expected dtype for the tensors.  Must match
+   * those stored in the checkpoint.
+   * @return a new instance of RestoreV2
+   */
+  public static RestoreV2 create(Scope scope, Operand<String> prefix, Operand<String> tensorNames, Operand<String> shapeAndSlices, List<Class<?>> dtypes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("RestoreV2", scope.makeOpName("RestoreV2"));
+    opBuilder.addInput(prefix.asOutput());
+    opBuilder.addInput(tensorNames.asOutput());
+    opBuilder.addInput(shapeAndSlices.asOutput());
+    DataType[] dtypesArray = new DataType[dtypes.size()];
+    for (int i = 0; i < dtypesArray.length; ++i) {
+      dtypesArray[i] = DataType.fromClass(dtypes.get(i));
+    }
+    opBuilder.setAttr("dtypes", dtypesArray);
+    return new RestoreV2(opBuilder.build());
+  }
+  
+  /**
+   * shape {N}.  The restored tensors, whose shapes are read from the
+   * checkpoint directly.
+   */
+  public List<Output<?>> tensors() {
+    return tensors;
+  }
+  
+  @Override
+  @SuppressWarnings({"rawtypes", "unchecked"})
+  public Iterator<Operand<Object>> iterator() {
+    return (Iterator) tensors.iterator();
+  }
+  
+  private List<Output<?>> tensors;
+  
+  private RestoreV2(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    int tensorsLength = operation.outputListLength("tensors");
+    tensors = Arrays.asList(operation.outputList(outputIdx, tensorsLength));
+    outputIdx += tensorsLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/Reverse.java java-ops/org/tensorflow/op/core/Reverse.java
--- java/org/tensorflow/op/core/Reverse.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Reverse.java	2018-10-16 20:18:38.474432211 +0900
@@ -0,0 +1,118 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Reverses specific dimensions of a tensor.
+ * <p>
+ * NOTE `tf.reverse` has now changed behavior in preparation for 1.0.
+ * `tf.reverse_v2` is currently an alias that will be deprecated before TF 1.0.
+ * <p>
+ * Given a `tensor`, and a `int32` tensor `axis` representing the set of
+ * dimensions of `tensor` to reverse. This operation reverses each dimension
+ * `i` for which there exists `j` s.t. `axis[j] == i`.
+ * <p>
+ * `tensor` can have up to 8 dimensions. The number of dimensions specified
+ * in `axis` may be 0 or more entries. If an index is specified more than
+ * once, a InvalidArgument error is raised.
+ * <p>
+ * For example:
+ * <pre>{@code
+ * # tensor 't' is [[[[ 0,  1,  2,  3],
+ * #                  [ 4,  5,  6,  7],
+ * #                  [ 8,  9, 10, 11]],
+ * #                 [[12, 13, 14, 15],
+ * #                  [16, 17, 18, 19],
+ * #                  [20, 21, 22, 23]]]]
+ * # tensor 't' shape is [1, 2, 3, 4]
+ * 
+ * # 'dims' is [3] or 'dims' is [-1]
+ * reverse(t, dims) ==> [[[[ 3,  2,  1,  0],
+ *                         [ 7,  6,  5,  4],
+ *                         [ 11, 10, 9, 8]],
+ *                        [[15, 14, 13, 12],
+ *                         [19, 18, 17, 16],
+ *                         [23, 22, 21, 20]]]]
+ * 
+ * # 'dims' is '[1]' (or 'dims' is '[-3]')
+ * reverse(t, dims) ==> [[[[12, 13, 14, 15],
+ *                         [16, 17, 18, 19],
+ *                         [20, 21, 22, 23]
+ *                        [[ 0,  1,  2,  3],
+ *                         [ 4,  5,  6,  7],
+ *                         [ 8,  9, 10, 11]]]]
+ * 
+ * # 'dims' is '[2]' (or 'dims' is '[-2]')
+ * reverse(t, dims) ==> [[[[8, 9, 10, 11],
+ *                         [4, 5, 6, 7],
+ *                         [0, 1, 2, 3]]
+ *                        [[20, 21, 22, 23],
+ *                         [16, 17, 18, 19],
+ *                         [12, 13, 14, 15]]]]
+ * }</pre>
+ * 
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class Reverse<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Reverse operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param tensor Up to 8-D.
+   * @param axis 1-D. The indices of the dimensions to reverse. Must be in the range
+   * `[-rank(tensor), rank(tensor))`.
+   * @return a new instance of Reverse
+   */
+  public static <T, U extends Number> Reverse<T> create(Scope scope, Operand<T> tensor, Operand<U> axis) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ReverseV2", scope.makeOpName("Reverse"));
+    opBuilder.addInput(tensor.asOutput());
+    opBuilder.addInput(axis.asOutput());
+    return new Reverse<T>(opBuilder.build());
+  }
+  
+  /**
+   * The same shape as `tensor`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private Reverse(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ReverseSequence.java java-ops/org/tensorflow/op/core/ReverseSequence.java
--- java/org/tensorflow/op/core/ReverseSequence.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ReverseSequence.java	2018-10-16 20:18:38.474432211 +0900
@@ -0,0 +1,160 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Reverses variable length slices.
+ * <p>
+ * This op first slices `input` along the dimension `batch_dim`, and for each
+ * slice `i`, reverses the first `seq_lengths[i]` elements along
+ * the dimension `seq_dim`.
+ * <p>
+ * The elements of `seq_lengths` must obey `seq_lengths[i] <= input.dims[seq_dim]`,
+ * and `seq_lengths` must be a vector of length `input.dims[batch_dim]`.
+ * <p>
+ * The output slice `i` along dimension `batch_dim` is then given by input
+ * slice `i`, with the first `seq_lengths[i]` slices along dimension
+ * `seq_dim` reversed.
+ * <p>
+ * For example:
+ * <pre>{@code
+ * # Given this:
+ * batch_dim = 0
+ * seq_dim = 1
+ * input.dims = (4, 8, ...)
+ * seq_lengths = [7, 2, 3, 5]
+ * 
+ * # then slices of input are reversed on seq_dim, but only up to seq_lengths:
+ * output[0, 0:7, :, ...] = input[0, 7:0:-1, :, ...]
+ * output[1, 0:2, :, ...] = input[1, 2:0:-1, :, ...]
+ * output[2, 0:3, :, ...] = input[2, 3:0:-1, :, ...]
+ * output[3, 0:5, :, ...] = input[3, 5:0:-1, :, ...]
+ * 
+ * # while entries past seq_lens are copied through:
+ * output[0, 7:, :, ...] = input[0, 7:, :, ...]
+ * output[1, 2:, :, ...] = input[1, 2:, :, ...]
+ * output[2, 3:, :, ...] = input[2, 3:, :, ...]
+ * output[3, 2:, :, ...] = input[3, 2:, :, ...]
+ * }</pre>
+ * In contrast, if:
+ * <pre>{@code
+ * # Given this:
+ * batch_dim = 2
+ * seq_dim = 0
+ * input.dims = (8, ?, 4, ...)
+ * seq_lengths = [7, 2, 3, 5]
+ * 
+ * # then slices of input are reversed on seq_dim, but only up to seq_lengths:
+ * output[0:7, :, 0, :, ...] = input[7:0:-1, :, 0, :, ...]
+ * output[0:2, :, 1, :, ...] = input[2:0:-1, :, 1, :, ...]
+ * output[0:3, :, 2, :, ...] = input[3:0:-1, :, 2, :, ...]
+ * output[0:5, :, 3, :, ...] = input[5:0:-1, :, 3, :, ...]
+ * 
+ * # while entries past seq_lens are copied through:
+ * output[7:, :, 0, :, ...] = input[7:, :, 0, :, ...]
+ * output[2:, :, 1, :, ...] = input[2:, :, 1, :, ...]
+ * output[3:, :, 2, :, ...] = input[3:, :, 2, :, ...]
+ * output[2:, :, 3, :, ...] = input[2:, :, 3, :, ...]
+ * }</pre>
+ * 
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class ReverseSequence<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ReverseSequence}
+   */
+  public static class Options {
+    
+    /**
+     * @param batchDim The dimension along which reversal is performed.
+     */
+    public Options batchDim(Long batchDim) {
+      this.batchDim = batchDim;
+      return this;
+    }
+    
+    private Long batchDim;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ReverseSequence operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input The input to reverse.
+   * @param seqLengths 1-D with length `input.dims(batch_dim)` and
+   * `max(seq_lengths) <= input.dims(seq_dim)`
+   * @param seqDim The dimension which is partially reversed.
+   * @param options carries optional attributes values
+   * @return a new instance of ReverseSequence
+   */
+  public static <T, U extends Number> ReverseSequence<T> create(Scope scope, Operand<T> input, Operand<U> seqLengths, Long seqDim, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ReverseSequence", scope.makeOpName("ReverseSequence"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(seqLengths.asOutput());
+    opBuilder.setAttr("seq_dim", seqDim);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.batchDim != null) {
+          opBuilder.setAttr("batch_dim", opts.batchDim);
+        }
+      }
+    }
+    return new ReverseSequence<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param batchDim The dimension along which reversal is performed.
+   */
+  public static Options batchDim(Long batchDim) {
+    return new Options().batchDim(batchDim);
+  }
+  
+  /**
+   * The partially reversed input. It has the same shape as `input`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private ReverseSequence(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/RFFT2D.java java-ops/org/tensorflow/op/core/RFFT2D.java
--- java/org/tensorflow/op/core/RFFT2D.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/RFFT2D.java	2018-10-16 20:18:38.406432259 +0900
@@ -0,0 +1,88 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * 2D real-valued fast Fourier transform.
+ * <p>
+ * Computes the 2-dimensional discrete Fourier transform of a real-valued signal
+ * over the inner-most 2 dimensions of `input`.
+ * <p>
+ * Since the DFT of a real signal is Hermitian-symmetric, `RFFT2D` only returns the
+ * `fft_length / 2 + 1` unique components of the FFT for the inner-most dimension
+ * of `output`: the zero-frequency term, followed by the `fft_length / 2`
+ * positive-frequency terms.
+ * <p>
+ * Along each axis `RFFT2D` is computed on, if `fft_length` is smaller than the
+ * corresponding dimension of `input`, the dimension is cropped. If it is larger,
+ * the dimension is padded with zeros.
+ */
+@Operator
+public final class RFFT2D extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new RFFT2D operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input A float32 tensor.
+   * @param fftLength An int32 tensor of shape [2]. The FFT length for each dimension.
+   * @return a new instance of RFFT2D
+   */
+  public static RFFT2D create(Scope scope, Operand<Float> input, Operand<Integer> fftLength) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("RFFT2D", scope.makeOpName("RFFT2D"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(fftLength.asOutput());
+    return new RFFT2D(opBuilder.build());
+  }
+  
+  /**
+   * A complex64 tensor of the same rank as `input`. The inner-most 2
+   *   dimensions of `input` are replaced with their 2D Fourier transform. The
+   *   inner-most dimension contains `fft_length / 2 + 1` unique frequency
+   *   components.
+   * <p>
+   * @compatibility(numpy)
+   * Equivalent to np.fft.rfft2
+   * @end_compatibility
+   */
+  public Output<?> output() {
+    return output;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) output;
+  }
+  
+  private Output<?> output;
+  
+  private RFFT2D(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/RFFT3D.java java-ops/org/tensorflow/op/core/RFFT3D.java
--- java/org/tensorflow/op/core/RFFT3D.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/RFFT3D.java	2018-10-16 20:18:38.406432259 +0900
@@ -0,0 +1,88 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * 3D real-valued fast Fourier transform.
+ * <p>
+ * Computes the 3-dimensional discrete Fourier transform of a real-valued signal
+ * over the inner-most 3 dimensions of `input`.
+ * <p>
+ * Since the DFT of a real signal is Hermitian-symmetric, `RFFT3D` only returns the
+ * `fft_length / 2 + 1` unique components of the FFT for the inner-most dimension
+ * of `output`: the zero-frequency term, followed by the `fft_length / 2`
+ * positive-frequency terms.
+ * <p>
+ * Along each axis `RFFT3D` is computed on, if `fft_length` is smaller than the
+ * corresponding dimension of `input`, the dimension is cropped. If it is larger,
+ * the dimension is padded with zeros.
+ */
+@Operator
+public final class RFFT3D extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new RFFT3D operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input A float32 tensor.
+   * @param fftLength An int32 tensor of shape [3]. The FFT length for each dimension.
+   * @return a new instance of RFFT3D
+   */
+  public static RFFT3D create(Scope scope, Operand<Float> input, Operand<Integer> fftLength) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("RFFT3D", scope.makeOpName("RFFT3D"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(fftLength.asOutput());
+    return new RFFT3D(opBuilder.build());
+  }
+  
+  /**
+   * A complex64 tensor of the same rank as `input`. The inner-most 3
+   *   dimensions of `input` are replaced with the their 3D Fourier transform. The
+   *   inner-most dimension contains `fft_length / 2 + 1` unique frequency
+   *   components.
+   * <p>
+   * @compatibility(numpy)
+   * Equivalent to np.fft.rfftn with 3 dimensions.
+   * @end_compatibility
+   */
+  public Output<?> output() {
+    return output;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) output;
+  }
+  
+  private Output<?> output;
+  
+  private RFFT3D(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/RFFT.java java-ops/org/tensorflow/op/core/RFFT.java
--- java/org/tensorflow/op/core/RFFT.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/RFFT.java	2018-10-16 20:18:38.405432259 +0900
@@ -0,0 +1,86 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Real-valued fast Fourier transform.
+ * <p>
+ * Computes the 1-dimensional discrete Fourier transform of a real-valued signal
+ * over the inner-most dimension of `input`.
+ * <p>
+ * Since the DFT of a real signal is Hermitian-symmetric, `RFFT` only returns the
+ * `fft_length / 2 + 1` unique components of the FFT: the zero-frequency term,
+ * followed by the `fft_length / 2` positive-frequency terms.
+ * <p>
+ * Along the axis `RFFT` is computed on, if `fft_length` is smaller than the
+ * corresponding dimension of `input`, the dimension is cropped. If it is larger,
+ * the dimension is padded with zeros.
+ */
+@Operator
+public final class RFFT extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new RFFT operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input A float32 tensor.
+   * @param fftLength An int32 tensor of shape [1]. The FFT length.
+   * @return a new instance of RFFT
+   */
+  public static RFFT create(Scope scope, Operand<Float> input, Operand<Integer> fftLength) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("RFFT", scope.makeOpName("RFFT"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(fftLength.asOutput());
+    return new RFFT(opBuilder.build());
+  }
+  
+  /**
+   * A complex64 tensor of the same rank as `input`. The inner-most
+   *   dimension of `input` is replaced with the `fft_length / 2 + 1` unique
+   *   frequency components of its 1D Fourier transform.
+   * <p>
+   * @compatibility(numpy)
+   * Equivalent to np.fft.rfft
+   * @end_compatibility
+   */
+  public Output<?> output() {
+    return output;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) output;
+  }
+  
+  private Output<?> output;
+  
+  private RFFT(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/RGBToHSV.java java-ops/org/tensorflow/op/core/RGBToHSV.java
--- java/org/tensorflow/op/core/RGBToHSV.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/RGBToHSV.java	2018-10-16 20:18:38.407432258 +0900
@@ -0,0 +1,76 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Converts one or more images from RGB to HSV.
+ * <p>
+ * Outputs a tensor of the same shape as the `images` tensor, containing the HSV
+ * value of the pixels. The output is only well defined if the value in `images`
+ * are in `[0,1]`.
+ * <p>
+ * `output[..., 0]` contains hue, `output[..., 1]` contains saturation, and
+ * `output[..., 2]` contains value. All HSV values are in `[0,1]`. A hue of 0
+ * corresponds to pure red, hue 1/3 is pure green, and 2/3 is pure blue.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class RGBToHSV<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new RGBToHSV operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param images 1-D or higher rank. RGB data to convert. Last dimension must be size 3.
+   * @return a new instance of RGBToHSV
+   */
+  public static <T extends Number> RGBToHSV<T> create(Scope scope, Operand<T> images) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("RGBToHSV", scope.makeOpName("RGBToHSV"));
+    opBuilder.addInput(images.asOutput());
+    return new RGBToHSV<T>(opBuilder.build());
+  }
+  
+  /**
+   * `images` converted to HSV.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private RGBToHSV(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/RightShift.java java-ops/org/tensorflow/op/core/RightShift.java
--- java/org/tensorflow/op/core/RightShift.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/RightShift.java	2018-10-16 20:18:38.475432210 +0900
@@ -0,0 +1,75 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Elementwise computes the bitwise right-shift of `x` and `y`.
+ * <p>
+ * Performs a logical shift for unsigned integer types, and an arithmetic shift
+ * for signed integer types.
+ * <p>
+ * If `y` is negative, or greater than or equal to than the width of `x` in bits
+ * the result is implementation defined.
+ * 
+ * @param <T> data type for {@code z()} output
+ */
+@Operator
+public final class RightShift<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new RightShift operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param y 
+   * @return a new instance of RightShift
+   */
+  public static <T extends Number> RightShift<T> create(Scope scope, Operand<T> x, Operand<T> y) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("RightShift", scope.makeOpName("RightShift"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(y.asOutput());
+    return new RightShift<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return z;
+  }
+  
+  private Output<T> z;
+  
+  private RightShift(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Rint.java java-ops/org/tensorflow/op/core/Rint.java
--- java/org/tensorflow/op/core/Rint.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Rint.java	2018-10-16 20:18:38.475432210 +0900
@@ -0,0 +1,77 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns element-wise integer closest to x.
+ * <p>
+ * If the result is midway between two representable values,
+ * the even representable is chosen.
+ * For example:
+ * <pre>{@code
+ * rint(-1.5) ==> -2.0
+ * rint(0.5000001) ==> 1.0
+ * rint([-1.7, -1.5, -0.2, 0.2, 1.5, 1.7, 2.0]) ==> [-2., -2., -0., 0., 2., 2., 2.]
+ * }</pre>
+ * 
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class Rint<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Rint operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of Rint
+   */
+  public static <T extends Number> Rint<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Rint", scope.makeOpName("Rint"));
+    opBuilder.addInput(x.asOutput());
+    return new Rint<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private Rint(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Roll.java java-ops/org/tensorflow/op/core/Roll.java
--- java/org/tensorflow/op/core/Roll.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Roll.java	2018-10-16 20:18:38.476432210 +0900
@@ -0,0 +1,101 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Rolls the elements of a tensor along an axis.
+ * <p>
+ * The elements are shifted positively (towards larger indices) by the offset of
+ * `shift` along the dimension of `axis`. Negative `shift` values will shift
+ * elements in the opposite direction. Elements that roll passed the last position
+ * will wrap around to the first and vice versa. Multiple shifts along multiple
+ * axes may be specified.
+ * <p>
+ * For example:
+ * <pre>{@code
+ * # 't' is [0, 1, 2, 3, 4]
+ * roll(t, shift=2, axis=0) ==> [3, 4, 0, 1, 2]
+ * 
+ * # shifting along multiple dimensions
+ * # 't' is [[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]]
+ * roll(t, shift=[1, -2], axis=[0, 1]) ==> [[7, 8, 9, 5, 6], [2, 3, 4, 0, 1]]
+ * 
+ * # shifting along the same axis multiple times
+ * # 't' is [[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]]
+ * roll(t, shift=[2, -3], axis=[1, 1]) ==> [[1, 2, 3, 4, 0], [6, 7, 8, 9, 5]]
+ * }</pre>
+ * 
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class Roll<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Roll operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param shift Dimension must be 0-D or 1-D. `shift[i]` specifies the number of places by which
+   * elements are shifted positively (towards larger indices) along the dimension
+   * specified by `axis[i]`. Negative shifts will roll the elements in the opposite
+   * direction.
+   * @param axis Dimension must be 0-D or 1-D. `axis[i]` specifies the dimension that the shift
+   * `shift[i]` should occur. If the same axis is referenced more than once, the
+   * total shift for that axis will be the sum of all the shifts that belong to that
+   * axis.
+   * @return a new instance of Roll
+   */
+  public static <T, U extends Number, V extends Number> Roll<T> create(Scope scope, Operand<T> input, Operand<U> shift, Operand<V> axis) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Roll", scope.makeOpName("Roll"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(shift.asOutput());
+    opBuilder.addInput(axis.asOutput());
+    return new Roll<T>(opBuilder.build());
+  }
+  
+  /**
+   * Has the same shape and size as the input. The elements are shifted
+   * positively (towards larger indices) by the offsets of `shift` along the
+   * dimensions of `axis`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private Roll(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Round.java java-ops/org/tensorflow/op/core/Round.java
--- java/org/tensorflow/op/core/Round.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Round.java	2018-10-16 20:18:38.476432210 +0900
@@ -0,0 +1,70 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Rounds the values of a tensor to the nearest integer, element-wise.
+ * <p>
+ * Rounds half to even.  Also known as bankers rounding. If you want to round
+ * according to the current system rounding mode use std::cint.
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class Round<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Round operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of Round
+   */
+  public static <T> Round<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Round", scope.makeOpName("Round"));
+    opBuilder.addInput(x.asOutput());
+    return new Round<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private Round(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Rpc.java java-ops/org/tensorflow/op/core/Rpc.java
--- java/org/tensorflow/op/core/Rpc.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Rpc.java	2018-10-16 20:18:38.477432209 +0900
@@ -0,0 +1,202 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Perform batches of RPC requests.
+ * <p>
+ * This op asynchronously performs either a single RPC request, or a batch
+ * of requests.  RPC requests are defined by three main parameters:
+ * <p>
+ *   - `address` (the host+port or BNS address of the request)
+ *   - `method` (the RPC method name for the request)
+ *   - `request` (the serialized proto string, or vector of strings,
+ *      of the RPC request argument).
+ * <p>
+ * For example, if you have an RPC service running on port localhost:2345,
+ * and its interface is configured with the following proto declaration:
+ * <pre>{@code
+ * service MyService {
+ *   rpc MyMethod(MyRequestProto) returns (MyResponseProto) {
+ *   }
+ * };
+ * }</pre>
+ * then call this op with arguments:
+ * <pre>{@code
+ * address = "localhost:2345"
+ * method = "MyService/MyMethod"
+ * }</pre>
+ * The `request` tensor is a string tensor representing serialized `MyRequestProto`
+ * strings; and the output string tensor `response` will have the same shape
+ * and contain (upon successful completion) corresponding serialized
+ * `MyResponseProto` strings.
+ * <p>
+ * For example, to send a single, empty, `MyRequestProto`, call
+ * this op with `request = ""`.  To send 5 <b>parallel</b> empty requests,
+ * call this op with `request = ["", "", "", "", ""]`.
+ * <p>
+ * More generally, one can create a batch of `MyRequestProto` serialized protos
+ * from regular batched tensors using the `encode_proto` op, and convert
+ * the response `MyResponseProto` serialized protos to batched tensors
+ * using the `decode_proto` op.
+ * <p>
+ * <b>NOTE</b> Working with serialized proto strings is faster than instantiating
+ * actual proto objects in memory, so no performance degradation is expected
+ * compared to writing custom kernels for this workflow.
+ * <p>
+ * If the connection fails or the remote worker returns an error
+ * status, the op reraises this exception locally.
+ * <p>
+ * See the `TryRpc` op if you prefer to handle RPC failures manually in the graph.
+ */
+@Operator
+public final class Rpc extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Rpc}
+   */
+  public static class Options {
+    
+    /**
+     * @param protocol RPC protocol to use.  Empty string means use the default protocol.
+     * Options include 'grpc'.
+     */
+    public Options protocol(String protocol) {
+      this.protocol = protocol;
+      return this;
+    }
+    
+    /**
+     * @param failFast `boolean`. If `true` (default), then failures to connect
+     * (i.e., the server does not immediately respond) cause an RPC failure.
+     */
+    public Options failFast(Boolean failFast) {
+      this.failFast = failFast;
+      return this;
+    }
+    
+    /**
+     * @param timeoutInMs `int`. If `0` (default), then the kernel will run the RPC
+     * request and only time out if the RPC deadline passes or the session times out.
+     * If this value is greater than `0`, then the op will raise an exception if
+     * the RPC takes longer than `timeout_in_ms`.
+     */
+    public Options timeoutInMs(Long timeoutInMs) {
+      this.timeoutInMs = timeoutInMs;
+      return this;
+    }
+    
+    private String protocol;
+    private Boolean failFast;
+    private Long timeoutInMs;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Rpc operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param address `0-D` or `1-D`.  The address (i.e. host_name:port) of the RPC server.
+   * If this tensor has more than 1 element, then multiple parallel rpc requests
+   * are sent.  This argument broadcasts with `method` and `request`.
+   * @param method `0-D` or `1-D`.  The method address on the RPC server.
+   * If this tensor has more than 1 element, then multiple parallel rpc requests
+   * are sent.  This argument broadcasts with `address` and `request`.
+   * @param request `0-D` or `1-D`.  Serialized proto strings: the rpc request argument.
+   * If this tensor has more than 1 element, then multiple parallel rpc requests
+   * are sent.  This argument broadcasts with `address` and `method`.
+   * @param options carries optional attributes values
+   * @return a new instance of Rpc
+   */
+  public static Rpc create(Scope scope, Operand<String> address, Operand<String> method, Operand<String> request, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Rpc", scope.makeOpName("Rpc"));
+    opBuilder.addInput(address.asOutput());
+    opBuilder.addInput(method.asOutput());
+    opBuilder.addInput(request.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.protocol != null) {
+          opBuilder.setAttr("protocol", opts.protocol);
+        }
+        if (opts.failFast != null) {
+          opBuilder.setAttr("fail_fast", opts.failFast);
+        }
+        if (opts.timeoutInMs != null) {
+          opBuilder.setAttr("timeout_in_ms", opts.timeoutInMs);
+        }
+      }
+    }
+    return new Rpc(opBuilder.build());
+  }
+  
+  /**
+   * @param protocol RPC protocol to use.  Empty string means use the default protocol.
+   * Options include 'grpc'.
+   */
+  public static Options protocol(String protocol) {
+    return new Options().protocol(protocol);
+  }
+  
+  /**
+   * @param failFast `boolean`. If `true` (default), then failures to connect
+   * (i.e., the server does not immediately respond) cause an RPC failure.
+   */
+  public static Options failFast(Boolean failFast) {
+    return new Options().failFast(failFast);
+  }
+  
+  /**
+   * @param timeoutInMs `int`. If `0` (default), then the kernel will run the RPC
+   * request and only time out if the RPC deadline passes or the session times out.
+   * If this value is greater than `0`, then the op will raise an exception if
+   * the RPC takes longer than `timeout_in_ms`.
+   */
+  public static Options timeoutInMs(Long timeoutInMs) {
+    return new Options().timeoutInMs(timeoutInMs);
+  }
+  
+  /**
+   * Same shape as `request`. Serialized proto strings: the rpc responses.
+   */
+  public Output<String> response() {
+    return response;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return response;
+  }
+  
+  private Output<String> response;
+  
+  private Rpc(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    response = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/RsqrtGrad.java java-ops/org/tensorflow/op/core/RsqrtGrad.java
--- java/org/tensorflow/op/core/RsqrtGrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/RsqrtGrad.java	2018-10-16 20:18:38.478432208 +0900
@@ -0,0 +1,70 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Computes the gradient for the rsqrt of `x` wrt its input.
+ * <p>
+ * Specifically, `grad = dy * -0.5 * y^3`, where `y = rsqrt(x)`, and `dy`
+ * is the corresponding input gradient.
+ * 
+ * @param <T> data type for {@code z()} output
+ */
+public final class RsqrtGrad<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new RsqrtGrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param y 
+   * @param dy 
+   * @return a new instance of RsqrtGrad
+   */
+  public static <T> RsqrtGrad<T> create(Scope scope, Operand<T> y, Operand<T> dy) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("RsqrtGrad", scope.makeOpName("RsqrtGrad"));
+    opBuilder.addInput(y.asOutput());
+    opBuilder.addInput(dy.asOutput());
+    return new RsqrtGrad<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return z;
+  }
+  
+  private Output<T> z;
+  
+  private RsqrtGrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Rsqrt.java java-ops/org/tensorflow/op/core/Rsqrt.java
--- java/org/tensorflow/op/core/Rsqrt.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Rsqrt.java	2018-10-16 20:18:38.477432209 +0900
@@ -0,0 +1,69 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes reciprocal of square root of x element-wise.
+ * <p>
+ * I.e., \\(y = 1 / \sqrt{x}\\).
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class Rsqrt<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Rsqrt operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of Rsqrt
+   */
+  public static <T> Rsqrt<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Rsqrt", scope.makeOpName("Rsqrt"));
+    opBuilder.addInput(x.asOutput());
+    return new Rsqrt<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private Rsqrt(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SampleDistortedBoundingBox.java java-ops/org/tensorflow/op/core/SampleDistortedBoundingBox.java
--- java/org/tensorflow/op/core/SampleDistortedBoundingBox.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SampleDistortedBoundingBox.java	2018-10-16 20:18:38.480432207 +0900
@@ -0,0 +1,303 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Generate a single randomly distorted bounding box for an image.
+ * <p>
+ * Bounding box annotations are often supplied in addition to ground-truth labels
+ * in image recognition or object localization tasks. A common technique for
+ * training such a system is to randomly distort an image while preserving
+ * its content, i.e. <i>data augmentation</i>. This Op outputs a randomly distorted
+ * localization of an object, i.e. bounding box, given an `image_size`,
+ * `bounding_boxes` and a series of constraints.
+ * <p>
+ * The output of this Op is a single bounding box that may be used to crop the
+ * original image. The output is returned as 3 tensors: `begin`, `size` and
+ * `bboxes`. The first 2 tensors can be fed directly into `tf.slice` to crop the
+ * image. The latter may be supplied to `tf.image.draw_bounding_boxes` to visualize
+ * what the bounding box looks like.
+ * <p>
+ * Bounding boxes are supplied and returned as `[y_min, x_min, y_max, x_max]`. The
+ * bounding box coordinates are floats in `[0.0, 1.0]` relative to the width and
+ * height of the underlying image.
+ * <p>
+ * For example,
+ * <pre>{@code
+ *     # Generate a single distorted bounding box.
+ *     begin, size, bbox_for_draw = tf.image.sample_distorted_bounding_box(
+ *         tf.shape(image),
+ *         bounding_boxes=bounding_boxes)
+ * 
+ *     # Draw the bounding box in an image summary.
+ *     image_with_box = tf.image.draw_bounding_boxes(tf.expand_dims(image, 0),
+ *                                                   bbox_for_draw)
+ *     tf.summary.image('images_with_box', image_with_box)
+ * 
+ *     # Employ the bounding box to distort the image.
+ *     distorted_image = tf.slice(image, begin, size)
+ * }</pre>
+ * Note that if no bounding box information is available, setting
+ * `use_image_if_no_bounding_boxes = true` will assume there is a single implicit
+ * bounding box covering the whole image. If `use_image_if_no_bounding_boxes` is
+ * false and no bounding boxes are supplied, an error is raised.
+ * 
+ * @param <T> data type for {@code begin()} output
+ */
+@Operator
+public final class SampleDistortedBoundingBox<T extends Number> extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.SampleDistortedBoundingBox}
+   */
+  public static class Options {
+    
+    /**
+     * @param seed If either `seed` or `seed2` are set to non-zero, the random number
+     * generator is seeded by the given `seed`.  Otherwise, it is seeded by a random
+     * seed.
+     */
+    public Options seed(Long seed) {
+      this.seed = seed;
+      return this;
+    }
+    
+    /**
+     * @param seed2 A second seed to avoid seed collision.
+     */
+    public Options seed2(Long seed2) {
+      this.seed2 = seed2;
+      return this;
+    }
+    
+    /**
+     * @param minObjectCovered The cropped area of the image must contain at least this
+     * fraction of any bounding box supplied. The value of this parameter should be
+     * non-negative. In the case of 0, the cropped area does not need to overlap
+     * any of the bounding boxes supplied.
+     */
+    public Options minObjectCovered(Float minObjectCovered) {
+      this.minObjectCovered = minObjectCovered;
+      return this;
+    }
+    
+    /**
+     * @param aspectRatioRange The cropped area of the image must have an aspect ratio =
+     * width / height within this range.
+     */
+    public Options aspectRatioRange(List<Float> aspectRatioRange) {
+      this.aspectRatioRange = aspectRatioRange;
+      return this;
+    }
+    
+    /**
+     * @param areaRange The cropped area of the image must contain a fraction of the
+     * supplied image within this range.
+     */
+    public Options areaRange(List<Float> areaRange) {
+      this.areaRange = areaRange;
+      return this;
+    }
+    
+    /**
+     * @param maxAttempts Number of attempts at generating a cropped region of the image
+     * of the specified constraints. After `max_attempts` failures, return the entire
+     * image.
+     */
+    public Options maxAttempts(Long maxAttempts) {
+      this.maxAttempts = maxAttempts;
+      return this;
+    }
+    
+    /**
+     * @param useImageIfNoBoundingBoxes Controls behavior if no bounding boxes supplied.
+     * If true, assume an implicit bounding box covering the whole input. If false,
+     * raise an error.
+     */
+    public Options useImageIfNoBoundingBoxes(Boolean useImageIfNoBoundingBoxes) {
+      this.useImageIfNoBoundingBoxes = useImageIfNoBoundingBoxes;
+      return this;
+    }
+    
+    private Long seed;
+    private Long seed2;
+    private Float minObjectCovered;
+    private List<Float> aspectRatioRange;
+    private List<Float> areaRange;
+    private Long maxAttempts;
+    private Boolean useImageIfNoBoundingBoxes;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new SampleDistortedBoundingBox operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param imageSize 1-D, containing `[height, width, channels]`.
+   * @param boundingBoxes 3-D with shape `[batch, N, 4]` describing the N bounding boxes
+   * associated with the image.
+   * @param options carries optional attributes values
+   * @return a new instance of SampleDistortedBoundingBox
+   */
+  public static <T extends Number> SampleDistortedBoundingBox<T> create(Scope scope, Operand<T> imageSize, Operand<Float> boundingBoxes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SampleDistortedBoundingBox", scope.makeOpName("SampleDistortedBoundingBox"));
+    opBuilder.addInput(imageSize.asOutput());
+    opBuilder.addInput(boundingBoxes.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.seed != null) {
+          opBuilder.setAttr("seed", opts.seed);
+        }
+        if (opts.seed2 != null) {
+          opBuilder.setAttr("seed2", opts.seed2);
+        }
+        if (opts.minObjectCovered != null) {
+          opBuilder.setAttr("min_object_covered", opts.minObjectCovered);
+        }
+        if (opts.aspectRatioRange != null) {
+          float[] aspectRatioRangeArray = new float[opts.aspectRatioRange.size()];
+          for (int i = 0; i < aspectRatioRangeArray.length; ++i) {
+            aspectRatioRangeArray[i] = opts.aspectRatioRange.get(i);
+          }
+          opBuilder.setAttr("aspect_ratio_range", aspectRatioRangeArray);
+        }
+        if (opts.areaRange != null) {
+          float[] areaRangeArray = new float[opts.areaRange.size()];
+          for (int i = 0; i < areaRangeArray.length; ++i) {
+            areaRangeArray[i] = opts.areaRange.get(i);
+          }
+          opBuilder.setAttr("area_range", areaRangeArray);
+        }
+        if (opts.maxAttempts != null) {
+          opBuilder.setAttr("max_attempts", opts.maxAttempts);
+        }
+        if (opts.useImageIfNoBoundingBoxes != null) {
+          opBuilder.setAttr("use_image_if_no_bounding_boxes", opts.useImageIfNoBoundingBoxes);
+        }
+      }
+    }
+    return new SampleDistortedBoundingBox<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param seed If either `seed` or `seed2` are set to non-zero, the random number
+   * generator is seeded by the given `seed`.  Otherwise, it is seeded by a random
+   * seed.
+   */
+  public static Options seed(Long seed) {
+    return new Options().seed(seed);
+  }
+  
+  /**
+   * @param seed2 A second seed to avoid seed collision.
+   */
+  public static Options seed2(Long seed2) {
+    return new Options().seed2(seed2);
+  }
+  
+  /**
+   * @param minObjectCovered The cropped area of the image must contain at least this
+   * fraction of any bounding box supplied. The value of this parameter should be
+   * non-negative. In the case of 0, the cropped area does not need to overlap
+   * any of the bounding boxes supplied.
+   */
+  public static Options minObjectCovered(Float minObjectCovered) {
+    return new Options().minObjectCovered(minObjectCovered);
+  }
+  
+  /**
+   * @param aspectRatioRange The cropped area of the image must have an aspect ratio =
+   * width / height within this range.
+   */
+  public static Options aspectRatioRange(List<Float> aspectRatioRange) {
+    return new Options().aspectRatioRange(aspectRatioRange);
+  }
+  
+  /**
+   * @param areaRange The cropped area of the image must contain a fraction of the
+   * supplied image within this range.
+   */
+  public static Options areaRange(List<Float> areaRange) {
+    return new Options().areaRange(areaRange);
+  }
+  
+  /**
+   * @param maxAttempts Number of attempts at generating a cropped region of the image
+   * of the specified constraints. After `max_attempts` failures, return the entire
+   * image.
+   */
+  public static Options maxAttempts(Long maxAttempts) {
+    return new Options().maxAttempts(maxAttempts);
+  }
+  
+  /**
+   * @param useImageIfNoBoundingBoxes Controls behavior if no bounding boxes supplied.
+   * If true, assume an implicit bounding box covering the whole input. If false,
+   * raise an error.
+   */
+  public static Options useImageIfNoBoundingBoxes(Boolean useImageIfNoBoundingBoxes) {
+    return new Options().useImageIfNoBoundingBoxes(useImageIfNoBoundingBoxes);
+  }
+  
+  /**
+   * 1-D, containing `[offset_height, offset_width, 0]`. Provide as input to
+   * `tf.slice`.
+   */
+  public Output<T> begin() {
+    return begin;
+  }
+  
+  /**
+   * 1-D, containing `[target_height, target_width, -1]`. Provide as input to
+   * `tf.slice`.
+   */
+  public Output<T> size() {
+    return size;
+  }
+  
+  /**
+   * 3-D with shape `[1, 1, 4]` containing the distorted bounding box.
+   * Provide as input to `tf.image.draw_bounding_boxes`.
+   */
+  public Output<Float> bboxes() {
+    return bboxes;
+  }
+  
+  private Output<T> begin;
+  private Output<T> size;
+  private Output<Float> bboxes;
+  
+  private SampleDistortedBoundingBox(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    begin = operation.output(outputIdx++);
+    size = operation.output(outputIdx++);
+    bboxes = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SampleDistortedBoundingBoxV2.java java-ops/org/tensorflow/op/core/SampleDistortedBoundingBoxV2.java
--- java/org/tensorflow/op/core/SampleDistortedBoundingBoxV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SampleDistortedBoundingBoxV2.java	2018-10-16 20:18:38.482432205 +0900
@@ -0,0 +1,283 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Generate a single randomly distorted bounding box for an image.
+ * <p>
+ * Bounding box annotations are often supplied in addition to ground-truth labels
+ * in image recognition or object localization tasks. A common technique for
+ * training such a system is to randomly distort an image while preserving
+ * its content, i.e. <i>data augmentation</i>. This Op outputs a randomly distorted
+ * localization of an object, i.e. bounding box, given an `image_size`,
+ * `bounding_boxes` and a series of constraints.
+ * <p>
+ * The output of this Op is a single bounding box that may be used to crop the
+ * original image. The output is returned as 3 tensors: `begin`, `size` and
+ * `bboxes`. The first 2 tensors can be fed directly into `tf.slice` to crop the
+ * image. The latter may be supplied to `tf.image.draw_bounding_boxes` to visualize
+ * what the bounding box looks like.
+ * <p>
+ * Bounding boxes are supplied and returned as `[y_min, x_min, y_max, x_max]`. The
+ * bounding box coordinates are floats in `[0.0, 1.0]` relative to the width and
+ * height of the underlying image.
+ * <p>
+ * For example,
+ * <pre>{@code
+ *     # Generate a single distorted bounding box.
+ *     begin, size, bbox_for_draw = tf.image.sample_distorted_bounding_box(
+ *         tf.shape(image),
+ *         bounding_boxes=bounding_boxes)
+ * 
+ *     # Draw the bounding box in an image summary.
+ *     image_with_box = tf.image.draw_bounding_boxes(tf.expand_dims(image, 0),
+ *                                                   bbox_for_draw)
+ *     tf.summary.image('images_with_box', image_with_box)
+ * 
+ *     # Employ the bounding box to distort the image.
+ *     distorted_image = tf.slice(image, begin, size)
+ * }</pre>
+ * Note that if no bounding box information is available, setting
+ * `use_image_if_no_bounding_boxes = true` will assume there is a single implicit
+ * bounding box covering the whole image. If `use_image_if_no_bounding_boxes` is
+ * false and no bounding boxes are supplied, an error is raised.
+ * 
+ * @param <T> data type for {@code begin()} output
+ */
+@Operator
+public final class SampleDistortedBoundingBoxV2<T extends Number> extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.SampleDistortedBoundingBoxV2}
+   */
+  public static class Options {
+    
+    /**
+     * @param seed If either `seed` or `seed2` are set to non-zero, the random number
+     * generator is seeded by the given `seed`.  Otherwise, it is seeded by a random
+     * seed.
+     */
+    public Options seed(Long seed) {
+      this.seed = seed;
+      return this;
+    }
+    
+    /**
+     * @param seed2 A second seed to avoid seed collision.
+     */
+    public Options seed2(Long seed2) {
+      this.seed2 = seed2;
+      return this;
+    }
+    
+    /**
+     * @param aspectRatioRange The cropped area of the image must have an aspect ratio =
+     * width / height within this range.
+     */
+    public Options aspectRatioRange(List<Float> aspectRatioRange) {
+      this.aspectRatioRange = aspectRatioRange;
+      return this;
+    }
+    
+    /**
+     * @param areaRange The cropped area of the image must contain a fraction of the
+     * supplied image within this range.
+     */
+    public Options areaRange(List<Float> areaRange) {
+      this.areaRange = areaRange;
+      return this;
+    }
+    
+    /**
+     * @param maxAttempts Number of attempts at generating a cropped region of the image
+     * of the specified constraints. After `max_attempts` failures, return the entire
+     * image.
+     */
+    public Options maxAttempts(Long maxAttempts) {
+      this.maxAttempts = maxAttempts;
+      return this;
+    }
+    
+    /**
+     * @param useImageIfNoBoundingBoxes Controls behavior if no bounding boxes supplied.
+     * If true, assume an implicit bounding box covering the whole input. If false,
+     * raise an error.
+     */
+    public Options useImageIfNoBoundingBoxes(Boolean useImageIfNoBoundingBoxes) {
+      this.useImageIfNoBoundingBoxes = useImageIfNoBoundingBoxes;
+      return this;
+    }
+    
+    private Long seed;
+    private Long seed2;
+    private List<Float> aspectRatioRange;
+    private List<Float> areaRange;
+    private Long maxAttempts;
+    private Boolean useImageIfNoBoundingBoxes;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new SampleDistortedBoundingBoxV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param imageSize 1-D, containing `[height, width, channels]`.
+   * @param boundingBoxes 3-D with shape `[batch, N, 4]` describing the N bounding boxes
+   * associated with the image.
+   * @param minObjectCovered The cropped area of the image must contain at least this
+   * fraction of any bounding box supplied. The value of this parameter should be
+   * non-negative. In the case of 0, the cropped area does not need to overlap
+   * any of the bounding boxes supplied.
+   * @param options carries optional attributes values
+   * @return a new instance of SampleDistortedBoundingBoxV2
+   */
+  public static <T extends Number> SampleDistortedBoundingBoxV2<T> create(Scope scope, Operand<T> imageSize, Operand<Float> boundingBoxes, Operand<Float> minObjectCovered, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SampleDistortedBoundingBoxV2", scope.makeOpName("SampleDistortedBoundingBoxV2"));
+    opBuilder.addInput(imageSize.asOutput());
+    opBuilder.addInput(boundingBoxes.asOutput());
+    opBuilder.addInput(minObjectCovered.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.seed != null) {
+          opBuilder.setAttr("seed", opts.seed);
+        }
+        if (opts.seed2 != null) {
+          opBuilder.setAttr("seed2", opts.seed2);
+        }
+        if (opts.aspectRatioRange != null) {
+          float[] aspectRatioRangeArray = new float[opts.aspectRatioRange.size()];
+          for (int i = 0; i < aspectRatioRangeArray.length; ++i) {
+            aspectRatioRangeArray[i] = opts.aspectRatioRange.get(i);
+          }
+          opBuilder.setAttr("aspect_ratio_range", aspectRatioRangeArray);
+        }
+        if (opts.areaRange != null) {
+          float[] areaRangeArray = new float[opts.areaRange.size()];
+          for (int i = 0; i < areaRangeArray.length; ++i) {
+            areaRangeArray[i] = opts.areaRange.get(i);
+          }
+          opBuilder.setAttr("area_range", areaRangeArray);
+        }
+        if (opts.maxAttempts != null) {
+          opBuilder.setAttr("max_attempts", opts.maxAttempts);
+        }
+        if (opts.useImageIfNoBoundingBoxes != null) {
+          opBuilder.setAttr("use_image_if_no_bounding_boxes", opts.useImageIfNoBoundingBoxes);
+        }
+      }
+    }
+    return new SampleDistortedBoundingBoxV2<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param seed If either `seed` or `seed2` are set to non-zero, the random number
+   * generator is seeded by the given `seed`.  Otherwise, it is seeded by a random
+   * seed.
+   */
+  public static Options seed(Long seed) {
+    return new Options().seed(seed);
+  }
+  
+  /**
+   * @param seed2 A second seed to avoid seed collision.
+   */
+  public static Options seed2(Long seed2) {
+    return new Options().seed2(seed2);
+  }
+  
+  /**
+   * @param aspectRatioRange The cropped area of the image must have an aspect ratio =
+   * width / height within this range.
+   */
+  public static Options aspectRatioRange(List<Float> aspectRatioRange) {
+    return new Options().aspectRatioRange(aspectRatioRange);
+  }
+  
+  /**
+   * @param areaRange The cropped area of the image must contain a fraction of the
+   * supplied image within this range.
+   */
+  public static Options areaRange(List<Float> areaRange) {
+    return new Options().areaRange(areaRange);
+  }
+  
+  /**
+   * @param maxAttempts Number of attempts at generating a cropped region of the image
+   * of the specified constraints. After `max_attempts` failures, return the entire
+   * image.
+   */
+  public static Options maxAttempts(Long maxAttempts) {
+    return new Options().maxAttempts(maxAttempts);
+  }
+  
+  /**
+   * @param useImageIfNoBoundingBoxes Controls behavior if no bounding boxes supplied.
+   * If true, assume an implicit bounding box covering the whole input. If false,
+   * raise an error.
+   */
+  public static Options useImageIfNoBoundingBoxes(Boolean useImageIfNoBoundingBoxes) {
+    return new Options().useImageIfNoBoundingBoxes(useImageIfNoBoundingBoxes);
+  }
+  
+  /**
+   * 1-D, containing `[offset_height, offset_width, 0]`. Provide as input to
+   * `tf.slice`.
+   */
+  public Output<T> begin() {
+    return begin;
+  }
+  
+  /**
+   * 1-D, containing `[target_height, target_width, -1]`. Provide as input to
+   * `tf.slice`.
+   */
+  public Output<T> size() {
+    return size;
+  }
+  
+  /**
+   * 3-D with shape `[1, 1, 4]` containing the distorted bounding box.
+   * Provide as input to `tf.image.draw_bounding_boxes`.
+   */
+  public Output<Float> bboxes() {
+    return bboxes;
+  }
+  
+  private Output<T> begin;
+  private Output<T> size;
+  private Output<Float> bboxes;
+  
+  private SampleDistortedBoundingBoxV2(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    begin = operation.output(outputIdx++);
+    size = operation.output(outputIdx++);
+    bboxes = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Save.java java-ops/org/tensorflow/op/core/Save.java
--- java/org/tensorflow/op/core/Save.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Save.java	2018-10-16 20:18:38.484432204 +0900
@@ -0,0 +1,61 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Saves the input tensors to disk.
+ * <p>
+ * The size of `tensor_names` must match the number of tensors in `data`. `data[i]`
+ * is written to `filename` with name `tensor_names[i]`.
+ * <p>
+ * See also `SaveSlices`.
+ */
+@Operator
+public final class Save extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new Save operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param filename Must have a single element. The name of the file to which we write
+   * the tensor.
+   * @param tensorNames Shape `[N]`. The names of the tensors to be saved.
+   * @param data `N` tensors to save.
+   * @return a new instance of Save
+   */
+  public static Save create(Scope scope, Operand<String> filename, Operand<String> tensorNames, Iterable<Operand<?>> data) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Save", scope.makeOpName("Save"));
+    opBuilder.addInput(filename.asOutput());
+    opBuilder.addInput(tensorNames.asOutput());
+    opBuilder.addInputList(Operands.asOutputs(data));
+    return new Save(opBuilder.build());
+  }
+  
+  
+  private Save(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SaveSlices.java java-ops/org/tensorflow/op/core/SaveSlices.java
--- java/org/tensorflow/op/core/SaveSlices.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SaveSlices.java	2018-10-16 20:18:38.485432203 +0900
@@ -0,0 +1,89 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Saves input tensors slices to disk.
+ * <p>
+ * This is like `Save` except that tensors can be listed in the saved file as being
+ * a slice of a larger tensor.  `shapes_and_slices` specifies the shape of the
+ * larger tensor and the slice that this tensor covers. `shapes_and_slices` must
+ * have as many elements as `tensor_names`.
+ * <p>
+ * Elements of the `shapes_and_slices` input must either be:
+ * <ul>
+ * <li>
+ * The empty string, in which case the corresponding tensor is
+ *    saved normally.
+ * </li>
+ * <li>
+ * A string of the form `dim0 dim1 ... dimN-1 slice-spec` where the
+ *    `dimI` are the dimensions of the larger tensor and `slice-spec`
+ *    specifies what part is covered by the tensor to save.
+ * </li>
+ * </ul>
+ * `slice-spec` itself is a `:`-separated list: `slice0:slice1:...:sliceN-1`
+ * where each `sliceI` is either:
+ * <ul>
+ * <li>
+ * The string `-` meaning that the slice covers all indices of this dimension
+ * </li>
+ * <li>
+ * `start,length` where `start` and `length` are integers.  In that
+ *    case the slice covers `length` indices starting at `start`.
+ * </li>
+ * </ul>
+ * See also `Save`.
+ */
+@Operator
+public final class SaveSlices extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new SaveSlices operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param filename Must have a single element. The name of the file to which we write the
+   * tensor.
+   * @param tensorNames Shape `[N]`. The names of the tensors to be saved.
+   * @param shapesAndSlices Shape `[N]`.  The shapes and slice specifications to use when
+   * saving the tensors.
+   * @param data `N` tensors to save.
+   * @return a new instance of SaveSlices
+   */
+  public static SaveSlices create(Scope scope, Operand<String> filename, Operand<String> tensorNames, Operand<String> shapesAndSlices, Iterable<Operand<?>> data) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SaveSlices", scope.makeOpName("SaveSlices"));
+    opBuilder.addInput(filename.asOutput());
+    opBuilder.addInput(tensorNames.asOutput());
+    opBuilder.addInput(shapesAndSlices.asOutput());
+    opBuilder.addInputList(Operands.asOutputs(data));
+    return new SaveSlices(opBuilder.build());
+  }
+  
+  
+  private SaveSlices(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SaveV2.java java-ops/org/tensorflow/op/core/SaveV2.java
--- java/org/tensorflow/op/core/SaveV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SaveV2.java	2018-10-16 20:18:38.486432203 +0900
@@ -0,0 +1,63 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Saves tensors in V2 checkpoint format.
+ * <p>
+ * By default, saves the named tensors in full.  If the caller wishes to save
+ * specific slices of full tensors, "shape_and_slices" should be non-empty strings
+ * and correspondingly well-formed.
+ */
+@Operator
+public final class SaveV2 extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new SaveV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param prefix Must have a single element. The prefix of the V2 checkpoint to which we
+   * write the tensors.
+   * @param tensorNames shape {N}. The names of the tensors to be saved.
+   * @param shapeAndSlices shape {N}.  The slice specs of the tensors to be saved.
+   * Empty strings indicate that they are non-partitioned tensors.
+   * @param tensors `N` tensors to save.
+   * @return a new instance of SaveV2
+   */
+  public static SaveV2 create(Scope scope, Operand<String> prefix, Operand<String> tensorNames, Operand<String> shapeAndSlices, Iterable<Operand<?>> tensors) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SaveV2", scope.makeOpName("SaveV2"));
+    opBuilder.addInput(prefix.asOutput());
+    opBuilder.addInput(tensorNames.asOutput());
+    opBuilder.addInput(shapeAndSlices.asOutput());
+    opBuilder.addInputList(Operands.asOutputs(tensors));
+    return new SaveV2(opBuilder.build());
+  }
+  
+  
+  private SaveV2(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ScalarSummary.java java-ops/org/tensorflow/op/core/ScalarSummary.java
--- java/org/tensorflow/op/core/ScalarSummary.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ScalarSummary.java	2018-10-16 20:18:38.486432203 +0900
@@ -0,0 +1,71 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Outputs a `Summary` protocol buffer with scalar values.
+ * <p>
+ * The input `tags` and `values` must have the same shape.  The generated summary
+ * has a summary value for each tag-value pair in `tags` and `values`.
+ */
+@Operator
+public final class ScalarSummary extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Factory method to create a class to wrap a new ScalarSummary operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param tags Tags for the summary.
+   * @param values Same shape as `tags.  Values for the summary.
+   * @return a new instance of ScalarSummary
+   */
+  public static <T extends Number> ScalarSummary create(Scope scope, Operand<String> tags, Operand<T> values) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ScalarSummary", scope.makeOpName("ScalarSummary"));
+    opBuilder.addInput(tags.asOutput());
+    opBuilder.addInput(values.asOutput());
+    return new ScalarSummary(opBuilder.build());
+  }
+  
+  /**
+   * Scalar.  Serialized `Summary` protocol buffer.
+   */
+  public Output<String> summary() {
+    return summary;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return summary;
+  }
+  
+  private Output<String> summary;
+  
+  private ScalarSummary(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    summary = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ScatterAdd.java java-ops/org/tensorflow/op/core/ScatterAdd.java
--- java/org/tensorflow/op/core/ScatterAdd.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ScatterAdd.java	2018-10-16 20:18:38.487432202 +0900
@@ -0,0 +1,132 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Adds sparse updates to a variable reference.
+ * <p>
+ * This operation computes
+ * <p>
+ *     # Scalar indices
+ *     ref[indices, ...] += updates[...]
+ * <p>
+ *     # Vector indices (for each i)
+ *     ref[indices[i], ...] += updates[i, ...]
+ * <p>
+ *     # High rank indices (for each i, ..., j)
+ *     ref[indices[i, ..., j], ...] += updates[i, ..., j, ...]
+ * <p>
+ * This operation outputs `ref` after the update is done.
+ * This makes it easier to chain operations that need to use the reset value.
+ * <p>
+ * Duplicate entries are handled correctly: if multiple `indices` reference
+ * the same location, their contributions add.
+ * <p>
+ * Requires `updates.shape = indices.shape + ref.shape[1:]` or `updates.shape = []`.
+ * <p>
+ * <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
+ * <img style="width:100%" src="https://www.tensorflow.org/images/ScatterAdd.png" alt>
+ * </div>
+ * 
+ * @param <T> data type for {@code outputRef()} output
+ */
+@Operator
+public final class ScatterAdd<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ScatterAdd}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If True, the addition will be protected by a lock;
+     * otherwise the behavior is undefined, but may exhibit less contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ScatterAdd operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param ref Should be from a `Variable` node.
+   * @param indices A tensor of indices into the first dimension of `ref`.
+   * @param updates A tensor of updated values to add to `ref`.
+   * @param options carries optional attributes values
+   * @return a new instance of ScatterAdd
+   */
+  public static <T, U extends Number> ScatterAdd<T> create(Scope scope, Operand<T> ref, Operand<U> indices, Operand<T> updates, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ScatterAdd", scope.makeOpName("ScatterAdd"));
+    opBuilder.addInput(ref.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(updates.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ScatterAdd<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If True, the addition will be protected by a lock;
+   * otherwise the behavior is undefined, but may exhibit less contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * = Same as `ref`.  Returned as a convenience for operations that want
+   * to use the updated values after the update is done.
+   */
+  public Output<T> outputRef() {
+    return outputRef;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return outputRef;
+  }
+  
+  private Output<T> outputRef;
+  
+  private ScatterAdd(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    outputRef = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ScatterDiv.java java-ops/org/tensorflow/op/core/ScatterDiv.java
--- java/org/tensorflow/op/core/ScatterDiv.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ScatterDiv.java	2018-10-16 20:18:38.488432201 +0900
@@ -0,0 +1,128 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Divides a variable reference by sparse updates.
+ * <p>
+ * This operation computes
+ * <pre>{@code
+ *     # Scalar indices
+ *     ref[indices, ...] /= updates[...]
+ * 
+ *     # Vector indices (for each i)
+ *     ref[indices[i], ...] /= updates[i, ...]
+ * 
+ *     # High rank indices (for each i, ..., j)
+ *     ref[indices[i, ..., j], ...] /= updates[i, ..., j, ...]
+ * }</pre>
+ * This operation outputs `ref` after the update is done.
+ * This makes it easier to chain operations that need to use the reset value.
+ * <p>
+ * Duplicate entries are handled correctly: if multiple `indices` reference
+ * the same location, their contributions divide.
+ * <p>
+ * Requires `updates.shape = indices.shape + ref.shape[1:]` or `updates.shape = []`.
+ * 
+ * @param <T> data type for {@code outputRef()} output
+ */
+@Operator
+public final class ScatterDiv<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ScatterDiv}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If True, the operation will be protected by a lock;
+     * otherwise the behavior is undefined, but may exhibit less contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ScatterDiv operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param ref Should be from a `Variable` node.
+   * @param indices A tensor of indices into the first dimension of `ref`.
+   * @param updates A tensor of values that `ref` is divided by.
+   * @param options carries optional attributes values
+   * @return a new instance of ScatterDiv
+   */
+  public static <T, U extends Number> ScatterDiv<T> create(Scope scope, Operand<T> ref, Operand<U> indices, Operand<T> updates, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ScatterDiv", scope.makeOpName("ScatterDiv"));
+    opBuilder.addInput(ref.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(updates.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ScatterDiv<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If True, the operation will be protected by a lock;
+   * otherwise the behavior is undefined, but may exhibit less contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * = Same as `ref`.  Returned as a convenience for operations that want
+   * to use the updated values after the update is done.
+   */
+  public Output<T> outputRef() {
+    return outputRef;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return outputRef;
+  }
+  
+  private Output<T> outputRef;
+  
+  private ScatterDiv(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    outputRef = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ScatterMax.java java-ops/org/tensorflow/op/core/ScatterMax.java
--- java/org/tensorflow/op/core/ScatterMax.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ScatterMax.java	2018-10-16 20:18:38.489432200 +0900
@@ -0,0 +1,132 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Reduces sparse updates into a variable reference using the `max` operation.
+ * <p>
+ * This operation computes
+ * <p>
+ *     # Scalar indices
+ *     ref[indices, ...] = max(ref[indices, ...], updates[...])
+ * <p>
+ *     # Vector indices (for each i)
+ *     ref[indices[i], ...] = max(ref[indices[i], ...], updates[i, ...])
+ * <p>
+ *     # High rank indices (for each i, ..., j)
+ *     ref[indices[i, ..., j], ...] = max(ref[indices[i, ..., j], ...], updates[i, ..., j, ...])
+ * <p>
+ * This operation outputs `ref` after the update is done.
+ * This makes it easier to chain operations that need to use the reset value.
+ * <p>
+ * Duplicate entries are handled correctly: if multiple `indices` reference
+ * the same location, their contributions combine.
+ * <p>
+ * Requires `updates.shape = indices.shape + ref.shape[1:]` or `updates.shape = []`.
+ * <p>
+ * <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
+ * <img style="width:100%" src="https://www.tensorflow.org/images/ScatterAdd.png" alt>
+ * </div>
+ * 
+ * @param <T> data type for {@code outputRef()} output
+ */
+@Operator
+public final class ScatterMax<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ScatterMax}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If True, the update will be protected by a lock;
+     * otherwise the behavior is undefined, but may exhibit less contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ScatterMax operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param ref Should be from a `Variable` node.
+   * @param indices A tensor of indices into the first dimension of `ref`.
+   * @param updates A tensor of updated values to reduce into `ref`.
+   * @param options carries optional attributes values
+   * @return a new instance of ScatterMax
+   */
+  public static <T extends Number, U extends Number> ScatterMax<T> create(Scope scope, Operand<T> ref, Operand<U> indices, Operand<T> updates, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ScatterMax", scope.makeOpName("ScatterMax"));
+    opBuilder.addInput(ref.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(updates.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ScatterMax<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If True, the update will be protected by a lock;
+   * otherwise the behavior is undefined, but may exhibit less contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * = Same as `ref`.  Returned as a convenience for operations that want
+   * to use the updated values after the update is done.
+   */
+  public Output<T> outputRef() {
+    return outputRef;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return outputRef;
+  }
+  
+  private Output<T> outputRef;
+  
+  private ScatterMax(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    outputRef = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ScatterMin.java java-ops/org/tensorflow/op/core/ScatterMin.java
--- java/org/tensorflow/op/core/ScatterMin.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ScatterMin.java	2018-10-16 20:18:38.490432200 +0900
@@ -0,0 +1,132 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Reduces sparse updates into a variable reference using the `min` operation.
+ * <p>
+ * This operation computes
+ * <p>
+ *     # Scalar indices
+ *     ref[indices, ...] = min(ref[indices, ...], updates[...])
+ * <p>
+ *     # Vector indices (for each i)
+ *     ref[indices[i], ...] = min(ref[indices[i], ...], updates[i, ...])
+ * <p>
+ *     # High rank indices (for each i, ..., j)
+ *     ref[indices[i, ..., j], ...] = min(ref[indices[i, ..., j], ...], updates[i, ..., j, ...])
+ * <p>
+ * This operation outputs `ref` after the update is done.
+ * This makes it easier to chain operations that need to use the reset value.
+ * <p>
+ * Duplicate entries are handled correctly: if multiple `indices` reference
+ * the same location, their contributions combine.
+ * <p>
+ * Requires `updates.shape = indices.shape + ref.shape[1:]` or `updates.shape = []`.
+ * <p>
+ * <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
+ * <img style="width:100%" src="https://www.tensorflow.org/images/ScatterAdd.png" alt>
+ * </div>
+ * 
+ * @param <T> data type for {@code outputRef()} output
+ */
+@Operator
+public final class ScatterMin<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ScatterMin}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If True, the update will be protected by a lock;
+     * otherwise the behavior is undefined, but may exhibit less contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ScatterMin operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param ref Should be from a `Variable` node.
+   * @param indices A tensor of indices into the first dimension of `ref`.
+   * @param updates A tensor of updated values to reduce into `ref`.
+   * @param options carries optional attributes values
+   * @return a new instance of ScatterMin
+   */
+  public static <T extends Number, U extends Number> ScatterMin<T> create(Scope scope, Operand<T> ref, Operand<U> indices, Operand<T> updates, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ScatterMin", scope.makeOpName("ScatterMin"));
+    opBuilder.addInput(ref.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(updates.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ScatterMin<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If True, the update will be protected by a lock;
+   * otherwise the behavior is undefined, but may exhibit less contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * = Same as `ref`.  Returned as a convenience for operations that want
+   * to use the updated values after the update is done.
+   */
+  public Output<T> outputRef() {
+    return outputRef;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return outputRef;
+  }
+  
+  private Output<T> outputRef;
+  
+  private ScatterMin(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    outputRef = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ScatterMul.java java-ops/org/tensorflow/op/core/ScatterMul.java
--- java/org/tensorflow/op/core/ScatterMul.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ScatterMul.java	2018-10-16 20:18:38.490432200 +0900
@@ -0,0 +1,128 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Multiplies sparse updates into a variable reference.
+ * <p>
+ * This operation computes
+ * <pre>{@code
+ *     # Scalar indices
+ *     ref[indices, ...] *= updates[...]
+ * 
+ *     # Vector indices (for each i)
+ *     ref[indices[i], ...] *= updates[i, ...]
+ * 
+ *     # High rank indices (for each i, ..., j)
+ *     ref[indices[i, ..., j], ...] *= updates[i, ..., j, ...]
+ * }</pre>
+ * This operation outputs `ref` after the update is done.
+ * This makes it easier to chain operations that need to use the reset value.
+ * <p>
+ * Duplicate entries are handled correctly: if multiple `indices` reference
+ * the same location, their contributions multiply.
+ * <p>
+ * Requires `updates.shape = indices.shape + ref.shape[1:]` or `updates.shape = []`.
+ * 
+ * @param <T> data type for {@code outputRef()} output
+ */
+@Operator
+public final class ScatterMul<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ScatterMul}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If True, the operation will be protected by a lock;
+     * otherwise the behavior is undefined, but may exhibit less contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ScatterMul operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param ref Should be from a `Variable` node.
+   * @param indices A tensor of indices into the first dimension of `ref`.
+   * @param updates A tensor of updated values to multiply to `ref`.
+   * @param options carries optional attributes values
+   * @return a new instance of ScatterMul
+   */
+  public static <T, U extends Number> ScatterMul<T> create(Scope scope, Operand<T> ref, Operand<U> indices, Operand<T> updates, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ScatterMul", scope.makeOpName("ScatterMul"));
+    opBuilder.addInput(ref.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(updates.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ScatterMul<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If True, the operation will be protected by a lock;
+   * otherwise the behavior is undefined, but may exhibit less contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * = Same as `ref`.  Returned as a convenience for operations that want
+   * to use the updated values after the update is done.
+   */
+  public Output<T> outputRef() {
+    return outputRef;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return outputRef;
+  }
+  
+  private Output<T> outputRef;
+  
+  private ScatterMul(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    outputRef = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ScatterNdAdd.java java-ops/org/tensorflow/op/core/ScatterNdAdd.java
--- java/org/tensorflow/op/core/ScatterNdAdd.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ScatterNdAdd.java	2018-10-16 20:18:38.492432198 +0900
@@ -0,0 +1,145 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Applies sparse addition between `updates` and individual values or slices
+ * <p>
+ * within a given variable according to `indices`.
+ * <p>
+ * `ref` is a `Tensor` with rank `P` and `indices` is a `Tensor` of rank `Q`.
+ * <p>
+ * `indices` must be integer tensor, containing indices into `ref`.
+ * It must be shape `\\([d_0, ..., d_{Q-2}, K]\\)` where `0 < K <= P`.
+ * <p>
+ * The innermost dimension of `indices` (with length `K`) corresponds to
+ * indices into elements (if `K = P`) or slices (if `K < P`) along the `K`th
+ * dimension of `ref`.
+ * <p>
+ * `updates` is `Tensor` of rank `Q-1+P-K` with shape:
+ * <p>
+ * $$[d_0, ..., d_{Q-2}, ref.shape[K], ..., ref.shape[P-1]].$$
+ * <p>
+ * For example, say we want to add 4 scattered elements to a rank-1 tensor to 8
+ * elements. In Python, that addition would look like this:
+ * <p>
+ *     ref = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])
+ *     indices = tf.constant([[4], [3], [1], [7]])
+ *     updates = tf.constant([9, 10, 11, 12])
+ *     add = tf.scatter_nd_add(ref, indices, updates)
+ *     with tf.Session() as sess:
+ *       print sess.run(add)
+ * <p>
+ * The resulting update to ref would look like this:
+ * <p>
+ *     [1, 13, 3, 14, 14, 6, 7, 20]
+ * <p>
+ * See `tf.scatter_nd` for more details about how to make updates to
+ * slices.
+ * 
+ * @param <T> data type for {@code outputRef()} output
+ */
+@Operator
+public final class ScatterNdAdd<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ScatterNdAdd}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking An optional bool. Defaults to True. If True, the assignment will
+     * be protected by a lock; otherwise the behavior is undefined,
+     * but may exhibit less contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ScatterNdAdd operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param ref A mutable Tensor. Should be from a Variable node.
+   * @param indices A Tensor. Must be one of the following types: int32, int64.
+   * A tensor of indices into ref.
+   * @param updates A Tensor. Must have the same type as ref. A tensor of updated values
+   * to add to ref.
+   * @param options carries optional attributes values
+   * @return a new instance of ScatterNdAdd
+   */
+  public static <T, U extends Number> ScatterNdAdd<T> create(Scope scope, Operand<T> ref, Operand<U> indices, Operand<T> updates, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ScatterNdAdd", scope.makeOpName("ScatterNdAdd"));
+    opBuilder.addInput(ref.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(updates.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ScatterNdAdd<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking An optional bool. Defaults to True. If True, the assignment will
+   * be protected by a lock; otherwise the behavior is undefined,
+   * but may exhibit less contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * Same as ref. Returned as a convenience for operations that want
+   * to use the updated values after the update is done.
+   */
+  public Output<T> outputRef() {
+    return outputRef;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return outputRef;
+  }
+  
+  private Output<T> outputRef;
+  
+  private ScatterNdAdd(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    outputRef = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ScatterNd.java java-ops/org/tensorflow/op/core/ScatterNd.java
--- java/org/tensorflow/op/core/ScatterNd.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ScatterNd.java	2018-10-16 20:18:38.492432198 +0900
@@ -0,0 +1,148 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Scatter `updates` into a new tensor according to `indices`.
+ * <p>
+ * Creates a new tensor by applying sparse `updates` to individual values or
+ * slices within a tensor (initially zero for numeric, empty for string) of
+ * the given `shape` according to indices.  This operator is the inverse of the
+ * `tf.gather_nd` operator which extracts values or slices from a given tensor.
+ * <p>
+ * If `indices` contains duplicates, then their updates are accumulated (summed).
+ * <p>
+ * <b>WARNING</b>: The order in which updates are applied is nondeterministic, so the
+ * output will be nondeterministic if `indices` contains duplicates -- because
+ * of some numerical approximation issues, numbers summed in different order
+ * may yield different results.
+ * <p>
+ * `indices` is an integer tensor containing indices into a new tensor of shape
+ * `shape`.  The last dimension of `indices` can be at most the rank of `shape`:
+ * <p>
+ *     indices.shape[-1] <= shape.rank
+ * <p>
+ * The last dimension of `indices` corresponds to indices into elements
+ * (if `indices.shape[-1] = shape.rank`) or slices
+ * (if `indices.shape[-1] < shape.rank`) along dimension `indices.shape[-1]` of
+ * `shape`.  `updates` is a tensor with shape
+ * <p>
+ *     indices.shape[:-1] + shape[indices.shape[-1]:]
+ * <p>
+ * The simplest form of scatter is to insert individual elements in a tensor by
+ * index. For example, say we want to insert 4 scattered elements in a rank-1
+ * tensor with 8 elements.
+ * <p>
+ * <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
+ * <img style="width:100%" src="https://www.tensorflow.org/images/ScatterNd1.png" alt>
+ * </div>
+ * <p>
+ * In Python, this scatter operation would look like this:
+ * <pre>{@code
+ *     indices = tf.constant([[4], [3], [1], [7]])
+ *     updates = tf.constant([9, 10, 11, 12])
+ *     shape = tf.constant([8])
+ *     scatter = tf.scatter_nd(indices, updates, shape)
+ *     with tf.Session() as sess:
+ *       print(sess.run(scatter))
+ * }</pre>
+ * The resulting tensor would look like this:
+ * <p>
+ *     [0, 11, 0, 10, 9, 0, 0, 12]
+ * <p>
+ * We can also, insert entire slices of a higher rank tensor all at once. For
+ * example, if we wanted to insert two slices in the first dimension of a
+ * rank-3 tensor with two matrices of new values.
+ * <p>
+ * <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
+ * <img style="width:100%" src="https://www.tensorflow.org/images/ScatterNd2.png" alt>
+ * </div>
+ * <p>
+ * In Python, this scatter operation would look like this:
+ * <pre>{@code
+ *     indices = tf.constant([[0], [2]])
+ *     updates = tf.constant([[[5, 5, 5, 5], [6, 6, 6, 6],
+ *                             [7, 7, 7, 7], [8, 8, 8, 8]],
+ *                            [[5, 5, 5, 5], [6, 6, 6, 6],
+ *                             [7, 7, 7, 7], [8, 8, 8, 8]]])
+ *     shape = tf.constant([4, 4, 4])
+ *     scatter = tf.scatter_nd(indices, updates, shape)
+ *     with tf.Session() as sess:
+ *       print(sess.run(scatter))
+ * }</pre>
+ * The resulting tensor would look like this:
+ * <p>
+ *     [[[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],
+ *      [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]],
+ *      [[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],
+ *      [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]]]
+ * <p>
+ * Note that on CPU, if an out of bound index is found, an error is returned.
+ * On GPU, if an out of bound index is found, the index is ignored.
+ * 
+ * @param <U> data type for {@code output()} output
+ */
+@Operator
+public final class ScatterNd<U> extends PrimitiveOp implements Operand<U> {
+  
+  /**
+   * Factory method to create a class to wrap a new ScatterNd operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param indices Index tensor.
+   * @param updates Updates to scatter into output.
+   * @param shape 1-D. The shape of the resulting tensor.
+   * @return a new instance of ScatterNd
+   */
+  public static <U, T extends Number> ScatterNd<U> create(Scope scope, Operand<T> indices, Operand<U> updates, Operand<T> shape) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ScatterNd", scope.makeOpName("ScatterNd"));
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(updates.asOutput());
+    opBuilder.addInput(shape.asOutput());
+    return new ScatterNd<U>(opBuilder.build());
+  }
+  
+  /**
+   * A new tensor with the given shape and updates applied according
+   * to the indices.
+   */
+  public Output<U> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<U> asOutput() {
+    return output;
+  }
+  
+  private Output<U> output;
+  
+  private ScatterNd(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ScatterNdNonAliasingAdd.java java-ops/org/tensorflow/op/core/ScatterNdNonAliasingAdd.java
--- java/org/tensorflow/op/core/ScatterNdNonAliasingAdd.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ScatterNdNonAliasingAdd.java	2018-10-16 20:18:38.493432198 +0900
@@ -0,0 +1,109 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Applies sparse addition to `input` using individual values or slices
+ * <p>
+ * from `updates` according to indices `indices`.  The updates are non-aliasing:
+ * `input` is only modified in-place if no other operations will use it.
+ * Otherwise, a copy of `input` is made.  This operation has a gradient with
+ * respect to both `input` and `updates`.
+ * <p>
+ * `input` is a `Tensor` with rank `P` and `indices` is a `Tensor` of rank `Q`.
+ * <p>
+ * `indices` must be integer tensor, containing indices into `input`.
+ * It must be shape \\([d_0, ..., d_{Q-2}, K]\\) where `0 < K <= P`.
+ * <p>
+ * The innermost dimension of `indices` (with length `K`) corresponds to
+ * indices into elements (if `K = P`) or `(P-K)`-dimensional slices
+ * (if `K < P`) along the `K`th dimension of `input`.
+ * <p>
+ * `updates` is `Tensor` of rank `Q-1+P-K` with shape:
+ * <p>
+ * $$[d_0, ..., d_{Q-2}, input.shape[K], ..., input.shape[P-1]].$$
+ * <p>
+ * For example, say we want to add 4 scattered elements to a rank-1 tensor to 8
+ * elements. In Python, that addition would look like this:
+ * <p>
+ *     input = tf.constant([1, 2, 3, 4, 5, 6, 7, 8])
+ *     indices = tf.constant([[4], [3], [1], [7]])
+ *     updates = tf.constant([9, 10, 11, 12])
+ *     output = tf.scatter_nd_non_aliasing_add(input, indices, updates)
+ *     with tf.Session() as sess:
+ *       print(sess.run(output))
+ * <p>
+ * The resulting value `output` would look like this:
+ * <p>
+ *     [1, 13, 3, 14, 14, 6, 7, 20]
+ * <p>
+ * See `tf.scatter_nd` for more details about how to make updates to slices.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class ScatterNdNonAliasingAdd<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new ScatterNdNonAliasingAdd operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input A Tensor.
+   * @param indices A Tensor. Must be one of the following types: `int32`, `int64`.
+   * A tensor of indices into `input`.
+   * @param updates A Tensor. Must have the same type as ref. A tensor of updated values
+   * to add to `input`.
+   * @return a new instance of ScatterNdNonAliasingAdd
+   */
+  public static <T, U extends Number> ScatterNdNonAliasingAdd<T> create(Scope scope, Operand<T> input, Operand<U> indices, Operand<T> updates) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ScatterNdNonAliasingAdd", scope.makeOpName("ScatterNdNonAliasingAdd"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(updates.asOutput());
+    return new ScatterNdNonAliasingAdd<T>(opBuilder.build());
+  }
+  
+  /**
+   * A `Tensor` with the same shape as `input`, containing values of `input`
+   * updated with `updates`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private ScatterNdNonAliasingAdd(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ScatterNdSub.java java-ops/org/tensorflow/op/core/ScatterNdSub.java
--- java/org/tensorflow/op/core/ScatterNdSub.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ScatterNdSub.java	2018-10-16 20:18:38.495432196 +0900
@@ -0,0 +1,145 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Applies sparse subtraction between `updates` and individual values or slices
+ * <p>
+ * within a given variable according to `indices`.
+ * <p>
+ * `ref` is a `Tensor` with rank `P` and `indices` is a `Tensor` of rank `Q`.
+ * <p>
+ * `indices` must be integer tensor, containing indices into `ref`.
+ * It must be shape \\([d_0, ..., d_{Q-2}, K]\\) where `0 < K <= P`.
+ * <p>
+ * The innermost dimension of `indices` (with length `K`) corresponds to
+ * indices into elements (if `K = P`) or slices (if `K < P`) along the `K`th
+ * dimension of `ref`.
+ * <p>
+ * `updates` is `Tensor` of rank `Q-1+P-K` with shape:
+ * <p>
+ * $$[d_0, ..., d_{Q-2}, ref.shape[K], ..., ref.shape[P-1]].$$
+ * <p>
+ * For example, say we want to subtract 4 scattered elements from a rank-1 tensor
+ * with 8 elements. In Python, that subtraction would look like this:
+ * <p>
+ *     ref = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])
+ *     indices = tf.constant([[4], [3], [1], [7]])
+ *     updates = tf.constant([9, 10, 11, 12])
+ *     sub = tf.scatter_nd_sub(ref, indices, updates)
+ *     with tf.Session() as sess:
+ *       print sess.run(sub)
+ * <p>
+ * The resulting update to ref would look like this:
+ * <p>
+ *     [1, -9, 3, -6, -4, 6, 7, -4]
+ * <p>
+ * See `tf.scatter_nd` for more details about how to make updates to
+ * slices.
+ * 
+ * @param <T> data type for {@code outputRef()} output
+ */
+@Operator
+public final class ScatterNdSub<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ScatterNdSub}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking An optional bool. Defaults to True. If True, the assignment will
+     * be protected by a lock; otherwise the behavior is undefined,
+     * but may exhibit less contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ScatterNdSub operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param ref A mutable Tensor. Should be from a Variable node.
+   * @param indices A Tensor. Must be one of the following types: int32, int64.
+   * A tensor of indices into ref.
+   * @param updates A Tensor. Must have the same type as ref. A tensor of updated values
+   * to subtract from ref.
+   * @param options carries optional attributes values
+   * @return a new instance of ScatterNdSub
+   */
+  public static <T, U extends Number> ScatterNdSub<T> create(Scope scope, Operand<T> ref, Operand<U> indices, Operand<T> updates, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ScatterNdSub", scope.makeOpName("ScatterNdSub"));
+    opBuilder.addInput(ref.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(updates.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ScatterNdSub<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking An optional bool. Defaults to True. If True, the assignment will
+   * be protected by a lock; otherwise the behavior is undefined,
+   * but may exhibit less contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * Same as ref. Returned as a convenience for operations that want
+   * to use the updated values after the update is done.
+   */
+  public Output<T> outputRef() {
+    return outputRef;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return outputRef;
+  }
+  
+  private Output<T> outputRef;
+  
+  private ScatterNdSub(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    outputRef = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ScatterNdUpdate.java java-ops/org/tensorflow/op/core/ScatterNdUpdate.java
--- java/org/tensorflow/op/core/ScatterNdUpdate.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ScatterNdUpdate.java	2018-10-16 20:18:38.496432196 +0900
@@ -0,0 +1,147 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Applies sparse `updates` to individual values or slices within a given
+ * <p>
+ * variable according to `indices`.
+ * <p>
+ * `ref` is a `Tensor` with rank `P` and `indices` is a `Tensor` of rank `Q`.
+ * <p>
+ * `indices` must be integer tensor, containing indices into `ref`.
+ * It must be shape \\([d_0, ..., d_{Q-2}, K]\\) where `0 < K <= P`.
+ * <p>
+ * The innermost dimension of `indices` (with length `K`) corresponds to
+ * indices into elements (if `K = P`) or slices (if `K < P`) along the `K`th
+ * dimension of `ref`.
+ * <p>
+ * `updates` is `Tensor` of rank `Q-1+P-K` with shape:
+ * <p>
+ * $$[d_0, ..., d_{Q-2}, ref.shape[K], ..., ref.shape[P-1]].$$
+ * <p>
+ * For example, say we want to update 4 scattered elements to a rank-1 tensor to
+ * 8 elements. In Python, that update would look like this:
+ * <pre>{@code
+ *     ref = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])
+ *     indices = tf.constant([[4], [3], [1] ,[7]])
+ *     updates = tf.constant([9, 10, 11, 12])
+ *     update = tf.scatter_nd_update(ref, indices, updates)
+ *     with tf.Session() as sess:
+ *       print sess.run(update)
+ * }</pre>
+ * The resulting update to ref would look like this:
+ * <p>
+ *     [1, 11, 3, 10, 9, 6, 7, 12]
+ * <p>
+ * See `tf.scatter_nd` for more details about how to make updates to
+ * slices.
+ * <p>
+ * See also `tf.scatter_update` and `tf.batch_scatter_update`.
+ * 
+ * @param <T> data type for {@code outputRef()} output
+ */
+@Operator
+public final class ScatterNdUpdate<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ScatterNdUpdate}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking An optional bool. Defaults to True. If True, the assignment will
+     * be protected by a lock; otherwise the behavior is undefined,
+     * but may exhibit less contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ScatterNdUpdate operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param ref A mutable Tensor. Should be from a Variable node.
+   * @param indices A Tensor. Must be one of the following types: int32, int64.
+   * A tensor of indices into ref.
+   * @param updates A Tensor. Must have the same type as ref. A tensor of updated
+   * values to add to ref.
+   * @param options carries optional attributes values
+   * @return a new instance of ScatterNdUpdate
+   */
+  public static <T, U extends Number> ScatterNdUpdate<T> create(Scope scope, Operand<T> ref, Operand<U> indices, Operand<T> updates, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ScatterNdUpdate", scope.makeOpName("ScatterNdUpdate"));
+    opBuilder.addInput(ref.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(updates.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ScatterNdUpdate<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking An optional bool. Defaults to True. If True, the assignment will
+   * be protected by a lock; otherwise the behavior is undefined,
+   * but may exhibit less contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * Same as ref. Returned as a convenience for operations that want to
+   * use the updated values after the update is done.
+   */
+  public Output<T> outputRef() {
+    return outputRef;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return outputRef;
+  }
+  
+  private Output<T> outputRef;
+  
+  private ScatterNdUpdate(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    outputRef = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ScatterSub.java java-ops/org/tensorflow/op/core/ScatterSub.java
--- java/org/tensorflow/op/core/ScatterSub.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ScatterSub.java	2018-10-16 20:18:38.497432195 +0900
@@ -0,0 +1,131 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Subtracts sparse updates to a variable reference.
+ * <p>
+ * <pre>{@code
+ *     # Scalar indices
+ *     ref[indices, ...] -= updates[...]
+ * 
+ *     # Vector indices (for each i)
+ *     ref[indices[i], ...] -= updates[i, ...]
+ * 
+ *     # High rank indices (for each i, ..., j)
+ *     ref[indices[i, ..., j], ...] -= updates[i, ..., j, ...]
+ * }</pre>
+ * This operation outputs `ref` after the update is done.
+ * This makes it easier to chain operations that need to use the reset value.
+ * <p>
+ * Duplicate entries are handled correctly: if multiple `indices` reference
+ * the same location, their (negated) contributions add.
+ * <p>
+ * Requires `updates.shape = indices.shape + ref.shape[1:]` or `updates.shape = []`.
+ * <p>
+ * <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
+ * <img style="width:100%" src="https://www.tensorflow.org/images/ScatterSub.png" alt>
+ * </div>
+ * 
+ * @param <T> data type for {@code outputRef()} output
+ */
+@Operator
+public final class ScatterSub<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ScatterSub}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If True, the subtraction will be protected by a lock;
+     * otherwise the behavior is undefined, but may exhibit less contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ScatterSub operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param ref Should be from a `Variable` node.
+   * @param indices A tensor of indices into the first dimension of `ref`.
+   * @param updates A tensor of updated values to subtract from `ref`.
+   * @param options carries optional attributes values
+   * @return a new instance of ScatterSub
+   */
+  public static <T, U extends Number> ScatterSub<T> create(Scope scope, Operand<T> ref, Operand<U> indices, Operand<T> updates, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ScatterSub", scope.makeOpName("ScatterSub"));
+    opBuilder.addInput(ref.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(updates.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ScatterSub<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If True, the subtraction will be protected by a lock;
+   * otherwise the behavior is undefined, but may exhibit less contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * = Same as `ref`.  Returned as a convenience for operations that want
+   * to use the updated values after the update is done.
+   */
+  public Output<T> outputRef() {
+    return outputRef;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return outputRef;
+  }
+  
+  private Output<T> outputRef;
+  
+  private ScatterSub(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    outputRef = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ScatterUpdate.java java-ops/org/tensorflow/op/core/ScatterUpdate.java
--- java/org/tensorflow/op/core/ScatterUpdate.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ScatterUpdate.java	2018-10-16 20:18:38.498432194 +0900
@@ -0,0 +1,135 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Applies sparse updates to a variable reference.
+ * <p>
+ * This operation computes
+ * <pre>{@code
+ *     # Scalar indices
+ *     ref[indices, ...] = updates[...]
+ * 
+ *     # Vector indices (for each i)
+ *     ref[indices[i], ...] = updates[i, ...]
+ * 
+ *     # High rank indices (for each i, ..., j)
+ *     ref[indices[i, ..., j], ...] = updates[i, ..., j, ...]
+ * }</pre>
+ * This operation outputs `ref` after the update is done.
+ * This makes it easier to chain operations that need to use the reset value.
+ * <p>
+ * If values in `ref` is to be updated more than once, because there are
+ * duplicate entries in `indices`, the order at which the updates happen
+ * for each value is undefined.
+ * <p>
+ * Requires `updates.shape = indices.shape + ref.shape[1:]` or `updates.shape = []`.
+ * <p>
+ * <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
+ * <img style="width:100%" src="https://www.tensorflow.org/images/ScatterUpdate.png" alt>
+ * </div>
+ * <p>
+ * See also `tf.batch_scatter_update` and `tf.scatter_nd_update`.
+ * 
+ * @param <T> data type for {@code outputRef()} output
+ */
+@Operator
+public final class ScatterUpdate<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ScatterUpdate}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If True, the assignment will be protected by a lock;
+     * otherwise the behavior is undefined, but may exhibit less contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ScatterUpdate operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param ref Should be from a `Variable` node.
+   * @param indices A tensor of indices into the first dimension of `ref`.
+   * @param updates A tensor of updated values to store in `ref`.
+   * @param options carries optional attributes values
+   * @return a new instance of ScatterUpdate
+   */
+  public static <T, U extends Number> ScatterUpdate<T> create(Scope scope, Operand<T> ref, Operand<U> indices, Operand<T> updates, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ScatterUpdate", scope.makeOpName("ScatterUpdate"));
+    opBuilder.addInput(ref.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(updates.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new ScatterUpdate<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If True, the assignment will be protected by a lock;
+   * otherwise the behavior is undefined, but may exhibit less contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * = Same as `ref`.  Returned as a convenience for operations that want
+   * to use the updated values after the update is done.
+   */
+  public Output<T> outputRef() {
+    return outputRef;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return outputRef;
+  }
+  
+  private Output<T> outputRef;
+  
+  private ScatterUpdate(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    outputRef = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SdcaFprint.java java-ops/org/tensorflow/op/core/SdcaFprint.java
--- java/org/tensorflow/op/core/SdcaFprint.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SdcaFprint.java	2018-10-16 20:18:38.499432194 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes fingerprints of the input strings.
+ */
+@Operator
+public final class SdcaFprint extends PrimitiveOp implements Operand<Long> {
+  
+  /**
+   * Factory method to create a class to wrap a new SdcaFprint operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input vector of strings to compute fingerprints on.
+   * @return a new instance of SdcaFprint
+   */
+  public static SdcaFprint create(Scope scope, Operand<String> input) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SdcaFprint", scope.makeOpName("SdcaFprint"));
+    opBuilder.addInput(input.asOutput());
+    return new SdcaFprint(opBuilder.build());
+  }
+  
+  /**
+   * a (N,2) shaped matrix where N is the number of elements in the input
+   * vector. Each row contains the low and high parts of the fingerprint.
+   */
+  public Output<Long> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<Long> asOutput() {
+    return output;
+  }
+  
+  private Output<Long> output;
+  
+  private SdcaFprint(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SdcaOptimizer.java java-ops/org/tensorflow/op/core/SdcaOptimizer.java
--- java/org/tensorflow/op/core/SdcaOptimizer.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SdcaOptimizer.java	2018-10-16 20:18:38.501432192 +0900
@@ -0,0 +1,178 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Distributed version of Stochastic Dual Coordinate Ascent (SDCA) optimizer for
+ * <p>
+ * linear models with L1 + L2 regularization. As global optimization objective is
+ * strongly-convex, the optimizer optimizes the dual objective at each step. The
+ * optimizer applies each update one example at a time. Examples are sampled
+ * uniformly, and the optimizer is learning rate free and enjoys linear convergence
+ * rate.
+ * <p>
+ * [Proximal Stochastic Dual Coordinate Ascent](http://arxiv.org/pdf/1211.2717v1.pdf).<br>
+ * Shai Shalev-Shwartz, Tong Zhang. 2012
+ * <p>
+ * $$Loss Objective = \sum f_{i} (wx_{i}) + (l2 / 2) * |w|^2 + l1 * |w|$$
+ * <p>
+ * [Adding vs. Averaging in Distributed Primal-Dual Optimization](http://arxiv.org/abs/1502.03508).<br>
+ * Chenxin Ma, Virginia Smith, Martin Jaggi, Michael I. Jordan,
+ * Peter Richtarik, Martin Takac. 2015
+ * <p>
+ * [Stochastic Dual Coordinate Ascent with Adaptive Probabilities](https://arxiv.org/abs/1502.08053).<br>
+ * Dominik Csiba, Zheng Qu, Peter Richtarik. 2015
+ */
+@Operator
+public final class SdcaOptimizer extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.SdcaOptimizer}
+   */
+  public static class Options {
+    
+    /**
+     * @param adaptative Whether to use Adaptive SDCA for the inner loop.
+     */
+    public Options adaptative(Boolean adaptative) {
+      this.adaptative = adaptative;
+      return this;
+    }
+    
+    private Boolean adaptative;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new SdcaOptimizer operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param sparseExampleIndices a list of vectors which contain example indices.
+   * @param sparseFeatureIndices a list of vectors which contain feature indices.
+   * @param sparseFeatureValues a list of vectors which contains feature value
+   * associated with each feature group.
+   * @param denseFeatures a list of matrices which contains the dense feature values.
+   * @param exampleWeights a vector which contains the weight associated with each
+   * example.
+   * @param exampleLabels a vector which contains the label/target associated with each
+   * example.
+   * @param sparseIndices a list of vectors where each value is the indices which has
+   * corresponding weights in sparse_weights. This field maybe omitted for the
+   * dense approach.
+   * @param sparseWeights a list of vectors where each value is the weight associated with
+   * a sparse feature group.
+   * @param denseWeights a list of vectors where the values are the weights associated
+   * with a dense feature group.
+   * @param exampleStateData a list of vectors containing the example state data.
+   * @param lossType Type of the primal loss. Currently SdcaSolver supports logistic,
+   * squared and hinge losses.
+   * @param l1 Symmetric l1 regularization strength.
+   * @param l2 Symmetric l2 regularization strength.
+   * @param numLossPartitions Number of partitions of the global loss function.
+   * @param numInnerIterations Number of iterations per mini-batch.
+   * @param options carries optional attributes values
+   * @return a new instance of SdcaOptimizer
+   */
+  public static SdcaOptimizer create(Scope scope, Iterable<Operand<Long>> sparseExampleIndices, Iterable<Operand<Long>> sparseFeatureIndices, Iterable<Operand<Float>> sparseFeatureValues, Iterable<Operand<Float>> denseFeatures, Operand<Float> exampleWeights, Operand<Float> exampleLabels, Iterable<Operand<Long>> sparseIndices, Iterable<Operand<Float>> sparseWeights, Iterable<Operand<Float>> denseWeights, Operand<Float> exampleStateData, String lossType, Float l1, Float l2, Long numLossPartitions, Long numInnerIterations, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SdcaOptimizer", scope.makeOpName("SdcaOptimizer"));
+    opBuilder.addInputList(Operands.asOutputs(sparseExampleIndices));
+    opBuilder.addInputList(Operands.asOutputs(sparseFeatureIndices));
+    opBuilder.addInputList(Operands.asOutputs(sparseFeatureValues));
+    opBuilder.addInputList(Operands.asOutputs(denseFeatures));
+    opBuilder.addInput(exampleWeights.asOutput());
+    opBuilder.addInput(exampleLabels.asOutput());
+    opBuilder.addInputList(Operands.asOutputs(sparseIndices));
+    opBuilder.addInputList(Operands.asOutputs(sparseWeights));
+    opBuilder.addInputList(Operands.asOutputs(denseWeights));
+    opBuilder.addInput(exampleStateData.asOutput());
+    opBuilder.setAttr("loss_type", lossType);
+    opBuilder.setAttr("l1", l1);
+    opBuilder.setAttr("l2", l2);
+    opBuilder.setAttr("num_loss_partitions", numLossPartitions);
+    opBuilder.setAttr("num_inner_iterations", numInnerIterations);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.adaptative != null) {
+          opBuilder.setAttr("adaptative", opts.adaptative);
+        }
+      }
+    }
+    return new SdcaOptimizer(opBuilder.build());
+  }
+  
+  /**
+   * @param adaptative Whether to use Adaptive SDCA for the inner loop.
+   */
+  public static Options adaptative(Boolean adaptative) {
+    return new Options().adaptative(adaptative);
+  }
+  
+  /**
+   * a list of vectors containing the updated example state
+   * data.
+   */
+  public Output<Float> outExampleStateData() {
+    return outExampleStateData;
+  }
+  
+  /**
+   * a list of vectors where each value is the delta
+   * weights associated with a sparse feature group.
+   */
+  public List<Output<Float>> outDeltaSparseWeights() {
+    return outDeltaSparseWeights;
+  }
+  
+  /**
+   * a list of vectors where the values are the delta
+   * weights associated with a dense feature group.
+   */
+  public List<Output<Float>> outDeltaDenseWeights() {
+    return outDeltaDenseWeights;
+  }
+  
+  private Output<Float> outExampleStateData;
+  private List<Output<Float>> outDeltaSparseWeights;
+  private List<Output<Float>> outDeltaDenseWeights;
+  
+  @SuppressWarnings("unchecked")
+  private SdcaOptimizer(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    outExampleStateData = operation.output(outputIdx++);
+    int outDeltaSparseWeightsLength = operation.outputListLength("out_delta_sparse_weights");
+    outDeltaSparseWeights = Arrays.asList((Output<Float>[])operation.outputList(outputIdx, outDeltaSparseWeightsLength));
+    outputIdx += outDeltaSparseWeightsLength;
+    int outDeltaDenseWeightsLength = operation.outputListLength("out_delta_dense_weights");
+    outDeltaDenseWeights = Arrays.asList((Output<Float>[])operation.outputList(outputIdx, outDeltaDenseWeightsLength));
+    outputIdx += outDeltaDenseWeightsLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/SdcaShrinkL1.java java-ops/org/tensorflow/op/core/SdcaShrinkL1.java
--- java/org/tensorflow/op/core/SdcaShrinkL1.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SdcaShrinkL1.java	2018-10-16 20:18:38.502432191 +0900
@@ -0,0 +1,56 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Applies L1 regularization shrink step on the parameters.
+ */
+@Operator
+public final class SdcaShrinkL1 extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new SdcaShrinkL1 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param weights a list of vectors where each value is the weight associated with a
+   * feature group.
+   * @param l1 Symmetric l1 regularization strength.
+   * @param l2 Symmetric l2 regularization strength. Should be a positive float.
+   * @return a new instance of SdcaShrinkL1
+   */
+  public static SdcaShrinkL1 create(Scope scope, Iterable<Operand<Float>> weights, Float l1, Float l2) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SdcaShrinkL1", scope.makeOpName("SdcaShrinkL1"));
+    opBuilder.addInputList(Operands.asOutputs(weights));
+    opBuilder.setAttr("l1", l1);
+    opBuilder.setAttr("l2", l2);
+    return new SdcaShrinkL1(opBuilder.build());
+  }
+  
+  
+  private SdcaShrinkL1(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SegmentMax.java java-ops/org/tensorflow/op/core/SegmentMax.java
--- java/org/tensorflow/op/core/SegmentMax.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SegmentMax.java	2018-10-16 20:18:38.502432191 +0900
@@ -0,0 +1,86 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the maximum along segments of a tensor.
+ * <p>
+ * Read
+ * [the section on segmentation](https://tensorflow.org/api_guides/python/math_ops#Segmentation)
+ * for an explanation of segments.
+ * <p>
+ * Computes a tensor such that
+ * \\(output_i = \max_j(data_j)\\) where `max` is over `j` such
+ * that `segment_ids[j] == i`.
+ * <p>
+ * If the max is empty for a given segment ID `i`, `output[i] = 0`.
+ * <p>
+ * <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
+ * <img style="width:100%" src="https://www.tensorflow.org/images/SegmentMax.png" alt>
+ * </div>
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class SegmentMax<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new SegmentMax operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param data 
+   * @param segmentIds A 1-D tensor whose size is equal to the size of `data`'s
+   * first dimension.  Values should be sorted and can be repeated.
+   * @return a new instance of SegmentMax
+   */
+  public static <T extends Number, U extends Number> SegmentMax<T> create(Scope scope, Operand<T> data, Operand<U> segmentIds) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SegmentMax", scope.makeOpName("SegmentMax"));
+    opBuilder.addInput(data.asOutput());
+    opBuilder.addInput(segmentIds.asOutput());
+    return new SegmentMax<T>(opBuilder.build());
+  }
+  
+  /**
+   * Has same shape as data, except for dimension 0 which
+   * has size `k`, the number of segments.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private SegmentMax(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SegmentMean.java java-ops/org/tensorflow/op/core/SegmentMean.java
--- java/org/tensorflow/op/core/SegmentMean.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SegmentMean.java	2018-10-16 20:18:38.503432191 +0900
@@ -0,0 +1,87 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the mean along segments of a tensor.
+ * <p>
+ * Read
+ * [the section on segmentation](https://tensorflow.org/api_guides/python/math_ops#Segmentation)
+ * for an explanation of segments.
+ * <p>
+ * Computes a tensor such that
+ * \\(output_i = \frac{\sum_j data_j}{N}\\) where `mean` is
+ * over `j` such that `segment_ids[j] == i` and `N` is the total number of
+ * values summed.
+ * <p>
+ * If the mean is empty for a given segment ID `i`, `output[i] = 0`.
+ * <p>
+ * <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
+ * <img style="width:100%" src="https://www.tensorflow.org/images/SegmentMean.png" alt>
+ * </div>
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class SegmentMean<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new SegmentMean operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param data 
+   * @param segmentIds A 1-D tensor whose size is equal to the size of `data`'s
+   * first dimension.  Values should be sorted and can be repeated.
+   * @return a new instance of SegmentMean
+   */
+  public static <T, U extends Number> SegmentMean<T> create(Scope scope, Operand<T> data, Operand<U> segmentIds) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SegmentMean", scope.makeOpName("SegmentMean"));
+    opBuilder.addInput(data.asOutput());
+    opBuilder.addInput(segmentIds.asOutput());
+    return new SegmentMean<T>(opBuilder.build());
+  }
+  
+  /**
+   * Has same shape as data, except for dimension 0 which
+   * has size `k`, the number of segments.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private SegmentMean(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SegmentMin.java java-ops/org/tensorflow/op/core/SegmentMin.java
--- java/org/tensorflow/op/core/SegmentMin.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SegmentMin.java	2018-10-16 20:18:38.504432190 +0900
@@ -0,0 +1,86 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the minimum along segments of a tensor.
+ * <p>
+ * Read
+ * [the section on segmentation](https://tensorflow.org/api_guides/python/math_ops#Segmentation)
+ * for an explanation of segments.
+ * <p>
+ * Computes a tensor such that
+ * \\(output_i = \min_j(data_j)\\) where `min` is over `j` such
+ * that `segment_ids[j] == i`.
+ * <p>
+ * If the min is empty for a given segment ID `i`, `output[i] = 0`.
+ * <p>
+ * <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
+ * <img style="width:100%" src="https://www.tensorflow.org/images/SegmentMin.png" alt>
+ * </div>
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class SegmentMin<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new SegmentMin operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param data 
+   * @param segmentIds A 1-D tensor whose size is equal to the size of `data`'s
+   * first dimension.  Values should be sorted and can be repeated.
+   * @return a new instance of SegmentMin
+   */
+  public static <T extends Number, U extends Number> SegmentMin<T> create(Scope scope, Operand<T> data, Operand<U> segmentIds) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SegmentMin", scope.makeOpName("SegmentMin"));
+    opBuilder.addInput(data.asOutput());
+    opBuilder.addInput(segmentIds.asOutput());
+    return new SegmentMin<T>(opBuilder.build());
+  }
+  
+  /**
+   * Has same shape as data, except for dimension 0 which
+   * has size `k`, the number of segments.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private SegmentMin(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SegmentProd.java java-ops/org/tensorflow/op/core/SegmentProd.java
--- java/org/tensorflow/op/core/SegmentProd.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SegmentProd.java	2018-10-16 20:18:38.504432190 +0900
@@ -0,0 +1,86 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the product along segments of a tensor.
+ * <p>
+ * Read
+ * [the section on segmentation](https://tensorflow.org/api_guides/python/math_ops#Segmentation)
+ * for an explanation of segments.
+ * <p>
+ * Computes a tensor such that
+ * \\(output_i = \prod_j data_j\\) where the product is over `j` such
+ * that `segment_ids[j] == i`.
+ * <p>
+ * If the product is empty for a given segment ID `i`, `output[i] = 1`.
+ * <p>
+ * <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
+ * <img style="width:100%" src="https://www.tensorflow.org/images/SegmentProd.png" alt>
+ * </div>
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class SegmentProd<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new SegmentProd operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param data 
+   * @param segmentIds A 1-D tensor whose size is equal to the size of `data`'s
+   * first dimension.  Values should be sorted and can be repeated.
+   * @return a new instance of SegmentProd
+   */
+  public static <T, U extends Number> SegmentProd<T> create(Scope scope, Operand<T> data, Operand<U> segmentIds) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SegmentProd", scope.makeOpName("SegmentProd"));
+    opBuilder.addInput(data.asOutput());
+    opBuilder.addInput(segmentIds.asOutput());
+    return new SegmentProd<T>(opBuilder.build());
+  }
+  
+  /**
+   * Has same shape as data, except for dimension 0 which
+   * has size `k`, the number of segments.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private SegmentProd(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SegmentSum.java java-ops/org/tensorflow/op/core/SegmentSum.java
--- java/org/tensorflow/op/core/SegmentSum.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SegmentSum.java	2018-10-16 20:18:38.505432189 +0900
@@ -0,0 +1,86 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the sum along segments of a tensor.
+ * <p>
+ * Read
+ * [the section on segmentation](https://tensorflow.org/api_guides/python/math_ops#Segmentation)
+ * for an explanation of segments.
+ * <p>
+ * Computes a tensor such that
+ * \\(output_i = \sum_j data_j\\) where sum is over `j` such
+ * that `segment_ids[j] == i`.
+ * <p>
+ * If the sum is empty for a given segment ID `i`, `output[i] = 0`.
+ * <p>
+ * <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
+ * <img style="width:100%" src="https://www.tensorflow.org/images/SegmentSum.png" alt>
+ * </div>
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class SegmentSum<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new SegmentSum operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param data 
+   * @param segmentIds A 1-D tensor whose size is equal to the size of `data`'s
+   * first dimension.  Values should be sorted and can be repeated.
+   * @return a new instance of SegmentSum
+   */
+  public static <T, U extends Number> SegmentSum<T> create(Scope scope, Operand<T> data, Operand<U> segmentIds) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SegmentSum", scope.makeOpName("SegmentSum"));
+    opBuilder.addInput(data.asOutput());
+    opBuilder.addInput(segmentIds.asOutput());
+    return new SegmentSum<T>(opBuilder.build());
+  }
+  
+  /**
+   * Has same shape as data, except for dimension 0 which
+   * has size `k`, the number of segments.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private SegmentSum(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SelfAdjointEig.java java-ops/org/tensorflow/op/core/SelfAdjointEig.java
--- java/org/tensorflow/op/core/SelfAdjointEig.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SelfAdjointEig.java	2018-10-16 20:18:38.507432188 +0900
@@ -0,0 +1,120 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the eigen decomposition of one or more square self-adjoint matrices.
+ * <p>
+ * Computes the eigenvalues and (optionally) eigenvectors of each inner matrix in
+ * `input` such that `input[..., :, :] = v[..., :, :] * diag(e[..., :])`. The eigenvalues
+ * are sorted in non-decreasing order.
+ * <pre>{@code
+ * # a is a tensor.
+ * # e is a tensor of eigenvalues.
+ * # v is a tensor of eigenvectors.
+ * e, v = self_adjoint_eig(a)
+ * e = self_adjoint_eig(a, compute_v=False)
+ * }</pre>
+ * 
+ * 
+ * @param <T> data type for {@code e()} output
+ */
+@Operator
+public final class SelfAdjointEig<T> extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.SelfAdjointEig}
+   */
+  public static class Options {
+    
+    /**
+     * @param computeV If `True` then eigenvectors will be computed and returned in `v`.
+     * Otherwise, only the eigenvalues will be computed.
+     */
+    public Options computeV(Boolean computeV) {
+      this.computeV = computeV;
+      return this;
+    }
+    
+    private Boolean computeV;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new SelfAdjointEig operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input `Tensor` input of shape `[N, N]`.
+   * @param options carries optional attributes values
+   * @return a new instance of SelfAdjointEig
+   */
+  public static <T> SelfAdjointEig<T> create(Scope scope, Operand<T> input, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SelfAdjointEigV2", scope.makeOpName("SelfAdjointEig"));
+    opBuilder.addInput(input.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.computeV != null) {
+          opBuilder.setAttr("compute_v", opts.computeV);
+        }
+      }
+    }
+    return new SelfAdjointEig<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param computeV If `True` then eigenvectors will be computed and returned in `v`.
+   * Otherwise, only the eigenvalues will be computed.
+   */
+  public static Options computeV(Boolean computeV) {
+    return new Options().computeV(computeV);
+  }
+  
+  /**
+   * Eigenvalues. Shape is `[N]`.
+   */
+  public Output<T> e() {
+    return e;
+  }
+  
+  /**
+   * Eigenvectors. Shape is `[N, N]`.
+   */
+  public Output<T> v() {
+    return v;
+  }
+  
+  private Output<T> e;
+  private Output<T> v;
+  
+  private SelfAdjointEig(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    e = operation.output(outputIdx++);
+    v = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SeluGrad.java java-ops/org/tensorflow/op/core/SeluGrad.java
--- java/org/tensorflow/op/core/SeluGrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SeluGrad.java	2018-10-16 20:18:38.507432188 +0900
@@ -0,0 +1,69 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Computes gradients for the scaled exponential linear (Selu) operation.
+ * 
+ * @param <T> data type for {@code backprops()} output
+ */
+public final class SeluGrad<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new SeluGrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param gradients The backpropagated gradients to the corresponding Selu operation.
+   * @param outputs The outputs of the corresponding Selu operation.
+   * @return a new instance of SeluGrad
+   */
+  public static <T extends Number> SeluGrad<T> create(Scope scope, Operand<T> gradients, Operand<T> outputs) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SeluGrad", scope.makeOpName("SeluGrad"));
+    opBuilder.addInput(gradients.asOutput());
+    opBuilder.addInput(outputs.asOutput());
+    return new SeluGrad<T>(opBuilder.build());
+  }
+  
+  /**
+   * The gradients: `gradients * (outputs + scale * alpha)`
+   * if outputs < 0, `scale * gradients` otherwise.
+   */
+  public Output<T> backprops() {
+    return backprops;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return backprops;
+  }
+  
+  private Output<T> backprops;
+  
+  private SeluGrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    backprops = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Selu.java java-ops/org/tensorflow/op/core/Selu.java
--- java/org/tensorflow/op/core/Selu.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Selu.java	2018-10-16 20:18:38.507432188 +0900
@@ -0,0 +1,75 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes scaled exponential linear: `scale * alpha * (exp(features) - 1)`
+ * <p>
+ * if < 0, `scale * features` otherwise.
+ * <p>
+ * To be used together with
+ * `initializer = tf.variance_scaling_initializer(factor=1.0, mode='FAN_IN')`.
+ * For correct dropout, use `tf.contrib.nn.alpha_dropout`.
+ * <p>
+ * See [Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515)
+ * 
+ * @param <T> data type for {@code activations()} output
+ */
+@Operator
+public final class Selu<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Selu operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param features 
+   * @return a new instance of Selu
+   */
+  public static <T extends Number> Selu<T> create(Scope scope, Operand<T> features) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Selu", scope.makeOpName("Selu"));
+    opBuilder.addInput(features.asOutput());
+    return new Selu<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> activations() {
+    return activations;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return activations;
+  }
+  
+  private Output<T> activations;
+  
+  private Selu(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    activations = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SerializeIterator.java java-ops/org/tensorflow/op/core/SerializeIterator.java
--- java/org/tensorflow/op/core/SerializeIterator.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SerializeIterator.java	2018-10-16 20:18:38.508432187 +0900
@@ -0,0 +1,68 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Converts the given `resource_handle` representing an iterator to a variant tensor.
+ */
+@Operator
+public final class SerializeIterator extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new SerializeIterator operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param resourceHandle A handle to an iterator resource.
+   * @return a new instance of SerializeIterator
+   */
+  public static SerializeIterator create(Scope scope, Operand<?> resourceHandle) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SerializeIterator", scope.makeOpName("SerializeIterator"));
+    opBuilder.addInput(resourceHandle.asOutput());
+    return new SerializeIterator(opBuilder.build());
+  }
+  
+  /**
+   * A variant tensor storing the state of the iterator contained in the
+   * resource.
+   */
+  public Output<?> serialized() {
+    return serialized;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) serialized;
+  }
+  
+  private Output<?> serialized;
+  
+  private SerializeIterator(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    serialized = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SerializeManySparse.java java-ops/org/tensorflow/op/core/SerializeManySparse.java
--- java/org/tensorflow/op/core/SerializeManySparse.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SerializeManySparse.java	2018-10-16 20:18:38.508432187 +0900
@@ -0,0 +1,96 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Serialize an `N`-minibatch `SparseTensor` into an `[N, 3]` `Tensor` object.
+ * <p>
+ * The `SparseTensor` must have rank `R` greater than 1, and the first dimension
+ * is treated as the minibatch dimension.  Elements of the `SparseTensor`
+ * must be sorted in increasing order of this first dimension.  The serialized
+ * `SparseTensor` objects going into each row of `serialized_sparse` will have
+ * rank `R-1`.
+ * <p>
+ * The minibatch size `N` is extracted from `sparse_shape[0]`.
+ * 
+ * @param <U> data type for {@code serializedSparse()} output
+ */
+@Operator
+public final class SerializeManySparse<U> extends PrimitiveOp implements Operand<U> {
+  
+  /**
+   * Factory method to create a class to wrap a new SerializeManySparse operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param sparseIndices 2-D.  The `indices` of the minibatch `SparseTensor`.
+   * @param sparseValues 1-D.  The `values` of the minibatch `SparseTensor`.
+   * @param sparseShape 1-D.  The `shape` of the minibatch `SparseTensor`.
+   * @param outType The `dtype` to use for serialization; the supported types are `string`
+   * (default) and `variant`.
+   * @return a new instance of SerializeManySparse
+   */
+  public static <U, T> SerializeManySparse<U> create(Scope scope, Operand<Long> sparseIndices, Operand<T> sparseValues, Operand<Long> sparseShape, Class<U> outType) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SerializeManySparse", scope.makeOpName("SerializeManySparse"));
+    opBuilder.addInput(sparseIndices.asOutput());
+    opBuilder.addInput(sparseValues.asOutput());
+    opBuilder.addInput(sparseShape.asOutput());
+    opBuilder.setAttr("out_type", DataType.fromClass(outType));
+    return new SerializeManySparse<U>(opBuilder.build());
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new SerializeManySparse operation to the graph, using default output types.
+   * 
+   * @param scope current graph scope
+   * @param sparseIndices 2-D.  The `indices` of the minibatch `SparseTensor`.
+   * @param sparseValues 1-D.  The `values` of the minibatch `SparseTensor`.
+   * @param sparseShape 1-D.  The `shape` of the minibatch `SparseTensor`.
+   * @return a new instance of SerializeManySparse
+   */
+  public static <T> SerializeManySparse<String> create(Scope scope, Operand<Long> sparseIndices, Operand<T> sparseValues, Operand<Long> sparseShape) {
+    return create(scope, sparseIndices, sparseValues, sparseShape, String.class);
+  }
+  
+  /**
+   */
+  public Output<U> serializedSparse() {
+    return serializedSparse;
+  }
+  
+  @Override
+  public Output<U> asOutput() {
+    return serializedSparse;
+  }
+  
+  private Output<U> serializedSparse;
+  
+  private SerializeManySparse(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    serializedSparse = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SerializeSparse.java java-ops/org/tensorflow/op/core/SerializeSparse.java
--- java/org/tensorflow/op/core/SerializeSparse.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SerializeSparse.java	2018-10-16 20:18:38.509432186 +0900
@@ -0,0 +1,88 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Serialize a `SparseTensor` into a `[3]` `Tensor` object.
+ * 
+ * @param <U> data type for {@code serializedSparse()} output
+ */
+@Operator
+public final class SerializeSparse<U> extends PrimitiveOp implements Operand<U> {
+  
+  /**
+   * Factory method to create a class to wrap a new SerializeSparse operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param sparseIndices 2-D.  The `indices` of the `SparseTensor`.
+   * @param sparseValues 1-D.  The `values` of the `SparseTensor`.
+   * @param sparseShape 1-D.  The `shape` of the `SparseTensor`.
+   * @param outType The `dtype` to use for serialization; the supported types are `string`
+   * (default) and `variant`.
+   * @return a new instance of SerializeSparse
+   */
+  public static <U, T> SerializeSparse<U> create(Scope scope, Operand<Long> sparseIndices, Operand<T> sparseValues, Operand<Long> sparseShape, Class<U> outType) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SerializeSparse", scope.makeOpName("SerializeSparse"));
+    opBuilder.addInput(sparseIndices.asOutput());
+    opBuilder.addInput(sparseValues.asOutput());
+    opBuilder.addInput(sparseShape.asOutput());
+    opBuilder.setAttr("out_type", DataType.fromClass(outType));
+    return new SerializeSparse<U>(opBuilder.build());
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new SerializeSparse operation to the graph, using default output types.
+   * 
+   * @param scope current graph scope
+   * @param sparseIndices 2-D.  The `indices` of the `SparseTensor`.
+   * @param sparseValues 1-D.  The `values` of the `SparseTensor`.
+   * @param sparseShape 1-D.  The `shape` of the `SparseTensor`.
+   * @return a new instance of SerializeSparse
+   */
+  public static <T> SerializeSparse<String> create(Scope scope, Operand<Long> sparseIndices, Operand<T> sparseValues, Operand<Long> sparseShape) {
+    return create(scope, sparseIndices, sparseValues, sparseShape, String.class);
+  }
+  
+  /**
+   */
+  public Output<U> serializedSparse() {
+    return serializedSparse;
+  }
+  
+  @Override
+  public Output<U> asOutput() {
+    return serializedSparse;
+  }
+  
+  private Output<U> serializedSparse;
+  
+  private SerializeSparse(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    serializedSparse = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SerializeTensor.java java-ops/org/tensorflow/op/core/SerializeTensor.java
--- java/org/tensorflow/op/core/SerializeTensor.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SerializeTensor.java	2018-10-16 20:18:38.509432186 +0900
@@ -0,0 +1,66 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Transforms a Tensor into a serialized TensorProto proto.
+ */
+@Operator
+public final class SerializeTensor extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Factory method to create a class to wrap a new SerializeTensor operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param tensor A Tensor of type `T`.
+   * @return a new instance of SerializeTensor
+   */
+  public static <T> SerializeTensor create(Scope scope, Operand<T> tensor) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SerializeTensor", scope.makeOpName("SerializeTensor"));
+    opBuilder.addInput(tensor.asOutput());
+    return new SerializeTensor(opBuilder.build());
+  }
+  
+  /**
+   * A serialized TensorProto proto of the input tensor.
+   */
+  public Output<String> serialized() {
+    return serialized;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return serialized;
+  }
+  
+  private Output<String> serialized;
+  
+  private SerializeTensor(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    serialized = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SetDiff1D.java java-ops/org/tensorflow/op/core/SetDiff1D.java
--- java/org/tensorflow/op/core/SetDiff1D.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SetDiff1D.java	2018-10-16 20:18:38.326432315 +0900
@@ -0,0 +1,110 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the difference between two lists of numbers or strings.
+ * <p>
+ * Given a list `x` and a list `y`, this operation returns a list `out` that
+ * represents all values that are in `x` but not in `y`. The returned list `out`
+ * is sorted in the same order that the numbers appear in `x` (duplicates are
+ * preserved). This operation also returns a list `idx` that represents the
+ * position of each `out` element in `x`. In other words:
+ * <p>
+ * `out[i] = x[idx[i]] for i in [0, 1, ..., len(out) - 1]`
+ * <p>
+ * For example, given this input:
+ * <pre>{@code
+ * x = [1, 2, 3, 4, 5, 6]
+ * y = [1, 3, 5]
+ * }</pre>
+ * This operation would return:
+ * <pre>{@code
+ * out ==> [2, 4, 6]
+ * idx ==> [1, 3, 5]
+ * }</pre>
+ * 
+ * 
+ * @param <T> data type for {@code out()} output
+ * @param <U> data type for {@code idx()} output
+ */
+@Operator
+public final class SetDiff1D<T, U extends Number> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new SetDiff1D operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 1-D. Values to keep.
+   * @param y 1-D. Values to remove.
+   * @param outIdx 
+   * @return a new instance of SetDiff1D
+   */
+  public static <T, U extends Number> SetDiff1D<T, U> create(Scope scope, Operand<T> x, Operand<T> y, Class<U> outIdx) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ListDiff", scope.makeOpName("SetDiff1D"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(y.asOutput());
+    opBuilder.setAttr("out_idx", DataType.fromClass(outIdx));
+    return new SetDiff1D<T, U>(opBuilder.build());
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new SetDiff1D operation to the graph, using default output types.
+   * 
+   * @param scope current graph scope
+   * @param x 1-D. Values to keep.
+   * @param y 1-D. Values to remove.
+   * @return a new instance of SetDiff1D
+   */
+  public static <T> SetDiff1D<T, Integer> create(Scope scope, Operand<T> x, Operand<T> y) {
+    return create(scope, x, y, Integer.class);
+  }
+  
+  /**
+   * 1-D. Values present in `x` but not in `y`.
+   */
+  public Output<T> out() {
+    return out;
+  }
+  
+  /**
+   * 1-D. Positions of `x` values preserved in `out`.
+   */
+  public Output<U> idx() {
+    return idx;
+  }
+  
+  private Output<T> out;
+  private Output<U> idx;
+  
+  private SetDiff1D(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    out = operation.output(outputIdx++);
+    idx = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SetSize.java java-ops/org/tensorflow/op/core/SetSize.java
--- java/org/tensorflow/op/core/SetSize.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SetSize.java	2018-10-16 20:18:38.510432186 +0900
@@ -0,0 +1,113 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Number of unique elements along last dimension of input `set`.
+ * <p>
+ * Input `set` is a `SparseTensor` represented by `set_indices`, `set_values`,
+ * and `set_shape`. The last dimension contains values in a set, duplicates are
+ * allowed but ignored.
+ * <p>
+ * If `validate_indices` is `True`, this op validates the order and range of `set`
+ * indices.
+ */
+@Operator
+public final class SetSize extends PrimitiveOp implements Operand<Integer> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.SetSize}
+   */
+  public static class Options {
+    
+    /**
+     * @param validateIndices 
+     */
+    public Options validateIndices(Boolean validateIndices) {
+      this.validateIndices = validateIndices;
+      return this;
+    }
+    
+    private Boolean validateIndices;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new SetSize operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param setIndices 2D `Tensor`, indices of a `SparseTensor`.
+   * @param setValues 1D `Tensor`, values of a `SparseTensor`.
+   * @param setShape 1D `Tensor`, shape of a `SparseTensor`.
+   * @param options carries optional attributes values
+   * @return a new instance of SetSize
+   */
+  public static <T> SetSize create(Scope scope, Operand<Long> setIndices, Operand<T> setValues, Operand<Long> setShape, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SetSize", scope.makeOpName("SetSize"));
+    opBuilder.addInput(setIndices.asOutput());
+    opBuilder.addInput(setValues.asOutput());
+    opBuilder.addInput(setShape.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.validateIndices != null) {
+          opBuilder.setAttr("validate_indices", opts.validateIndices);
+        }
+      }
+    }
+    return new SetSize(opBuilder.build());
+  }
+  
+  /**
+   * @param validateIndices 
+   */
+  public static Options validateIndices(Boolean validateIndices) {
+    return new Options().validateIndices(validateIndices);
+  }
+  
+  /**
+   * For `set` ranked `n`, this is a `Tensor` with rank `n-1`, and the same 1st
+   * `n-1` dimensions as `set`. Each value is the number of unique elements in
+   * the corresponding `[0...n-1]` dimension of `set`.
+   */
+  public Output<Integer> size() {
+    return size;
+  }
+  
+  @Override
+  public Output<Integer> asOutput() {
+    return size;
+  }
+  
+  private Output<Integer> size;
+  
+  private SetSize(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    size = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SetStatsAggregatorDataset.java java-ops/org/tensorflow/op/core/SetStatsAggregatorDataset.java
--- java/org/tensorflow/op/core/SetStatsAggregatorDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SetStatsAggregatorDataset.java	2018-10-16 20:18:38.510432186 +0900
@@ -0,0 +1,82 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ */
+@Operator
+public final class SetStatsAggregatorDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new SetStatsAggregatorDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputDataset 
+   * @param statsAggregator 
+   * @param outputTypes 
+   * @param outputShapes 
+   * @return a new instance of SetStatsAggregatorDataset
+   */
+  public static SetStatsAggregatorDataset create(Scope scope, Operand<?> inputDataset, Operand<?> statsAggregator, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SetStatsAggregatorDataset", scope.makeOpName("SetStatsAggregatorDataset"));
+    opBuilder.addInput(inputDataset.asOutput());
+    opBuilder.addInput(statsAggregator.asOutput());
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new SetStatsAggregatorDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private SetStatsAggregatorDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Shape.java java-ops/org/tensorflow/op/core/Shape.java
--- java/org/tensorflow/op/core/Shape.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Shape.java	2018-10-16 20:18:38.510432186 +0900
@@ -0,0 +1,90 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns the shape of a tensor.
+ * <p>
+ * This operation returns a 1-D integer tensor representing the shape of `input`.
+ * <p>
+ * For example:
+ * <pre>{@code
+ * # 't' is [[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]]
+ * shape(t) ==> [2, 2, 3]
+ * }</pre>
+ * 
+ * 
+ * @param <U> data type for {@code output()} output
+ */
+@Operator
+public final class Shape<U extends Number> extends PrimitiveOp implements Operand<U> {
+  
+  /**
+   * Factory method to create a class to wrap a new Shape operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param outType 
+   * @return a new instance of Shape
+   */
+  public static <U extends Number, T> Shape<U> create(Scope scope, Operand<T> input, Class<U> outType) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Shape", scope.makeOpName("Shape"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.setAttr("out_type", DataType.fromClass(outType));
+    return new Shape<U>(opBuilder.build());
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Shape operation to the graph, using default output types.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @return a new instance of Shape
+   */
+  public static <T> Shape<Integer> create(Scope scope, Operand<T> input) {
+    return create(scope, input, Integer.class);
+  }
+  
+  /**
+   */
+  public Output<U> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<U> asOutput() {
+    return output;
+  }
+  
+  private Output<U> output;
+  
+  private Shape(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ShapeN.java java-ops/org/tensorflow/op/core/ShapeN.java
--- java/org/tensorflow/op/core/ShapeN.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ShapeN.java	2018-10-16 20:18:38.511432185 +0900
@@ -0,0 +1,90 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.Iterator;
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns shape of tensors.
+ * <p>
+ * This operation returns N 1-D integer tensors representing shape of `input[i]s`.
+ * 
+ * @param <U> data type for {@code output()} output
+ */
+@Operator
+public final class ShapeN<U extends Number> extends PrimitiveOp implements Iterable<Operand<U>> {
+  
+  /**
+   * Factory method to create a class to wrap a new ShapeN operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param outType 
+   * @return a new instance of ShapeN
+   */
+  public static <U extends Number, T> ShapeN<U> create(Scope scope, Operand<T> input, Class<U> outType) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ShapeN", scope.makeOpName("ShapeN"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.setAttr("out_type", DataType.fromClass(outType));
+    return new ShapeN<U>(opBuilder.build());
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ShapeN operation to the graph, using default output types.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @return a new instance of ShapeN
+   */
+  public static <T> ShapeN<Integer> create(Scope scope, Operand<T> input) {
+    return create(scope, input, Integer.class);
+  }
+  
+  /**
+   */
+  public List<Output<U>> output() {
+    return output;
+  }
+  
+  @Override
+  @SuppressWarnings({"rawtypes", "unchecked"})
+  public Iterator<Operand<U>> iterator() {
+    return (Iterator) output.iterator();
+  }
+  
+  private List<Output<U>> output;
+  
+  @SuppressWarnings("unchecked")
+  private ShapeN(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    int outputLength = operation.outputListLength("output");
+    output = Arrays.asList((Output<U>[])operation.outputList(outputIdx, outputLength));
+    outputIdx += outputLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/ShardedFilename.java java-ops/org/tensorflow/op/core/ShardedFilename.java
--- java/org/tensorflow/op/core/ShardedFilename.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ShardedFilename.java	2018-10-16 20:18:38.512432184 +0900
@@ -0,0 +1,71 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Generate a sharded filename. The filename is printf formatted as
+ * <p>
+ *    %s-%05d-of-%05d, basename, shard, num_shards.
+ */
+@Operator
+public final class ShardedFilename extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Factory method to create a class to wrap a new ShardedFilename operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param basename 
+   * @param shard 
+   * @param numShards 
+   * @return a new instance of ShardedFilename
+   */
+  public static ShardedFilename create(Scope scope, Operand<String> basename, Operand<Integer> shard, Operand<Integer> numShards) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ShardedFilename", scope.makeOpName("ShardedFilename"));
+    opBuilder.addInput(basename.asOutput());
+    opBuilder.addInput(shard.asOutput());
+    opBuilder.addInput(numShards.asOutput());
+    return new ShardedFilename(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<String> filename() {
+    return filename;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return filename;
+  }
+  
+  private Output<String> filename;
+  
+  private ShardedFilename(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    filename = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ShardedFilespec.java java-ops/org/tensorflow/op/core/ShardedFilespec.java
--- java/org/tensorflow/op/core/ShardedFilespec.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ShardedFilespec.java	2018-10-16 20:18:38.512432184 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Generate a glob pattern matching all sharded file names.
+ */
+@Operator
+public final class ShardedFilespec extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Factory method to create a class to wrap a new ShardedFilespec operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param basename 
+   * @param numShards 
+   * @return a new instance of ShardedFilespec
+   */
+  public static ShardedFilespec create(Scope scope, Operand<String> basename, Operand<Integer> numShards) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ShardedFilespec", scope.makeOpName("ShardedFilespec"));
+    opBuilder.addInput(basename.asOutput());
+    opBuilder.addInput(numShards.asOutput());
+    return new ShardedFilespec(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<String> filename() {
+    return filename;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return filename;
+  }
+  
+  private Output<String> filename;
+  
+  private ShardedFilespec(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    filename = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ShuffleAndRepeatDataset.java java-ops/org/tensorflow/op/core/ShuffleAndRepeatDataset.java
--- java/org/tensorflow/op/core/ShuffleAndRepeatDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ShuffleAndRepeatDataset.java	2018-10-16 20:18:38.513432184 +0900
@@ -0,0 +1,96 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Creates a dataset that shuffles and repeats elements from `input_dataset`
+ * <p>
+ * pseudorandomly.
+ */
+@Operator
+public final class ShuffleAndRepeatDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new ShuffleAndRepeatDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputDataset 
+   * @param bufferSize The number of output elements to buffer in an iterator over
+   * this dataset. Compare with the `min_after_dequeue` attr when creating a
+   * `RandomShuffleQueue`.
+   * @param seed A scalar seed for the random number generator. If either `seed` or
+   * `seed2` is set to be non-zero, the random number generator is seeded
+   * by the given seed.  Otherwise, a random seed is used.
+   * @param seed2 A second scalar seed to avoid seed collision.
+   * @param count A scalar representing the number of times the underlying dataset
+   * should be repeated. The default is `-1`, which results in infinite repetition.
+   * @param outputTypes 
+   * @param outputShapes 
+   * @return a new instance of ShuffleAndRepeatDataset
+   */
+  public static ShuffleAndRepeatDataset create(Scope scope, Operand<?> inputDataset, Operand<Long> bufferSize, Operand<Long> seed, Operand<Long> seed2, Operand<Long> count, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ShuffleAndRepeatDataset", scope.makeOpName("ShuffleAndRepeatDataset"));
+    opBuilder.addInput(inputDataset.asOutput());
+    opBuilder.addInput(bufferSize.asOutput());
+    opBuilder.addInput(seed.asOutput());
+    opBuilder.addInput(seed2.asOutput());
+    opBuilder.addInput(count.asOutput());
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new ShuffleAndRepeatDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private ShuffleAndRepeatDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ShuffleDataset.java java-ops/org/tensorflow/op/core/ShuffleDataset.java
--- java/org/tensorflow/op/core/ShuffleDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ShuffleDataset.java	2018-10-16 20:18:38.514432183 +0900
@@ -0,0 +1,133 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Creates a dataset that shuffles elements from `input_dataset` pseudorandomly.
+ */
+@Operator
+public final class ShuffleDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.ShuffleDataset}
+   */
+  public static class Options {
+    
+    /**
+     * @param reshuffleEachIteration If true, each iterator over this dataset will be given
+     * a different pseudorandomly generated seed, based on a sequence seeded by the
+     * `seed` and `seed2` inputs. If false, each iterator will be given the same
+     * seed, and repeated iteration over this dataset will yield the exact same
+     * sequence of results.
+     */
+    public Options reshuffleEachIteration(Boolean reshuffleEachIteration) {
+      this.reshuffleEachIteration = reshuffleEachIteration;
+      return this;
+    }
+    
+    private Boolean reshuffleEachIteration;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new ShuffleDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputDataset 
+   * @param bufferSize The number of output elements to buffer in an iterator over
+   * this dataset. Compare with the `min_after_dequeue` attr when creating a
+   * `RandomShuffleQueue`.
+   * @param seed A scalar seed for the random number generator. If either `seed` or
+   * `seed2` is set to be non-zero, the random number generator is seeded
+   * by the given seed.  Otherwise, a random seed is used.
+   * @param seed2 A second scalar seed to avoid seed collision.
+   * @param outputTypes 
+   * @param outputShapes 
+   * @param options carries optional attributes values
+   * @return a new instance of ShuffleDataset
+   */
+  public static ShuffleDataset create(Scope scope, Operand<?> inputDataset, Operand<Long> bufferSize, Operand<Long> seed, Operand<Long> seed2, List<Class<?>> outputTypes, List<Shape> outputShapes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ShuffleDataset", scope.makeOpName("ShuffleDataset"));
+    opBuilder.addInput(inputDataset.asOutput());
+    opBuilder.addInput(bufferSize.asOutput());
+    opBuilder.addInput(seed.asOutput());
+    opBuilder.addInput(seed2.asOutput());
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.reshuffleEachIteration != null) {
+          opBuilder.setAttr("reshuffle_each_iteration", opts.reshuffleEachIteration);
+        }
+      }
+    }
+    return new ShuffleDataset(opBuilder.build());
+  }
+  
+  /**
+   * @param reshuffleEachIteration If true, each iterator over this dataset will be given
+   * a different pseudorandomly generated seed, based on a sequence seeded by the
+   * `seed` and `seed2` inputs. If false, each iterator will be given the same
+   * seed, and repeated iteration over this dataset will yield the exact same
+   * sequence of results.
+   */
+  public static Options reshuffleEachIteration(Boolean reshuffleEachIteration) {
+    return new Options().reshuffleEachIteration(reshuffleEachIteration);
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private ShuffleDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SigmoidGrad.java java-ops/org/tensorflow/op/core/SigmoidGrad.java
--- java/org/tensorflow/op/core/SigmoidGrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SigmoidGrad.java	2018-10-16 20:18:38.515432182 +0900
@@ -0,0 +1,70 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Computes the gradient of the sigmoid of `x` wrt its input.
+ * <p>
+ * Specifically, `grad = dy * y * (1 - y)`, where `y = sigmoid(x)`, and
+ * `dy` is the corresponding input gradient.
+ * 
+ * @param <T> data type for {@code z()} output
+ */
+public final class SigmoidGrad<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new SigmoidGrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param y 
+   * @param dy 
+   * @return a new instance of SigmoidGrad
+   */
+  public static <T> SigmoidGrad<T> create(Scope scope, Operand<T> y, Operand<T> dy) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SigmoidGrad", scope.makeOpName("SigmoidGrad"));
+    opBuilder.addInput(y.asOutput());
+    opBuilder.addInput(dy.asOutput());
+    return new SigmoidGrad<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return z;
+  }
+  
+  private Output<T> z;
+  
+  private SigmoidGrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Sigmoid.java java-ops/org/tensorflow/op/core/Sigmoid.java
--- java/org/tensorflow/op/core/Sigmoid.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Sigmoid.java	2018-10-16 20:18:38.515432182 +0900
@@ -0,0 +1,69 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes sigmoid of `x` element-wise.
+ * <p>
+ * Specifically, `y = 1 / (1 + exp(-x))`.
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class Sigmoid<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Sigmoid operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of Sigmoid
+   */
+  public static <T> Sigmoid<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Sigmoid", scope.makeOpName("Sigmoid"));
+    opBuilder.addInput(x.asOutput());
+    return new Sigmoid<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private Sigmoid(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Sign.java java-ops/org/tensorflow/op/core/Sign.java
--- java/org/tensorflow/op/core/Sign.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Sign.java	2018-10-16 20:18:38.516432182 +0900
@@ -0,0 +1,71 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns an element-wise indication of the sign of a number.
+ * <p>
+ * `y = sign(x) = -1` if `x < 0`; 0 if `x == 0`; 1 if `x > 0`.
+ * <p>
+ * For complex numbers, `y = sign(x) = x / |x|` if `x != 0`, otherwise `y = 0`.
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class Sign<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Sign operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of Sign
+   */
+  public static <T> Sign<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Sign", scope.makeOpName("Sign"));
+    opBuilder.addInput(x.asOutput());
+    return new Sign<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private Sign(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Sinh.java java-ops/org/tensorflow/op/core/Sinh.java
--- java/org/tensorflow/op/core/Sinh.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Sinh.java	2018-10-16 20:18:38.518432180 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes hyperbolic sine of x element-wise.
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class Sinh<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Sinh operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of Sinh
+   */
+  public static <T> Sinh<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Sinh", scope.makeOpName("Sinh"));
+    opBuilder.addInput(x.asOutput());
+    return new Sinh<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private Sinh(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Sin.java java-ops/org/tensorflow/op/core/Sin.java
--- java/org/tensorflow/op/core/Sin.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Sin.java	2018-10-16 20:18:38.517432181 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes sin of x element-wise.
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class Sin<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Sin operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of Sin
+   */
+  public static <T> Sin<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Sin", scope.makeOpName("Sin"));
+    opBuilder.addInput(x.asOutput());
+    return new Sin<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private Sin(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SinkDataset.java java-ops/org/tensorflow/op/core/SinkDataset.java
--- java/org/tensorflow/op/core/SinkDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SinkDataset.java	2018-10-16 20:18:38.518432180 +0900
@@ -0,0 +1,66 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * A placeholder for input pipeline graph optimizations.
+ * <p>
+ * A placeholder for input pipeline graph optimizations.
+ */
+public final class SinkDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new SinkDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputDataset A variant tensor representing the input dataset.
+   * @return a new instance of SinkDataset
+   */
+  public static SinkDataset create(Scope scope, Operand<?> inputDataset) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SinkDataset", scope.makeOpName("SinkDataset"));
+    opBuilder.addInput(inputDataset.asOutput());
+    return new SinkDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private SinkDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Size.java java-ops/org/tensorflow/op/core/Size.java
--- java/org/tensorflow/op/core/Size.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Size.java	2018-10-16 20:18:38.518432180 +0900
@@ -0,0 +1,91 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns the size of a tensor.
+ * <p>
+ * This operation returns an integer representing the number of elements in
+ * `input`.
+ * <p>
+ * For example:
+ * <pre>{@code
+ * # 't' is [[[1, 1,, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]]]
+ * size(t) ==> 12
+ * }</pre>
+ * 
+ * 
+ * @param <U> data type for {@code output()} output
+ */
+@Operator
+public final class Size<U extends Number> extends PrimitiveOp implements Operand<U> {
+  
+  /**
+   * Factory method to create a class to wrap a new Size operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param outType 
+   * @return a new instance of Size
+   */
+  public static <U extends Number, T> Size<U> create(Scope scope, Operand<T> input, Class<U> outType) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Size", scope.makeOpName("Size"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.setAttr("out_type", DataType.fromClass(outType));
+    return new Size<U>(opBuilder.build());
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Size operation to the graph, using default output types.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @return a new instance of Size
+   */
+  public static <T> Size<Integer> create(Scope scope, Operand<T> input) {
+    return create(scope, input, Integer.class);
+  }
+  
+  /**
+   */
+  public Output<U> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<U> asOutput() {
+    return output;
+  }
+  
+  private Output<U> output;
+  
+  private Size(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SkipDataset.java java-ops/org/tensorflow/op/core/SkipDataset.java
--- java/org/tensorflow/op/core/SkipDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SkipDataset.java	2018-10-16 20:18:38.519432179 +0900
@@ -0,0 +1,84 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Creates a dataset that skips `count` elements from the `input_dataset`.
+ */
+@Operator
+public final class SkipDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new SkipDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputDataset 
+   * @param count A scalar representing the number of elements from the `input_dataset`
+   * that should be skipped.  If count is -1, skips everything.
+   * @param outputTypes 
+   * @param outputShapes 
+   * @return a new instance of SkipDataset
+   */
+  public static SkipDataset create(Scope scope, Operand<?> inputDataset, Operand<Long> count, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SkipDataset", scope.makeOpName("SkipDataset"));
+    opBuilder.addInput(inputDataset.asOutput());
+    opBuilder.addInput(count.asOutput());
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new SkipDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private SkipDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Skipgram.java java-ops/org/tensorflow/op/core/Skipgram.java
--- java/org/tensorflow/op/core/Skipgram.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Skipgram.java	2018-10-16 20:18:38.519432179 +0900
@@ -0,0 +1,192 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Parses a text file and creates a batch of examples.
+ */
+@Operator
+public final class Skipgram extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Skipgram}
+   */
+  public static class Options {
+    
+    /**
+     * @param windowSize The number of words to predict to the left and right of the target.
+     */
+    public Options windowSize(Long windowSize) {
+      this.windowSize = windowSize;
+      return this;
+    }
+    
+    /**
+     * @param minCount The minimum number of word occurrences for it to be included in the
+     * vocabulary.
+     */
+    public Options minCount(Long minCount) {
+      this.minCount = minCount;
+      return this;
+    }
+    
+    /**
+     * @param subsample Threshold for word occurrence. Words that appear with higher
+     * frequency will be randomly down-sampled. Set to 0 to disable.
+     */
+    public Options subsample(Float subsample) {
+      this.subsample = subsample;
+      return this;
+    }
+    
+    private Long windowSize;
+    private Long minCount;
+    private Float subsample;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Skipgram operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param filename The corpus's text file name.
+   * @param batchSize The size of produced batch.
+   * @param options carries optional attributes values
+   * @return a new instance of Skipgram
+   */
+  public static Skipgram create(Scope scope, String filename, Long batchSize, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Skipgram", scope.makeOpName("Skipgram"));
+    opBuilder.setAttr("filename", filename);
+    opBuilder.setAttr("batch_size", batchSize);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.windowSize != null) {
+          opBuilder.setAttr("window_size", opts.windowSize);
+        }
+        if (opts.minCount != null) {
+          opBuilder.setAttr("min_count", opts.minCount);
+        }
+        if (opts.subsample != null) {
+          opBuilder.setAttr("subsample", opts.subsample);
+        }
+      }
+    }
+    return new Skipgram(opBuilder.build());
+  }
+  
+  /**
+   * @param windowSize The number of words to predict to the left and right of the target.
+   */
+  public static Options windowSize(Long windowSize) {
+    return new Options().windowSize(windowSize);
+  }
+  
+  /**
+   * @param minCount The minimum number of word occurrences for it to be included in the
+   * vocabulary.
+   */
+  public static Options minCount(Long minCount) {
+    return new Options().minCount(minCount);
+  }
+  
+  /**
+   * @param subsample Threshold for word occurrence. Words that appear with higher
+   * frequency will be randomly down-sampled. Set to 0 to disable.
+   */
+  public static Options subsample(Float subsample) {
+    return new Options().subsample(subsample);
+  }
+  
+  /**
+   * A vector of words in the corpus.
+   */
+  public Output<String> vocabWord() {
+    return vocabWord;
+  }
+  
+  /**
+   * Frequencies of words. Sorted in the non-ascending order.
+   */
+  public Output<Integer> vocabFreq() {
+    return vocabFreq;
+  }
+  
+  /**
+   * Number of words per epoch in the data file.
+   */
+  public Output<Long> wordsPerEpoch() {
+    return wordsPerEpoch;
+  }
+  
+  /**
+   * The current epoch number.
+   */
+  public Output<Integer> currentEpoch() {
+    return currentEpoch;
+  }
+  
+  /**
+   * The total number of words processed so far.
+   */
+  public Output<Long> totalWordsProcessed() {
+    return totalWordsProcessed;
+  }
+  
+  /**
+   * A vector of word ids.
+   */
+  public Output<Integer> examples() {
+    return examples;
+  }
+  
+  /**
+   * A vector of word ids.
+   */
+  public Output<Integer> labels() {
+    return labels;
+  }
+  
+  private Output<String> vocabWord;
+  private Output<Integer> vocabFreq;
+  private Output<Long> wordsPerEpoch;
+  private Output<Integer> currentEpoch;
+  private Output<Long> totalWordsProcessed;
+  private Output<Integer> examples;
+  private Output<Integer> labels;
+  
+  private Skipgram(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    vocabWord = operation.output(outputIdx++);
+    vocabFreq = operation.output(outputIdx++);
+    wordsPerEpoch = operation.output(outputIdx++);
+    currentEpoch = operation.output(outputIdx++);
+    totalWordsProcessed = operation.output(outputIdx++);
+    examples = operation.output(outputIdx++);
+    labels = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Slice.java java-ops/org/tensorflow/op/core/Slice.java
--- java/org/tensorflow/op/core/Slice.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Slice.java	2018-10-16 20:18:38.520432179 +0900
@@ -0,0 +1,82 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Return a slice from 'input'.
+ * <p>
+ * The output tensor is a tensor with dimensions described by 'size'
+ * whose values are extracted from 'input' starting at the offsets in
+ * 'begin'.
+ * <p>
+ * <i>Requirements</i>:
+ *   0 <= begin[i] <= begin[i] + size[i] <= Di  for i in [0, n)
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class Slice<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Slice operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param begin begin[i] specifies the offset into the 'i'th dimension of
+   * 'input' to slice from.
+   * @param size size[i] specifies the number of elements of the 'i'th dimension
+   * of 'input' to slice. If size[i] is -1, all remaining elements in dimension
+   * i are included in the slice (i.e. this is equivalent to setting
+   * size[i] = input.dim_size(i) - begin[i]).
+   * @return a new instance of Slice
+   */
+  public static <T, U extends Number> Slice<T> create(Scope scope, Operand<T> input, Operand<U> begin, Operand<U> size) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Slice", scope.makeOpName("Slice"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(begin.asOutput());
+    opBuilder.addInput(size.asOutput());
+    return new Slice<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private Slice(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SlideDataset.java java-ops/org/tensorflow/op/core/SlideDataset.java
--- java/org/tensorflow/op/core/SlideDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SlideDataset.java	2018-10-16 20:18:38.521432178 +0900
@@ -0,0 +1,90 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Creates a dataset that passes a sliding window over `input_dataset`.
+ */
+@Operator
+public final class SlideDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new SlideDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputDataset 
+   * @param windowSize A scalar representing the number of elements in the
+   * sliding window.
+   * @param windowShift A scalar representing the steps moving the sliding window
+   * forward in one iteration. It must be positive.
+   * @param windowStride A scalar representing the stride of the input elements of the sliding window.
+   * It must be positive.
+   * @param outputTypes 
+   * @param outputShapes 
+   * @return a new instance of SlideDataset
+   */
+  public static SlideDataset create(Scope scope, Operand<?> inputDataset, Operand<Long> windowSize, Operand<Long> windowShift, Operand<Long> windowStride, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SlideDataset", scope.makeOpName("SlideDataset"));
+    opBuilder.addInput(inputDataset.asOutput());
+    opBuilder.addInput(windowSize.asOutput());
+    opBuilder.addInput(windowShift.asOutput());
+    opBuilder.addInput(windowStride.asOutput());
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new SlideDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private SlideDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Snapshot.java java-ops/org/tensorflow/op/core/Snapshot.java
--- java/org/tensorflow/op/core/Snapshot.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Snapshot.java	2018-10-16 20:18:38.521432178 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns a copy of the input tensor.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class Snapshot<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Snapshot operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @return a new instance of Snapshot
+   */
+  public static <T> Snapshot<T> create(Scope scope, Operand<T> input) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Snapshot", scope.makeOpName("Snapshot"));
+    opBuilder.addInput(input.asOutput());
+    return new Snapshot<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private Snapshot(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SoftmaxCrossEntropyWithLogits.java java-ops/org/tensorflow/op/core/SoftmaxCrossEntropyWithLogits.java
--- java/org/tensorflow/op/core/SoftmaxCrossEntropyWithLogits.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SoftmaxCrossEntropyWithLogits.java	2018-10-16 20:18:38.521432178 +0900
@@ -0,0 +1,78 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes softmax cross entropy cost and gradients to backpropagate.
+ * <p>
+ * Inputs are the logits, not probabilities.
+ * 
+ * @param <T> data type for {@code loss()} output
+ */
+@Operator
+public final class SoftmaxCrossEntropyWithLogits<T extends Number> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new SoftmaxCrossEntropyWithLogits operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param features batch_size x num_classes matrix
+   * @param labels batch_size x num_classes matrix
+   * The caller must ensure that each batch of labels represents a valid
+   * probability distribution.
+   * @return a new instance of SoftmaxCrossEntropyWithLogits
+   */
+  public static <T extends Number> SoftmaxCrossEntropyWithLogits<T> create(Scope scope, Operand<T> features, Operand<T> labels) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SoftmaxCrossEntropyWithLogits", scope.makeOpName("SoftmaxCrossEntropyWithLogits"));
+    opBuilder.addInput(features.asOutput());
+    opBuilder.addInput(labels.asOutput());
+    return new SoftmaxCrossEntropyWithLogits<T>(opBuilder.build());
+  }
+  
+  /**
+   * Per example loss (batch_size vector).
+   */
+  public Output<T> loss() {
+    return loss;
+  }
+  
+  /**
+   * backpropagated gradients (batch_size x num_classes matrix).
+   */
+  public Output<T> backprop() {
+    return backprop;
+  }
+  
+  private Output<T> loss;
+  private Output<T> backprop;
+  
+  private SoftmaxCrossEntropyWithLogits(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    loss = operation.output(outputIdx++);
+    backprop = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Softmax.java java-ops/org/tensorflow/op/core/Softmax.java
--- java/org/tensorflow/op/core/Softmax.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Softmax.java	2018-10-16 20:18:38.521432178 +0900
@@ -0,0 +1,72 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes softmax activations.
+ * <p>
+ * For each batch `i` and class `j` we have
+ * <p>
+ *     $$softmax[i, j] = exp(logits[i, j]) / sum_j(exp(logits[i, j]))$$
+ * 
+ * @param <T> data type for {@code softmax()} output
+ */
+@Operator
+public final class Softmax<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Softmax operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param logits 2-D with shape `[batch_size, num_classes]`.
+   * @return a new instance of Softmax
+   */
+  public static <T extends Number> Softmax<T> create(Scope scope, Operand<T> logits) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Softmax", scope.makeOpName("Softmax"));
+    opBuilder.addInput(logits.asOutput());
+    return new Softmax<T>(opBuilder.build());
+  }
+  
+  /**
+   * Same shape as `logits`.
+   */
+  public Output<T> softmax() {
+    return softmax;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return softmax;
+  }
+  
+  private Output<T> softmax;
+  
+  private Softmax(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    softmax = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SoftplusGrad.java java-ops/org/tensorflow/op/core/SoftplusGrad.java
--- java/org/tensorflow/op/core/SoftplusGrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SoftplusGrad.java	2018-10-16 20:18:38.522432177 +0900
@@ -0,0 +1,68 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Computes softplus gradients for a softplus operation.
+ * 
+ * @param <T> data type for {@code backprops()} output
+ */
+public final class SoftplusGrad<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new SoftplusGrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param gradients The backpropagated gradients to the corresponding softplus operation.
+   * @param features The features passed as input to the corresponding softplus operation.
+   * @return a new instance of SoftplusGrad
+   */
+  public static <T extends Number> SoftplusGrad<T> create(Scope scope, Operand<T> gradients, Operand<T> features) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SoftplusGrad", scope.makeOpName("SoftplusGrad"));
+    opBuilder.addInput(gradients.asOutput());
+    opBuilder.addInput(features.asOutput());
+    return new SoftplusGrad<T>(opBuilder.build());
+  }
+  
+  /**
+   * The gradients: `gradients / (1 + exp(-features))`.
+   */
+  public Output<T> backprops() {
+    return backprops;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return backprops;
+  }
+  
+  private Output<T> backprops;
+  
+  private SoftplusGrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    backprops = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Softplus.java java-ops/org/tensorflow/op/core/Softplus.java
--- java/org/tensorflow/op/core/Softplus.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Softplus.java	2018-10-16 20:18:38.522432177 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes softplus: `log(exp(features) + 1)`.
+ * 
+ * @param <T> data type for {@code activations()} output
+ */
+@Operator
+public final class Softplus<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Softplus operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param features 
+   * @return a new instance of Softplus
+   */
+  public static <T extends Number> Softplus<T> create(Scope scope, Operand<T> features) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Softplus", scope.makeOpName("Softplus"));
+    opBuilder.addInput(features.asOutput());
+    return new Softplus<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> activations() {
+    return activations;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return activations;
+  }
+  
+  private Output<T> activations;
+  
+  private Softplus(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    activations = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SoftsignGrad.java java-ops/org/tensorflow/op/core/SoftsignGrad.java
--- java/org/tensorflow/op/core/SoftsignGrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SoftsignGrad.java	2018-10-16 20:18:38.523432177 +0900
@@ -0,0 +1,68 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Computes softsign gradients for a softsign operation.
+ * 
+ * @param <T> data type for {@code backprops()} output
+ */
+public final class SoftsignGrad<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new SoftsignGrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param gradients The backpropagated gradients to the corresponding softsign operation.
+   * @param features The features passed as input to the corresponding softsign operation.
+   * @return a new instance of SoftsignGrad
+   */
+  public static <T extends Number> SoftsignGrad<T> create(Scope scope, Operand<T> gradients, Operand<T> features) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SoftsignGrad", scope.makeOpName("SoftsignGrad"));
+    opBuilder.addInput(gradients.asOutput());
+    opBuilder.addInput(features.asOutput());
+    return new SoftsignGrad<T>(opBuilder.build());
+  }
+  
+  /**
+   * The gradients: `gradients / (1 + abs(features)) ** 2`.
+   */
+  public Output<T> backprops() {
+    return backprops;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return backprops;
+  }
+  
+  private Output<T> backprops;
+  
+  private SoftsignGrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    backprops = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Softsign.java java-ops/org/tensorflow/op/core/Softsign.java
--- java/org/tensorflow/op/core/Softsign.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Softsign.java	2018-10-16 20:18:38.522432177 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes softsign: `features / (abs(features) + 1)`.
+ * 
+ * @param <T> data type for {@code activations()} output
+ */
+@Operator
+public final class Softsign<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Softsign operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param features 
+   * @return a new instance of Softsign
+   */
+  public static <T extends Number> Softsign<T> create(Scope scope, Operand<T> features) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Softsign", scope.makeOpName("Softsign"));
+    opBuilder.addInput(features.asOutput());
+    return new Softsign<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> activations() {
+    return activations;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return activations;
+  }
+  
+  private Output<T> activations;
+  
+  private Softsign(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    activations = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SpaceToBatch.java java-ops/org/tensorflow/op/core/SpaceToBatch.java
--- java/org/tensorflow/op/core/SpaceToBatch.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SpaceToBatch.java	2018-10-16 20:18:38.524432176 +0900
@@ -0,0 +1,147 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * SpaceToBatch for 4-D tensors of type T.
+ * <p>
+ * This is a legacy version of the more general SpaceToBatchND.
+ * <p>
+ * Zero-pads and then rearranges (permutes) blocks of spatial data into batch.
+ * More specifically, this op outputs a copy of the input tensor where values from
+ * the `height` and `width` dimensions are moved to the `batch` dimension. After
+ * the zero-padding, both `height` and `width` of the input must be divisible by the
+ * block size.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class SpaceToBatch<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new SpaceToBatch operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 4-D with shape `[batch, height, width, depth]`.
+   * @param paddings 2-D tensor of non-negative integers with shape `[2, 2]`. It specifies
+   *   the padding of the input with zeros across the spatial dimensions as follows:
+   * <p>
+   *       paddings = [[pad_top, pad_bottom], [pad_left, pad_right]]
+   * <p>
+   *   The effective spatial dimensions of the zero-padded input tensor will be:
+   * <p>
+   *       height_pad = pad_top + height + pad_bottom
+   *       width_pad = pad_left + width + pad_right
+   * <p>
+   * The attr `block_size` must be greater than one. It indicates the block size.
+   * <p>
+   *   * Non-overlapping blocks of size `block_size x block size` in the height and
+   *     width dimensions are rearranged into the batch dimension at each location.
+   *   * The batch of the output tensor is `batch * block_size * block_size`.
+   *   * Both height_pad and width_pad must be divisible by block_size.
+   * <p>
+   * The shape of the output will be:
+   * <p>
+   *     [batch<i>block_size</i>block_size, height_pad/block_size, width_pad/block_size,
+   *      depth]
+   * <p>
+   * Some examples:
+   * <p>
+   * (1) For the following input of shape `[1, 2, 2, 1]` and block_size of 2:
+   * <pre>{@code
+   * x = [[[[1], [2]], [[3], [4]]]]
+   * }</pre>
+   * The output tensor has shape `[4, 1, 1, 1]` and value:
+   * <pre>{@code
+   * [[[[1]]], [[[2]]], [[[3]]], [[[4]]]]
+   * }</pre>
+   * (2) For the following input of shape `[1, 2, 2, 3]` and block_size of 2:
+   * <pre>{@code
+   * x = [[[[1, 2, 3], [4, 5, 6]],
+   *       [[7, 8, 9], [10, 11, 12]]]]
+   * }</pre>
+   * The output tensor has shape `[4, 1, 1, 3]` and value:
+   * <pre>{@code
+   * [[[1, 2, 3]], [[4, 5, 6]], [[7, 8, 9]], [[10, 11, 12]]]
+   * }</pre>
+   * (3) For the following input of shape `[1, 4, 4, 1]` and block_size of 2:
+   * <pre>{@code
+   * x = [[[[1],   [2],  [3],  [4]],
+   *       [[5],   [6],  [7],  [8]],
+   *       [[9],  [10], [11],  [12]],
+   *       [[13], [14], [15],  [16]]]]
+   * }</pre>
+   * The output tensor has shape `[4, 2, 2, 1]` and value:
+   * <pre>{@code
+   * x = [[[[1], [3]], [[9], [11]]],
+   *      [[[2], [4]], [[10], [12]]],
+   *      [[[5], [7]], [[13], [15]]],
+   *      [[[6], [8]], [[14], [16]]]]
+   * }</pre>
+   * (4) For the following input of shape `[2, 2, 4, 1]` and block_size of 2:
+   * <pre>{@code
+   * x = [[[[1],   [2],  [3],  [4]],
+   *       [[5],   [6],  [7],  [8]]],
+   *      [[[9],  [10], [11],  [12]],
+   *       [[13], [14], [15],  [16]]]]
+   * }</pre>
+   * The output tensor has shape `[8, 1, 2, 1]` and value:
+   * <pre>{@code
+   * x = [[[[1], [3]]], [[[9], [11]]], [[[2], [4]]], [[[10], [12]]],
+   *      [[[5], [7]]], [[[13], [15]]], [[[6], [8]]], [[[14], [16]]]]
+   * }</pre>
+   * Among others, this operation is useful for reducing atrous convolution into
+   * regular convolution.
+   * @param blockSize 
+   * @return a new instance of SpaceToBatch
+   */
+  public static <T, U extends Number> SpaceToBatch<T> create(Scope scope, Operand<T> input, Operand<U> paddings, Long blockSize) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SpaceToBatch", scope.makeOpName("SpaceToBatch"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(paddings.asOutput());
+    opBuilder.setAttr("block_size", blockSize);
+    return new SpaceToBatch<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private SpaceToBatch(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SpaceToBatchND.java java-ops/org/tensorflow/op/core/SpaceToBatchND.java
--- java/org/tensorflow/op/core/SpaceToBatchND.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SpaceToBatchND.java	2018-10-16 20:18:38.526432175 +0900
@@ -0,0 +1,172 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * SpaceToBatch for N-D tensors of type T.
+ * <p>
+ * This operation divides "spatial" dimensions `[1, ..., M]` of the input into a
+ * grid of blocks of shape `block_shape`, and interleaves these blocks with the
+ * "batch" dimension (0) such that in the output, the spatial dimensions
+ * `[1, ..., M]` correspond to the position within the grid, and the batch
+ * dimension combines both the position within a spatial block and the original
+ * batch position.  Prior to division into blocks, the spatial dimensions of the
+ * input are optionally zero padded according to `paddings`.  See below for a
+ * precise description.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class SpaceToBatchND<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new SpaceToBatchND operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input N-D with shape `input_shape = [batch] + spatial_shape + remaining_shape`,
+   * where spatial_shape has `M` dimensions.
+   * @param blockShape 1-D with shape `[M]`, all values must be >= 1.
+   * @param paddings 2-D with shape `[M, 2]`, all values must be >= 0.
+   *   `paddings[i] = [pad_start, pad_end]` specifies the padding for input dimension
+   *   `i + 1`, which corresponds to spatial dimension `i`.  It is required that
+   *   `block_shape[i]` divides `input_shape[i + 1] + pad_start + pad_end`.
+   * <p>
+   * This operation is equivalent to the following steps:
+   * <p>
+   * 1. Zero-pad the start and end of dimensions `[1, ..., M]` of the
+   *    input according to `paddings` to produce `padded` of shape `padded_shape`.
+   * <p>
+   * 2. Reshape `padded` to `reshaped_padded` of shape:
+   * <p>
+   *      [batch] +
+   *      [padded_shape[1] / block_shape[0],
+   *        block_shape[0],
+   *       ...,
+   *       padded_shape[M] / block_shape[M-1],
+   *       block_shape[M-1]] +
+   *      remaining_shape
+   * <p>
+   * 3. Permute dimensions of `reshaped_padded` to produce
+   *    `permuted_reshaped_padded` of shape:
+   * <p>
+   *      block_shape +
+   *      [batch] +
+   *      [padded_shape[1] / block_shape[0],
+   *       ...,
+   *       padded_shape[M] / block_shape[M-1]] +
+   *      remaining_shape
+   * <p>
+   * 4. Reshape `permuted_reshaped_padded` to flatten `block_shape` into the batch
+   *    dimension, producing an output tensor of shape:
+   * <p>
+   *      [batch * prod(block_shape)] +
+   *      [padded_shape[1] / block_shape[0],
+   *       ...,
+   *       padded_shape[M] / block_shape[M-1]] +
+   *      remaining_shape
+   * <p>
+   * Some examples:
+   * <p>
+   * (1) For the following input of shape `[1, 2, 2, 1]`, `block_shape = [2, 2]`, and
+   *     `paddings = [[0, 0], [0, 0]]`:
+   * <pre>{@code
+   * x = [[[[1], [2]], [[3], [4]]]]
+   * }</pre>
+   * The output tensor has shape `[4, 1, 1, 1]` and value:
+   * <pre>{@code
+   * [[[[1]]], [[[2]]], [[[3]]], [[[4]]]]
+   * }</pre>
+   * (2) For the following input of shape `[1, 2, 2, 3]`, `block_shape = [2, 2]`, and
+   *     `paddings = [[0, 0], [0, 0]]`:
+   * <pre>{@code
+   * x = [[[[1, 2, 3], [4, 5, 6]],
+   *       [[7, 8, 9], [10, 11, 12]]]]
+   * }</pre>
+   * The output tensor has shape `[4, 1, 1, 3]` and value:
+   * <pre>{@code
+   * [[[1, 2, 3]], [[4, 5, 6]], [[7, 8, 9]], [[10, 11, 12]]]
+   * }</pre>
+   * (3) For the following input of shape `[1, 4, 4, 1]`, `block_shape = [2, 2]`, and
+   *     `paddings = [[0, 0], [0, 0]]`:
+   * <pre>{@code
+   * x = [[[[1],   [2],  [3],  [4]],
+   *       [[5],   [6],  [7],  [8]],
+   *       [[9],  [10], [11],  [12]],
+   *       [[13], [14], [15],  [16]]]]
+   * }</pre>
+   * The output tensor has shape `[4, 2, 2, 1]` and value:
+   * <pre>{@code
+   * x = [[[[1], [3]], [[9], [11]]],
+   *      [[[2], [4]], [[10], [12]]],
+   *      [[[5], [7]], [[13], [15]]],
+   *      [[[6], [8]], [[14], [16]]]]
+   * }</pre>
+   * (4) For the following input of shape `[2, 2, 4, 1]`, block_shape = `[2, 2]`, and
+   *     paddings = `[[0, 0], [2, 0]]`:
+   * <pre>{@code
+   * x = [[[[1],   [2],  [3],  [4]],
+   *       [[5],   [6],  [7],  [8]]],
+   *      [[[9],  [10], [11],  [12]],
+   *       [[13], [14], [15],  [16]]]]
+   * }</pre>
+   * The output tensor has shape `[8, 1, 3, 1]` and value:
+   * <pre>{@code
+   * x = [[[[0], [1], [3]]], [[[0], [9], [11]]],
+   *      [[[0], [2], [4]]], [[[0], [10], [12]]],
+   *      [[[0], [5], [7]]], [[[0], [13], [15]]],
+   *      [[[0], [6], [8]]], [[[0], [14], [16]]]]
+   * }</pre>
+   * Among others, this operation is useful for reducing atrous convolution into
+   * regular convolution.
+   * @return a new instance of SpaceToBatchND
+   */
+  public static <T, U extends Number, V extends Number> SpaceToBatchND<T> create(Scope scope, Operand<T> input, Operand<U> blockShape, Operand<V> paddings) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SpaceToBatchND", scope.makeOpName("SpaceToBatchND"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(blockShape.asOutput());
+    opBuilder.addInput(paddings.asOutput());
+    return new SpaceToBatchND<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private SpaceToBatchND(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SpaceToDepth.java java-ops/org/tensorflow/op/core/SpaceToDepth.java
--- java/org/tensorflow/op/core/SpaceToDepth.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SpaceToDepth.java	2018-10-16 20:18:38.528432173 +0900
@@ -0,0 +1,177 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * SpaceToDepth for tensors of type T.
+ * <p>
+ * Rearranges blocks of spatial data, into depth. More specifically,
+ * this op outputs a copy of the input tensor where values from the `height`
+ * and `width` dimensions are moved to the `depth` dimension.
+ * The attr `block_size` indicates the input block size.
+ * <p>
+ *   * Non-overlapping blocks of size `block_size x block size` are rearranged
+ *     into depth at each location.
+ *   * The depth of the output tensor is `block_size * block_size * input_depth`.
+ *   * The Y, X coordinates within each block of the input become the high order
+ *     component of the output channel index.
+ *   * The input tensor's height and width must be divisible by block_size.
+ * <p>
+ * The `data_format` attr specifies the layout of the input and output tensors
+ * with the following options:
+ *   "NHWC": `[ batch, height, width, channels ]`
+ *   "NCHW": `[ batch, channels, height, width ]`
+ *   "NCHW_VECT_C":
+ *       `qint8 [ batch, channels / 4, height, width, 4 ]`
+ * <p>
+ * It is useful to consider the operation as transforming a 6-D Tensor.
+ * e.g. for data_format = NHWC,
+ *      Each element in the input tensor can be specified via 6 coordinates,
+ *      ordered by decreasing memory layout significance as:
+ *      n,oY,bY,oX,bX,iC  (where n=batch index, oX, oY means X or Y coordinates
+ *                         within the output image, bX, bY means coordinates
+ *                         within the input block, iC means input channels).
+ *      The output would be a transpose to the following layout:
+ *      n,oY,oX,bY,bX,iC
+ * <p>
+ * This operation is useful for resizing the activations between convolutions
+ * (but keeping all data), e.g. instead of pooling. It is also useful for training
+ * purely convolutional models.
+ * <p>
+ * For example, given an input of shape `[1, 2, 2, 1]`, data_format = "NHWC" and
+ * block_size = 2:
+ * <pre>{@code
+ * x = [[[[1], [2]],
+ *       [[3], [4]]]]
+ * }</pre>
+ * This operation will output a tensor of shape `[1, 1, 1, 4]`:
+ * <pre>{@code
+ * [[[[1, 2, 3, 4]]]]
+ * }</pre>
+ * Here, the input has a batch of 1 and each batch element has shape `[2, 2, 1]`,
+ * the corresponding output will have a single element (i.e. width and height are
+ * both 1) and will have a depth of 4 channels (1 * block_size * block_size).
+ * The output element shape is `[1, 1, 4]`.
+ * <p>
+ * For an input tensor with larger depth, here of shape `[1, 2, 2, 3]`, e.g.
+ * <pre>{@code
+ * x = [[[[1, 2, 3], [4, 5, 6]],
+ *       [[7, 8, 9], [10, 11, 12]]]]
+ * }</pre>
+ * This operation, for block_size of 2, will return the following tensor of shape
+ * `[1, 1, 1, 12]`
+ * <pre>{@code
+ * [[[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]]]]
+ * }</pre>
+ * Similarly, for the following input of shape `[1 4 4 1]`, and a block size of 2:
+ * <pre>{@code
+ * x = [[[[1],   [2],  [5],  [6]],
+ *       [[3],   [4],  [7],  [8]],
+ *       [[9],  [10], [13],  [14]],
+ *       [[11], [12], [15],  [16]]]]
+ * }</pre>
+ * the operator will return the following tensor of shape `[1 2 2 4]`:
+ * <pre>{@code
+ * x = [[[[1, 2, 3, 4],
+ *        [5, 6, 7, 8]],
+ *       [[9, 10, 11, 12],
+ *        [13, 14, 15, 16]]]]
+ * }</pre>
+ * 
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class SpaceToDepth<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.SpaceToDepth}
+   */
+  public static class Options {
+    
+    /**
+     * @param dataFormat 
+     */
+    public Options dataFormat(String dataFormat) {
+      this.dataFormat = dataFormat;
+      return this;
+    }
+    
+    private String dataFormat;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new SpaceToDepth operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param blockSize The size of the spatial block.
+   * @param options carries optional attributes values
+   * @return a new instance of SpaceToDepth
+   */
+  public static <T> SpaceToDepth<T> create(Scope scope, Operand<T> input, Long blockSize, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SpaceToDepth", scope.makeOpName("SpaceToDepth"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.setAttr("block_size", blockSize);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.dataFormat != null) {
+          opBuilder.setAttr("data_format", opts.dataFormat);
+        }
+      }
+    }
+    return new SpaceToDepth<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param dataFormat 
+   */
+  public static Options dataFormat(String dataFormat) {
+    return new Options().dataFormat(dataFormat);
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private SpaceToDepth(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseAccumulatorApplyGradient.java java-ops/org/tensorflow/op/core/SparseAccumulatorApplyGradient.java
--- java/org/tensorflow/op/core/SparseAccumulatorApplyGradient.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseAccumulatorApplyGradient.java	2018-10-16 20:18:38.528432173 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Applies a sparse gradient to a given accumulator.
+ * <p>
+ * Does not add if local_step is smaller than the accumulator's
+ * global_step.
+ */
+@Operator
+public final class SparseAccumulatorApplyGradient extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new SparseAccumulatorApplyGradient operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param handle The handle to a accumulator.
+   * @param localStep The local_step value at which the sparse gradient was computed.
+   * @param gradientIndices Indices of the sparse gradient to be accumulated. Must be a
+   * vector.
+   * @param gradientValues Values are the non-zero slices of the gradient, and must have
+   * the same first dimension as indices, i.e., the nnz represented by indices and
+   * values must be consistent.
+   * @param gradientShape Shape of the sparse gradient to be accumulated.
+   * @param hasKnownShape Boolean indicating whether gradient_shape is unknown, in which
+   * case the input is ignored during validation.
+   * @return a new instance of SparseAccumulatorApplyGradient
+   */
+  public static <T> SparseAccumulatorApplyGradient create(Scope scope, Operand<String> handle, Operand<Long> localStep, Operand<Long> gradientIndices, Operand<T> gradientValues, Operand<Long> gradientShape, Boolean hasKnownShape) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseAccumulatorApplyGradient", scope.makeOpName("SparseAccumulatorApplyGradient"));
+    opBuilder.addInput(handle.asOutput());
+    opBuilder.addInput(localStep.asOutput());
+    opBuilder.addInput(gradientIndices.asOutput());
+    opBuilder.addInput(gradientValues.asOutput());
+    opBuilder.addInput(gradientShape.asOutput());
+    opBuilder.setAttr("has_known_shape", hasKnownShape);
+    return new SparseAccumulatorApplyGradient(opBuilder.build());
+  }
+  
+  
+  private SparseAccumulatorApplyGradient(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseAccumulatorTakeGradient.java java-ops/org/tensorflow/op/core/SparseAccumulatorTakeGradient.java
--- java/org/tensorflow/op/core/SparseAccumulatorTakeGradient.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseAccumulatorTakeGradient.java	2018-10-16 20:18:38.528432173 +0900
@@ -0,0 +1,94 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Extracts the average sparse gradient in a SparseConditionalAccumulator.
+ * <p>
+ * The op will blocks until sufficient (i.e., more than num_required)
+ * gradients have been accumulated. If the accumulator has already
+ * aggregated more than num_required gradients, it will return its
+ * average of the accumulated gradients.  Also automatically increments
+ * the recorded global_step in the accumulator by 1, and resets the
+ * aggregate to 0.
+ * 
+ * @param <T> data type for {@code values()} output
+ */
+@Operator
+public final class SparseAccumulatorTakeGradient<T> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new SparseAccumulatorTakeGradient operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param handle The handle to a SparseConditionalAccumulator.
+   * @param numRequired Number of gradients required before we return an aggregate.
+   * @param dtype The data type of accumulated gradients. Needs to correspond to the type
+   * of the accumulator.
+   * @return a new instance of SparseAccumulatorTakeGradient
+   */
+  public static <T> SparseAccumulatorTakeGradient<T> create(Scope scope, Operand<String> handle, Operand<Integer> numRequired, Class<T> dtype) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseAccumulatorTakeGradient", scope.makeOpName("SparseAccumulatorTakeGradient"));
+    opBuilder.addInput(handle.asOutput());
+    opBuilder.addInput(numRequired.asOutput());
+    opBuilder.setAttr("dtype", DataType.fromClass(dtype));
+    return new SparseAccumulatorTakeGradient<T>(opBuilder.build());
+  }
+  
+  /**
+   * Indices of the average of the accumulated sparse gradients.
+   */
+  public Output<Long> indices() {
+    return indices;
+  }
+  
+  /**
+   * Values of the average of the accumulated sparse gradients.
+   */
+  public Output<T> values() {
+    return values;
+  }
+  
+  /**
+   * Shape of the average of the accumulated sparse gradients.
+   */
+  public Output<Long> shape() {
+    return shape;
+  }
+  
+  private Output<Long> indices;
+  private Output<T> values;
+  private Output<Long> shape;
+  
+  private SparseAccumulatorTakeGradient(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    indices = operation.output(outputIdx++);
+    values = operation.output(outputIdx++);
+    shape = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseAddGrad.java java-ops/org/tensorflow/op/core/SparseAddGrad.java
--- java/org/tensorflow/op/core/SparseAddGrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseAddGrad.java	2018-10-16 20:18:38.530432172 +0900
@@ -0,0 +1,87 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * The gradient operator for the SparseAdd op.
+ * <p>
+ * The SparseAdd op calculates A + B, where A, B, and the sum are all represented
+ * as `SparseTensor` objects.  This op takes in the upstream gradient w.r.t.
+ * non-empty values of the sum, and outputs the gradients w.r.t. the non-empty
+ * values of A and B.
+ * 
+ * @param <T> data type for {@code aValGrad()} output
+ */
+@Operator
+public final class SparseAddGrad<T> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new SparseAddGrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param backpropValGrad 1-D with shape `[nnz(sum)]`.  The gradient with respect to
+   * the non-empty values of the sum.
+   * @param aIndices 2-D.  The `indices` of the `SparseTensor` A, size `[nnz(A), ndims]`.
+   * @param bIndices 2-D.  The `indices` of the `SparseTensor` B, size `[nnz(B), ndims]`.
+   * @param sumIndices 2-D.  The `indices` of the sum `SparseTensor`, size
+   * `[nnz(sum), ndims]`.
+   * @return a new instance of SparseAddGrad
+   */
+  public static <T> SparseAddGrad<T> create(Scope scope, Operand<T> backpropValGrad, Operand<Long> aIndices, Operand<Long> bIndices, Operand<Long> sumIndices) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseAddGrad", scope.makeOpName("SparseAddGrad"));
+    opBuilder.addInput(backpropValGrad.asOutput());
+    opBuilder.addInput(aIndices.asOutput());
+    opBuilder.addInput(bIndices.asOutput());
+    opBuilder.addInput(sumIndices.asOutput());
+    return new SparseAddGrad<T>(opBuilder.build());
+  }
+  
+  /**
+   * 1-D with shape `[nnz(A)]`. The gradient with respect to the
+   * non-empty values of A.
+   */
+  public Output<T> aValGrad() {
+    return aValGrad;
+  }
+  
+  /**
+   * 1-D with shape `[nnz(B)]`. The gradient with respect to the
+   * non-empty values of B.
+   */
+  public Output<T> bValGrad() {
+    return bValGrad;
+  }
+  
+  private Output<T> aValGrad;
+  private Output<T> bValGrad;
+  
+  private SparseAddGrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    aValGrad = operation.output(outputIdx++);
+    bValGrad = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseAdd.java java-ops/org/tensorflow/op/core/SparseAdd.java
--- java/org/tensorflow/op/core/SparseAdd.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseAdd.java	2018-10-16 20:18:38.530432172 +0900
@@ -0,0 +1,105 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Adds two `SparseTensor` objects to produce another `SparseTensor`.
+ * <p>
+ * The input `SparseTensor` objects' indices are assumed ordered in standard
+ * lexicographic order.  If this is not the case, before this step run
+ * `SparseReorder` to restore index ordering.
+ * <p>
+ * By default, if two values sum to zero at some index, the output `SparseTensor`
+ * would still include that particular location in its index, storing a zero in the
+ * corresponding value slot.  To override this, callers can specify `thresh`,
+ * indicating that if the sum has a magnitude strictly smaller than `thresh`, its
+ * corresponding value and index would then not be included.  In particular,
+ * `thresh == 0` (default) means everything is kept and actual thresholding happens
+ * only for a positive value.
+ * <p>
+ * In the following shapes, `nnz` is the count after taking `thresh` into account.
+ * 
+ * @param <T> data type for {@code sumValues()} output
+ */
+@Operator
+public final class SparseAdd<T> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new SparseAdd operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param aIndices 2-D.  The `indices` of the first `SparseTensor`, size `[nnz, ndims]` Matrix.
+   * @param aValues 1-D.  The `values` of the first `SparseTensor`, size `[nnz]` Vector.
+   * @param aShape 1-D.  The `shape` of the first `SparseTensor`, size `[ndims]` Vector.
+   * @param bIndices 2-D.  The `indices` of the second `SparseTensor`, size `[nnz, ndims]` Matrix.
+   * @param bValues 1-D.  The `values` of the second `SparseTensor`, size `[nnz]` Vector.
+   * @param bShape 1-D.  The `shape` of the second `SparseTensor`, size `[ndims]` Vector.
+   * @param thresh 0-D.  The magnitude threshold that determines if an output value/index
+   * pair takes space.
+   * @return a new instance of SparseAdd
+   */
+  public static <T, U extends Number> SparseAdd<T> create(Scope scope, Operand<Long> aIndices, Operand<T> aValues, Operand<Long> aShape, Operand<Long> bIndices, Operand<T> bValues, Operand<Long> bShape, Operand<U> thresh) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseAdd", scope.makeOpName("SparseAdd"));
+    opBuilder.addInput(aIndices.asOutput());
+    opBuilder.addInput(aValues.asOutput());
+    opBuilder.addInput(aShape.asOutput());
+    opBuilder.addInput(bIndices.asOutput());
+    opBuilder.addInput(bValues.asOutput());
+    opBuilder.addInput(bShape.asOutput());
+    opBuilder.addInput(thresh.asOutput());
+    return new SparseAdd<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<Long> sumIndices() {
+    return sumIndices;
+  }
+  
+  /**
+   */
+  public Output<T> sumValues() {
+    return sumValues;
+  }
+  
+  /**
+   */
+  public Output<Long> sumShape() {
+    return sumShape;
+  }
+  
+  private Output<Long> sumIndices;
+  private Output<T> sumValues;
+  private Output<Long> sumShape;
+  
+  private SparseAdd(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    sumIndices = operation.output(outputIdx++);
+    sumValues = operation.output(outputIdx++);
+    sumShape = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseApplyAdadelta.java java-ops/org/tensorflow/op/core/SparseApplyAdadelta.java
--- java/org/tensorflow/op/core/SparseApplyAdadelta.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseApplyAdadelta.java	2018-10-16 20:18:38.531432171 +0900
@@ -0,0 +1,118 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * var: Should be from a Variable().
+ * 
+ * @param <T> data type for {@code out()} output
+ */
+@Operator
+public final class SparseApplyAdadelta<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.SparseApplyAdadelta}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If True, updating of the var and accum tensors will be protected by
+     * a lock; otherwise the behavior is undefined, but may exhibit less contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new SparseApplyAdadelta operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var 
+   * @param accum Should be from a Variable().
+   * @param accumUpdate : Should be from a Variable().
+   * @param lr Learning rate. Must be a scalar.
+   * @param rho Decay factor. Must be a scalar.
+   * @param epsilon Constant factor. Must be a scalar.
+   * @param grad The gradient.
+   * @param indices A vector of indices into the first dimension of var and accum.
+   * @param options carries optional attributes values
+   * @return a new instance of SparseApplyAdadelta
+   */
+  public static <T, U extends Number> SparseApplyAdadelta<T> create(Scope scope, Operand<T> var, Operand<T> accum, Operand<T> accumUpdate, Operand<T> lr, Operand<T> rho, Operand<T> epsilon, Operand<T> grad, Operand<U> indices, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseApplyAdadelta", scope.makeOpName("SparseApplyAdadelta"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(accum.asOutput());
+    opBuilder.addInput(accumUpdate.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(rho.asOutput());
+    opBuilder.addInput(epsilon.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new SparseApplyAdadelta<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If True, updating of the var and accum tensors will be protected by
+   * a lock; otherwise the behavior is undefined, but may exhibit less contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * Same as "var".
+   */
+  public Output<T> out() {
+    return out;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return out;
+  }
+  
+  private Output<T> out;
+  
+  private SparseApplyAdadelta(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    out = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseApplyAdagradDA.java java-ops/org/tensorflow/op/core/SparseApplyAdagradDA.java
--- java/org/tensorflow/op/core/SparseApplyAdagradDA.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseApplyAdagradDA.java	2018-10-16 20:18:38.532432170 +0900
@@ -0,0 +1,120 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update entries in '*var' and '*accum' according to the proximal adagrad scheme.
+ * 
+ * @param <T> data type for {@code out()} output
+ */
+@Operator
+public final class SparseApplyAdagradDA<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.SparseApplyAdagradDA}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If True, updating of the var and accum tensors will be protected by
+     * a lock; otherwise the behavior is undefined, but may exhibit less contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new SparseApplyAdagradDA operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param gradientAccumulator Should be from a Variable().
+   * @param gradientSquaredAccumulator Should be from a Variable().
+   * @param grad The gradient.
+   * @param indices A vector of indices into the first dimension of var and accum.
+   * @param lr Learning rate. Must be a scalar.
+   * @param l1 L1 regularization. Must be a scalar.
+   * @param l2 L2 regularization. Must be a scalar.
+   * @param globalStep Training step number. Must be a scalar.
+   * @param options carries optional attributes values
+   * @return a new instance of SparseApplyAdagradDA
+   */
+  public static <T, U extends Number> SparseApplyAdagradDA<T> create(Scope scope, Operand<T> var, Operand<T> gradientAccumulator, Operand<T> gradientSquaredAccumulator, Operand<T> grad, Operand<U> indices, Operand<T> lr, Operand<T> l1, Operand<T> l2, Operand<Long> globalStep, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseApplyAdagradDA", scope.makeOpName("SparseApplyAdagradDA"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(gradientAccumulator.asOutput());
+    opBuilder.addInput(gradientSquaredAccumulator.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(l1.asOutput());
+    opBuilder.addInput(l2.asOutput());
+    opBuilder.addInput(globalStep.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new SparseApplyAdagradDA<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If True, updating of the var and accum tensors will be protected by
+   * a lock; otherwise the behavior is undefined, but may exhibit less contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * Same as "var".
+   */
+  public Output<T> out() {
+    return out;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return out;
+  }
+  
+  private Output<T> out;
+  
+  private SparseApplyAdagradDA(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    out = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseApplyAdagrad.java java-ops/org/tensorflow/op/core/SparseApplyAdagrad.java
--- java/org/tensorflow/op/core/SparseApplyAdagrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseApplyAdagrad.java	2018-10-16 20:18:38.532432170 +0900
@@ -0,0 +1,137 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update relevant entries in '*var' and '*accum' according to the adagrad scheme.
+ * <p>
+ * That is for rows we have grad for, we update var and accum as follows:
+ * $$accum += grad * grad$$
+ * $$var -= lr * grad * (1 / sqrt(accum))$$
+ * 
+ * @param <T> data type for {@code out()} output
+ */
+@Operator
+public final class SparseApplyAdagrad<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.SparseApplyAdagrad}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If `True`, updating of the var and accum tensors will be protected
+     * by a lock; otherwise the behavior is undefined, but may exhibit less
+     * contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    /**
+     * @param updateSlots 
+     */
+    public Options updateSlots(Boolean updateSlots) {
+      this.updateSlots = updateSlots;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    private Boolean updateSlots;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new SparseApplyAdagrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param accum Should be from a Variable().
+   * @param lr Learning rate. Must be a scalar.
+   * @param grad The gradient.
+   * @param indices A vector of indices into the first dimension of var and accum.
+   * @param options carries optional attributes values
+   * @return a new instance of SparseApplyAdagrad
+   */
+  public static <T, U extends Number> SparseApplyAdagrad<T> create(Scope scope, Operand<T> var, Operand<T> accum, Operand<T> lr, Operand<T> grad, Operand<U> indices, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseApplyAdagrad", scope.makeOpName("SparseApplyAdagrad"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(accum.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+        if (opts.updateSlots != null) {
+          opBuilder.setAttr("update_slots", opts.updateSlots);
+        }
+      }
+    }
+    return new SparseApplyAdagrad<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If `True`, updating of the var and accum tensors will be protected
+   * by a lock; otherwise the behavior is undefined, but may exhibit less
+   * contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * @param updateSlots 
+   */
+  public static Options updateSlots(Boolean updateSlots) {
+    return new Options().updateSlots(updateSlots);
+  }
+  
+  /**
+   * Same as "var".
+   */
+  public Output<T> out() {
+    return out;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return out;
+  }
+  
+  private Output<T> out;
+  
+  private SparseApplyAdagrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    out = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseApplyCenteredRMSProp.java java-ops/org/tensorflow/op/core/SparseApplyCenteredRMSProp.java
--- java/org/tensorflow/op/core/SparseApplyCenteredRMSProp.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseApplyCenteredRMSProp.java	2018-10-16 20:18:38.533432170 +0900
@@ -0,0 +1,141 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update '*var' according to the centered RMSProp algorithm.
+ * <p>
+ * The centered RMSProp algorithm uses an estimate of the centered second moment
+ * (i.e., the variance) for normalization, as opposed to regular RMSProp, which
+ * uses the (uncentered) second moment. This often helps with training, but is
+ * slightly more expensive in terms of computation and memory.
+ * <p>
+ * Note that in dense implementation of this algorithm, mg, ms, and mom will
+ * update even if the grad is zero, but in this sparse implementation, mg, ms,
+ * and mom will not update in iterations during which the grad is zero.
+ * <p>
+ * mean_square = decay * mean_square + (1-decay) * gradient ** 2
+ * mean_grad = decay * mean_grad + (1-decay) * gradient
+ * Delta = learning_rate * gradient / sqrt(mean_square + epsilon - mean_grad ** 2)
+ * <p>
+ * $$ms <- rho * ms_{t-1} + (1-rho) * grad * grad$$
+ * $$mom <- momentum * mom_{t-1} + lr * grad / sqrt(ms + epsilon)$$
+ * $$var <- var - mom$$
+ * 
+ * @param <T> data type for {@code out()} output
+ */
+@Operator
+public final class SparseApplyCenteredRMSProp<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.SparseApplyCenteredRMSProp}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If `True`, updating of the var, mg, ms, and mom tensors is
+     * protected by a lock; otherwise the behavior is undefined, but may exhibit less
+     * contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new SparseApplyCenteredRMSProp operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param mg Should be from a Variable().
+   * @param ms Should be from a Variable().
+   * @param mom Should be from a Variable().
+   * @param lr Scaling factor. Must be a scalar.
+   * @param rho Decay rate. Must be a scalar.
+   * @param momentum 
+   * @param epsilon Ridge term. Must be a scalar.
+   * @param grad The gradient.
+   * @param indices A vector of indices into the first dimension of var, ms and mom.
+   * @param options carries optional attributes values
+   * @return a new instance of SparseApplyCenteredRMSProp
+   */
+  public static <T, U extends Number> SparseApplyCenteredRMSProp<T> create(Scope scope, Operand<T> var, Operand<T> mg, Operand<T> ms, Operand<T> mom, Operand<T> lr, Operand<T> rho, Operand<T> momentum, Operand<T> epsilon, Operand<T> grad, Operand<U> indices, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseApplyCenteredRMSProp", scope.makeOpName("SparseApplyCenteredRMSProp"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(mg.asOutput());
+    opBuilder.addInput(ms.asOutput());
+    opBuilder.addInput(mom.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(rho.asOutput());
+    opBuilder.addInput(momentum.asOutput());
+    opBuilder.addInput(epsilon.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new SparseApplyCenteredRMSProp<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If `True`, updating of the var, mg, ms, and mom tensors is
+   * protected by a lock; otherwise the behavior is undefined, but may exhibit less
+   * contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * Same as "var".
+   */
+  public Output<T> out() {
+    return out;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return out;
+  }
+  
+  private Output<T> out;
+  
+  private SparseApplyCenteredRMSProp(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    out = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseApplyFtrl.java java-ops/org/tensorflow/op/core/SparseApplyFtrl.java
--- java/org/tensorflow/op/core/SparseApplyFtrl.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseApplyFtrl.java	2018-10-16 20:18:38.534432169 +0900
@@ -0,0 +1,129 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update relevant entries in '*var' according to the Ftrl-proximal scheme.
+ * <p>
+ * That is for rows we have grad for, we update var, accum and linear as follows:
+ * $$accum_new = accum + grad * grad$$
+ * $$linear += grad + (accum_{new}^{-lr_{power}} - accum^{-lr_{power}} / lr * var$$
+ * $$quadratic = 1.0 / (accum_{new}^{lr_{power}} * lr) + 2 * l2$$
+ * $$var = (sign(linear) * l1 - linear) / quadratic\ if\ |linear| > l1\ else\ 0.0$$
+ * $$accum = accum_{new}$$
+ * 
+ * @param <T> data type for {@code out()} output
+ */
+@Operator
+public final class SparseApplyFtrl<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.SparseApplyFtrl}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If `True`, updating of the var and accum tensors will be protected
+     * by a lock; otherwise the behavior is undefined, but may exhibit less
+     * contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new SparseApplyFtrl operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param accum Should be from a Variable().
+   * @param linear Should be from a Variable().
+   * @param grad The gradient.
+   * @param indices A vector of indices into the first dimension of var and accum.
+   * @param lr Scaling factor. Must be a scalar.
+   * @param l1 L1 regularization. Must be a scalar.
+   * @param l2 L2 regularization. Must be a scalar.
+   * @param lrPower Scaling factor. Must be a scalar.
+   * @param options carries optional attributes values
+   * @return a new instance of SparseApplyFtrl
+   */
+  public static <T, U extends Number> SparseApplyFtrl<T> create(Scope scope, Operand<T> var, Operand<T> accum, Operand<T> linear, Operand<T> grad, Operand<U> indices, Operand<T> lr, Operand<T> l1, Operand<T> l2, Operand<T> lrPower, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseApplyFtrl", scope.makeOpName("SparseApplyFtrl"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(accum.asOutput());
+    opBuilder.addInput(linear.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(l1.asOutput());
+    opBuilder.addInput(l2.asOutput());
+    opBuilder.addInput(lrPower.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new SparseApplyFtrl<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If `True`, updating of the var and accum tensors will be protected
+   * by a lock; otherwise the behavior is undefined, but may exhibit less
+   * contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * Same as "var".
+   */
+  public Output<T> out() {
+    return out;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return out;
+  }
+  
+  private Output<T> out;
+  
+  private SparseApplyFtrl(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    out = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseApplyFtrlV2.java java-ops/org/tensorflow/op/core/SparseApplyFtrlV2.java
--- java/org/tensorflow/op/core/SparseApplyFtrlV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseApplyFtrlV2.java	2018-10-16 20:18:38.535432168 +0900
@@ -0,0 +1,133 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update relevant entries in '*var' according to the Ftrl-proximal scheme.
+ * <p>
+ * That is for rows we have grad for, we update var, accum and linear as follows:
+ * grad_with_shrinkage = grad + 2 * l2_shrinkage * var
+ * accum_new = accum + grad_with_shrinkage * grad_with_shrinkage
+ * linear += grad_with_shrinkage +
+ *     (accum_new^(-lr_power) - accum^(-lr_power)) / lr * var
+ * quadratic = 1.0 / (accum_new^(lr_power) * lr) + 2 * l2
+ * var = (sign(linear) * l1 - linear) / quadratic if |linear| > l1 else 0.0
+ * accum = accum_new
+ * 
+ * @param <T> data type for {@code out()} output
+ */
+@Operator
+public final class SparseApplyFtrlV2<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.SparseApplyFtrlV2}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If `True`, updating of the var and accum tensors will be protected
+     * by a lock; otherwise the behavior is undefined, but may exhibit less
+     * contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new SparseApplyFtrlV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param accum Should be from a Variable().
+   * @param linear Should be from a Variable().
+   * @param grad The gradient.
+   * @param indices A vector of indices into the first dimension of var and accum.
+   * @param lr Scaling factor. Must be a scalar.
+   * @param l1 L1 regularization. Must be a scalar.
+   * @param l2 L2 shrinkage regulariation. Must be a scalar.
+   * @param l2Shrinkage 
+   * @param lrPower Scaling factor. Must be a scalar.
+   * @param options carries optional attributes values
+   * @return a new instance of SparseApplyFtrlV2
+   */
+  public static <T, U extends Number> SparseApplyFtrlV2<T> create(Scope scope, Operand<T> var, Operand<T> accum, Operand<T> linear, Operand<T> grad, Operand<U> indices, Operand<T> lr, Operand<T> l1, Operand<T> l2, Operand<T> l2Shrinkage, Operand<T> lrPower, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseApplyFtrlV2", scope.makeOpName("SparseApplyFtrlV2"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(accum.asOutput());
+    opBuilder.addInput(linear.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(l1.asOutput());
+    opBuilder.addInput(l2.asOutput());
+    opBuilder.addInput(l2Shrinkage.asOutput());
+    opBuilder.addInput(lrPower.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new SparseApplyFtrlV2<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If `True`, updating of the var and accum tensors will be protected
+   * by a lock; otherwise the behavior is undefined, but may exhibit less
+   * contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * Same as "var".
+   */
+  public Output<T> out() {
+    return out;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return out;
+  }
+  
+  private Output<T> out;
+  
+  private SparseApplyFtrlV2(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    out = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseApplyMomentum.java java-ops/org/tensorflow/op/core/SparseApplyMomentum.java
--- java/org/tensorflow/op/core/SparseApplyMomentum.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseApplyMomentum.java	2018-10-16 20:18:38.535432168 +0900
@@ -0,0 +1,146 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update relevant entries in '*var' and '*accum' according to the momentum scheme.
+ * <p>
+ * Set use_nesterov = True if you want to use Nesterov momentum.
+ * <p>
+ * That is for rows we have grad for, we update var and accum as follows:
+ * <p>
+ * $$accum = accum * momentum + grad$$
+ * $$var -= lr * accum$$
+ * 
+ * @param <T> data type for {@code out()} output
+ */
+@Operator
+public final class SparseApplyMomentum<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.SparseApplyMomentum}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If `True`, updating of the var and accum tensors will be protected
+     * by a lock; otherwise the behavior is undefined, but may exhibit less
+     * contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    /**
+     * @param useNesterov If `True`, the tensor passed to compute grad will be
+     * var - lr * momentum * accum, so in the end, the var you get is actually
+     * var - lr * momentum * accum.
+     */
+    public Options useNesterov(Boolean useNesterov) {
+      this.useNesterov = useNesterov;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    private Boolean useNesterov;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new SparseApplyMomentum operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param accum Should be from a Variable().
+   * @param lr Learning rate. Must be a scalar.
+   * @param grad The gradient.
+   * @param indices A vector of indices into the first dimension of var and accum.
+   * @param momentum Momentum. Must be a scalar.
+   * @param options carries optional attributes values
+   * @return a new instance of SparseApplyMomentum
+   */
+  public static <T, U extends Number> SparseApplyMomentum<T> create(Scope scope, Operand<T> var, Operand<T> accum, Operand<T> lr, Operand<T> grad, Operand<U> indices, Operand<T> momentum, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseApplyMomentum", scope.makeOpName("SparseApplyMomentum"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(accum.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(momentum.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+        if (opts.useNesterov != null) {
+          opBuilder.setAttr("use_nesterov", opts.useNesterov);
+        }
+      }
+    }
+    return new SparseApplyMomentum<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If `True`, updating of the var and accum tensors will be protected
+   * by a lock; otherwise the behavior is undefined, but may exhibit less
+   * contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * @param useNesterov If `True`, the tensor passed to compute grad will be
+   * var - lr * momentum * accum, so in the end, the var you get is actually
+   * var - lr * momentum * accum.
+   */
+  public static Options useNesterov(Boolean useNesterov) {
+    return new Options().useNesterov(useNesterov);
+  }
+  
+  /**
+   * Same as "var".
+   */
+  public Output<T> out() {
+    return out;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return out;
+  }
+  
+  private Output<T> out;
+  
+  private SparseApplyMomentum(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    out = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseApplyProximalAdagrad.java java-ops/org/tensorflow/op/core/SparseApplyProximalAdagrad.java
--- java/org/tensorflow/op/core/SparseApplyProximalAdagrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseApplyProximalAdagrad.java	2018-10-16 20:18:38.536432167 +0900
@@ -0,0 +1,122 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Sparse update entries in '*var' and '*accum' according to FOBOS algorithm.
+ * <p>
+ * That is for rows we have grad for, we update var and accum as follows:
+ * $$accum += grad <i> grad$$
+ * $$prox_v = var$$
+ * $$prox_v -= lr </i> grad <i> (1 / sqrt(accum))$$
+ * $$var = sign(prox_v)/(1+lr</i>l2) <i> max{|prox_v|-lr</i>l1,0}$$
+ * 
+ * @param <T> data type for {@code out()} output
+ */
+@Operator
+public final class SparseApplyProximalAdagrad<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.SparseApplyProximalAdagrad}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If True, updating of the var and accum tensors will be protected by
+     * a lock; otherwise the behavior is undefined, but may exhibit less contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new SparseApplyProximalAdagrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param accum Should be from a Variable().
+   * @param lr Learning rate. Must be a scalar.
+   * @param l1 L1 regularization. Must be a scalar.
+   * @param l2 L2 regularization. Must be a scalar.
+   * @param grad The gradient.
+   * @param indices A vector of indices into the first dimension of var and accum.
+   * @param options carries optional attributes values
+   * @return a new instance of SparseApplyProximalAdagrad
+   */
+  public static <T, U extends Number> SparseApplyProximalAdagrad<T> create(Scope scope, Operand<T> var, Operand<T> accum, Operand<T> lr, Operand<T> l1, Operand<T> l2, Operand<T> grad, Operand<U> indices, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseApplyProximalAdagrad", scope.makeOpName("SparseApplyProximalAdagrad"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(accum.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(l1.asOutput());
+    opBuilder.addInput(l2.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new SparseApplyProximalAdagrad<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If True, updating of the var and accum tensors will be protected by
+   * a lock; otherwise the behavior is undefined, but may exhibit less contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * Same as "var".
+   */
+  public Output<T> out() {
+    return out;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return out;
+  }
+  
+  private Output<T> out;
+  
+  private SparseApplyProximalAdagrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    out = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseApplyProximalGradientDescent.java java-ops/org/tensorflow/op/core/SparseApplyProximalGradientDescent.java
--- java/org/tensorflow/op/core/SparseApplyProximalGradientDescent.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseApplyProximalGradientDescent.java	2018-10-16 20:18:38.536432167 +0900
@@ -0,0 +1,118 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Sparse update '*var' as FOBOS algorithm with fixed learning rate.
+ * <p>
+ * That is for rows we have grad for, we update var as follows:
+ * $$prox_v = var - alpha <i> grad$$
+ * $$var = sign(prox_v)/(1+alpha</i>l2) <i> max{|prox_v|-alpha</i>l1,0}$$
+ * 
+ * @param <T> data type for {@code out()} output
+ */
+@Operator
+public final class SparseApplyProximalGradientDescent<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.SparseApplyProximalGradientDescent}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If True, the subtraction will be protected by a lock;
+     * otherwise the behavior is undefined, but may exhibit less contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new SparseApplyProximalGradientDescent operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param alpha Scaling factor. Must be a scalar.
+   * @param l1 L1 regularization. Must be a scalar.
+   * @param l2 L2 regularization. Must be a scalar.
+   * @param grad The gradient.
+   * @param indices A vector of indices into the first dimension of var and accum.
+   * @param options carries optional attributes values
+   * @return a new instance of SparseApplyProximalGradientDescent
+   */
+  public static <T, U extends Number> SparseApplyProximalGradientDescent<T> create(Scope scope, Operand<T> var, Operand<T> alpha, Operand<T> l1, Operand<T> l2, Operand<T> grad, Operand<U> indices, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseApplyProximalGradientDescent", scope.makeOpName("SparseApplyProximalGradientDescent"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(alpha.asOutput());
+    opBuilder.addInput(l1.asOutput());
+    opBuilder.addInput(l2.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new SparseApplyProximalGradientDescent<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If True, the subtraction will be protected by a lock;
+   * otherwise the behavior is undefined, but may exhibit less contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * Same as "var".
+   */
+  public Output<T> out() {
+    return out;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return out;
+  }
+  
+  private Output<T> out;
+  
+  private SparseApplyProximalGradientDescent(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    out = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseApplyRMSProp.java java-ops/org/tensorflow/op/core/SparseApplyRMSProp.java
--- java/org/tensorflow/op/core/SparseApplyRMSProp.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseApplyRMSProp.java	2018-10-16 20:18:38.537432167 +0900
@@ -0,0 +1,133 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Update '*var' according to the RMSProp algorithm.
+ * <p>
+ * Note that in dense implementation of this algorithm, ms and mom will
+ * update even if the grad is zero, but in this sparse implementation, ms
+ * and mom will not update in iterations during which the grad is zero.
+ * <p>
+ * mean_square = decay * mean_square + (1-decay) * gradient ** 2
+ * Delta = learning_rate * gradient / sqrt(mean_square + epsilon)
+ * <p>
+ * $$ms <- rho * ms_{t-1} + (1-rho) * grad * grad$$
+ * $$mom <- momentum * mom_{t-1} + lr * grad / sqrt(ms + epsilon)$$
+ * $$var <- var - mom$$
+ * 
+ * @param <T> data type for {@code out()} output
+ */
+@Operator
+public final class SparseApplyRMSProp<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.SparseApplyRMSProp}
+   */
+  public static class Options {
+    
+    /**
+     * @param useLocking If `True`, updating of the var, ms, and mom tensors is protected
+     * by a lock; otherwise the behavior is undefined, but may exhibit less
+     * contention.
+     */
+    public Options useLocking(Boolean useLocking) {
+      this.useLocking = useLocking;
+      return this;
+    }
+    
+    private Boolean useLocking;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new SparseApplyRMSProp operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param var Should be from a Variable().
+   * @param ms Should be from a Variable().
+   * @param mom Should be from a Variable().
+   * @param lr Scaling factor. Must be a scalar.
+   * @param rho Decay rate. Must be a scalar.
+   * @param momentum 
+   * @param epsilon Ridge term. Must be a scalar.
+   * @param grad The gradient.
+   * @param indices A vector of indices into the first dimension of var, ms and mom.
+   * @param options carries optional attributes values
+   * @return a new instance of SparseApplyRMSProp
+   */
+  public static <T, U extends Number> SparseApplyRMSProp<T> create(Scope scope, Operand<T> var, Operand<T> ms, Operand<T> mom, Operand<T> lr, Operand<T> rho, Operand<T> momentum, Operand<T> epsilon, Operand<T> grad, Operand<U> indices, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseApplyRMSProp", scope.makeOpName("SparseApplyRMSProp"));
+    opBuilder.addInput(var.asOutput());
+    opBuilder.addInput(ms.asOutput());
+    opBuilder.addInput(mom.asOutput());
+    opBuilder.addInput(lr.asOutput());
+    opBuilder.addInput(rho.asOutput());
+    opBuilder.addInput(momentum.asOutput());
+    opBuilder.addInput(epsilon.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.useLocking != null) {
+          opBuilder.setAttr("use_locking", opts.useLocking);
+        }
+      }
+    }
+    return new SparseApplyRMSProp<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param useLocking If `True`, updating of the var, ms, and mom tensors is protected
+   * by a lock; otherwise the behavior is undefined, but may exhibit less
+   * contention.
+   */
+  public static Options useLocking(Boolean useLocking) {
+    return new Options().useLocking(useLocking);
+  }
+  
+  /**
+   * Same as "var".
+   */
+  public Output<T> out() {
+    return out;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return out;
+  }
+  
+  private Output<T> out;
+  
+  private SparseApplyRMSProp(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    out = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseConcat.java java-ops/org/tensorflow/op/core/SparseConcat.java
--- java/org/tensorflow/op/core/SparseConcat.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseConcat.java	2018-10-16 20:18:38.538432166 +0900
@@ -0,0 +1,131 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Concatenates a list of `SparseTensor` along the specified dimension.
+ * <p>
+ * Concatenation is with respect to the dense versions of these sparse tensors.
+ * It is assumed that each input is a `SparseTensor` whose elements are ordered
+ * along increasing dimension number.
+ * <p>
+ * All inputs' shapes must match, except for the concat dimension.  The
+ * `indices`, `values`, and `shapes` lists must have the same length.
+ * <p>
+ * The output shape is identical to the inputs', except along the concat
+ * dimension, where it is the sum of the inputs' sizes along that dimension.
+ * <p>
+ * The output elements will be resorted to preserve the sort order along
+ * increasing dimension number.
+ * <p>
+ * This op runs in `O(M log M)` time, where `M` is the total number of non-empty
+ * values across all inputs. This is due to the need for an internal sort in
+ * order to concatenate efficiently across an arbitrary dimension.
+ * <p>
+ * For example, if `concat_dim = 1` and the inputs are
+ * <p>
+ *     sp_inputs[0]: shape = [2, 3]
+ *     [0, 2]: "a"
+ *     [1, 0]: "b"
+ *     [1, 1]: "c"
+ * <p>
+ *     sp_inputs[1]: shape = [2, 4]
+ *     [0, 1]: "d"
+ *     [0, 2]: "e"
+ * <p>
+ * then the output will be
+ * <p>
+ *     shape = [2, 7]
+ *     [0, 2]: "a"
+ *     [0, 4]: "d"
+ *     [0, 5]: "e"
+ *     [1, 0]: "b"
+ *     [1, 1]: "c"
+ * <p>
+ * Graphically this is equivalent to doing
+ * <p>
+ *     [    a] concat [  d e  ] = [    a   d e  ]
+ *     [b c  ]        [       ]   [b c          ]
+ * 
+ * @param <T> data type for {@code outputValues()} output
+ */
+@Operator
+public final class SparseConcat<T> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new SparseConcat operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param indices 2-D.  Indices of each input `SparseTensor`.
+   * @param values 1-D.  Non-empty values of each `SparseTensor`.
+   * @param shapes 1-D.  Shapes of each `SparseTensor`.
+   * @param concatDim Dimension to concatenate along. Must be in range [-rank, rank),
+   * where rank is the number of dimensions in each input `SparseTensor`.
+   * @return a new instance of SparseConcat
+   */
+  public static <T> SparseConcat<T> create(Scope scope, Iterable<Operand<Long>> indices, Operand<T> values, Iterable<Operand<Long>> shapes, Long concatDim) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseConcat", scope.makeOpName("SparseConcat"));
+    opBuilder.addInputList(Operands.asOutputs(indices));
+    opBuilder.addInput(values.asOutput());
+    opBuilder.addInputList(Operands.asOutputs(shapes));
+    opBuilder.setAttr("concat_dim", concatDim);
+    return new SparseConcat<T>(opBuilder.build());
+  }
+  
+  /**
+   * 2-D.  Indices of the concatenated `SparseTensor`.
+   */
+  public Output<Long> outputIndices() {
+    return outputIndices;
+  }
+  
+  /**
+   * 1-D.  Non-empty values of the concatenated `SparseTensor`.
+   */
+  public Output<T> outputValues() {
+    return outputValues;
+  }
+  
+  /**
+   * 1-D.  Shape of the concatenated `SparseTensor`.
+   */
+  public Output<Long> outputShape() {
+    return outputShape;
+  }
+  
+  private Output<Long> outputIndices;
+  private Output<T> outputValues;
+  private Output<Long> outputShape;
+  
+  private SparseConcat(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    outputIndices = operation.output(outputIdx++);
+    outputValues = operation.output(outputIdx++);
+    outputShape = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseConditionalAccumulator.java java-ops/org/tensorflow/op/core/SparseConditionalAccumulator.java
--- java/org/tensorflow/op/core/SparseConditionalAccumulator.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseConditionalAccumulator.java	2018-10-16 20:18:38.539432165 +0900
@@ -0,0 +1,153 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * A conditional accumulator for aggregating sparse gradients.
+ * <p>
+ * The accumulator accepts gradients marked with local_step greater or
+ * equal to the most recent global_step known to the accumulator. The
+ * average can be extracted from the accumulator, provided sufficient
+ * gradients have been accumulated. Extracting the average automatically
+ * resets the aggregate to 0, and increments the global_step recorded by
+ * the accumulator.
+ */
+@Operator
+public final class SparseConditionalAccumulator extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.SparseConditionalAccumulator}
+   */
+  public static class Options {
+    
+    /**
+     * @param container If non-empty, this accumulator is placed in the given container.
+     * Otherwise, a default container is used.
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName If non-empty, this accumulator will be shared under the given name
+     * across multiple sessions.
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    /**
+     * @param reductionType 
+     */
+    public Options reductionType(String reductionType) {
+      this.reductionType = reductionType;
+      return this;
+    }
+    
+    private String container;
+    private String sharedName;
+    private String reductionType;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new SparseConditionalAccumulator operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param dtype The type of the value being accumulated.
+   * @param shape The shape of the values.
+   * @param options carries optional attributes values
+   * @return a new instance of SparseConditionalAccumulator
+   */
+  public static <T> SparseConditionalAccumulator create(Scope scope, Class<T> dtype, Shape shape, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseConditionalAccumulator", scope.makeOpName("SparseConditionalAccumulator"));
+    opBuilder.setAttr("dtype", DataType.fromClass(dtype));
+    opBuilder.setAttr("shape", shape);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+        if (opts.reductionType != null) {
+          opBuilder.setAttr("reduction_type", opts.reductionType);
+        }
+      }
+    }
+    return new SparseConditionalAccumulator(opBuilder.build());
+  }
+  
+  /**
+   * @param container If non-empty, this accumulator is placed in the given container.
+   * Otherwise, a default container is used.
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName If non-empty, this accumulator will be shared under the given name
+   * across multiple sessions.
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   * @param reductionType 
+   */
+  public static Options reductionType(String reductionType) {
+    return new Options().reductionType(reductionType);
+  }
+  
+  /**
+   * The handle to the accumulator.
+   */
+  public Output<String> handle() {
+    return handle;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return handle;
+  }
+  
+  private Output<String> handle;
+  
+  private SparseConditionalAccumulator(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseCross.java java-ops/org/tensorflow/op/core/SparseCross.java
--- java/org/tensorflow/op/core/SparseCross.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseCross.java	2018-10-16 20:18:38.540432165 +0900
@@ -0,0 +1,140 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Generates sparse cross from a list of sparse and dense tensors.
+ * <p>
+ * The op takes two lists, one of 2D `SparseTensor` and one of 2D `Tensor`, each
+ * representing features of one feature column. It outputs a 2D `SparseTensor` with
+ * the batchwise crosses of these features.
+ * <p>
+ * For example, if the inputs are
+ * <p>
+ *     inputs[0]: SparseTensor with shape = [2, 2]
+ *     [0, 0]: "a"
+ *     [1, 0]: "b"
+ *     [1, 1]: "c"
+ * <p>
+ *     inputs[1]: SparseTensor with shape = [2, 1]
+ *     [0, 0]: "d"
+ *     [1, 0]: "e"
+ * <p>
+ *     inputs[2]: Tensor [["f"], ["g"]]
+ * <p>
+ * then the output will be
+ * <p>
+ *     shape = [2, 2]
+ *     [0, 0]: "a_X_d_X_f"
+ *     [1, 0]: "b_X_e_X_g"
+ *     [1, 1]: "c_X_e_X_g"
+ * <p>
+ * if hashed_output=true then the output will be
+ * <p>
+ *     shape = [2, 2]
+ *     [0, 0]: FingerprintCat64(
+ *                 Fingerprint64("f"), FingerprintCat64(
+ *                     Fingerprint64("d"), Fingerprint64("a")))
+ *     [1, 0]: FingerprintCat64(
+ *                 Fingerprint64("g"), FingerprintCat64(
+ *                     Fingerprint64("e"), Fingerprint64("b")))
+ *     [1, 1]: FingerprintCat64(
+ *                 Fingerprint64("g"), FingerprintCat64(
+ *                     Fingerprint64("e"), Fingerprint64("c")))
+ * 
+ * @param <T> data type for {@code outputValues()} output
+ */
+@Operator
+public final class SparseCross<T> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new SparseCross operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param indices 2-D.  Indices of each input `SparseTensor`.
+   * @param values 1-D.   values of each `SparseTensor`.
+   * @param shapes 1-D.   Shapes of each `SparseTensor`.
+   * @param denseInputs 2-D.    Columns represented by dense `Tensor`.
+   * @param hashedOutput If true, returns the hash of the cross instead of the string.
+   * This will allow us avoiding string manipulations.
+   * @param numBuckets It is used if hashed_output is true.
+   * output = hashed_value%num_buckets if num_buckets > 0 else hashed_value.
+   * @param hashKey Specify the hash_key that will be used by the `FingerprintCat64`
+   * function to combine the crosses fingerprints.
+   * @param outType 
+   * @param internalType 
+   * @return a new instance of SparseCross
+   */
+  public static <T, U> SparseCross<T> create(Scope scope, Iterable<Operand<Long>> indices, Iterable<Operand<?>> values, Iterable<Operand<Long>> shapes, Iterable<Operand<?>> denseInputs, Boolean hashedOutput, Long numBuckets, Long hashKey, Class<T> outType, Class<U> internalType) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseCross", scope.makeOpName("SparseCross"));
+    opBuilder.addInputList(Operands.asOutputs(indices));
+    opBuilder.addInputList(Operands.asOutputs(values));
+    opBuilder.addInputList(Operands.asOutputs(shapes));
+    opBuilder.addInputList(Operands.asOutputs(denseInputs));
+    opBuilder.setAttr("hashed_output", hashedOutput);
+    opBuilder.setAttr("num_buckets", numBuckets);
+    opBuilder.setAttr("hash_key", hashKey);
+    opBuilder.setAttr("out_type", DataType.fromClass(outType));
+    opBuilder.setAttr("internal_type", DataType.fromClass(internalType));
+    return new SparseCross<T>(opBuilder.build());
+  }
+  
+  /**
+   * 2-D.  Indices of the concatenated `SparseTensor`.
+   */
+  public Output<Long> outputIndices() {
+    return outputIndices;
+  }
+  
+  /**
+   * 1-D.  Non-empty values of the concatenated or hashed
+   * `SparseTensor`.
+   */
+  public Output<T> outputValues() {
+    return outputValues;
+  }
+  
+  /**
+   * 1-D.  Shape of the concatenated `SparseTensor`.
+   */
+  public Output<Long> outputShape() {
+    return outputShape;
+  }
+  
+  private Output<Long> outputIndices;
+  private Output<T> outputValues;
+  private Output<Long> outputShape;
+  
+  private SparseCross(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    outputIndices = operation.output(outputIdx++);
+    outputValues = operation.output(outputIdx++);
+    outputShape = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseDenseCwiseAdd.java java-ops/org/tensorflow/op/core/SparseDenseCwiseAdd.java
--- java/org/tensorflow/op/core/SparseDenseCwiseAdd.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseDenseCwiseAdd.java	2018-10-16 20:18:38.541432164 +0900
@@ -0,0 +1,84 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Adds up a SparseTensor and a dense Tensor, using these special rules:
+ * <p>
+ * (1) Broadcasts the dense side to have the same shape as the sparse side, if
+ *     eligible;
+ * (2) Then, only the dense values pointed to by the indices of the SparseTensor
+ *     participate in the cwise addition.
+ * <p>
+ * By these rules, the result is a logical SparseTensor with exactly the same
+ * indices and shape, but possibly with different non-zero values.  The output of
+ * this Op is the resultant non-zero values.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class SparseDenseCwiseAdd<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new SparseDenseCwiseAdd operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param spIndices 2-D.  `N x R` matrix with the indices of non-empty values in a
+   * SparseTensor, possibly not in canonical ordering.
+   * @param spValues 1-D.  `N` non-empty values corresponding to `sp_indices`.
+   * @param spShape 1-D.  Shape of the input SparseTensor.
+   * @param dense `R`-D.  The dense Tensor operand.
+   * @return a new instance of SparseDenseCwiseAdd
+   */
+  public static <T> SparseDenseCwiseAdd<T> create(Scope scope, Operand<Long> spIndices, Operand<T> spValues, Operand<Long> spShape, Operand<T> dense) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseDenseCwiseAdd", scope.makeOpName("SparseDenseCwiseAdd"));
+    opBuilder.addInput(spIndices.asOutput());
+    opBuilder.addInput(spValues.asOutput());
+    opBuilder.addInput(spShape.asOutput());
+    opBuilder.addInput(dense.asOutput());
+    return new SparseDenseCwiseAdd<T>(opBuilder.build());
+  }
+  
+  /**
+   * 1-D.  The `N` values that are operated on.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private SparseDenseCwiseAdd(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseDenseCwiseDiv.java java-ops/org/tensorflow/op/core/SparseDenseCwiseDiv.java
--- java/org/tensorflow/op/core/SparseDenseCwiseDiv.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseDenseCwiseDiv.java	2018-10-16 20:18:38.541432164 +0900
@@ -0,0 +1,78 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Component-wise divides a SparseTensor by a dense Tensor.
+ * <p>
+ * <i>Limitation</i>: this Op only broadcasts the dense side to the sparse side, but not
+ * the other direction.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class SparseDenseCwiseDiv<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new SparseDenseCwiseDiv operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param spIndices 2-D.  `N x R` matrix with the indices of non-empty values in a
+   * SparseTensor, possibly not in canonical ordering.
+   * @param spValues 1-D.  `N` non-empty values corresponding to `sp_indices`.
+   * @param spShape 1-D.  Shape of the input SparseTensor.
+   * @param dense `R`-D.  The dense Tensor operand.
+   * @return a new instance of SparseDenseCwiseDiv
+   */
+  public static <T> SparseDenseCwiseDiv<T> create(Scope scope, Operand<Long> spIndices, Operand<T> spValues, Operand<Long> spShape, Operand<T> dense) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseDenseCwiseDiv", scope.makeOpName("SparseDenseCwiseDiv"));
+    opBuilder.addInput(spIndices.asOutput());
+    opBuilder.addInput(spValues.asOutput());
+    opBuilder.addInput(spShape.asOutput());
+    opBuilder.addInput(dense.asOutput());
+    return new SparseDenseCwiseDiv<T>(opBuilder.build());
+  }
+  
+  /**
+   * 1-D.  The `N` values that are operated on.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private SparseDenseCwiseDiv(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseDenseCwiseMul.java java-ops/org/tensorflow/op/core/SparseDenseCwiseMul.java
--- java/org/tensorflow/op/core/SparseDenseCwiseMul.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseDenseCwiseMul.java	2018-10-16 20:18:38.542432164 +0900
@@ -0,0 +1,82 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Component-wise multiplies a SparseTensor by a dense Tensor.
+ * <p>
+ * The output locations corresponding to the implicitly zero elements in the sparse
+ * tensor will be zero (i.e., will not take up storage space), regardless of the
+ * contents of the dense tensor (even if it's +/-INF and that INF<i>0 == NaN).
+ * <p>
+ * </i>Limitation*: this Op only broadcasts the dense side to the sparse side, but not
+ * the other direction.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class SparseDenseCwiseMul<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new SparseDenseCwiseMul operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param spIndices 2-D.  `N x R` matrix with the indices of non-empty values in a
+   * SparseTensor, possibly not in canonical ordering.
+   * @param spValues 1-D.  `N` non-empty values corresponding to `sp_indices`.
+   * @param spShape 1-D.  Shape of the input SparseTensor.
+   * @param dense `R`-D.  The dense Tensor operand.
+   * @return a new instance of SparseDenseCwiseMul
+   */
+  public static <T> SparseDenseCwiseMul<T> create(Scope scope, Operand<Long> spIndices, Operand<T> spValues, Operand<Long> spShape, Operand<T> dense) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseDenseCwiseMul", scope.makeOpName("SparseDenseCwiseMul"));
+    opBuilder.addInput(spIndices.asOutput());
+    opBuilder.addInput(spValues.asOutput());
+    opBuilder.addInput(spShape.asOutput());
+    opBuilder.addInput(dense.asOutput());
+    return new SparseDenseCwiseMul<T>(opBuilder.build());
+  }
+  
+  /**
+   * 1-D.  The `N` values that are operated on.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private SparseDenseCwiseMul(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseFillEmptyRowsGrad.java java-ops/org/tensorflow/op/core/SparseFillEmptyRowsGrad.java
--- java/org/tensorflow/op/core/SparseFillEmptyRowsGrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseFillEmptyRowsGrad.java	2018-10-16 20:18:38.544432162 +0900
@@ -0,0 +1,83 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * The gradient of SparseFillEmptyRows.
+ * <p>
+ * Takes vectors reverse_index_map, shaped `[N]`, and grad_values,
+ * shaped `[N_full]`, where `N_full >= N` and copies data into either
+ * `d_values` or `d_default_value`.  Here `d_values` is shaped `[N]` and
+ * `d_default_value` is a scalar.
+ * <p>
+ *   d_values[j] = grad_values[reverse_index_map[j]]
+ *   d_default_value = sum_{k : 0 .. N_full - 1} (
+ *      grad_values[k] * 1{k not in reverse_index_map})
+ * 
+ * @param <T> data type for {@code dValues()} output
+ */
+@Operator
+public final class SparseFillEmptyRowsGrad<T> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new SparseFillEmptyRowsGrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param reverseIndexMap 1-D.  The reverse index map from SparseFillEmptyRows.
+   * @param gradValues 1-D.  The gradients from backprop.
+   * @return a new instance of SparseFillEmptyRowsGrad
+   */
+  public static <T> SparseFillEmptyRowsGrad<T> create(Scope scope, Operand<Long> reverseIndexMap, Operand<T> gradValues) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseFillEmptyRowsGrad", scope.makeOpName("SparseFillEmptyRowsGrad"));
+    opBuilder.addInput(reverseIndexMap.asOutput());
+    opBuilder.addInput(gradValues.asOutput());
+    return new SparseFillEmptyRowsGrad<T>(opBuilder.build());
+  }
+  
+  /**
+   * 1-D.  The backprop into values.
+   */
+  public Output<T> dValues() {
+    return dValues;
+  }
+  
+  /**
+   * 0-D.  The backprop into default_value.
+   */
+  public Output<T> dDefaultValue() {
+    return dDefaultValue;
+  }
+  
+  private Output<T> dValues;
+  private Output<T> dDefaultValue;
+  
+  private SparseFillEmptyRowsGrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    dValues = operation.output(outputIdx++);
+    dDefaultValue = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseFillEmptyRows.java java-ops/org/tensorflow/op/core/SparseFillEmptyRows.java
--- java/org/tensorflow/op/core/SparseFillEmptyRows.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseFillEmptyRows.java	2018-10-16 20:18:38.543432163 +0900
@@ -0,0 +1,135 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Fills empty rows in the input 2-D `SparseTensor` with a default value.
+ * <p>
+ * The input `SparseTensor` is represented via the tuple of inputs
+ * (`indices`, `values`, `dense_shape`).  The output `SparseTensor` has the
+ * same `dense_shape` but with indices `output_indices` and values
+ * `output_values`.
+ * <p>
+ * This op inserts a single entry for every row that doesn't have any values.
+ * The index is created as `[row, 0, ..., 0]` and the inserted value
+ * is `default_value`.
+ * <p>
+ * For example, suppose `sp_input` has shape `[5, 6]` and non-empty values:
+ * <p>
+ *     [0, 1]: a
+ *     [0, 3]: b
+ *     [2, 0]: c
+ *     [3, 1]: d
+ * <p>
+ * Rows 1 and 4 are empty, so the output will be of shape `[5, 6]` with values:
+ * <p>
+ *     [0, 1]: a
+ *     [0, 3]: b
+ *     [1, 0]: default_value
+ *     [2, 0]: c
+ *     [3, 1]: d
+ *     [4, 0]: default_value
+ * <p>
+ * The output `SparseTensor` will be in row-major order and will have the
+ * same shape as the input.
+ * <p>
+ * This op also returns an indicator vector shaped `[dense_shape[0]]` such that
+ * <p>
+ *     empty_row_indicator[i] = True iff row i was an empty row.
+ * <p>
+ * And a reverse index map vector shaped `[indices.shape[0]]` that is used during
+ * backpropagation,
+ * <p>
+ *     reverse_index_map[j] = out_j s.t. indices[j, :] == output_indices[out_j, :]
+ * 
+ * @param <T> data type for {@code outputValues()} output
+ */
+@Operator
+public final class SparseFillEmptyRows<T> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new SparseFillEmptyRows operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param indices 2-D. the indices of the sparse tensor.
+   * @param values 1-D. the values of the sparse tensor.
+   * @param denseShape 1-D. the shape of the sparse tensor.
+   * @param defaultValue 0-D. default value to insert into location `[row, 0, ..., 0]`
+   *   for rows missing from the input sparse tensor.
+   * output indices: 2-D. the indices of the filled sparse tensor.
+   * @return a new instance of SparseFillEmptyRows
+   */
+  public static <T> SparseFillEmptyRows<T> create(Scope scope, Operand<Long> indices, Operand<T> values, Operand<Long> denseShape, Operand<T> defaultValue) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseFillEmptyRows", scope.makeOpName("SparseFillEmptyRows"));
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(values.asOutput());
+    opBuilder.addInput(denseShape.asOutput());
+    opBuilder.addInput(defaultValue.asOutput());
+    return new SparseFillEmptyRows<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<Long> outputIndices() {
+    return outputIndices;
+  }
+  
+  /**
+   * 1-D. the values of the filled sparse tensor.
+   */
+  public Output<T> outputValues() {
+    return outputValues;
+  }
+  
+  /**
+   * 1-D. whether the dense row was missing in the
+   * input sparse tensor.
+   */
+  public Output<Boolean> emptyRowIndicator() {
+    return emptyRowIndicator;
+  }
+  
+  /**
+   * 1-D. a map from the input indices to the output indices.
+   */
+  public Output<Long> reverseIndexMap() {
+    return reverseIndexMap;
+  }
+  
+  private Output<Long> outputIndices;
+  private Output<T> outputValues;
+  private Output<Boolean> emptyRowIndicator;
+  private Output<Long> reverseIndexMap;
+  
+  private SparseFillEmptyRows(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    outputIndices = operation.output(outputIdx++);
+    outputValues = operation.output(outputIdx++);
+    emptyRowIndicator = operation.output(outputIdx++);
+    reverseIndexMap = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseMatMul.java java-ops/org/tensorflow/op/core/SparseMatMul.java
--- java/org/tensorflow/op/core/SparseMatMul.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseMatMul.java	2018-10-16 20:18:38.544432162 +0900
@@ -0,0 +1,168 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Multiply matrix "a" by matrix "b".
+ * <p>
+ * The inputs must be two-dimensional matrices and the inner dimension of "a" must
+ * match the outer dimension of "b". Both "a" and "b" must be `Tensor`s not
+ * `SparseTensor`s.  This op is optimized for the case where at least one of "a" or
+ * "b" is sparse, in the sense that they have a large proportion of zero values.
+ * The breakeven for using this versus a dense matrix multiply on one platform was
+ * 30% zero values in the sparse matrix.
+ * <p>
+ * The gradient computation of this operation will only take advantage of sparsity
+ * in the input gradient when that gradient comes from a Relu.
+ */
+@Operator
+public final class SparseMatMul extends PrimitiveOp implements Operand<Float> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.SparseMatMul}
+   */
+  public static class Options {
+    
+    /**
+     * @param transposeA 
+     */
+    public Options transposeA(Boolean transposeA) {
+      this.transposeA = transposeA;
+      return this;
+    }
+    
+    /**
+     * @param transposeB 
+     */
+    public Options transposeB(Boolean transposeB) {
+      this.transposeB = transposeB;
+      return this;
+    }
+    
+    /**
+     * @param aIsSparse 
+     */
+    public Options aIsSparse(Boolean aIsSparse) {
+      this.aIsSparse = aIsSparse;
+      return this;
+    }
+    
+    /**
+     * @param bIsSparse 
+     */
+    public Options bIsSparse(Boolean bIsSparse) {
+      this.bIsSparse = bIsSparse;
+      return this;
+    }
+    
+    private Boolean transposeA;
+    private Boolean transposeB;
+    private Boolean aIsSparse;
+    private Boolean bIsSparse;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new SparseMatMul operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param a 
+   * @param b 
+   * @param options carries optional attributes values
+   * @return a new instance of SparseMatMul
+   */
+  public static <T extends Number, U extends Number> SparseMatMul create(Scope scope, Operand<T> a, Operand<U> b, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseMatMul", scope.makeOpName("SparseMatMul"));
+    opBuilder.addInput(a.asOutput());
+    opBuilder.addInput(b.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.transposeA != null) {
+          opBuilder.setAttr("transpose_a", opts.transposeA);
+        }
+        if (opts.transposeB != null) {
+          opBuilder.setAttr("transpose_b", opts.transposeB);
+        }
+        if (opts.aIsSparse != null) {
+          opBuilder.setAttr("a_is_sparse", opts.aIsSparse);
+        }
+        if (opts.bIsSparse != null) {
+          opBuilder.setAttr("b_is_sparse", opts.bIsSparse);
+        }
+      }
+    }
+    return new SparseMatMul(opBuilder.build());
+  }
+  
+  /**
+   * @param transposeA 
+   */
+  public static Options transposeA(Boolean transposeA) {
+    return new Options().transposeA(transposeA);
+  }
+  
+  /**
+   * @param transposeB 
+   */
+  public static Options transposeB(Boolean transposeB) {
+    return new Options().transposeB(transposeB);
+  }
+  
+  /**
+   * @param aIsSparse 
+   */
+  public static Options aIsSparse(Boolean aIsSparse) {
+    return new Options().aIsSparse(aIsSparse);
+  }
+  
+  /**
+   * @param bIsSparse 
+   */
+  public static Options bIsSparse(Boolean bIsSparse) {
+    return new Options().bIsSparse(bIsSparse);
+  }
+  
+  /**
+   */
+  public Output<Float> product() {
+    return product;
+  }
+  
+  @Override
+  public Output<Float> asOutput() {
+    return product;
+  }
+  
+  private Output<Float> product;
+  
+  private SparseMatMul(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    product = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseReduceMax.java java-ops/org/tensorflow/op/core/SparseReduceMax.java
--- java/org/tensorflow/op/core/SparseReduceMax.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseReduceMax.java	2018-10-16 20:18:38.545432161 +0900
@@ -0,0 +1,122 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the max of elements across dimensions of a SparseTensor.
+ * <p>
+ * This Op takes a SparseTensor and is the sparse counterpart to
+ * `tf.reduce_max()`.  In particular, this Op also returns a dense `Tensor`
+ * instead of a sparse one.
+ * <p>
+ * Reduces `sp_input` along the dimensions given in `reduction_axes`.  Unless
+ * `keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
+ * `reduction_axes`. If `keep_dims` is true, the reduced dimensions are retained
+ * with length 1.
+ * <p>
+ * If `reduction_axes` has no entries, all dimensions are reduced, and a tensor
+ * with a single element is returned.  Additionally, the axes can be negative,
+ * which are interpreted according to the indexing rules in Python.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class SparseReduceMax<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.SparseReduceMax}
+   */
+  public static class Options {
+    
+    /**
+     * @param keepDims If true, retain reduced dimensions with length 1.
+     */
+    public Options keepDims(Boolean keepDims) {
+      this.keepDims = keepDims;
+      return this;
+    }
+    
+    private Boolean keepDims;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new SparseReduceMax operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputIndices 2-D.  `N x R` matrix with the indices of non-empty values in a
+   * SparseTensor, possibly not in canonical ordering.
+   * @param inputValues 1-D.  `N` non-empty values corresponding to `input_indices`.
+   * @param inputShape 1-D.  Shape of the input SparseTensor.
+   * @param reductionAxes 1-D.  Length-`K` vector containing the reduction axes.
+   * @param options carries optional attributes values
+   * @return a new instance of SparseReduceMax
+   */
+  public static <T extends Number> SparseReduceMax<T> create(Scope scope, Operand<Long> inputIndices, Operand<T> inputValues, Operand<Long> inputShape, Operand<Integer> reductionAxes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseReduceMax", scope.makeOpName("SparseReduceMax"));
+    opBuilder.addInput(inputIndices.asOutput());
+    opBuilder.addInput(inputValues.asOutput());
+    opBuilder.addInput(inputShape.asOutput());
+    opBuilder.addInput(reductionAxes.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.keepDims != null) {
+          opBuilder.setAttr("keep_dims", opts.keepDims);
+        }
+      }
+    }
+    return new SparseReduceMax<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param keepDims If true, retain reduced dimensions with length 1.
+   */
+  public static Options keepDims(Boolean keepDims) {
+    return new Options().keepDims(keepDims);
+  }
+  
+  /**
+   * `R-K`-D.  The reduced Tensor.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private SparseReduceMax(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseReduceMaxSparse.java java-ops/org/tensorflow/op/core/SparseReduceMaxSparse.java
--- java/org/tensorflow/op/core/SparseReduceMaxSparse.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseReduceMaxSparse.java	2018-10-16 20:18:38.546432161 +0900
@@ -0,0 +1,132 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the max of elements across dimensions of a SparseTensor.
+ * <p>
+ * This Op takes a SparseTensor and is the sparse counterpart to
+ * `tf.reduce_max()`.  In contrast to SparseReduceMax, this Op returns a
+ * SparseTensor.
+ * <p>
+ * Reduces `sp_input` along the dimensions given in `reduction_axes`.  Unless
+ * `keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
+ * `reduction_axes`. If `keep_dims` is true, the reduced dimensions are retained
+ * with length 1.
+ * <p>
+ * If `reduction_axes` has no entries, all dimensions are reduced, and a tensor
+ * with a single element is returned.  Additionally, the axes can be negative,
+ * which are interpreted according to the indexing rules in Python.
+ * 
+ * @param <T> data type for {@code outputValues()} output
+ */
+@Operator
+public final class SparseReduceMaxSparse<T extends Number> extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.SparseReduceMaxSparse}
+   */
+  public static class Options {
+    
+    /**
+     * @param keepDims If true, retain reduced dimensions with length 1.
+     */
+    public Options keepDims(Boolean keepDims) {
+      this.keepDims = keepDims;
+      return this;
+    }
+    
+    private Boolean keepDims;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new SparseReduceMaxSparse operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputIndices 2-D.  `N x R` matrix with the indices of non-empty values in a
+   * SparseTensor, possibly not in canonical ordering.
+   * @param inputValues 1-D.  `N` non-empty values corresponding to `input_indices`.
+   * @param inputShape 1-D.  Shape of the input SparseTensor.
+   * @param reductionAxes 1-D.  Length-`K` vector containing the reduction axes.
+   * @param options carries optional attributes values
+   * @return a new instance of SparseReduceMaxSparse
+   */
+  public static <T extends Number> SparseReduceMaxSparse<T> create(Scope scope, Operand<Long> inputIndices, Operand<T> inputValues, Operand<Long> inputShape, Operand<Integer> reductionAxes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseReduceMaxSparse", scope.makeOpName("SparseReduceMaxSparse"));
+    opBuilder.addInput(inputIndices.asOutput());
+    opBuilder.addInput(inputValues.asOutput());
+    opBuilder.addInput(inputShape.asOutput());
+    opBuilder.addInput(reductionAxes.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.keepDims != null) {
+          opBuilder.setAttr("keep_dims", opts.keepDims);
+        }
+      }
+    }
+    return new SparseReduceMaxSparse<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param keepDims If true, retain reduced dimensions with length 1.
+   */
+  public static Options keepDims(Boolean keepDims) {
+    return new Options().keepDims(keepDims);
+  }
+  
+  /**
+   */
+  public Output<Long> outputIndices() {
+    return outputIndices;
+  }
+  
+  /**
+   */
+  public Output<T> outputValues() {
+    return outputValues;
+  }
+  
+  /**
+   */
+  public Output<Long> outputShape() {
+    return outputShape;
+  }
+  
+  private Output<Long> outputIndices;
+  private Output<T> outputValues;
+  private Output<Long> outputShape;
+  
+  private SparseReduceMaxSparse(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    outputIndices = operation.output(outputIdx++);
+    outputValues = operation.output(outputIdx++);
+    outputShape = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseReduceSum.java java-ops/org/tensorflow/op/core/SparseReduceSum.java
--- java/org/tensorflow/op/core/SparseReduceSum.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseReduceSum.java	2018-10-16 20:18:38.547432160 +0900
@@ -0,0 +1,122 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the sum of elements across dimensions of a SparseTensor.
+ * <p>
+ * This Op takes a SparseTensor and is the sparse counterpart to
+ * `tf.reduce_sum()`.  In particular, this Op also returns a dense `Tensor`
+ * instead of a sparse one.
+ * <p>
+ * Reduces `sp_input` along the dimensions given in `reduction_axes`.  Unless
+ * `keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
+ * `reduction_axes`. If `keep_dims` is true, the reduced dimensions are retained
+ * with length 1.
+ * <p>
+ * If `reduction_axes` has no entries, all dimensions are reduced, and a tensor
+ * with a single element is returned.  Additionally, the axes can be negative,
+ * which are interpreted according to the indexing rules in Python.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class SparseReduceSum<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.SparseReduceSum}
+   */
+  public static class Options {
+    
+    /**
+     * @param keepDims If true, retain reduced dimensions with length 1.
+     */
+    public Options keepDims(Boolean keepDims) {
+      this.keepDims = keepDims;
+      return this;
+    }
+    
+    private Boolean keepDims;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new SparseReduceSum operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputIndices 2-D.  `N x R` matrix with the indices of non-empty values in a
+   * SparseTensor, possibly not in canonical ordering.
+   * @param inputValues 1-D.  `N` non-empty values corresponding to `input_indices`.
+   * @param inputShape 1-D.  Shape of the input SparseTensor.
+   * @param reductionAxes 1-D.  Length-`K` vector containing the reduction axes.
+   * @param options carries optional attributes values
+   * @return a new instance of SparseReduceSum
+   */
+  public static <T> SparseReduceSum<T> create(Scope scope, Operand<Long> inputIndices, Operand<T> inputValues, Operand<Long> inputShape, Operand<Integer> reductionAxes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseReduceSum", scope.makeOpName("SparseReduceSum"));
+    opBuilder.addInput(inputIndices.asOutput());
+    opBuilder.addInput(inputValues.asOutput());
+    opBuilder.addInput(inputShape.asOutput());
+    opBuilder.addInput(reductionAxes.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.keepDims != null) {
+          opBuilder.setAttr("keep_dims", opts.keepDims);
+        }
+      }
+    }
+    return new SparseReduceSum<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param keepDims If true, retain reduced dimensions with length 1.
+   */
+  public static Options keepDims(Boolean keepDims) {
+    return new Options().keepDims(keepDims);
+  }
+  
+  /**
+   * `R-K`-D.  The reduced Tensor.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private SparseReduceSum(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseReduceSumSparse.java java-ops/org/tensorflow/op/core/SparseReduceSumSparse.java
--- java/org/tensorflow/op/core/SparseReduceSumSparse.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseReduceSumSparse.java	2018-10-16 20:18:38.547432160 +0900
@@ -0,0 +1,132 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the sum of elements across dimensions of a SparseTensor.
+ * <p>
+ * This Op takes a SparseTensor and is the sparse counterpart to
+ * `tf.reduce_sum()`.  In contrast to SparseReduceSum, this Op returns a
+ * SparseTensor.
+ * <p>
+ * Reduces `sp_input` along the dimensions given in `reduction_axes`.  Unless
+ * `keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
+ * `reduction_axes`. If `keep_dims` is true, the reduced dimensions are retained
+ * with length 1.
+ * <p>
+ * If `reduction_axes` has no entries, all dimensions are reduced, and a tensor
+ * with a single element is returned.  Additionally, the axes can be negative,
+ * which are interpreted according to the indexing rules in Python.
+ * 
+ * @param <T> data type for {@code outputValues()} output
+ */
+@Operator
+public final class SparseReduceSumSparse<T> extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.SparseReduceSumSparse}
+   */
+  public static class Options {
+    
+    /**
+     * @param keepDims If true, retain reduced dimensions with length 1.
+     */
+    public Options keepDims(Boolean keepDims) {
+      this.keepDims = keepDims;
+      return this;
+    }
+    
+    private Boolean keepDims;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new SparseReduceSumSparse operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputIndices 2-D.  `N x R` matrix with the indices of non-empty values in a
+   * SparseTensor, possibly not in canonical ordering.
+   * @param inputValues 1-D.  `N` non-empty values corresponding to `input_indices`.
+   * @param inputShape 1-D.  Shape of the input SparseTensor.
+   * @param reductionAxes 1-D.  Length-`K` vector containing the reduction axes.
+   * @param options carries optional attributes values
+   * @return a new instance of SparseReduceSumSparse
+   */
+  public static <T> SparseReduceSumSparse<T> create(Scope scope, Operand<Long> inputIndices, Operand<T> inputValues, Operand<Long> inputShape, Operand<Integer> reductionAxes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseReduceSumSparse", scope.makeOpName("SparseReduceSumSparse"));
+    opBuilder.addInput(inputIndices.asOutput());
+    opBuilder.addInput(inputValues.asOutput());
+    opBuilder.addInput(inputShape.asOutput());
+    opBuilder.addInput(reductionAxes.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.keepDims != null) {
+          opBuilder.setAttr("keep_dims", opts.keepDims);
+        }
+      }
+    }
+    return new SparseReduceSumSparse<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param keepDims If true, retain reduced dimensions with length 1.
+   */
+  public static Options keepDims(Boolean keepDims) {
+    return new Options().keepDims(keepDims);
+  }
+  
+  /**
+   */
+  public Output<Long> outputIndices() {
+    return outputIndices;
+  }
+  
+  /**
+   */
+  public Output<T> outputValues() {
+    return outputValues;
+  }
+  
+  /**
+   */
+  public Output<Long> outputShape() {
+    return outputShape;
+  }
+  
+  private Output<Long> outputIndices;
+  private Output<T> outputValues;
+  private Output<Long> outputShape;
+  
+  private SparseReduceSumSparse(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    outputIndices = operation.output(outputIdx++);
+    outputValues = operation.output(outputIdx++);
+    outputShape = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseReorder.java java-ops/org/tensorflow/op/core/SparseReorder.java
--- java/org/tensorflow/op/core/SparseReorder.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseReorder.java	2018-10-16 20:18:38.548432159 +0900
@@ -0,0 +1,87 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Reorders a SparseTensor into the canonical, row-major ordering.
+ * <p>
+ * Note that by convention, all sparse ops preserve the canonical ordering along
+ * increasing dimension number. The only time ordering can be violated is during
+ * manual manipulation of the indices and values vectors to add entries.
+ * <p>
+ * Reordering does not affect the shape of the SparseTensor.
+ * <p>
+ * If the tensor has rank `R` and `N` non-empty values, `input_indices` has
+ * shape `[N, R]`, input_values has length `N`, and input_shape has length `R`.
+ * 
+ * @param <T> data type for {@code outputValues()} output
+ */
+@Operator
+public final class SparseReorder<T> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new SparseReorder operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputIndices 2-D.  `N x R` matrix with the indices of non-empty values in a
+   * SparseTensor, possibly not in canonical ordering.
+   * @param inputValues 1-D.  `N` non-empty values corresponding to `input_indices`.
+   * @param inputShape 1-D.  Shape of the input SparseTensor.
+   * @return a new instance of SparseReorder
+   */
+  public static <T> SparseReorder<T> create(Scope scope, Operand<Long> inputIndices, Operand<T> inputValues, Operand<Long> inputShape) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseReorder", scope.makeOpName("SparseReorder"));
+    opBuilder.addInput(inputIndices.asOutput());
+    opBuilder.addInput(inputValues.asOutput());
+    opBuilder.addInput(inputShape.asOutput());
+    return new SparseReorder<T>(opBuilder.build());
+  }
+  
+  /**
+   * 2-D.  `N x R` matrix with the same indices as input_indices, but
+   * in canonical row-major ordering.
+   */
+  public Output<Long> outputIndices() {
+    return outputIndices;
+  }
+  
+  /**
+   * 1-D.  `N` non-empty values corresponding to `output_indices`.
+   */
+  public Output<T> outputValues() {
+    return outputValues;
+  }
+  
+  private Output<Long> outputIndices;
+  private Output<T> outputValues;
+  
+  private SparseReorder(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    outputIndices = operation.output(outputIdx++);
+    outputValues = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseReshape.java java-ops/org/tensorflow/op/core/SparseReshape.java
--- java/org/tensorflow/op/core/SparseReshape.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseReshape.java	2018-10-16 20:18:38.549432158 +0900
@@ -0,0 +1,94 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Reshapes a SparseTensor to represent values in a new dense shape.
+ * <p>
+ * This operation has the same semantics as reshape on the represented dense
+ * tensor.  The `input_indices` are recomputed based on the requested `new_shape`.
+ * <p>
+ * If one component of `new_shape` is the special value -1, the size of that
+ * dimension is computed so that the total dense size remains constant.  At
+ * most one component of `new_shape` can be -1.  The number of dense elements
+ * implied by `new_shape` must be the same as the number of dense elements
+ * originally implied by `input_shape`.
+ * <p>
+ * Reshaping does not affect the order of values in the SparseTensor.
+ * <p>
+ * If the input tensor has rank `R_in` and `N` non-empty values, and `new_shape`
+ * has length `R_out`, then `input_indices` has shape `[N, R_in]`,
+ * `input_shape` has length `R_in`, `output_indices` has shape `[N, R_out]`, and
+ * `output_shape` has length `R_out`.
+ */
+@Operator
+public final class SparseReshape extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new SparseReshape operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputIndices 2-D.  `N x R_in` matrix with the indices of non-empty values in a
+   * SparseTensor.
+   * @param inputShape 1-D.  `R_in` vector with the input SparseTensor's dense shape.
+   * @param newShape 1-D.  `R_out` vector with the requested new dense shape.
+   * @return a new instance of SparseReshape
+   */
+  public static SparseReshape create(Scope scope, Operand<Long> inputIndices, Operand<Long> inputShape, Operand<Long> newShape) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseReshape", scope.makeOpName("SparseReshape"));
+    opBuilder.addInput(inputIndices.asOutput());
+    opBuilder.addInput(inputShape.asOutput());
+    opBuilder.addInput(newShape.asOutput());
+    return new SparseReshape(opBuilder.build());
+  }
+  
+  /**
+   * 2-D.  `N x R_out` matrix with the updated indices of non-empty
+   * values in the output SparseTensor.
+   */
+  public Output<Long> outputIndices() {
+    return outputIndices;
+  }
+  
+  /**
+   * 1-D.  `R_out` vector with the full dense shape of the output
+   * SparseTensor.  This is the same as `new_shape` but with any -1 dimensions
+   * filled in.
+   */
+  public Output<Long> outputShape() {
+    return outputShape;
+  }
+  
+  private Output<Long> outputIndices;
+  private Output<Long> outputShape;
+  
+  private SparseReshape(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    outputIndices = operation.output(outputIdx++);
+    outputShape = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseSegmentMeanGrad.java java-ops/org/tensorflow/op/core/SparseSegmentMeanGrad.java
--- java/org/tensorflow/op/core/SparseSegmentMeanGrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseSegmentMeanGrad.java	2018-10-16 20:18:38.550432158 +0900
@@ -0,0 +1,76 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes gradients for SparseSegmentMean.
+ * <p>
+ * Returns tensor "output" with same shape as grad, except for dimension 0 whose
+ * value is output_dim0.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class SparseSegmentMeanGrad<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new SparseSegmentMeanGrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param grad gradient propagated to the SparseSegmentMean op.
+   * @param indices indices passed to the corresponding SparseSegmentMean op.
+   * @param segmentIds segment_ids passed to the corresponding SparseSegmentMean op.
+   * @param outputDim0 dimension 0 of "data" passed to SparseSegmentMean op.
+   * @return a new instance of SparseSegmentMeanGrad
+   */
+  public static <T extends Number, U extends Number> SparseSegmentMeanGrad<T> create(Scope scope, Operand<T> grad, Operand<U> indices, Operand<Integer> segmentIds, Operand<Integer> outputDim0) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseSegmentMeanGrad", scope.makeOpName("SparseSegmentMeanGrad"));
+    opBuilder.addInput(grad.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(segmentIds.asOutput());
+    opBuilder.addInput(outputDim0.asOutput());
+    return new SparseSegmentMeanGrad<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private SparseSegmentMeanGrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseSegmentMean.java java-ops/org/tensorflow/op/core/SparseSegmentMean.java
--- java/org/tensorflow/op/core/SparseSegmentMean.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseSegmentMean.java	2018-10-16 20:18:38.549432158 +0900
@@ -0,0 +1,80 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the mean along sparse segments of a tensor.
+ * <p>
+ * Read
+ * [the section on segmentation](https://tensorflow.org/api_guides/python/math_ops#Segmentation)
+ * for an explanation of segments.
+ * <p>
+ * Like `SegmentMean`, but `segment_ids` can have rank less than `data`'s first
+ * dimension, selecting a subset of dimension 0, specified by `indices`.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class SparseSegmentMean<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new SparseSegmentMean operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param data 
+   * @param indices A 1-D tensor. Has same rank as `segment_ids`.
+   * @param segmentIds A 1-D tensor. Values should be sorted and can be repeated.
+   * @return a new instance of SparseSegmentMean
+   */
+  public static <T extends Number, U extends Number> SparseSegmentMean<T> create(Scope scope, Operand<T> data, Operand<U> indices, Operand<Integer> segmentIds) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseSegmentMean", scope.makeOpName("SparseSegmentMean"));
+    opBuilder.addInput(data.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(segmentIds.asOutput());
+    return new SparseSegmentMean<T>(opBuilder.build());
+  }
+  
+  /**
+   * Has same shape as data, except for dimension 0 which
+   * has size `k`, the number of segments.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private SparseSegmentMean(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseSegmentMeanWithNumSegments.java java-ops/org/tensorflow/op/core/SparseSegmentMeanWithNumSegments.java
--- java/org/tensorflow/op/core/SparseSegmentMeanWithNumSegments.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseSegmentMeanWithNumSegments.java	2018-10-16 20:18:38.550432158 +0900
@@ -0,0 +1,82 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the mean along sparse segments of a tensor.
+ * <p>
+ * Like `SparseSegmentMean`, but allows missing ids in `segment_ids`. If an id is
+ * misisng, the `output` tensor at that position will be zeroed.
+ * <p>
+ * Read
+ * [the section on segmentation](https://tensorflow.org/api_guides/python/math_ops#Segmentation)
+ * for an explanation of segments.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class SparseSegmentMeanWithNumSegments<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new SparseSegmentMeanWithNumSegments operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param data 
+   * @param indices A 1-D tensor. Has same rank as `segment_ids`.
+   * @param segmentIds A 1-D tensor. Values should be sorted and can be repeated.
+   * @param numSegments Should equal the number of distinct segment IDs.
+   * @return a new instance of SparseSegmentMeanWithNumSegments
+   */
+  public static <T extends Number, U extends Number, V extends Number> SparseSegmentMeanWithNumSegments<T> create(Scope scope, Operand<T> data, Operand<U> indices, Operand<Integer> segmentIds, Operand<V> numSegments) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseSegmentMeanWithNumSegments", scope.makeOpName("SparseSegmentMeanWithNumSegments"));
+    opBuilder.addInput(data.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(segmentIds.asOutput());
+    opBuilder.addInput(numSegments.asOutput());
+    return new SparseSegmentMeanWithNumSegments<T>(opBuilder.build());
+  }
+  
+  /**
+   * Has same shape as data, except for dimension 0 which has size
+   * `num_segments`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private SparseSegmentMeanWithNumSegments(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseSegmentSqrtNGrad.java java-ops/org/tensorflow/op/core/SparseSegmentSqrtNGrad.java
--- java/org/tensorflow/op/core/SparseSegmentSqrtNGrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseSegmentSqrtNGrad.java	2018-10-16 20:18:38.551432157 +0900
@@ -0,0 +1,76 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes gradients for SparseSegmentSqrtN.
+ * <p>
+ * Returns tensor "output" with same shape as grad, except for dimension 0 whose
+ * value is output_dim0.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class SparseSegmentSqrtNGrad<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new SparseSegmentSqrtNGrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param grad gradient propagated to the SparseSegmentSqrtN op.
+   * @param indices indices passed to the corresponding SparseSegmentSqrtN op.
+   * @param segmentIds segment_ids passed to the corresponding SparseSegmentSqrtN op.
+   * @param outputDim0 dimension 0 of "data" passed to SparseSegmentSqrtN op.
+   * @return a new instance of SparseSegmentSqrtNGrad
+   */
+  public static <T extends Number, U extends Number> SparseSegmentSqrtNGrad<T> create(Scope scope, Operand<T> grad, Operand<U> indices, Operand<Integer> segmentIds, Operand<Integer> outputDim0) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseSegmentSqrtNGrad", scope.makeOpName("SparseSegmentSqrtNGrad"));
+    opBuilder.addInput(grad.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(segmentIds.asOutput());
+    opBuilder.addInput(outputDim0.asOutput());
+    return new SparseSegmentSqrtNGrad<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private SparseSegmentSqrtNGrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseSegmentSqrtN.java java-ops/org/tensorflow/op/core/SparseSegmentSqrtN.java
--- java/org/tensorflow/op/core/SparseSegmentSqrtN.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseSegmentSqrtN.java	2018-10-16 20:18:38.551432157 +0900
@@ -0,0 +1,79 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the sum along sparse segments of a tensor divided by the sqrt of N.
+ * <p>
+ * N is the size of the segment being reduced.
+ * <p>
+ * Read
+ * [the section on segmentation](https://tensorflow.org/api_guides/python/math_ops#Segmentation)
+ * for an explanation of segments.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class SparseSegmentSqrtN<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new SparseSegmentSqrtN operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param data 
+   * @param indices A 1-D tensor. Has same rank as `segment_ids`.
+   * @param segmentIds A 1-D tensor. Values should be sorted and can be repeated.
+   * @return a new instance of SparseSegmentSqrtN
+   */
+  public static <T extends Number, U extends Number> SparseSegmentSqrtN<T> create(Scope scope, Operand<T> data, Operand<U> indices, Operand<Integer> segmentIds) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseSegmentSqrtN", scope.makeOpName("SparseSegmentSqrtN"));
+    opBuilder.addInput(data.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(segmentIds.asOutput());
+    return new SparseSegmentSqrtN<T>(opBuilder.build());
+  }
+  
+  /**
+   * Has same shape as data, except for dimension 0 which
+   * has size `k`, the number of segments.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private SparseSegmentSqrtN(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseSegmentSqrtNWithNumSegments.java java-ops/org/tensorflow/op/core/SparseSegmentSqrtNWithNumSegments.java
--- java/org/tensorflow/op/core/SparseSegmentSqrtNWithNumSegments.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseSegmentSqrtNWithNumSegments.java	2018-10-16 20:18:38.552432156 +0900
@@ -0,0 +1,84 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the sum along sparse segments of a tensor divided by the sqrt of N.
+ * <p>
+ * N is the size of the segment being reduced.
+ * <p>
+ * Like `SparseSegmentSqrtN`, but allows missing ids in `segment_ids`. If an id is
+ * misisng, the `output` tensor at that position will be zeroed.
+ * <p>
+ * Read
+ * [the section on segmentation](https://tensorflow.org/api_guides/python/math_ops#Segmentation)
+ * for an explanation of segments.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class SparseSegmentSqrtNWithNumSegments<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new SparseSegmentSqrtNWithNumSegments operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param data 
+   * @param indices A 1-D tensor. Has same rank as `segment_ids`.
+   * @param segmentIds A 1-D tensor. Values should be sorted and can be repeated.
+   * @param numSegments Should equal the number of distinct segment IDs.
+   * @return a new instance of SparseSegmentSqrtNWithNumSegments
+   */
+  public static <T extends Number, U extends Number, V extends Number> SparseSegmentSqrtNWithNumSegments<T> create(Scope scope, Operand<T> data, Operand<U> indices, Operand<Integer> segmentIds, Operand<V> numSegments) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseSegmentSqrtNWithNumSegments", scope.makeOpName("SparseSegmentSqrtNWithNumSegments"));
+    opBuilder.addInput(data.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(segmentIds.asOutput());
+    opBuilder.addInput(numSegments.asOutput());
+    return new SparseSegmentSqrtNWithNumSegments<T>(opBuilder.build());
+  }
+  
+  /**
+   * Has same shape as data, except for dimension 0 which
+   * has size `k`, the number of segments.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private SparseSegmentSqrtNWithNumSegments(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseSegmentSum.java java-ops/org/tensorflow/op/core/SparseSegmentSum.java
--- java/org/tensorflow/op/core/SparseSegmentSum.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseSegmentSum.java	2018-10-16 20:18:38.552432156 +0900
@@ -0,0 +1,103 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the sum along sparse segments of a tensor.
+ * <p>
+ * Read
+ * [the section on segmentation](https://tensorflow.org/api_guides/python/math_ops#Segmentation)
+ * for an explanation of segments.
+ * <p>
+ * Like `SegmentSum`, but `segment_ids` can have rank less than `data`'s first
+ * dimension, selecting a subset of dimension 0, specified by `indices`.
+ * <p>
+ * For example:
+ * <pre>{@code
+ * c = tf.constant([[1,2,3,4], [-1,-2,-3,-4], [5,6,7,8]])
+ * 
+ * # Select two rows, one segment.
+ * tf.sparse_segment_sum(c, tf.constant([0, 1]), tf.constant([0, 0]))
+ * # => [[0 0 0 0]]
+ * 
+ * # Select two rows, two segment.
+ * tf.sparse_segment_sum(c, tf.constant([0, 1]), tf.constant([0, 1]))
+ * # => [[ 1  2  3  4]
+ * #     [-1 -2 -3 -4]]
+ * 
+ * # Select all rows, two segments.
+ * tf.sparse_segment_sum(c, tf.constant([0, 1, 2]), tf.constant([0, 0, 1]))
+ * # => [[0 0 0 0]
+ * #     [5 6 7 8]]
+ * 
+ * # Which is equivalent to:
+ * tf.segment_sum(c, tf.constant([0, 0, 1]))
+ * }</pre>
+ * 
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class SparseSegmentSum<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new SparseSegmentSum operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param data 
+   * @param indices A 1-D tensor. Has same rank as `segment_ids`.
+   * @param segmentIds A 1-D tensor. Values should be sorted and can be repeated.
+   * @return a new instance of SparseSegmentSum
+   */
+  public static <T extends Number, U extends Number> SparseSegmentSum<T> create(Scope scope, Operand<T> data, Operand<U> indices, Operand<Integer> segmentIds) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseSegmentSum", scope.makeOpName("SparseSegmentSum"));
+    opBuilder.addInput(data.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(segmentIds.asOutput());
+    return new SparseSegmentSum<T>(opBuilder.build());
+  }
+  
+  /**
+   * Has same shape as data, except for dimension 0 which
+   * has size `k`, the number of segments.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private SparseSegmentSum(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseSegmentSumWithNumSegments.java java-ops/org/tensorflow/op/core/SparseSegmentSumWithNumSegments.java
--- java/org/tensorflow/op/core/SparseSegmentSumWithNumSegments.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseSegmentSumWithNumSegments.java	2018-10-16 20:18:38.553432156 +0900
@@ -0,0 +1,103 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the sum along sparse segments of a tensor.
+ * <p>
+ * Like `SparseSegmentSum`, but allows missing ids in `segment_ids`. If an id is
+ * misisng, the `output` tensor at that position will be zeroed.
+ * <p>
+ * Read
+ * [the section on segmentation](https://tensorflow.org/api_guides/python/math_ops#Segmentation)
+ * for an explanation of segments.
+ * <p>
+ * For example:
+ * <pre>{@code
+ * c = tf.constant([[1,2,3,4], [-1,-2,-3,-4], [5,6,7,8]])
+ * 
+ * tf.sparse_segment_sum_with_num_segments(
+ *     c, tf.constant([0, 1]), tf.constant([0, 0]), num_segments=3)
+ * # => [[0 0 0 0]
+ * #     [0 0 0 0]
+ * #     [0 0 0 0]]
+ * 
+ * tf.sparse_segment_sum_with_num_segments(c,
+ *                                         tf.constant([0, 1]),
+ *                                         tf.constant([0, 2],
+ *                                         num_segments=4))
+ * # => [[ 1  2  3  4]
+ * #     [ 0  0  0  0]
+ * #     [-1 -2 -3 -4]
+ * #     [ 0  0  0  0]]
+ * }</pre>
+ * 
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class SparseSegmentSumWithNumSegments<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new SparseSegmentSumWithNumSegments operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param data 
+   * @param indices A 1-D tensor. Has same rank as `segment_ids`.
+   * @param segmentIds A 1-D tensor. Values should be sorted and can be repeated.
+   * @param numSegments Should equal the number of distinct segment IDs.
+   * @return a new instance of SparseSegmentSumWithNumSegments
+   */
+  public static <T extends Number, U extends Number, V extends Number> SparseSegmentSumWithNumSegments<T> create(Scope scope, Operand<T> data, Operand<U> indices, Operand<Integer> segmentIds, Operand<V> numSegments) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseSegmentSumWithNumSegments", scope.makeOpName("SparseSegmentSumWithNumSegments"));
+    opBuilder.addInput(data.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(segmentIds.asOutput());
+    opBuilder.addInput(numSegments.asOutput());
+    return new SparseSegmentSumWithNumSegments<T>(opBuilder.build());
+  }
+  
+  /**
+   * Has same shape as data, except for dimension 0 which
+   * has size `num_segments`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private SparseSegmentSumWithNumSegments(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseSliceGrad.java java-ops/org/tensorflow/op/core/SparseSliceGrad.java
--- java/org/tensorflow/op/core/SparseSliceGrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseSliceGrad.java	2018-10-16 20:18:38.554432155 +0900
@@ -0,0 +1,79 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * The gradient operator for the SparseSlice op.
+ * <p>
+ * This op takes in the upstream gradient w.r.t. non-empty values of
+ * the sliced `SparseTensor`, and outputs the gradients w.r.t.
+ * the non-empty values of input `SparseTensor`.
+ * 
+ * @param <T> data type for {@code valGrad()} output
+ */
+@Operator
+public final class SparseSliceGrad<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new SparseSliceGrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param backpropValGrad 1-D. The gradient with respect to
+   * the non-empty values of the sliced `SparseTensor`.
+   * @param inputIndices 2-D.  The `indices` of the input `SparseTensor`.
+   * @param inputStart 1-D. tensor represents the start of the slice.
+   * @param outputIndices 2-D.  The `indices` of the sliced `SparseTensor`.
+   * @return a new instance of SparseSliceGrad
+   */
+  public static <T> SparseSliceGrad<T> create(Scope scope, Operand<T> backpropValGrad, Operand<Long> inputIndices, Operand<Long> inputStart, Operand<Long> outputIndices) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseSliceGrad", scope.makeOpName("SparseSliceGrad"));
+    opBuilder.addInput(backpropValGrad.asOutput());
+    opBuilder.addInput(inputIndices.asOutput());
+    opBuilder.addInput(inputStart.asOutput());
+    opBuilder.addInput(outputIndices.asOutput());
+    return new SparseSliceGrad<T>(opBuilder.build());
+  }
+  
+  /**
+   * 1-D. The gradient with respect to the non-empty values of input `SparseTensor`.
+   */
+  public Output<T> valGrad() {
+    return valGrad;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return valGrad;
+  }
+  
+  private Output<T> valGrad;
+  
+  private SparseSliceGrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    valGrad = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseSlice.java java-ops/org/tensorflow/op/core/SparseSlice.java
--- java/org/tensorflow/op/core/SparseSlice.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseSlice.java	2018-10-16 20:18:38.554432155 +0900
@@ -0,0 +1,108 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Slice a `SparseTensor` based on the `start` and `size`.
+ * <p>
+ * For example, if the input is
+ * <p>
+ *     input_tensor = shape = [2, 7]
+ *     [    a   d e  ]
+ *     [b c          ]
+ * <p>
+ * Graphically the output tensors are:
+ * <p>
+ *     sparse_slice([0, 0], [2, 4]) = shape = [2, 4]
+ *     [    a  ]
+ *     [b c    ]
+ * <p>
+ *     sparse_slice([0, 4], [2, 3]) = shape = [2, 3]
+ *     [ d e  ]
+ *     [      ]
+ * 
+ * @param <T> data type for {@code outputValues()} output
+ */
+@Operator
+public final class SparseSlice<T> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new SparseSlice operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param indices 2-D tensor represents the indices of the sparse tensor.
+   * @param values 1-D tensor represents the values of the sparse tensor.
+   * @param shape 1-D. tensor represents the shape of the sparse tensor.
+   * @param start 1-D. tensor represents the start of the slice.
+   * @param size 1-D. tensor represents the size of the slice.
+   * output indices: A list of 1-D tensors represents the indices of the output
+   * sparse tensors.
+   * @return a new instance of SparseSlice
+   */
+  public static <T> SparseSlice<T> create(Scope scope, Operand<Long> indices, Operand<T> values, Operand<Long> shape, Operand<Long> start, Operand<Long> size) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseSlice", scope.makeOpName("SparseSlice"));
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(values.asOutput());
+    opBuilder.addInput(shape.asOutput());
+    opBuilder.addInput(start.asOutput());
+    opBuilder.addInput(size.asOutput());
+    return new SparseSlice<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<Long> outputIndices() {
+    return outputIndices;
+  }
+  
+  /**
+   * A list of 1-D tensors represents the values of the output sparse
+   * tensors.
+   */
+  public Output<T> outputValues() {
+    return outputValues;
+  }
+  
+  /**
+   * A list of 1-D tensors represents the shape of the output sparse
+   * tensors.
+   */
+  public Output<Long> outputShape() {
+    return outputShape;
+  }
+  
+  private Output<Long> outputIndices;
+  private Output<T> outputValues;
+  private Output<Long> outputShape;
+  
+  private SparseSlice(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    outputIndices = operation.output(outputIdx++);
+    outputValues = operation.output(outputIdx++);
+    outputShape = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseSoftmaxCrossEntropyWithLogits.java java-ops/org/tensorflow/op/core/SparseSoftmaxCrossEntropyWithLogits.java
--- java/org/tensorflow/op/core/SparseSoftmaxCrossEntropyWithLogits.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseSoftmaxCrossEntropyWithLogits.java	2018-10-16 20:18:38.556432154 +0900
@@ -0,0 +1,82 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes softmax cross entropy cost and gradients to backpropagate.
+ * <p>
+ * Unlike `SoftmaxCrossEntropyWithLogits`, this operation does not accept
+ * a matrix of label probabilities, but rather a single label per row
+ * of features.  This label is considered to have probability 1.0 for the
+ * given row.
+ * <p>
+ * Inputs are the logits, not probabilities.
+ * 
+ * @param <T> data type for {@code loss()} output
+ */
+@Operator
+public final class SparseSoftmaxCrossEntropyWithLogits<T extends Number> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new SparseSoftmaxCrossEntropyWithLogits operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param features batch_size x num_classes matrix
+   * @param labels batch_size vector with values in [0, num_classes).
+   * This is the label for the given minibatch entry.
+   * @return a new instance of SparseSoftmaxCrossEntropyWithLogits
+   */
+  public static <T extends Number, U extends Number> SparseSoftmaxCrossEntropyWithLogits<T> create(Scope scope, Operand<T> features, Operand<U> labels) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseSoftmaxCrossEntropyWithLogits", scope.makeOpName("SparseSoftmaxCrossEntropyWithLogits"));
+    opBuilder.addInput(features.asOutput());
+    opBuilder.addInput(labels.asOutput());
+    return new SparseSoftmaxCrossEntropyWithLogits<T>(opBuilder.build());
+  }
+  
+  /**
+   * Per example loss (batch_size vector).
+   */
+  public Output<T> loss() {
+    return loss;
+  }
+  
+  /**
+   * backpropagated gradients (batch_size x num_classes matrix).
+   */
+  public Output<T> backprop() {
+    return backprop;
+  }
+  
+  private Output<T> loss;
+  private Output<T> backprop;
+  
+  private SparseSoftmaxCrossEntropyWithLogits(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    loss = operation.output(outputIdx++);
+    backprop = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseSoftmax.java java-ops/org/tensorflow/op/core/SparseSoftmax.java
--- java/org/tensorflow/op/core/SparseSoftmax.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseSoftmax.java	2018-10-16 20:18:38.555432154 +0900
@@ -0,0 +1,89 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Applies softmax to a batched N-D `SparseTensor`.
+ * <p>
+ * The inputs represent an N-D SparseTensor  with logical shape `[..., B, C]`
+ * (where `N >= 2`), and with indices sorted in the canonical lexicographic order.
+ * <p>
+ * This op is equivalent to applying the normal `tf.nn.softmax()` to each innermost
+ * logical submatrix with shape `[B, C]`, but with the catch that <i>the implicitly
+ * zero elements do not participate</i>.  Specifically, the algorithm is equivalent
+ * to the following:
+ * <p>
+ *   (1) Applies `tf.nn.softmax()` to a densified view of each innermost submatrix
+ *       with shape `[B, C]`, along the size-C dimension;
+ *   (2) Masks out the original implicitly-zero locations;
+ *   (3) Renormalizes the remaining elements.
+ * <p>
+ * Hence, the `SparseTensor` result has exactly the same non-zero indices and
+ * shape.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class SparseSoftmax<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new SparseSoftmax operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param spIndices 2-D.  `NNZ x R` matrix with the indices of non-empty values in a
+   * SparseTensor, in canonical ordering.
+   * @param spValues 1-D.  `NNZ` non-empty values corresponding to `sp_indices`.
+   * @param spShape 1-D.  Shape of the input SparseTensor.
+   * @return a new instance of SparseSoftmax
+   */
+  public static <T extends Number> SparseSoftmax<T> create(Scope scope, Operand<Long> spIndices, Operand<T> spValues, Operand<Long> spShape) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseSoftmax", scope.makeOpName("SparseSoftmax"));
+    opBuilder.addInput(spIndices.asOutput());
+    opBuilder.addInput(spValues.asOutput());
+    opBuilder.addInput(spShape.asOutput());
+    return new SparseSoftmax<T>(opBuilder.build());
+  }
+  
+  /**
+   * 1-D.  The `NNZ` values for the result `SparseTensor`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private SparseSoftmax(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseSparseMaximum.java java-ops/org/tensorflow/op/core/SparseSparseMaximum.java
--- java/org/tensorflow/op/core/SparseSparseMaximum.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseSparseMaximum.java	2018-10-16 20:18:38.556432154 +0900
@@ -0,0 +1,85 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns the element-wise max of two SparseTensors.
+ * <p>
+ * Assumes the two SparseTensors have the same shape, i.e., no broadcasting.
+ * 
+ * @param <T> data type for {@code outputValues()} output
+ */
+@Operator
+public final class SparseSparseMaximum<T extends Number> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new SparseSparseMaximum operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param aIndices 2-D.  `N x R` matrix with the indices of non-empty values in a
+   * SparseTensor, in the canonical lexicographic ordering.
+   * @param aValues 1-D.  `N` non-empty values corresponding to `a_indices`.
+   * @param aShape 1-D.  Shape of the input SparseTensor.
+   * @param bIndices counterpart to `a_indices` for the other operand.
+   * @param bValues counterpart to `a_values` for the other operand; must be of the same dtype.
+   * @param bShape counterpart to `a_shape` for the other operand; the two shapes must be equal.
+   * @return a new instance of SparseSparseMaximum
+   */
+  public static <T extends Number> SparseSparseMaximum<T> create(Scope scope, Operand<Long> aIndices, Operand<T> aValues, Operand<Long> aShape, Operand<Long> bIndices, Operand<T> bValues, Operand<Long> bShape) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseSparseMaximum", scope.makeOpName("SparseSparseMaximum"));
+    opBuilder.addInput(aIndices.asOutput());
+    opBuilder.addInput(aValues.asOutput());
+    opBuilder.addInput(aShape.asOutput());
+    opBuilder.addInput(bIndices.asOutput());
+    opBuilder.addInput(bValues.asOutput());
+    opBuilder.addInput(bShape.asOutput());
+    return new SparseSparseMaximum<T>(opBuilder.build());
+  }
+  
+  /**
+   * 2-D.  The indices of the output SparseTensor.
+   */
+  public Output<Long> outputIndices() {
+    return outputIndices;
+  }
+  
+  /**
+   * 1-D.  The values of the output SparseTensor.
+   */
+  public Output<T> outputValues() {
+    return outputValues;
+  }
+  
+  private Output<Long> outputIndices;
+  private Output<T> outputValues;
+  
+  private SparseSparseMaximum(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    outputIndices = operation.output(outputIdx++);
+    outputValues = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseSparseMinimum.java java-ops/org/tensorflow/op/core/SparseSparseMinimum.java
--- java/org/tensorflow/op/core/SparseSparseMinimum.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseSparseMinimum.java	2018-10-16 20:18:38.557432153 +0900
@@ -0,0 +1,85 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns the element-wise min of two SparseTensors.
+ * <p>
+ * Assumes the two SparseTensors have the same shape, i.e., no broadcasting.
+ * 
+ * @param <T> data type for {@code outputValues()} output
+ */
+@Operator
+public final class SparseSparseMinimum<T> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new SparseSparseMinimum operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param aIndices 2-D.  `N x R` matrix with the indices of non-empty values in a
+   * SparseTensor, in the canonical lexicographic ordering.
+   * @param aValues 1-D.  `N` non-empty values corresponding to `a_indices`.
+   * @param aShape 1-D.  Shape of the input SparseTensor.
+   * @param bIndices counterpart to `a_indices` for the other operand.
+   * @param bValues counterpart to `a_values` for the other operand; must be of the same dtype.
+   * @param bShape counterpart to `a_shape` for the other operand; the two shapes must be equal.
+   * @return a new instance of SparseSparseMinimum
+   */
+  public static <T> SparseSparseMinimum<T> create(Scope scope, Operand<Long> aIndices, Operand<T> aValues, Operand<Long> aShape, Operand<Long> bIndices, Operand<T> bValues, Operand<Long> bShape) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseSparseMinimum", scope.makeOpName("SparseSparseMinimum"));
+    opBuilder.addInput(aIndices.asOutput());
+    opBuilder.addInput(aValues.asOutput());
+    opBuilder.addInput(aShape.asOutput());
+    opBuilder.addInput(bIndices.asOutput());
+    opBuilder.addInput(bValues.asOutput());
+    opBuilder.addInput(bShape.asOutput());
+    return new SparseSparseMinimum<T>(opBuilder.build());
+  }
+  
+  /**
+   * 2-D.  The indices of the output SparseTensor.
+   */
+  public Output<Long> outputIndices() {
+    return outputIndices;
+  }
+  
+  /**
+   * 1-D.  The values of the output SparseTensor.
+   */
+  public Output<T> outputValues() {
+    return outputValues;
+  }
+  
+  private Output<Long> outputIndices;
+  private Output<T> outputValues;
+  
+  private SparseSparseMinimum(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    outputIndices = operation.output(outputIdx++);
+    outputValues = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseSplit.java java-ops/org/tensorflow/op/core/SparseSplit.java
--- java/org/tensorflow/op/core/SparseSplit.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseSplit.java	2018-10-16 20:18:38.558432152 +0900
@@ -0,0 +1,120 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Split a `SparseTensor` into `num_split` tensors along one dimension.
+ * <p>
+ * If the `shape[split_dim]` is not an integer multiple of `num_split`. Slices
+ * `[0 : shape[split_dim] % num_split]` gets one extra dimension.
+ * For example, if `split_dim = 1` and `num_split = 2` and the input is
+ * <p>
+ *     input_tensor = shape = [2, 7]
+ *     [    a   d e  ]
+ *     [b c          ]
+ * <p>
+ * Graphically the output tensors are:
+ * <p>
+ *     output_tensor[0] = shape = [2, 4]
+ *     [    a  ]
+ *     [b c    ]
+ * <p>
+ *     output_tensor[1] = shape = [2, 3]
+ *     [ d e  ]
+ *     [      ]
+ * 
+ * @param <T> data type for {@code outputValues()} output
+ */
+@Operator
+public final class SparseSplit<T> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new SparseSplit operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param splitDim 0-D.  The dimension along which to split.  Must be in the range
+   * `[0, rank(shape))`.
+   * @param indices 2-D tensor represents the indices of the sparse tensor.
+   * @param values 1-D tensor represents the values of the sparse tensor.
+   * @param shape 1-D. tensor represents the shape of the sparse tensor.
+   * output indices: A list of 1-D tensors represents the indices of the output
+   * sparse tensors.
+   * @param numSplit The number of ways to split.
+   * @return a new instance of SparseSplit
+   */
+  public static <T> SparseSplit<T> create(Scope scope, Operand<Long> splitDim, Operand<Long> indices, Operand<T> values, Operand<Long> shape, Long numSplit) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseSplit", scope.makeOpName("SparseSplit"));
+    opBuilder.addInput(splitDim.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(values.asOutput());
+    opBuilder.addInput(shape.asOutput());
+    opBuilder.setAttr("num_split", numSplit);
+    return new SparseSplit<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public List<Output<Long>> outputIndices() {
+    return outputIndices;
+  }
+  
+  /**
+   * A list of 1-D tensors represents the values of the output sparse
+   * tensors.
+   */
+  public List<Output<T>> outputValues() {
+    return outputValues;
+  }
+  
+  /**
+   * A list of 1-D tensors represents the shape of the output sparse
+   * tensors.
+   */
+  public List<Output<Long>> outputShape() {
+    return outputShape;
+  }
+  
+  private List<Output<Long>> outputIndices;
+  private List<Output<T>> outputValues;
+  private List<Output<Long>> outputShape;
+  
+  @SuppressWarnings("unchecked")
+  private SparseSplit(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    int outputIndicesLength = operation.outputListLength("output_indices");
+    outputIndices = Arrays.asList((Output<Long>[])operation.outputList(outputIdx, outputIndicesLength));
+    outputIdx += outputIndicesLength;
+    int outputValuesLength = operation.outputListLength("output_values");
+    outputValues = Arrays.asList((Output<T>[])operation.outputList(outputIdx, outputValuesLength));
+    outputIdx += outputValuesLength;
+    int outputShapeLength = operation.outputListLength("output_shape");
+    outputShape = Arrays.asList((Output<Long>[])operation.outputList(outputIdx, outputShapeLength));
+    outputIdx += outputShapeLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseTensorDenseAdd.java java-ops/org/tensorflow/op/core/SparseTensorDenseAdd.java
--- java/org/tensorflow/op/core/SparseTensorDenseAdd.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseTensorDenseAdd.java	2018-10-16 20:18:38.558432152 +0900
@@ -0,0 +1,75 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Adds up a `SparseTensor` and a dense `Tensor`, producing a dense `Tensor`.
+ * <p>
+ * This Op does not require `a_indices` be sorted in standard lexicographic order.
+ * 
+ * @param <U> data type for {@code output()} output
+ */
+@Operator
+public final class SparseTensorDenseAdd<U> extends PrimitiveOp implements Operand<U> {
+  
+  /**
+   * Factory method to create a class to wrap a new SparseTensorDenseAdd operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param aIndices 2-D.  The `indices` of the `SparseTensor`, with shape `[nnz, ndims]`.
+   * @param aValues 1-D.  The `values` of the `SparseTensor`, with shape `[nnz]`.
+   * @param aShape 1-D.  The `shape` of the `SparseTensor`, with shape `[ndims]`.
+   * @param b `ndims`-D Tensor.  With shape `a_shape`.
+   * @return a new instance of SparseTensorDenseAdd
+   */
+  public static <U, T extends Number> SparseTensorDenseAdd<U> create(Scope scope, Operand<T> aIndices, Operand<U> aValues, Operand<T> aShape, Operand<U> b) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseTensorDenseAdd", scope.makeOpName("SparseTensorDenseAdd"));
+    opBuilder.addInput(aIndices.asOutput());
+    opBuilder.addInput(aValues.asOutput());
+    opBuilder.addInput(aShape.asOutput());
+    opBuilder.addInput(b.asOutput());
+    return new SparseTensorDenseAdd<U>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<U> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<U> asOutput() {
+    return output;
+  }
+  
+  private Output<U> output;
+  
+  private SparseTensorDenseAdd(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseTensorDenseMatMul.java java-ops/org/tensorflow/op/core/SparseTensorDenseMatMul.java
--- java/org/tensorflow/op/core/SparseTensorDenseMatMul.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseTensorDenseMatMul.java	2018-10-16 20:18:38.559432151 +0900
@@ -0,0 +1,140 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Multiply SparseTensor (of rank 2) "A" by dense matrix "B".
+ * <p>
+ * No validity checking is performed on the indices of A.  However, the following
+ * input format is recommended for optimal behavior:
+ * <p>
+ * if adjoint_a == false:
+ *   A should be sorted in lexicographically increasing order.  Use SparseReorder
+ *   if you're not sure.
+ * if adjoint_a == true:
+ *   A should be sorted in order of increasing dimension 1 (i.e., "column major"
+ *   order instead of "row major" order).
+ * 
+ * @param <U> data type for {@code product()} output
+ */
+@Operator
+public final class SparseTensorDenseMatMul<U> extends PrimitiveOp implements Operand<U> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.SparseTensorDenseMatMul}
+   */
+  public static class Options {
+    
+    /**
+     * @param adjointA Use the adjoint of A in the matrix multiply.  If A is complex, this
+     * is transpose(conj(A)).  Otherwise it's transpose(A).
+     */
+    public Options adjointA(Boolean adjointA) {
+      this.adjointA = adjointA;
+      return this;
+    }
+    
+    /**
+     * @param adjointB Use the adjoint of B in the matrix multiply.  If B is complex, this
+     * is transpose(conj(B)).  Otherwise it's transpose(B).
+     */
+    public Options adjointB(Boolean adjointB) {
+      this.adjointB = adjointB;
+      return this;
+    }
+    
+    private Boolean adjointA;
+    private Boolean adjointB;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new SparseTensorDenseMatMul operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param aIndices 2-D.  The `indices` of the `SparseTensor`, size `[nnz, 2]` Matrix.
+   * @param aValues 1-D.  The `values` of the `SparseTensor`, size `[nnz]` Vector.
+   * @param aShape 1-D.  The `shape` of the `SparseTensor`, size `[2]` Vector.
+   * @param b 2-D.  A dense Matrix.
+   * @param options carries optional attributes values
+   * @return a new instance of SparseTensorDenseMatMul
+   */
+  public static <U, T extends Number> SparseTensorDenseMatMul<U> create(Scope scope, Operand<T> aIndices, Operand<U> aValues, Operand<Long> aShape, Operand<U> b, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseTensorDenseMatMul", scope.makeOpName("SparseTensorDenseMatMul"));
+    opBuilder.addInput(aIndices.asOutput());
+    opBuilder.addInput(aValues.asOutput());
+    opBuilder.addInput(aShape.asOutput());
+    opBuilder.addInput(b.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.adjointA != null) {
+          opBuilder.setAttr("adjoint_a", opts.adjointA);
+        }
+        if (opts.adjointB != null) {
+          opBuilder.setAttr("adjoint_b", opts.adjointB);
+        }
+      }
+    }
+    return new SparseTensorDenseMatMul<U>(opBuilder.build());
+  }
+  
+  /**
+   * @param adjointA Use the adjoint of A in the matrix multiply.  If A is complex, this
+   * is transpose(conj(A)).  Otherwise it's transpose(A).
+   */
+  public static Options adjointA(Boolean adjointA) {
+    return new Options().adjointA(adjointA);
+  }
+  
+  /**
+   * @param adjointB Use the adjoint of B in the matrix multiply.  If B is complex, this
+   * is transpose(conj(B)).  Otherwise it's transpose(B).
+   */
+  public static Options adjointB(Boolean adjointB) {
+    return new Options().adjointB(adjointB);
+  }
+  
+  /**
+   */
+  public Output<U> product() {
+    return product;
+  }
+  
+  @Override
+  public Output<U> asOutput() {
+    return product;
+  }
+  
+  private Output<U> product;
+  
+  private SparseTensorDenseMatMul(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    product = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseTensorSliceDataset.java java-ops/org/tensorflow/op/core/SparseTensorSliceDataset.java
--- java/org/tensorflow/op/core/SparseTensorSliceDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseTensorSliceDataset.java	2018-10-16 20:18:38.559432151 +0900
@@ -0,0 +1,70 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Creates a dataset that splits a SparseTensor into elements row-wise.
+ */
+@Operator
+public final class SparseTensorSliceDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new SparseTensorSliceDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param indices 
+   * @param values 
+   * @param denseShape 
+   * @return a new instance of SparseTensorSliceDataset
+   */
+  public static <T> SparseTensorSliceDataset create(Scope scope, Operand<Long> indices, Operand<T> values, Operand<Long> denseShape) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseTensorSliceDataset", scope.makeOpName("SparseTensorSliceDataset"));
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(values.asOutput());
+    opBuilder.addInput(denseShape.asOutput());
+    return new SparseTensorSliceDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private SparseTensorSliceDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseToDense.java java-ops/org/tensorflow/op/core/SparseToDense.java
--- java/org/tensorflow/op/core/SparseToDense.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseToDense.java	2018-10-16 20:18:38.560432151 +0900
@@ -0,0 +1,131 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Converts a sparse representation into a dense tensor.
+ * <p>
+ * Builds an array `dense` with shape `output_shape` such that
+ * <pre>{@code
+ * # If sparse_indices is scalar
+ * dense[i] = (i == sparse_indices ? sparse_values : default_value)
+ * 
+ * # If sparse_indices is a vector, then for each i
+ * dense[sparse_indices[i]] = sparse_values[i]
+ * 
+ * # If sparse_indices is an n by d matrix, then for each i in [0, n)
+ * dense[sparse_indices[i][0], ..., sparse_indices[i][d-1]] = sparse_values[i]
+ * }</pre>
+ * All other values in `dense` are set to `default_value`.  If `sparse_values` is a
+ * scalar, all sparse indices are set to this single value.
+ * <p>
+ * Indices should be sorted in lexicographic order, and indices must not
+ * contain any repeats. If `validate_indices` is true, these properties
+ * are checked during execution.
+ * 
+ * @param <U> data type for {@code dense()} output
+ */
+@Operator
+public final class SparseToDense<U> extends PrimitiveOp implements Operand<U> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.SparseToDense}
+   */
+  public static class Options {
+    
+    /**
+     * @param validateIndices If true, indices are checked to make sure they are sorted in
+     * lexicographic order and that there are no repeats.
+     */
+    public Options validateIndices(Boolean validateIndices) {
+      this.validateIndices = validateIndices;
+      return this;
+    }
+    
+    private Boolean validateIndices;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new SparseToDense operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param sparseIndices 0-D, 1-D, or 2-D.  `sparse_indices[i]` contains the complete
+   * index where `sparse_values[i]` will be placed.
+   * @param outputShape 1-D.  Shape of the dense output tensor.
+   * @param sparseValues 1-D.  Values corresponding to each row of `sparse_indices`,
+   * or a scalar value to be used for all sparse indices.
+   * @param defaultValue Scalar value to set for indices not specified in
+   * `sparse_indices`.
+   * @param options carries optional attributes values
+   * @return a new instance of SparseToDense
+   */
+  public static <U, T extends Number> SparseToDense<U> create(Scope scope, Operand<T> sparseIndices, Operand<T> outputShape, Operand<U> sparseValues, Operand<U> defaultValue, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseToDense", scope.makeOpName("SparseToDense"));
+    opBuilder.addInput(sparseIndices.asOutput());
+    opBuilder.addInput(outputShape.asOutput());
+    opBuilder.addInput(sparseValues.asOutput());
+    opBuilder.addInput(defaultValue.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.validateIndices != null) {
+          opBuilder.setAttr("validate_indices", opts.validateIndices);
+        }
+      }
+    }
+    return new SparseToDense<U>(opBuilder.build());
+  }
+  
+  /**
+   * @param validateIndices If true, indices are checked to make sure they are sorted in
+   * lexicographic order and that there are no repeats.
+   */
+  public static Options validateIndices(Boolean validateIndices) {
+    return new Options().validateIndices(validateIndices);
+  }
+  
+  /**
+   * Dense output tensor of shape `output_shape`.
+   */
+  public Output<U> dense() {
+    return dense;
+  }
+  
+  @Override
+  public Output<U> asOutput() {
+    return dense;
+  }
+  
+  private Output<U> dense;
+  
+  private SparseToDense(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    dense = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SparseToSparseSetOperation.java java-ops/org/tensorflow/op/core/SparseToSparseSetOperation.java
--- java/org/tensorflow/op/core/SparseToSparseSetOperation.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SparseToSparseSetOperation.java	2018-10-16 20:18:38.562432149 +0900
@@ -0,0 +1,161 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Applies set operation along last dimension of 2 `SparseTensor` inputs.
+ * <p>
+ * See SetOperationOp::SetOperationFromContext for values of `set_operation`.
+ * <p>
+ * If `validate_indices` is `True`, `SparseToSparseSetOperation` validates the
+ * order and range of `set1` and `set2` indices.
+ * <p>
+ * Input `set1` is a `SparseTensor` represented by `set1_indices`, `set1_values`,
+ * and `set1_shape`. For `set1` ranked `n`, 1st `n-1` dimensions must be the same
+ * as `set2`. Dimension `n` contains values in a set, duplicates are allowed but
+ * ignored.
+ * <p>
+ * Input `set2` is a `SparseTensor` represented by `set2_indices`, `set2_values`,
+ * and `set2_shape`. For `set2` ranked `n`, 1st `n-1` dimensions must be the same
+ * as `set1`. Dimension `n` contains values in a set, duplicates are allowed but
+ * ignored.
+ * <p>
+ * If `validate_indices` is `True`, this op validates the order and range of `set1`
+ * and `set2` indices.
+ * <p>
+ * Output `result` is a `SparseTensor` represented by `result_indices`,
+ * `result_values`, and `result_shape`. For `set1` and `set2` ranked `n`, this
+ * has rank `n` and the same 1st `n-1` dimensions as `set1` and `set2`. The `nth`
+ * dimension contains the result of `set_operation` applied to the corresponding
+ * `[0...n-1]` dimension of `set`.
+ * 
+ * @param <T> data type for {@code resultValues()} output
+ */
+@Operator
+public final class SparseToSparseSetOperation<T> extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.SparseToSparseSetOperation}
+   */
+  public static class Options {
+    
+    /**
+     * @param validateIndices 
+     */
+    public Options validateIndices(Boolean validateIndices) {
+      this.validateIndices = validateIndices;
+      return this;
+    }
+    
+    private Boolean validateIndices;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new SparseToSparseSetOperation operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param set1Indices 2D `Tensor`, indices of a `SparseTensor`. Must be in row-major
+   * order.
+   * @param set1Values 1D `Tensor`, values of a `SparseTensor`. Must be in row-major
+   * order.
+   * @param set1Shape 1D `Tensor`, shape of a `SparseTensor`. `set1_shape[0...n-1]` must
+   * be the same as `set2_shape[0...n-1]`, `set1_shape[n]` is the
+   * max set size across `0...n-1` dimensions.
+   * @param set2Indices 2D `Tensor`, indices of a `SparseTensor`. Must be in row-major
+   * order.
+   * @param set2Values 1D `Tensor`, values of a `SparseTensor`. Must be in row-major
+   * order.
+   * @param set2Shape 1D `Tensor`, shape of a `SparseTensor`. `set2_shape[0...n-1]` must
+   * be the same as `set1_shape[0...n-1]`, `set2_shape[n]` is the
+   * max set size across `0...n-1` dimensions.
+   * @param setOperation 
+   * @param options carries optional attributes values
+   * @return a new instance of SparseToSparseSetOperation
+   */
+  public static <T> SparseToSparseSetOperation<T> create(Scope scope, Operand<Long> set1Indices, Operand<T> set1Values, Operand<Long> set1Shape, Operand<Long> set2Indices, Operand<T> set2Values, Operand<Long> set2Shape, String setOperation, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SparseToSparseSetOperation", scope.makeOpName("SparseToSparseSetOperation"));
+    opBuilder.addInput(set1Indices.asOutput());
+    opBuilder.addInput(set1Values.asOutput());
+    opBuilder.addInput(set1Shape.asOutput());
+    opBuilder.addInput(set2Indices.asOutput());
+    opBuilder.addInput(set2Values.asOutput());
+    opBuilder.addInput(set2Shape.asOutput());
+    opBuilder.setAttr("set_operation", setOperation);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.validateIndices != null) {
+          opBuilder.setAttr("validate_indices", opts.validateIndices);
+        }
+      }
+    }
+    return new SparseToSparseSetOperation<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param validateIndices 
+   */
+  public static Options validateIndices(Boolean validateIndices) {
+    return new Options().validateIndices(validateIndices);
+  }
+  
+  /**
+   * 2D indices of a `SparseTensor`.
+   */
+  public Output<Long> resultIndices() {
+    return resultIndices;
+  }
+  
+  /**
+   * 1D values of a `SparseTensor`.
+   */
+  public Output<T> resultValues() {
+    return resultValues;
+  }
+  
+  /**
+   * 1D `Tensor` shape of a `SparseTensor`. `result_shape[0...n-1]` is
+   * the same as the 1st `n-1` dimensions of `set1` and `set2`, `result_shape[n]`
+   * is the max result set size across all `0...n-1` dimensions.
+   */
+  public Output<Long> resultShape() {
+    return resultShape;
+  }
+  
+  private Output<Long> resultIndices;
+  private Output<T> resultValues;
+  private Output<Long> resultShape;
+  
+  private SparseToSparseSetOperation(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    resultIndices = operation.output(outputIdx++);
+    resultValues = operation.output(outputIdx++);
+    resultShape = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Split.java java-ops/org/tensorflow/op/core/Split.java
--- java/org/tensorflow/op/core/Split.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Split.java	2018-10-16 20:18:38.563432149 +0900
@@ -0,0 +1,83 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.Iterator;
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Splits a tensor into `num_split` tensors along one dimension.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class Split<T> extends PrimitiveOp implements Iterable<Operand<T>> {
+  
+  /**
+   * Factory method to create a class to wrap a new Split operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param axis 0-D.  The dimension along which to split.  Must be in the range
+   * `[-rank(value), rank(value))`.
+   * @param value The tensor to split.
+   * @param numSplit The number of ways to split.  Must evenly divide
+   * `value.shape[split_dim]`.
+   * @return a new instance of Split
+   */
+  public static <T> Split<T> create(Scope scope, Operand<Integer> axis, Operand<T> value, Long numSplit) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Split", scope.makeOpName("Split"));
+    opBuilder.addInput(axis.asOutput());
+    opBuilder.addInput(value.asOutput());
+    opBuilder.setAttr("num_split", numSplit);
+    return new Split<T>(opBuilder.build());
+  }
+  
+  /**
+   * They are identically shaped tensors, whose shape matches that of `value`
+   * except along `axis`, where their sizes are
+   * `values.shape[split_dim] / num_split`.
+   */
+  public List<Output<T>> output() {
+    return output;
+  }
+  
+  @Override
+  @SuppressWarnings({"rawtypes", "unchecked"})
+  public Iterator<Operand<T>> iterator() {
+    return (Iterator) output.iterator();
+  }
+  
+  private List<Output<T>> output;
+  
+  @SuppressWarnings("unchecked")
+  private Split(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    int outputLength = operation.outputListLength("output");
+    output = Arrays.asList((Output<T>[])operation.outputList(outputIdx, outputLength));
+    outputIdx += outputLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/SplitV.java java-ops/org/tensorflow/op/core/SplitV.java
--- java/org/tensorflow/op/core/SplitV.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SplitV.java	2018-10-16 20:18:38.563432149 +0900
@@ -0,0 +1,86 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.Iterator;
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Splits a tensor into `num_split` tensors along one dimension.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class SplitV<T> extends PrimitiveOp implements Iterable<Operand<T>> {
+  
+  /**
+   * Factory method to create a class to wrap a new SplitV operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param value The tensor to split.
+   * @param sizeSplits list containing the sizes of each output tensor along the split
+   * dimension. Must sum to the dimension of value along split_dim.
+   * Can contain one -1 indicating that dimension is to be inferred.
+   * @param axis 0-D.  The dimension along which to split.  Must be in the range
+   * `[-rank(value), rank(value))`.
+   * @param numSplit 
+   * @return a new instance of SplitV
+   */
+  public static <T, U extends Number> SplitV<T> create(Scope scope, Operand<T> value, Operand<U> sizeSplits, Operand<Integer> axis, Long numSplit) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SplitV", scope.makeOpName("SplitV"));
+    opBuilder.addInput(value.asOutput());
+    opBuilder.addInput(sizeSplits.asOutput());
+    opBuilder.addInput(axis.asOutput());
+    opBuilder.setAttr("num_split", numSplit);
+    return new SplitV<T>(opBuilder.build());
+  }
+  
+  /**
+   * Tensors whose shape matches that of `value`
+   * except along `axis`, where their sizes are
+   * `size_splits[i]`.
+   */
+  public List<Output<T>> output() {
+    return output;
+  }
+  
+  @Override
+  @SuppressWarnings({"rawtypes", "unchecked"})
+  public Iterator<Operand<T>> iterator() {
+    return (Iterator) output.iterator();
+  }
+  
+  private List<Output<T>> output;
+  
+  @SuppressWarnings("unchecked")
+  private SplitV(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    int outputLength = operation.outputListLength("output");
+    output = Arrays.asList((Output<T>[])operation.outputList(outputIdx, outputLength));
+    outputIdx += outputLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/SqlDataset.java java-ops/org/tensorflow/op/core/SqlDataset.java
--- java/org/tensorflow/op/core/SqlDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SqlDataset.java	2018-10-16 20:18:38.564432148 +0900
@@ -0,0 +1,85 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Creates a dataset that executes a SQL query and emits rows of the result set.
+ */
+@Operator
+public final class SqlDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new SqlDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param driverName The database type. Currently, the only supported type is 'sqlite'.
+   * @param dataSourceName A connection string to connect to the database.
+   * @param query A SQL query to execute.
+   * @param outputTypes 
+   * @param outputShapes 
+   * @return a new instance of SqlDataset
+   */
+  public static SqlDataset create(Scope scope, Operand<String> driverName, Operand<String> dataSourceName, Operand<String> query, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SqlDataset", scope.makeOpName("SqlDataset"));
+    opBuilder.addInput(driverName.asOutput());
+    opBuilder.addInput(dataSourceName.asOutput());
+    opBuilder.addInput(query.asOutput());
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new SqlDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private SqlDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SqrtGrad.java java-ops/org/tensorflow/op/core/SqrtGrad.java
--- java/org/tensorflow/op/core/SqrtGrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SqrtGrad.java	2018-10-16 20:18:38.566432147 +0900
@@ -0,0 +1,70 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Computes the gradient for the sqrt of `x` wrt its input.
+ * <p>
+ * Specifically, `grad = dy * 0.5 / y`, where `y = sqrt(x)`, and `dy`
+ * is the corresponding input gradient.
+ * 
+ * @param <T> data type for {@code z()} output
+ */
+public final class SqrtGrad<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new SqrtGrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param y 
+   * @param dy 
+   * @return a new instance of SqrtGrad
+   */
+  public static <T> SqrtGrad<T> create(Scope scope, Operand<T> y, Operand<T> dy) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SqrtGrad", scope.makeOpName("SqrtGrad"));
+    opBuilder.addInput(y.asOutput());
+    opBuilder.addInput(dy.asOutput());
+    return new SqrtGrad<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return z;
+  }
+  
+  private Output<T> z;
+  
+  private SqrtGrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Sqrt.java java-ops/org/tensorflow/op/core/Sqrt.java
--- java/org/tensorflow/op/core/Sqrt.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Sqrt.java	2018-10-16 20:18:38.565432147 +0900
@@ -0,0 +1,69 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes square root of x element-wise.
+ * <p>
+ * I.e., \\(y = \sqrt{x} = x^{1/2}\\).
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class Sqrt<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Sqrt operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of Sqrt
+   */
+  public static <T> Sqrt<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Sqrt", scope.makeOpName("Sqrt"));
+    opBuilder.addInput(x.asOutput());
+    return new Sqrt<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private Sqrt(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SquaredDifference.java java-ops/org/tensorflow/op/core/SquaredDifference.java
--- java/org/tensorflow/op/core/SquaredDifference.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SquaredDifference.java	2018-10-16 20:18:38.566432147 +0900
@@ -0,0 +1,72 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns (x - y)(x - y) element-wise.
+ * <p>
+ * <i>NOTE</i>: `SquaredDifference` supports broadcasting. More about broadcasting
+ * [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
+ * 
+ * @param <T> data type for {@code z()} output
+ */
+@Operator
+public final class SquaredDifference<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new SquaredDifference operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param y 
+   * @return a new instance of SquaredDifference
+   */
+  public static <T> SquaredDifference<T> create(Scope scope, Operand<T> x, Operand<T> y) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SquaredDifference", scope.makeOpName("SquaredDifference"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(y.asOutput());
+    return new SquaredDifference<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return z;
+  }
+  
+  private Output<T> z;
+  
+  private SquaredDifference(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Square.java java-ops/org/tensorflow/op/core/Square.java
--- java/org/tensorflow/op/core/Square.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Square.java	2018-10-16 20:18:38.566432147 +0900
@@ -0,0 +1,69 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes square of x element-wise.
+ * <p>
+ * I.e., \\(y = x * x = x^2\\).
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class Square<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Square operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of Square
+   */
+  public static <T> Square<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Square", scope.makeOpName("Square"));
+    opBuilder.addInput(x.asOutput());
+    return new Square<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private Square(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Squeeze.java java-ops/org/tensorflow/op/core/Squeeze.java
--- java/org/tensorflow/op/core/Squeeze.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Squeeze.java	2018-10-16 20:18:38.567432146 +0900
@@ -0,0 +1,129 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Removes dimensions of size 1 from the shape of a tensor.
+ * <p>
+ * Given a tensor `input`, this operation returns a tensor of the same type with
+ * all dimensions of size 1 removed. If you don't want to remove all size 1
+ * dimensions, you can remove specific size 1 dimensions by specifying
+ * `axis`.
+ * <p>
+ * For example:
+ * <pre>{@code
+ * # 't' is a tensor of shape [1, 2, 1, 3, 1, 1]
+ * shape(squeeze(t)) ==> [2, 3]
+ * }</pre>
+ * Or, to remove specific size 1 dimensions:
+ * <pre>{@code
+ * # 't' is a tensor of shape [1, 2, 1, 3, 1, 1]
+ * shape(squeeze(t, [2, 4])) ==> [1, 2, 3, 1]
+ * }</pre>
+ * 
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class Squeeze<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Squeeze}
+   */
+  public static class Options {
+    
+    /**
+     * @param axis If specified, only squeezes the dimensions listed. The dimension
+     * index starts at 0. It is an error to squeeze a dimension that is not 1. Must
+     * be in the range `[-rank(input), rank(input))`.
+     */
+    public Options axis(List<Long> axis) {
+      this.axis = axis;
+      return this;
+    }
+    
+    private List<Long> axis;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Squeeze operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input The `input` to squeeze.
+   * @param options carries optional attributes values
+   * @return a new instance of Squeeze
+   */
+  public static <T> Squeeze<T> create(Scope scope, Operand<T> input, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Squeeze", scope.makeOpName("Squeeze"));
+    opBuilder.addInput(input.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.axis != null) {
+          long[] axisArray = new long[opts.axis.size()];
+          for (int i = 0; i < axisArray.length; ++i) {
+            axisArray[i] = opts.axis.get(i);
+          }
+          opBuilder.setAttr("squeeze_dims", axisArray);
+        }
+      }
+    }
+    return new Squeeze<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param axis If specified, only squeezes the dimensions listed. The dimension
+   * index starts at 0. It is an error to squeeze a dimension that is not 1. Must
+   * be in the range `[-rank(input), rank(input))`.
+   */
+  public static Options axis(List<Long> axis) {
+    return new Options().axis(axis);
+  }
+  
+  /**
+   * Contains the same data as `input`, but has one or more dimensions of
+   * size 1 removed.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private Squeeze(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Stack.java java-ops/org/tensorflow/op/core/Stack.java
--- java/org/tensorflow/op/core/Stack.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Stack.java	2018-10-16 20:18:38.373432282 +0900
@@ -0,0 +1,122 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Packs a list of `N` rank-`R` tensors into one rank-`(R+1)` tensor.
+ * <p>
+ * Packs the `N` tensors in `values` into a tensor with rank one higher than each
+ * tensor in `values`, by packing them along the `axis` dimension.
+ * Given a list of tensors of shape `(A, B, C)`;
+ * <p>
+ * if `axis == 0` then the `output` tensor will have the shape `(N, A, B, C)`.
+ * if `axis == 1` then the `output` tensor will have the shape `(A, N, B, C)`.
+ * Etc.
+ * <p>
+ * For example:
+ * <pre>{@code
+ * # 'x' is [1, 4]
+ * # 'y' is [2, 5]
+ * # 'z' is [3, 6]
+ * pack([x, y, z]) => [[1, 4], [2, 5], [3, 6]]  # Pack along first dim.
+ * pack([x, y, z], axis=1) => [[1, 2, 3], [4, 5, 6]]
+ * }</pre>
+ * This is the opposite of `unpack`.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class Stack<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Stack}
+   */
+  public static class Options {
+    
+    /**
+     * @param axis Dimension along which to pack.  Negative values wrap around, so the
+     * valid range is `[-(R+1), R+1)`.
+     */
+    public Options axis(Long axis) {
+      this.axis = axis;
+      return this;
+    }
+    
+    private Long axis;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Stack operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param values Must be of same shape and type.
+   * @param options carries optional attributes values
+   * @return a new instance of Stack
+   */
+  public static <T> Stack<T> create(Scope scope, Operand<T> values, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Pack", scope.makeOpName("Stack"));
+    opBuilder.addInput(values.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.axis != null) {
+          opBuilder.setAttr("axis", opts.axis);
+        }
+      }
+    }
+    return new Stack<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param axis Dimension along which to pack.  Negative values wrap around, so the
+   * valid range is `[-(R+1), R+1)`.
+   */
+  public static Options axis(Long axis) {
+    return new Options().axis(axis);
+  }
+  
+  /**
+   * The packed tensor.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private Stack(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/StageClear.java java-ops/org/tensorflow/op/core/StageClear.java
--- java/org/tensorflow/op/core/StageClear.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/StageClear.java	2018-10-16 20:18:38.568432145 +0900
@@ -0,0 +1,146 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Op removes all elements in the underlying container.
+ */
+@Operator
+public final class StageClear extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.StageClear}
+   */
+  public static class Options {
+    
+    /**
+     * @param capacity 
+     */
+    public Options capacity(Long capacity) {
+      this.capacity = capacity;
+      return this;
+    }
+    
+    /**
+     * @param memoryLimit 
+     */
+    public Options memoryLimit(Long memoryLimit) {
+      this.memoryLimit = memoryLimit;
+      return this;
+    }
+    
+    /**
+     * @param container 
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName 
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private Long capacity;
+    private Long memoryLimit;
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new StageClear operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param dtypes 
+   * @param options carries optional attributes values
+   * @return a new instance of StageClear
+   */
+  public static StageClear create(Scope scope, List<Class<?>> dtypes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("StageClear", scope.makeOpName("StageClear"));
+    DataType[] dtypesArray = new DataType[dtypes.size()];
+    for (int i = 0; i < dtypesArray.length; ++i) {
+      dtypesArray[i] = DataType.fromClass(dtypes.get(i));
+    }
+    opBuilder.setAttr("dtypes", dtypesArray);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.capacity != null) {
+          opBuilder.setAttr("capacity", opts.capacity);
+        }
+        if (opts.memoryLimit != null) {
+          opBuilder.setAttr("memory_limit", opts.memoryLimit);
+        }
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new StageClear(opBuilder.build());
+  }
+  
+  /**
+   * @param capacity 
+   */
+  public static Options capacity(Long capacity) {
+    return new Options().capacity(capacity);
+  }
+  
+  /**
+   * @param memoryLimit 
+   */
+  public static Options memoryLimit(Long memoryLimit) {
+    return new Options().memoryLimit(memoryLimit);
+  }
+  
+  /**
+   * @param container 
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName 
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  
+  private StageClear(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Stage.java java-ops/org/tensorflow/op/core/Stage.java
--- java/org/tensorflow/op/core/Stage.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Stage.java	2018-10-16 20:18:38.567432146 +0900
@@ -0,0 +1,152 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Stage values similar to a lightweight Enqueue.
+ * <p>
+ * The basic functionality of this Op is similar to a queue with many
+ * fewer capabilities and options.  This Op is optimized for performance.
+ */
+@Operator
+public final class Stage extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Stage}
+   */
+  public static class Options {
+    
+    /**
+     * @param capacity Maximum number of elements in the Staging Area. If > 0, inserts
+     * on the container will block when the capacity is reached.
+     */
+    public Options capacity(Long capacity) {
+      this.capacity = capacity;
+      return this;
+    }
+    
+    /**
+     * @param memoryLimit The maximum number of bytes allowed for Tensors in the Staging Area.
+     * If > 0, inserts will block until sufficient space is available.
+     */
+    public Options memoryLimit(Long memoryLimit) {
+      this.memoryLimit = memoryLimit;
+      return this;
+    }
+    
+    /**
+     * @param container If non-empty, this queue is placed in the given container. Otherwise,
+     * a default container is used.
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName It is necessary to match this name to the matching Unstage Op.
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private Long capacity;
+    private Long memoryLimit;
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Stage operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param values a list of tensors
+   * dtypes A list of data types that inserted values should adhere to.
+   * @param options carries optional attributes values
+   * @return a new instance of Stage
+   */
+  public static Stage create(Scope scope, Iterable<Operand<?>> values, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Stage", scope.makeOpName("Stage"));
+    opBuilder.addInputList(Operands.asOutputs(values));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.capacity != null) {
+          opBuilder.setAttr("capacity", opts.capacity);
+        }
+        if (opts.memoryLimit != null) {
+          opBuilder.setAttr("memory_limit", opts.memoryLimit);
+        }
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new Stage(opBuilder.build());
+  }
+  
+  /**
+   * @param capacity Maximum number of elements in the Staging Area. If > 0, inserts
+   * on the container will block when the capacity is reached.
+   */
+  public static Options capacity(Long capacity) {
+    return new Options().capacity(capacity);
+  }
+  
+  /**
+   * @param memoryLimit The maximum number of bytes allowed for Tensors in the Staging Area.
+   * If > 0, inserts will block until sufficient space is available.
+   */
+  public static Options memoryLimit(Long memoryLimit) {
+    return new Options().memoryLimit(memoryLimit);
+  }
+  
+  /**
+   * @param container If non-empty, this queue is placed in the given container. Otherwise,
+   * a default container is used.
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName It is necessary to match this name to the matching Unstage Op.
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  
+  private Stage(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/StagePeek.java java-ops/org/tensorflow/op/core/StagePeek.java
--- java/org/tensorflow/op/core/StagePeek.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/StagePeek.java	2018-10-16 20:18:38.568432145 +0900
@@ -0,0 +1,173 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.Iterator;
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Op peeks at the values at the specified index.  If the
+ * <p>
+ * underlying container does not contain sufficient elements
+ * this op will block until it does.   This Op is optimized for
+ * performance.
+ */
+@Operator
+public final class StagePeek extends PrimitiveOp implements Iterable<Operand<Object>> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.StagePeek}
+   */
+  public static class Options {
+    
+    /**
+     * @param capacity 
+     */
+    public Options capacity(Long capacity) {
+      this.capacity = capacity;
+      return this;
+    }
+    
+    /**
+     * @param memoryLimit 
+     */
+    public Options memoryLimit(Long memoryLimit) {
+      this.memoryLimit = memoryLimit;
+      return this;
+    }
+    
+    /**
+     * @param container 
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName 
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private Long capacity;
+    private Long memoryLimit;
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new StagePeek operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param index 
+   * @param dtypes 
+   * @param options carries optional attributes values
+   * @return a new instance of StagePeek
+   */
+  public static StagePeek create(Scope scope, Operand<Integer> index, List<Class<?>> dtypes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("StagePeek", scope.makeOpName("StagePeek"));
+    opBuilder.addInput(index.asOutput());
+    DataType[] dtypesArray = new DataType[dtypes.size()];
+    for (int i = 0; i < dtypesArray.length; ++i) {
+      dtypesArray[i] = DataType.fromClass(dtypes.get(i));
+    }
+    opBuilder.setAttr("dtypes", dtypesArray);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.capacity != null) {
+          opBuilder.setAttr("capacity", opts.capacity);
+        }
+        if (opts.memoryLimit != null) {
+          opBuilder.setAttr("memory_limit", opts.memoryLimit);
+        }
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new StagePeek(opBuilder.build());
+  }
+  
+  /**
+   * @param capacity 
+   */
+  public static Options capacity(Long capacity) {
+    return new Options().capacity(capacity);
+  }
+  
+  /**
+   * @param memoryLimit 
+   */
+  public static Options memoryLimit(Long memoryLimit) {
+    return new Options().memoryLimit(memoryLimit);
+  }
+  
+  /**
+   * @param container 
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName 
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   */
+  public List<Output<?>> values() {
+    return values;
+  }
+  
+  @Override
+  @SuppressWarnings({"rawtypes", "unchecked"})
+  public Iterator<Operand<Object>> iterator() {
+    return (Iterator) values.iterator();
+  }
+  
+  private List<Output<?>> values;
+  
+  private StagePeek(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    int valuesLength = operation.outputListLength("values");
+    values = Arrays.asList(operation.outputList(outputIdx, valuesLength));
+    outputIdx += valuesLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/StageSize.java java-ops/org/tensorflow/op/core/StageSize.java
--- java/org/tensorflow/op/core/StageSize.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/StageSize.java	2018-10-16 20:18:38.568432145 +0900
@@ -0,0 +1,162 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Op returns the number of elements in the underlying container.
+ */
+@Operator
+public final class StageSize extends PrimitiveOp implements Operand<Integer> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.StageSize}
+   */
+  public static class Options {
+    
+    /**
+     * @param capacity 
+     */
+    public Options capacity(Long capacity) {
+      this.capacity = capacity;
+      return this;
+    }
+    
+    /**
+     * @param memoryLimit 
+     */
+    public Options memoryLimit(Long memoryLimit) {
+      this.memoryLimit = memoryLimit;
+      return this;
+    }
+    
+    /**
+     * @param container 
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName 
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private Long capacity;
+    private Long memoryLimit;
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new StageSize operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param dtypes 
+   * @param options carries optional attributes values
+   * @return a new instance of StageSize
+   */
+  public static StageSize create(Scope scope, List<Class<?>> dtypes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("StageSize", scope.makeOpName("StageSize"));
+    DataType[] dtypesArray = new DataType[dtypes.size()];
+    for (int i = 0; i < dtypesArray.length; ++i) {
+      dtypesArray[i] = DataType.fromClass(dtypes.get(i));
+    }
+    opBuilder.setAttr("dtypes", dtypesArray);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.capacity != null) {
+          opBuilder.setAttr("capacity", opts.capacity);
+        }
+        if (opts.memoryLimit != null) {
+          opBuilder.setAttr("memory_limit", opts.memoryLimit);
+        }
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new StageSize(opBuilder.build());
+  }
+  
+  /**
+   * @param capacity 
+   */
+  public static Options capacity(Long capacity) {
+    return new Options().capacity(capacity);
+  }
+  
+  /**
+   * @param memoryLimit 
+   */
+  public static Options memoryLimit(Long memoryLimit) {
+    return new Options().memoryLimit(memoryLimit);
+  }
+  
+  /**
+   * @param container 
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName 
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   */
+  public Output<Integer> size() {
+    return size;
+  }
+  
+  @Override
+  public Output<Integer> asOutput() {
+    return size;
+  }
+  
+  private Output<Integer> size;
+  
+  private StageSize(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    size = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/StatelessMultinomial.java java-ops/org/tensorflow/op/core/StatelessMultinomial.java
--- java/org/tensorflow/op/core/StatelessMultinomial.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/StatelessMultinomial.java	2018-10-16 20:18:38.569432144 +0900
@@ -0,0 +1,91 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Draws samples from a multinomial distribution.
+ * 
+ * @param <V> data type for {@code output()} output
+ */
+@Operator
+public final class StatelessMultinomial<V extends Number> extends PrimitiveOp implements Operand<V> {
+  
+  /**
+   * Factory method to create a class to wrap a new StatelessMultinomial operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param logits 2-D Tensor with shape `[batch_size, num_classes]`.  Each slice `[i, :]`
+   * represents the unnormalized log probabilities for all classes.
+   * @param numSamples 0-D.  Number of independent samples to draw for each row slice.
+   * @param seed 2 seeds (shape [2]).
+   * @param outputDtype 
+   * @return a new instance of StatelessMultinomial
+   */
+  public static <V extends Number, T extends Number, U extends Number> StatelessMultinomial<V> create(Scope scope, Operand<T> logits, Operand<Integer> numSamples, Operand<U> seed, Class<V> outputDtype) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("StatelessMultinomial", scope.makeOpName("StatelessMultinomial"));
+    opBuilder.addInput(logits.asOutput());
+    opBuilder.addInput(numSamples.asOutput());
+    opBuilder.addInput(seed.asOutput());
+    opBuilder.setAttr("output_dtype", DataType.fromClass(outputDtype));
+    return new StatelessMultinomial<V>(opBuilder.build());
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new StatelessMultinomial operation to the graph, using default output types.
+   * 
+   * @param scope current graph scope
+   * @param logits 2-D Tensor with shape `[batch_size, num_classes]`.  Each slice `[i, :]`
+   * represents the unnormalized log probabilities for all classes.
+   * @param numSamples 0-D.  Number of independent samples to draw for each row slice.
+   * @param seed 2 seeds (shape [2]).
+   * @return a new instance of StatelessMultinomial
+   */
+  public static <T extends Number, U extends Number> StatelessMultinomial<Long> create(Scope scope, Operand<T> logits, Operand<Integer> numSamples, Operand<U> seed) {
+    return create(scope, logits, numSamples, seed, Long.class);
+  }
+  
+  /**
+   * 2-D Tensor with shape `[batch_size, num_samples]`.  Each slice `[i, :]`
+   * contains the drawn class labels with range `[0, num_classes)`.
+   */
+  public Output<V> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<V> asOutput() {
+    return output;
+  }
+  
+  private Output<V> output;
+  
+  private StatelessMultinomial(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/StatelessRandomNormal.java java-ops/org/tensorflow/op/core/StatelessRandomNormal.java
--- java/org/tensorflow/op/core/StatelessRandomNormal.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/StatelessRandomNormal.java	2018-10-16 20:18:38.569432144 +0900
@@ -0,0 +1,89 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Outputs deterministic pseudorandom values from a normal distribution.
+ * <p>
+ * The generated values will have mean 0 and standard deviation 1.
+ * <p>
+ * The outputs are a deterministic function of `shape` and `seed`.
+ * 
+ * @param <V> data type for {@code output()} output
+ */
+@Operator
+public final class StatelessRandomNormal<V extends Number> extends PrimitiveOp implements Operand<V> {
+  
+  /**
+   * Factory method to create a class to wrap a new StatelessRandomNormal operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param shape The shape of the output tensor.
+   * @param seed 2 seeds (shape [2]).
+   * @param dtype The type of the output.
+   * @return a new instance of StatelessRandomNormal
+   */
+  public static <V extends Number, T extends Number, U extends Number> StatelessRandomNormal<V> create(Scope scope, Operand<T> shape, Operand<U> seed, Class<V> dtype) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("StatelessRandomNormal", scope.makeOpName("StatelessRandomNormal"));
+    opBuilder.addInput(shape.asOutput());
+    opBuilder.addInput(seed.asOutput());
+    opBuilder.setAttr("dtype", DataType.fromClass(dtype));
+    return new StatelessRandomNormal<V>(opBuilder.build());
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new StatelessRandomNormal operation to the graph, using default output types.
+   * 
+   * @param scope current graph scope
+   * @param shape The shape of the output tensor.
+   * @param seed 2 seeds (shape [2]).
+   * @return a new instance of StatelessRandomNormal
+   */
+  public static <T extends Number, U extends Number> StatelessRandomNormal<Float> create(Scope scope, Operand<T> shape, Operand<U> seed) {
+    return create(scope, shape, seed, Float.class);
+  }
+  
+  /**
+   * Random values with specified shape.
+   */
+  public Output<V> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<V> asOutput() {
+    return output;
+  }
+  
+  private Output<V> output;
+  
+  private StatelessRandomNormal(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/StatelessRandomUniform.java java-ops/org/tensorflow/op/core/StatelessRandomUniform.java
--- java/org/tensorflow/op/core/StatelessRandomUniform.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/StatelessRandomUniform.java	2018-10-16 20:18:38.570432144 +0900
@@ -0,0 +1,90 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Outputs deterministic pseudorandom random values from a uniform distribution.
+ * <p>
+ * The generated values follow a uniform distribution in the range `[0, 1)`. The
+ * lower bound 0 is included in the range, while the upper bound 1 is excluded.
+ * <p>
+ * The outputs are a deterministic function of `shape` and `seed`.
+ * 
+ * @param <V> data type for {@code output()} output
+ */
+@Operator
+public final class StatelessRandomUniform<V extends Number> extends PrimitiveOp implements Operand<V> {
+  
+  /**
+   * Factory method to create a class to wrap a new StatelessRandomUniform operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param shape The shape of the output tensor.
+   * @param seed 2 seeds (shape [2]).
+   * @param dtype The type of the output.
+   * @return a new instance of StatelessRandomUniform
+   */
+  public static <V extends Number, T extends Number, U extends Number> StatelessRandomUniform<V> create(Scope scope, Operand<T> shape, Operand<U> seed, Class<V> dtype) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("StatelessRandomUniform", scope.makeOpName("StatelessRandomUniform"));
+    opBuilder.addInput(shape.asOutput());
+    opBuilder.addInput(seed.asOutput());
+    opBuilder.setAttr("dtype", DataType.fromClass(dtype));
+    return new StatelessRandomUniform<V>(opBuilder.build());
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new StatelessRandomUniform operation to the graph, using default output types.
+   * 
+   * @param scope current graph scope
+   * @param shape The shape of the output tensor.
+   * @param seed 2 seeds (shape [2]).
+   * @return a new instance of StatelessRandomUniform
+   */
+  public static <T extends Number, U extends Number> StatelessRandomUniform<Float> create(Scope scope, Operand<T> shape, Operand<U> seed) {
+    return create(scope, shape, seed, Float.class);
+  }
+  
+  /**
+   * Random values with specified shape.
+   */
+  public Output<V> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<V> asOutput() {
+    return output;
+  }
+  
+  private Output<V> output;
+  
+  private StatelessRandomUniform(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/StatelessTruncatedNormal.java java-ops/org/tensorflow/op/core/StatelessTruncatedNormal.java
--- java/org/tensorflow/op/core/StatelessTruncatedNormal.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/StatelessTruncatedNormal.java	2018-10-16 20:18:38.570432144 +0900
@@ -0,0 +1,91 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Outputs deterministic pseudorandom values from a truncated normal distribution.
+ * <p>
+ * The generated values follow a normal distribution with mean 0 and standard
+ * deviation 1, except that values whose magnitude is more than 2 standard
+ * deviations from the mean are dropped and re-picked.
+ * <p>
+ * The outputs are a deterministic function of `shape` and `seed`.
+ * 
+ * @param <V> data type for {@code output()} output
+ */
+@Operator
+public final class StatelessTruncatedNormal<V extends Number> extends PrimitiveOp implements Operand<V> {
+  
+  /**
+   * Factory method to create a class to wrap a new StatelessTruncatedNormal operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param shape The shape of the output tensor.
+   * @param seed 2 seeds (shape [2]).
+   * @param dtype The type of the output.
+   * @return a new instance of StatelessTruncatedNormal
+   */
+  public static <V extends Number, T extends Number, U extends Number> StatelessTruncatedNormal<V> create(Scope scope, Operand<T> shape, Operand<U> seed, Class<V> dtype) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("StatelessTruncatedNormal", scope.makeOpName("StatelessTruncatedNormal"));
+    opBuilder.addInput(shape.asOutput());
+    opBuilder.addInput(seed.asOutput());
+    opBuilder.setAttr("dtype", DataType.fromClass(dtype));
+    return new StatelessTruncatedNormal<V>(opBuilder.build());
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new StatelessTruncatedNormal operation to the graph, using default output types.
+   * 
+   * @param scope current graph scope
+   * @param shape The shape of the output tensor.
+   * @param seed 2 seeds (shape [2]).
+   * @return a new instance of StatelessTruncatedNormal
+   */
+  public static <T extends Number, U extends Number> StatelessTruncatedNormal<Float> create(Scope scope, Operand<T> shape, Operand<U> seed) {
+    return create(scope, shape, seed, Float.class);
+  }
+  
+  /**
+   * Random values with specified shape.
+   */
+  public Output<V> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<V> asOutput() {
+    return output;
+  }
+  
+  private Output<V> output;
+  
+  private StatelessTruncatedNormal(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/StaticRegexFullMatch.java java-ops/org/tensorflow/op/core/StaticRegexFullMatch.java
--- java/org/tensorflow/op/core/StaticRegexFullMatch.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/StaticRegexFullMatch.java	2018-10-16 20:18:38.571432143 +0900
@@ -0,0 +1,73 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Check if the input matches the regex pattern.
+ * <p>
+ * The input is a string tensor of any shape. The pattern is the
+ * regular expression to be matched with every element of the input tensor.
+ * The boolean values (True or False) of the output tensor indicate
+ * if the input matches the regex pattern provided.
+ * <p>
+ * The pattern follows the re2 syntax (https://github.com/google/re2/wiki/Syntax)
+ */
+public final class StaticRegexFullMatch extends PrimitiveOp implements Operand<Boolean> {
+  
+  /**
+   * Factory method to create a class to wrap a new StaticRegexFullMatch operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input A string tensor of the text to be processed.
+   * @param pattern The regular expression to match the input.
+   * @return a new instance of StaticRegexFullMatch
+   */
+  public static StaticRegexFullMatch create(Scope scope, Operand<String> input, String pattern) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("StaticRegexFullMatch", scope.makeOpName("StaticRegexFullMatch"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.setAttr("pattern", pattern);
+    return new StaticRegexFullMatch(opBuilder.build());
+  }
+  
+  /**
+   * A bool tensor with the same shape as `input`.
+   */
+  public Output<Boolean> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<Boolean> asOutput() {
+    return output;
+  }
+  
+  private Output<Boolean> output;
+  
+  private StaticRegexFullMatch(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/StaticRegexReplace.java java-ops/org/tensorflow/op/core/StaticRegexReplace.java
--- java/org/tensorflow/op/core/StaticRegexReplace.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/StaticRegexReplace.java	2018-10-16 20:18:38.571432143 +0900
@@ -0,0 +1,106 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Replaces the match of pattern in input with rewrite.
+ * <p>
+ * It follows the re2 syntax (https://github.com/google/re2/wiki/Syntax)
+ */
+public final class StaticRegexReplace extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.StaticRegexReplace}
+   */
+  public static class Options {
+    
+    /**
+     * @param replaceGlobal If True, the replacement is global, otherwise the replacement
+     * is done only on the first match.
+     */
+    public Options replaceGlobal(Boolean replaceGlobal) {
+      this.replaceGlobal = replaceGlobal;
+      return this;
+    }
+    
+    private Boolean replaceGlobal;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new StaticRegexReplace operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input The text to be processed.
+   * @param pattern The regular expression to match the input.
+   * @param rewrite The rewrite to be applied to the matched expresion.
+   * @param options carries optional attributes values
+   * @return a new instance of StaticRegexReplace
+   */
+  public static StaticRegexReplace create(Scope scope, Operand<String> input, String pattern, String rewrite, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("StaticRegexReplace", scope.makeOpName("StaticRegexReplace"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.setAttr("pattern", pattern);
+    opBuilder.setAttr("rewrite", rewrite);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.replaceGlobal != null) {
+          opBuilder.setAttr("replace_global", opts.replaceGlobal);
+        }
+      }
+    }
+    return new StaticRegexReplace(opBuilder.build());
+  }
+  
+  /**
+   * @param replaceGlobal If True, the replacement is global, otherwise the replacement
+   * is done only on the first match.
+   */
+  public static Options replaceGlobal(Boolean replaceGlobal) {
+    return new Options().replaceGlobal(replaceGlobal);
+  }
+  
+  /**
+   * The text after applying pattern and rewrite.
+   */
+  public Output<String> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return output;
+  }
+  
+  private Output<String> output;
+  
+  private StaticRegexReplace(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/StatsAggregatorHandle.java java-ops/org/tensorflow/op/core/StatsAggregatorHandle.java
--- java/org/tensorflow/op/core/StatsAggregatorHandle.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/StatsAggregatorHandle.java	2018-10-16 20:18:38.571432143 +0900
@@ -0,0 +1,117 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Creates a statistics manager resource.
+ */
+@Operator
+public final class StatsAggregatorHandle extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.StatsAggregatorHandle}
+   */
+  public static class Options {
+    
+    /**
+     * @param container 
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName 
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new StatsAggregatorHandle operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param options carries optional attributes values
+   * @return a new instance of StatsAggregatorHandle
+   */
+  public static StatsAggregatorHandle create(Scope scope, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("StatsAggregatorHandle", scope.makeOpName("StatsAggregatorHandle"));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new StatsAggregatorHandle(opBuilder.build());
+  }
+  
+  /**
+   * @param container 
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName 
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private StatsAggregatorHandle(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/StatsAggregatorSummary.java java-ops/org/tensorflow/op/core/StatsAggregatorSummary.java
--- java/org/tensorflow/op/core/StatsAggregatorSummary.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/StatsAggregatorSummary.java	2018-10-16 20:18:38.571432143 +0900
@@ -0,0 +1,65 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Produces a summary of any statistics recorded by the given statistics manager.
+ */
+@Operator
+public final class StatsAggregatorSummary extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Factory method to create a class to wrap a new StatsAggregatorSummary operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param iterator 
+   * @return a new instance of StatsAggregatorSummary
+   */
+  public static StatsAggregatorSummary create(Scope scope, Operand<?> iterator) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("StatsAggregatorSummary", scope.makeOpName("StatsAggregatorSummary"));
+    opBuilder.addInput(iterator.asOutput());
+    return new StatsAggregatorSummary(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<String> summary() {
+    return summary;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return summary;
+  }
+  
+  private Output<String> summary;
+  
+  private StatsAggregatorSummary(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    summary = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/StopGradient.java java-ops/org/tensorflow/op/core/StopGradient.java
--- java/org/tensorflow/op/core/StopGradient.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/StopGradient.java	2018-10-16 20:18:38.572432143 +0900
@@ -0,0 +1,92 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Stops gradient computation.
+ * <p>
+ * When executed in a graph, this op outputs its input tensor as-is.
+ * <p>
+ * When building ops to compute gradients, this op prevents the contribution of
+ * its inputs to be taken into account.  Normally, the gradient generator adds ops
+ * to a graph to compute the derivatives of a specified 'loss' by recursively
+ * finding out inputs that contributed to its computation.  If you insert this op
+ * in the graph it inputs are masked from the gradient generator.  They are not
+ * taken into account for computing gradients.
+ * <p>
+ * This is useful any time you want to compute a value with TensorFlow but need
+ * to pretend that the value was a constant. Some examples include:
+ * <ul>
+ * <li>
+ * The <i>EM</i> algorithm where the <i>M-step</i> should not involve backpropagation
+ *    through the output of the <i>E-step</i>.
+ * </li>
+ * <li>
+ * Contrastive divergence training of Boltzmann machines where, when
+ *    differentiating the energy function, the training must not backpropagate
+ *    through the graph that generated the samples from the model.
+ * </li>
+ * <li>
+ * Adversarial training, where no backprop should happen through the adversarial
+ *    example generation process.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class StopGradient<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new StopGradient operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @return a new instance of StopGradient
+   */
+  public static <T> StopGradient<T> create(Scope scope, Operand<T> input) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("StopGradient", scope.makeOpName("StopGradient"));
+    opBuilder.addInput(input.asOutput());
+    return new StopGradient<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private StopGradient(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/StridedSliceAssign.java java-ops/org/tensorflow/op/core/StridedSliceAssign.java
--- java/org/tensorflow/op/core/StridedSliceAssign.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/StridedSliceAssign.java	2018-10-16 20:18:38.575432140 +0900
@@ -0,0 +1,192 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Assign `value` to the sliced l-value reference of `ref`.
+ * <p>
+ * The values of `value` are assigned to the positions in the variable
+ * `ref` that are selected by the slice parameters. The slice parameters
+ * `begin, `end`, `strides`, etc. work exactly as in `StridedSlice`.
+ * <p>
+ * NOTE this op currently does not support broadcasting and so `value`'s
+ * shape must be exactly the shape produced by the slice of `ref`.
+ * 
+ * @param <T> data type for {@code outputRef()} output
+ */
+@Operator
+public final class StridedSliceAssign<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.StridedSliceAssign}
+   */
+  public static class Options {
+    
+    /**
+     * @param beginMask 
+     */
+    public Options beginMask(Long beginMask) {
+      this.beginMask = beginMask;
+      return this;
+    }
+    
+    /**
+     * @param endMask 
+     */
+    public Options endMask(Long endMask) {
+      this.endMask = endMask;
+      return this;
+    }
+    
+    /**
+     * @param ellipsisMask 
+     */
+    public Options ellipsisMask(Long ellipsisMask) {
+      this.ellipsisMask = ellipsisMask;
+      return this;
+    }
+    
+    /**
+     * @param newAxisMask 
+     */
+    public Options newAxisMask(Long newAxisMask) {
+      this.newAxisMask = newAxisMask;
+      return this;
+    }
+    
+    /**
+     * @param shrinkAxisMask 
+     */
+    public Options shrinkAxisMask(Long shrinkAxisMask) {
+      this.shrinkAxisMask = shrinkAxisMask;
+      return this;
+    }
+    
+    private Long beginMask;
+    private Long endMask;
+    private Long ellipsisMask;
+    private Long newAxisMask;
+    private Long shrinkAxisMask;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new StridedSliceAssign operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param ref 
+   * @param begin 
+   * @param end 
+   * @param strides 
+   * @param value 
+   * @param options carries optional attributes values
+   * @return a new instance of StridedSliceAssign
+   */
+  public static <T, U extends Number> StridedSliceAssign<T> create(Scope scope, Operand<T> ref, Operand<U> begin, Operand<U> end, Operand<U> strides, Operand<T> value, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("StridedSliceAssign", scope.makeOpName("StridedSliceAssign"));
+    opBuilder.addInput(ref.asOutput());
+    opBuilder.addInput(begin.asOutput());
+    opBuilder.addInput(end.asOutput());
+    opBuilder.addInput(strides.asOutput());
+    opBuilder.addInput(value.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.beginMask != null) {
+          opBuilder.setAttr("begin_mask", opts.beginMask);
+        }
+        if (opts.endMask != null) {
+          opBuilder.setAttr("end_mask", opts.endMask);
+        }
+        if (opts.ellipsisMask != null) {
+          opBuilder.setAttr("ellipsis_mask", opts.ellipsisMask);
+        }
+        if (opts.newAxisMask != null) {
+          opBuilder.setAttr("new_axis_mask", opts.newAxisMask);
+        }
+        if (opts.shrinkAxisMask != null) {
+          opBuilder.setAttr("shrink_axis_mask", opts.shrinkAxisMask);
+        }
+      }
+    }
+    return new StridedSliceAssign<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param beginMask 
+   */
+  public static Options beginMask(Long beginMask) {
+    return new Options().beginMask(beginMask);
+  }
+  
+  /**
+   * @param endMask 
+   */
+  public static Options endMask(Long endMask) {
+    return new Options().endMask(endMask);
+  }
+  
+  /**
+   * @param ellipsisMask 
+   */
+  public static Options ellipsisMask(Long ellipsisMask) {
+    return new Options().ellipsisMask(ellipsisMask);
+  }
+  
+  /**
+   * @param newAxisMask 
+   */
+  public static Options newAxisMask(Long newAxisMask) {
+    return new Options().newAxisMask(newAxisMask);
+  }
+  
+  /**
+   * @param shrinkAxisMask 
+   */
+  public static Options shrinkAxisMask(Long shrinkAxisMask) {
+    return new Options().shrinkAxisMask(shrinkAxisMask);
+  }
+  
+  /**
+   */
+  public Output<T> outputRef() {
+    return outputRef;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return outputRef;
+  }
+  
+  private Output<T> outputRef;
+  
+  private StridedSliceAssign(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    outputRef = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/StridedSliceGrad.java java-ops/org/tensorflow/op/core/StridedSliceGrad.java
--- java/org/tensorflow/op/core/StridedSliceGrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/StridedSliceGrad.java	2018-10-16 20:18:38.575432140 +0900
@@ -0,0 +1,194 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns the gradient of `StridedSlice`.
+ * <p>
+ * Since `StridedSlice` cuts out pieces of its `input` which is size
+ * `shape`, its gradient will have the same shape (which is passed here
+ * as `shape`). The gradient will be zero in any element that the slice
+ * does not select.
+ * <p>
+ * Arguments are the same as StridedSliceGrad with the exception that
+ * `dy` is the input gradient to be propagated and `shape` is the
+ * shape of `StridedSlice`'s `input`.
+ * 
+ * @param <U> data type for {@code output()} output
+ */
+@Operator
+public final class StridedSliceGrad<U> extends PrimitiveOp implements Operand<U> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.StridedSliceGrad}
+   */
+  public static class Options {
+    
+    /**
+     * @param beginMask 
+     */
+    public Options beginMask(Long beginMask) {
+      this.beginMask = beginMask;
+      return this;
+    }
+    
+    /**
+     * @param endMask 
+     */
+    public Options endMask(Long endMask) {
+      this.endMask = endMask;
+      return this;
+    }
+    
+    /**
+     * @param ellipsisMask 
+     */
+    public Options ellipsisMask(Long ellipsisMask) {
+      this.ellipsisMask = ellipsisMask;
+      return this;
+    }
+    
+    /**
+     * @param newAxisMask 
+     */
+    public Options newAxisMask(Long newAxisMask) {
+      this.newAxisMask = newAxisMask;
+      return this;
+    }
+    
+    /**
+     * @param shrinkAxisMask 
+     */
+    public Options shrinkAxisMask(Long shrinkAxisMask) {
+      this.shrinkAxisMask = shrinkAxisMask;
+      return this;
+    }
+    
+    private Long beginMask;
+    private Long endMask;
+    private Long ellipsisMask;
+    private Long newAxisMask;
+    private Long shrinkAxisMask;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new StridedSliceGrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param shape 
+   * @param begin 
+   * @param end 
+   * @param strides 
+   * @param dy 
+   * @param options carries optional attributes values
+   * @return a new instance of StridedSliceGrad
+   */
+  public static <U, T extends Number> StridedSliceGrad<U> create(Scope scope, Operand<T> shape, Operand<T> begin, Operand<T> end, Operand<T> strides, Operand<U> dy, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("StridedSliceGrad", scope.makeOpName("StridedSliceGrad"));
+    opBuilder.addInput(shape.asOutput());
+    opBuilder.addInput(begin.asOutput());
+    opBuilder.addInput(end.asOutput());
+    opBuilder.addInput(strides.asOutput());
+    opBuilder.addInput(dy.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.beginMask != null) {
+          opBuilder.setAttr("begin_mask", opts.beginMask);
+        }
+        if (opts.endMask != null) {
+          opBuilder.setAttr("end_mask", opts.endMask);
+        }
+        if (opts.ellipsisMask != null) {
+          opBuilder.setAttr("ellipsis_mask", opts.ellipsisMask);
+        }
+        if (opts.newAxisMask != null) {
+          opBuilder.setAttr("new_axis_mask", opts.newAxisMask);
+        }
+        if (opts.shrinkAxisMask != null) {
+          opBuilder.setAttr("shrink_axis_mask", opts.shrinkAxisMask);
+        }
+      }
+    }
+    return new StridedSliceGrad<U>(opBuilder.build());
+  }
+  
+  /**
+   * @param beginMask 
+   */
+  public static Options beginMask(Long beginMask) {
+    return new Options().beginMask(beginMask);
+  }
+  
+  /**
+   * @param endMask 
+   */
+  public static Options endMask(Long endMask) {
+    return new Options().endMask(endMask);
+  }
+  
+  /**
+   * @param ellipsisMask 
+   */
+  public static Options ellipsisMask(Long ellipsisMask) {
+    return new Options().ellipsisMask(ellipsisMask);
+  }
+  
+  /**
+   * @param newAxisMask 
+   */
+  public static Options newAxisMask(Long newAxisMask) {
+    return new Options().newAxisMask(newAxisMask);
+  }
+  
+  /**
+   * @param shrinkAxisMask 
+   */
+  public static Options shrinkAxisMask(Long shrinkAxisMask) {
+    return new Options().shrinkAxisMask(shrinkAxisMask);
+  }
+  
+  /**
+   */
+  public Output<U> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<U> asOutput() {
+    return output;
+  }
+  
+  private Output<U> output;
+  
+  private StridedSliceGrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/StridedSlice.java java-ops/org/tensorflow/op/core/StridedSlice.java
--- java/org/tensorflow/op/core/StridedSlice.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/StridedSlice.java	2018-10-16 20:18:38.574432141 +0900
@@ -0,0 +1,309 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Return a strided slice from `input`.
+ * <p>
+ * Note, most python users will want to use the Python `Tensor.__getitem__`
+ * or `Variable.__getitem__` rather than this op directly.
+ * <p>
+ * The goal of this op is to produce a new tensor with a subset of
+ * the elements from the `n` dimensional `input` tensor. The subset is chosen using
+ * a sequence of `m` sparse range specifications encoded into the arguments
+ * of this function. Note, in some cases
+ * `m` could be equal to `n`, but this need not be the case. Each
+ * range specification entry can be one of the following:
+ * <p>
+ * - An ellipsis (...). Ellipses are used to imply zero or more
+ *   dimensions of full-dimension selection and are produced using
+ *   `ellipsis_mask`. For example, `foo[...]` is the identity slice.
+ * <p>
+ * - A new axis. This is used to insert a new shape=1 dimension and is
+ *   produced using `new_axis_mask`. For example, `foo[:, ...]` where
+ *   `foo` is shape `(3, 4)` produces a `(1, 3, 4)` tensor.
+ * <p>
+ * - A range `begin:end:stride`. This is used to specify how much to choose from
+ *   a given dimension. `stride` can be any integer but 0.  `begin` is an integer
+ *   which represents the index of the first value to select while `end` represents
+ *   the index of the last value to select. The number of values selected in each
+ *   dimension is `end - begin` if `stride > 0` and `begin - end` if `stride < 0`.
+ *   `begin` and `end` can be negative where `-1` is the last element, `-2` is
+ *   the second to last. `begin_mask` controls whether to replace the explicitly
+ *   given `begin` with an implicit effective value of `0` if `stride > 0` and
+ *   `-1` if `stride < 0`. `end_mask` is analogous but produces the number
+ *   required to create the largest open interval. For example, given a shape
+ *   `(3,)` tensor `foo[:]`, the effective `begin` and `end` are `0` and `3`. Do
+ *   not assume this is equivalent to `foo[0:-1]` which has an effective `begin`
+ *   and `end` of `0` and `2`. Another example is `foo[-2::-1]` which reverses the
+ *   first dimension of a tensor while dropping the last two (in the original
+ *   order elements). For example `foo = [1,2,3,4]; foo[-2::-1]` is `[4,3]`.
+ * <p>
+ * - A single index. This is used to keep only elements that have a given
+ *   index. For example (`foo[2, :]` on a shape `(5,6)` tensor produces a
+ *   shape `(6,)` tensor. This is encoded in `begin` and `end` and
+ *   `shrink_axis_mask`.
+ * <p>
+ * Each conceptual range specification is encoded in the op's argument. This
+ * encoding is best understand by considering a non-trivial example. In
+ * particular,
+ * `foo[1, 2:4, None, ..., :-3:-1, :]` will be encoded as
+ * <pre>{@code
+ * begin = [1, 2, x, x, 0, x] # x denotes don't care (usually 0)
+ * end = [2, 4, x, x, -3, x]
+ * strides = [1, 1, x, x, -1, 1]
+ * begin_mask = 1<<4 | 1 << 5 = 48
+ * end_mask = 1<<5 = 32
+ * ellipsis_mask = 1<<3 = 8
+ * new_axis_mask = 1<<2 4
+ * shrink_axis_mask = 1<<0
+ * }</pre>
+ * In this case if `foo.shape` is (5, 5, 5, 5, 5, 5) the final shape of
+ * the slice becomes (2, 1, 5, 5, 2, 5).
+ * Let us walk step by step through each argument specification.
+ * <p>
+ * 1.  The first argument in the example slice is turned into `begin = 1` and
+ * `end = begin + 1 = 2`. To disambiguate from the original spec `2:4` we
+ * also set the appropriate bit in `shrink_axis_mask`.
+ * <p>
+ * 2. `2:4` is contributes 2, 4, 1 to begin, end, and stride. All masks have
+ * zero bits contributed.
+ * <p>
+ * 3. None is a synonym for `tf.newaxis`. This means insert a dimension of size 1
+ * dimension in the final shape. Dummy values are contributed to begin,
+ * end and stride, while the new_axis_mask bit is set.
+ * <p>
+ * 4. `...` grab the full ranges from as many dimensions as needed to
+ * fully specify a slice for every dimension of the input shape.
+ * <p>
+ * 5. `:-3:-1` shows the use of negative indices. A negative index `i` associated
+ * with a dimension that has shape `s` is converted to a positive index
+ * `s + i`. So `-1` becomes `s-1` (i.e. the last element). This conversion
+ * is done internally so begin, end and strides receive x, -3, and -1.
+ * The appropriate begin_mask bit is set to indicate the start range is the
+ * full range (ignoring the x).
+ * <p>
+ * 6. `:` indicates that the entire contents of the corresponding dimension
+ * is selected. This is equivalent to `::` or `0::1`. begin, end, and strides
+ * receive 0, 0, and 1, respectively. The appropriate bits in `begin_mask` and
+ * `end_mask` are also set.
+ * <p>
+ * <i>Requirements</i>:
+ *   `0 != strides[i] for i in [0, m)`
+ *   `ellipsis_mask must be a power of two (only one ellipsis)`
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class StridedSlice<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.StridedSlice}
+   */
+  public static class Options {
+    
+    /**
+     * @param beginMask a bitmask where a bit i being 1 means to ignore the begin
+     * value and instead use the largest interval possible. At runtime
+     * begin[i] will be replaced with `[0, n-1)` if `stride[i] > 0` or
+     * `[-1, n-1]` if `stride[i] < 0`
+     */
+    public Options beginMask(Long beginMask) {
+      this.beginMask = beginMask;
+      return this;
+    }
+    
+    /**
+     * @param endMask analogous to `begin_mask`
+     */
+    public Options endMask(Long endMask) {
+      this.endMask = endMask;
+      return this;
+    }
+    
+    /**
+     * @param ellipsisMask a bitmask where bit `i` being 1 means the `i`th
+     * position is actually an ellipsis. One bit at most can be 1.
+     * If `ellipsis_mask == 0`, then an implicit ellipsis mask of `1 << (m+1)`
+     * is provided. This means that `foo[3:5] == foo[3:5, ...]`. An ellipsis
+     * implicitly creates as many range specifications as necessary to fully
+     * specify the sliced range for every dimension. For example for a 4-dimensional
+     * tensor `foo` the slice `foo[2, ..., 5:8]` implies `foo[2, :, :, 5:8]`.
+     */
+    public Options ellipsisMask(Long ellipsisMask) {
+      this.ellipsisMask = ellipsisMask;
+      return this;
+    }
+    
+    /**
+     * @param newAxisMask a bitmask where bit `i` being 1 means the `i`th
+     * specification creates a new shape 1 dimension. For example
+     * `foo[:4, tf.newaxis, :2]` would produce a shape `(4, 1, 2)` tensor.
+     */
+    public Options newAxisMask(Long newAxisMask) {
+      this.newAxisMask = newAxisMask;
+      return this;
+    }
+    
+    /**
+     * @param shrinkAxisMask a bitmask where bit `i` implies that the `i`th
+     * specification should shrink the dimensionality. begin and end
+     * must imply a slice of size 1 in the dimension. For example in
+     * python one might do `foo[:, 3, :]` which would result in
+     * `shrink_axis_mask` being 2.
+     */
+    public Options shrinkAxisMask(Long shrinkAxisMask) {
+      this.shrinkAxisMask = shrinkAxisMask;
+      return this;
+    }
+    
+    private Long beginMask;
+    private Long endMask;
+    private Long ellipsisMask;
+    private Long newAxisMask;
+    private Long shrinkAxisMask;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new StridedSlice operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param begin `begin[k]` specifies the offset into the `k`th range specification.
+   * The exact dimension this corresponds to will be determined by context.
+   * Out-of-bounds values will be silently clamped. If the `k`th bit of
+   * `begin_mask` then `begin[k]` is ignored and the full range of the
+   * appropriate dimension is used instead. Negative values causes indexing
+   * to start from the highest element e.g. If `foo==[1,2,3]` then `foo[-1]==3`.
+   * @param end `end[i]` is like `begin` with the exception that `end_mask` is
+   * used to determine full ranges.
+   * @param strides `strides[i]` specifies the increment in the `i`th specification
+   * after extracting a given element. Negative indices will reverse
+   * the original order. Out or range values are
+   * clamped to `[0,dim[i]) if slice[i]>0` or `[-1,dim[i]-1] if slice[i] < 0`
+   * @param options carries optional attributes values
+   * @return a new instance of StridedSlice
+   */
+  public static <T, U extends Number> StridedSlice<T> create(Scope scope, Operand<T> input, Operand<U> begin, Operand<U> end, Operand<U> strides, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("StridedSlice", scope.makeOpName("StridedSlice"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(begin.asOutput());
+    opBuilder.addInput(end.asOutput());
+    opBuilder.addInput(strides.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.beginMask != null) {
+          opBuilder.setAttr("begin_mask", opts.beginMask);
+        }
+        if (opts.endMask != null) {
+          opBuilder.setAttr("end_mask", opts.endMask);
+        }
+        if (opts.ellipsisMask != null) {
+          opBuilder.setAttr("ellipsis_mask", opts.ellipsisMask);
+        }
+        if (opts.newAxisMask != null) {
+          opBuilder.setAttr("new_axis_mask", opts.newAxisMask);
+        }
+        if (opts.shrinkAxisMask != null) {
+          opBuilder.setAttr("shrink_axis_mask", opts.shrinkAxisMask);
+        }
+      }
+    }
+    return new StridedSlice<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param beginMask a bitmask where a bit i being 1 means to ignore the begin
+   * value and instead use the largest interval possible. At runtime
+   * begin[i] will be replaced with `[0, n-1)` if `stride[i] > 0` or
+   * `[-1, n-1]` if `stride[i] < 0`
+   */
+  public static Options beginMask(Long beginMask) {
+    return new Options().beginMask(beginMask);
+  }
+  
+  /**
+   * @param endMask analogous to `begin_mask`
+   */
+  public static Options endMask(Long endMask) {
+    return new Options().endMask(endMask);
+  }
+  
+  /**
+   * @param ellipsisMask a bitmask where bit `i` being 1 means the `i`th
+   * position is actually an ellipsis. One bit at most can be 1.
+   * If `ellipsis_mask == 0`, then an implicit ellipsis mask of `1 << (m+1)`
+   * is provided. This means that `foo[3:5] == foo[3:5, ...]`. An ellipsis
+   * implicitly creates as many range specifications as necessary to fully
+   * specify the sliced range for every dimension. For example for a 4-dimensional
+   * tensor `foo` the slice `foo[2, ..., 5:8]` implies `foo[2, :, :, 5:8]`.
+   */
+  public static Options ellipsisMask(Long ellipsisMask) {
+    return new Options().ellipsisMask(ellipsisMask);
+  }
+  
+  /**
+   * @param newAxisMask a bitmask where bit `i` being 1 means the `i`th
+   * specification creates a new shape 1 dimension. For example
+   * `foo[:4, tf.newaxis, :2]` would produce a shape `(4, 1, 2)` tensor.
+   */
+  public static Options newAxisMask(Long newAxisMask) {
+    return new Options().newAxisMask(newAxisMask);
+  }
+  
+  /**
+   * @param shrinkAxisMask a bitmask where bit `i` implies that the `i`th
+   * specification should shrink the dimensionality. begin and end
+   * must imply a slice of size 1 in the dimension. For example in
+   * python one might do `foo[:, 3, :]` which would result in
+   * `shrink_axis_mask` being 2.
+   */
+  public static Options shrinkAxisMask(Long shrinkAxisMask) {
+    return new Options().shrinkAxisMask(shrinkAxisMask);
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private StridedSlice(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/StringFormat.java java-ops/org/tensorflow/op/core/StringFormat.java
--- java/org/tensorflow/op/core/StringFormat.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/StringFormat.java	2018-10-16 20:18:38.576432140 +0900
@@ -0,0 +1,141 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Formats a string template using a list of tensors.
+ * <p>
+ * Formats a string template using a list of tensors, pretty-printing tensor summaries.
+ */
+@Operator
+public final class StringFormat extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.StringFormat}
+   */
+  public static class Options {
+    
+    /**
+     * @param template A string, the template to format tensor summaries into.
+     */
+    public Options template(String template) {
+      this.template = template;
+      return this;
+    }
+    
+    /**
+     * @param placeholder A string, at each placeholder in the template a subsequent tensor summary will be inserted.
+     */
+    public Options placeholder(String placeholder) {
+      this.placeholder = placeholder;
+      return this;
+    }
+    
+    /**
+     * @param summarize When formatting the tensor summaries print the first and last summarize entries of each tensor dimension.
+     */
+    public Options summarize(Long summarize) {
+      this.summarize = summarize;
+      return this;
+    }
+    
+    private String template;
+    private String placeholder;
+    private Long summarize;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new StringFormat operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputs The list of tensors to format into the placeholder string.
+   * @param options carries optional attributes values
+   * @return a new instance of StringFormat
+   */
+  public static StringFormat create(Scope scope, Iterable<Operand<?>> inputs, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("StringFormat", scope.makeOpName("StringFormat"));
+    opBuilder.addInputList(Operands.asOutputs(inputs));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.template != null) {
+          opBuilder.setAttr("template", opts.template);
+        }
+        if (opts.placeholder != null) {
+          opBuilder.setAttr("placeholder", opts.placeholder);
+        }
+        if (opts.summarize != null) {
+          opBuilder.setAttr("summarize", opts.summarize);
+        }
+      }
+    }
+    return new StringFormat(opBuilder.build());
+  }
+  
+  /**
+   * @param template A string, the template to format tensor summaries into.
+   */
+  public static Options template(String template) {
+    return new Options().template(template);
+  }
+  
+  /**
+   * @param placeholder A string, at each placeholder in the template a subsequent tensor summary will be inserted.
+   */
+  public static Options placeholder(String placeholder) {
+    return new Options().placeholder(placeholder);
+  }
+  
+  /**
+   * @param summarize When formatting the tensor summaries print the first and last summarize entries of each tensor dimension.
+   */
+  public static Options summarize(Long summarize) {
+    return new Options().summarize(summarize);
+  }
+  
+  /**
+   * = The resulting string scalar.
+   */
+  public Output<String> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return output;
+  }
+  
+  private Output<String> output;
+  
+  private StringFormat(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/StringJoin.java java-ops/org/tensorflow/op/core/StringJoin.java
--- java/org/tensorflow/op/core/StringJoin.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/StringJoin.java	2018-10-16 20:18:38.576432140 +0900
@@ -0,0 +1,104 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Joins the strings in the given list of string tensors into one tensor;
+ * <p>
+ * with the given separator (default is an empty separator).
+ */
+@Operator
+public final class StringJoin extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.StringJoin}
+   */
+  public static class Options {
+    
+    /**
+     * @param separator string, an optional join separator.
+     */
+    public Options separator(String separator) {
+      this.separator = separator;
+      return this;
+    }
+    
+    private String separator;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new StringJoin operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputs A list of string tensors.  The tensors must all have the same shape,
+   * or be scalars.  Scalars may be mixed in; these will be broadcast to the shape
+   * of non-scalar inputs.
+   * @param options carries optional attributes values
+   * @return a new instance of StringJoin
+   */
+  public static StringJoin create(Scope scope, Iterable<Operand<String>> inputs, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("StringJoin", scope.makeOpName("StringJoin"));
+    opBuilder.addInputList(Operands.asOutputs(inputs));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.separator != null) {
+          opBuilder.setAttr("separator", opts.separator);
+        }
+      }
+    }
+    return new StringJoin(opBuilder.build());
+  }
+  
+  /**
+   * @param separator string, an optional join separator.
+   */
+  public static Options separator(String separator) {
+    return new Options().separator(separator);
+  }
+  
+  /**
+   */
+  public Output<String> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return output;
+  }
+  
+  private Output<String> output;
+  
+  private StringJoin(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/StringLength.java java-ops/org/tensorflow/op/core/StringLength.java
--- java/org/tensorflow/op/core/StringLength.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/StringLength.java	2018-10-16 20:18:38.576432140 +0900
@@ -0,0 +1,111 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * String lengths of `input`.
+ * <p>
+ * Computes the length of each string given in the input tensor.
+ */
+@Operator
+public final class StringLength extends PrimitiveOp implements Operand<Integer> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.StringLength}
+   */
+  public static class Options {
+    
+    /**
+     * @param unit The unit that is counted to compute string length.  One of: `"BYTE"` (for
+     * the number of bytes in each string) or `"UTF8_CHAR"` (for the number of UTF-8
+     * encoded Unicode code points in each string).  Results are undefined
+     * if `unit=UTF8_CHAR` and the `input` strings do not contain structurally
+     * valid UTF-8.
+     */
+    public Options unit(String unit) {
+      this.unit = unit;
+      return this;
+    }
+    
+    private String unit;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new StringLength operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input The string for which to compute the length.
+   * @param options carries optional attributes values
+   * @return a new instance of StringLength
+   */
+  public static StringLength create(Scope scope, Operand<String> input, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("StringLength", scope.makeOpName("StringLength"));
+    opBuilder.addInput(input.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.unit != null) {
+          opBuilder.setAttr("unit", opts.unit);
+        }
+      }
+    }
+    return new StringLength(opBuilder.build());
+  }
+  
+  /**
+   * @param unit The unit that is counted to compute string length.  One of: `"BYTE"` (for
+   * the number of bytes in each string) or `"UTF8_CHAR"` (for the number of UTF-8
+   * encoded Unicode code points in each string).  Results are undefined
+   * if `unit=UTF8_CHAR` and the `input` strings do not contain structurally
+   * valid UTF-8.
+   */
+  public static Options unit(String unit) {
+    return new Options().unit(unit);
+  }
+  
+  /**
+   * Integer tensor that has the same shape as `input`. The output contains the
+   * element-wise string lengths of `input`.
+   */
+  public Output<Integer> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<Integer> asOutput() {
+    return output;
+  }
+  
+  private Output<Integer> output;
+  
+  private StringLength(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/StringSplit.java java-ops/org/tensorflow/op/core/StringSplit.java
--- java/org/tensorflow/op/core/StringSplit.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/StringSplit.java	2018-10-16 20:18:38.577432139 +0900
@@ -0,0 +1,138 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Split elements of `input` based on `delimiter` into a `SparseTensor`.
+ * <p>
+ * Let N be the size of source (typically N will be the batch size). Split each
+ * element of `input` based on `delimiter` and return a `SparseTensor`
+ * containing the splitted tokens. Empty tokens are ignored.
+ * <p>
+ * `delimiter` can be empty, or a string of split characters. If `delimiter` is an
+ *  empty string, each element of `input` is split into individual single-byte
+ *  character strings, including splitting of UTF-8 multibyte sequences. Otherwise
+ *  every character of `delimiter` is a potential split point.
+ * <p>
+ * For example:
+ *   N = 2, input[0] is 'hello world' and input[1] is 'a b c', then the output
+ *   will be
+ * <p>
+ *   indices = [0, 0;
+ *              0, 1;
+ *              1, 0;
+ *              1, 1;
+ *              1, 2]
+ *   shape = [2, 3]
+ *   values = ['hello', 'world', 'a', 'b', 'c']
+ */
+@Operator
+public final class StringSplit extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.StringSplit}
+   */
+  public static class Options {
+    
+    /**
+     * @param skipEmpty A `bool`. If `True`, skip the empty strings from the result.
+     */
+    public Options skipEmpty(Boolean skipEmpty) {
+      this.skipEmpty = skipEmpty;
+      return this;
+    }
+    
+    private Boolean skipEmpty;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new StringSplit operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 1-D. Strings to split.
+   * @param delimiter 0-D. Delimiter characters (bytes), or empty string.
+   * @param options carries optional attributes values
+   * @return a new instance of StringSplit
+   */
+  public static StringSplit create(Scope scope, Operand<String> input, Operand<String> delimiter, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("StringSplit", scope.makeOpName("StringSplit"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(delimiter.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.skipEmpty != null) {
+          opBuilder.setAttr("skip_empty", opts.skipEmpty);
+        }
+      }
+    }
+    return new StringSplit(opBuilder.build());
+  }
+  
+  /**
+   * @param skipEmpty A `bool`. If `True`, skip the empty strings from the result.
+   */
+  public static Options skipEmpty(Boolean skipEmpty) {
+    return new Options().skipEmpty(skipEmpty);
+  }
+  
+  /**
+   * A dense matrix of int64 representing the indices of the sparse tensor.
+   */
+  public Output<Long> indices() {
+    return indices;
+  }
+  
+  /**
+   * A vector of strings corresponding to the splited values.
+   */
+  public Output<String> values() {
+    return values;
+  }
+  
+  /**
+   * a length-2 vector of int64 representing the shape of the sparse
+   * tensor, where the first value is N and the second value is the maximum number
+   * of tokens in a single input entry.
+   */
+  public Output<Long> shape() {
+    return shape;
+  }
+  
+  private Output<Long> indices;
+  private Output<String> values;
+  private Output<Long> shape;
+  
+  private StringSplit(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    indices = operation.output(outputIdx++);
+    values = operation.output(outputIdx++);
+    shape = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/StringSplitV2.java java-ops/org/tensorflow/op/core/StringSplitV2.java
--- java/org/tensorflow/op/core/StringSplitV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/StringSplitV2.java	2018-10-16 20:18:38.578432138 +0900
@@ -0,0 +1,136 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Split elements of `source` based on `sep` into a `SparseTensor`.
+ * <p>
+ * Let N be the size of source (typically N will be the batch size). Split each
+ * element of `source` based on `sep` and return a `SparseTensor`
+ * containing the split tokens. Empty tokens are ignored.
+ * <p>
+ * For example, N = 2, source[0] is 'hello world' and source[1] is 'a b c',
+ * then the output will be
+ * <pre>{@code
+ * st.indices = [0, 0;
+ *               0, 1;
+ *               1, 0;
+ *               1, 1;
+ *               1, 2]
+ * st.shape = [2, 3]
+ * st.values = ['hello', 'world', 'a', 'b', 'c']
+ * }</pre>
+ * If `sep` is given, consecutive delimiters are not grouped together and are
+ * deemed to delimit empty strings. For example, source of `"1<>2<><>3"` and
+ * sep of `"<>"` returns `["1", "2", "", "3"]`. If `sep` is None or an empty
+ * string, consecutive whitespace are regarded as a single separator, and the
+ * result will contain no empty strings at the startor end if the string has
+ * leading or trailing whitespace.
+ * <p>
+ * Note that the above mentioned behavior matches python's str.split.
+ */
+@Operator
+public final class StringSplitV2 extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.StringSplitV2}
+   */
+  public static class Options {
+    
+    /**
+     * @param maxsplit An `int`. If `maxsplit > 0`, limit of the split of the result.
+     */
+    public Options maxsplit(Long maxsplit) {
+      this.maxsplit = maxsplit;
+      return this;
+    }
+    
+    private Long maxsplit;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new StringSplitV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input `1-D` string `Tensor`, the strings to split.
+   * @param sep `0-D` string `Tensor`, the delimiter character.
+   * @param options carries optional attributes values
+   * @return a new instance of StringSplitV2
+   */
+  public static StringSplitV2 create(Scope scope, Operand<String> input, Operand<String> sep, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("StringSplitV2", scope.makeOpName("StringSplitV2"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(sep.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.maxsplit != null) {
+          opBuilder.setAttr("maxsplit", opts.maxsplit);
+        }
+      }
+    }
+    return new StringSplitV2(opBuilder.build());
+  }
+  
+  /**
+   * @param maxsplit An `int`. If `maxsplit > 0`, limit of the split of the result.
+   */
+  public static Options maxsplit(Long maxsplit) {
+    return new Options().maxsplit(maxsplit);
+  }
+  
+  /**
+   */
+  public Output<Long> indices() {
+    return indices;
+  }
+  
+  /**
+   */
+  public Output<String> values() {
+    return values;
+  }
+  
+  /**
+   */
+  public Output<Long> shape() {
+    return shape;
+  }
+  
+  private Output<Long> indices;
+  private Output<String> values;
+  private Output<Long> shape;
+  
+  private StringSplitV2(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    indices = operation.output(outputIdx++);
+    values = operation.output(outputIdx++);
+    shape = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/StringStrip.java java-ops/org/tensorflow/op/core/StringStrip.java
--- java/org/tensorflow/op/core/StringStrip.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/StringStrip.java	2018-10-16 20:18:38.578432138 +0900
@@ -0,0 +1,66 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Strip leading and trailing whitespaces from the Tensor.
+ */
+@Operator
+public final class StringStrip extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Factory method to create a class to wrap a new StringStrip operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input A string `Tensor` of any shape.
+   * @return a new instance of StringStrip
+   */
+  public static StringStrip create(Scope scope, Operand<String> input) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("StringStrip", scope.makeOpName("StringStrip"));
+    opBuilder.addInput(input.asOutput());
+    return new StringStrip(opBuilder.build());
+  }
+  
+  /**
+   * A string `Tensor` of the same shape as the input.
+   */
+  public Output<String> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return output;
+  }
+  
+  private Output<String> output;
+  
+  private StringStrip(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/StringToHashBucketFast.java java-ops/org/tensorflow/op/core/StringToHashBucketFast.java
--- java/org/tensorflow/op/core/StringToHashBucketFast.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/StringToHashBucketFast.java	2018-10-16 20:18:38.579432137 +0900
@@ -0,0 +1,75 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Converts each string in the input Tensor to its hash mod by a number of buckets.
+ * <p>
+ * The hash function is deterministic on the content of the string within the
+ * process and will never change. However, it is not suitable for cryptography.
+ * This function may be used when CPU time is scarce and inputs are trusted or
+ * unimportant. There is a risk of adversaries constructing inputs that all hash
+ * to the same bucket. To prevent this problem, use a strong hash function with
+ * `tf.string_to_hash_bucket_strong`.
+ */
+@Operator
+public final class StringToHashBucketFast extends PrimitiveOp implements Operand<Long> {
+  
+  /**
+   * Factory method to create a class to wrap a new StringToHashBucketFast operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input The strings to assign a hash bucket.
+   * @param numBuckets The number of buckets.
+   * @return a new instance of StringToHashBucketFast
+   */
+  public static StringToHashBucketFast create(Scope scope, Operand<String> input, Long numBuckets) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("StringToHashBucketFast", scope.makeOpName("StringToHashBucketFast"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.setAttr("num_buckets", numBuckets);
+    return new StringToHashBucketFast(opBuilder.build());
+  }
+  
+  /**
+   * A Tensor of the same shape as the input `string_tensor`.
+   */
+  public Output<Long> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<Long> asOutput() {
+    return output;
+  }
+  
+  private Output<Long> output;
+  
+  private StringToHashBucketFast(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/StringToHashBucket.java java-ops/org/tensorflow/op/core/StringToHashBucket.java
--- java/org/tensorflow/op/core/StringToHashBucket.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/StringToHashBucket.java	2018-10-16 20:18:38.579432137 +0900
@@ -0,0 +1,75 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Converts each string in the input Tensor to its hash mod by a number of buckets.
+ * <p>
+ * The hash function is deterministic on the content of the string within the
+ * process.
+ * <p>
+ * Note that the hash function may change from time to time.
+ * This functionality will be deprecated and it's recommended to use
+ * `tf.string_to_hash_bucket_fast()` or `tf.string_to_hash_bucket_strong()`.
+ */
+@Operator
+public final class StringToHashBucket extends PrimitiveOp implements Operand<Long> {
+  
+  /**
+   * Factory method to create a class to wrap a new StringToHashBucket operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param stringTensor 
+   * @param numBuckets The number of buckets.
+   * @return a new instance of StringToHashBucket
+   */
+  public static StringToHashBucket create(Scope scope, Operand<String> stringTensor, Long numBuckets) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("StringToHashBucket", scope.makeOpName("StringToHashBucket"));
+    opBuilder.addInput(stringTensor.asOutput());
+    opBuilder.setAttr("num_buckets", numBuckets);
+    return new StringToHashBucket(opBuilder.build());
+  }
+  
+  /**
+   * A Tensor of the same shape as the input `string_tensor`.
+   */
+  public Output<Long> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<Long> asOutput() {
+    return output;
+  }
+  
+  private Output<Long> output;
+  
+  private StringToHashBucket(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/StringToHashBucketStrong.java java-ops/org/tensorflow/op/core/StringToHashBucketStrong.java
--- java/org/tensorflow/op/core/StringToHashBucketStrong.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/StringToHashBucketStrong.java	2018-10-16 20:18:38.580432137 +0900
@@ -0,0 +1,87 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Converts each string in the input Tensor to its hash mod by a number of buckets.
+ * <p>
+ * The hash function is deterministic on the content of the string within the
+ * process. The hash function is a keyed hash function, where attribute `key`
+ * defines the key of the hash function. `key` is an array of 2 elements.
+ * <p>
+ * A strong hash is important when inputs may be malicious, e.g. URLs with
+ * additional components. Adversaries could try to make their inputs hash to the
+ * same bucket for a denial-of-service attack or to skew the results. A strong
+ * hash prevents this by making it difficult, if not infeasible, to compute inputs
+ * that hash to the same bucket. This comes at a cost of roughly 4x higher compute
+ * time than `tf.string_to_hash_bucket_fast`.
+ */
+@Operator
+public final class StringToHashBucketStrong extends PrimitiveOp implements Operand<Long> {
+  
+  /**
+   * Factory method to create a class to wrap a new StringToHashBucketStrong operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input The strings to assign a hash bucket.
+   * @param numBuckets The number of buckets.
+   * @param key The key for the keyed hash function passed as a list of two uint64
+   * elements.
+   * @return a new instance of StringToHashBucketStrong
+   */
+  public static StringToHashBucketStrong create(Scope scope, Operand<String> input, Long numBuckets, List<Long> key) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("StringToHashBucketStrong", scope.makeOpName("StringToHashBucketStrong"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.setAttr("num_buckets", numBuckets);
+    long[] keyArray = new long[key.size()];
+    for (int i = 0; i < keyArray.length; ++i) {
+      keyArray[i] = key.get(i);
+    }
+    opBuilder.setAttr("key", keyArray);
+    return new StringToHashBucketStrong(opBuilder.build());
+  }
+  
+  /**
+   * A Tensor of the same shape as the input `string_tensor`.
+   */
+  public Output<Long> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<Long> asOutput() {
+    return output;
+  }
+  
+  private Output<Long> output;
+  
+  private StringToHashBucketStrong(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/StringToNumber.java java-ops/org/tensorflow/op/core/StringToNumber.java
--- java/org/tensorflow/op/core/StringToNumber.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/StringToNumber.java	2018-10-16 20:18:38.580432137 +0900
@@ -0,0 +1,85 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Converts each string in the input Tensor to the specified numeric type.
+ * <p>
+ * (Note that int32 overflow results in an error while float overflow
+ * results in a rounded value.)
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class StringToNumber<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new StringToNumber operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param stringTensor 
+   * @param outType The numeric type to interpret each string in `string_tensor` as.
+   * @return a new instance of StringToNumber
+   */
+  public static <T extends Number> StringToNumber<T> create(Scope scope, Operand<String> stringTensor, Class<T> outType) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("StringToNumber", scope.makeOpName("StringToNumber"));
+    opBuilder.addInput(stringTensor.asOutput());
+    opBuilder.setAttr("out_type", DataType.fromClass(outType));
+    return new StringToNumber<T>(opBuilder.build());
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new StringToNumber operation to the graph, using default output types.
+   * 
+   * @param scope current graph scope
+   * @param stringTensor 
+   * @return a new instance of StringToNumber
+   */
+  public static StringToNumber<Float> create(Scope scope, Operand<String> stringTensor) {
+    return create(scope, stringTensor, Float.class);
+  }
+  
+  /**
+   * A Tensor of the same shape as the input `string_tensor`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private StringToNumber(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Sub.java java-ops/org/tensorflow/op/core/Sub.java
--- java/org/tensorflow/op/core/Sub.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Sub.java	2018-10-16 20:18:38.582432135 +0900
@@ -0,0 +1,72 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns x - y element-wise.
+ * <p>
+ * <i>NOTE</i>: `Subtract` supports broadcasting. More about broadcasting
+ * [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
+ * 
+ * @param <T> data type for {@code z()} output
+ */
+@Operator
+public final class Sub<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Sub operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param y 
+   * @return a new instance of Sub
+   */
+  public static <T> Sub<T> create(Scope scope, Operand<T> x, Operand<T> y) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Sub", scope.makeOpName("Sub"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(y.asOutput());
+    return new Sub<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return z;
+  }
+  
+  private Output<T> z;
+  
+  private Sub(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Substr.java java-ops/org/tensorflow/op/core/Substr.java
--- java/org/tensorflow/op/core/Substr.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Substr.java	2018-10-16 20:18:38.583432135 +0900
@@ -0,0 +1,140 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Return substrings from `Tensor` of strings.
+ * <p>
+ * For each string in the input `Tensor`, creates a substring starting at index
+ * `pos` with a total length of `len`.
+ * <p>
+ * If `len` defines a substring that would extend beyond the length of the input
+ * string, then as many characters as possible are used.
+ * <p>
+ * A negative `pos` indicates distance within the string backwards from the end.
+ * <p>
+ * If `pos` specifies an index which is out of range for any of the input strings,
+ * then an `InvalidArgumentError` is thrown.
+ * <p>
+ * `pos` and `len` must have the same shape, otherwise a `ValueError` is thrown on
+ * Op creation.
+ * <p>
+ * <i>NOTE</i>: `Substr` supports broadcasting up to two dimensions. More about
+ * broadcasting
+ * [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
+ * <p>
+ * ---
+ * <p>
+ * Examples
+ * <p>
+ * Using scalar `pos` and `len`:
+ * <pre>{@code
+ * input = [b'Hello', b'World']
+ * position = 1
+ * length = 3
+ * 
+ * output = [b'ell', b'orl']
+ * }</pre>
+ * Using `pos` and `len` with same shape as `input`:
+ * <pre>{@code
+ * input = [[b'ten', b'eleven', b'twelve'],
+ *          [b'thirteen', b'fourteen', b'fifteen'],
+ *          [b'sixteen', b'seventeen', b'eighteen']]
+ * position = [[1, 2, 3],
+ *             [1, 2, 3],
+ *             [1, 2, 3]]
+ * length =   [[2, 3, 4],
+ *             [4, 3, 2],
+ *             [5, 5, 5]]
+ * 
+ * output = [[b'en', b'eve', b'lve'],
+ *           [b'hirt', b'urt', b'te'],
+ *           [b'ixtee', b'vente', b'hteen']]
+ * }</pre>
+ * Broadcasting `pos` and `len` onto `input`:
+ * <pre>{@code
+ * input = [[b'ten', b'eleven', b'twelve'],
+ *          [b'thirteen', b'fourteen', b'fifteen'],
+ *          [b'sixteen', b'seventeen', b'eighteen'],
+ *          [b'nineteen', b'twenty', b'twentyone']]
+ * position = [1, 2, 3]
+ * length =   [1, 2, 3]
+ * 
+ * output = [[b'e', b'ev', b'lve'],
+ *           [b'h', b'ur', b'tee'],
+ *           [b'i', b've', b'hte'],
+ *           [b'i', b'en', b'nty']]
+ * }</pre>
+ * Broadcasting `input` onto `pos` and `len`:
+ * <pre>{@code
+ * input = b'thirteen'
+ * position = [1, 5, 7]
+ * length =   [3, 2, 1]
+ * 
+ * output = [b'hir', b'ee', b'n']
+ * }</pre>
+ * 
+ */
+@Operator
+public final class Substr extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Factory method to create a class to wrap a new Substr operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input Tensor of strings
+   * @param pos Scalar defining the position of first character in each substring
+   * @param len Scalar defining the number of characters to include in each substring
+   * @return a new instance of Substr
+   */
+  public static <T extends Number> Substr create(Scope scope, Operand<String> input, Operand<T> pos, Operand<T> len) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Substr", scope.makeOpName("Substr"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(pos.asOutput());
+    opBuilder.addInput(len.asOutput());
+    return new Substr(opBuilder.build());
+  }
+  
+  /**
+   * Tensor of substrings
+   */
+  public Output<String> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return output;
+  }
+  
+  private Output<String> output;
+  
+  private Substr(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Subtract.java java-ops/org/tensorflow/op/core/Subtract.java
--- java/org/tensorflow/op/core/Subtract.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Subtract.java	2018-10-16 20:18:38.581432136 +0900
@@ -0,0 +1,72 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns x - y element-wise.
+ * <p>
+ * <i>NOTE</i>: `Subtract` supports broadcasting. More about broadcasting
+ * [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
+ * 
+ * @param <T> data type for {@code z()} output
+ */
+@Operator
+public final class Subtract<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Subtract operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param y 
+   * @return a new instance of Subtract
+   */
+  public static <T> Subtract<T> create(Scope scope, Operand<T> x, Operand<T> y) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Sub", scope.makeOpName("Subtract"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(y.asOutput());
+    return new Subtract<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return z;
+  }
+  
+  private Output<T> z;
+  
+  private Subtract(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Sum.java java-ops/org/tensorflow/op/core/Sum.java
--- java/org/tensorflow/op/core/Sum.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Sum.java	2018-10-16 20:18:38.583432135 +0900
@@ -0,0 +1,110 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the sum of elements across dimensions of a tensor.
+ * <p>
+ * Reduces `input` along the dimensions given in `axis`. Unless
+ * `keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
+ * `axis`. If `keep_dims` is true, the reduced dimensions are
+ * retained with length 1.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class Sum<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Sum}
+   */
+  public static class Options {
+    
+    /**
+     * @param keepDims If true, retain reduced dimensions with length 1.
+     */
+    public Options keepDims(Boolean keepDims) {
+      this.keepDims = keepDims;
+      return this;
+    }
+    
+    private Boolean keepDims;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Sum operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input The tensor to reduce.
+   * @param axis The dimensions to reduce. Must be in the range
+   * `[-rank(input), rank(input))`.
+   * @param options carries optional attributes values
+   * @return a new instance of Sum
+   */
+  public static <T, U extends Number> Sum<T> create(Scope scope, Operand<T> input, Operand<U> axis, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Sum", scope.makeOpName("Sum"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(axis.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.keepDims != null) {
+          opBuilder.setAttr("keep_dims", opts.keepDims);
+        }
+      }
+    }
+    return new Sum<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param keepDims If true, retain reduced dimensions with length 1.
+   */
+  public static Options keepDims(Boolean keepDims) {
+    return new Options().keepDims(keepDims);
+  }
+  
+  /**
+   * The reduced tensor.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private Sum(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/SummaryWriter.java java-ops/org/tensorflow/op/core/SummaryWriter.java
--- java/org/tensorflow/op/core/SummaryWriter.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/SummaryWriter.java	2018-10-16 20:18:38.584432134 +0900
@@ -0,0 +1,114 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ */
+public final class SummaryWriter extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.SummaryWriter}
+   */
+  public static class Options {
+    
+    /**
+     * @param sharedName 
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    /**
+     * @param container 
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    private String sharedName;
+    private String container;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new SummaryWriter operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param options carries optional attributes values
+   * @return a new instance of SummaryWriter
+   */
+  public static SummaryWriter create(Scope scope, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("SummaryWriter", scope.makeOpName("SummaryWriter"));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+      }
+    }
+    return new SummaryWriter(opBuilder.build());
+  }
+  
+  /**
+   * @param sharedName 
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   * @param container 
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   */
+  public Output<?> writer() {
+    return writer;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) writer;
+  }
+  
+  private Output<?> writer;
+  
+  private SummaryWriter(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    writer = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Svd.java java-ops/org/tensorflow/op/core/Svd.java
--- java/org/tensorflow/op/core/Svd.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Svd.java	2018-10-16 20:18:38.585432133 +0900
@@ -0,0 +1,159 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the singular value decompositions of one or more matrices.
+ * <p>
+ * Computes the SVD of each inner matrix in `input` such that
+ * `input[..., :, :] = u[..., :, :] * diag(s[..., :, :]) * transpose(v[..., :, :])`
+ * <pre>{@code
+ * # a is a tensor containing a batch of matrices.
+ * # s is a tensor of singular values for each matrix.
+ * # u is the tensor containing of left singular vectors for each matrix.
+ * # v is the tensor containing of right singular vectors for each matrix.
+ * s, u, v = svd(a)
+ * s, _, _ = svd(a, compute_uv=False)
+ * }</pre>
+ * 
+ * 
+ * @param <T> data type for {@code s()} output
+ */
+@Operator
+public final class Svd<T> extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Svd}
+   */
+  public static class Options {
+    
+    /**
+     * @param computeUv If true, left and right singular vectors will be
+     * computed and returned in `u` and `v`, respectively.
+     * If false, `u` and `v` are not set and should never referenced.
+     */
+    public Options computeUv(Boolean computeUv) {
+      this.computeUv = computeUv;
+      return this;
+    }
+    
+    /**
+     * @param fullMatrices If true, compute full-sized `u` and `v`. If false
+     * (the default), compute only the leading `P` singular vectors.
+     * Ignored if `compute_uv` is `False`.
+     */
+    public Options fullMatrices(Boolean fullMatrices) {
+      this.fullMatrices = fullMatrices;
+      return this;
+    }
+    
+    private Boolean computeUv;
+    private Boolean fullMatrices;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Svd operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input A tensor of shape `[..., M, N]` whose inner-most 2 dimensions
+   * form matrices of size `[M, N]`. Let `P` be the minimum of `M` and `N`.
+   * @param options carries optional attributes values
+   * @return a new instance of Svd
+   */
+  public static <T> Svd<T> create(Scope scope, Operand<T> input, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Svd", scope.makeOpName("Svd"));
+    opBuilder.addInput(input.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.computeUv != null) {
+          opBuilder.setAttr("compute_uv", opts.computeUv);
+        }
+        if (opts.fullMatrices != null) {
+          opBuilder.setAttr("full_matrices", opts.fullMatrices);
+        }
+      }
+    }
+    return new Svd<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param computeUv If true, left and right singular vectors will be
+   * computed and returned in `u` and `v`, respectively.
+   * If false, `u` and `v` are not set and should never referenced.
+   */
+  public static Options computeUv(Boolean computeUv) {
+    return new Options().computeUv(computeUv);
+  }
+  
+  /**
+   * @param fullMatrices If true, compute full-sized `u` and `v`. If false
+   * (the default), compute only the leading `P` singular vectors.
+   * Ignored if `compute_uv` is `False`.
+   */
+  public static Options fullMatrices(Boolean fullMatrices) {
+    return new Options().fullMatrices(fullMatrices);
+  }
+  
+  /**
+   * Singular values. Shape is `[..., P]`.
+   */
+  public Output<T> s() {
+    return s;
+  }
+  
+  /**
+   * Left singular vectors. If `full_matrices` is `False` then shape is
+   * `[..., M, P]`; if `full_matrices` is `True` then shape is
+   * `[..., M, M]`. Undefined if `compute_uv` is `False`.
+   */
+  public Output<T> u() {
+    return u;
+  }
+  
+  /**
+   * Left singular vectors. If `full_matrices` is `False` then shape is
+   * `[..., N, P]`. If `full_matrices` is `True` then shape is `[..., N, N]`.
+   * Undefined if `compute_uv` is false.
+   */
+  public Output<T> v() {
+    return v;
+  }
+  
+  private Output<T> s;
+  private Output<T> u;
+  private Output<T> v;
+  
+  private Svd(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    s = operation.output(outputIdx++);
+    u = operation.output(outputIdx++);
+    v = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Switch.java java-ops/org/tensorflow/op/core/Switch.java
--- java/org/tensorflow/op/core/Switch.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Switch.java	2018-10-16 20:18:38.585432133 +0900
@@ -0,0 +1,77 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Forwards `data` to the output port determined by `pred`.
+ * <p>
+ * If `pred` is true, the `data` input is forwarded to `output_true`. Otherwise,
+ * the data goes to `output_false`.
+ * <p>
+ * See also `RefSwitch` and `Merge`.
+ * 
+ * @param <T> data type for {@code outputFalse()} output
+ */
+public final class Switch<T> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new Switch operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param data The tensor to be forwarded to the appropriate output.
+   * @param pred A scalar that specifies which output port will receive data.
+   * @return a new instance of Switch
+   */
+  public static <T> Switch<T> create(Scope scope, Operand<T> data, Operand<Boolean> pred) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Switch", scope.makeOpName("Switch"));
+    opBuilder.addInput(data.asOutput());
+    opBuilder.addInput(pred.asOutput());
+    return new Switch<T>(opBuilder.build());
+  }
+  
+  /**
+   * If `pred` is false, data will be forwarded to this output.
+   */
+  public Output<T> outputFalse() {
+    return outputFalse;
+  }
+  
+  /**
+   * If `pred` is true, data will be forwarded to this output.
+   */
+  public Output<T> outputTrue() {
+    return outputTrue;
+  }
+  
+  private Output<T> outputFalse;
+  private Output<T> outputTrue;
+  
+  private Switch(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    outputFalse = operation.output(outputIdx++);
+    outputTrue = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TakeDataset.java java-ops/org/tensorflow/op/core/TakeDataset.java
--- java/org/tensorflow/op/core/TakeDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TakeDataset.java	2018-10-16 20:18:38.586432132 +0900
@@ -0,0 +1,85 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Creates a dataset that contains `count` elements from the `input_dataset`.
+ */
+@Operator
+public final class TakeDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new TakeDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputDataset 
+   * @param count A scalar representing the number of elements from the `input_dataset`
+   * that should be taken. A value of `-1` indicates that all of `input_dataset`
+   * is taken.
+   * @param outputTypes 
+   * @param outputShapes 
+   * @return a new instance of TakeDataset
+   */
+  public static TakeDataset create(Scope scope, Operand<?> inputDataset, Operand<Long> count, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TakeDataset", scope.makeOpName("TakeDataset"));
+    opBuilder.addInput(inputDataset.asOutput());
+    opBuilder.addInput(count.asOutput());
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new TakeDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private TakeDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TakeManySparseFromTensorsMap.java java-ops/org/tensorflow/op/core/TakeManySparseFromTensorsMap.java
--- java/org/tensorflow/op/core/TakeManySparseFromTensorsMap.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TakeManySparseFromTensorsMap.java	2018-10-16 20:18:38.587432132 +0900
@@ -0,0 +1,188 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Read `SparseTensors` from a `SparseTensorsMap` and concatenate them.
+ * <p>
+ * The input `sparse_handles` must be an `int64` matrix of shape `[N, 1]` where
+ * `N` is the minibatch size and the rows correspond to the output handles of
+ * `AddSparseToTensorsMap` or `AddManySparseToTensorsMap`.  The ranks of the
+ * original `SparseTensor` objects that went into the given input ops must all
+ * match.  When the final `SparseTensor` is created, it has rank one
+ * higher than the ranks of the incoming `SparseTensor` objects
+ * (they have been concatenated along a new row dimension on the left).
+ * <p>
+ * The output `SparseTensor` object's shape values for all dimensions but the
+ * first are the max across the input `SparseTensor` objects' shape values
+ * for the corresponding dimensions.  Its first shape value is `N`, the minibatch
+ * size.
+ * <p>
+ * The input `SparseTensor` objects' indices are assumed ordered in
+ * standard lexicographic order.  If this is not the case, after this
+ * step run `SparseReorder` to restore index ordering.
+ * <p>
+ * For example, if the handles represent an input, which is a `[2, 3]` matrix
+ * representing two original `SparseTensor` objects:
+ * <pre>{@code
+ *     index = [ 0]
+ *             [10]
+ *             [20]
+ *     values = [1, 2, 3]
+ *     shape = [50]
+ * }</pre>
+ * and
+ * <pre>{@code
+ *     index = [ 2]
+ *             [10]
+ *     values = [4, 5]
+ *     shape = [30]
+ * }</pre>
+ * then the final `SparseTensor` will be:
+ * <pre>{@code
+ *     index = [0  0]
+ *             [0 10]
+ *             [0 20]
+ *             [1  2]
+ *             [1 10]
+ *     values = [1, 2, 3, 4, 5]
+ *     shape = [2 50]
+ * }</pre>
+ * 
+ * 
+ * @param <T> data type for {@code sparseValues()} output
+ */
+@Operator
+public final class TakeManySparseFromTensorsMap<T> extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.TakeManySparseFromTensorsMap}
+   */
+  public static class Options {
+    
+    /**
+     * @param container The container name for the `SparseTensorsMap` read by this op.
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName The shared name for the `SparseTensorsMap` read by this op.
+     * It should not be blank; rather the `shared_name` or unique Operation name
+     * of the Op that created the original `SparseTensorsMap` should be used.
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new TakeManySparseFromTensorsMap operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param sparseHandles 1-D, The `N` serialized `SparseTensor` objects.
+   * Shape: `[N]`.
+   * @param dtype The `dtype` of the `SparseTensor` objects stored in the
+   * `SparseTensorsMap`.
+   * @param options carries optional attributes values
+   * @return a new instance of TakeManySparseFromTensorsMap
+   */
+  public static <T> TakeManySparseFromTensorsMap<T> create(Scope scope, Operand<Long> sparseHandles, Class<T> dtype, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TakeManySparseFromTensorsMap", scope.makeOpName("TakeManySparseFromTensorsMap"));
+    opBuilder.addInput(sparseHandles.asOutput());
+    opBuilder.setAttr("dtype", DataType.fromClass(dtype));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new TakeManySparseFromTensorsMap<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param container The container name for the `SparseTensorsMap` read by this op.
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName The shared name for the `SparseTensorsMap` read by this op.
+   * It should not be blank; rather the `shared_name` or unique Operation name
+   * of the Op that created the original `SparseTensorsMap` should be used.
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   * 2-D.  The `indices` of the minibatch `SparseTensor`.
+   */
+  public Output<Long> sparseIndices() {
+    return sparseIndices;
+  }
+  
+  /**
+   * 1-D.  The `values` of the minibatch `SparseTensor`.
+   */
+  public Output<T> sparseValues() {
+    return sparseValues;
+  }
+  
+  /**
+   * 1-D.  The `shape` of the minibatch `SparseTensor`.
+   */
+  public Output<Long> sparseShape() {
+    return sparseShape;
+  }
+  
+  private Output<Long> sparseIndices;
+  private Output<T> sparseValues;
+  private Output<Long> sparseShape;
+  
+  private TakeManySparseFromTensorsMap(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    sparseIndices = operation.output(outputIdx++);
+    sparseValues = operation.output(outputIdx++);
+    sparseShape = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TanhGrad.java java-ops/org/tensorflow/op/core/TanhGrad.java
--- java/org/tensorflow/op/core/TanhGrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TanhGrad.java	2018-10-16 20:18:38.588432131 +0900
@@ -0,0 +1,70 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Computes the gradient for the tanh of `x` wrt its input.
+ * <p>
+ * Specifically, `grad = dy <i> (1 - y</i>y)`, where `y = tanh(x)`, and `dy`
+ * is the corresponding input gradient.
+ * 
+ * @param <T> data type for {@code z()} output
+ */
+public final class TanhGrad<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new TanhGrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param y 
+   * @param dy 
+   * @return a new instance of TanhGrad
+   */
+  public static <T> TanhGrad<T> create(Scope scope, Operand<T> y, Operand<T> dy) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TanhGrad", scope.makeOpName("TanhGrad"));
+    opBuilder.addInput(y.asOutput());
+    opBuilder.addInput(dy.asOutput());
+    return new TanhGrad<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return z;
+  }
+  
+  private Output<T> z;
+  
+  private TanhGrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Tanh.java java-ops/org/tensorflow/op/core/Tanh.java
--- java/org/tensorflow/op/core/Tanh.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Tanh.java	2018-10-16 20:18:38.588432131 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes hyperbolic tangent of `x` element-wise.
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class Tanh<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Tanh operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of Tanh
+   */
+  public static <T> Tanh<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Tanh", scope.makeOpName("Tanh"));
+    opBuilder.addInput(x.asOutput());
+    return new Tanh<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private Tanh(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Tan.java java-ops/org/tensorflow/op/core/Tan.java
--- java/org/tensorflow/op/core/Tan.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Tan.java	2018-10-16 20:18:38.587432132 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes tan of x element-wise.
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class Tan<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Tan operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @return a new instance of Tan
+   */
+  public static <T> Tan<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Tan", scope.makeOpName("Tan"));
+    opBuilder.addInput(x.asOutput());
+    return new Tan<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private Tan(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TemporaryVariable.java java-ops/org/tensorflow/op/core/TemporaryVariable.java
--- java/org/tensorflow/op/core/TemporaryVariable.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TemporaryVariable.java	2018-10-16 20:18:38.589432130 +0900
@@ -0,0 +1,123 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns a tensor that may be mutated, but only persists within a single step.
+ * <p>
+ * This is an experimental op for internal use only and it is possible to use this
+ * op in unsafe ways.  DO NOT USE unless you fully understand the risks.
+ * <p>
+ * It is the caller's responsibility to ensure that 'ref' is eventually passed to a
+ * matching 'DestroyTemporaryVariable' op after all other uses have completed.
+ * <p>
+ * Outputs a ref to the tensor state so it may be read or modified.
+ * <p>
+ *   E.g.
+ *       var = state_ops._temporary_variable([1, 2], types.float_)
+ *       var_name = var.op.name
+ *       var = state_ops.assign(var, [[4.0, 5.0]])
+ *       var = state_ops.assign_add(var, [[6.0, 7.0]])
+ *       final = state_ops._destroy_temporary_variable(var, var_name=var_name)
+ * 
+ * @param <T> data type for {@code ref()} output
+ */
+@Operator
+public final class TemporaryVariable<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.TemporaryVariable}
+   */
+  public static class Options {
+    
+    /**
+     * @param varName Overrides the name used for the temporary variable resource. Default
+     * value is the name of the 'TemporaryVariable' op (which is guaranteed unique).
+     */
+    public Options varName(String varName) {
+      this.varName = varName;
+      return this;
+    }
+    
+    private String varName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new TemporaryVariable operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param shape The shape of the variable tensor.
+   * @param dtype The type of elements in the variable tensor.
+   * @param options carries optional attributes values
+   * @return a new instance of TemporaryVariable
+   */
+  public static <T> TemporaryVariable<T> create(Scope scope, Shape shape, Class<T> dtype, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TemporaryVariable", scope.makeOpName("TemporaryVariable"));
+    opBuilder.setAttr("shape", shape);
+    opBuilder.setAttr("dtype", DataType.fromClass(dtype));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.varName != null) {
+          opBuilder.setAttr("var_name", opts.varName);
+        }
+      }
+    }
+    return new TemporaryVariable<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param varName Overrides the name used for the temporary variable resource. Default
+   * value is the name of the 'TemporaryVariable' op (which is guaranteed unique).
+   */
+  public static Options varName(String varName) {
+    return new Options().varName(varName);
+  }
+  
+  /**
+   * A reference to the variable tensor.
+   */
+  public Output<T> ref() {
+    return ref;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return ref;
+  }
+  
+  private Output<T> ref;
+  
+  private TemporaryVariable(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    ref = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TensorArrayClose.java java-ops/org/tensorflow/op/core/TensorArrayClose.java
--- java/org/tensorflow/op/core/TensorArrayClose.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TensorArrayClose.java	2018-10-16 20:18:38.589432130 +0900
@@ -0,0 +1,53 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Delete the TensorArray from its resource container.
+ * <p>
+ * This enables the user to close and release the resource in the middle
+ * of a step/run.
+ */
+@Operator
+public final class TensorArrayClose extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new TensorArrayClose operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param handle The handle to a TensorArray (output of TensorArray or TensorArrayGrad).
+   * @return a new instance of TensorArrayClose
+   */
+  public static TensorArrayClose create(Scope scope, Operand<?> handle) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TensorArrayCloseV3", scope.makeOpName("TensorArrayClose"));
+    opBuilder.addInput(handle.asOutput());
+    return new TensorArrayClose(opBuilder.build());
+  }
+  
+  
+  private TensorArrayClose(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TensorArrayConcat.java java-ops/org/tensorflow/op/core/TensorArrayConcat.java
--- java/org/tensorflow/op/core/TensorArrayConcat.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TensorArrayConcat.java	2018-10-16 20:18:38.590432130 +0900
@@ -0,0 +1,132 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Concat the elements from the TensorArray into value `value`.
+ * <p>
+ * Takes `T` elements of shapes
+ * <p>
+ *   <pre>{@code
+ *   (n0 x d0 x d1 x ...), (n1 x d0 x d1 x ...), ..., (n(T-1) x d0 x d1 x ...)
+ *   }</pre>
+ * and concatenates them into a Tensor of shape:
+ * <p>
+ *   <pre>{@code
+ * (n0 + n1 + ... + n(T-1) x d0 x d1 x ...)}</pre>
+ * All elements must have the same shape (excepting the first dimension).
+ * 
+ * @param <T> data type for {@code value()} output
+ */
+@Operator
+public final class TensorArrayConcat<T> extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.TensorArrayConcat}
+   */
+  public static class Options {
+    
+    /**
+     * @param elementShapeExcept0 The expected shape of an element, if known,
+     * excluding the first dimension. Used to validate the shapes of
+     * TensorArray elements. If this shape is not fully specified, concatenating
+     * zero-size TensorArrays is an error.
+     */
+    public Options elementShapeExcept0(Shape elementShapeExcept0) {
+      this.elementShapeExcept0 = elementShapeExcept0;
+      return this;
+    }
+    
+    private Shape elementShapeExcept0;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new TensorArrayConcat operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param handle The handle to a TensorArray.
+   * @param flowIn A float scalar that enforces proper chaining of operations.
+   * @param dtype The type of the elem that is returned.
+   * @param options carries optional attributes values
+   * @return a new instance of TensorArrayConcat
+   */
+  public static <T> TensorArrayConcat<T> create(Scope scope, Operand<?> handle, Operand<Float> flowIn, Class<T> dtype, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TensorArrayConcatV3", scope.makeOpName("TensorArrayConcat"));
+    opBuilder.addInput(handle.asOutput());
+    opBuilder.addInput(flowIn.asOutput());
+    opBuilder.setAttr("dtype", DataType.fromClass(dtype));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.elementShapeExcept0 != null) {
+          opBuilder.setAttr("element_shape_except0", opts.elementShapeExcept0);
+        }
+      }
+    }
+    return new TensorArrayConcat<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param elementShapeExcept0 The expected shape of an element, if known,
+   * excluding the first dimension. Used to validate the shapes of
+   * TensorArray elements. If this shape is not fully specified, concatenating
+   * zero-size TensorArrays is an error.
+   */
+  public static Options elementShapeExcept0(Shape elementShapeExcept0) {
+    return new Options().elementShapeExcept0(elementShapeExcept0);
+  }
+  
+  /**
+   * All of the elements in the TensorArray, concatenated along the first
+   * axis.
+   */
+  public Output<T> value() {
+    return value;
+  }
+  
+  /**
+   * A vector of the row sizes of the original T elements in the
+   * value output.  In the example above, this would be the values:
+   * `(n1, n2, ..., n(T-1))`.
+   */
+  public Output<Long> lengths() {
+    return lengths;
+  }
+  
+  private Output<T> value;
+  private Output<Long> lengths;
+  
+  private TensorArrayConcat(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    value = operation.output(outputIdx++);
+    lengths = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TensorArrayGather.java java-ops/org/tensorflow/op/core/TensorArrayGather.java
--- java/org/tensorflow/op/core/TensorArrayGather.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TensorArrayGather.java	2018-10-16 20:18:38.591432129 +0900
@@ -0,0 +1,117 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Gather specific elements from the TensorArray into output `value`.
+ * <p>
+ * All elements selected by `indices` must have the same shape.
+ * 
+ * @param <T> data type for {@code value()} output
+ */
+@Operator
+public final class TensorArrayGather<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.TensorArrayGather}
+   */
+  public static class Options {
+    
+    /**
+     * @param elementShape The expected shape of an element, if known. Used to
+     * validate the shapes of TensorArray elements. If this shape is not
+     * fully specified, gathering zero-size TensorArrays is an error.
+     */
+    public Options elementShape(Shape elementShape) {
+      this.elementShape = elementShape;
+      return this;
+    }
+    
+    private Shape elementShape;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new TensorArrayGather operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param handle The handle to a TensorArray.
+   * @param indices The locations in the TensorArray from which to read tensor elements.
+   * @param flowIn A float scalar that enforces proper chaining of operations.
+   * @param dtype The type of the elem that is returned.
+   * @param options carries optional attributes values
+   * @return a new instance of TensorArrayGather
+   */
+  public static <T> TensorArrayGather<T> create(Scope scope, Operand<?> handle, Operand<Integer> indices, Operand<Float> flowIn, Class<T> dtype, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TensorArrayGatherV3", scope.makeOpName("TensorArrayGather"));
+    opBuilder.addInput(handle.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(flowIn.asOutput());
+    opBuilder.setAttr("dtype", DataType.fromClass(dtype));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.elementShape != null) {
+          opBuilder.setAttr("element_shape", opts.elementShape);
+        }
+      }
+    }
+    return new TensorArrayGather<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param elementShape The expected shape of an element, if known. Used to
+   * validate the shapes of TensorArray elements. If this shape is not
+   * fully specified, gathering zero-size TensorArrays is an error.
+   */
+  public static Options elementShape(Shape elementShape) {
+    return new Options().elementShape(elementShape);
+  }
+  
+  /**
+   * All of the elements in the TensorArray, concatenated along a new
+   * axis (the new dimension 0).
+   */
+  public Output<T> value() {
+    return value;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return value;
+  }
+  
+  private Output<T> value;
+  
+  private TensorArrayGather(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    value = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TensorArrayGrad.java java-ops/org/tensorflow/op/core/TensorArrayGrad.java
--- java/org/tensorflow/op/core/TensorArrayGrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TensorArrayGrad.java	2018-10-16 20:18:38.592432128 +0900
@@ -0,0 +1,110 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Creates a TensorArray for storing the gradients of values in the given handle.
+ * <p>
+ * If the given TensorArray gradient already exists, returns a reference to it.
+ * <p>
+ * Locks the size of the original TensorArray by disabling its dynamic size flag.
+ * <p>
+ * **A note about the input flow_in:**
+ * <p>
+ * The handle flow_in forces the execution of the gradient lookup to occur
+ * only after certain other operations have occurred.  For example, when
+ * the forward TensorArray is dynamically sized, writes to this TensorArray
+ * may resize the object.  The gradient TensorArray is statically sized based
+ * on the size of the forward TensorArray when this operation executes.
+ * Furthermore, the size of the forward TensorArray is frozen by this call.
+ * As a result, the flow is used to ensure that the call to generate the gradient
+ * TensorArray only happens after all writes are executed.
+ * <p>
+ * In the case of dynamically sized TensorArrays, gradient computation should
+ * only be performed on read operations that have themselves been chained via
+ * flow to occur only after all writes have executed. That way the final size
+ * of the forward TensorArray is known when this operation is called.
+ * <p>
+ * **A note about the source attribute:**
+ * <p>
+ * TensorArray gradient calls use an accumulator TensorArray object.  If
+ * multiple gradients are calculated and run in the same session, the multiple
+ * gradient nodes may accidentally flow through the same accumulator TensorArray.
+ * This double counts and generally breaks the TensorArray gradient flow.
+ * <p>
+ * The solution is to identify which gradient call this particular
+ * TensorArray gradient is being called in.  This is performed by identifying
+ * a unique string (e.g. "gradients", "gradients_1", ...) from the input
+ * gradient Tensor's name.  This string is used as a suffix when creating
+ * the TensorArray gradient object here (the attribute `source`).
+ * <p>
+ * The attribute `source` is added as a suffix to the forward TensorArray's
+ * name when performing the creation / lookup, so that each separate gradient
+ * calculation gets its own TensorArray accumulator.
+ */
+@Operator
+public final class TensorArrayGrad extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new TensorArrayGrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param handle The handle to the forward TensorArray.
+   * @param flowIn A float scalar that enforces proper chaining of operations.
+   * @param source The gradient source string, used to decide which gradient TensorArray
+   * to return.
+   * @return a new instance of TensorArrayGrad
+   */
+  public static TensorArrayGrad create(Scope scope, Operand<?> handle, Operand<Float> flowIn, String source) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TensorArrayGradV3", scope.makeOpName("TensorArrayGrad"));
+    opBuilder.addInput(handle.asOutput());
+    opBuilder.addInput(flowIn.asOutput());
+    opBuilder.setAttr("source", source);
+    return new TensorArrayGrad(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> gradHandle() {
+    return gradHandle;
+  }
+  
+  /**
+   */
+  public Output<Float> flowOut() {
+    return flowOut;
+  }
+  
+  private Output<?> gradHandle;
+  private Output<Float> flowOut;
+  
+  private TensorArrayGrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    gradHandle = operation.output(outputIdx++);
+    flowOut = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TensorArrayGradWithShape.java java-ops/org/tensorflow/op/core/TensorArrayGradWithShape.java
--- java/org/tensorflow/op/core/TensorArrayGradWithShape.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TensorArrayGradWithShape.java	2018-10-16 20:18:38.592432128 +0900
@@ -0,0 +1,82 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Creates a TensorArray for storing multiple gradients of values in the given handle.
+ * <p>
+ * Similar to TensorArrayGradV3. However it creates an accumulator with an
+ * expanded shape compared to the input TensorArray whose gradient is being
+ * computed. This enables multiple gradients for the same TensorArray to be
+ * calculated using the same accumulator.
+ */
+@Operator
+public final class TensorArrayGradWithShape extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new TensorArrayGradWithShape operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param handle The handle to the forward TensorArray.
+   * @param flowIn A float scalar that enforces proper chaining of operations.
+   * @param shapeToPrepend An int32 vector representing a shape. Elements in the gradient accumulator will
+   * have shape which is this shape_to_prepend value concatenated with shape of the
+   * elements in the TensorArray corresponding to the input handle.
+   * @param source The gradient source string, used to decide which gradient TensorArray
+   * to return.
+   * @return a new instance of TensorArrayGradWithShape
+   */
+  public static TensorArrayGradWithShape create(Scope scope, Operand<?> handle, Operand<Float> flowIn, Operand<Integer> shapeToPrepend, String source) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TensorArrayGradWithShape", scope.makeOpName("TensorArrayGradWithShape"));
+    opBuilder.addInput(handle.asOutput());
+    opBuilder.addInput(flowIn.asOutput());
+    opBuilder.addInput(shapeToPrepend.asOutput());
+    opBuilder.setAttr("source", source);
+    return new TensorArrayGradWithShape(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> gradHandle() {
+    return gradHandle;
+  }
+  
+  /**
+   */
+  public Output<Float> flowOut() {
+    return flowOut;
+  }
+  
+  private Output<?> gradHandle;
+  private Output<Float> flowOut;
+  
+  private TensorArrayGradWithShape(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    gradHandle = operation.output(outputIdx++);
+    flowOut = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TensorArray.java java-ops/org/tensorflow/op/core/TensorArray.java
--- java/org/tensorflow/op/core/TensorArray.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TensorArray.java	2018-10-16 20:18:38.596432126 +0900
@@ -0,0 +1,210 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * An array of Tensors of given size.
+ * <p>
+ * Write data via Write and read via Read or Pack.
+ */
+@Operator
+public final class TensorArray extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.TensorArray}
+   */
+  public static class Options {
+    
+    /**
+     * @param elementShape The expected shape of an element, if known. Used to
+     * validate the shapes of TensorArray elements. If this shape is not
+     * fully specified, gathering zero-size TensorArrays is an error.
+     */
+    public Options elementShape(Shape elementShape) {
+      this.elementShape = elementShape;
+      return this;
+    }
+    
+    /**
+     * @param dynamicSize A boolean that determines whether writes to the TensorArray
+     * are allowed to grow the size.  By default, this is not allowed.
+     */
+    public Options dynamicSize(Boolean dynamicSize) {
+      this.dynamicSize = dynamicSize;
+      return this;
+    }
+    
+    /**
+     * @param clearAfterRead If true (default), Tensors in the TensorArray are cleared
+     * after being read.  This disables multiple read semantics but allows early
+     * release of memory.
+     */
+    public Options clearAfterRead(Boolean clearAfterRead) {
+      this.clearAfterRead = clearAfterRead;
+      return this;
+    }
+    
+    /**
+     * @param identicalElementShapes If true (default is false), then all
+     * elements in the TensorArray will be expected to have have identical shapes.
+     * This allows certain behaviors, like dynamically checking for
+     * consistent shapes on write, and being able to fill in properly
+     * shaped zero tensors on stack -- even if the element_shape attribute
+     * is not fully defined.
+     */
+    public Options identicalElementShapes(Boolean identicalElementShapes) {
+      this.identicalElementShapes = identicalElementShapes;
+      return this;
+    }
+    
+    /**
+     * @param tensorArrayName Overrides the name used for the temporary tensor_array
+     * resource. Default value is the name of the 'TensorArray' op (which
+     * is guaranteed unique).
+     */
+    public Options tensorArrayName(String tensorArrayName) {
+      this.tensorArrayName = tensorArrayName;
+      return this;
+    }
+    
+    private Shape elementShape;
+    private Boolean dynamicSize;
+    private Boolean clearAfterRead;
+    private Boolean identicalElementShapes;
+    private String tensorArrayName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new TensorArray operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param size The size of the array.
+   * @param dtype The type of the elements on the tensor_array.
+   * @param options carries optional attributes values
+   * @return a new instance of TensorArray
+   */
+  public static <T> TensorArray create(Scope scope, Operand<Integer> size, Class<T> dtype, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TensorArrayV3", scope.makeOpName("TensorArray"));
+    opBuilder.addInput(size.asOutput());
+    opBuilder.setAttr("dtype", DataType.fromClass(dtype));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.elementShape != null) {
+          opBuilder.setAttr("element_shape", opts.elementShape);
+        }
+        if (opts.dynamicSize != null) {
+          opBuilder.setAttr("dynamic_size", opts.dynamicSize);
+        }
+        if (opts.clearAfterRead != null) {
+          opBuilder.setAttr("clear_after_read", opts.clearAfterRead);
+        }
+        if (opts.identicalElementShapes != null) {
+          opBuilder.setAttr("identical_element_shapes", opts.identicalElementShapes);
+        }
+        if (opts.tensorArrayName != null) {
+          opBuilder.setAttr("tensor_array_name", opts.tensorArrayName);
+        }
+      }
+    }
+    return new TensorArray(opBuilder.build());
+  }
+  
+  /**
+   * @param elementShape The expected shape of an element, if known. Used to
+   * validate the shapes of TensorArray elements. If this shape is not
+   * fully specified, gathering zero-size TensorArrays is an error.
+   */
+  public static Options elementShape(Shape elementShape) {
+    return new Options().elementShape(elementShape);
+  }
+  
+  /**
+   * @param dynamicSize A boolean that determines whether writes to the TensorArray
+   * are allowed to grow the size.  By default, this is not allowed.
+   */
+  public static Options dynamicSize(Boolean dynamicSize) {
+    return new Options().dynamicSize(dynamicSize);
+  }
+  
+  /**
+   * @param clearAfterRead If true (default), Tensors in the TensorArray are cleared
+   * after being read.  This disables multiple read semantics but allows early
+   * release of memory.
+   */
+  public static Options clearAfterRead(Boolean clearAfterRead) {
+    return new Options().clearAfterRead(clearAfterRead);
+  }
+  
+  /**
+   * @param identicalElementShapes If true (default is false), then all
+   * elements in the TensorArray will be expected to have have identical shapes.
+   * This allows certain behaviors, like dynamically checking for
+   * consistent shapes on write, and being able to fill in properly
+   * shaped zero tensors on stack -- even if the element_shape attribute
+   * is not fully defined.
+   */
+  public static Options identicalElementShapes(Boolean identicalElementShapes) {
+    return new Options().identicalElementShapes(identicalElementShapes);
+  }
+  
+  /**
+   * @param tensorArrayName Overrides the name used for the temporary tensor_array
+   * resource. Default value is the name of the 'TensorArray' op (which
+   * is guaranteed unique).
+   */
+  public static Options tensorArrayName(String tensorArrayName) {
+    return new Options().tensorArrayName(tensorArrayName);
+  }
+  
+  /**
+   * The handle to the TensorArray.
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  /**
+   * A scalar used to control gradient flow.
+   */
+  public Output<Float> flow() {
+    return flow;
+  }
+  
+  private Output<?> handle;
+  private Output<Float> flow;
+  
+  private TensorArray(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+    flow = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TensorArrayPack.java java-ops/org/tensorflow/op/core/TensorArrayPack.java
--- java/org/tensorflow/op/core/TensorArrayPack.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TensorArrayPack.java	2018-10-16 20:18:38.592432128 +0900
@@ -0,0 +1,105 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * @param <T> data type for {@code value()} output
+ */
+@Operator
+public final class TensorArrayPack<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.TensorArrayPack}
+   */
+  public static class Options {
+    
+    /**
+     * @param elementShape 
+     */
+    public Options elementShape(Shape elementShape) {
+      this.elementShape = elementShape;
+      return this;
+    }
+    
+    private Shape elementShape;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new TensorArrayPack operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param handle 
+   * @param flowIn 
+   * @param dtype 
+   * @param options carries optional attributes values
+   * @return a new instance of TensorArrayPack
+   */
+  public static <T> TensorArrayPack<T> create(Scope scope, Operand<String> handle, Operand<Float> flowIn, Class<T> dtype, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TensorArrayPack", scope.makeOpName("TensorArrayPack"));
+    opBuilder.addInput(handle.asOutput());
+    opBuilder.addInput(flowIn.asOutput());
+    opBuilder.setAttr("dtype", DataType.fromClass(dtype));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.elementShape != null) {
+          opBuilder.setAttr("element_shape", opts.elementShape);
+        }
+      }
+    }
+    return new TensorArrayPack<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param elementShape 
+   */
+  public static Options elementShape(Shape elementShape) {
+    return new Options().elementShape(elementShape);
+  }
+  
+  /**
+   */
+  public Output<T> value() {
+    return value;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return value;
+  }
+  
+  private Output<T> value;
+  
+  private TensorArrayPack(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    value = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TensorArrayRead.java java-ops/org/tensorflow/op/core/TensorArrayRead.java
--- java/org/tensorflow/op/core/TensorArrayRead.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TensorArrayRead.java	2018-10-16 20:18:38.593432128 +0900
@@ -0,0 +1,75 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Read an element from the TensorArray into output `value`.
+ * 
+ * @param <T> data type for {@code value()} output
+ */
+@Operator
+public final class TensorArrayRead<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new TensorArrayRead operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param handle The handle to a TensorArray.
+   * @param index 
+   * @param flowIn A float scalar that enforces proper chaining of operations.
+   * @param dtype The type of the elem that is returned.
+   * @return a new instance of TensorArrayRead
+   */
+  public static <T> TensorArrayRead<T> create(Scope scope, Operand<?> handle, Operand<Integer> index, Operand<Float> flowIn, Class<T> dtype) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TensorArrayReadV3", scope.makeOpName("TensorArrayRead"));
+    opBuilder.addInput(handle.asOutput());
+    opBuilder.addInput(index.asOutput());
+    opBuilder.addInput(flowIn.asOutput());
+    opBuilder.setAttr("dtype", DataType.fromClass(dtype));
+    return new TensorArrayRead<T>(opBuilder.build());
+  }
+  
+  /**
+   * The tensor that is read from the TensorArray.
+   */
+  public Output<T> value() {
+    return value;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return value;
+  }
+  
+  private Output<T> value;
+  
+  private TensorArrayRead(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    value = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TensorArrayScatter.java java-ops/org/tensorflow/op/core/TensorArrayScatter.java
--- java/org/tensorflow/op/core/TensorArrayScatter.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TensorArrayScatter.java	2018-10-16 20:18:38.594432127 +0900
@@ -0,0 +1,74 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Scatter the data from the input value into specific TensorArray elements.
+ * <p>
+ * `indices` must be a vector, its length must match the first dim of `value`.
+ */
+@Operator
+public final class TensorArrayScatter extends PrimitiveOp implements Operand<Float> {
+  
+  /**
+   * Factory method to create a class to wrap a new TensorArrayScatter operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param handle The handle to a TensorArray.
+   * @param indices The locations at which to write the tensor elements.
+   * @param value The concatenated tensor to write to the TensorArray.
+   * @param flowIn A float scalar that enforces proper chaining of operations.
+   * @return a new instance of TensorArrayScatter
+   */
+  public static <T> TensorArrayScatter create(Scope scope, Operand<?> handle, Operand<Integer> indices, Operand<T> value, Operand<Float> flowIn) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TensorArrayScatterV3", scope.makeOpName("TensorArrayScatter"));
+    opBuilder.addInput(handle.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(value.asOutput());
+    opBuilder.addInput(flowIn.asOutput());
+    return new TensorArrayScatter(opBuilder.build());
+  }
+  
+  /**
+   * A float scalar that enforces proper chaining of operations.
+   */
+  public Output<Float> flowOut() {
+    return flowOut;
+  }
+  
+  @Override
+  public Output<Float> asOutput() {
+    return flowOut;
+  }
+  
+  private Output<Float> flowOut;
+  
+  private TensorArrayScatter(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    flowOut = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TensorArraySize.java java-ops/org/tensorflow/op/core/TensorArraySize.java
--- java/org/tensorflow/op/core/TensorArraySize.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TensorArraySize.java	2018-10-16 20:18:38.594432127 +0900
@@ -0,0 +1,68 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Get the current size of the TensorArray.
+ */
+@Operator
+public final class TensorArraySize extends PrimitiveOp implements Operand<Integer> {
+  
+  /**
+   * Factory method to create a class to wrap a new TensorArraySize operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param handle The handle to a TensorArray (output of TensorArray or TensorArrayGrad).
+   * @param flowIn A float scalar that enforces proper chaining of operations.
+   * @return a new instance of TensorArraySize
+   */
+  public static TensorArraySize create(Scope scope, Operand<?> handle, Operand<Float> flowIn) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TensorArraySizeV3", scope.makeOpName("TensorArraySize"));
+    opBuilder.addInput(handle.asOutput());
+    opBuilder.addInput(flowIn.asOutput());
+    return new TensorArraySize(opBuilder.build());
+  }
+  
+  /**
+   * The current size of the TensorArray.
+   */
+  public Output<Integer> size() {
+    return size;
+  }
+  
+  @Override
+  public Output<Integer> asOutput() {
+    return size;
+  }
+  
+  private Output<Integer> size;
+  
+  private TensorArraySize(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    size = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TensorArraySplit.java java-ops/org/tensorflow/op/core/TensorArraySplit.java
--- java/org/tensorflow/op/core/TensorArraySplit.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TensorArraySplit.java	2018-10-16 20:18:38.595432126 +0900
@@ -0,0 +1,95 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Split the data from the input value into TensorArray elements.
+ * <p>
+ * Assuming that `lengths` takes on values
+ * <p>
+ *   <pre>{@code
+ * (n0, n1, ..., n(T-1))}</pre>
+ * and that `value` has shape
+ * <p>
+ *   <pre>{@code
+ * (n0 + n1 + ... + n(T-1) x d0 x d1 x ...)}</pre>
+ * ,
+ * <p>
+ * this splits values into a TensorArray with T tensors.
+ * <p>
+ * TensorArray index t will be the subtensor of values with starting position
+ * <p>
+ *   <pre>{@code
+ * (n0 + n1 + ... + n(t-1), 0, 0, ...)}</pre>
+ * and having size
+ * <p>
+ *   <pre>{@code
+ * nt x d0 x d1 x ...}</pre>
+ * 
+ */
+@Operator
+public final class TensorArraySplit extends PrimitiveOp implements Operand<Float> {
+  
+  /**
+   * Factory method to create a class to wrap a new TensorArraySplit operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param handle The handle to a TensorArray.
+   * @param value The concatenated tensor to write to the TensorArray.
+   * @param lengths The vector of lengths, how to split the rows of value into the
+   * TensorArray.
+   * @param flowIn A float scalar that enforces proper chaining of operations.
+   * @return a new instance of TensorArraySplit
+   */
+  public static <T> TensorArraySplit create(Scope scope, Operand<?> handle, Operand<T> value, Operand<Long> lengths, Operand<Float> flowIn) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TensorArraySplitV3", scope.makeOpName("TensorArraySplit"));
+    opBuilder.addInput(handle.asOutput());
+    opBuilder.addInput(value.asOutput());
+    opBuilder.addInput(lengths.asOutput());
+    opBuilder.addInput(flowIn.asOutput());
+    return new TensorArraySplit(opBuilder.build());
+  }
+  
+  /**
+   * A float scalar that enforces proper chaining of operations.
+   */
+  public Output<Float> flowOut() {
+    return flowOut;
+  }
+  
+  @Override
+  public Output<Float> asOutput() {
+    return flowOut;
+  }
+  
+  private Output<Float> flowOut;
+  
+  private TensorArraySplit(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    flowOut = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TensorArrayUnpack.java java-ops/org/tensorflow/op/core/TensorArrayUnpack.java
--- java/org/tensorflow/op/core/TensorArrayUnpack.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TensorArrayUnpack.java	2018-10-16 20:18:38.596432126 +0900
@@ -0,0 +1,68 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ */
+@Operator
+public final class TensorArrayUnpack extends PrimitiveOp implements Operand<Float> {
+  
+  /**
+   * Factory method to create a class to wrap a new TensorArrayUnpack operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param handle 
+   * @param value 
+   * @param flowIn 
+   * @return a new instance of TensorArrayUnpack
+   */
+  public static <T> TensorArrayUnpack create(Scope scope, Operand<String> handle, Operand<T> value, Operand<Float> flowIn) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TensorArrayUnpack", scope.makeOpName("TensorArrayUnpack"));
+    opBuilder.addInput(handle.asOutput());
+    opBuilder.addInput(value.asOutput());
+    opBuilder.addInput(flowIn.asOutput());
+    return new TensorArrayUnpack(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<Float> flowOut() {
+    return flowOut;
+  }
+  
+  @Override
+  public Output<Float> asOutput() {
+    return flowOut;
+  }
+  
+  private Output<Float> flowOut;
+  
+  private TensorArrayUnpack(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    flowOut = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TensorArrayWrite.java java-ops/org/tensorflow/op/core/TensorArrayWrite.java
--- java/org/tensorflow/op/core/TensorArrayWrite.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TensorArrayWrite.java	2018-10-16 20:18:38.597432125 +0900
@@ -0,0 +1,72 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Push an element onto the tensor_array.
+ */
+@Operator
+public final class TensorArrayWrite extends PrimitiveOp implements Operand<Float> {
+  
+  /**
+   * Factory method to create a class to wrap a new TensorArrayWrite operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param handle The handle to a TensorArray.
+   * @param index The position to write to inside the TensorArray.
+   * @param value The tensor to write to the TensorArray.
+   * @param flowIn A float scalar that enforces proper chaining of operations.
+   * @return a new instance of TensorArrayWrite
+   */
+  public static <T> TensorArrayWrite create(Scope scope, Operand<?> handle, Operand<Integer> index, Operand<T> value, Operand<Float> flowIn) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TensorArrayWriteV3", scope.makeOpName("TensorArrayWrite"));
+    opBuilder.addInput(handle.asOutput());
+    opBuilder.addInput(index.asOutput());
+    opBuilder.addInput(value.asOutput());
+    opBuilder.addInput(flowIn.asOutput());
+    return new TensorArrayWrite(opBuilder.build());
+  }
+  
+  /**
+   * A float scalar that enforces proper chaining of operations.
+   */
+  public Output<Float> flowOut() {
+    return flowOut;
+  }
+  
+  @Override
+  public Output<Float> asOutput() {
+    return flowOut;
+  }
+  
+  private Output<Float> flowOut;
+  
+  private TensorArrayWrite(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    flowOut = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TensorDataset.java java-ops/org/tensorflow/op/core/TensorDataset.java
--- java/org/tensorflow/op/core/TensorDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TensorDataset.java	2018-10-16 20:18:38.598432124 +0900
@@ -0,0 +1,75 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Creates a dataset that emits `components` as a tuple of tensors once.
+ */
+@Operator
+public final class TensorDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new TensorDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param components 
+   * @param outputShapes 
+   * @return a new instance of TensorDataset
+   */
+  public static TensorDataset create(Scope scope, Iterable<Operand<?>> components, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TensorDataset", scope.makeOpName("TensorDataset"));
+    opBuilder.addInputList(Operands.asOutputs(components));
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new TensorDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private TensorDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TensorListConcatLists.java java-ops/org/tensorflow/op/core/TensorListConcatLists.java
--- java/org/tensorflow/op/core/TensorListConcatLists.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TensorListConcatLists.java	2018-10-16 20:18:38.599432123 +0900
@@ -0,0 +1,70 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ */
+@Operator
+public final class TensorListConcatLists extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new TensorListConcatLists operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputA 
+   * @param inputB 
+   * @param elementDtype 
+   * @return a new instance of TensorListConcatLists
+   */
+  public static <T> TensorListConcatLists create(Scope scope, Operand<?> inputA, Operand<?> inputB, Class<T> elementDtype) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TensorListConcatLists", scope.makeOpName("TensorListConcatLists"));
+    opBuilder.addInput(inputA.asOutput());
+    opBuilder.addInput(inputB.asOutput());
+    opBuilder.setAttr("element_dtype", DataType.fromClass(elementDtype));
+    return new TensorListConcatLists(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> output() {
+    return output;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) output;
+  }
+  
+  private Output<?> output;
+  
+  private TensorListConcatLists(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TensorListElementShape.java java-ops/org/tensorflow/op/core/TensorListElementShape.java
--- java/org/tensorflow/op/core/TensorListElementShape.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TensorListElementShape.java	2018-10-16 20:18:38.599432123 +0900
@@ -0,0 +1,73 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * The shape of the elements of the given list, as a tensor.
+ * <p>
+ *   input_handle: the list
+ *   element_shape: the shape of elements of the list
+ * 
+ * @param <T> data type for {@code elementShape()} output
+ */
+@Operator
+public final class TensorListElementShape<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new TensorListElementShape operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputHandle 
+   * @param shapeType 
+   * @return a new instance of TensorListElementShape
+   */
+  public static <T extends Number> TensorListElementShape<T> create(Scope scope, Operand<?> inputHandle, Class<T> shapeType) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TensorListElementShape", scope.makeOpName("TensorListElementShape"));
+    opBuilder.addInput(inputHandle.asOutput());
+    opBuilder.setAttr("shape_type", DataType.fromClass(shapeType));
+    return new TensorListElementShape<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> elementShape() {
+    return elementShape;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return elementShape;
+  }
+  
+  private Output<T> elementShape;
+  
+  private TensorListElementShape(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    elementShape = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TensorListFromTensor.java java-ops/org/tensorflow/op/core/TensorListFromTensor.java
--- java/org/tensorflow/op/core/TensorListFromTensor.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TensorListFromTensor.java	2018-10-16 20:18:38.600432123 +0900
@@ -0,0 +1,73 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Creates a TensorList which, when stacked, has the value of `tensor`.
+ * <p>
+ * Each tensor in the result list corresponds to one row of the input tensor.
+ * <p>
+ * tensor: The input tensor.
+ * output_handle: The list.
+ */
+@Operator
+public final class TensorListFromTensor extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new TensorListFromTensor operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param tensor 
+   * @param elementShape 
+   * @return a new instance of TensorListFromTensor
+   */
+  public static <T, U extends Number> TensorListFromTensor create(Scope scope, Operand<T> tensor, Operand<U> elementShape) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TensorListFromTensor", scope.makeOpName("TensorListFromTensor"));
+    opBuilder.addInput(tensor.asOutput());
+    opBuilder.addInput(elementShape.asOutput());
+    return new TensorListFromTensor(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> outputHandle() {
+    return outputHandle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) outputHandle;
+  }
+  
+  private Output<?> outputHandle;
+  
+  private TensorListFromTensor(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    outputHandle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TensorListGather.java java-ops/org/tensorflow/op/core/TensorListGather.java
--- java/org/tensorflow/op/core/TensorListGather.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TensorListGather.java	2018-10-16 20:18:38.600432123 +0900
@@ -0,0 +1,79 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Creates a Tensor by indexing into the TensorList.
+ * <p>
+ * Each row in the produced Tensor corresponds to the element in the TensorList
+ * specified by the given index (see `tf.gather`).  
+ * <p>
+ * input_handle: The input tensor list.
+ * indices: The indices used to index into the list.
+ * values: The tensor.
+ * 
+ * @param <T> data type for {@code values()} output
+ */
+@Operator
+public final class TensorListGather<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new TensorListGather operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputHandle 
+   * @param indices 
+   * @param elementDtype 
+   * @return a new instance of TensorListGather
+   */
+  public static <T> TensorListGather<T> create(Scope scope, Operand<?> inputHandle, Operand<Integer> indices, Class<T> elementDtype) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TensorListGather", scope.makeOpName("TensorListGather"));
+    opBuilder.addInput(inputHandle.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.setAttr("element_dtype", DataType.fromClass(elementDtype));
+    return new TensorListGather<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> values() {
+    return values;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return values;
+  }
+  
+  private Output<T> values;
+  
+  private TensorListGather(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    values = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TensorListGetItem.java java-ops/org/tensorflow/op/core/TensorListGetItem.java
--- java/org/tensorflow/op/core/TensorListGetItem.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TensorListGetItem.java	2018-10-16 20:18:38.600432123 +0900
@@ -0,0 +1,70 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * @param <T> data type for {@code item()} output
+ */
+@Operator
+public final class TensorListGetItem<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new TensorListGetItem operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputHandle 
+   * @param index 
+   * @param elementDtype 
+   * @return a new instance of TensorListGetItem
+   */
+  public static <T> TensorListGetItem<T> create(Scope scope, Operand<?> inputHandle, Operand<Integer> index, Class<T> elementDtype) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TensorListGetItem", scope.makeOpName("TensorListGetItem"));
+    opBuilder.addInput(inputHandle.asOutput());
+    opBuilder.addInput(index.asOutput());
+    opBuilder.setAttr("element_dtype", DataType.fromClass(elementDtype));
+    return new TensorListGetItem<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> item() {
+    return item;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return item;
+  }
+  
+  private Output<T> item;
+  
+  private TensorListGetItem(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    item = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TensorListLength.java java-ops/org/tensorflow/op/core/TensorListLength.java
--- java/org/tensorflow/op/core/TensorListLength.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TensorListLength.java	2018-10-16 20:18:38.601432122 +0900
@@ -0,0 +1,68 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns the number of tensors in the input tensor list.
+ * <p>
+ * input_handle: the input list
+ * length: the number of tensors in the list
+ */
+@Operator
+public final class TensorListLength extends PrimitiveOp implements Operand<Integer> {
+  
+  /**
+   * Factory method to create a class to wrap a new TensorListLength operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputHandle 
+   * @return a new instance of TensorListLength
+   */
+  public static TensorListLength create(Scope scope, Operand<?> inputHandle) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TensorListLength", scope.makeOpName("TensorListLength"));
+    opBuilder.addInput(inputHandle.asOutput());
+    return new TensorListLength(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<Integer> length() {
+    return length;
+  }
+  
+  @Override
+  public Output<Integer> asOutput() {
+    return length;
+  }
+  
+  private Output<Integer> length;
+  
+  private TensorListLength(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    length = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TensorListPopBack.java java-ops/org/tensorflow/op/core/TensorListPopBack.java
--- java/org/tensorflow/op/core/TensorListPopBack.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TensorListPopBack.java	2018-10-16 20:18:38.601432122 +0900
@@ -0,0 +1,80 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns the last element of the input list as well as a list with all but that element.
+ * <p>
+ * Fails if the list is empty.
+ * <p>
+ * input_handle: the input list
+ * tensor: the withdrawn last element of the list
+ * element_dtype: the type of elements in the list
+ * element_shape: the shape of the output tensor
+ * 
+ * @param <T> data type for {@code tensor()} output
+ */
+@Operator
+public final class TensorListPopBack<T> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new TensorListPopBack operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputHandle 
+   * @param elementDtype 
+   * @return a new instance of TensorListPopBack
+   */
+  public static <T> TensorListPopBack<T> create(Scope scope, Operand<?> inputHandle, Class<T> elementDtype) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TensorListPopBack", scope.makeOpName("TensorListPopBack"));
+    opBuilder.addInput(inputHandle.asOutput());
+    opBuilder.setAttr("element_dtype", DataType.fromClass(elementDtype));
+    return new TensorListPopBack<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> outputHandle() {
+    return outputHandle;
+  }
+  
+  /**
+   */
+  public Output<T> tensor() {
+    return tensor;
+  }
+  
+  private Output<?> outputHandle;
+  private Output<T> tensor;
+  
+  private TensorListPopBack(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    outputHandle = operation.output(outputIdx++);
+    tensor = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TensorListPushBackBatch.java java-ops/org/tensorflow/op/core/TensorListPushBackBatch.java
--- java/org/tensorflow/op/core/TensorListPushBackBatch.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TensorListPushBackBatch.java	2018-10-16 20:18:38.601432122 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ */
+@Operator
+public final class TensorListPushBackBatch extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new TensorListPushBackBatch operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputHandles 
+   * @param tensor 
+   * @return a new instance of TensorListPushBackBatch
+   */
+  public static <T> TensorListPushBackBatch create(Scope scope, Operand<?> inputHandles, Operand<T> tensor) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TensorListPushBackBatch", scope.makeOpName("TensorListPushBackBatch"));
+    opBuilder.addInput(inputHandles.asOutput());
+    opBuilder.addInput(tensor.asOutput());
+    return new TensorListPushBackBatch(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> outputHandles() {
+    return outputHandles;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) outputHandles;
+  }
+  
+  private Output<?> outputHandles;
+  
+  private TensorListPushBackBatch(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    outputHandles = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TensorListPushBack.java java-ops/org/tensorflow/op/core/TensorListPushBack.java
--- java/org/tensorflow/op/core/TensorListPushBack.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TensorListPushBack.java	2018-10-16 20:18:38.601432122 +0900
@@ -0,0 +1,74 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns a list list which has the passed-in `Tensor` as last element and the other elements of the given list in `input_handle`.
+ * <p>
+ * tensor: The tensor to put on the list.
+ * input_handle: The old list.
+ * output_handle: A list with the elements of the old list followed by tensor.
+ * element_dtype: the type of elements in the list.
+ * element_shape: a shape compatible with that of elements in the list.
+ */
+@Operator
+public final class TensorListPushBack extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new TensorListPushBack operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputHandle 
+   * @param tensor 
+   * @return a new instance of TensorListPushBack
+   */
+  public static <T> TensorListPushBack create(Scope scope, Operand<?> inputHandle, Operand<T> tensor) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TensorListPushBack", scope.makeOpName("TensorListPushBack"));
+    opBuilder.addInput(inputHandle.asOutput());
+    opBuilder.addInput(tensor.asOutput());
+    return new TensorListPushBack(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> outputHandle() {
+    return outputHandle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) outputHandle;
+  }
+  
+  private Output<?> outputHandle;
+  
+  private TensorListPushBack(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    outputHandle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TensorListReserve.java java-ops/org/tensorflow/op/core/TensorListReserve.java
--- java/org/tensorflow/op/core/TensorListReserve.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TensorListReserve.java	2018-10-16 20:18:38.602432121 +0900
@@ -0,0 +1,76 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * List of the given size with empty elements.
+ * <p>
+ * element_shape: the shape of the future elements of the list
+ * num_elements: the number of elements to reserve
+ * handle: the output list
+ * element_dtype: the desired type of elements in the list.
+ */
+@Operator
+public final class TensorListReserve extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new TensorListReserve operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param elementShape 
+   * @param numElements 
+   * @param elementDtype 
+   * @return a new instance of TensorListReserve
+   */
+  public static <T extends Number, U> TensorListReserve create(Scope scope, Operand<T> elementShape, Operand<Integer> numElements, Class<U> elementDtype) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TensorListReserve", scope.makeOpName("TensorListReserve"));
+    opBuilder.addInput(elementShape.asOutput());
+    opBuilder.addInput(numElements.asOutput());
+    opBuilder.setAttr("element_dtype", DataType.fromClass(elementDtype));
+    return new TensorListReserve(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private TensorListReserve(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TensorListScatter.java java-ops/org/tensorflow/op/core/TensorListScatter.java
--- java/org/tensorflow/op/core/TensorListScatter.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TensorListScatter.java	2018-10-16 20:18:38.602432121 +0900
@@ -0,0 +1,79 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Creates a TensorList by indexing into a Tensor.
+ * <p>
+ * Each member of the TensorList corresponds to one row of the input tensor,
+ * specified by the given index (see `tf.gather`).
+ * <p>
+ * tensor: The input tensor.
+ * indices: The indices used to index into the list.
+ * element_shape: The shape of the elements in the list (can be less specified than
+ *   the shape of the tensor).  
+ * output_handle: The TensorList.
+ */
+@Operator
+public final class TensorListScatter extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new TensorListScatter operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param tensor 
+   * @param indices 
+   * @param elementShape 
+   * @return a new instance of TensorListScatter
+   */
+  public static <T, U extends Number> TensorListScatter create(Scope scope, Operand<T> tensor, Operand<Integer> indices, Operand<U> elementShape) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TensorListScatter", scope.makeOpName("TensorListScatter"));
+    opBuilder.addInput(tensor.asOutput());
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(elementShape.asOutput());
+    return new TensorListScatter(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> outputHandle() {
+    return outputHandle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) outputHandle;
+  }
+  
+  private Output<?> outputHandle;
+  
+  private TensorListScatter(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    outputHandle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TensorListSetItem.java java-ops/org/tensorflow/op/core/TensorListSetItem.java
--- java/org/tensorflow/op/core/TensorListSetItem.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TensorListSetItem.java	2018-10-16 20:18:38.602432121 +0900
@@ -0,0 +1,69 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ */
+@Operator
+public final class TensorListSetItem extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new TensorListSetItem operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputHandle 
+   * @param index 
+   * @param item 
+   * @return a new instance of TensorListSetItem
+   */
+  public static <T> TensorListSetItem create(Scope scope, Operand<?> inputHandle, Operand<Integer> index, Operand<T> item) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TensorListSetItem", scope.makeOpName("TensorListSetItem"));
+    opBuilder.addInput(inputHandle.asOutput());
+    opBuilder.addInput(index.asOutput());
+    opBuilder.addInput(item.asOutput());
+    return new TensorListSetItem(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> outputHandle() {
+    return outputHandle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) outputHandle;
+  }
+  
+  private Output<?> outputHandle;
+  
+  private TensorListSetItem(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    outputHandle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TensorListStack.java java-ops/org/tensorflow/op/core/TensorListStack.java
--- java/org/tensorflow/op/core/TensorListStack.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TensorListStack.java	2018-10-16 20:18:38.603432121 +0900
@@ -0,0 +1,111 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Stacks all tensors in the list.
+ * <p>
+ * Requires that all tensors have the same shape.
+ * <p>
+ * input_handle: the input list
+ * tensor: the gathered result
+ * num_elements: optional. If not -1, the number of elements in the list.
+ * 
+ * 
+ * @param <T> data type for {@code tensor()} output
+ */
+@Operator
+public final class TensorListStack<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.TensorListStack}
+   */
+  public static class Options {
+    
+    /**
+     * @param numElements 
+     */
+    public Options numElements(Long numElements) {
+      this.numElements = numElements;
+      return this;
+    }
+    
+    private Long numElements;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new TensorListStack operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputHandle 
+   * @param elementDtype 
+   * @param options carries optional attributes values
+   * @return a new instance of TensorListStack
+   */
+  public static <T> TensorListStack<T> create(Scope scope, Operand<?> inputHandle, Class<T> elementDtype, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TensorListStack", scope.makeOpName("TensorListStack"));
+    opBuilder.addInput(inputHandle.asOutput());
+    opBuilder.setAttr("element_dtype", DataType.fromClass(elementDtype));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.numElements != null) {
+          opBuilder.setAttr("num_elements", opts.numElements);
+        }
+      }
+    }
+    return new TensorListStack<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param numElements 
+   */
+  public static Options numElements(Long numElements) {
+    return new Options().numElements(numElements);
+  }
+  
+  /**
+   */
+  public Output<T> tensor() {
+    return tensor;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return tensor;
+  }
+  
+  private Output<T> tensor;
+  
+  private TensorListStack(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    tensor = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TensorSliceDataset.java java-ops/org/tensorflow/op/core/TensorSliceDataset.java
--- java/org/tensorflow/op/core/TensorSliceDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TensorSliceDataset.java	2018-10-16 20:18:38.603432121 +0900
@@ -0,0 +1,75 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Creates a dataset that emits each dim-0 slice of `components` once.
+ */
+@Operator
+public final class TensorSliceDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new TensorSliceDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param components 
+   * @param outputShapes 
+   * @return a new instance of TensorSliceDataset
+   */
+  public static TensorSliceDataset create(Scope scope, Iterable<Operand<?>> components, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TensorSliceDataset", scope.makeOpName("TensorSliceDataset"));
+    opBuilder.addInputList(Operands.asOutputs(components));
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new TensorSliceDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private TensorSliceDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TensorSummary.java java-ops/org/tensorflow/op/core/TensorSummary.java
--- java/org/tensorflow/op/core/TensorSummary.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TensorSummary.java	2018-10-16 20:18:38.603432121 +0900
@@ -0,0 +1,146 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Outputs a `Summary` protocol buffer with a tensor.
+ * <p>
+ * This op is being phased out in favor of TensorSummaryV2, which lets callers pass
+ * a tag as well as a serialized SummaryMetadata proto string that contains
+ * plugin-specific data. We will keep this op to maintain backwards compatibility.
+ */
+@Operator
+public final class TensorSummary extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.TensorSummary}
+   */
+  public static class Options {
+    
+    /**
+     * @param description A json-encoded SummaryDescription proto.
+     */
+    public Options description(String description) {
+      this.description = description;
+      return this;
+    }
+    
+    /**
+     * @param labels An unused list of strings.
+     */
+    public Options labels(List<String> labels) {
+      this.labels = labels;
+      return this;
+    }
+    
+    /**
+     * @param displayName An unused string.
+     */
+    public Options displayName(String displayName) {
+      this.displayName = displayName;
+      return this;
+    }
+    
+    private String description;
+    private List<String> labels;
+    private String displayName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new TensorSummary operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param tensor A tensor to serialize.
+   * @param options carries optional attributes values
+   * @return a new instance of TensorSummary
+   */
+  public static <T> TensorSummary create(Scope scope, Operand<T> tensor, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TensorSummary", scope.makeOpName("TensorSummary"));
+    opBuilder.addInput(tensor.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.description != null) {
+          opBuilder.setAttr("description", opts.description);
+        }
+        if (opts.labels != null) {
+          String[] labelsArray = new String[opts.labels.size()];
+          for (int i = 0; i < labelsArray.length; ++i) {
+            labelsArray[i] = opts.labels.get(i);
+          }
+          opBuilder.setAttr("labels", labelsArray);
+        }
+        if (opts.displayName != null) {
+          opBuilder.setAttr("display_name", opts.displayName);
+        }
+      }
+    }
+    return new TensorSummary(opBuilder.build());
+  }
+  
+  /**
+   * @param description A json-encoded SummaryDescription proto.
+   */
+  public static Options description(String description) {
+    return new Options().description(description);
+  }
+  
+  /**
+   * @param labels An unused list of strings.
+   */
+  public static Options labels(List<String> labels) {
+    return new Options().labels(labels);
+  }
+  
+  /**
+   * @param displayName An unused string.
+   */
+  public static Options displayName(String displayName) {
+    return new Options().displayName(displayName);
+  }
+  
+  /**
+   */
+  public Output<String> summary() {
+    return summary;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return summary;
+  }
+  
+  private Output<String> summary;
+  
+  private TensorSummary(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    summary = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TensorSummaryV2.java java-ops/org/tensorflow/op/core/TensorSummaryV2.java
--- java/org/tensorflow/op/core/TensorSummaryV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TensorSummaryV2.java	2018-10-16 20:18:38.603432121 +0900
@@ -0,0 +1,70 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Outputs a `Summary` protocol buffer with a tensor and per-plugin data.
+ */
+@Operator
+public final class TensorSummaryV2 extends PrimitiveOp implements Operand<String> {
+  
+  /**
+   * Factory method to create a class to wrap a new TensorSummaryV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param tag A string attached to this summary. Used for organization in TensorBoard.
+   * @param tensor A tensor to serialize.
+   * @param serializedSummaryMetadata A serialized SummaryMetadata proto. Contains plugin
+   * data.
+   * @return a new instance of TensorSummaryV2
+   */
+  public static <T> TensorSummaryV2 create(Scope scope, Operand<String> tag, Operand<T> tensor, Operand<String> serializedSummaryMetadata) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TensorSummaryV2", scope.makeOpName("TensorSummaryV2"));
+    opBuilder.addInput(tag.asOutput());
+    opBuilder.addInput(tensor.asOutput());
+    opBuilder.addInput(serializedSummaryMetadata.asOutput());
+    return new TensorSummaryV2(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<String> summary() {
+    return summary;
+  }
+  
+  @Override
+  public Output<String> asOutput() {
+    return summary;
+  }
+  
+  private Output<String> summary;
+  
+  private TensorSummaryV2(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    summary = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TextLineDataset.java java-ops/org/tensorflow/op/core/TextLineDataset.java
--- java/org/tensorflow/op/core/TextLineDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TextLineDataset.java	2018-10-16 20:18:38.604432120 +0900
@@ -0,0 +1,72 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Creates a dataset that emits the lines of one or more text files.
+ */
+@Operator
+public final class TextLineDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new TextLineDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param filenames A scalar or a vector containing the name(s) of the file(s) to be
+   * read.
+   * @param compressionType A scalar containing either (i) the empty string (no
+   * compression), (ii) "ZLIB", or (iii) "GZIP".
+   * @param bufferSize A scalar containing the number of bytes to buffer.
+   * @return a new instance of TextLineDataset
+   */
+  public static TextLineDataset create(Scope scope, Operand<String> filenames, Operand<String> compressionType, Operand<Long> bufferSize) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TextLineDataset", scope.makeOpName("TextLineDataset"));
+    opBuilder.addInput(filenames.asOutput());
+    opBuilder.addInput(compressionType.asOutput());
+    opBuilder.addInput(bufferSize.asOutput());
+    return new TextLineDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private TextLineDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TextLineReader.java java-ops/org/tensorflow/op/core/TextLineReader.java
--- java/org/tensorflow/op/core/TextLineReader.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TextLineReader.java	2018-10-16 20:18:38.604432120 +0900
@@ -0,0 +1,141 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * A Reader that outputs the lines of a file delimited by '\n'.
+ */
+@Operator
+public final class TextLineReader extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.TextLineReader}
+   */
+  public static class Options {
+    
+    /**
+     * @param skipHeaderLines Number of lines to skip from the beginning of every file.
+     */
+    public Options skipHeaderLines(Long skipHeaderLines) {
+      this.skipHeaderLines = skipHeaderLines;
+      return this;
+    }
+    
+    /**
+     * @param container If non-empty, this reader is placed in the given container.
+     * Otherwise, a default container is used.
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName If non-empty, this reader is named in the given bucket
+     * with this shared_name. Otherwise, the node name is used instead.
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private Long skipHeaderLines;
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new TextLineReader operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param options carries optional attributes values
+   * @return a new instance of TextLineReader
+   */
+  public static TextLineReader create(Scope scope, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TextLineReaderV2", scope.makeOpName("TextLineReader"));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.skipHeaderLines != null) {
+          opBuilder.setAttr("skip_header_lines", opts.skipHeaderLines);
+        }
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new TextLineReader(opBuilder.build());
+  }
+  
+  /**
+   * @param skipHeaderLines Number of lines to skip from the beginning of every file.
+   */
+  public static Options skipHeaderLines(Long skipHeaderLines) {
+    return new Options().skipHeaderLines(skipHeaderLines);
+  }
+  
+  /**
+   * @param container If non-empty, this reader is placed in the given container.
+   * Otherwise, a default container is used.
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName If non-empty, this reader is named in the given bucket
+   * with this shared_name. Otherwise, the node name is used instead.
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   * The handle to reference the Reader.
+   */
+  public Output<?> readerHandle() {
+    return readerHandle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) readerHandle;
+  }
+  
+  private Output<?> readerHandle;
+  
+  private TextLineReader(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    readerHandle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TFRecordDataset.java java-ops/org/tensorflow/op/core/TFRecordDataset.java
--- java/org/tensorflow/op/core/TFRecordDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TFRecordDataset.java	2018-10-16 20:18:38.585432133 +0900
@@ -0,0 +1,73 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Creates a dataset that emits the records from one or more TFRecord files.
+ */
+@Operator
+public final class TFRecordDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new TFRecordDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param filenames A scalar or vector containing the name(s) of the file(s) to be
+   * read.
+   * @param compressionType A scalar containing either (i) the empty string (no
+   * compression), (ii) "ZLIB", or (iii) "GZIP".
+   * @param bufferSize A scalar representing the number of bytes to buffer. A value of
+   * 0 means no buffering will be performed.
+   * @return a new instance of TFRecordDataset
+   */
+  public static TFRecordDataset create(Scope scope, Operand<String> filenames, Operand<String> compressionType, Operand<Long> bufferSize) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TFRecordDataset", scope.makeOpName("TFRecordDataset"));
+    opBuilder.addInput(filenames.asOutput());
+    opBuilder.addInput(compressionType.asOutput());
+    opBuilder.addInput(bufferSize.asOutput());
+    return new TFRecordDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private TFRecordDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TFRecordReader.java java-ops/org/tensorflow/op/core/TFRecordReader.java
--- java/org/tensorflow/op/core/TFRecordReader.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TFRecordReader.java	2018-10-16 20:18:38.586432132 +0900
@@ -0,0 +1,141 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * A Reader that outputs the records from a TensorFlow Records file.
+ */
+@Operator
+public final class TFRecordReader extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.TFRecordReader}
+   */
+  public static class Options {
+    
+    /**
+     * @param container If non-empty, this reader is placed in the given container.
+     * Otherwise, a default container is used.
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName If non-empty, this reader is named in the given bucket
+     * with this shared_name. Otherwise, the node name is used instead.
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    /**
+     * @param compressionType 
+     */
+    public Options compressionType(String compressionType) {
+      this.compressionType = compressionType;
+      return this;
+    }
+    
+    private String container;
+    private String sharedName;
+    private String compressionType;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new TFRecordReader operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param options carries optional attributes values
+   * @return a new instance of TFRecordReader
+   */
+  public static TFRecordReader create(Scope scope, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TFRecordReaderV2", scope.makeOpName("TFRecordReader"));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+        if (opts.compressionType != null) {
+          opBuilder.setAttr("compression_type", opts.compressionType);
+        }
+      }
+    }
+    return new TFRecordReader(opBuilder.build());
+  }
+  
+  /**
+   * @param container If non-empty, this reader is placed in the given container.
+   * Otherwise, a default container is used.
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName If non-empty, this reader is named in the given bucket
+   * with this shared_name. Otherwise, the node name is used instead.
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   * @param compressionType 
+   */
+  public static Options compressionType(String compressionType) {
+    return new Options().compressionType(compressionType);
+  }
+  
+  /**
+   * The handle to reference the Reader.
+   */
+  public Output<?> readerHandle() {
+    return readerHandle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) readerHandle;
+  }
+  
+  private Output<?> readerHandle;
+  
+  private TFRecordReader(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    readerHandle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TileGrad.java java-ops/org/tensorflow/op/core/TileGrad.java
--- java/org/tensorflow/op/core/TileGrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TileGrad.java	2018-10-16 20:18:38.605432119 +0900
@@ -0,0 +1,73 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns the gradient of `Tile`.
+ * <p>
+ * Since `Tile` takes an input and repeats the input `multiples` times
+ * along each dimension, `TileGrad` takes in `multiples` and aggregates
+ * each repeated tile of `input` into `output`.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class TileGrad<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new TileGrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param multiples 
+   * @return a new instance of TileGrad
+   */
+  public static <T> TileGrad<T> create(Scope scope, Operand<T> input, Operand<Integer> multiples) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TileGrad", scope.makeOpName("TileGrad"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(multiples.asOutput());
+    return new TileGrad<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private TileGrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Tile.java java-ops/org/tensorflow/op/core/Tile.java
--- java/org/tensorflow/op/core/Tile.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Tile.java	2018-10-16 20:18:38.605432119 +0900
@@ -0,0 +1,75 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Constructs a tensor by tiling a given tensor.
+ * <p>
+ * This operation creates a new tensor by replicating `input` `multiples` times.
+ * The output tensor's i'th dimension has `input.dims(i) * multiples[i]` elements,
+ * and the values of `input` are replicated `multiples[i]` times along the 'i'th
+ * dimension. For example, tiling `[a b c d]` by `[2]` produces
+ * `[a b c d a b c d]`.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class Tile<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Tile operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 1-D or higher.
+   * @param multiples 1-D. Length must be the same as the number of dimensions in `input`
+   * @return a new instance of Tile
+   */
+  public static <T, U extends Number> Tile<T> create(Scope scope, Operand<T> input, Operand<U> multiples) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Tile", scope.makeOpName("Tile"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(multiples.asOutput());
+    return new Tile<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private Tile(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Timestamp.java java-ops/org/tensorflow/op/core/Timestamp.java
--- java/org/tensorflow/op/core/Timestamp.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Timestamp.java	2018-10-16 20:18:38.605432119 +0900
@@ -0,0 +1,68 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Provides the time since epoch in seconds.
+ * <p>
+ * Returns the timestamp as a `float64` for seconds since the Unix epoch.
+ * <p>
+ * Note: the timestamp is computed when the op is executed, not when it is added
+ * to the graph.
+ */
+@Operator
+public final class Timestamp extends PrimitiveOp implements Operand<Double> {
+  
+  /**
+   * Factory method to create a class to wrap a new Timestamp operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @return a new instance of Timestamp
+   */
+  public static Timestamp create(Scope scope) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Timestamp", scope.makeOpName("Timestamp"));
+    return new Timestamp(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<Double> ts() {
+    return ts;
+  }
+  
+  @Override
+  public Output<Double> asOutput() {
+    return ts;
+  }
+  
+  private Output<Double> ts;
+  
+  private Timestamp(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    ts = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TopK.java java-ops/org/tensorflow/op/core/TopK.java
--- java/org/tensorflow/op/core/TopK.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TopK.java	2018-10-16 20:18:38.606432119 +0900
@@ -0,0 +1,122 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Finds values and indices of the `k` largest elements for the last dimension.
+ * <p>
+ * If the input is a vector (rank-1), finds the `k` largest entries in the vector
+ * and outputs their values and indices as vectors.  Thus `values[j]` is the
+ * `j`-th largest entry in `input`, and its index is `indices[j]`.
+ * <p>
+ * For matrices (resp. higher rank input), computes the top `k` entries in each
+ * row (resp. vector along the last dimension).  Thus,
+ * <p>
+ *     values.shape = indices.shape = input.shape[:-1] + [k]
+ * <p>
+ * If two elements are equal, the lower-index element appears first.
+ * 
+ * @param <T> data type for {@code values()} output
+ */
+@Operator
+public final class TopK<T extends Number> extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.TopK}
+   */
+  public static class Options {
+    
+    /**
+     * @param sorted If true the resulting `k` elements will be sorted by the values in
+     * descending order.
+     */
+    public Options sorted(Boolean sorted) {
+      this.sorted = sorted;
+      return this;
+    }
+    
+    private Boolean sorted;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new TopK operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 1-D or higher with last dimension at least `k`.
+   * @param k 0-D.  Number of top elements to look for along the last dimension (along each
+   * row for matrices).
+   * @param options carries optional attributes values
+   * @return a new instance of TopK
+   */
+  public static <T extends Number> TopK<T> create(Scope scope, Operand<T> input, Operand<Integer> k, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TopKV2", scope.makeOpName("TopK"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.addInput(k.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.sorted != null) {
+          opBuilder.setAttr("sorted", opts.sorted);
+        }
+      }
+    }
+    return new TopK<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param sorted If true the resulting `k` elements will be sorted by the values in
+   * descending order.
+   */
+  public static Options sorted(Boolean sorted) {
+    return new Options().sorted(sorted);
+  }
+  
+  /**
+   * The `k` largest elements along each last dimensional slice.
+   */
+  public Output<T> values() {
+    return values;
+  }
+  
+  /**
+   * The indices of `values` within the last dimension of `input`.
+   */
+  public Output<Integer> indices() {
+    return indices;
+  }
+  
+  private Output<T> values;
+  private Output<Integer> indices;
+  
+  private TopK(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    values = operation.output(outputIdx++);
+    indices = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Transpose.java java-ops/org/tensorflow/op/core/Transpose.java
--- java/org/tensorflow/op/core/Transpose.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Transpose.java	2018-10-16 20:18:38.607432118 +0900
@@ -0,0 +1,72 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Shuffle dimensions of x according to a permutation.
+ * <p>
+ * The output `y` has the same rank as `x`. The shapes of `x` and `y` satisfy:
+ *   `y.shape[i] == x.shape[perm[i]] for i in [0, 1, ..., rank(x) - 1]`
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class Transpose<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Transpose operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param perm 
+   * @return a new instance of Transpose
+   */
+  public static <T, U extends Number> Transpose<T> create(Scope scope, Operand<T> x, Operand<U> perm) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Transpose", scope.makeOpName("Transpose"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(perm.asOutput());
+    return new Transpose<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private Transpose(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TruncateDiv.java java-ops/org/tensorflow/op/core/TruncateDiv.java
--- java/org/tensorflow/op/core/TruncateDiv.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TruncateDiv.java	2018-10-16 20:18:38.607432118 +0900
@@ -0,0 +1,77 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns x / y element-wise for integer types.
+ * <p>
+ * Truncation designates that negative numbers will round fractional quantities
+ * toward zero. I.e. -7 / 5 = -1. This matches C semantics but it is different
+ * than Python semantics. See `FloorDiv` for a division function that matches
+ * Python Semantics.
+ * <p>
+ * <i>NOTE</i>: `TruncateDiv` supports broadcasting. More about broadcasting
+ * [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
+ * 
+ * @param <T> data type for {@code z()} output
+ */
+@Operator
+public final class TruncateDiv<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new TruncateDiv operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param y 
+   * @return a new instance of TruncateDiv
+   */
+  public static <T> TruncateDiv<T> create(Scope scope, Operand<T> x, Operand<T> y) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TruncateDiv", scope.makeOpName("TruncateDiv"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(y.asOutput());
+    return new TruncateDiv<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return z;
+  }
+  
+  private Output<T> z;
+  
+  private TruncateDiv(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TruncatedNormal.java java-ops/org/tensorflow/op/core/TruncatedNormal.java
--- java/org/tensorflow/op/core/TruncatedNormal.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TruncatedNormal.java	2018-10-16 20:18:38.608432117 +0900
@@ -0,0 +1,133 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Outputs random values from a truncated normal distribution.
+ * <p>
+ * The generated values follow a normal distribution with mean 0 and standard
+ * deviation 1, except that values whose magnitude is more than 2 standard
+ * deviations from the mean are dropped and re-picked.
+ * 
+ * @param <U> data type for {@code output()} output
+ */
+@Operator
+public final class TruncatedNormal<U extends Number> extends PrimitiveOp implements Operand<U> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.TruncatedNormal}
+   */
+  public static class Options {
+    
+    /**
+     * @param seed If either `seed` or `seed2` are set to be non-zero, the random number
+     * generator is seeded by the given seed.  Otherwise, it is seeded by a
+     * random seed.
+     */
+    public Options seed(Long seed) {
+      this.seed = seed;
+      return this;
+    }
+    
+    /**
+     * @param seed2 A second seed to avoid seed collision.
+     */
+    public Options seed2(Long seed2) {
+      this.seed2 = seed2;
+      return this;
+    }
+    
+    private Long seed;
+    private Long seed2;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new TruncatedNormal operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param shape The shape of the output tensor.
+   * @param dtype The type of the output.
+   * @param options carries optional attributes values
+   * @return a new instance of TruncatedNormal
+   */
+  public static <U extends Number, T extends Number> TruncatedNormal<U> create(Scope scope, Operand<T> shape, Class<U> dtype, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TruncatedNormal", scope.makeOpName("TruncatedNormal"));
+    opBuilder.addInput(shape.asOutput());
+    opBuilder.setAttr("dtype", DataType.fromClass(dtype));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.seed != null) {
+          opBuilder.setAttr("seed", opts.seed);
+        }
+        if (opts.seed2 != null) {
+          opBuilder.setAttr("seed2", opts.seed2);
+        }
+      }
+    }
+    return new TruncatedNormal<U>(opBuilder.build());
+  }
+  
+  /**
+   * @param seed If either `seed` or `seed2` are set to be non-zero, the random number
+   * generator is seeded by the given seed.  Otherwise, it is seeded by a
+   * random seed.
+   */
+  public static Options seed(Long seed) {
+    return new Options().seed(seed);
+  }
+  
+  /**
+   * @param seed2 A second seed to avoid seed collision.
+   */
+  public static Options seed2(Long seed2) {
+    return new Options().seed2(seed2);
+  }
+  
+  /**
+   * A tensor of the specified shape filled with random truncated normal
+   * values.
+   */
+  public Output<U> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<U> asOutput() {
+    return output;
+  }
+  
+  private Output<U> output;
+  
+  private TruncatedNormal(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TruncateMod.java java-ops/org/tensorflow/op/core/TruncateMod.java
--- java/org/tensorflow/op/core/TruncateMod.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TruncateMod.java	2018-10-16 20:18:38.608432117 +0900
@@ -0,0 +1,75 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns element-wise remainder of division. This emulates C semantics in that
+ * <p>
+ * the result here is consistent with a truncating divide. E.g. `truncate(x / y) *
+ * y + truncate_mod(x, y) = x`.
+ * <p>
+ * <i>NOTE</i>: `TruncateMod` supports broadcasting. More about broadcasting
+ * [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
+ * 
+ * @param <T> data type for {@code z()} output
+ */
+@Operator
+public final class TruncateMod<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new TruncateMod operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param y 
+   * @return a new instance of TruncateMod
+   */
+  public static <T extends Number> TruncateMod<T> create(Scope scope, Operand<T> x, Operand<T> y) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TruncateMod", scope.makeOpName("TruncateMod"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(y.asOutput());
+    return new TruncateMod<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return z;
+  }
+  
+  private Output<T> z;
+  
+  private TruncateMod(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/TryRpc.java java-ops/org/tensorflow/op/core/TryRpc.java
--- java/org/tensorflow/op/core/TryRpc.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/TryRpc.java	2018-10-16 20:18:38.609432117 +0900
@@ -0,0 +1,218 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Perform batches of RPC requests.
+ * <p>
+ * This op asynchronously performs either a single RPC request, or a batch
+ * of requests.  RPC requests are defined by three main parameters:
+ * <p>
+ *   - `address` (the host+port or BNS address of the request)
+ *   - `method` (the method name for the request)
+ *   - `request` (the serialized proto string, or vector of strings,
+ *      of the RPC request argument).
+ * <p>
+ * For example, if you have an RPC service running on port localhost:2345,
+ * and its interface is configured with the following proto declaration:
+ * <pre>{@code
+ * service MyService {
+ *   rpc MyMethod(MyRequestProto) returns (MyResponseProto) {
+ *   }
+ * };
+ * }</pre>
+ * then call this op with arguments:
+ * <pre>{@code
+ * address = "localhost:2345"
+ * method = "MyService/MyMethod"
+ * }</pre>
+ * The `request` tensor is a string tensor representing serialized `MyRequestProto`
+ * strings; and the output string tensor `response` will have the same shape
+ * and contain (upon successful completion) corresponding serialized
+ * `MyResponseProto` strings.
+ * <p>
+ * For example, to send a single, empty, `MyRequestProto`, call
+ * this op with `request = ""`.  To send 5 <b>parallel</b> empty requests,
+ * call this op with `request = ["", "", "", "", ""]`.
+ * <p>
+ * More generally, one can create a batch of `MyRequestProto` serialized protos
+ * from regular batched tensors using the `encode_proto` op, and convert
+ * the response `MyResponseProto` serialized protos to batched tensors
+ * using the `decode_proto` op.
+ * <p>
+ * <b>NOTE</b> Working with serialized proto strings is faster than instantiating
+ * actual proto objects in memory, so no performance degradation is expected
+ * compared to writing custom kernels for this workflow.
+ * <p>
+ * Unlike the standard `Rpc` op, if the connection fails or the remote worker
+ * returns an error status, this op does <b>not</b> reraise the exception.
+ * Instead, the `status_code` and `status_message` entry for the corresponding RPC
+ * call is set with the error returned from the RPC call.  The `response` tensor
+ * will contain valid response values for those minibatch entries whose RPCs did
+ * not fail; the rest of the entries will have empty strings.
+ */
+@Operator
+public final class TryRpc extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.TryRpc}
+   */
+  public static class Options {
+    
+    /**
+     * @param protocol RPC protocol to use.  Empty string means use the default protocol.
+     * Options include 'grpc'.
+     */
+    public Options protocol(String protocol) {
+      this.protocol = protocol;
+      return this;
+    }
+    
+    /**
+     * @param failFast `boolean`. If `true` (default), then failures to connect
+     * (i.e., the server does not immediately respond) cause an RPC failure.
+     */
+    public Options failFast(Boolean failFast) {
+      this.failFast = failFast;
+      return this;
+    }
+    
+    /**
+     * @param timeoutInMs `int`. If `0` (default), then the kernel will run the RPC
+     * request and only time out if the RPC deadline passes or the session times out.
+     * If this value is greater than `0`, then the op will raise an exception if
+     * the RPC takes longer than `timeout_in_ms`.
+     */
+    public Options timeoutInMs(Long timeoutInMs) {
+      this.timeoutInMs = timeoutInMs;
+      return this;
+    }
+    
+    private String protocol;
+    private Boolean failFast;
+    private Long timeoutInMs;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new TryRpc operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param address `0-D` or `1-D`.  The address (i.e. host_name:port) of the RPC server.
+   * If this tensor has more than 1 element, then multiple parallel rpc requests
+   * are sent.  This argument broadcasts with `method` and `request`.
+   * @param method `0-D` or `1-D`.  The method address on the RPC server.
+   * If this tensor has more than 1 element, then multiple parallel rpc requests
+   * are sent.  This argument broadcasts with `address` and `request`.
+   * @param request `0-D` or `1-D`.  Serialized proto strings: the rpc request argument.
+   * If this tensor has more than 1 element, then multiple parallel rpc requests
+   * are sent.  This argument broadcasts with `address` and `method`.
+   * @param options carries optional attributes values
+   * @return a new instance of TryRpc
+   */
+  public static TryRpc create(Scope scope, Operand<String> address, Operand<String> method, Operand<String> request, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("TryRpc", scope.makeOpName("TryRpc"));
+    opBuilder.addInput(address.asOutput());
+    opBuilder.addInput(method.asOutput());
+    opBuilder.addInput(request.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.protocol != null) {
+          opBuilder.setAttr("protocol", opts.protocol);
+        }
+        if (opts.failFast != null) {
+          opBuilder.setAttr("fail_fast", opts.failFast);
+        }
+        if (opts.timeoutInMs != null) {
+          opBuilder.setAttr("timeout_in_ms", opts.timeoutInMs);
+        }
+      }
+    }
+    return new TryRpc(opBuilder.build());
+  }
+  
+  /**
+   * @param protocol RPC protocol to use.  Empty string means use the default protocol.
+   * Options include 'grpc'.
+   */
+  public static Options protocol(String protocol) {
+    return new Options().protocol(protocol);
+  }
+  
+  /**
+   * @param failFast `boolean`. If `true` (default), then failures to connect
+   * (i.e., the server does not immediately respond) cause an RPC failure.
+   */
+  public static Options failFast(Boolean failFast) {
+    return new Options().failFast(failFast);
+  }
+  
+  /**
+   * @param timeoutInMs `int`. If `0` (default), then the kernel will run the RPC
+   * request and only time out if the RPC deadline passes or the session times out.
+   * If this value is greater than `0`, then the op will raise an exception if
+   * the RPC takes longer than `timeout_in_ms`.
+   */
+  public static Options timeoutInMs(Long timeoutInMs) {
+    return new Options().timeoutInMs(timeoutInMs);
+  }
+  
+  /**
+   * Same shape as `request`. Serialized proto strings: the rpc responses.
+   */
+  public Output<String> response() {
+    return response;
+  }
+  
+  /**
+   * Same shape as `request`.  Values correspond to tensorflow Status enum codes.
+   */
+  public Output<Integer> statusCode() {
+    return statusCode;
+  }
+  
+  /**
+   * Same shape as `request`.  Values correspond to Status messages
+   * returned from the RPC calls.
+   */
+  public Output<String> statusMessage() {
+    return statusMessage;
+  }
+  
+  private Output<String> response;
+  private Output<Integer> statusCode;
+  private Output<String> statusMessage;
+  
+  private TryRpc(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    response = operation.output(outputIdx++);
+    statusCode = operation.output(outputIdx++);
+    statusMessage = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/UnbatchDataset.java java-ops/org/tensorflow/op/core/UnbatchDataset.java
--- java/org/tensorflow/op/core/UnbatchDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/UnbatchDataset.java	2018-10-16 20:18:38.610432116 +0900
@@ -0,0 +1,81 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * A dataset that splits the elements of its input into multiple elements.
+ */
+@Operator
+public final class UnbatchDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new UnbatchDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputDataset 
+   * @param outputTypes 
+   * @param outputShapes 
+   * @return a new instance of UnbatchDataset
+   */
+  public static UnbatchDataset create(Scope scope, Operand<?> inputDataset, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("UnbatchDataset", scope.makeOpName("UnbatchDataset"));
+    opBuilder.addInput(inputDataset.asOutput());
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new UnbatchDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private UnbatchDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/UnbatchGrad.java java-ops/org/tensorflow/op/core/UnbatchGrad.java
--- java/org/tensorflow/op/core/UnbatchGrad.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/UnbatchGrad.java	2018-10-16 20:18:38.611432115 +0900
@@ -0,0 +1,141 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Gradient of Unbatch.
+ * <p>
+ * Acts like Batch but using the given batch_index index of batching things as they
+ * become available. This ensures that the gradients are propagated back in the
+ * same session which did the forward pass.
+ * <p>
+ * original_input: The input to the Unbatch operation this is the gradient of.
+ * batch_index: The batch_index given to the Unbatch operation this is the gradient
+ * of.
+ * grad: The downstream gradient.
+ * id: The id scalar emitted by Batch.
+ * batched_grad: The return value, either an empty tensor or the batched gradient.
+ * container: Container to control resource sharing.
+ * shared_name: Instances of UnbatchGrad with the same container and shared_name
+ *  are assumed to possibly belong to the same batch. If left empty, the op name
+ *  will be used as the shared name.
+ * 
+ * @param <T> data type for {@code batchedGrad()} output
+ */
+@Operator
+public final class UnbatchGrad<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.UnbatchGrad}
+   */
+  public static class Options {
+    
+    /**
+     * @param container 
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName 
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new UnbatchGrad operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param originalInput 
+   * @param batchIndex 
+   * @param grad 
+   * @param id 
+   * @param options carries optional attributes values
+   * @return a new instance of UnbatchGrad
+   */
+  public static <T> UnbatchGrad<T> create(Scope scope, Operand<T> originalInput, Operand<Long> batchIndex, Operand<T> grad, Operand<Long> id, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("UnbatchGrad", scope.makeOpName("UnbatchGrad"));
+    opBuilder.addInput(originalInput.asOutput());
+    opBuilder.addInput(batchIndex.asOutput());
+    opBuilder.addInput(grad.asOutput());
+    opBuilder.addInput(id.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new UnbatchGrad<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param container 
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName 
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   */
+  public Output<T> batchedGrad() {
+    return batchedGrad;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return batchedGrad;
+  }
+  
+  private Output<T> batchedGrad;
+  
+  private UnbatchGrad(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    batchedGrad = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Unbatch.java java-ops/org/tensorflow/op/core/Unbatch.java
--- java/org/tensorflow/op/core/Unbatch.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Unbatch.java	2018-10-16 20:18:38.610432116 +0900
@@ -0,0 +1,145 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Reverses the operation of Batch for a single output Tensor.
+ * <p>
+ * An instance of Unbatch either receives an empty batched_tensor, in which case it
+ * asynchronously waits until the values become available from a concurrently
+ * running instance of Unbatch with the same container and shared_name, or receives
+ * a non-empty batched_tensor in which case it finalizes all other concurrently
+ * running instances and outputs its own element from the batch.
+ * <p>
+ * batched_tensor: The possibly transformed output of Batch. The size of the first
+ *  dimension should remain unchanged by the transformations for the operation to
+ *  work.
+ * batch_index: The matching batch_index obtained from Batch.
+ * id: The id scalar emitted by Batch.
+ * unbatched_tensor: The Tensor corresponding to this execution.
+ * timeout_micros: Maximum amount of time (in microseconds) to wait to receive the
+ *  batched input tensor associated with a given invocation of the op.
+ * container: Container to control resource sharing.
+ * shared_name: Instances of Unbatch with the same container and shared_name are
+ *  assumed to possibly belong to the same batch. If left empty, the op name will
+ *  be used as the shared name.
+ * 
+ * @param <T> data type for {@code unbatchedTensor()} output
+ */
+@Operator
+public final class Unbatch<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Unbatch}
+   */
+  public static class Options {
+    
+    /**
+     * @param container 
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName 
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Unbatch operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param batchedTensor 
+   * @param batchIndex 
+   * @param id 
+   * @param timeoutMicros 
+   * @param options carries optional attributes values
+   * @return a new instance of Unbatch
+   */
+  public static <T> Unbatch<T> create(Scope scope, Operand<T> batchedTensor, Operand<Long> batchIndex, Operand<Long> id, Long timeoutMicros, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Unbatch", scope.makeOpName("Unbatch"));
+    opBuilder.addInput(batchedTensor.asOutput());
+    opBuilder.addInput(batchIndex.asOutput());
+    opBuilder.addInput(id.asOutput());
+    opBuilder.setAttr("timeout_micros", timeoutMicros);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new Unbatch<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param container 
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName 
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   */
+  public Output<T> unbatchedTensor() {
+    return unbatchedTensor;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return unbatchedTensor;
+  }
+  
+  private Output<T> unbatchedTensor;
+  
+  private Unbatch(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    unbatchedTensor = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/UnicodeScript.java java-ops/org/tensorflow/op/core/UnicodeScript.java
--- java/org/tensorflow/op/core/UnicodeScript.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/UnicodeScript.java	2018-10-16 20:18:38.611432115 +0900
@@ -0,0 +1,72 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Determine the script codes of a given tensor of Unicode integer code points.
+ * <p>
+ * This operation converts Unicode code points to script codes corresponding to
+ * each code point. Script codes correspond to International Components for
+ * Unicode (ICU) UScriptCode values. See http://icu-project.org/apiref/icu4c/uscript_8h.html.
+ * Returns -1 (USCRIPT_INVALID_CODE) for invalid codepoints. Output shape will
+ * match input shape.
+ */
+@Operator
+public final class UnicodeScript extends PrimitiveOp implements Operand<Integer> {
+  
+  /**
+   * Factory method to create a class to wrap a new UnicodeScript operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input A Tensor of int32 Unicode code points.
+   * @return a new instance of UnicodeScript
+   */
+  public static UnicodeScript create(Scope scope, Operand<Integer> input) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("UnicodeScript", scope.makeOpName("UnicodeScript"));
+    opBuilder.addInput(input.asOutput());
+    return new UnicodeScript(opBuilder.build());
+  }
+  
+  /**
+   * A Tensor of int32 script codes corresponding to each input code point.
+   */
+  public Output<Integer> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<Integer> asOutput() {
+    return output;
+  }
+  
+  private Output<Integer> output;
+  
+  private UnicodeScript(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/UniformCandidateSampler.java java-ops/org/tensorflow/op/core/UniformCandidateSampler.java
--- java/org/tensorflow/op/core/UniformCandidateSampler.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/UniformCandidateSampler.java	2018-10-16 20:18:38.612432114 +0900
@@ -0,0 +1,163 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Generates labels for candidate sampling with a uniform distribution.
+ * <p>
+ * See explanations of candidate sampling and the data formats at
+ * go/candidate-sampling.
+ * <p>
+ * For each batch, this op picks a single set of sampled candidate labels.
+ * <p>
+ * The advantages of sampling candidates per-batch are simplicity and the
+ * possibility of efficient dense matrix multiplication. The disadvantage is that
+ * the sampled candidates must be chosen independently of the context and of the
+ * true labels.
+ */
+@Operator
+public final class UniformCandidateSampler extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.UniformCandidateSampler}
+   */
+  public static class Options {
+    
+    /**
+     * @param seed If either seed or seed2 are set to be non-zero, the random number
+     * generator is seeded by the given seed.  Otherwise, it is seeded by a
+     * random seed.
+     */
+    public Options seed(Long seed) {
+      this.seed = seed;
+      return this;
+    }
+    
+    /**
+     * @param seed2 An second seed to avoid seed collision.
+     */
+    public Options seed2(Long seed2) {
+      this.seed2 = seed2;
+      return this;
+    }
+    
+    private Long seed;
+    private Long seed2;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new UniformCandidateSampler operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param trueClasses A batch_size * num_true matrix, in which each row contains the
+   * IDs of the num_true target_classes in the corresponding original label.
+   * @param numTrue Number of true labels per context.
+   * @param numSampled Number of candidates to randomly sample.
+   * @param unique If unique is true, we sample with rejection, so that all sampled
+   * candidates in a batch are unique. This requires some approximation to
+   * estimate the post-rejection sampling probabilities.
+   * @param rangeMax The sampler will sample integers from the interval [0, range_max).
+   * @param options carries optional attributes values
+   * @return a new instance of UniformCandidateSampler
+   */
+  public static UniformCandidateSampler create(Scope scope, Operand<Long> trueClasses, Long numTrue, Long numSampled, Boolean unique, Long rangeMax, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("UniformCandidateSampler", scope.makeOpName("UniformCandidateSampler"));
+    opBuilder.addInput(trueClasses.asOutput());
+    opBuilder.setAttr("num_true", numTrue);
+    opBuilder.setAttr("num_sampled", numSampled);
+    opBuilder.setAttr("unique", unique);
+    opBuilder.setAttr("range_max", rangeMax);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.seed != null) {
+          opBuilder.setAttr("seed", opts.seed);
+        }
+        if (opts.seed2 != null) {
+          opBuilder.setAttr("seed2", opts.seed2);
+        }
+      }
+    }
+    return new UniformCandidateSampler(opBuilder.build());
+  }
+  
+  /**
+   * @param seed If either seed or seed2 are set to be non-zero, the random number
+   * generator is seeded by the given seed.  Otherwise, it is seeded by a
+   * random seed.
+   */
+  public static Options seed(Long seed) {
+    return new Options().seed(seed);
+  }
+  
+  /**
+   * @param seed2 An second seed to avoid seed collision.
+   */
+  public static Options seed2(Long seed2) {
+    return new Options().seed2(seed2);
+  }
+  
+  /**
+   * A vector of length num_sampled, in which each element is
+   * the ID of a sampled candidate.
+   */
+  public Output<Long> sampledCandidates() {
+    return sampledCandidates;
+  }
+  
+  /**
+   * A batch_size * num_true matrix, representing
+   * the number of times each candidate is expected to occur in a batch
+   * of sampled candidates. If unique=true, then this is a probability.
+   */
+  public Output<Float> trueExpectedCount() {
+    return trueExpectedCount;
+  }
+  
+  /**
+   * A vector of length num_sampled, for each sampled
+   * candidate representing the number of times the candidate is expected
+   * to occur in a batch of sampled candidates.  If unique=true, then this is a
+   * probability.
+   */
+  public Output<Float> sampledExpectedCount() {
+    return sampledExpectedCount;
+  }
+  
+  private Output<Long> sampledCandidates;
+  private Output<Float> trueExpectedCount;
+  private Output<Float> sampledExpectedCount;
+  
+  private UniformCandidateSampler(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    sampledCandidates = operation.output(outputIdx++);
+    trueExpectedCount = operation.output(outputIdx++);
+    sampledExpectedCount = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Unique.java java-ops/org/tensorflow/op/core/Unique.java
--- java/org/tensorflow/op/core/Unique.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Unique.java	2018-10-16 20:18:38.613432114 +0900
@@ -0,0 +1,103 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Finds unique elements in a 1-D tensor.
+ * <p>
+ * This operation returns a tensor `y` containing all of the unique elements of `x`
+ * sorted in the same order that they occur in `x`. This operation also returns a
+ * tensor `idx` the same size as `x` that contains the index of each value of `x`
+ * in the unique output `y`. In other words:
+ * <p>
+ * `y[idx[i]] = x[i] for i in [0, 1,...,rank(x) - 1]`
+ * <p>
+ * For example:
+ * <pre>{@code
+ * # tensor 'x' is [1, 1, 2, 4, 4, 4, 7, 8, 8]
+ * y, idx = unique(x)
+ * y ==> [1, 2, 4, 7, 8]
+ * idx ==> [0, 0, 1, 2, 2, 2, 3, 4, 4]
+ * }</pre>
+ * 
+ * 
+ * @param <T> data type for {@code y()} output
+ * @param <U> data type for {@code idx()} output
+ */
+@Operator
+public final class Unique<T, U extends Number> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new Unique operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 1-D.
+   * @param outIdx 
+   * @return a new instance of Unique
+   */
+  public static <T, U extends Number> Unique<T, U> create(Scope scope, Operand<T> x, Class<U> outIdx) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Unique", scope.makeOpName("Unique"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.setAttr("out_idx", DataType.fromClass(outIdx));
+    return new Unique<T, U>(opBuilder.build());
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Unique operation to the graph, using default output types.
+   * 
+   * @param scope current graph scope
+   * @param x 1-D.
+   * @return a new instance of Unique
+   */
+  public static <T> Unique<T, Integer> create(Scope scope, Operand<T> x) {
+    return create(scope, x, Integer.class);
+  }
+  
+  /**
+   * 1-D.
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  /**
+   * 1-D.
+   */
+  public Output<U> idx() {
+    return idx;
+  }
+  
+  private Output<T> y;
+  private Output<U> idx;
+  
+  private Unique(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+    idx = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/UniqueV2.java java-ops/org/tensorflow/op/core/UniqueV2.java
--- java/org/tensorflow/op/core/UniqueV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/UniqueV2.java	2018-10-16 20:18:38.614432113 +0900
@@ -0,0 +1,133 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Finds unique elements along an axis of a tensor.
+ * <p>
+ * This operation either returns a tensor `y` containing unique elements
+ * along the `axis` of a tensor. The returned unique elements is sorted
+ * in the same order as they occur along `axis` in `x`.
+ * This operation also returns a tensor `idx` that is the same size as
+ * the number of the elements in `x` along the `axis` dimension. It
+ * contains the index in the unique output `y`.
+ * In other words, for an `1-D` tensor `x` with `axis = None:
+ * <p>
+ * `y[idx[i]] = x[i] for i in [0, 1,...,rank(x) - 1]`
+ * <p>
+ * For example:
+ * <pre>{@code
+ * # tensor 'x' is [1, 1, 2, 4, 4, 4, 7, 8, 8]
+ * y, idx = unique(x)
+ * y ==> [1, 2, 4, 7, 8]
+ * idx ==> [0, 0, 1, 2, 2, 2, 3, 4, 4]
+ * }</pre>
+ * For an `2-D` tensor `x` with `axis = 0`:
+ * <pre>{@code
+ * # tensor 'x' is [[1, 0, 0],
+ * #                [1, 0, 0],
+ * #                [2, 0, 0]]
+ * y, idx = unique(x, axis=0)
+ * y ==> [[1, 0, 0],
+ *        [2, 0, 0]]
+ * idx ==> [0, 0, 1]
+ * }</pre>
+ * For an `2-D` tensor `x` with `axis = 1`:
+ * <pre>{@code
+ * # tensor 'x' is [[1, 0, 0],
+ * #                [1, 0, 0],
+ * #                [2, 0, 0]]
+ * y, idx = unique(x, axis=1)
+ * y ==> [[1, 0],
+ *        [1, 0],
+ *        [2, 0]]
+ * idx ==> [0, 1, 1]
+ * }</pre>
+ * 
+ * 
+ * @param <T> data type for {@code y()} output
+ * @param <V> data type for {@code idx()} output
+ */
+@Operator
+public final class UniqueV2<T, V extends Number> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new UniqueV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x A `Tensor`.
+   * @param axis A `Tensor` of type `int32` (default: None). The axis of the Tensor to
+   * find the unique elements.
+   * @param outIdx 
+   * @return a new instance of UniqueV2
+   */
+  public static <T, V extends Number, U extends Number> UniqueV2<T, V> create(Scope scope, Operand<T> x, Operand<U> axis, Class<V> outIdx) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("UniqueV2", scope.makeOpName("UniqueV2"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(axis.asOutput());
+    opBuilder.setAttr("out_idx", DataType.fromClass(outIdx));
+    return new UniqueV2<T, V>(opBuilder.build());
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new UniqueV2 operation to the graph, using default output types.
+   * 
+   * @param scope current graph scope
+   * @param x A `Tensor`.
+   * @param axis A `Tensor` of type `int32` (default: None). The axis of the Tensor to
+   * find the unique elements.
+   * @return a new instance of UniqueV2
+   */
+  public static <T, U extends Number> UniqueV2<T, Integer> create(Scope scope, Operand<T> x, Operand<U> axis) {
+    return create(scope, x, axis, Integer.class);
+  }
+  
+  /**
+   * A `Tensor`. Unique elements along the `axis` of `Tensor` x.
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  /**
+   * A 1-D Tensor. Has the same type as x that contains the index of each
+   * value of x in the output y.
+   */
+  public Output<V> idx() {
+    return idx;
+  }
+  
+  private Output<T> y;
+  private Output<V> idx;
+  
+  private UniqueV2(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+    idx = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/UniqueWithCounts.java java-ops/org/tensorflow/op/core/UniqueWithCounts.java
--- java/org/tensorflow/op/core/UniqueWithCounts.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/UniqueWithCounts.java	2018-10-16 20:18:38.614432113 +0900
@@ -0,0 +1,114 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Finds unique elements in a 1-D tensor.
+ * <p>
+ * This operation returns a tensor `y` containing all of the unique elements of `x`
+ * sorted in the same order that they occur in `x`. This operation also returns a
+ * tensor `idx` the same size as `x` that contains the index of each value of `x`
+ * in the unique output `y`. Finally, it returns a third tensor `count` that
+ * contains the count of each element of `y` in `x`. In other words:
+ * <p>
+ * `y[idx[i]] = x[i] for i in [0, 1,...,rank(x) - 1]`
+ * <p>
+ * For example:
+ * <pre>{@code
+ * # tensor 'x' is [1, 1, 2, 4, 4, 4, 7, 8, 8]
+ * y, idx, count = unique_with_counts(x)
+ * y ==> [1, 2, 4, 7, 8]
+ * idx ==> [0, 0, 1, 2, 2, 2, 3, 4, 4]
+ * count ==> [2, 1, 3, 1, 2]
+ * }</pre>
+ * 
+ * 
+ * @param <T> data type for {@code y()} output
+ * @param <U> data type for {@code idx()} output
+ */
+@Operator
+public final class UniqueWithCounts<T, U extends Number> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new UniqueWithCounts operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 1-D.
+   * @param outIdx 
+   * @return a new instance of UniqueWithCounts
+   */
+  public static <T, U extends Number> UniqueWithCounts<T, U> create(Scope scope, Operand<T> x, Class<U> outIdx) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("UniqueWithCounts", scope.makeOpName("UniqueWithCounts"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.setAttr("out_idx", DataType.fromClass(outIdx));
+    return new UniqueWithCounts<T, U>(opBuilder.build());
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new UniqueWithCounts operation to the graph, using default output types.
+   * 
+   * @param scope current graph scope
+   * @param x 1-D.
+   * @return a new instance of UniqueWithCounts
+   */
+  public static <T> UniqueWithCounts<T, Integer> create(Scope scope, Operand<T> x) {
+    return create(scope, x, Integer.class);
+  }
+  
+  /**
+   * 1-D.
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  /**
+   * 1-D.
+   */
+  public Output<U> idx() {
+    return idx;
+  }
+  
+  /**
+   * 1-D.
+   */
+  public Output<U> count() {
+    return count;
+  }
+  
+  private Output<T> y;
+  private Output<U> idx;
+  private Output<U> count;
+  
+  private UniqueWithCounts(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+    idx = operation.output(outputIdx++);
+    count = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/UniqueWithCountsV2.java java-ops/org/tensorflow/op/core/UniqueWithCountsV2.java
--- java/org/tensorflow/op/core/UniqueWithCountsV2.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/UniqueWithCountsV2.java	2018-10-16 20:18:38.616432111 +0900
@@ -0,0 +1,146 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Finds unique elements along an axis of a tensor.
+ * <p>
+ * This operation either returns a tensor `y` containing unique elements
+ * along the `axis` of a tensor. The returned unique elements is sorted
+ * in the same order as they occur along `axis` in `x`.
+ * This operation also returns a tensor `idx` and a tensor `count`
+ * that are the same size as the number of the elements in `x` along the
+ * `axis` dimension. The `idx` contains the index in the unique output `y`
+ * and the `count` contains the count in the unique output `y`.
+ * In other words, for an `1-D` tensor `x` with `axis = None:
+ * <p>
+ * `y[idx[i]] = x[i] for i in [0, 1,...,rank(x) - 1]`
+ * <p>
+ * For example:
+ * <pre>{@code
+ * # tensor 'x' is [1, 1, 2, 4, 4, 4, 7, 8, 8]
+ * y, idx, count = unique_with_counts(x)
+ * y ==> [1, 2, 4, 7, 8]
+ * idx ==> [0, 0, 1, 2, 2, 2, 3, 4, 4]
+ * count ==> [2, 1, 3, 1, 2]
+ * }</pre>
+ * For an `2-D` tensor `x` with `axis = 0`:
+ * <pre>{@code
+ * # tensor 'x' is [[1, 0, 0],
+ * #                [1, 0, 0],
+ * #                [2, 0, 0]]
+ * y, idx, count = unique_with_counts(x, axis=0)
+ * y ==> [[1, 0, 0],
+ *        [2, 0, 0]]
+ * idx ==> [0, 0, 1]
+ * count ==> [2, 1]
+ * }</pre>
+ * For an `2-D` tensor `x` with `axis = 1`:
+ * <pre>{@code
+ * # tensor 'x' is [[1, 0, 0],
+ * #                [1, 0, 0],
+ * #                [2, 0, 0]]
+ * y, idx, count = unique_with_counts(x, axis=1)
+ * y ==> [[1, 0],
+ *        [1, 0],
+ *        [2, 0]]
+ * idx ==> [0, 1, 1]
+ * count ==> [1, 2]
+ * }</pre>
+ * 
+ * 
+ * @param <T> data type for {@code y()} output
+ * @param <V> data type for {@code idx()} output
+ */
+@Operator
+public final class UniqueWithCountsV2<T, V extends Number> extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new UniqueWithCountsV2 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x A `Tensor`.
+   * @param axis A `Tensor` of type `int32` (default: None). The axis of the Tensor to
+   * find the unique elements.
+   * @param outIdx 
+   * @return a new instance of UniqueWithCountsV2
+   */
+  public static <T, V extends Number, U extends Number> UniqueWithCountsV2<T, V> create(Scope scope, Operand<T> x, Operand<U> axis, Class<V> outIdx) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("UniqueWithCountsV2", scope.makeOpName("UniqueWithCountsV2"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(axis.asOutput());
+    opBuilder.setAttr("out_idx", DataType.fromClass(outIdx));
+    return new UniqueWithCountsV2<T, V>(opBuilder.build());
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new UniqueWithCountsV2 operation to the graph, using default output types.
+   * 
+   * @param scope current graph scope
+   * @param x A `Tensor`.
+   * @param axis A `Tensor` of type `int32` (default: None). The axis of the Tensor to
+   * find the unique elements.
+   * @return a new instance of UniqueWithCountsV2
+   */
+  public static <T, U extends Number> UniqueWithCountsV2<T, Integer> create(Scope scope, Operand<T> x, Operand<U> axis) {
+    return create(scope, x, axis, Integer.class);
+  }
+  
+  /**
+   * A `Tensor`. Unique elements along the `axis` of `Tensor` x.
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  /**
+   * A 1-D Tensor. Has the same type as x that contains the index of each
+   * value of x in the output y.
+   */
+  public Output<V> idx() {
+    return idx;
+  }
+  
+  /**
+   * A 1-D Tensor. The count of each value of x in the output y.
+   */
+  public Output<V> count() {
+    return count;
+  }
+  
+  private Output<T> y;
+  private Output<V> idx;
+  private Output<V> count;
+  
+  private UniqueWithCountsV2(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+    idx = operation.output(outputIdx++);
+    count = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/UnravelIndex.java java-ops/org/tensorflow/op/core/UnravelIndex.java
--- java/org/tensorflow/op/core/UnravelIndex.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/UnravelIndex.java	2018-10-16 20:18:38.617432111 +0900
@@ -0,0 +1,79 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Converts a flat index or array of flat indices into a tuple of
+ * <p>
+ * coordinate arrays.
+ * <p>
+ * @compatibility(numpy)
+ * Equivalent to np.unravel_index
+ * @end_compatibility
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class UnravelIndex<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new UnravelIndex operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param indices An 0-D or 1-D `int` Tensor whose elements are indices into the
+   * flattened version of an array of dimensions dims.
+   * @param dims An 1-D `int` Tensor. The shape of the array to use for unraveling
+   * indices.
+   * @return a new instance of UnravelIndex
+   */
+  public static <T extends Number> UnravelIndex<T> create(Scope scope, Operand<T> indices, Operand<T> dims) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("UnravelIndex", scope.makeOpName("UnravelIndex"));
+    opBuilder.addInput(indices.asOutput());
+    opBuilder.addInput(dims.asOutput());
+    return new UnravelIndex<T>(opBuilder.build());
+  }
+  
+  /**
+   * An 2-D (or 1-D if indices is 0-D) tensor where each row has the
+   * same shape as the indices array.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private UnravelIndex(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/UnsortedSegmentMax.java java-ops/org/tensorflow/op/core/UnsortedSegmentMax.java
--- java/org/tensorflow/op/core/UnsortedSegmentMax.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/UnsortedSegmentMax.java	2018-10-16 20:18:38.617432111 +0900
@@ -0,0 +1,100 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the maximum along segments of a tensor.
+ * <p>
+ * Read
+ * [the section on segmentation](https://tensorflow.org/api_guides/python/math_ops#Segmentation)
+ * for an explanation of segments.
+ * <p>
+ * This operator is similar to the unsorted segment sum operator found
+ * [(here)](../../../api_docs/python/math_ops.md#UnsortedSegmentSum).
+ * Instead of computing the sum over segments, it computes the maximum such that:
+ * <p>
+ * \\(output_i = \max_{j...} data[j...]\\) where max is over tuples `j...` such
+ * that `segment_ids[j...] == i`.
+ * <p>
+ * If the maximum is empty for a given segment ID `i`, it outputs the smallest
+ * possible value for the specific numeric type,
+ * `output[i] = numeric_limits<T>::lowest()`.
+ * <p>
+ * If the given segment ID `i` is negative, then the corresponding value is
+ * dropped, and will not be included in the result.
+ * <p>
+ * <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
+ * <img style="width:100%" src="https://www.tensorflow.org/images/UnsortedSegmentMax.png" alt>
+ * </div>
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class UnsortedSegmentMax<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new UnsortedSegmentMax operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param data 
+   * @param segmentIds A tensor whose shape is a prefix of `data.shape`.END
+   *   }
+   *   out_arg {
+   *     name: "output"
+   *     description: <<END
+   * Has same shape as data, except for the first `segment_ids.rank`
+   * dimensions, which are replaced with a single dimension which has size
+   * `num_segments`.
+   * @param numSegments 
+   * @return a new instance of UnsortedSegmentMax
+   */
+  public static <T extends Number, U extends Number, V extends Number> UnsortedSegmentMax<T> create(Scope scope, Operand<T> data, Operand<U> segmentIds, Operand<V> numSegments) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("UnsortedSegmentMax", scope.makeOpName("UnsortedSegmentMax"));
+    opBuilder.addInput(data.asOutput());
+    opBuilder.addInput(segmentIds.asOutput());
+    opBuilder.addInput(numSegments.asOutput());
+    return new UnsortedSegmentMax<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private UnsortedSegmentMax(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/UnsortedSegmentMin.java java-ops/org/tensorflow/op/core/UnsortedSegmentMin.java
--- java/org/tensorflow/op/core/UnsortedSegmentMin.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/UnsortedSegmentMin.java	2018-10-16 20:18:38.618432110 +0900
@@ -0,0 +1,92 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the minimum along segments of a tensor.
+ * <p>
+ * Read
+ * [the section on segmentation](https://tensorflow.org/api_guides/python/math_ops#segmentation)
+ * for an explanation of segments.
+ * <p>
+ * This operator is similar to the unsorted segment sum operator found
+ * [(here)](../../../api_docs/python/math_ops.md#UnsortedSegmentSum).
+ * Instead of computing the sum over segments, it computes the minimum such that:
+ * <p>
+ * \\(output_i = \min_{j...} data_[j...]\\) where min is over tuples `j...` such
+ * that `segment_ids[j...] == i`.
+ * <p>
+ * If the minimum is empty for a given segment ID `i`, it outputs the largest
+ * possible value for the specific numeric type,
+ * `output[i] = numeric_limits<T>::max()`.
+ * <p>
+ * If the given segment ID `i` is negative, then the corresponding value is
+ * dropped, and will not be included in the result.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class UnsortedSegmentMin<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new UnsortedSegmentMin operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param data 
+   * @param segmentIds A tensor whose shape is a prefix of `data.shape`.
+   * @param numSegments 
+   * @return a new instance of UnsortedSegmentMin
+   */
+  public static <T extends Number, U extends Number, V extends Number> UnsortedSegmentMin<T> create(Scope scope, Operand<T> data, Operand<U> segmentIds, Operand<V> numSegments) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("UnsortedSegmentMin", scope.makeOpName("UnsortedSegmentMin"));
+    opBuilder.addInput(data.asOutput());
+    opBuilder.addInput(segmentIds.asOutput());
+    opBuilder.addInput(numSegments.asOutput());
+    return new UnsortedSegmentMin<T>(opBuilder.build());
+  }
+  
+  /**
+   * Has same shape as data, except for the first `segment_ids.rank`
+   * dimensions, which are replaced with a single dimension which has size
+   * `num_segments`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private UnsortedSegmentMin(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/UnsortedSegmentProd.java java-ops/org/tensorflow/op/core/UnsortedSegmentProd.java
--- java/org/tensorflow/op/core/UnsortedSegmentProd.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/UnsortedSegmentProd.java	2018-10-16 20:18:38.619432109 +0900
@@ -0,0 +1,91 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the product along segments of a tensor.
+ * <p>
+ * Read
+ * [the section on segmentation](https://tensorflow.org/api_guides/python/math_ops#segmentation)
+ * for an explanation of segments.
+ * <p>
+ * This operator is similar to the unsorted segment sum operator found
+ * [(here)](../../../api_docs/python/math_ops.md#UnsortedSegmentSum).
+ * Instead of computing the sum over segments, it computes the product of all
+ * entries belonging to a segment such that:
+ * <p>
+ * \\(output_i = \prod_{j...} data[j...]\\) where the product is over tuples
+ * `j...` such that `segment_ids[j...] == i`.
+ * <p>
+ * If there is no entry for a given segment ID `i`, it outputs 1.
+ * <p>
+ * If the given segment ID `i` is negative, then the corresponding value is
+ * dropped, and will not be included in the result.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class UnsortedSegmentProd<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new UnsortedSegmentProd operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param data 
+   * @param segmentIds A tensor whose shape is a prefix of `data.shape`.
+   * @param numSegments 
+   * @return a new instance of UnsortedSegmentProd
+   */
+  public static <T, U extends Number, V extends Number> UnsortedSegmentProd<T> create(Scope scope, Operand<T> data, Operand<U> segmentIds, Operand<V> numSegments) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("UnsortedSegmentProd", scope.makeOpName("UnsortedSegmentProd"));
+    opBuilder.addInput(data.asOutput());
+    opBuilder.addInput(segmentIds.asOutput());
+    opBuilder.addInput(numSegments.asOutput());
+    return new UnsortedSegmentProd<T>(opBuilder.build());
+  }
+  
+  /**
+   * Has same shape as data, except for the first `segment_ids.rank`
+   * dimensions, which are replaced with a single dimension which has size
+   * `num_segments`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private UnsortedSegmentProd(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/UnsortedSegmentSum.java java-ops/org/tensorflow/op/core/UnsortedSegmentSum.java
--- java/org/tensorflow/op/core/UnsortedSegmentSum.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/UnsortedSegmentSum.java	2018-10-16 20:18:38.619432109 +0900
@@ -0,0 +1,94 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Computes the sum along segments of a tensor.
+ * <p>
+ * Read
+ * [the section on segmentation](https://tensorflow.org/api_guides/python/math_ops#Segmentation)
+ * for an explanation of segments.
+ * <p>
+ * Computes a tensor such that
+ * \\(output[i] = \sum_{j...} data[j...]\\) where the sum is over tuples `j...` such
+ * that `segment_ids[j...] == i`.  Unlike `SegmentSum`, `segment_ids`
+ * need not be sorted and need not cover all values in the full
+ * range of valid values.
+ * <p>
+ * If the sum is empty for a given segment ID `i`, `output[i] = 0`.
+ * If the given segment ID `i` is negative, the value is dropped and will not be
+ * added to the sum of the segment.
+ * <p>
+ * `num_segments` should equal the number of distinct segment IDs.
+ * <p>
+ * <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
+ * <img style="width:100%" src="https://www.tensorflow.org/images/UnsortedSegmentSum.png" alt>
+ * </div>
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class UnsortedSegmentSum<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new UnsortedSegmentSum operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param data 
+   * @param segmentIds A tensor whose shape is a prefix of `data.shape`.
+   * @param numSegments 
+   * @return a new instance of UnsortedSegmentSum
+   */
+  public static <T, U extends Number, V extends Number> UnsortedSegmentSum<T> create(Scope scope, Operand<T> data, Operand<U> segmentIds, Operand<V> numSegments) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("UnsortedSegmentSum", scope.makeOpName("UnsortedSegmentSum"));
+    opBuilder.addInput(data.asOutput());
+    opBuilder.addInput(segmentIds.asOutput());
+    opBuilder.addInput(numSegments.asOutput());
+    return new UnsortedSegmentSum<T>(opBuilder.build());
+  }
+  
+  /**
+   * Has same shape as data, except for the first `segment_ids.rank`
+   * dimensions, which are replaced with a single dimension which has size
+   * `num_segments`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private UnsortedSegmentSum(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Unstack.java java-ops/org/tensorflow/op/core/Unstack.java
--- java/org/tensorflow/op/core/Unstack.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Unstack.java	2018-10-16 20:18:38.616432111 +0900
@@ -0,0 +1,126 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.Iterator;
+import java.util.List;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Unpacks a given dimension of a rank-`R` tensor into `num` rank-`(R-1)` tensors.
+ * <p>
+ * Unpacks `num` tensors from `value` by chipping it along the `axis` dimension.
+ * For example, given a tensor of shape `(A, B, C, D)`;
+ * <p>
+ * If `axis == 0` then the i'th tensor in `output` is the slice `value[i, :, :, :]`
+ *   and each tensor in `output` will have shape `(B, C, D)`. (Note that the
+ *   dimension unpacked along is gone, unlike `split`).
+ * <p>
+ * If `axis == 1` then the i'th tensor in `output` is the slice `value[:, i, :, :]`
+ *   and each tensor in `output` will have shape `(A, C, D)`.
+ * Etc.
+ * <p>
+ * This is the opposite of `pack`.
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class Unstack<T> extends PrimitiveOp implements Iterable<Operand<T>> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Unstack}
+   */
+  public static class Options {
+    
+    /**
+     * @param axis Dimension along which to unpack.  Negative values wrap around, so the
+     * valid range is `[-R, R)`.
+     */
+    public Options axis(Long axis) {
+      this.axis = axis;
+      return this;
+    }
+    
+    private Long axis;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Unstack operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param value 1-D or higher, with `axis` dimension size equal to `num`.
+   * @param num 
+   * @param options carries optional attributes values
+   * @return a new instance of Unstack
+   */
+  public static <T> Unstack<T> create(Scope scope, Operand<T> value, Long num, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Unpack", scope.makeOpName("Unstack"));
+    opBuilder.addInput(value.asOutput());
+    opBuilder.setAttr("num", num);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.axis != null) {
+          opBuilder.setAttr("axis", opts.axis);
+        }
+      }
+    }
+    return new Unstack<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param axis Dimension along which to unpack.  Negative values wrap around, so the
+   * valid range is `[-R, R)`.
+   */
+  public static Options axis(Long axis) {
+    return new Options().axis(axis);
+  }
+  
+  /**
+   * The list of tensors unpacked from `value`.
+   */
+  public List<Output<T>> output() {
+    return output;
+  }
+  
+  @Override
+  @SuppressWarnings({"rawtypes", "unchecked"})
+  public Iterator<Operand<T>> iterator() {
+    return (Iterator) output.iterator();
+  }
+  
+  private List<Output<T>> output;
+  
+  @SuppressWarnings("unchecked")
+  private Unstack(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    int outputLength = operation.outputListLength("output");
+    output = Arrays.asList((Output<T>[])operation.outputList(outputIdx, outputLength));
+    outputIdx += outputLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/Unstage.java java-ops/org/tensorflow/op/core/Unstage.java
--- java/org/tensorflow/op/core/Unstage.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Unstage.java	2018-10-16 20:18:38.620432109 +0900
@@ -0,0 +1,170 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.Arrays;
+import java.util.Iterator;
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Op is similar to a lightweight Dequeue.
+ * <p>
+ * The basic functionality is similar to dequeue with many fewer
+ * capabilities and options.  This Op is optimized for performance.
+ */
+@Operator
+public final class Unstage extends PrimitiveOp implements Iterable<Operand<Object>> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Unstage}
+   */
+  public static class Options {
+    
+    /**
+     * @param capacity 
+     */
+    public Options capacity(Long capacity) {
+      this.capacity = capacity;
+      return this;
+    }
+    
+    /**
+     * @param memoryLimit 
+     */
+    public Options memoryLimit(Long memoryLimit) {
+      this.memoryLimit = memoryLimit;
+      return this;
+    }
+    
+    /**
+     * @param container 
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName 
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private Long capacity;
+    private Long memoryLimit;
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Unstage operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param dtypes 
+   * @param options carries optional attributes values
+   * @return a new instance of Unstage
+   */
+  public static Unstage create(Scope scope, List<Class<?>> dtypes, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Unstage", scope.makeOpName("Unstage"));
+    DataType[] dtypesArray = new DataType[dtypes.size()];
+    for (int i = 0; i < dtypesArray.length; ++i) {
+      dtypesArray[i] = DataType.fromClass(dtypes.get(i));
+    }
+    opBuilder.setAttr("dtypes", dtypesArray);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.capacity != null) {
+          opBuilder.setAttr("capacity", opts.capacity);
+        }
+        if (opts.memoryLimit != null) {
+          opBuilder.setAttr("memory_limit", opts.memoryLimit);
+        }
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new Unstage(opBuilder.build());
+  }
+  
+  /**
+   * @param capacity 
+   */
+  public static Options capacity(Long capacity) {
+    return new Options().capacity(capacity);
+  }
+  
+  /**
+   * @param memoryLimit 
+   */
+  public static Options memoryLimit(Long memoryLimit) {
+    return new Options().memoryLimit(memoryLimit);
+  }
+  
+  /**
+   * @param container 
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName 
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   */
+  public List<Output<?>> values() {
+    return values;
+  }
+  
+  @Override
+  @SuppressWarnings({"rawtypes", "unchecked"})
+  public Iterator<Operand<Object>> iterator() {
+    return (Iterator) values.iterator();
+  }
+  
+  private List<Output<?>> values;
+  
+  private Unstage(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    int valuesLength = operation.outputListLength("values");
+    values = Arrays.asList(operation.outputList(outputIdx, valuesLength));
+    outputIdx += valuesLength;
+  }
+}
diff -ruN java/org/tensorflow/op/core/UpperBound.java java-ops/org/tensorflow/op/core/UpperBound.java
--- java/org/tensorflow/op/core/UpperBound.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/UpperBound.java	2018-10-16 20:18:38.621432108 +0900
@@ -0,0 +1,105 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * Applies upper_bound(sorted_search_values, values) along each row.
+ * <p>
+ * Each set of rows with the same index in (sorted_inputs, values) is treated
+ * independently.  The resulting row is the equivalent of calling
+ * `np.searchsorted(sorted_inputs, values, side='right')`.
+ * <p>
+ * The result is not a global index to the entire 
+ * `Tensor`, but rather just the index in the last dimension.
+ * <p>
+ * A 2-D example:
+ *   sorted_sequence = [[0, 3, 9, 9, 10],
+ *                      [1, 2, 3, 4, 5]]
+ *   values = [[2, 4, 9],
+ *             [0, 2, 6]]
+ * <p>
+ *   result = UpperBound(sorted_sequence, values)
+ * <p>
+ *   result == [[1, 2, 4],
+ *              [0, 2, 5]]
+ * 
+ * @param <U> data type for {@code output()} output
+ */
+public final class UpperBound<U extends Number> extends PrimitiveOp implements Operand<U> {
+  
+  /**
+   * Factory method to create a class to wrap a new UpperBound operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param sortedInputs 2-D Tensor where each row is ordered.
+   * @param values 2-D Tensor with the same numbers of rows as `sorted_search_values`. Contains
+   * the values that will be searched for in `sorted_search_values`.
+   * @param outType 
+   * @return a new instance of UpperBound
+   */
+  public static <U extends Number, T> UpperBound<U> create(Scope scope, Operand<T> sortedInputs, Operand<T> values, Class<U> outType) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("UpperBound", scope.makeOpName("UpperBound"));
+    opBuilder.addInput(sortedInputs.asOutput());
+    opBuilder.addInput(values.asOutput());
+    opBuilder.setAttr("out_type", DataType.fromClass(outType));
+    return new UpperBound<U>(opBuilder.build());
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new UpperBound operation to the graph, using default output types.
+   * 
+   * @param scope current graph scope
+   * @param sortedInputs 2-D Tensor where each row is ordered.
+   * @param values 2-D Tensor with the same numbers of rows as `sorted_search_values`. Contains
+   * the values that will be searched for in `sorted_search_values`.
+   * @return a new instance of UpperBound
+   */
+  public static <T> UpperBound<Integer> create(Scope scope, Operand<T> sortedInputs, Operand<T> values) {
+    return create(scope, sortedInputs, values, Integer.class);
+  }
+  
+  /**
+   * A `Tensor` with the same shape as `values`.  It contains the last scalar index
+   * into the last dimension where values can be inserted without changing the
+   * ordered property.
+   */
+  public Output<U> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<U> asOutput() {
+    return output;
+  }
+  
+  private Output<U> output;
+  
+  private UpperBound(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/VarHandleOp.java java-ops/org/tensorflow/op/core/VarHandleOp.java
--- java/org/tensorflow/op/core/VarHandleOp.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/VarHandleOp.java	2018-10-16 20:18:38.621432108 +0900
@@ -0,0 +1,124 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Creates a handle to a Variable resource.
+ */
+@Operator
+public final class VarHandleOp extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.VarHandleOp}
+   */
+  public static class Options {
+    
+    /**
+     * @param container the container this variable is placed in.
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName the name by which this variable is referred to.
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new VarHandleOp operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param dtype the type of this variable. Must agree with the dtypes
+   * of all ops using this variable.
+   * @param shape The (possibly partially specified) shape of this variable.
+   * @param options carries optional attributes values
+   * @return a new instance of VarHandleOp
+   */
+  public static <T> VarHandleOp create(Scope scope, Class<T> dtype, Shape shape, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("VarHandleOp", scope.makeOpName("VarHandleOp"));
+    opBuilder.setAttr("dtype", DataType.fromClass(dtype));
+    opBuilder.setAttr("shape", shape);
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new VarHandleOp(opBuilder.build());
+  }
+  
+  /**
+   * @param container the container this variable is placed in.
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName the name by which this variable is referred to.
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   */
+  public Output<?> resource() {
+    return resource;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) resource;
+  }
+  
+  private Output<?> resource;
+  
+  private VarHandleOp(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    resource = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Variable.java java-ops/org/tensorflow/op/core/Variable.java
--- java/org/tensorflow/op/core/Variable.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Variable.java	2018-10-16 20:18:38.622432107 +0900
@@ -0,0 +1,133 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Holds state in the form of a tensor that persists across steps.
+ * <p>
+ * Outputs a ref to the tensor state so it may be read or modified.
+ * TODO(zhifengc/mrry): Adds a pointer to a more detail document
+ * about sharing states in tensorflow.
+ * 
+ * @param <T> data type for {@code ref()} output
+ */
+@Operator
+public final class Variable<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.Variable}
+   */
+  public static class Options {
+    
+    /**
+     * @param container If non-empty, this variable is placed in the given container.
+     * Otherwise, a default container is used.
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName If non-empty, this variable is named in the given bucket
+     * with this shared_name. Otherwise, the node name is used instead.
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new Variable operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param shape The shape of the variable tensor.
+   * @param dtype The type of elements in the variable tensor.
+   * @param options carries optional attributes values
+   * @return a new instance of Variable
+   */
+  public static <T> Variable<T> create(Scope scope, Shape shape, Class<T> dtype, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("VariableV2", scope.makeOpName("Variable"));
+    opBuilder.setAttr("shape", shape);
+    opBuilder.setAttr("dtype", DataType.fromClass(dtype));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new Variable<T>(opBuilder.build());
+  }
+  
+  /**
+   * @param container If non-empty, this variable is placed in the given container.
+   * Otherwise, a default container is used.
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName If non-empty, this variable is named in the given bucket
+   * with this shared_name. Otherwise, the node name is used instead.
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   * A reference to the variable tensor.
+   */
+  public Output<T> ref() {
+    return ref;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return ref;
+  }
+  
+  private Output<T> ref;
+  
+  private Variable(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    ref = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/VariableShape.java java-ops/org/tensorflow/op/core/VariableShape.java
--- java/org/tensorflow/op/core/VariableShape.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/VariableShape.java	2018-10-16 20:18:38.621432108 +0900
@@ -0,0 +1,90 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns the shape of the variable pointed to by `resource`.
+ * <p>
+ * This operation returns a 1-D integer tensor representing the shape of `input`.
+ * <p>
+ * For example:
+ * <pre>{@code
+ * # 't' is [[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]]
+ * shape(t) ==> [2, 2, 3]
+ * }</pre>
+ * 
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class VariableShape<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new VariableShape operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @param outType 
+   * @return a new instance of VariableShape
+   */
+  public static <T extends Number> VariableShape<T> create(Scope scope, Operand<?> input, Class<T> outType) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("VariableShape", scope.makeOpName("VariableShape"));
+    opBuilder.addInput(input.asOutput());
+    opBuilder.setAttr("out_type", DataType.fromClass(outType));
+    return new VariableShape<T>(opBuilder.build());
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new VariableShape operation to the graph, using default output types.
+   * 
+   * @param scope current graph scope
+   * @param input 
+   * @return a new instance of VariableShape
+   */
+  public static VariableShape<Integer> create(Scope scope, Operand<?> input) {
+    return create(scope, input, Integer.class);
+  }
+  
+  /**
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private VariableShape(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/VarIsInitializedOp.java java-ops/org/tensorflow/op/core/VarIsInitializedOp.java
--- java/org/tensorflow/op/core/VarIsInitializedOp.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/VarIsInitializedOp.java	2018-10-16 20:18:38.621432108 +0900
@@ -0,0 +1,67 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Checks whether a resource handle-based variable has been initialized.
+ */
+@Operator
+public final class VarIsInitializedOp extends PrimitiveOp implements Operand<Boolean> {
+  
+  /**
+   * Factory method to create a class to wrap a new VarIsInitializedOp operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param resource the input resource handle.
+   * @return a new instance of VarIsInitializedOp
+   */
+  public static VarIsInitializedOp create(Scope scope, Operand<?> resource) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("VarIsInitializedOp", scope.makeOpName("VarIsInitializedOp"));
+    opBuilder.addInput(resource.asOutput());
+    return new VarIsInitializedOp(opBuilder.build());
+  }
+  
+  /**
+   * a scalar boolean which is true if the variable has been
+   * initialized.
+   */
+  public Output<Boolean> isInitialized() {
+    return isInitialized;
+  }
+  
+  @Override
+  public Output<Boolean> asOutput() {
+    return isInitialized;
+  }
+  
+  private Output<Boolean> isInitialized;
+  
+  private VarIsInitializedOp(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    isInitialized = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Where3.java java-ops/org/tensorflow/op/core/Where3.java
--- java/org/tensorflow/op/core/Where3.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Where3.java	2018-10-16 20:18:38.505432189 +0900
@@ -0,0 +1,113 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Selects elements from `x` or `y`, depending on `condition`.
+ * <p>
+ * The `x`, and `y` tensors must all have the same shape, and the
+ * output will also have that shape.
+ * <p>
+ * The `condition` tensor must be a scalar if `x` and `y` are scalars.
+ * If `x` and `y` are vectors or higher rank, then `condition` must be either a
+ * scalar, a vector with size matching the first dimension of `x`, or must have
+ * the same shape as `x`.
+ * <p>
+ * The `condition` tensor acts as a mask that chooses, based on the value at each
+ * element, whether the corresponding element / row in the output should be
+ * taken from `x` (if true) or `y` (if false).
+ * <p>
+ * If `condition` is a vector and `x` and `y` are higher rank matrices, then
+ * it chooses which row (outer dimension) to copy from `x` and `y`.
+ * If `condition` has the same shape as `x` and `y`, then it chooses which
+ * element to copy from `x` and `y`.
+ * <p>
+ * For example:
+ * <pre>{@code
+ * # 'condition' tensor is [[True,  False]
+ * #                        [False, True]]
+ * # 't' is [[1, 2],
+ * #         [3, 4]]
+ * # 'e' is [[5, 6],
+ * #         [7, 8]]
+ * select(condition, t, e)  # => [[1, 6], [7, 4]]
+ * 
+ * 
+ * # 'condition' tensor is [True, False]
+ * # 't' is [[1, 2],
+ * #         [3, 4]]
+ * # 'e' is [[5, 6],
+ * #         [7, 8]]
+ * select(condition, t, e) ==> [[1, 2],
+ *                              [7, 8]]
+ * 
+ * }</pre>
+ * 
+ * 
+ * @param <T> data type for {@code output()} output
+ */
+@Operator
+public final class Where3<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Where3 operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param condition 
+   * @param x = A `Tensor` which may have the same shape as `condition`.
+   * If `condition` is rank 1, `x` may have higher rank,
+   * but its first dimension must match the size of `condition`.
+   * @param y = A `Tensor` with the same type and shape as `x`.
+   * @return a new instance of Where3
+   */
+  public static <T> Where3<T> create(Scope scope, Operand<Boolean> condition, Operand<T> x, Operand<T> y) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Select", scope.makeOpName("Where3"));
+    opBuilder.addInput(condition.asOutput());
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(y.asOutput());
+    return new Where3<T>(opBuilder.build());
+  }
+  
+  /**
+   * = A `Tensor` with the same type and shape as `x` and `y`.
+   */
+  public Output<T> output() {
+    return output;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return output;
+  }
+  
+  private Output<T> output;
+  
+  private Where3(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    output = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Where.java java-ops/org/tensorflow/op/core/Where.java
--- java/org/tensorflow/op/core/Where.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Where.java	2018-10-16 20:18:38.622432107 +0900
@@ -0,0 +1,125 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns locations of nonzero / true values in a tensor.
+ * <p>
+ * This operation returns the coordinates of true elements in `condition`. The
+ * coordinates are returned in a 2-D tensor where the first dimension (rows)
+ * represents the number of true elements, and the second dimension (columns)
+ * represents the coordinates of the true elements. Keep in mind, the shape of
+ * the output tensor can vary depending on how many true values there are in
+ * `condition`. Indices are output in row-major order.
+ * <p>
+ * For example:
+ * <pre>{@code
+ * # 'input' tensor is [[True, False]
+ * #                    [True, False]]
+ * # 'input' has two true values, so output has two coordinates.
+ * # 'input' has rank of 2, so coordinates have two indices.
+ * where(input) ==> [[0, 0],
+ *                   [1, 0]]
+ * 
+ * # `condition` tensor is [[[True, False]
+ * #                     [True, False]]
+ * #                    [[False, True]
+ * #                     [False, True]]
+ * #                    [[False, False]
+ * #                     [False, True]]]
+ * # 'input' has 5 true values, so output has 5 coordinates.
+ * # 'input' has rank of 3, so coordinates have three indices.
+ * where(input) ==> [[0, 0, 0],
+ *                   [0, 1, 0],
+ *                   [1, 0, 1],
+ *                   [1, 1, 1],
+ *                   [2, 1, 1]]
+ * 
+ * # `condition` tensor is [[[1.5,  0.0]
+ * #                     [-0.5, 0.0]]
+ * #                    [[0.0,  0.25]
+ * #                     [0.0,  0.75]]
+ * #                    [[0.0,  0.0]
+ * #                     [0.0,  0.01]]]
+ * # 'input' has 5 nonzero values, so output has 5 coordinates.
+ * # 'input' has rank of 3, so coordinates have three indices.
+ * where(input) ==> [[0, 0, 0],
+ *                   [0, 1, 0],
+ *                   [1, 0, 1],
+ *                   [1, 1, 1],
+ *                   [2, 1, 1]]
+ * 
+ * # `condition` tensor is [[[1.5 + 0.0j, 0.0  + 0.0j]
+ * #                     [0.0 + 0.5j, 0.0  + 0.0j]]
+ * #                    [[0.0 + 0.0j, 0.25 + 1.5j]
+ * #                     [0.0 + 0.0j, 0.75 + 0.0j]]
+ * #                    [[0.0 + 0.0j, 0.0  + 0.0j]
+ * #                     [0.0 + 0.0j, 0.01 + 0.0j]]]
+ * # 'input' has 5 nonzero magnitude values, so output has 5 coordinates.
+ * # 'input' has rank of 3, so coordinates have three indices.
+ * where(input) ==> [[0, 0, 0],
+ *                   [0, 1, 0],
+ *                   [1, 0, 1],
+ *                   [1, 1, 1],
+ *                   [2, 1, 1]]
+ * }</pre>
+ * 
+ */
+@Operator
+public final class Where extends PrimitiveOp implements Operand<Long> {
+  
+  /**
+   * Factory method to create a class to wrap a new Where operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param condition 
+   * @return a new instance of Where
+   */
+  public static <T> Where create(Scope scope, Operand<T> condition) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Where", scope.makeOpName("Where"));
+    opBuilder.addInput(condition.asOutput());
+    return new Where(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<Long> index() {
+    return index;
+  }
+  
+  @Override
+  public Output<Long> asOutput() {
+    return index;
+  }
+  
+  private Output<Long> index;
+  
+  private Where(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    index = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/WholeFileReader.java java-ops/org/tensorflow/op/core/WholeFileReader.java
--- java/org/tensorflow/op/core/WholeFileReader.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/WholeFileReader.java	2018-10-16 20:18:38.622432107 +0900
@@ -0,0 +1,125 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * A Reader that outputs the entire contents of a file as a value.
+ * <p>
+ * To use, enqueue filenames in a Queue.  The output of ReaderRead will
+ * be a filename (key) and the contents of that file (value).
+ */
+@Operator
+public final class WholeFileReader extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.WholeFileReader}
+   */
+  public static class Options {
+    
+    /**
+     * @param container If non-empty, this reader is placed in the given container.
+     * Otherwise, a default container is used.
+     */
+    public Options container(String container) {
+      this.container = container;
+      return this;
+    }
+    
+    /**
+     * @param sharedName If non-empty, this reader is named in the given bucket
+     * with this shared_name. Otherwise, the node name is used instead.
+     */
+    public Options sharedName(String sharedName) {
+      this.sharedName = sharedName;
+      return this;
+    }
+    
+    private String container;
+    private String sharedName;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new WholeFileReader operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param options carries optional attributes values
+   * @return a new instance of WholeFileReader
+   */
+  public static WholeFileReader create(Scope scope, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("WholeFileReaderV2", scope.makeOpName("WholeFileReader"));
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.container != null) {
+          opBuilder.setAttr("container", opts.container);
+        }
+        if (opts.sharedName != null) {
+          opBuilder.setAttr("shared_name", opts.sharedName);
+        }
+      }
+    }
+    return new WholeFileReader(opBuilder.build());
+  }
+  
+  /**
+   * @param container If non-empty, this reader is placed in the given container.
+   * Otherwise, a default container is used.
+   */
+  public static Options container(String container) {
+    return new Options().container(container);
+  }
+  
+  /**
+   * @param sharedName If non-empty, this reader is named in the given bucket
+   * with this shared_name. Otherwise, the node name is used instead.
+   */
+  public static Options sharedName(String sharedName) {
+    return new Options().sharedName(sharedName);
+  }
+  
+  /**
+   * The handle to reference the Reader.
+   */
+  public Output<?> readerHandle() {
+    return readerHandle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) readerHandle;
+  }
+  
+  private Output<?> readerHandle;
+  
+  private WholeFileReader(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    readerHandle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/WindowDataset.java java-ops/org/tensorflow/op/core/WindowDataset.java
--- java/org/tensorflow/op/core/WindowDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/WindowDataset.java	2018-10-16 20:18:38.623432107 +0900
@@ -0,0 +1,90 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ * A dataset that creates window datasets from the input dataset.
+ */
+public final class WindowDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new WindowDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputDataset 
+   * @param size A scalar representing the number of elements to accumulate in a window.
+   * @param shift A scalar representing the steps moving the sliding window forward in one
+   * iteration. It must be positive.
+   * @param stride A scalar representing the stride of the input elements of the sliding window.
+   * It must be positive.
+   * @param dropRemainder A scalar representing whether a window should be dropped in case its size is
+   * smaller than desired.
+   * @param outputTypes 
+   * @param outputShapes 
+   * @return a new instance of WindowDataset
+   */
+  public static WindowDataset create(Scope scope, Operand<?> inputDataset, Operand<Long> size, Operand<Long> shift, Operand<Long> stride, Operand<Boolean> dropRemainder, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("WindowDataset", scope.makeOpName("WindowDataset"));
+    opBuilder.addInput(inputDataset.asOutput());
+    opBuilder.addInput(size.asOutput());
+    opBuilder.addInput(shift.asOutput());
+    opBuilder.addInput(stride.asOutput());
+    opBuilder.addInput(dropRemainder.asOutput());
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new WindowDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private WindowDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/WriteAudioSummary.java java-ops/org/tensorflow/op/core/WriteAudioSummary.java
--- java/org/tensorflow/op/core/WriteAudioSummary.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/WriteAudioSummary.java	2018-10-16 20:18:38.623432107 +0900
@@ -0,0 +1,89 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ */
+public final class WriteAudioSummary extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.WriteAudioSummary}
+   */
+  public static class Options {
+    
+    /**
+     * @param maxOutputs 
+     */
+    public Options maxOutputs(Long maxOutputs) {
+      this.maxOutputs = maxOutputs;
+      return this;
+    }
+    
+    private Long maxOutputs;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new WriteAudioSummary operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param writer 
+   * @param step 
+   * @param tag 
+   * @param tensor 
+   * @param sampleRate 
+   * @param options carries optional attributes values
+   * @return a new instance of WriteAudioSummary
+   */
+  public static WriteAudioSummary create(Scope scope, Operand<?> writer, Operand<Long> step, Operand<String> tag, Operand<Float> tensor, Operand<Float> sampleRate, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("WriteAudioSummary", scope.makeOpName("WriteAudioSummary"));
+    opBuilder.addInput(writer.asOutput());
+    opBuilder.addInput(step.asOutput());
+    opBuilder.addInput(tag.asOutput());
+    opBuilder.addInput(tensor.asOutput());
+    opBuilder.addInput(sampleRate.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.maxOutputs != null) {
+          opBuilder.setAttr("max_outputs", opts.maxOutputs);
+        }
+      }
+    }
+    return new WriteAudioSummary(opBuilder.build());
+  }
+  
+  /**
+   * @param maxOutputs 
+   */
+  public static Options maxOutputs(Long maxOutputs) {
+    return new Options().maxOutputs(maxOutputs);
+  }
+  
+  
+  private WriteAudioSummary(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/WriteFile.java java-ops/org/tensorflow/op/core/WriteFile.java
--- java/org/tensorflow/op/core/WriteFile.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/WriteFile.java	2018-10-16 20:18:38.623432107 +0900
@@ -0,0 +1,54 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Writes contents to the file at input filename. Creates file and recursively
+ * <p>
+ * creates directory if not existing.
+ */
+@Operator
+public final class WriteFile extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new WriteFile operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param filename scalar. The name of the file to which we write the contents.
+   * @param contents scalar. The content to be written to the output file.
+   * @return a new instance of WriteFile
+   */
+  public static WriteFile create(Scope scope, Operand<String> filename, Operand<String> contents) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("WriteFile", scope.makeOpName("WriteFile"));
+    opBuilder.addInput(filename.asOutput());
+    opBuilder.addInput(contents.asOutput());
+    return new WriteFile(opBuilder.build());
+  }
+  
+  
+  private WriteFile(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/WriteGraphSummary.java java-ops/org/tensorflow/op/core/WriteGraphSummary.java
--- java/org/tensorflow/op/core/WriteGraphSummary.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/WriteGraphSummary.java	2018-10-16 20:18:38.623432107 +0900
@@ -0,0 +1,51 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ */
+public final class WriteGraphSummary extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new WriteGraphSummary operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param writer 
+   * @param step 
+   * @param tensor 
+   * @return a new instance of WriteGraphSummary
+   */
+  public static WriteGraphSummary create(Scope scope, Operand<?> writer, Operand<Long> step, Operand<String> tensor) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("WriteGraphSummary", scope.makeOpName("WriteGraphSummary"));
+    opBuilder.addInput(writer.asOutput());
+    opBuilder.addInput(step.asOutput());
+    opBuilder.addInput(tensor.asOutput());
+    return new WriteGraphSummary(opBuilder.build());
+  }
+  
+  
+  private WriteGraphSummary(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/WriteHistogramSummary.java java-ops/org/tensorflow/op/core/WriteHistogramSummary.java
--- java/org/tensorflow/op/core/WriteHistogramSummary.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/WriteHistogramSummary.java	2018-10-16 20:18:38.624432106 +0900
@@ -0,0 +1,53 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ */
+public final class WriteHistogramSummary extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new WriteHistogramSummary operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param writer 
+   * @param step 
+   * @param tag 
+   * @param values 
+   * @return a new instance of WriteHistogramSummary
+   */
+  public static <T extends Number> WriteHistogramSummary create(Scope scope, Operand<?> writer, Operand<Long> step, Operand<String> tag, Operand<T> values) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("WriteHistogramSummary", scope.makeOpName("WriteHistogramSummary"));
+    opBuilder.addInput(writer.asOutput());
+    opBuilder.addInput(step.asOutput());
+    opBuilder.addInput(tag.asOutput());
+    opBuilder.addInput(values.asOutput());
+    return new WriteHistogramSummary(opBuilder.build());
+  }
+  
+  
+  private WriteHistogramSummary(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/WriteImageSummary.java java-ops/org/tensorflow/op/core/WriteImageSummary.java
--- java/org/tensorflow/op/core/WriteImageSummary.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/WriteImageSummary.java	2018-10-16 20:18:38.624432106 +0900
@@ -0,0 +1,90 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.types.UInt8;
+
+/**
+ */
+public final class WriteImageSummary extends PrimitiveOp {
+  
+  /**
+   * Optional attributes for {@link org.tensorflow.op.core.WriteImageSummary}
+   */
+  public static class Options {
+    
+    /**
+     * @param maxImages 
+     */
+    public Options maxImages(Long maxImages) {
+      this.maxImages = maxImages;
+      return this;
+    }
+    
+    private Long maxImages;
+    
+    private Options() {
+    }
+  }
+  
+  /**
+   * Factory method to create a class to wrap a new WriteImageSummary operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param writer 
+   * @param step 
+   * @param tag 
+   * @param tensor 
+   * @param badColor 
+   * @param options carries optional attributes values
+   * @return a new instance of WriteImageSummary
+   */
+  public static <T extends Number> WriteImageSummary create(Scope scope, Operand<?> writer, Operand<Long> step, Operand<String> tag, Operand<T> tensor, Operand<UInt8> badColor, Options... options) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("WriteImageSummary", scope.makeOpName("WriteImageSummary"));
+    opBuilder.addInput(writer.asOutput());
+    opBuilder.addInput(step.asOutput());
+    opBuilder.addInput(tag.asOutput());
+    opBuilder.addInput(tensor.asOutput());
+    opBuilder.addInput(badColor.asOutput());
+    if (options != null) {
+      for (Options opts : options) {
+        if (opts.maxImages != null) {
+          opBuilder.setAttr("max_images", opts.maxImages);
+        }
+      }
+    }
+    return new WriteImageSummary(opBuilder.build());
+  }
+  
+  /**
+   * @param maxImages 
+   */
+  public static Options maxImages(Long maxImages) {
+    return new Options().maxImages(maxImages);
+  }
+  
+  
+  private WriteImageSummary(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/WriteScalarSummary.java java-ops/org/tensorflow/op/core/WriteScalarSummary.java
--- java/org/tensorflow/op/core/WriteScalarSummary.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/WriteScalarSummary.java	2018-10-16 20:18:38.624432106 +0900
@@ -0,0 +1,53 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ */
+public final class WriteScalarSummary extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new WriteScalarSummary operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param writer 
+   * @param step 
+   * @param tag 
+   * @param value 
+   * @return a new instance of WriteScalarSummary
+   */
+  public static <T extends Number> WriteScalarSummary create(Scope scope, Operand<?> writer, Operand<Long> step, Operand<String> tag, Operand<T> value) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("WriteScalarSummary", scope.makeOpName("WriteScalarSummary"));
+    opBuilder.addInput(writer.asOutput());
+    opBuilder.addInput(step.asOutput());
+    opBuilder.addInput(tag.asOutput());
+    opBuilder.addInput(value.asOutput());
+    return new WriteScalarSummary(opBuilder.build());
+  }
+  
+  
+  private WriteScalarSummary(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/WriteSummary.java java-ops/org/tensorflow/op/core/WriteSummary.java
--- java/org/tensorflow/op/core/WriteSummary.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/WriteSummary.java	2018-10-16 20:18:38.625432105 +0900
@@ -0,0 +1,55 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+
+/**
+ */
+public final class WriteSummary extends PrimitiveOp {
+  
+  /**
+   * Factory method to create a class to wrap a new WriteSummary operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param writer 
+   * @param step 
+   * @param tensor 
+   * @param tag 
+   * @param summaryMetadata 
+   * @return a new instance of WriteSummary
+   */
+  public static <T> WriteSummary create(Scope scope, Operand<?> writer, Operand<Long> step, Operand<T> tensor, Operand<String> tag, Operand<String> summaryMetadata) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("WriteSummary", scope.makeOpName("WriteSummary"));
+    opBuilder.addInput(writer.asOutput());
+    opBuilder.addInput(step.asOutput());
+    opBuilder.addInput(tensor.asOutput());
+    opBuilder.addInput(tag.asOutput());
+    opBuilder.addInput(summaryMetadata.asOutput());
+    return new WriteSummary(opBuilder.build());
+  }
+  
+  
+  private WriteSummary(Operation operation) {
+    super(operation);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Xdivy.java java-ops/org/tensorflow/op/core/Xdivy.java
--- java/org/tensorflow/op/core/Xdivy.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Xdivy.java	2018-10-16 20:18:38.625432105 +0900
@@ -0,0 +1,69 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns 0 if x == 0, and x / y otherwise, elementwise.
+ * 
+ * @param <T> data type for {@code z()} output
+ */
+@Operator
+public final class Xdivy<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Xdivy operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param y 
+   * @return a new instance of Xdivy
+   */
+  public static <T> Xdivy<T> create(Scope scope, Operand<T> x, Operand<T> y) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Xdivy", scope.makeOpName("Xdivy"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(y.asOutput());
+    return new Xdivy<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return z;
+  }
+  
+  private Output<T> z;
+  
+  private Xdivy(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Xlogy.java java-ops/org/tensorflow/op/core/Xlogy.java
--- java/org/tensorflow/op/core/Xlogy.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Xlogy.java	2018-10-16 20:18:38.625432105 +0900
@@ -0,0 +1,69 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns 0 if x == 0, and x * log(y) otherwise, elementwise.
+ * 
+ * @param <T> data type for {@code z()} output
+ */
+@Operator
+public final class Xlogy<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Xlogy operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param y 
+   * @return a new instance of Xlogy
+   */
+  public static <T> Xlogy<T> create(Scope scope, Operand<T> x, Operand<T> y) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Xlogy", scope.makeOpName("Xlogy"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(y.asOutput());
+    return new Xlogy<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return z;
+  }
+  
+  private Output<T> z;
+  
+  private Xlogy(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ZerosLike.java java-ops/org/tensorflow/op/core/ZerosLike.java
--- java/org/tensorflow/op/core/ZerosLike.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ZerosLike.java	2018-10-16 20:18:38.625432105 +0900
@@ -0,0 +1,68 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Returns a tensor of zeros with the same shape and type as x.
+ * 
+ * @param <T> data type for {@code y()} output
+ */
+@Operator
+public final class ZerosLike<T> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new ZerosLike operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x a tensor of type T.
+   * @return a new instance of ZerosLike
+   */
+  public static <T> ZerosLike<T> create(Scope scope, Operand<T> x) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ZerosLike", scope.makeOpName("ZerosLike"));
+    opBuilder.addInput(x.asOutput());
+    return new ZerosLike<T>(opBuilder.build());
+  }
+  
+  /**
+   * a tensor of the same shape and type as x but filled with zeros.
+   */
+  public Output<T> y() {
+    return y;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return y;
+  }
+  
+  private Output<T> y;
+  
+  private ZerosLike(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    y = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/Zeta.java java-ops/org/tensorflow/op/core/Zeta.java
--- java/org/tensorflow/op/core/Zeta.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/Zeta.java	2018-10-16 20:18:38.625432105 +0900
@@ -0,0 +1,73 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Compute the Hurwitz zeta function \\(\zeta(x, q)\\).
+ * <p>
+ * The Hurwitz zeta function is defined as:
+ * <p>
+ * \\(\zeta(x, q) = \sum_{n=0}^{\infty} (q + n)^{-x}\\)
+ * 
+ * @param <T> data type for {@code z()} output
+ */
+@Operator
+public final class Zeta<T extends Number> extends PrimitiveOp implements Operand<T> {
+  
+  /**
+   * Factory method to create a class to wrap a new Zeta operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param x 
+   * @param q 
+   * @return a new instance of Zeta
+   */
+  public static <T extends Number> Zeta<T> create(Scope scope, Operand<T> x, Operand<T> q) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("Zeta", scope.makeOpName("Zeta"));
+    opBuilder.addInput(x.asOutput());
+    opBuilder.addInput(q.asOutput());
+    return new Zeta<T>(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<T> z() {
+    return z;
+  }
+  
+  @Override
+  public Output<T> asOutput() {
+    return z;
+  }
+  
+  private Output<T> z;
+  
+  private Zeta(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    z = operation.output(outputIdx++);
+  }
+}
diff -ruN java/org/tensorflow/op/core/ZipDataset.java java-ops/org/tensorflow/op/core/ZipDataset.java
--- java/org/tensorflow/op/core/ZipDataset.java	1970-01-01 09:00:00.000000000 +0900
+++ java-ops/org/tensorflow/op/core/ZipDataset.java	2018-10-16 20:18:38.626432105 +0900
@@ -0,0 +1,82 @@
+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+=======================================================================*/
+
+// This class has been generated, DO NOT EDIT!
+
+package org.tensorflow.op.core;
+
+import java.util.List;
+import org.tensorflow.DataType;
+import org.tensorflow.Operand;
+import org.tensorflow.Operation;
+import org.tensorflow.OperationBuilder;
+import org.tensorflow.Output;
+import org.tensorflow.Shape;
+import org.tensorflow.op.Operands;
+import org.tensorflow.op.PrimitiveOp;
+import org.tensorflow.op.Scope;
+import org.tensorflow.op.annotation.Operator;
+
+/**
+ * Creates a dataset that zips together `input_datasets`.
+ */
+@Operator
+public final class ZipDataset extends PrimitiveOp implements Operand<Object> {
+  
+  /**
+   * Factory method to create a class to wrap a new ZipDataset operation to the graph.
+   * 
+   * @param scope current graph scope
+   * @param inputDatasets 
+   * @param outputTypes 
+   * @param outputShapes 
+   * @return a new instance of ZipDataset
+   */
+  public static ZipDataset create(Scope scope, Iterable<Operand<?>> inputDatasets, List<Class<?>> outputTypes, List<Shape> outputShapes) {
+    OperationBuilder opBuilder = scope.graph().opBuilder("ZipDataset", scope.makeOpName("ZipDataset"));
+    opBuilder.addInputList(Operands.asOutputs(inputDatasets));
+    DataType[] outputTypesArray = new DataType[outputTypes.size()];
+    for (int i = 0; i < outputTypesArray.length; ++i) {
+      outputTypesArray[i] = DataType.fromClass(outputTypes.get(i));
+    }
+    opBuilder.setAttr("output_types", outputTypesArray);
+    Shape[] outputShapesArray = new Shape[outputShapes.size()];
+    for (int i = 0; i < outputShapesArray.length; ++i) {
+      outputShapesArray[i] = outputShapes.get(i);
+    }
+    opBuilder.setAttr("output_shapes", outputShapesArray);
+    return new ZipDataset(opBuilder.build());
+  }
+  
+  /**
+   */
+  public Output<?> handle() {
+    return handle;
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public Output<Object> asOutput() {
+    return (Output<Object>) handle;
+  }
+  
+  private Output<?> handle;
+  
+  private ZipDataset(Operation operation) {
+    super(operation);
+    int outputIdx = 0;
+    handle = operation.output(outputIdx++);
+  }
+}
