// Targeted by JavaCPP version 1.5.7: DO NOT EDIT THIS FILE

package org.bytedeco.tensorflow.global;

import org.bytedeco.tensorflow.*;

import org.bytedeco.tensorflow.Allocator;
import java.nio.*;
import org.bytedeco.javacpp.*;
import org.bytedeco.javacpp.annotation.*;

import static org.bytedeco.javacpp.presets.javacpp.*;

public class tensorflow extends org.bytedeco.tensorflow.presets.tensorflow {
    static { Loader.load(); }

// Targeting ../AllocatorAttributesVector.java


// Targeting ../AllocRecordVector.java


// Targeting ../DeviceContextInlinedVector.java


// Targeting ../DeviceTypeVector.java


// Targeting ../TensorValueVector.java


// Targeting ../WrappedAllocatorVector.java


// Targeting ../LongVector.java


// Targeting ../DataTypeVector.java


// Targeting ../TensorHandleVector.java


// Targeting ../StringStringMap.java


// Targeting ../StringIntMap.java


// Targeting ../IntStringMap.java


// Targeting ../StringFeatureMap.java


// Targeting ../StringFeatureListMap.java


// Targeting ../StringCollectionDefMap.java


// Targeting ../StringSignatureDefMap.java


// Targeting ../StringTensorInfoMap.java


// Targeting ../IntFunctionDef_ArgAttrsMap.java


// Targeting ../StringStructuredValueMap.java


// Targeting ../StringSavedConcreteFunctionMap.java


// Targeting ../StringAttrValueMap.java


// Targeting ../NameRangeMap.java


// Targeting ../TF_SessionStringMap.java


// Targeting ../DeviceMap.java


// Targeting ../RemoteContexts.java


// Targeting ../StringFlatSet.java


// Targeting ../StringList.java


// Targeting ../TensorIdTensorIdMap.java


// Targeting ../SafeTensorIdTensorIdMap.java


// Targeting ../TF_OutputTensorHandleMap.java


// Targeting ../StringSet.java


// Targeting ../StringPieceVector.java


// Targeting ../StringVector.java


// Targeting ../IntIntVector.java


// Targeting ../IntIntPairVector.java


// Targeting ../StringStringPairVector.java


// Targeting ../DeviceVector.java


// Targeting ../DeviceContextVector.java


// Targeting ../TensorShapeProtoVector.java


// Targeting ../TensorVector.java


// Targeting ../TensorProtoVector.java


// Targeting ../TensorShapeVector.java


// Targeting ../NodeOutVector.java


// Targeting ../NodeVector.java


// Targeting ../NodeIntPairVector.java


// Targeting ../StringAttrPairVector.java


// Targeting ../ConstTensorPtrVector.java


// Targeting ../ConstDimensionPtrVector.java


// Targeting ../StringTensorPairVector.java


// Targeting ../EdgeVector.java


// Targeting ../OpDefVector.java


// Targeting ../OutputVector.java


// Targeting ../CollectiveImplementationVector.java


// Targeting ../TensorHandleTF_OutputPairVector.java


// Targeting ../LongLongPair.java


// Targeting ../WrappedAllocator.java


// Targeting ../ShapeHandlePair.java


// Targeting ../DimensionHandlePair.java


// Targeting ../EdgeSetBoolPair.java


// Targeting ../StringIntPair.java


// Targeting ../StringPieceIntPair.java


// Targeting ../TensorSlideStringPair.java


// Targeting ../DataTypeTensorShapePair.java


// Targeting ../NodeIndexPair.java


// Targeting ../StringSliceInfoMap.java


// Targeting ../StringIntUnorderedMap.java


// Targeting ../VarToShapeMap.java


// Targeting ../VarToDataTypeMap.java


// Targeting ../StringTensorSliceSetMap.java


// Targeting ../StringNodeMap.java


// Targeting ../IntTensorShapeMap.java


// Targeting ../IntDataTypeTensorShapePairMap.java


// Targeting ../DtypeAndPartialTensorShapeIntMap.java


// Targeting ../StringUnorderedSet.java


// Parsed from google/protobuf/port_def.inc

// Protocol Buffers - Google's data interchange format
// Copyright 2008 Google Inc.  All rights reserved.
// https://developers.google.com/protocol-buffers/
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are
// met:
//
//     * Redistributions of source code must retain the above copyright
// notice, this list of conditions and the following disclaimer.
//     * Redistributions in binary form must reproduce the above
// copyright notice, this list of conditions and the following disclaimer
// in the documentation and/or other materials provided with the
// distribution.
//     * Neither the name of Google Inc. nor the names of its
// contributors may be used to endorse or promote products derived from
// this software without specific prior written permission.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
// "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

// This file defines common macros that are used in protobuf.
//
// To hide these definitions from the outside world (and to prevent collisions
// if more than one version of protobuf is #included in the same project) you
// must follow this pattern when #including port_def.inc in a header file:
//
// #include "other_header.h"
// #include "message.h"
// // etc.
//
// #include "port_def.inc"  // MUST be last header included
//
// // Definitions for this header.
//
// #include "port_undef.inc"
//
// This is a textual header with no include guard, because we want to
// detect/prohibit anytime it is #included twice without a corresponding
// #undef.

// These macros are private and should always be
// ::util::RetrieveErrorSpace(*this) headers. If any of these errors fire, you
// should either properly #include port_undef.h at the end of your header that
// #includes port.h, or don't #include port.h twice in a .cc file.
// #ifdef PROTOBUF_NAMESPACE
// #error PROTOBUF_NAMESPACE was previously defined
// #endif
// #ifdef PROTOBUF_NAMESPACE_ID
// #endif
// #ifdef PROTOBUF_ALWAYS_INLINE
// #endif
// #ifdef PROTOBUF_COLD
// #error PROTOBUF_COLD was previously defined
// #endif
// #ifdef PROTOBUF_NOINLINE
// #endif
// #ifdef PROTOBUF_SECTION_VARIABLE
// #error PROTOBUF_SECTION_VARIABLE was previously defined
// #endif
// #ifdef PROTOBUF_DEPRECATED
// #endif
// #ifdef PROTOBUF_DEPRECATED_MSG
// #error PROTOBUF_DEPRECATED_MSG was previously defined
// #endif
// #ifdef PROTOBUF_FUNC_ALIGN
// #error PROTOBUF_FUNC_ALIGN was previously defined
// #endif
// #ifdef PROTOBUF_RETURNS_NONNULL
// #endif
// #ifdef PROTOBUF_ATTRIBUTE_REINITIALIZES
// #endif
// #ifdef PROTOBUF_RTTI
// #error PROTOBUF_RTTI was previously defined
// #endif
// #ifdef PROTOBUF_VERSION
// #error PROTOBUF_VERSION was previously defined
// #endif
// #ifdef PROTOBUF_VERSION_SUFFIX
// #error PROTOBUF_VERSION_SUFFIX was previously defined
// #endif
// #ifdef PROTOBUF_MIN_HEADER_VERSION_FOR_PROTOC
// #error PROTOBUF_MIN_HEADER_VERSION_FOR_PROTOC was previously defined
// #endif
// #ifdef PROTOBUF_MIN_PROTOC_VERSION
// #error PROTOBUF_MIN_PROTOC_VERSION was previously defined
// #endif
// #ifdef PROTOBUF_PREDICT_TRUE
// #error PROTOBUF_PREDICT_TRUE was previously defined
// #endif
// #ifdef PROTOBUF_PREDICT_FALSE
// #error PROTOBUF_PREDICT_FALSE was previously defined
// #endif
// #ifdef PROTOBUF_FIELD_OFFSET
// #error PROTOBUF_FIELD_OFFSET was previously defined
// #endif
// #ifdef PROTOBUF_LL_FORMAT
// #error PROTOBUF_LL_FORMAT was previously defined
// #endif
// #ifdef PROTOBUF_GUARDED_BY
// #error PROTOBUF_GUARDED_BY was previously defined
// #endif
// #ifdef PROTOBUF_LONGLONG
// #error PROTOBUF_LONGLONG was previously defined
// #endif
// #ifdef PROTOBUF_ULONGLONG
// #error PROTOBUF_ULONGLONG was previously defined
// #endif
// #ifdef PROTOBUF_FALLTHROUGH_INTENDED
// #endif
// #ifdef PROTOBUF_EXPORT
// #endif
// #ifdef PROTOC_EXPORT
// #endif
// #ifdef PROTOBUF_MUST_USE_RESULT
// #error PROTOBUF_MUST_USE_RESULT was previously defined
// #endif
// #ifdef PROTOBUF_UNUSED
// #endif


public static final String PROTOBUF_NAMESPACE = "google::protobuf";
// #define PROTOBUF_NAMESPACE_ID google::protobuf
// #define PROTOBUF_NAMESPACE_OPEN
//   namespace google {
//   namespace protobuf {
// #define PROTOBUF_NAMESPACE_CLOSE
//   } /* namespace protobuf */
//   } /* namespace google */
// #define PROTOBUF_DEPRECATED
// #define PROTOBUF_DEPRECATED_MSG(x)
// #define PROTOBUF_SECTION_VARIABLE(x)
// #define PROTOBUF_MUST_USE_RESULT

// ----------------------------------------------------------------------------
// Annotations:  Some parts of the code have been annotated in ways that might
//   be useful to some compilers or tools, but are not supported universally.
//   You can #define these annotations yourself if the default implementation
//   is not right for you.

// #ifdef GOOGLE_ATTRIBUTE_ALWAYS_INLINE
// #else
// #if defined(__GNUC__) && (__GNUC__ > 3 ||(__GNUC__ == 3 && __GNUC_MINOR__ >= 1))
// For functions we want to force inline.
// Introduced in gcc 3.1.
// #define PROTOBUF_ALWAYS_INLINE __attribute__ ((always_inline))
// #else
// Other compilers will have to figure it out for themselves.
// #define PROTOBUF_ALWAYS_INLINE
// #endif
// #endif

// #ifdef GOOGLE_ATTRIBUTE_NOINLINE
// #else
// #if defined(__GNUC__) && (__GNUC__ > 3 ||(__GNUC__ == 3 && __GNUC_MINOR__ >= 1))
// For functions we want to force not inline.
// Introduced in gcc 3.1.
// #define PROTOBUF_NOINLINE __attribute__ ((noinline))
// #elif defined(_MSC_VER) && (_MSC_VER >= 1400)
// Seems to have been around since at least Visual Studio 2005
// #define PROTOBUF_NOINLINE __declspec(noinline)
// #else
// Other compilers will have to figure it out for themselves.
// #define PROTOBUF_NOINLINE
// #endif
// #endif

// #ifdef GOOGLE_ATTRIBUTE_FUNC_ALIGN
// #else
// #if defined(__clang__) ||
//     defined(__GNUC__) && (__GNUC__ > 4 ||(__GNUC__ == 4 && __GNUC_MINOR__ >= 3))
// Function alignment attribute introduced in gcc 4.3
// #define PROTOBUF_FUNC_ALIGN(bytes) __attribute__ ((aligned(bytes)))
// #else
// #define PROTOBUF_FUNC_ALIGN(bytes)
// #endif
// #endif

// #ifdef GOOGLE_PREDICT_TRUE
// #else
// #ifdef __GNUC__
// Provided at least since GCC 3.0.
// #define PROTOBUF_PREDICT_TRUE(x) (__builtin_expect(!!(x), 1))
// #else
// #define PROTOBUF_PREDICT_TRUE(x) (x)
// #endif
// #endif

// #ifdef GOOGLE_PREDICT_FALSE
// #else
// #ifdef __GNUC__
// Provided at least since GCC 3.0.
// #define PROTOBUF_PREDICT_FALSE(x) (__builtin_expect(x, 0))
// #else
// #define PROTOBUF_PREDICT_FALSE(x) (x)
// #endif
// #endif

// #ifdef GOOGLE_PROTOBUF_ATTRIBUTE_RETURNS_NONNULL
// #else
// #ifdef __GNUC__
// #define PROTOBUF_RETURNS_NONNULL __attribute__((returns_nonnull))
// #else
// #define PROTOBUF_RETURNS_NONNULL
// #endif
// #endif

// #if defined(__has_cpp_attribute)
// #if __has_cpp_attribute(clang::reinitializes)
// #define PROTOBUF_ATTRIBUTE_REINITIALIZES [[clang::reinitializes]]
// #endif
// #endif
// #ifndef PROTOBUF_ATTRIBUTE_REINITIALIZES
// #define PROTOBUF_ATTRIBUTE_REINITIALIZES
// #endif

// #define PROTOBUF_GUARDED_BY(x)
// #define PROTOBUF_COLD

// Copied from ABSL.
// #if defined(__clang__) && defined(__has_warning)
// #if __has_feature(cxx_attributes) && __has_warning("-Wimplicit-fallthrough")
// #define PROTOBUF_FALLTHROUGH_INTENDED [[clang::fallthrough]]
// #endif
// #elif defined(__GNUC__) && __GNUC__ >= 7
// #define PROTOBUF_FALLTHROUGH_INTENDED [[gnu::fallthrough]]
// #endif

// #ifndef PROTOBUF_FALLTHROUGH_INTENDED
// #define PROTOBUF_FALLTHROUGH_INTENDED
// #endif

// #if defined(__has_cpp_attribute)
// #define HAS_ATTRIBUTE(attr) __has_cpp_attribute(attr)
// #else
// #define HAS_ATTRIBUTE(attr) 0
// #endif

// #if HAS_ATTRIBUTE(unused) || (defined(__GNUC__) && !defined(__clang__))
// #define PROTOBUF_UNUSED __attribute__((__unused__))
// #else
// #define PROTOBUF_UNUSED
// #endif

// #undef HAS_ATTRIBUTE

// #ifdef _MSC_VER
// #define PROTOBUF_LONGLONG(x) x##I64
// #define PROTOBUF_ULONGLONG(x) x##UI64
public static final String PROTOBUF_LL_FORMAT = "I64";  // As in printf("%I64d", ...)
// #else
// By long long, we actually mean int64.
// #define PROTOBUF_LONGLONG(x) x##LL
// #define PROTOBUF_ULONGLONG(x) x##ULL
// Used to format real long long integers.  // As in "%lld". Note that "q" is poor form also.
// #endif


// Shared google3/opensource definitions. //////////////////////////////////////

public static final int PROTOBUF_VERSION = 3008000;
public static final int PROTOBUF_MIN_HEADER_VERSION_FOR_PROTOC = 3008000;
public static final int PROTOBUF_MIN_PROTOC_VERSION = 3008000;
public static final String PROTOBUF_VERSION_SUFFIX = "";

// The minimum library version which works with the current version of the
// headers.
public static final int GOOGLE_PROTOBUF_MIN_LIBRARY_VERSION = 3008000;

// #if defined(GOOGLE_PROTOBUF_NO_RTTI) && GOOGLE_PROTOBUF_NO_RTTI
public static final int PROTOBUF_RTTI = 0;
// #else
// #endif

// Returns the offset of the given field within the given aggregate type.
// This is equivalent to the ANSI C offsetof() macro.  However, according
// to the C++ standard, offsetof() only works on POD types, and GCC
// enforces this requirement with a warning.  In practice, this rule is
// unnecessarily strict; there is probably no compiler or platform on
// which the offsets of the direct fields of a class are non-constant.
// Fields inherited from superclasses *can* have non-constant offsets,
// but that's not what this macro will be used for.
// #if defined(__clang__)
// For Clang we use __builtin_offsetof() and suppress the warning,
// to avoid Control Flow Integrity and UBSan vptr sanitizers from
// crashing while trying to validate the invalid reinterpet_casts.
// #define PROTOBUF_FIELD_OFFSET(TYPE, FIELD)
//   _Pragma("clang diagnostic push")
//   _Pragma("clang diagnostic ignored \"-Winvalid-offsetof\"")
//   __builtin_offsetof(TYPE, FIELD)
//   _Pragma("clang diagnostic pop")
// #else
// Note that we calculate relative to the pointer value 16 here since if we
// just use zero, GCC complains about dereferencing a NULL pointer.  We
// choose 16 rather than some other number just in case the compiler would
// be confused by an unaligned pointer.
// #define PROTOBUF_FIELD_OFFSET(TYPE, FIELD)
//   static_cast< ::google::protobuf::uint32>(reinterpret_cast<const char*>(
//                              &reinterpret_cast<const TYPE*>(16)->FIELD) -
//                          reinterpret_cast<const char*>(16))
// #endif


// #if defined(_MSC_VER) && defined(PROTOBUF_USE_DLLS)
// #ifdef LIBPROTOBUF_EXPORTS
// #define PROTOBUF_EXPORT __declspec(dllexport)
// #else
// #define PROTOBUF_EXPORT __declspec(dllimport)
// #endif
// #ifdef LIBPROTOC_EXPORTS
// #define PROTOC_EXPORT __declspec(dllexport)
// #else
// #define PROTOC_EXPORT __declspec(dllimport)
// #endif
// #else
// #define PROTOBUF_EXPORT
// #define PROTOC_EXPORT
// #endif

// Windows declares several inconvenient macro names.  We #undef them and then
// restore them in port_undef.inc.
// #ifdef _MSC_VER
// #pragma push_macro("GetMessage")
// #undef GetMessage
// #endif

// #if defined(__clang__)
// #pragma clang diagnostic push
// TODO(gerbens) ideally we cleanup the code. But a cursory try shows many
// violations. So let's ignore for now.
// #pragma clang diagnostic ignored "-Wshorten-64-to-32"
// #endif


// Parsed from google/protobuf/arena.h

// Protocol Buffers - Google's data interchange format
// Copyright 2008 Google Inc.  All rights reserved.
// https://developers.google.com/protocol-buffers/
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are
// met:
//
//     * Redistributions of source code must retain the above copyright
// notice, this list of conditions and the following disclaimer.
//     * Redistributions in binary form must reproduce the above
// copyright notice, this list of conditions and the following disclaimer
// in the documentation and/or other materials provided with the
// distribution.
//     * Neither the name of Google Inc. nor the names of its
// contributors may be used to endorse or promote products derived from
// this software without specific prior written permission.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
// "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

// This file defines an Arena allocator for better allocation performance.

// #ifndef GOOGLE_PROTOBUF_ARENA_H__
// #define GOOGLE_PROTOBUF_ARENA_H__

// #include <limits>
// #include <type_traits>
// #include <utility>
// #ifdef max
// #undef max  // Visual Studio defines this macro
// #endif
// #if defined(_MSC_VER) && !defined(_LIBCPP_STD_VER) && !_HAS_EXCEPTIONS
// Work around bugs in MSVC <typeinfo> header when _HAS_EXCEPTIONS=0.
// #include <exception>
// #include <typeinfo>

// #else
// #include <typeinfo>
// #endif

// #include <google/protobuf/arena_impl.h>
// #include <google/protobuf/port.h>
// #include <type_traits>

// #include <google/protobuf/port_def.inc>

// #ifdef SWIG
// #error "You cannot SWIG proto headers"
// #endif  // defined below

  // namespace protobuf
  // namespace google    // defined below  // defined in message.h




// Targeting ../ArenaStringPtr.java


// Targeting ../LazyField.java

        // defined in lazy_field.h  // defined in repeated_field.h

// Templated cleanup methods.
@Namespace("google::protobuf::internal") public static native void arena_free(Pointer object, @Cast("size_t") long size);


// Targeting ../ArenaOptions.java



// Support for non-RTTI environments. (The metrics hooks API uses type
// information.)
// #if PROTOBUF_RTTI
// #define RTTI_TYPE_ID(type) (&typeid(type))
// Targeting ../Arena.java



// Defined above for supporting environments without RTTI.
// #undef RTTI_TYPE_ID

  // namespace protobuf
  // namespace google

// #include <google/protobuf/port_undef.inc>

// #endif  // GOOGLE_PROTOBUF_ARENA_H__


// Parsed from google/protobuf/message_lite.h

// Protocol Buffers - Google's data interchange format
// Copyright 2008 Google Inc.  All rights reserved.
// https://developers.google.com/protocol-buffers/
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are
// met:
//
//     * Redistributions of source code must retain the above copyright
// notice, this list of conditions and the following disclaimer.
//     * Redistributions in binary form must reproduce the above
// copyright notice, this list of conditions and the following disclaimer
// in the documentation and/or other materials provided with the
// distribution.
//     * Neither the name of Google Inc. nor the names of its
// contributors may be used to endorse or promote products derived from
// this software without specific prior written permission.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
// "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

// Authors: wink@google.com (Wink Saville),
//          kenton@google.com (Kenton Varda)
//  Based on original Protocol Buffers design by
//  Sanjay Ghemawat, Jeff Dean, and others.
//
// Defines MessageLite, the abstract interface implemented by all (lite
// and non-lite) protocol message objects.

// #ifndef GOOGLE_PROTOBUF_MESSAGE_LITE_H__
// #define GOOGLE_PROTOBUF_MESSAGE_LITE_H__

// #include <climits>
// #include <string>

// #include <google/protobuf/stubs/common.h>
// #include <google/protobuf/stubs/logging.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/stubs/once.h>
// #include <google/protobuf/port.h>
// #include <google/protobuf/stubs/strutil.h>


// #include <google/protobuf/port_def.inc>

// #ifdef SWIG
// #error "You cannot SWIG proto headers"
// #endif
// Targeting ../CodedInputStream.java


// Targeting ../CodedOutputStream.java


// Targeting ../ZeroCopyInputStream.java


// Targeting ../ZeroCopyOutputStream.java



  // namespace io
// Targeting ../ParseContext.java


// Targeting ../RepeatedPtrFieldBase.java


// Targeting ../WireFormatLite.java


// Targeting ../WeakFieldMap.java



// We compute sizes as size_t but cache them as int.  This function converts a
// computed size to a cached size.  Since we don't proceed with serialization
// if the total size was > INT_MAX, it is not important what this function
// returns for inputs > INT_MAX.  However this case should not error or
// GOOGLE_CHECK-fail, because the full size_t resolution is still returned from
// ByteSizeLong() and checked against INT_MAX; we can catch the overflow
// there.
@Namespace("google::protobuf::internal") public static native int ToCachedSize(@Cast("size_t") long size);

// We mainly calculate sizes in terms of size_t, but some functions that
// compute sizes return "int".  These int sizes are expected to always be
// positive. This function is more efficient than casting an int to size_t
// directly on 64-bit platforms because it avoids making the compiler emit a
// sign extending instruction, which we don't want and don't want to pay for.
@Namespace("google::protobuf::internal") public static native @Cast("size_t") long FromIntSize(int size);

// For cases where a legacy function returns an integer size.  We GOOGLE_DCHECK()
// that the conversion will fit within an integer; if this is false then we
// are losing information.
@Namespace("google::protobuf::internal") public static native int ToIntSize(@Cast("size_t") long size);

// This type wraps a variable whose constructor and destructor are explicitly
// called. It is particularly useful for a global variable, without its
// constructor and destructor run on start and end of the program lifetime.
// This circumvents the initial construction order fiasco, while keeping
// the address of the empty string a compile time constant.
//
// Pay special attention to the initialization state of the object.
// 1. The object is "uninitialized" to begin with.
// 2. Call DefaultConstruct() only if the object is uninitialized.
//    After the call, the object becomes "initialized".
// 3. Call get() and get_mutable() only if the object is initialized.
// 4. Call Destruct() only if the object is initialized.
//    After the call, the object becomes uninitialized.

// Default empty string object. Don't use this directly. Instead, call
// GetEmptyString() to get the reference.


@Namespace("google::protobuf::internal") public static native @StdString BytePointer GetEmptyStringAlreadyInited();

@Namespace("google::protobuf::internal") public static native @Cast("size_t") long StringSpaceUsedExcludingSelfLong(@StdString BytePointer str);
@Namespace("google::protobuf::internal") public static native @Cast("size_t") long StringSpaceUsedExcludingSelfLong(@StdString String str);


// Targeting ../MessageLite.java










// Targeting ../BoundedZCIS.java









  // namespace internal



  // namespace protobuf
  // namespace google

// #include <google/protobuf/port_undef.inc>

// #endif  // GOOGLE_PROTOBUF_MESSAGE_LITE_H__


// Parsed from google/protobuf/unknown_field_set.h

// Protocol Buffers - Google's data interchange format
// Copyright 2008 Google Inc.  All rights reserved.
// https://developers.google.com/protocol-buffers/
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are
// met:
//
//     * Redistributions of source code must retain the above copyright
// notice, this list of conditions and the following disclaimer.
//     * Redistributions in binary form must reproduce the above
// copyright notice, this list of conditions and the following disclaimer
// in the documentation and/or other materials provided with the
// distribution.
//     * Neither the name of Google Inc. nor the names of its
// contributors may be used to endorse or promote products derived from
// this software without specific prior written permission.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
// "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

// Author: kenton@google.com (Kenton Varda)
//  Based on original Protocol Buffers design by
//  Sanjay Ghemawat, Jeff Dean, and others.
//
// Contains classes used to keep track of unrecognized fields seen while
// parsing a protocol message.

// #ifndef GOOGLE_PROTOBUF_UNKNOWN_FIELD_SET_H__
// #define GOOGLE_PROTOBUF_UNKNOWN_FIELD_SET_H__

// #include <assert.h>
// #include <string>
// #include <vector>
// #include <google/protobuf/stubs/common.h>
// #include <google/protobuf/stubs/logging.h>
// #include <google/protobuf/parse_context.h>
// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/message_lite.h>
// #include <google/protobuf/port.h>

// #include <google/protobuf/port_def.inc>

// #ifdef SWIG
// #error "You cannot SWIG proto headers"
// #endif     // coded_stream.h    // coded_stream.h  // zero_copy_stream.h

// Targeting ../InternalMetadataWithArena.java


// Targeting ../WireFormat.java


// Targeting ../MessageSetFieldSkipperUsingCord.java


// extension_set_heavy.cc
  // namespace internal       // message.h
// Targeting ../UnknownFieldSet.java


// Targeting ../UnknownField.java



// ===================================================================
// inline implementations











































  // namespace protobuf
  // namespace google

// #include <google/protobuf/port_undef.inc>
// #endif  // GOOGLE_PROTOBUF_UNKNOWN_FIELD_SET_H__


// Parsed from tensorflow/core/platform/default/integral_types.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_PLATFORM_DEFAULT_INTEGRAL_TYPES_H_
// #define TENSORFLOW_CORE_PLATFORM_DEFAULT_INTEGRAL_TYPES_H_

// IWYU pragma: private, include "third_party/tensorflow/core/platform/types.h"
// IWYU pragma: friend third_party/tensorflow/core/platform/types.h

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_PLATFORM_DEFAULT_INTEGRAL_TYPES_H_


// Parsed from tensorflow/core/lib/bfloat16/bfloat16.h

/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_LIB_BFLOAT16_BFLOAT16_H_
// #define TENSORFLOW_CORE_LIB_BFLOAT16_BFLOAT16_H_

// #include <cmath>
// #include <complex>

// #include "tensorflow/core/platform/byte_order.h"

// #ifdef __CUDACC__
// All functions callable from CUDA code must be qualified with __device__
// #define B16_DEVICE_FUNC __host__ __device__

// #else
// #define B16_DEVICE_FUNC

// #endif


// Single precision complex.
// Double precision complex.
// Targeting ../bfloat16.java



@Namespace("tensorflow") public static native @Cast("std::ostream*") @ByRef @Name("operator <<") Pointer shiftLeft(@Cast("std::ostream*") @ByRef Pointer os,
                                                @Const @ByRef bfloat16 dt);

@Namespace("tensorflow") public static native @ByVal @Name("operator +") bfloat16 add(@ByVal bfloat16 a, @ByVal bfloat16 b);
@Namespace("tensorflow") public static native @ByVal @Name("operator +") bfloat16 add(@ByVal bfloat16 a, int b);
@Namespace("tensorflow") public static native @ByVal @Name("operator +") bfloat16 add(int a, @ByVal bfloat16 b);
@Namespace("tensorflow") public static native @ByVal @Name("operator -") bfloat16 subtract(@ByVal bfloat16 a, @ByVal bfloat16 b);
@Namespace("tensorflow") public static native @ByVal @Name("operator *") bfloat16 multiply(@ByVal bfloat16 a, @ByVal bfloat16 b);
@Namespace("tensorflow") public static native @ByVal @Name("operator /") bfloat16 divide(@ByVal bfloat16 a, @ByVal bfloat16 b);
@Namespace("tensorflow") public static native @ByVal @Name("operator -") bfloat16 subtract(@ByVal bfloat16 a);
@Namespace("tensorflow") public static native @Cast("bool") @Name("operator <") boolean lessThan(@ByVal bfloat16 a, @ByVal bfloat16 b);
@Namespace("tensorflow") public static native @Cast("bool") @Name("operator <=") boolean lessThanEquals(@ByVal bfloat16 a, @ByVal bfloat16 b);
@Namespace("tensorflow") public static native @Cast("bool") @Name("operator ==") boolean equals(@ByVal bfloat16 a, @ByVal bfloat16 b);
@Namespace("tensorflow") public static native @Cast("bool") @Name("operator !=") boolean notEquals(@ByVal bfloat16 a, @ByVal bfloat16 b);
@Namespace("tensorflow") public static native @Cast("bool") @Name("operator >") boolean greaterThan(@ByVal bfloat16 a, @ByVal bfloat16 b);
@Namespace("tensorflow") public static native @Cast("bool") @Name("operator >=") boolean greaterThanEquals(@ByVal bfloat16 a, @ByVal bfloat16 b);
@Namespace("tensorflow") public static native @ByRef @Name("operator +=") bfloat16 addPut(@ByRef bfloat16 a, @ByVal bfloat16 b);
@Namespace("tensorflow") public static native @ByRef @Name("operator -=") bfloat16 subtractPut(@ByRef bfloat16 a, @ByVal bfloat16 b);
@Namespace("tensorflow") public static native @ByVal @Name("operator ++") bfloat16 increment(@ByRef bfloat16 a);
@Namespace("tensorflow") public static native @ByVal @Name("operator --") bfloat16 decrement(@ByRef bfloat16 a);
@Namespace("tensorflow") public static native @ByVal @Name("operator ++") bfloat16 increment(@ByRef bfloat16 a, int arg1);
@Namespace("tensorflow") public static native @ByVal @Name("operator --") bfloat16 decrement(@ByRef bfloat16 a, int arg1);
@Namespace("tensorflow") public static native @ByRef @Name("operator *=") bfloat16 multiplyPut(@ByRef bfloat16 a, @ByVal bfloat16 b);
@Namespace("tensorflow") public static native @ByRef @Name("operator /=") bfloat16 dividePut(@ByRef bfloat16 a, @ByVal bfloat16 b);

// Targeting ../HalfHash.java


@Namespace("std") public static native @Cast("bool") boolean isinf(@Const @ByRef bfloat16 a);
@Namespace("std") public static native @Cast("bool") boolean isnan(@Const @ByRef bfloat16 a);
@Namespace("std") public static native @Cast("bool") boolean isfinite(@Const @ByRef bfloat16 a);
@Namespace("std") public static native @ByVal bfloat16 abs(@Const @ByRef bfloat16 a);
@Namespace("std") public static native @ByVal bfloat16 exp(@Const @ByRef bfloat16 a);
@Namespace("std") public static native @ByVal bfloat16 expm1(@Const @ByRef bfloat16 a);
@Namespace("std") public static native @ByVal bfloat16 log(@Const @ByRef bfloat16 a);
@Namespace("std") public static native @ByVal bfloat16 log1p(@Const @ByRef bfloat16 a);
@Namespace("std") public static native @ByVal bfloat16 log10(@Const @ByRef bfloat16 a);
@Namespace("std") public static native @ByVal bfloat16 sqrt(@Const @ByRef bfloat16 a);
@Namespace("std") public static native @ByVal bfloat16 pow(@Const @ByRef bfloat16 a, @Const @ByRef bfloat16 b);
@Namespace("std") public static native @ByVal bfloat16 sin(@Const @ByRef bfloat16 a);
@Namespace("std") public static native @ByVal bfloat16 cos(@Const @ByRef bfloat16 a);
@Namespace("std") public static native @ByVal bfloat16 tan(@Const @ByRef bfloat16 a);
@Namespace("std") public static native @ByVal bfloat16 tanh(@Const @ByRef bfloat16 a);
@Namespace("std") public static native @ByVal bfloat16 floor(@Const @ByRef bfloat16 a);
@Namespace("std") public static native @ByVal bfloat16 ceil(@Const @ByRef bfloat16 a);
  // namespace std

// #endif  // TENSORFLOW_CORE_LIB_BFLOAT16_BFLOAT16_H_


// Parsed from tensorflow/core/framework/numeric_types.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_NUMERIC_TYPES_H_
// #define TENSORFLOW_CORE_FRAMEWORK_NUMERIC_TYPES_H_

// #include <complex>
// #include "third_party/eigen3/unsupported/Eigen/CXX11/Tensor"
// Disable clang-format to prevent 'FixedPoint' header from being included
// before 'Tensor' header on which it depends.
// clang-format off
// #include "third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint"
// clang-format on

// #include "tensorflow/core/lib/bfloat16/bfloat16.h"
// #include "tensorflow/core/platform/types.h"

// Single precision complex.
// Double precision complex.

// We use Eigen's QInt implementations for our quantized int types.

  // namespace tensorflow




public static native @ByVal bfloat16 FloatToBFloat16(float float_val);
// Targeting ../bfloat16NumTraits.java



  // namespace numext
  // namespace Eigen

// #if defined(_MSC_VER) && !defined(__clang__)
  // namespace std
// #endif  // _MSC_VER

// #endif  // TENSORFLOW_CORE_FRAMEWORK_NUMERIC_TYPES_H_


// Parsed from tensorflow/core/platform/init_main.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_PLATFORM_INIT_MAIN_H_
// #define TENSORFLOW_CORE_PLATFORM_INIT_MAIN_H_

// Platform-specific initialization routine that should be invoked by a
// main() program that uses TensorFlow.
// This performs necessary initialization on some platforms; TensorFlow
// may not work unless it has been called.
@Namespace("tensorflow::port") public static native void InitMain(@Cast("const char*") BytePointer usage, IntPointer argc, @Cast("char***") @ByPtrPtr PointerPointer argv);
@Namespace("tensorflow::port") public static native void InitMain(String usage, IntBuffer argc, @Cast("char***") @ByPtrPtr PointerPointer argv);
@Namespace("tensorflow::port") public static native void InitMain(@Cast("const char*") BytePointer usage, int[] argc, @Cast("char***") @ByPtrPtr PointerPointer argv);
@Namespace("tensorflow::port") public static native void InitMain(String usage, IntPointer argc, @Cast("char***") @ByPtrPtr PointerPointer argv);
@Namespace("tensorflow::port") public static native void InitMain(@Cast("const char*") BytePointer usage, IntBuffer argc, @Cast("char***") @ByPtrPtr PointerPointer argv);
@Namespace("tensorflow::port") public static native void InitMain(String usage, int[] argc, @Cast("char***") @ByPtrPtr PointerPointer argv);

  // namespace port
  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_PLATFORM_INIT_MAIN_H_


// Parsed from tensorflow/core/platform/types.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_PLATFORM_TYPES_H_
// #define TENSORFLOW_CORE_PLATFORM_TYPES_H_

// #include <string>

// #include "tensorflow/core/platform/platform.h"
// #include "tensorflow/core/platform/tstring.h"

// Include appropriate platform-dependent implementations
// #if defined(PLATFORM_GOOGLE) || defined(GOOGLE_INTEGRAL_TYPES)
// #include "tensorflow/core/platform/google/integral_types.h"
// #elif defined(PLATFORM_WINDOWS)
// #include "tensorflow/core/platform/windows/integral_types.h"
// #elif defined(PLATFORM_POSIX) || defined(PLATFORM_POSIX_ANDROID) ||
//     defined(PLATFORM_GOOGLE_ANDROID)
// #include "tensorflow/core/platform/default/integral_types.h"
// #else
// #error Define the appropriate PLATFORM_<foo> macro for this platform
// #endif

// Alias tensorflow::string to std::string.

@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::uint8") byte kuint8max();
public static final byte kuint8max = kuint8max();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::uint16") short kuint16max();
public static final short kuint16max = kuint16max();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::uint32") int kuint32max();
public static final int kuint32max = kuint32max();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::uint64") long kuint64max();
public static final long kuint64max = kuint64max();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::int8") byte kint8min();
public static final byte kint8min = kint8min();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::int8") byte kint8max();
public static final byte kint8max = kint8max();
@Namespace("tensorflow") @MemberGetter public static native short kint16min();
public static final short kint16min = kint16min();
@Namespace("tensorflow") @MemberGetter public static native short kint16max();
public static final short kint16max = kint16max();
@Namespace("tensorflow") @MemberGetter public static native int kint32min();
public static final int kint32min = kint32min();
@Namespace("tensorflow") @MemberGetter public static native int kint32max();
public static final int kint32max = kint32max();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::int64") long kint64min();
public static final long kint64min = kint64min();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::int64") long kint64max();
public static final long kint64max = kint64max();

// A typedef for a uint64 used as a short fingerprint.

  // namespace tensorflow

// Alias namespace ::stream_executor as ::tensorflow::se.

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_PLATFORM_TYPES_H_


// Parsed from tensorflow/core/platform/mutex.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_PLATFORM_MUTEX_H_
// #define TENSORFLOW_CORE_PLATFORM_MUTEX_H_

// #include <chrono>  // NOLINT
// for std::try_to_lock_t and std::cv_status
// #include <condition_variable>  // NOLINT
// #include <mutex>               // NOLINT

// #include "tensorflow/core/platform/platform.h"
// #include "tensorflow/core/platform/thread_annotations.h"
// #include "tensorflow/core/platform/types.h"

// Include appropriate platform-dependent implementation details of mutex etc.
// #if defined(PLATFORM_GOOGLE)
// #elif defined(PLATFORM_POSIX) || defined(PLATFORM_POSIX_ANDROID) ||
//     defined(PLATFORM_GOOGLE_ANDROID) || defined(PLATFORM_WINDOWS)
// #include "tensorflow/core/platform/default/mutex_data.h"
// #else
// #error Define the appropriate PLATFORM_<foo> macro for this platform
// #endif

/** enum tensorflow::ConditionResult */
public static final int kCond_Timeout = 0, kCond_MaybeNotified = 1;
/** enum tensorflow::LinkerInitialized */
public static final int LINKER_INITIALIZED = 0;

// Mimic std::mutex + C++17's shared_mutex, adding a LinkerInitialized
// constructor interface.  This type is as fast as mutex, but is also a shared
// lock, and provides conditional critical sections (via Await()), as an
// alternative to condition variables.
// Targeting ../Condition.java



// Mimic a subset of the std::unique_lock<tensorflow::mutex> functionality.

// Catch bug where variable name is omitted, e.g. mutex_lock (mu);
// #define mutex_lock(x) static_assert(0, "mutex_lock_decl_missing_var_name");

// Mimic a subset of the std::shared_lock<tensorflow::mutex> functionality.
// Name chosen to minimise conflicts with the tf_shared_lock macro, below.

// Catch bug where variable name is omitted, e.g. tf_shared_lock (mu);
// #define tf_shared_lock(x)
//   static_assert(0, "tf_shared_lock_decl_missing_var_name");

// Mimic std::condition_variable.

// Like "cv->wait(*mu)", except that it only waits for up to "ms" milliseconds.
//
// Returns kCond_Timeout if the timeout expired without this
// thread noticing a signal on the condition variable.  Otherwise may
// return either kCond_Timeout or kCond_MaybeNotified
@Namespace("tensorflow") public static native @Cast("tensorflow::ConditionResult") int WaitForMilliseconds(@Cast("tensorflow::mutex_lock*") Pointer mu,
                                           @Cast("tensorflow::condition_variable*") Pointer cv, @Cast("tensorflow::int64") long ms);

// ------------------------------------------------------------
// Implementation details follow.   Clients should ignore them.

// private static




// private static






// private static




  // namespace tensorflow

// Include appropriate platform-dependent implementation details of mutex etc.
// #if defined(PLATFORM_GOOGLE)
// #elif defined(PLATFORM_POSIX) || defined(PLATFORM_POSIX_ANDROID) ||
//     defined(PLATFORM_GOOGLE_ANDROID) || defined(PLATFORM_WINDOWS)
// #include "tensorflow/core/platform/default/mutex.h"
// #else
// #error Define the appropriate PLATFORM_<foo> macro for this platform
// #endif

// #endif  // TENSORFLOW_CORE_PLATFORM_MUTEX_H_


// Parsed from tensorflow/core/platform/macros.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_PLATFORM_MACROS_H_
// #define TENSORFLOW_CORE_PLATFORM_MACROS_H_

// Compiler attributes
// #if (defined(__GNUC__) || defined(__APPLE__)) && !defined(SWIG)
// Compiler supports GCC-style attributes
// #define TF_ATTRIBUTE_NORETURN __attribute__((noreturn))
// #define TF_ATTRIBUTE_ALWAYS_INLINE __attribute__((always_inline))
// #define TF_ATTRIBUTE_NOINLINE __attribute__((noinline))
// #define TF_ATTRIBUTE_UNUSED __attribute__((unused))
// #define TF_ATTRIBUTE_COLD __attribute__((cold))
// #define TF_ATTRIBUTE_WEAK __attribute__((weak))
// #define TF_PACKED __attribute__((packed))
// #define TF_MUST_USE_RESULT __attribute__((warn_unused_result))
// #define TF_PRINTF_ATTRIBUTE(string_index, first_to_check)
//   __attribute__((__format__(__printf__, string_index, first_to_check)))
// #define TF_SCANF_ATTRIBUTE(string_index, first_to_check)
//   __attribute__((__format__(__scanf__, string_index, first_to_check)))
// #elif defined(_MSC_VER)
// Non-GCC equivalents
// #define TF_ATTRIBUTE_NORETURN __declspec(noreturn)
// #define TF_ATTRIBUTE_ALWAYS_INLINE __forceinline
// #define TF_ATTRIBUTE_NOINLINE
// #define TF_ATTRIBUTE_UNUSED
// #define TF_ATTRIBUTE_COLD
// #define TF_ATTRIBUTE_WEAK
// #define TF_MUST_USE_RESULT
// #define TF_PACKED
// #define TF_PRINTF_ATTRIBUTE(string_index, first_to_check)
// #define TF_SCANF_ATTRIBUTE(string_index, first_to_check)
// #else
// Non-GCC equivalents
// #define TF_ATTRIBUTE_NORETURN
// #define TF_ATTRIBUTE_ALWAYS_INLINE
// #define TF_ATTRIBUTE_NOINLINE
// #define TF_ATTRIBUTE_UNUSED
// #define TF_ATTRIBUTE_COLD
// #define TF_ATTRIBUTE_WEAK
// #define TF_MUST_USE_RESULT
// #define TF_PACKED
// #define TF_PRINTF_ATTRIBUTE(string_index, first_to_check)
// #define TF_SCANF_ATTRIBUTE(string_index, first_to_check)
// #endif

// Control visiblity outside .so
// #if defined(_WIN32)
// #ifdef TF_COMPILE_LIBRARY
// #define TF_EXPORT __declspec(dllexport)
// #else
// #define TF_EXPORT __declspec(dllimport)
// #endif  // TF_COMPILE_LIBRARY
// #else
// #define TF_EXPORT __attribute__((visibility("default")))
// #endif  // _WIN32

// #ifdef __has_builtin
// #define TF_HAS_BUILTIN(x) __has_builtin(x)
// #else
// #define TF_HAS_BUILTIN(x) 0
// #endif

// Compilers can be told that a certain branch is not likely to be taken
// (for instance, a CHECK failure), and use that information in static
// analysis. Giving it this information can help it optimize for the
// common case in the absence of better information (ie.
// -fprofile-arcs).
//
// We need to disable this for GPU builds, though, since nvcc8 and older
// don't recognize `__builtin_expect` as a builtin, and fail compilation.
// #if (!defined(__NVCC__)) &&
//     (TF_HAS_BUILTIN(__builtin_expect) || (defined(__GNUC__) && __GNUC__ >= 3))
// #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))
// #define TF_PREDICT_TRUE(x) (__builtin_expect(!!(x), 1))
// #else
// #define TF_PREDICT_FALSE(x) (x)
// #define TF_PREDICT_TRUE(x) (x)
// #endif

// A macro to disallow the copy constructor and operator= functions
// This is usually placed in the private: declarations for a class.
// #define TF_DISALLOW_COPY_AND_ASSIGN(TypeName)
//   TypeName(const TypeName&) = delete;
//   void operator=(const TypeName&) = delete

// The TF_ARRAYSIZE(arr) macro returns the # of elements in an array arr.
//
// The expression TF_ARRAYSIZE(a) is a compile-time constant of type
// size_t.
// #define TF_ARRAYSIZE(a)
//   ((sizeof(a) / sizeof(*(a))) /
//    static_cast<size_t>(!(sizeof(a) % sizeof(*(a)))))

// #if defined(__GXX_EXPERIMENTAL_CXX0X__) || __cplusplus >= 201103L ||
//     (defined(_MSC_VER) && _MSC_VER >= 1900)
// Define this to 1 if the code is compiled in C++11 mode; leave it
// undefined otherwise.  Do NOT define it to 0 -- that causes
// '#ifdef LANG_CXX11' to behave differently from '#if LANG_CXX11'.
public static final int LANG_CXX11 = 1;
// #endif

// #if defined(__clang__) && defined(LANG_CXX11) && defined(__has_warning)
// #if __has_feature(cxx_attributes) && __has_warning("-Wimplicit-fallthrough")
// #define TF_FALLTHROUGH_INTENDED [[clang::fallthrough]]  // NOLINT
// #endif
// #endif

// #ifndef TF_FALLTHROUGH_INTENDED
// #define TF_FALLTHROUGH_INTENDED
//   do {
//   } while (0)
// #endif

// #endif  // TENSORFLOW_CORE_PLATFORM_MACROS_H_


// Parsed from tensorflow/core/util/port.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_UTIL_PORT_H_
// #define TENSORFLOW_CORE_UTIL_PORT_H_

// Returns true if GOOGLE_CUDA is defined.
@Namespace("tensorflow") public static native @Cast("bool") boolean IsGoogleCudaEnabled();

// Returns true if TENSORFLOW_USE_ROCM is defined. (i.e. TF is built with ROCm)
@Namespace("tensorflow") public static native @Cast("bool") boolean IsBuiltWithROCm();

// Returns true if either
//
//   GOOGLE_CUDA is defined, and the given CUDA version supports
//   half-precision matrix multiplications and convolution operations.
//
//     OR
//
//   TENSORFLOW_USE_ROCM is defined
//
@Namespace("tensorflow") public static native @Cast("bool") boolean GpuSupportsHalfMatMulAndConv();

// Returns true if INTEL_MKL is defined
@Namespace("tensorflow") public static native @Cast("bool") boolean IsMklEnabled();

  // end namespace tensorflow

// #endif  // TENSORFLOW_CORE_UTIL_PORT_H_


// Parsed from tensorflow/core/lib/core/error_codes.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/lib/core/error_codes.proto

// #ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2flib_2fcore_2ferror_5fcodes_2eproto
// #define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2flib_2fcore_2ferror_5fcodes_2eproto

// #include <limits>
// #include <string>

// #include <google/protobuf/port_def.inc>
// #if PROTOBUF_VERSION < 3008000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please update
// #error your headers.
// #endif
// #if 3008000 < PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/port_undef.inc>
// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/generated_message_reflection.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/generated_enum_reflection.h>
// @@protoc_insertion_point(includes)
// #include <google/protobuf/port_def.inc>
// #define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcore_2flib_2fcore_2ferror_5fcodes_2eproto
// Targeting ../AnyMetadata.java


  // namespace internal
 /* namespace protobuf */
   /* namespace google */

// Internal implementation detail -- do not use these members.
 /* namespace protobuf */
   /* namespace google */

/** enum tensorflow::error::Code */
public static final int
  OK = 0,
  CANCELLED = 1,
  UNKNOWN = 2,
  INVALID_ARGUMENT = 3,
  DEADLINE_EXCEEDED = 4,
  NOT_FOUND = 5,
  ALREADY_EXISTS = 6,
  PERMISSION_DENIED = 7,
  UNAUTHENTICATED = 16,
  RESOURCE_EXHAUSTED = 8,
  FAILED_PRECONDITION = 9,
  ABORTED = 10,
  OUT_OF_RANGE = 11,
  UNIMPLEMENTED = 12,
  INTERNAL = 13,
  UNAVAILABLE = 14,
  DATA_LOSS = 15,
  DO_NOT_USE_RESERVED_FOR_FUTURE_EXPANSION_USE_DEFAULT_IN_SWITCH_INSTEAD_ = 20;
@Name("tensorflow::error::Code_INT_MIN_SENTINEL_DO_NOT_USE_") public static native @MemberGetter int Code_INT_MIN_SENTINEL_DO_NOT_USE_();
public static final int
  Code_INT_MIN_SENTINEL_DO_NOT_USE_ = Code_INT_MIN_SENTINEL_DO_NOT_USE_();
@Name("tensorflow::error::Code_INT_MAX_SENTINEL_DO_NOT_USE_") public static native @MemberGetter int Code_INT_MAX_SENTINEL_DO_NOT_USE_();
public static final int
  Code_INT_MAX_SENTINEL_DO_NOT_USE_ = Code_INT_MAX_SENTINEL_DO_NOT_USE_();
@Namespace("tensorflow::error") public static native @Cast("bool") boolean Code_IsValid(int value);
@Namespace("tensorflow::error") @MemberGetter public static native @Cast("const tensorflow::error::Code") int Code_MIN();
@Namespace("tensorflow::error") @MemberGetter public static native @Cast("const tensorflow::error::Code") int Code_MAX();
@Namespace("tensorflow::error") @MemberGetter public static native int Code_ARRAYSIZE();

@Namespace("tensorflow::error") public static native @Cast("const google::protobuf::EnumDescriptor*") Pointer Code_descriptor();
@Namespace("tensorflow::error") public static native @Cast("bool") boolean Code_Parse(
    @StdString BytePointer name, @Cast("tensorflow::error::Code*") IntPointer value);
@Namespace("tensorflow::error") public static native @Cast("bool") boolean Code_Parse(
    @StdString String name, @Cast("tensorflow::error::Code*") IntBuffer value);
@Namespace("tensorflow::error") public static native @Cast("bool") boolean Code_Parse(
    @StdString BytePointer name, @Cast("tensorflow::error::Code*") int... value);
@Namespace("tensorflow::error") public static native @Cast("bool") boolean Code_Parse(
    @StdString String name, @Cast("tensorflow::error::Code*") IntPointer value);
@Namespace("tensorflow::error") public static native @Cast("bool") boolean Code_Parse(
    @StdString BytePointer name, @Cast("tensorflow::error::Code*") IntBuffer value);
@Namespace("tensorflow::error") public static native @Cast("bool") boolean Code_Parse(
    @StdString String name, @Cast("tensorflow::error::Code*") int... value);
// ===================================================================


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__

// @@protoc_insertion_point(namespace_scope)

  // namespace error
  // namespace tensorflow


 /* namespace protobuf */
   /* namespace google */

// @@protoc_insertion_point(global_scope)

// #include <google/protobuf/port_undef.inc>
// #endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2flib_2fcore_2ferror_5fcodes_2eproto


// Parsed from tensorflow/core/lib/core/errors.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_LIB_CORE_ERRORS_H_
// #define TENSORFLOW_CORE_LIB_CORE_ERRORS_H_

// #include <sstream>

// #include "absl/strings/str_join.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/strings/str_util.h"
// #include "tensorflow/core/lib/strings/strcat.h"
// #include "tensorflow/core/platform/logging.h"
// #include "tensorflow/core/platform/macros.h"

// The DECLARE_ERROR macro below only supports types that can be converted
// into StrCat's AlphaNum. For the other types we rely on a slower path
// through std::stringstream. To add support of a new type, it is enough to
// make sure there is an operator<<() for it:
//
//   std::ostream& operator<<(std::ostream& os, const MyType& foo) {
//     os << foo.ToString();
//     return os;
//   }
// Eventually absl::strings will have native support for this and we will be
// able to completely remove PrepareForStrCat().



  // namespace internal

// Append some context to an error message.  Each time we append
// context put it on a new line, since it is possible for there
// to be several layers of additional context.

// For propagating errors when calling a function.
// #define TF_RETURN_IF_ERROR(...)
//   do {
//     const ::tensorflow::Status _status = (__VA_ARGS__);
//     if (TF_PREDICT_FALSE(!_status.ok())) return _status;
//   } while (0)

// #define TF_RETURN_WITH_CONTEXT_IF_ERROR(expr, ...)
//   do {
//     ::tensorflow::Status _status = (expr);
//     if (TF_PREDICT_FALSE(!_status.ok())) {
//       ::tensorflow::errors::AppendToMessage(&_status, __VA_ARGS__);
//       return _status;
//     }
//   } while (0)

// Convenience functions for generating and using error status.
// Example usage:
//   status.Update(errors::InvalidArgument("The ", foo, " isn't right."));
//   if (errors::IsInvalidArgument(status)) { ... }
//   switch (status.code()) { case error::INVALID_ARGUMENT: ... }

// #define DECLARE_ERROR(FUNC, CONST)
//   template <typename... Args>
//   ::tensorflow::Status FUNC(Args... args) {
//     return ::tensorflow::Status(
//         ::tensorflow::error::CONST,
//         ::tensorflow::strings::StrCat(
//             ::tensorflow::errors::internal::PrepareForStrCat(args)...));
//   }
//   inline bool Is##FUNC(const ::tensorflow::Status& status) {
//     return status.code() == ::tensorflow::error::CONST;
//   }
  @Namespace("tensorflow::errors") public static native @Cast("bool") boolean IsCancelled(@Const @ByRef Status status);
  @Namespace("tensorflow::errors") public static native @Cast("bool") boolean IsInvalidArgument(@Const @ByRef Status status);
  @Namespace("tensorflow::errors") public static native @Cast("bool") boolean IsNotFound(@Const @ByRef Status status);
  @Namespace("tensorflow::errors") public static native @Cast("bool") boolean IsAlreadyExists(@Const @ByRef Status status);
  @Namespace("tensorflow::errors") public static native @Cast("bool") boolean IsResourceExhausted(@Const @ByRef Status status);
  @Namespace("tensorflow::errors") public static native @Cast("bool") boolean IsUnavailable(@Const @ByRef Status status);
  @Namespace("tensorflow::errors") public static native @Cast("bool") boolean IsFailedPrecondition(@Const @ByRef Status status);
  @Namespace("tensorflow::errors") public static native @Cast("bool") boolean IsOutOfRange(@Const @ByRef Status status);
  @Namespace("tensorflow::errors") public static native @Cast("bool") boolean IsUnimplemented(@Const @ByRef Status status);
  @Namespace("tensorflow::errors") public static native @Cast("bool") boolean IsInternal(@Const @ByRef Status status);
  @Namespace("tensorflow::errors") public static native @Cast("bool") boolean IsAborted(@Const @ByRef Status status);
  @Namespace("tensorflow::errors") public static native @Cast("bool") boolean IsDeadlineExceeded(@Const @ByRef Status status);
  @Namespace("tensorflow::errors") public static native @Cast("bool") boolean IsDataLoss(@Const @ByRef Status status);
  @Namespace("tensorflow::errors") public static native @Cast("bool") boolean IsUnknown(@Const @ByRef Status status);
  @Namespace("tensorflow::errors") public static native @Cast("bool") boolean IsPermissionDenied(@Const @ByRef Status status);
  @Namespace("tensorflow::errors") public static native @Cast("bool") boolean IsUnauthenticated(@Const @ByRef Status status);

// #undef DECLARE_ERROR

// Produces a formatted string pattern from the name which can uniquely identify
// this node upstream to produce an informative error message. The pattern
// followed is: {{node <name>}}
// Note: The pattern below determines the regex _NODEDEF_NAME_RE in the file
// tensorflow/python/client/session.py
// LINT.IfChange
@Namespace("tensorflow::errors") public static native @StdString BytePointer FormatNodeNameForError(@StdString BytePointer name);
@Namespace("tensorflow::errors") public static native @StdString String FormatNodeNameForError(@StdString String name);
// LINT.ThenChange(//tensorflow/python/client/session.py)
// LINT.IfChange
@Namespace("tensorflow::errors") public static native @StdString BytePointer FormatColocationNodeForError(@StdString BytePointer name);
@Namespace("tensorflow::errors") public static native @StdString String FormatColocationNodeForError(@StdString String name);
// LINT.ThenChange(//tensorflow/python/framework/error_interpolation.py)

@Namespace("tensorflow::errors") public static native @StdString BytePointer FormatFunctionForError(@StdString BytePointer name);
@Namespace("tensorflow::errors") public static native @StdString String FormatFunctionForError(@StdString String name);

// The CanonicalCode() for non-errors.

  // namespace errors
  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_LIB_CORE_ERRORS_H_


// Parsed from tensorflow/core/platform/logging.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_PLATFORM_LOGGING_H_
// #define TENSORFLOW_CORE_PLATFORM_LOGGING_H_

// #include "tensorflow/core/platform/platform.h"  // To pick up PLATFORM_define

// #if defined(PLATFORM_GOOGLE) || defined(PLATFORM_GOOGLE_ANDROID) ||
//     defined(GOOGLE_LOGGING) || defined(__EMSCRIPTEN__)
// #include "tensorflow/core/platform/google/build_config/logging.h"
// Adapt Google LogSink interface to the TF interface.

  // namespace tensorflow

// #else
// #include "tensorflow/core/platform/default/logging.h"
// #endif
// Emit "message" as a log message to the log for the specified
// "severity" as if it came from a LOG call at "fname:line"
@Namespace("tensorflow::internal") public static native void LogString(@Cast("const char*") BytePointer fname, int line, int severity,
               @StdString BytePointer message);
@Namespace("tensorflow::internal") public static native void LogString(String fname, int line, int severity,
               @StdString String message);
  // namespace internal

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_PLATFORM_LOGGING_H_


// Parsed from tensorflow/core/lib/core/status.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_LIB_CORE_STATUS_H_
// #define TENSORFLOW_CORE_LIB_CORE_STATUS_H_

// #include <functional>
// #include <iosfwd>
// #include <memory>
// #include <string>
// #include "tensorflow/core/lib/core/error_codes.pb.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/platform/logging.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/types.h"

// #if defined(__clang__)
// Only clang supports warn_unused_result as a type annotation.
// Targeting ../Status.java


// Targeting ../StatusGroup.java











/** \ingroup core */
@Namespace("tensorflow") public static native @Cast("std::ostream*") @ByRef @Name("operator <<") Pointer shiftLeft(@Cast("std::ostream*") @ByRef Pointer os, @Const @ByRef Status x);

@Namespace("tensorflow") public static native @StdString @Cast({"char*", "std::string*"}) BytePointer TfCheckOpHelperOutOfLine(
    @Const @ByRef Status v, @Cast("const char*") BytePointer msg);
@Namespace("tensorflow") public static native @StdString @Cast({"char*", "std::string*"}) BytePointer TfCheckOpHelperOutOfLine(
    @Const @ByRef Status v, String msg);

@Namespace("tensorflow") public static native @StdString @Cast({"char*", "std::string*"}) BytePointer TfCheckOpHelper(@ByVal Status v,
                                           @Cast("const char*") BytePointer msg);
@Namespace("tensorflow") public static native @StdString @Cast({"char*", "std::string*"}) BytePointer TfCheckOpHelper(@ByVal Status v,
                                           String msg);

// #define TF_DO_CHECK_OK(val, level)
//   while (auto _result = ::tensorflow::TfCheckOpHelper(val, #val))
//   LOG(level) << *(_result)

public static native void TF_CHECK_OK(@ByVal Status val);
public static native void TF_QCHECK_OK(@ByVal Status val);

// DEBUG only version of TF_CHECK_OK.  Compiler still parses 'val' even in opt
// mode.
// #ifndef NDEBUG
// #define TF_DCHECK_OK(val) TF_CHECK_OK(val)
// #else
// #define TF_DCHECK_OK(val)
//   while (false && (::tensorflow::Status::OK() == (val))) LOG(FATAL)
// #endif

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_LIB_CORE_STATUS_H_


// Parsed from tensorflow/core/util/device_name_utils.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_UTIL_DEVICE_NAME_UTILS_H_
// #define TENSORFLOW_CORE_UTIL_DEVICE_NAME_UTILS_H_

// #include <string>

// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// Targeting ../DeviceNameUtils.java



@Namespace("tensorflow") public static native @Cast("std::ostream*") @ByRef @Name("operator <<") Pointer shiftLeft(@Cast("std::ostream*") @ByRef Pointer os,
                         @Const @ByRef DeviceNameUtils.ParsedName x);

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_UTIL_DEVICE_NAME_UTILS_H_


// Parsed from tensorflow/core/lib/io/zlib_compression_options.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_LIB_IO_ZLIB_COMPRESSION_OPTIONS_H_
// #define TENSORFLOW_LIB_IO_ZLIB_COMPRESSION_OPTIONS_H_

// #include "tensorflow/core/platform/types.h"
// Targeting ../ZlibCompressionOptions.java









  // namespace io
  // namespace tensorflow

// #endif  // TENSORFLOW_LIB_IO_ZLIB_COMPRESSION_OPTIONS_H_


// Parsed from tensorflow/core/lib/io/zlib_outputbuffer.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_LIB_IO_COMPRESSED_OUTPUTBUFFER_H_
// #define TENSORFLOW_CORE_LIB_IO_COMPRESSED_OUTPUTBUFFER_H_

// #include <zlib.h>

// #include <string>

// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/lib/io/zlib_compression_options.h"
// #include "tensorflow/core/platform/env.h"
// #include "tensorflow/core/platform/file_system.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/types.h"
// Targeting ../ZlibOutputBuffer.java



  // namespace io
  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_LIB_IO_COMPRESSED_OUTPUTBUFFER_H_


// Parsed from tensorflow/core/lib/io/inputstream_interface.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_LIB_IO_INPUTSTREAM_INTERFACE_H_
// #define TENSORFLOW_CORE_LIB_IO_INPUTSTREAM_INTERFACE_H_

// #include <string>

// #include "tensorflow/core/lib/core/errors.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/platform/cord.h"
// #include "tensorflow/core/platform/types.h"
// Targeting ../InputStreamInterface.java



  // namespace io
  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_LIB_IO_INPUTSTREAM_INTERFACE_H_


// Parsed from tensorflow/core/lib/io/record_reader.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_LIB_IO_RECORD_READER_H_
// #define TENSORFLOW_CORE_LIB_IO_RECORD_READER_H_

// #include "tensorflow/core/lib/core/errors.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/lib/io/inputstream_interface.h"
// #if !defined(IS_SLIM_BUILD)
// #include "tensorflow/core/lib/io/zlib_compression_options.h"
// #include "tensorflow/core/lib/io/zlib_inputstream.h"
// #endif  // IS_SLIM_BUILD
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/types.h"
// Targeting ../RecordReaderOptions.java


// Targeting ../RecordReader.java


// Targeting ../SequentialRecordReader.java



  // namespace io
  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_LIB_IO_RECORD_READER_H_


// Parsed from tensorflow/core/lib/io/record_writer.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_LIB_IO_RECORD_WRITER_H_
// #define TENSORFLOW_CORE_LIB_IO_RECORD_WRITER_H_

// #include "tensorflow/core/lib/core/coding.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/lib/hash/crc32c.h"
// #if !defined(IS_SLIM_BUILD)
// #include "tensorflow/core/lib/io/zlib_compression_options.h"
// #include "tensorflow/core/lib/io/zlib_outputbuffer.h"
// #endif  // IS_SLIM_BUILD
// #include "tensorflow/core/platform/cord.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/types.h"
// Targeting ../RecordWriterOptions.java


// Targeting ../RecordWriter.java







// #if defined(PLATFORM_GOOGLE)
// #endif

  // namespace io
  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_LIB_IO_RECORD_WRITER_H_


// Parsed from tensorflow/core/platform/protobuf.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_PLATFORM_PROTOBUF_H_
// #define TENSORFLOW_CORE_PLATFORM_PROTOBUF_H_

// #include "tensorflow/core/platform/platform.h"
// #include "tensorflow/core/platform/types.h"

// Import whatever namespace protobuf comes from into the
// ::tensorflow::protobuf namespace.
//
// TensorFlow code should use the ::tensorflow::protobuf namespace to
// refer to all protobuf APIs.

// #ifndef TENSORFLOW_LITE_PROTOS
// #endif

// #include "google/protobuf/io/coded_stream.h"
// #include "google/protobuf/io/zero_copy_stream.h"
// #include "google/protobuf/io/zero_copy_stream_impl_lite.h"
// #include "google/protobuf/arena.h"
// #include "google/protobuf/map.h"
// #include "google/protobuf/repeated_field.h"
@Namespace("tensorflow") public static native @Cast("const char*") BytePointer kProtobufInt64Typename(); public static native void kProtobufInt64Typename(BytePointer setter);
@Namespace("tensorflow") public static native @Cast("const char*") BytePointer kProtobufUint64Typename(); public static native void kProtobufUint64Typename(BytePointer setter);

// Parses a protocol buffer contained in a string in the binary wire format.
// Returns true on success. Note: Unlike protobuf's builtin ParseFromString,
// this function has no size restrictions on the total size of the encoded
// protocol buffer.
@Namespace("tensorflow") public static native @Cast("bool") boolean ParseProtoUnlimited(MessageLite proto,
                         @StdString BytePointer serialized);
@Namespace("tensorflow") public static native @Cast("bool") boolean ParseProtoUnlimited(MessageLite proto,
                         @StdString String serialized);
@Namespace("tensorflow") public static native @Cast("bool") boolean ParseProtoUnlimited(MessageLite proto, @Const Pointer serialized,
                         @Cast("size_t") long size);

// Returns the string value for the value of a string or bytes protobuf field.
@Namespace("tensorflow") public static native @StdString BytePointer ProtobufStringToString(@StdString BytePointer s);
@Namespace("tensorflow") public static native @StdString String ProtobufStringToString(@StdString String s);

// Set <dest> to <src>. Swapping is allowed, as <src> does not need to be
// preserved.
@Namespace("tensorflow") public static native void SetProtobufStringSwapAllowed(@StdString @Cast({"char*", "std::string*"}) BytePointer src, @StdString @Cast({"char*", "std::string*"}) BytePointer dest);

// #if defined(TENSORFLOW_PROTOBUF_USES_CORD)
// #endif  // defined(TENSORFLOW_PROTOBUF_USES_CORD)

@Namespace("tensorflow") public static native @Cast("bool") boolean SerializeToTString(@Const @ByRef MessageLite proto,
                               @StdString @Cast({"char*", "std::string*"}) BytePointer output);

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_PLATFORM_PROTOBUF_H_


// Parsed from tensorflow/core/platform/file_system.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_PLATFORM_FILE_SYSTEM_H_
// #define TENSORFLOW_CORE_PLATFORM_FILE_SYSTEM_H_

// #include <stdint.h>
// #include <functional>
// #include <string>
// #include <unordered_map>
// #include <vector>
// #include "tensorflow/core/lib/core/errors.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/platform/cord.h"
// #include "tensorflow/core/platform/file_statistics.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/platform.h"
// #include "tensorflow/core/platform/types.h"

// #ifdef PLATFORM_WINDOWS
// #undef DeleteFile
// #undef CopyFile
// #endif
// Targeting ../FileSystem.java


// Targeting ../RandomAccessFile.java


// Targeting ../WritableFile.java


// Targeting ../ReadOnlyMemoryRegion.java


// Targeting ../FileSystemRegistry.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_PLATFORM_FILE_SYSTEM_H_


// Parsed from tensorflow/core/platform/file_statistics.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_PLATFORM_FILE_STATISTICS_H_
// #define TENSORFLOW_CORE_PLATFORM_FILE_STATISTICS_H_

// #include "tensorflow/core/platform/types.h"
// Targeting ../FileStatistics.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_PLATFORM_FILE_STATISTICS_H_


// Parsed from tensorflow/core/platform/env.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_PLATFORM_ENV_H_
// #define TENSORFLOW_CORE_PLATFORM_ENV_H_

// #include <stdint.h>
// #include <memory>
// #include <string>
// #include <unordered_map>
// #include <vector>
// #include "tensorflow/core/lib/core/errors.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/platform/env_time.h"
// #include "tensorflow/core/platform/file_system.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/mutex.h"
// #include "tensorflow/core/platform/numa.h"
// #include "tensorflow/core/platform/protobuf.h"
// #include "tensorflow/core/platform/types.h"

// Delete the definition of CopyFile as the linker gets confused.
// #ifdef PLATFORM_WINDOWS
// #undef CopyFile
// #endif
// Targeting ../Env.java


// Targeting ../EnvWrapper.java


// Targeting ../Thread.java


// Targeting ../ThreadOptions.java



/** A utility routine: copy contents of {@code src} in file system {@code src_fs}
 *  to {@code target} in file system {@code target_fs}. */
@Namespace("tensorflow") public static native @ByVal Status FileSystemCopyFile(FileSystem src_fs, @StdString BytePointer src,
                          FileSystem target_fs, @StdString BytePointer target);
@Namespace("tensorflow") public static native @ByVal Status FileSystemCopyFile(FileSystem src_fs, @StdString String src,
                          FileSystem target_fs, @StdString String target);

/** A utility routine: reads contents of named file into {@code *data} */
@Namespace("tensorflow") public static native @ByVal Status ReadFileToString(Env env, @StdString BytePointer fname, @StdString @Cast({"char*", "std::string*"}) BytePointer data);
@Namespace("tensorflow") public static native @ByVal Status ReadFileToString(Env env, @StdString String fname, @StdString @Cast({"char*", "std::string*"}) BytePointer data);

/** A utility routine: write contents of {@code data} to file named {@code fname}
 *  (overwriting existing contents, if any). */
@Namespace("tensorflow") public static native @ByVal Status WriteStringToFile(Env env, @StdString BytePointer fname,
                         @StringPiece BytePointer data);
@Namespace("tensorflow") public static native @ByVal Status WriteStringToFile(Env env, @StdString String fname,
                         @StringPiece String data);

/** Write binary representation of "proto" to the named file. */
@Namespace("tensorflow") public static native @ByVal Status WriteBinaryProto(Env env, @StdString BytePointer fname,
                        @Cast("const tensorflow::protobuf::MessageLite*") @ByRef MessageLite proto);
@Namespace("tensorflow") public static native @ByVal Status WriteBinaryProto(Env env, @StdString String fname,
                        @Cast("const tensorflow::protobuf::MessageLite*") @ByRef MessageLite proto);

/** Reads contents of named file and parse as binary encoded proto data
 *  and store into {@code *proto}. */
@Namespace("tensorflow") public static native @ByVal Status ReadBinaryProto(Env env, @StdString BytePointer fname,
                       @Cast("tensorflow::protobuf::MessageLite*") MessageLite proto);
@Namespace("tensorflow") public static native @ByVal Status ReadBinaryProto(Env env, @StdString String fname,
                       @Cast("tensorflow::protobuf::MessageLite*") MessageLite proto);

/** Write the text representation of "proto" to the named file. */
@Namespace("tensorflow") public static native @ByVal Status WriteTextProto(Env env, @StdString BytePointer fname,
                      @Cast("const tensorflow::protobuf::Message*") @ByRef MessageLite proto);
@Namespace("tensorflow") public static native @ByVal Status WriteTextProto(Env env, @StdString String fname,
                      @Cast("const tensorflow::protobuf::Message*") @ByRef MessageLite proto);

/** Read contents of named file and parse as text encoded proto data
 *  and store into {@code *proto}. */
@Namespace("tensorflow") public static native @ByVal Status ReadTextProto(Env env, @StdString BytePointer fname,
                     @Cast("tensorflow::protobuf::Message*") MessageLite proto);
@Namespace("tensorflow") public static native @ByVal Status ReadTextProto(Env env, @StdString String fname,
                     @Cast("tensorflow::protobuf::Message*") MessageLite proto);

/** Read contents of named file and parse as either text or binary encoded proto
 *  data and store into {@code *proto}. */
@Namespace("tensorflow") public static native @ByVal Status ReadTextOrBinaryProto(Env env, @StdString BytePointer fname,
                             @Cast("tensorflow::protobuf::Message*") MessageLite proto
);
@Namespace("tensorflow") public static native @ByVal Status ReadTextOrBinaryProto(Env env, @StdString String fname,
                             @Cast("tensorflow::protobuf::Message*") MessageLite proto
);

// START_SKIP_DOXYGEN

  // namespace register_file_system

// END_SKIP_DOXYGEN

  // namespace tensorflow

// Register a FileSystem implementation for a scheme. Files with names that have
// "scheme://" prefixes are routed to use this implementation.
// #define REGISTER_FILE_SYSTEM_ENV(env, scheme, factory)
//   REGISTER_FILE_SYSTEM_UNIQ_HELPER(__COUNTER__, env, scheme, factory)
// #define REGISTER_FILE_SYSTEM_UNIQ_HELPER(ctr, env, scheme, factory)
//   REGISTER_FILE_SYSTEM_UNIQ(ctr, env, scheme, factory)
// #define REGISTER_FILE_SYSTEM_UNIQ(ctr, env, scheme, factory)
//   static ::tensorflow::register_file_system::Register<factory>
//       register_ff##ctr TF_ATTRIBUTE_UNUSED =
//           ::tensorflow::register_file_system::Register<factory>(env, scheme)

// #define REGISTER_FILE_SYSTEM(scheme, factory)
//   REGISTER_FILE_SYSTEM_ENV(::tensorflow::Env::Default(), scheme, factory);

// #endif  // TENSORFLOW_CORE_PLATFORM_ENV_H_


// Parsed from tensorflow/core/example/feature.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/example/feature.proto

// #ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fexample_2ffeature_2eproto
// #define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fexample_2ffeature_2eproto

// #include <limits>
// #include <string>

// #include <google/protobuf/port_def.inc>
// #if PROTOBUF_VERSION < 3008000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please update
// #error your headers.
// #endif
// #if 3008000 < PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/port_undef.inc>
// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/generated_message_reflection.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/map.h>  // IWYU pragma: export
// #include <google/protobuf/map_entry.h>
// #include <google/protobuf/map_field_inl.h>
// #include <google/protobuf/unknown_field_set.h>
// @@protoc_insertion_point(includes)
// #include <google/protobuf/port_def.inc>
// #define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcore_2fexample_2ffeature_2eproto
  // namespace internal
 /* namespace protobuf */
   /* namespace google */

// Internal implementation detail -- do not use these members.
  // namespace tensorflow









 /* namespace protobuf */
   /* namespace google */
// Targeting ../BytesList.java


// Targeting ../FloatList.java


// Targeting ../Int64List.java


// Targeting ../Feature.java


// -------------------------------------------------------------------
// Targeting ../Features.java


// Targeting ../FeatureList.java


// -------------------------------------------------------------------
// Targeting ../FeatureLists.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// BytesList

// repeated bytes value = 1;
















// -------------------------------------------------------------------

// FloatList

// repeated float value = 1 [packed = true];








// -------------------------------------------------------------------

// Int64List

// repeated int64 value = 1 [packed = true];








// -------------------------------------------------------------------

// Feature

// .tensorflow.BytesList bytes_list = 1;









// .tensorflow.FloatList float_list = 2;









// .tensorflow.Int64List int64_list = 3;












// -------------------------------------------------------------------

// -------------------------------------------------------------------

// Features

// map<string, .tensorflow.Feature> feature = 1;





// -------------------------------------------------------------------

// FeatureList

// repeated .tensorflow.Feature feature = 1;








// -------------------------------------------------------------------

// -------------------------------------------------------------------

// FeatureLists

// map<string, .tensorflow.FeatureList> feature_list = 1;





// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #include <google/protobuf/port_undef.inc>
// #endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fexample_2ffeature_2eproto


// Parsed from tensorflow/core/example/example.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/example/example.proto

// #ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fexample_2fexample_2eproto
// #define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fexample_2fexample_2eproto

// #include <limits>
// #include <string>

// #include <google/protobuf/port_def.inc>
// #if PROTOBUF_VERSION < 3008000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please update
// #error your headers.
// #endif
// #if 3008000 < PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/port_undef.inc>
// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/generated_message_reflection.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/example/feature.pb.h"
// @@protoc_insertion_point(includes)
// #include <google/protobuf/port_def.inc>
// #define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcore_2fexample_2fexample_2eproto
  // namespace internal
 /* namespace protobuf */
   /* namespace google */

// Internal implementation detail -- do not use these members.
  // namespace tensorflow


 /* namespace protobuf */
   /* namespace google */
// Targeting ../Example.java


// Targeting ../SequenceExample.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// Example

// .tensorflow.Features features = 1;







// -------------------------------------------------------------------

// SequenceExample

// .tensorflow.Features context = 1;







// .tensorflow.FeatureLists feature_lists = 2;







// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #include <google/protobuf/port_undef.inc>
// #endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fexample_2fexample_2eproto


// Parsed from tensorflow/core/protobuf/debug.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/protobuf/debug.proto

// #ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fdebug_2eproto
// #define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fdebug_2eproto

// #include <limits>
// #include <string>

// #include <google/protobuf/port_def.inc>
// #if PROTOBUF_VERSION < 3008000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please update
// #error your headers.
// #endif
// #if 3008000 < PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/port_undef.inc>
// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/generated_message_reflection.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/unknown_field_set.h>
// @@protoc_insertion_point(includes)
// #include <google/protobuf/port_def.inc>
// #define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcore_2fprotobuf_2fdebug_2eproto
  // namespace internal
 /* namespace protobuf */
   /* namespace google */

// Internal implementation detail -- do not use these members.
  // namespace tensorflow




 /* namespace protobuf */
   /* namespace google */
// Targeting ../DebugTensorWatch.java


// Targeting ../DebugOptions.java


// Targeting ../DebuggedSourceFile.java


// Targeting ../DebuggedSourceFiles.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// DebugTensorWatch

// string node_name = 1;












// int32 output_slot = 2;




// repeated string debug_ops = 3;
















// repeated string debug_urls = 4;
















// bool tolerate_debug_op_creation_failures = 5;




// -------------------------------------------------------------------

// DebugOptions

// repeated .tensorflow.DebugTensorWatch debug_tensor_watch_opts = 4;








// int64 global_step = 10;




// bool reset_disk_byte_usage = 11;




// -------------------------------------------------------------------

// DebuggedSourceFile

// string host = 1;












// string file_path = 2;












// int64 last_modified = 3;




// int64 bytes = 4;




// repeated string lines = 5;
















// -------------------------------------------------------------------

// DebuggedSourceFiles

// repeated .tensorflow.DebuggedSourceFile source_files = 1;








// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #include <google/protobuf/port_undef.inc>
// #endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fdebug_2eproto


// Parsed from tensorflow/core/protobuf/cluster.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/protobuf/cluster.proto

// #ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fcluster_2eproto
// #define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fcluster_2eproto

// #include <limits>
// #include <string>

// #include <google/protobuf/port_def.inc>
// #if PROTOBUF_VERSION < 3008000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please update
// #error your headers.
// #endif
// #if 3008000 < PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/port_undef.inc>
// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/generated_message_reflection.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/map.h>  // IWYU pragma: export
// #include <google/protobuf/map_entry.h>
// #include <google/protobuf/map_field_inl.h>
// #include <google/protobuf/unknown_field_set.h>
// @@protoc_insertion_point(includes)
// #include <google/protobuf/port_def.inc>
// #define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcore_2fprotobuf_2fcluster_2eproto
  // namespace internal
 /* namespace protobuf */
   /* namespace google */

// Internal implementation detail -- do not use these members.
  // namespace tensorflow



 /* namespace protobuf */
   /* namespace google */

// ===================================================================
// Targeting ../JobDef.java


// Targeting ../ClusterDef.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// -------------------------------------------------------------------

// JobDef

// string name = 1;












// map<int32, string> tasks = 2;





// -------------------------------------------------------------------

// ClusterDef

// repeated .tensorflow.JobDef job = 1;








// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #include <google/protobuf/port_undef.inc>
// #endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fcluster_2eproto


// Parsed from tensorflow/core/protobuf/verifier_config.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/protobuf/verifier_config.proto

// #ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fverifier_5fconfig_2eproto
// #define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fverifier_5fconfig_2eproto

// #include <limits>
// #include <string>

// #include <google/protobuf/port_def.inc>
// #if PROTOBUF_VERSION < 3008000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please update
// #error your headers.
// #endif
// #if 3008000 < PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/port_undef.inc>
// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/generated_message_reflection.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/generated_enum_reflection.h>
// #include <google/protobuf/unknown_field_set.h>
// @@protoc_insertion_point(includes)
// #include <google/protobuf/port_def.inc>
// #define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcore_2fprotobuf_2fverifier_5fconfig_2eproto
  // namespace internal
 /* namespace protobuf */
   /* namespace google */

// Internal implementation detail -- do not use these members.
  // namespace tensorflow

 /* namespace protobuf */
   /* namespace google */

/** enum tensorflow::VerifierConfig_Toggle */
public static final int
  VerifierConfig_Toggle_DEFAULT = 0,
  VerifierConfig_Toggle_ON = 1,
  VerifierConfig_Toggle_OFF = 2;
@Name("tensorflow::VerifierConfig_Toggle_VerifierConfig_Toggle_INT_MIN_SENTINEL_DO_NOT_USE_") public static native @MemberGetter int VerifierConfig_Toggle_VerifierConfig_Toggle_INT_MIN_SENTINEL_DO_NOT_USE_();
public static final int
  VerifierConfig_Toggle_VerifierConfig_Toggle_INT_MIN_SENTINEL_DO_NOT_USE_ = VerifierConfig_Toggle_VerifierConfig_Toggle_INT_MIN_SENTINEL_DO_NOT_USE_();
@Name("tensorflow::VerifierConfig_Toggle_VerifierConfig_Toggle_INT_MAX_SENTINEL_DO_NOT_USE_") public static native @MemberGetter int VerifierConfig_Toggle_VerifierConfig_Toggle_INT_MAX_SENTINEL_DO_NOT_USE_();
public static final int
  VerifierConfig_Toggle_VerifierConfig_Toggle_INT_MAX_SENTINEL_DO_NOT_USE_ = VerifierConfig_Toggle_VerifierConfig_Toggle_INT_MAX_SENTINEL_DO_NOT_USE_();
@Namespace("tensorflow") public static native @Cast("bool") boolean VerifierConfig_Toggle_IsValid(int value);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::VerifierConfig_Toggle") int VerifierConfig_Toggle_Toggle_MIN();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::VerifierConfig_Toggle") int VerifierConfig_Toggle_Toggle_MAX();
@Namespace("tensorflow") @MemberGetter public static native int VerifierConfig_Toggle_Toggle_ARRAYSIZE();

@Namespace("tensorflow") public static native @Cast("const google::protobuf::EnumDescriptor*") Pointer VerifierConfig_Toggle_descriptor();
@Namespace("tensorflow") public static native @Cast("bool") boolean VerifierConfig_Toggle_Parse(
    @StdString BytePointer name, @Cast("tensorflow::VerifierConfig_Toggle*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean VerifierConfig_Toggle_Parse(
    @StdString String name, @Cast("tensorflow::VerifierConfig_Toggle*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean VerifierConfig_Toggle_Parse(
    @StdString BytePointer name, @Cast("tensorflow::VerifierConfig_Toggle*") int... value);
@Namespace("tensorflow") public static native @Cast("bool") boolean VerifierConfig_Toggle_Parse(
    @StdString String name, @Cast("tensorflow::VerifierConfig_Toggle*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean VerifierConfig_Toggle_Parse(
    @StdString BytePointer name, @Cast("tensorflow::VerifierConfig_Toggle*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean VerifierConfig_Toggle_Parse(
    @StdString String name, @Cast("tensorflow::VerifierConfig_Toggle*") int... value);
// Targeting ../VerifierConfig.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// VerifierConfig

// int64 verification_timeout_in_ms = 1;




// .tensorflow.VerifierConfig.Toggle structure_verifier = 2;




// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__

// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow


 /* namespace protobuf */
   /* namespace google */

// @@protoc_insertion_point(global_scope)

// #include <google/protobuf/port_undef.inc>
// #endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fverifier_5fconfig_2eproto


// Parsed from tensorflow/core/protobuf/rewriter_config.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/protobuf/rewriter_config.proto

// #ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto
// #define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto

// #include <limits>
// #include <string>

// #include <google/protobuf/port_def.inc>
// #if PROTOBUF_VERSION < 3008000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please update
// #error your headers.
// #endif
// #if 3008000 < PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/port_undef.inc>
// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/generated_message_reflection.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/map.h>  // IWYU pragma: export
// #include <google/protobuf/map_entry.h>
// #include <google/protobuf/map_field_inl.h>
// #include <google/protobuf/generated_enum_reflection.h>
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/attr_value.pb.h"
// #include "tensorflow/core/protobuf/verifier_config.pb.h"
// @@protoc_insertion_point(includes)
// #include <google/protobuf/port_def.inc>
// #define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto
  // namespace internal
 /* namespace protobuf */
   /* namespace google */

// Internal implementation detail -- do not use these members.
  // namespace tensorflow





 /* namespace protobuf */
   /* namespace google */

/** enum tensorflow::RewriterConfig_Toggle */
public static final int
  RewriterConfig_Toggle_DEFAULT = 0,
  RewriterConfig_Toggle_ON = 1,
  RewriterConfig_Toggle_OFF = 2,
  RewriterConfig_Toggle_AGGRESSIVE = 3;
@Name("tensorflow::RewriterConfig_Toggle_RewriterConfig_Toggle_INT_MIN_SENTINEL_DO_NOT_USE_") public static native @MemberGetter int RewriterConfig_Toggle_RewriterConfig_Toggle_INT_MIN_SENTINEL_DO_NOT_USE_();
public static final int
  RewriterConfig_Toggle_RewriterConfig_Toggle_INT_MIN_SENTINEL_DO_NOT_USE_ = RewriterConfig_Toggle_RewriterConfig_Toggle_INT_MIN_SENTINEL_DO_NOT_USE_();
@Name("tensorflow::RewriterConfig_Toggle_RewriterConfig_Toggle_INT_MAX_SENTINEL_DO_NOT_USE_") public static native @MemberGetter int RewriterConfig_Toggle_RewriterConfig_Toggle_INT_MAX_SENTINEL_DO_NOT_USE_();
public static final int
  RewriterConfig_Toggle_RewriterConfig_Toggle_INT_MAX_SENTINEL_DO_NOT_USE_ = RewriterConfig_Toggle_RewriterConfig_Toggle_INT_MAX_SENTINEL_DO_NOT_USE_();
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_Toggle_IsValid(int value);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::RewriterConfig_Toggle") int RewriterConfig_Toggle_Toggle_MIN();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::RewriterConfig_Toggle") int RewriterConfig_Toggle_Toggle_MAX();
@Namespace("tensorflow") @MemberGetter public static native int RewriterConfig_Toggle_Toggle_ARRAYSIZE();

@Namespace("tensorflow") public static native @Cast("const google::protobuf::EnumDescriptor*") Pointer RewriterConfig_Toggle_descriptor();
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_Toggle_Parse(
    @StdString BytePointer name, @Cast("tensorflow::RewriterConfig_Toggle*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_Toggle_Parse(
    @StdString String name, @Cast("tensorflow::RewriterConfig_Toggle*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_Toggle_Parse(
    @StdString BytePointer name, @Cast("tensorflow::RewriterConfig_Toggle*") int... value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_Toggle_Parse(
    @StdString String name, @Cast("tensorflow::RewriterConfig_Toggle*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_Toggle_Parse(
    @StdString BytePointer name, @Cast("tensorflow::RewriterConfig_Toggle*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_Toggle_Parse(
    @StdString String name, @Cast("tensorflow::RewriterConfig_Toggle*") int... value);
/** enum tensorflow::RewriterConfig_NumIterationsType */
public static final int
  RewriterConfig_NumIterationsType_DEFAULT_NUM_ITERS = 0,
  RewriterConfig_NumIterationsType_ONE = 1,
  RewriterConfig_NumIterationsType_TWO = 2;
@Name("tensorflow::RewriterConfig_NumIterationsType_RewriterConfig_NumIterationsType_INT_MIN_SENTINEL_DO_NOT_USE_") public static native @MemberGetter int RewriterConfig_NumIterationsType_RewriterConfig_NumIterationsType_INT_MIN_SENTINEL_DO_NOT_USE_();
public static final int
  RewriterConfig_NumIterationsType_RewriterConfig_NumIterationsType_INT_MIN_SENTINEL_DO_NOT_USE_ = RewriterConfig_NumIterationsType_RewriterConfig_NumIterationsType_INT_MIN_SENTINEL_DO_NOT_USE_();
@Name("tensorflow::RewriterConfig_NumIterationsType_RewriterConfig_NumIterationsType_INT_MAX_SENTINEL_DO_NOT_USE_") public static native @MemberGetter int RewriterConfig_NumIterationsType_RewriterConfig_NumIterationsType_INT_MAX_SENTINEL_DO_NOT_USE_();
public static final int
  RewriterConfig_NumIterationsType_RewriterConfig_NumIterationsType_INT_MAX_SENTINEL_DO_NOT_USE_ = RewriterConfig_NumIterationsType_RewriterConfig_NumIterationsType_INT_MAX_SENTINEL_DO_NOT_USE_();
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_NumIterationsType_IsValid(int value);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::RewriterConfig_NumIterationsType") int RewriterConfig_NumIterationsType_NumIterationsType_MIN();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::RewriterConfig_NumIterationsType") int RewriterConfig_NumIterationsType_NumIterationsType_MAX();
@Namespace("tensorflow") @MemberGetter public static native int RewriterConfig_NumIterationsType_NumIterationsType_ARRAYSIZE();

@Namespace("tensorflow") public static native @Cast("const google::protobuf::EnumDescriptor*") Pointer RewriterConfig_NumIterationsType_descriptor();
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_NumIterationsType_Parse(
    @StdString BytePointer name, @Cast("tensorflow::RewriterConfig_NumIterationsType*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_NumIterationsType_Parse(
    @StdString String name, @Cast("tensorflow::RewriterConfig_NumIterationsType*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_NumIterationsType_Parse(
    @StdString BytePointer name, @Cast("tensorflow::RewriterConfig_NumIterationsType*") int... value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_NumIterationsType_Parse(
    @StdString String name, @Cast("tensorflow::RewriterConfig_NumIterationsType*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_NumIterationsType_Parse(
    @StdString BytePointer name, @Cast("tensorflow::RewriterConfig_NumIterationsType*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_NumIterationsType_Parse(
    @StdString String name, @Cast("tensorflow::RewriterConfig_NumIterationsType*") int... value);
/** enum tensorflow::RewriterConfig_MemOptType */
public static final int
  RewriterConfig_MemOptType_DEFAULT_MEM_OPT = 0,
  RewriterConfig_MemOptType_NO_MEM_OPT = 1,
  RewriterConfig_MemOptType_MANUAL = 2,
  RewriterConfig_MemOptType_SWAPPING_HEURISTICS = 4,
  RewriterConfig_MemOptType_RECOMPUTATION_HEURISTICS = 5,
  RewriterConfig_MemOptType_SCHEDULING_HEURISTICS = 6,
  RewriterConfig_MemOptType_HEURISTICS = 3;
@Name("tensorflow::RewriterConfig_MemOptType_RewriterConfig_MemOptType_INT_MIN_SENTINEL_DO_NOT_USE_") public static native @MemberGetter int RewriterConfig_MemOptType_RewriterConfig_MemOptType_INT_MIN_SENTINEL_DO_NOT_USE_();
public static final int
  RewriterConfig_MemOptType_RewriterConfig_MemOptType_INT_MIN_SENTINEL_DO_NOT_USE_ = RewriterConfig_MemOptType_RewriterConfig_MemOptType_INT_MIN_SENTINEL_DO_NOT_USE_();
@Name("tensorflow::RewriterConfig_MemOptType_RewriterConfig_MemOptType_INT_MAX_SENTINEL_DO_NOT_USE_") public static native @MemberGetter int RewriterConfig_MemOptType_RewriterConfig_MemOptType_INT_MAX_SENTINEL_DO_NOT_USE_();
public static final int
  RewriterConfig_MemOptType_RewriterConfig_MemOptType_INT_MAX_SENTINEL_DO_NOT_USE_ = RewriterConfig_MemOptType_RewriterConfig_MemOptType_INT_MAX_SENTINEL_DO_NOT_USE_();
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_MemOptType_IsValid(int value);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::RewriterConfig_MemOptType") int RewriterConfig_MemOptType_MemOptType_MIN();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::RewriterConfig_MemOptType") int RewriterConfig_MemOptType_MemOptType_MAX();
@Namespace("tensorflow") @MemberGetter public static native int RewriterConfig_MemOptType_MemOptType_ARRAYSIZE();

@Namespace("tensorflow") public static native @Cast("const google::protobuf::EnumDescriptor*") Pointer RewriterConfig_MemOptType_descriptor();
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_MemOptType_Parse(
    @StdString BytePointer name, @Cast("tensorflow::RewriterConfig_MemOptType*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_MemOptType_Parse(
    @StdString String name, @Cast("tensorflow::RewriterConfig_MemOptType*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_MemOptType_Parse(
    @StdString BytePointer name, @Cast("tensorflow::RewriterConfig_MemOptType*") int... value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_MemOptType_Parse(
    @StdString String name, @Cast("tensorflow::RewriterConfig_MemOptType*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_MemOptType_Parse(
    @StdString BytePointer name, @Cast("tensorflow::RewriterConfig_MemOptType*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_MemOptType_Parse(
    @StdString String name, @Cast("tensorflow::RewriterConfig_MemOptType*") int... value);
// Targeting ../AutoParallelOptions.java


// Targeting ../ScopedAllocatorOptions.java


// -------------------------------------------------------------------
// Targeting ../RewriterConfig_CustomGraphOptimizer.java


// Targeting ../RewriterConfig.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// AutoParallelOptions

// bool enable = 1;




// int32 num_replicas = 2;




// -------------------------------------------------------------------

// ScopedAllocatorOptions

// repeated string enable_op = 1;
















// -------------------------------------------------------------------

// -------------------------------------------------------------------

// RewriterConfig_CustomGraphOptimizer

// string name = 1;












// map<string, .tensorflow.AttrValue> parameter_map = 2;




// -------------------------------------------------------------------

// RewriterConfig

// .tensorflow.RewriterConfig.Toggle layout_optimizer = 1;




// .tensorflow.RewriterConfig.Toggle constant_folding = 3;




// .tensorflow.RewriterConfig.Toggle shape_optimization = 13;




// .tensorflow.RewriterConfig.Toggle remapping = 14;




// .tensorflow.RewriterConfig.Toggle arithmetic_optimization = 7;




// .tensorflow.RewriterConfig.Toggle dependency_optimization = 8;




// .tensorflow.RewriterConfig.Toggle loop_optimization = 9;




// .tensorflow.RewriterConfig.Toggle function_optimization = 10;




// .tensorflow.RewriterConfig.Toggle debug_stripper = 11;




// bool disable_model_pruning = 2;




// .tensorflow.RewriterConfig.Toggle scoped_allocator_optimization = 15;




// .tensorflow.RewriterConfig.Toggle pin_to_host_optimization = 18;




// .tensorflow.RewriterConfig.Toggle implementation_selector = 22;




// .tensorflow.RewriterConfig.Toggle auto_mixed_precision = 23;




// bool disable_meta_optimizer = 19;




// .tensorflow.RewriterConfig.NumIterationsType meta_optimizer_iterations = 12;




// int32 min_graph_nodes = 17;




// .tensorflow.RewriterConfig.MemOptType memory_optimization = 4;




// string memory_optimizer_target_node_name_scope = 6;












// int64 meta_optimizer_timeout_ms = 20;




// .tensorflow.AutoParallelOptions auto_parallel = 5;








// bool fail_on_optimizer_errors = 21;




// .tensorflow.ScopedAllocatorOptions scoped_allocator_opts = 16;








// repeated string optimizers = 100;
















// repeated .tensorflow.RewriterConfig.CustomGraphOptimizer custom_optimizers = 200;








// .tensorflow.VerifierConfig inter_optimizer_verifier_config = 300;







// .tensorflow.VerifierConfig post_optimization_verifier_config = 301;







// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow




 /* namespace protobuf */
   /* namespace google */

// @@protoc_insertion_point(global_scope)

// #include <google/protobuf/port_undef.inc>
// #endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto


// Parsed from tensorflow/core/protobuf/config.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/protobuf/config.proto

// #ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto
// #define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto

// #include <limits>
// #include <string>

// #include <google/protobuf/port_def.inc>
// #if PROTOBUF_VERSION < 3008000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please update
// #error your headers.
// #endif
// #if 3008000 < PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/port_undef.inc>
// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/generated_message_reflection.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/map.h>  // IWYU pragma: export
// #include <google/protobuf/map_entry.h>
// #include <google/protobuf/map_field_inl.h>
// #include <google/protobuf/generated_enum_reflection.h>
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/cost_graph.pb.h"
// #include "tensorflow/core/framework/graph.pb.h"
// #include "tensorflow/core/framework/step_stats.pb.h"
// #include "tensorflow/core/protobuf/cluster.pb.h"
// #include "tensorflow/core/protobuf/debug.pb.h"
// #include "tensorflow/core/protobuf/rewriter_config.pb.h"
// @@protoc_insertion_point(includes)
// #include <google/protobuf/port_def.inc>
// #define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto
  // namespace internal
 /* namespace protobuf */
   /* namespace google */

// Internal implementation detail -- do not use these members.
  // namespace tensorflow



















 /* namespace protobuf */
   /* namespace google */

/** enum tensorflow::OptimizerOptions_Level */
public static final int
  OptimizerOptions_Level_L1 = 0,
  OptimizerOptions_Level_L0 = -1;
@Name("tensorflow::OptimizerOptions_Level_OptimizerOptions_Level_INT_MIN_SENTINEL_DO_NOT_USE_") public static native @MemberGetter int OptimizerOptions_Level_OptimizerOptions_Level_INT_MIN_SENTINEL_DO_NOT_USE_();
public static final int
  OptimizerOptions_Level_OptimizerOptions_Level_INT_MIN_SENTINEL_DO_NOT_USE_ = OptimizerOptions_Level_OptimizerOptions_Level_INT_MIN_SENTINEL_DO_NOT_USE_();
@Name("tensorflow::OptimizerOptions_Level_OptimizerOptions_Level_INT_MAX_SENTINEL_DO_NOT_USE_") public static native @MemberGetter int OptimizerOptions_Level_OptimizerOptions_Level_INT_MAX_SENTINEL_DO_NOT_USE_();
public static final int
  OptimizerOptions_Level_OptimizerOptions_Level_INT_MAX_SENTINEL_DO_NOT_USE_ = OptimizerOptions_Level_OptimizerOptions_Level_INT_MAX_SENTINEL_DO_NOT_USE_();
@Namespace("tensorflow") public static native @Cast("bool") boolean OptimizerOptions_Level_IsValid(int value);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::OptimizerOptions_Level") int OptimizerOptions_Level_Level_MIN();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::OptimizerOptions_Level") int OptimizerOptions_Level_Level_MAX();
@Namespace("tensorflow") @MemberGetter public static native int OptimizerOptions_Level_Level_ARRAYSIZE();

@Namespace("tensorflow") public static native @Cast("const google::protobuf::EnumDescriptor*") Pointer OptimizerOptions_Level_descriptor();
@Namespace("tensorflow") public static native @Cast("bool") boolean OptimizerOptions_Level_Parse(
    @StdString BytePointer name, @Cast("tensorflow::OptimizerOptions_Level*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean OptimizerOptions_Level_Parse(
    @StdString String name, @Cast("tensorflow::OptimizerOptions_Level*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean OptimizerOptions_Level_Parse(
    @StdString BytePointer name, @Cast("tensorflow::OptimizerOptions_Level*") int... value);
@Namespace("tensorflow") public static native @Cast("bool") boolean OptimizerOptions_Level_Parse(
    @StdString String name, @Cast("tensorflow::OptimizerOptions_Level*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean OptimizerOptions_Level_Parse(
    @StdString BytePointer name, @Cast("tensorflow::OptimizerOptions_Level*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean OptimizerOptions_Level_Parse(
    @StdString String name, @Cast("tensorflow::OptimizerOptions_Level*") int... value);
/** enum tensorflow::OptimizerOptions_GlobalJitLevel */
public static final int
  OptimizerOptions_GlobalJitLevel_DEFAULT = 0,
  OptimizerOptions_GlobalJitLevel_OFF = -1,
  OptimizerOptions_GlobalJitLevel_ON_1 = 1,
  OptimizerOptions_GlobalJitLevel_ON_2 = 2;
@Name("tensorflow::OptimizerOptions_GlobalJitLevel_OptimizerOptions_GlobalJitLevel_INT_MIN_SENTINEL_DO_NOT_USE_") public static native @MemberGetter int OptimizerOptions_GlobalJitLevel_OptimizerOptions_GlobalJitLevel_INT_MIN_SENTINEL_DO_NOT_USE_();
public static final int
  OptimizerOptions_GlobalJitLevel_OptimizerOptions_GlobalJitLevel_INT_MIN_SENTINEL_DO_NOT_USE_ = OptimizerOptions_GlobalJitLevel_OptimizerOptions_GlobalJitLevel_INT_MIN_SENTINEL_DO_NOT_USE_();
@Name("tensorflow::OptimizerOptions_GlobalJitLevel_OptimizerOptions_GlobalJitLevel_INT_MAX_SENTINEL_DO_NOT_USE_") public static native @MemberGetter int OptimizerOptions_GlobalJitLevel_OptimizerOptions_GlobalJitLevel_INT_MAX_SENTINEL_DO_NOT_USE_();
public static final int
  OptimizerOptions_GlobalJitLevel_OptimizerOptions_GlobalJitLevel_INT_MAX_SENTINEL_DO_NOT_USE_ = OptimizerOptions_GlobalJitLevel_OptimizerOptions_GlobalJitLevel_INT_MAX_SENTINEL_DO_NOT_USE_();
@Namespace("tensorflow") public static native @Cast("bool") boolean OptimizerOptions_GlobalJitLevel_IsValid(int value);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::OptimizerOptions_GlobalJitLevel") int OptimizerOptions_GlobalJitLevel_GlobalJitLevel_MIN();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::OptimizerOptions_GlobalJitLevel") int OptimizerOptions_GlobalJitLevel_GlobalJitLevel_MAX();
@Namespace("tensorflow") @MemberGetter public static native int OptimizerOptions_GlobalJitLevel_GlobalJitLevel_ARRAYSIZE();

@Namespace("tensorflow") public static native @Cast("const google::protobuf::EnumDescriptor*") Pointer OptimizerOptions_GlobalJitLevel_descriptor();
@Namespace("tensorflow") public static native @Cast("bool") boolean OptimizerOptions_GlobalJitLevel_Parse(
    @StdString BytePointer name, @Cast("tensorflow::OptimizerOptions_GlobalJitLevel*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean OptimizerOptions_GlobalJitLevel_Parse(
    @StdString String name, @Cast("tensorflow::OptimizerOptions_GlobalJitLevel*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean OptimizerOptions_GlobalJitLevel_Parse(
    @StdString BytePointer name, @Cast("tensorflow::OptimizerOptions_GlobalJitLevel*") int... value);
@Namespace("tensorflow") public static native @Cast("bool") boolean OptimizerOptions_GlobalJitLevel_Parse(
    @StdString String name, @Cast("tensorflow::OptimizerOptions_GlobalJitLevel*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean OptimizerOptions_GlobalJitLevel_Parse(
    @StdString BytePointer name, @Cast("tensorflow::OptimizerOptions_GlobalJitLevel*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean OptimizerOptions_GlobalJitLevel_Parse(
    @StdString String name, @Cast("tensorflow::OptimizerOptions_GlobalJitLevel*") int... value);
/** enum tensorflow::RunOptions_TraceLevel */
public static final int
  RunOptions_TraceLevel_NO_TRACE = 0,
  RunOptions_TraceLevel_SOFTWARE_TRACE = 1,
  RunOptions_TraceLevel_HARDWARE_TRACE = 2,
  RunOptions_TraceLevel_FULL_TRACE = 3;
@Name("tensorflow::RunOptions_TraceLevel_RunOptions_TraceLevel_INT_MIN_SENTINEL_DO_NOT_USE_") public static native @MemberGetter int RunOptions_TraceLevel_RunOptions_TraceLevel_INT_MIN_SENTINEL_DO_NOT_USE_();
public static final int
  RunOptions_TraceLevel_RunOptions_TraceLevel_INT_MIN_SENTINEL_DO_NOT_USE_ = RunOptions_TraceLevel_RunOptions_TraceLevel_INT_MIN_SENTINEL_DO_NOT_USE_();
@Name("tensorflow::RunOptions_TraceLevel_RunOptions_TraceLevel_INT_MAX_SENTINEL_DO_NOT_USE_") public static native @MemberGetter int RunOptions_TraceLevel_RunOptions_TraceLevel_INT_MAX_SENTINEL_DO_NOT_USE_();
public static final int
  RunOptions_TraceLevel_RunOptions_TraceLevel_INT_MAX_SENTINEL_DO_NOT_USE_ = RunOptions_TraceLevel_RunOptions_TraceLevel_INT_MAX_SENTINEL_DO_NOT_USE_();
@Namespace("tensorflow") public static native @Cast("bool") boolean RunOptions_TraceLevel_IsValid(int value);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::RunOptions_TraceLevel") int RunOptions_TraceLevel_TraceLevel_MIN();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::RunOptions_TraceLevel") int RunOptions_TraceLevel_TraceLevel_MAX();
@Namespace("tensorflow") @MemberGetter public static native int RunOptions_TraceLevel_TraceLevel_ARRAYSIZE();

@Namespace("tensorflow") public static native @Cast("const google::protobuf::EnumDescriptor*") Pointer RunOptions_TraceLevel_descriptor();
@Namespace("tensorflow") public static native @Cast("bool") boolean RunOptions_TraceLevel_Parse(
    @StdString BytePointer name, @Cast("tensorflow::RunOptions_TraceLevel*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RunOptions_TraceLevel_Parse(
    @StdString String name, @Cast("tensorflow::RunOptions_TraceLevel*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RunOptions_TraceLevel_Parse(
    @StdString BytePointer name, @Cast("tensorflow::RunOptions_TraceLevel*") int... value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RunOptions_TraceLevel_Parse(
    @StdString String name, @Cast("tensorflow::RunOptions_TraceLevel*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RunOptions_TraceLevel_Parse(
    @StdString BytePointer name, @Cast("tensorflow::RunOptions_TraceLevel*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RunOptions_TraceLevel_Parse(
    @StdString String name, @Cast("tensorflow::RunOptions_TraceLevel*") int... value);
// Targeting ../GPUOptions_Experimental_VirtualDevices.java


// Targeting ../GPUOptions_Experimental.java


// Targeting ../GPUOptions.java


// Targeting ../OptimizerOptions.java


// Targeting ../GraphOptions.java


// Targeting ../ThreadPoolOptionProto.java


// Targeting ../RPCOptions.java


// Targeting ../SessionMetadata.java


// -------------------------------------------------------------------
// Targeting ../ConfigProto_Experimental.java


// Targeting ../ConfigProto.java


// Targeting ../RunOptions_Experimental.java


// Targeting ../RunOptions.java


// Targeting ../RunMetadata_FunctionGraphs.java


// Targeting ../RunMetadata.java


// Targeting ../TensorConnection.java


// -------------------------------------------------------------------

// -------------------------------------------------------------------
// Targeting ../CallableOptions.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// GPUOptions_Experimental_VirtualDevices

// repeated float memory_limit_mb = 1;








// -------------------------------------------------------------------

// GPUOptions_Experimental

// repeated .tensorflow.GPUOptions.Experimental.VirtualDevices virtual_devices = 1;








// bool use_unified_memory = 2;




// int32 num_dev_to_dev_copy_streams = 3;




// string collective_ring_order = 4;












// bool timestamped_allocator = 5;




// int32 kernel_tracker_max_interval = 7;




// int32 kernel_tracker_max_bytes = 8;




// int32 kernel_tracker_max_pending = 9;




// -------------------------------------------------------------------

// GPUOptions

// double per_process_gpu_memory_fraction = 1;




// bool allow_growth = 4;




// string allocator_type = 2;












// int64 deferred_deletion_bytes = 3;




// string visible_device_list = 5;












// int32 polling_active_delay_usecs = 6;




// int32 polling_inactive_delay_msecs = 7;




// bool force_gpu_compatible = 8;




// .tensorflow.GPUOptions.Experimental experimental = 9;








// -------------------------------------------------------------------

// OptimizerOptions

// bool do_common_subexpression_elimination = 1;




// bool do_constant_folding = 2;




// int64 max_folded_constant_in_bytes = 6;




// bool do_function_inlining = 4;




// .tensorflow.OptimizerOptions.Level opt_level = 3;




// .tensorflow.OptimizerOptions.GlobalJitLevel global_jit_level = 5;




// -------------------------------------------------------------------

// GraphOptions

// bool enable_recv_scheduling = 2;




// .tensorflow.OptimizerOptions optimizer_options = 3;








// int64 build_cost_model = 4;




// int64 build_cost_model_after = 9;




// bool infer_shapes = 5;




// bool place_pruned_graph = 6;




// bool enable_bfloat16_sendrecv = 7;




// int32 timeline_step = 8;




// .tensorflow.RewriterConfig rewrite_options = 10;







// -------------------------------------------------------------------

// ThreadPoolOptionProto

// int32 num_threads = 1;




// string global_name = 2;












// -------------------------------------------------------------------

// RPCOptions

// bool use_rpc_for_inprocess_master = 1;




// string compression_algorithm = 2;












// int32 compression_level = 3;




// bool cache_rpc_response = 4;




// bool disable_session_connection_sharing = 5;




// -------------------------------------------------------------------

// SessionMetadata

// string name = 1;












// int64 version = 2;




// -------------------------------------------------------------------

// -------------------------------------------------------------------

// ConfigProto_Experimental

// string collective_group_leader = 1;












// string executor_type = 3;












// int32 recv_buf_max_chunk = 4;




// bool use_numa_affinity = 5;




// bool collective_deterministic_sequential_execution = 6;




// bool collective_nccl = 7;




// bool share_session_state_in_clusterspec_propagation = 8;




// bool disable_thread_spinning = 9;




// bool share_cluster_devices_in_session = 10;




// .tensorflow.SessionMetadata session_metadata = 11;








// bool optimize_for_static_graph = 12;




// -------------------------------------------------------------------

// ConfigProto

// map<string, int32> device_count = 1;





// int32 intra_op_parallelism_threads = 2;




// int32 inter_op_parallelism_threads = 5;




// bool use_per_session_threads = 9;




// repeated .tensorflow.ThreadPoolOptionProto session_inter_op_thread_pool = 12;








// int32 placement_period = 3;




// repeated string device_filters = 4;
















// .tensorflow.GPUOptions gpu_options = 6;








// bool allow_soft_placement = 7;




// bool log_device_placement = 8;




// .tensorflow.GraphOptions graph_options = 10;








// int64 operation_timeout_in_ms = 11;




// .tensorflow.RPCOptions rpc_options = 13;








// .tensorflow.ClusterDef cluster_def = 14;







// bool isolate_session_state = 15;




// .tensorflow.ConfigProto.Experimental experimental = 16;








// -------------------------------------------------------------------

// RunOptions_Experimental

// int64 collective_graph_key = 1;




// bool use_run_handler_pool = 2;




// -------------------------------------------------------------------

// RunOptions

// .tensorflow.RunOptions.TraceLevel trace_level = 1;




// int64 timeout_in_ms = 2;




// int32 inter_op_thread_pool = 3;




// bool output_partition_graphs = 5;




// .tensorflow.DebugOptions debug_options = 6;







// bool report_tensor_allocations_upon_oom = 7;




// .tensorflow.RunOptions.Experimental experimental = 8;








// -------------------------------------------------------------------

// RunMetadata_FunctionGraphs

// repeated .tensorflow.GraphDef partition_graphs = 1;







// .tensorflow.GraphDef pre_optimization_graph = 2;







// .tensorflow.GraphDef post_optimization_graph = 3;







// -------------------------------------------------------------------

// RunMetadata

// .tensorflow.StepStats step_stats = 1;







// .tensorflow.CostGraphDef cost_graph = 2;







// repeated .tensorflow.GraphDef partition_graphs = 3;







// repeated .tensorflow.RunMetadata.FunctionGraphs function_graphs = 4;








// -------------------------------------------------------------------

// TensorConnection

// string from_tensor = 1;












// string to_tensor = 2;












// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// CallableOptions

// repeated string feed = 1;
















// repeated string fetch = 2;
















// repeated string target = 3;
















// .tensorflow.RunOptions run_options = 4;








// repeated .tensorflow.TensorConnection tensor_connection = 5;








// map<string, string> feed_devices = 6;





// map<string, string> fetch_devices = 7;





// bool fetch_skip_sync = 8;




// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow




 /* namespace protobuf */
   /* namespace google */

// @@protoc_insertion_point(global_scope)

// #include <google/protobuf/port_undef.inc>
// #endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto


// Parsed from tensorflow/core/framework/cost_graph.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/cost_graph.proto

// #ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fcost_5fgraph_2eproto
// #define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fcost_5fgraph_2eproto

// #include <limits>
// #include <string>

// #include <google/protobuf/port_def.inc>
// #if PROTOBUF_VERSION < 3008000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please update
// #error your headers.
// #endif
// #if 3008000 < PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/port_undef.inc>
// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/generated_message_reflection.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/tensor_shape.pb.h"
// #include "tensorflow/core/framework/types.pb.h"
// @@protoc_insertion_point(includes)
// #include <google/protobuf/port_def.inc>
// #define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcore_2fframework_2fcost_5fgraph_2eproto
  // namespace internal
 /* namespace protobuf */
   /* namespace google */

// Internal implementation detail -- do not use these members.
  // namespace tensorflow




 /* namespace protobuf */
   /* namespace google */
// Targeting ../CostGraphDef_Node_InputInfo.java


// Targeting ../CostGraphDef_Node_OutputInfo.java


// Targeting ../CostGraphDef_Node.java


// Targeting ../CostGraphDef.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// CostGraphDef_Node_InputInfo

// int32 preceding_node = 1;




// int32 preceding_port = 2;




// -------------------------------------------------------------------

// CostGraphDef_Node_OutputInfo

// int64 size = 1;




// int64 alias_input_port = 2;




// .tensorflow.TensorShapeProto shape = 3;







// .tensorflow.DataType dtype = 4;




// -------------------------------------------------------------------

// CostGraphDef_Node

// string name = 1;












// string device = 2;












// int32 id = 3;




// repeated .tensorflow.CostGraphDef.Node.InputInfo input_info = 4;








// repeated .tensorflow.CostGraphDef.Node.OutputInfo output_info = 5;








// int64 temporary_memory_size = 6;




// int64 persistent_memory_size = 12;




// int64 host_temp_memory_size = 10 [deprecated = true];




// int64 device_temp_memory_size = 11 [deprecated = true];




// int64 device_persistent_memory_size = 16 [deprecated = true];




// int64 compute_cost = 9;




// int64 compute_time = 14;




// int64 memory_time = 15;




// bool is_final = 7;




// repeated int32 control_input = 8;








// bool inaccurate = 17;




// -------------------------------------------------------------------

// CostGraphDef

// repeated .tensorflow.CostGraphDef.Node node = 1;








// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #include <google/protobuf/port_undef.inc>
// #endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fcost_5fgraph_2eproto


// Parsed from tensorflow/core/framework/step_stats.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/step_stats.proto

// #ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto
// #define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto

// #include <limits>
// #include <string>

// #include <google/protobuf/port_def.inc>
// #if PROTOBUF_VERSION < 3008000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please update
// #error your headers.
// #endif
// #if 3008000 < PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/port_undef.inc>
// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/generated_message_reflection.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/map.h>  // IWYU pragma: export
// #include <google/protobuf/map_entry.h>
// #include <google/protobuf/map_field_inl.h>
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/allocation_description.pb.h"
// #include "tensorflow/core/framework/tensor_description.pb.h"
// @@protoc_insertion_point(includes)
// #include <google/protobuf/port_def.inc>
// #define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto
  // namespace internal
 /* namespace protobuf */
   /* namespace google */

// Internal implementation detail -- do not use these members.
  // namespace tensorflow








 /* namespace protobuf */
   /* namespace google */
// Targeting ../AllocationRecord.java


// Targeting ../AllocatorMemoryUsed.java


// Targeting ../NodeOutput.java


// Targeting ../MemoryStats.java


// Targeting ../NodeExecStats.java


// -------------------------------------------------------------------
// Targeting ../DeviceStepStats.java


// Targeting ../StepStats.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// AllocationRecord

// int64 alloc_micros = 1;




// int64 alloc_bytes = 2;




// -------------------------------------------------------------------

// AllocatorMemoryUsed

// string allocator_name = 1;












// int64 total_bytes = 2;




// int64 peak_bytes = 3;




// int64 live_bytes = 4;




// repeated .tensorflow.AllocationRecord allocation_records = 6;








// int64 allocator_bytes_in_use = 5;




// -------------------------------------------------------------------

// NodeOutput

// int32 slot = 1;




// .tensorflow.TensorDescription tensor_description = 3;







// -------------------------------------------------------------------

// MemoryStats

// int64 temp_memory_size = 1;




// int64 persistent_memory_size = 3;




// repeated int64 persistent_tensor_alloc_ids = 5;








// int64 device_temp_memory_size = 2 [deprecated = true];




// int64 device_persistent_memory_size = 4 [deprecated = true];




// repeated int64 device_persistent_tensor_alloc_ids = 6 [deprecated = true];








// -------------------------------------------------------------------

// NodeExecStats

// string node_name = 1;












// int64 all_start_micros = 2;




// int64 op_start_rel_micros = 3;




// int64 op_end_rel_micros = 4;




// int64 all_end_rel_micros = 5;




// repeated .tensorflow.AllocatorMemoryUsed memory = 6;








// repeated .tensorflow.NodeOutput output = 7;








// string timeline_label = 8;












// int64 scheduled_micros = 9;




// uint32 thread_id = 10;




// repeated .tensorflow.AllocationDescription referenced_tensor = 11;







// .tensorflow.MemoryStats memory_stats = 12;








// int64 all_start_nanos = 13;




// int64 op_start_rel_nanos = 14;




// int64 op_end_rel_nanos = 15;




// int64 all_end_rel_nanos = 16;




// int64 scheduled_nanos = 17;




// -------------------------------------------------------------------

// -------------------------------------------------------------------

// DeviceStepStats

// string device = 1;












// repeated .tensorflow.NodeExecStats node_stats = 2;








// map<uint32, string> thread_names = 3;





// -------------------------------------------------------------------

// StepStats

// repeated .tensorflow.DeviceStepStats dev_stats = 1;








// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #include <google/protobuf/port_undef.inc>
// #endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto


// Parsed from tensorflow/core/framework/versions.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/versions.proto

// #ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fversions_2eproto
// #define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fversions_2eproto

// #include <limits>
// #include <string>

// #include <google/protobuf/port_def.inc>
// #if PROTOBUF_VERSION < 3008000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please update
// #error your headers.
// #endif
// #if 3008000 < PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/port_undef.inc>
// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/generated_message_reflection.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/unknown_field_set.h>
// @@protoc_insertion_point(includes)
// #include <google/protobuf/port_def.inc>
// #define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcore_2fframework_2fversions_2eproto
  // namespace internal
 /* namespace protobuf */
   /* namespace google */

// Internal implementation detail -- do not use these members.
  // namespace tensorflow

 /* namespace protobuf */
   /* namespace google */
// Targeting ../VersionDef.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// VersionDef

// int32 producer = 1;




// int32 min_consumer = 2;




// repeated int32 bad_consumers = 3;








// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__

// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #include <google/protobuf/port_undef.inc>
// #endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fversions_2eproto


// Parsed from tensorflow/core/public/session_options.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_PUBLIC_SESSION_OPTIONS_H_
// #define TENSORFLOW_PUBLIC_SESSION_OPTIONS_H_

// #include <string>
// #include "tensorflow/core/platform/types.h"
// #include "tensorflow/core/protobuf/config.pb.h"
// Targeting ../SessionOptions.java



  // end namespace tensorflow

// #endif  // TENSORFLOW_PUBLIC_SESSION_OPTIONS_H_


// Parsed from tensorflow/core/lib/core/threadpool.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_LIB_CORE_THREADPOOL_H_
// #define TENSORFLOW_CORE_LIB_CORE_THREADPOOL_H_

// #include <functional>
// #include <memory>

// #include "tensorflow/core/lib/core/threadpool_interface.h"
// #include "tensorflow/core/platform/env.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/types.h"
// Targeting ../ThreadPoolDevice.java



// Targeting ../EigenEnvironment.java


// Targeting ../ThreadPool.java



  // namespace thread
  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_LIB_CORE_THREADPOOL_H_


// Parsed from tensorflow/core/framework/allocation_description.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/allocation_description.proto

// #ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fallocation_5fdescription_2eproto
// #define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fallocation_5fdescription_2eproto

// #include <limits>
// #include <string>

// #include <google/protobuf/port_def.inc>
// #if PROTOBUF_VERSION < 3008000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please update
// #error your headers.
// #endif
// #if 3008000 < PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/port_undef.inc>
// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/generated_message_reflection.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/unknown_field_set.h>
// @@protoc_insertion_point(includes)
// #include <google/protobuf/port_def.inc>
// #define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcore_2fframework_2fallocation_5fdescription_2eproto
  // namespace internal
 /* namespace protobuf */
   /* namespace google */

// Internal implementation detail -- do not use these members.
  // namespace tensorflow

 /* namespace protobuf */
   /* namespace google */
// Targeting ../AllocationDescription.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// AllocationDescription

// int64 requested_bytes = 1;




// int64 allocated_bytes = 2;




// string allocator_name = 3;












// int64 allocation_id = 4;




// bool has_single_reference = 5;




// uint64 ptr = 6;




// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__

// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #include <google/protobuf/port_undef.inc>
// #endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fallocation_5fdescription_2eproto


// Parsed from tensorflow/core/platform/tensor_coding.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// Helper routines for encoding/decoding tensor contents.
// #ifndef TENSORFLOW_PLATFORM_TENSOR_CODING_H_
// #define TENSORFLOW_PLATFORM_TENSOR_CODING_H_

// #include <string>
// #include "tensorflow/core/lib/core/refcount.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/platform/platform.h"
// #include "tensorflow/core/platform/protobuf.h"
// #include "tensorflow/core/platform/types.h"

// Store src contents in *out.  If backing memory for src is shared with *out,
// will ref obj during the call and will arrange to unref obj when no
// longer needed.
@Namespace("tensorflow::port") public static native void AssignRefCounted(@StringPiece BytePointer src, @Cast("tensorflow::core::RefCounted*") Pointer obj, @StdString @Cast({"char*", "std::string*"}) BytePointer out);
@Namespace("tensorflow::port") public static native void AssignRefCounted(@StringPiece String src, @Cast("tensorflow::core::RefCounted*") Pointer obj, @StdString @Cast({"char*", "std::string*"}) BytePointer out);

// Copy contents of src to dst[0,src.size()-1].
@Namespace("tensorflow::port") public static native void CopyToArray(@StdString BytePointer src, @Cast("char*") BytePointer dst);
@Namespace("tensorflow::port") public static native void CopyToArray(@StdString String src, @Cast("char*") ByteBuffer dst);
@Namespace("tensorflow::port") public static native void CopyToArray(@StdString BytePointer src, @Cast("char*") byte[] dst);
@Namespace("tensorflow::port") public static native void CopyToArray(@StdString String src, @Cast("char*") BytePointer dst);
@Namespace("tensorflow::port") public static native void CopyToArray(@StdString BytePointer src, @Cast("char*") ByteBuffer dst);
@Namespace("tensorflow::port") public static native void CopyToArray(@StdString String src, @Cast("char*") byte[] dst);

// Copy subrange [pos:(pos + n)) from src to dst. If pos >= src.size() the
// result is empty. If pos + n > src.size() the subrange [pos, size()) is
// copied.
@Namespace("tensorflow::port") public static native void CopySubrangeToArray(@StdString BytePointer src, @Cast("size_t") long pos, @Cast("size_t") long n,
                                @Cast("char*") BytePointer dst);
@Namespace("tensorflow::port") public static native void CopySubrangeToArray(@StdString String src, @Cast("size_t") long pos, @Cast("size_t") long n,
                                @Cast("char*") ByteBuffer dst);
@Namespace("tensorflow::port") public static native void CopySubrangeToArray(@StdString BytePointer src, @Cast("size_t") long pos, @Cast("size_t") long n,
                                @Cast("char*") byte[] dst);
@Namespace("tensorflow::port") public static native void CopySubrangeToArray(@StdString String src, @Cast("size_t") long pos, @Cast("size_t") long n,
                                @Cast("char*") BytePointer dst);
@Namespace("tensorflow::port") public static native void CopySubrangeToArray(@StdString BytePointer src, @Cast("size_t") long pos, @Cast("size_t") long n,
                                @Cast("char*") ByteBuffer dst);
@Namespace("tensorflow::port") public static native void CopySubrangeToArray(@StdString String src, @Cast("size_t") long pos, @Cast("size_t") long n,
                                @Cast("char*") byte[] dst);

// Store encoding of strings[0..n-1] in *out.
@Namespace("tensorflow::port") public static native void EncodeStringList(@StdString @Cast({"char*", "std::string*"}) BytePointer strings, @Cast("tensorflow::int64") long n, @StdString @Cast({"char*", "std::string*"}) BytePointer out);

// Decode n strings from src and store in strings[0..n-1].
// Returns true if successful, false on parse error.
@Namespace("tensorflow::port") public static native @Cast("bool") boolean DecodeStringList(@StdString BytePointer src, @StdString @Cast({"char*", "std::string*"}) BytePointer strings, @Cast("tensorflow::int64") long n);
@Namespace("tensorflow::port") public static native @Cast("bool") boolean DecodeStringList(@StdString String src, @StdString @Cast({"char*", "std::string*"}) BytePointer strings, @Cast("tensorflow::int64") long n);

// Assigns base[0..bytes-1] to *s
@Namespace("tensorflow::port") public static native void CopyFromArray(@StdString @Cast({"char*", "std::string*"}) BytePointer s, @Cast("const char*") BytePointer base, @Cast("size_t") long bytes);
@Namespace("tensorflow::port") public static native void CopyFromArray(@StdString @Cast({"char*", "std::string*"}) BytePointer s, String base, @Cast("size_t") long bytes);
// Targeting ../StringListEncoder.java


// Targeting ../StringListDecoder.java



@Namespace("tensorflow::port") public static native @MoveUniquePtr StringListEncoder NewStringListEncoder(@StdString @Cast({"char*", "std::string*"}) BytePointer out);
@Namespace("tensorflow::port") public static native @MoveUniquePtr StringListDecoder NewStringListDecoder(@StdString BytePointer in);
@Namespace("tensorflow::port") public static native @MoveUniquePtr StringListDecoder NewStringListDecoder(@StdString String in);

// #if defined(TENSORFLOW_PROTOBUF_USES_CORD)
// #endif  // defined(TENSORFLOW_PROTOBUF_USES_CORD)

  // namespace port
  // namespace tensorflow

// #endif  // TENSORFLOW_PLATFORM_TENSOR_CODING_H_


// Parsed from tensorflow/core/framework/resource_handle.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_FRAMEWORK_RESOURCE_HANDLE_H_
// #define TENSORFLOW_FRAMEWORK_RESOURCE_HANDLE_H_

// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.pb.h"
// #include "tensorflow/core/platform/tensor_coding.h"
// #include "tensorflow/core/platform/types.h"
// Targeting ../ResourceHandle.java



// For backwards compatibility for when this was a proto
@Namespace("tensorflow") public static native @StdString BytePointer ProtoDebugString(@Const @ByRef ResourceHandle handle);

// Encodes a list of ResourceHandle protos in the given StringListEncoder.
@Namespace("tensorflow") public static native void EncodeResourceHandleList(@Const ResourceHandle p, @Cast("tensorflow::int64") long n,
                              @MoveUniquePtr StringListEncoder e);

// Decodes a list of ResourceHandle protos from the given StringListDecoder.
@Namespace("tensorflow") public static native @Cast("bool") boolean DecodeResourceHandleList(@MoveUniquePtr StringListDecoder d,
                              ResourceHandle ps, @Cast("tensorflow::int64") long n);

  // namespace tensorflow

// #endif  // TENSORFLOW_FRAMEWORK_RESOURCE_HANDLE_H_


// Parsed from tensorflow/core/framework/allocator.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_ALLOCATOR_H_
// #define TENSORFLOW_CORE_FRAMEWORK_ALLOCATOR_H_

// #include <stdlib.h>

// #include <functional>
// #include <limits>

// #include "absl/strings/string_view.h"
// #include "absl/types/optional.h"
// #include "tensorflow/core/framework/numeric_types.h"
// #include "tensorflow/core/framework/type_traits.h"
// #include "tensorflow/core/platform/logging.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/numa.h"
// #include "tensorflow/core/platform/types.h"
// Targeting ../AllocationAttributes.java


// Targeting ../AllocatorStats.java


// Targeting ../Allocator.java


// Targeting ../AllocatorWrapper.java


// Targeting ../AllocatorAttributes.java



// Returns a trivial implementation of Allocator, which is a process singleton.
// Access through this function is only intended for use by restricted parts
// of the infrastructure.
@Namespace("tensorflow") public static native Allocator cpu_allocator_base();

// If available, calls ProcessState::GetCPUAllocator(numa_node).
// If not, falls back to cpu_allocator_base().
// Intended for use in contexts where ProcessState is not visible at
// compile time. Where ProcessState is visible, it's preferable to
// call it directly.
@Namespace("tensorflow") public static native Allocator cpu_allocator(int numa_node/*=port::kNUMANoAffinity*/);
@Namespace("tensorflow") public static native Allocator cpu_allocator();

// If 'enable' is true, the default CPU allocator implementation will collect
// AllocatorStats. By default, it's disabled.
@Namespace("tensorflow") public static native void EnableCPUAllocatorStats(@Cast("bool") boolean enable);
@Namespace("tensorflow") public static native @Cast("bool") boolean CPUAllocatorStatsEnabled();

// If 'enable' is true, the default CPU allocator implementation will collect
// full statistics. By default, it's disabled.
@Namespace("tensorflow") public static native void EnableCPUAllocatorFullStats(@Cast("bool") boolean enable);
@Namespace("tensorflow") public static native @Cast("bool") boolean CPUAllocatorFullStatsEnabled();
// Targeting ../SubAllocator.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_ALLOCATOR_H_


// Parsed from tensorflow/core/framework/tensor_shape.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/tensor_shape.proto

// #ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2ftensor_5fshape_2eproto
// #define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2ftensor_5fshape_2eproto

// #include <limits>
// #include <string>

// #include <google/protobuf/port_def.inc>
// #if PROTOBUF_VERSION < 3008000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please update
// #error your headers.
// #endif
// #if 3008000 < PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/port_undef.inc>
// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/generated_message_reflection.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/unknown_field_set.h>
// @@protoc_insertion_point(includes)
// #include <google/protobuf/port_def.inc>
// #define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcore_2fframework_2ftensor_5fshape_2eproto
  // namespace internal
 /* namespace protobuf */
   /* namespace google */

// Internal implementation detail -- do not use these members.
  // namespace tensorflow


 /* namespace protobuf */
   /* namespace google */
// Targeting ../TensorShapeProto_Dim.java


// Targeting ../TensorShapeProto.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// TensorShapeProto_Dim

// int64 size = 1;




// string name = 2;












// -------------------------------------------------------------------

// TensorShapeProto

// repeated .tensorflow.TensorShapeProto.Dim dim = 2;








// bool unknown_rank = 3;




// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #include <google/protobuf/port_undef.inc>
// #endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2ftensor_5fshape_2eproto


// Parsed from tensorflow/core/framework/types.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/types.proto

// #ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2ftypes_2eproto
// #define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2ftypes_2eproto

// #include <limits>
// #include <string>

// #include <google/protobuf/port_def.inc>
// #if PROTOBUF_VERSION < 3008000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please update
// #error your headers.
// #endif
// #if 3008000 < PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/port_undef.inc>
// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/generated_message_reflection.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/generated_enum_reflection.h>
// @@protoc_insertion_point(includes)
// #include <google/protobuf/port_def.inc>
// #define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcore_2fframework_2ftypes_2eproto
  // namespace internal
 /* namespace protobuf */
   /* namespace google */

// Internal implementation detail -- do not use these members.
 /* namespace protobuf */
   /* namespace google */

/** enum tensorflow::DataType */
public static final int
  DT_INVALID = 0,
  DT_FLOAT = 1,
  DT_DOUBLE = 2,
  DT_INT32 = 3,
  DT_UINT8 = 4,
  DT_INT16 = 5,
  DT_INT8 = 6,
  DT_STRING = 7,
  DT_COMPLEX64 = 8,
  DT_INT64 = 9,
  DT_BOOL = 10,
  DT_QINT8 = 11,
  DT_QUINT8 = 12,
  DT_QINT32 = 13,
  DT_BFLOAT16 = 14,
  DT_QINT16 = 15,
  DT_QUINT16 = 16,
  DT_UINT16 = 17,
  DT_COMPLEX128 = 18,
  DT_HALF = 19,
  DT_RESOURCE = 20,
  DT_VARIANT = 21,
  DT_UINT32 = 22,
  DT_UINT64 = 23,
  DT_FLOAT_REF = 101,
  DT_DOUBLE_REF = 102,
  DT_INT32_REF = 103,
  DT_UINT8_REF = 104,
  DT_INT16_REF = 105,
  DT_INT8_REF = 106,
  DT_STRING_REF = 107,
  DT_COMPLEX64_REF = 108,
  DT_INT64_REF = 109,
  DT_BOOL_REF = 110,
  DT_QINT8_REF = 111,
  DT_QUINT8_REF = 112,
  DT_QINT32_REF = 113,
  DT_BFLOAT16_REF = 114,
  DT_QINT16_REF = 115,
  DT_QUINT16_REF = 116,
  DT_UINT16_REF = 117,
  DT_COMPLEX128_REF = 118,
  DT_HALF_REF = 119,
  DT_RESOURCE_REF = 120,
  DT_VARIANT_REF = 121,
  DT_UINT32_REF = 122,
  DT_UINT64_REF = 123;
@Name("tensorflow::DataType_INT_MIN_SENTINEL_DO_NOT_USE_") public static native @MemberGetter int DataType_INT_MIN_SENTINEL_DO_NOT_USE_();
public static final int
  DataType_INT_MIN_SENTINEL_DO_NOT_USE_ = DataType_INT_MIN_SENTINEL_DO_NOT_USE_();
@Name("tensorflow::DataType_INT_MAX_SENTINEL_DO_NOT_USE_") public static native @MemberGetter int DataType_INT_MAX_SENTINEL_DO_NOT_USE_();
public static final int
  DataType_INT_MAX_SENTINEL_DO_NOT_USE_ = DataType_INT_MAX_SENTINEL_DO_NOT_USE_();
@Namespace("tensorflow") public static native @Cast("bool") boolean DataType_IsValid(int value);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::DataType") int DataType_MIN();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::DataType") int DataType_MAX();
@Namespace("tensorflow") @MemberGetter public static native int DataType_ARRAYSIZE();

@Namespace("tensorflow") public static native @Cast("const google::protobuf::EnumDescriptor*") Pointer DataType_descriptor();
@Namespace("tensorflow") public static native @Cast("bool") boolean DataType_Parse(
    @StdString BytePointer name, @Cast("tensorflow::DataType*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean DataType_Parse(
    @StdString String name, @Cast("tensorflow::DataType*") IntPointer value);
// ===================================================================


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__

// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow


 /* namespace protobuf */
   /* namespace google */

// @@protoc_insertion_point(global_scope)

// #include <google/protobuf/port_undef.inc>
// #endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2ftypes_2eproto


// Parsed from tensorflow/core/framework/resource_handle.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/resource_handle.proto

// #ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fresource_5fhandle_2eproto
// #define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fresource_5fhandle_2eproto

// #include <limits>
// #include <string>

// #include <google/protobuf/port_def.inc>
// #if PROTOBUF_VERSION < 3008000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please update
// #error your headers.
// #endif
// #if 3008000 < PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/port_undef.inc>
// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/generated_message_reflection.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/tensor_shape.pb.h"
// #include "tensorflow/core/framework/types.pb.h"
// @@protoc_insertion_point(includes)
// #include <google/protobuf/port_def.inc>
// #define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcore_2fframework_2fresource_5fhandle_2eproto
  // namespace internal
 /* namespace protobuf */
   /* namespace google */

// Internal implementation detail -- do not use these members.
  // namespace tensorflow


 /* namespace protobuf */
   /* namespace google */
// Targeting ../ResourceHandleProto_DtypeAndShape.java


// Targeting ../ResourceHandleProto.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// ResourceHandleProto_DtypeAndShape

// .tensorflow.DataType dtype = 1;




// .tensorflow.TensorShapeProto shape = 2;







// -------------------------------------------------------------------

// ResourceHandleProto

// string device = 1;












// string container = 2;












// string name = 3;












// uint64 hash_code = 4;




// string maybe_type_name = 5;












// repeated .tensorflow.ResourceHandleProto.DtypeAndShape dtypes_and_shapes = 6;








// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #include <google/protobuf/port_undef.inc>
// #endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fresource_5fhandle_2eproto


// Parsed from tensorflow/core/framework/tensor.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/tensor.proto

// #ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2ftensor_2eproto
// #define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2ftensor_2eproto

// #include <limits>
// #include <string>

// #include <google/protobuf/port_def.inc>
// #if PROTOBUF_VERSION < 3008000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please update
// #error your headers.
// #endif
// #if 3008000 < PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/port_undef.inc>
// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/generated_message_reflection.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/resource_handle.pb.h"
// #include "tensorflow/core/framework/tensor_shape.pb.h"
// #include "tensorflow/core/framework/types.pb.h"
// @@protoc_insertion_point(includes)
// #include <google/protobuf/port_def.inc>
// #define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcore_2fframework_2ftensor_2eproto
  // namespace internal
 /* namespace protobuf */
   /* namespace google */

// Internal implementation detail -- do not use these members.
  // namespace tensorflow


 /* namespace protobuf */
   /* namespace google */
// Targeting ../TensorProto.java


// Targeting ../VariantTensorDataProto.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// TensorProto

// .tensorflow.DataType dtype = 1;




// .tensorflow.TensorShapeProto tensor_shape = 2;







// int32 version_number = 3;




// bytes tensor_content = 4;












// repeated int32 half_val = 13 [packed = true];








// repeated float float_val = 5 [packed = true];








// repeated double double_val = 6 [packed = true];








// repeated int32 int_val = 7 [packed = true];








// repeated bytes string_val = 8;
















// repeated float scomplex_val = 9 [packed = true];








// repeated int64 int64_val = 10 [packed = true];








// repeated bool bool_val = 11 [packed = true];








// repeated double dcomplex_val = 12 [packed = true];








// repeated .tensorflow.ResourceHandleProto resource_handle_val = 14;







// repeated .tensorflow.VariantTensorDataProto variant_val = 15;








// repeated uint32 uint32_val = 16 [packed = true];








// repeated uint64 uint64_val = 17 [packed = true];








// -------------------------------------------------------------------

// VariantTensorDataProto

// string type_name = 1;












// bytes metadata = 2;












// repeated .tensorflow.TensorProto tensors = 3;








// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #include <google/protobuf/port_undef.inc>
// #endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2ftensor_2eproto


// Parsed from tensorflow/core/framework/tensor_description.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/tensor_description.proto

// #ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2ftensor_5fdescription_2eproto
// #define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2ftensor_5fdescription_2eproto

// #include <limits>
// #include <string>

// #include <google/protobuf/port_def.inc>
// #if PROTOBUF_VERSION < 3008000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please update
// #error your headers.
// #endif
// #if 3008000 < PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/port_undef.inc>
// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/generated_message_reflection.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/types.pb.h"
// #include "tensorflow/core/framework/tensor_shape.pb.h"
// #include "tensorflow/core/framework/allocation_description.pb.h"
// @@protoc_insertion_point(includes)
// #include <google/protobuf/port_def.inc>
// #define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcore_2fframework_2ftensor_5fdescription_2eproto
  // namespace internal
 /* namespace protobuf */
   /* namespace google */

// Internal implementation detail -- do not use these members.
  // namespace tensorflow

 /* namespace protobuf */
   /* namespace google */
// Targeting ../TensorDescription.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// TensorDescription

// .tensorflow.DataType dtype = 1;




// .tensorflow.TensorShapeProto shape = 2;







// .tensorflow.AllocationDescription allocation_description = 4;







// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__

// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #include <google/protobuf/port_undef.inc>
// #endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2ftensor_5fdescription_2eproto


// Parsed from tensorflow/core/framework/tensor_types.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_TENSOR_TYPES_H_
// #define TENSORFLOW_CORE_FRAMEWORK_TENSOR_TYPES_H_

// #include "third_party/eigen3/unsupported/Eigen/CXX11/Tensor"

// Helper to define Tensor types given that the scalar is of type T.

  // namespace tensorflow
// #endif  // TENSORFLOW_CORE_FRAMEWORK_TENSOR_TYPES_H_


// Parsed from tensorflow/core/framework/tensor_shape.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_TENSOR_SHAPE_H_
// #define TENSORFLOW_CORE_FRAMEWORK_TENSOR_SHAPE_H_

// #include <string>

// #include "third_party/eigen3/unsupported/Eigen/CXX11/Tensor"
// #include "tensorflow/core/framework/types.pb.h"
// #include "tensorflow/core/lib/core/errors.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// #include "tensorflow/core/lib/gtl/inlined_vector.h"
// #include "tensorflow/core/lib/strings/str_util.h"
// #include "tensorflow/core/platform/logging.h"

// START_SKIP_DOXYGEN
// Targeting ../TensorShapeRep.java


// Targeting ../TensorShapeBase.java



/** Outputs {@code TensorShapeBase} to {@code std::ostream}. */
// Targeting ../TensorShape.java


// Targeting ../TensorShapeDim.java


// Targeting ../TensorShapeIter.java


// Targeting ../TensorShapeUtils.java


// Targeting ../PartialTensorShape.java


// Targeting ../PartialTensorShapeUtils.java



// ----------------------------------------------------------------------------
// Template method implementation details below
// ----------------------------------------------------------------------------





// ----------------------------------------------------------------------------
// Inlining of some performance critical routines
// ----------------------------------------------------------------------------













// Declare explicit instantiations in .cc file
// Targeting ../DtypeAndPartialTensorShape.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_TENSOR_SHAPE_H_


// Parsed from tensorflow/core/framework/tensor_util.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_TENSOR_UTIL_H_
// #define TENSORFLOW_CORE_FRAMEWORK_TENSOR_UTIL_H_

// #include <algorithm>
// #include <vector>

// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor.pb.h"
// #include "tensorflow/core/framework/tensor_shape.pb.h"
// #include "tensorflow/core/framework/type_traits.h"
// #include "tensorflow/core/platform/protobuf.h"
// #include "tensorflow/core/platform/types.h"

// DeepCopy returns a tensor whose contents are a deep copy of the
// contents of 'other'.  This function is intended only for
// convenience, not speed.
//
// REQUIRES: 'other' must point to data stored in CPU memory.
// REQUIRES: 'other' must be a Tensor of a copy-able type if
//           'other' is not appropriately memory-aligned.
@Namespace("tensorflow::tensor") public static native @ByVal Tensor DeepCopy(@Const @ByRef Tensor other);

// Deep copies input to output.  This function is similar to above, but assumes
// that the memory for the output has already been allocated.
@Namespace("tensorflow::tensor") public static native void DeepCopy(@Const @ByRef Tensor input, Tensor output);

// Concatenates 'tensors' into a single tensor, along their 0th dimension.
//
// REQUIRES: All members of 'tensors' must have the same data type parameter.
// REQUIRES: Each member of 'tensors' must have at least one dimension.
// REQUIRES: Each member of 'tensors' must point to data stored in CPU memory.
// REQUIRES: Each member of 'tensors' must be a Tensor of a copy-able type if it
//           is not appropriately memory-aligned.
@Namespace("tensorflow::tensor") public static native @ByVal Status Concat(@Const @ByRef TensorVector tensors,
              Tensor result);

// Splits 'tensor' into 'sizes.size()' individual tensors, along the 0th
// dimension. The ith output tensor has 0th-dimension size 'sizes[i]'.
//
// REQUIRES: 'tensor' must have at least one dimension.
// REQUIRES: 'tensor.dim_size(0)' must equal the sum of the elements of 'sizes'.
// REQUIRES: 'tensor' must point to data stored in CPU memory.
// REQUIRES: 'tensor' must be a Tensor of a copy-able type if it is not
//           appropriately memory-aligned.
//
// Split() and Concat() are inverse operations.
@Namespace("tensorflow::tensor") public static native @ByVal Status Split(@Const @ByRef Tensor tensor, @Cast("tensorflow::int64*") @ArraySlice LongPointer sizes,
             TensorVector result);
@Namespace("tensorflow::tensor") public static native @ByVal Status Split(@Const @ByRef Tensor tensor, @Cast("tensorflow::int64*") @ArraySlice LongBuffer sizes,
             TensorVector result);
@Namespace("tensorflow::tensor") public static native @ByVal Status Split(@Const @ByRef Tensor tensor, @Cast("tensorflow::int64*") @ArraySlice long[] sizes,
             TensorVector result);
@Namespace("tensorflow::tensor::internal") public static native void SetTensorProtoShape(@Cast("size_t*") @StdVector SizeTPointer shape,
                         TensorShapeProto shape_proto);

// #define DEFINE_PROTO_FIELD_HELPER(TYPE, FIELDNAME)
//   template <>
//   class TensorProtoFieldHelper<TYPE> : public std::true_type {
//    public:
//     typedef decltype(
//         std::declval<TensorProto>().FIEDNAME##_val(0)) FieldType;
//     typedef decltype(
//         std::declval<TensorProto>().FIEDNAME##_val()) RepeatedFieldType;
//     typedef decltype(std::declval<TensorProto>().mutable_##FIELDNAME##_val())
//         MutableRepeatedFieldType;
//     static MutableRepeatedFieldType GetMutableField(TensorProto* proto) {
//       return proto->mutable_##FIELDNAME##_val();
//     }
//     static RepeatedFieldType& GetField(const TensorProto& proto) {
//       return proto.FIEDNAME##_val();
//     }
//   }

// The argument pairs in the following macro instantiations encode the
// mapping from C++ type ($1) to repeated field name "$2_val" used for storing
// values in TensorProto. See tensorflow/core/framework/tensor.proto.

// #undef DEFINE_PROTO_HELPER
// Targeting ../CopyHelper.java



// Overloads for complex types that store real and imaginary parts
// at indices 2*i and 2*i+1 in float or double field.

// Helper class to extract and insert values into TensorProto represented as
// repeated fields.

// Specialization for string.

  // namespace internal

// Creates a 'TensorProto' with specified shape and values.
// The dtype and a field to represent data values of the returned 'TensorProto'
// are determined based on type of the 'values' parameter.

// Converts values in tensor to run-length encoded compressed form.
//
// The elements of a tensor can be stored in a TensorProto in one of the
// following two forms:
// 1. As a raw byte string in the field `tensor_content` containing the
//    serialized in-memory representation of the tensor.
// 2. As values of a repeated field depending on the datatype, e.g. that
//    values of a DT_FLOAT tensor would be stored in the repeated field
//    `float_val`.
// Storage scheme 2 may use a simple form of run-length encoding to compress
// data: If the values contains a tail of identical values, the repeated field
// will be truncated such that the number of values in the repeated field is
// less than the number of elements implied by the field`tensor_shape`. The
// original tensor can be recovered by repeating the final value in the repeated
// field.
//
// The TensorProto will be compressed if a) the tensor contains at least
// min_num_elements elements and b) the compressed tensor proto is would be at
// most the size of the original tensor proto divided by min_compression_ratio.
//
// Returns true if the tensor was compressed.
@Namespace("tensorflow::tensor") public static native @Cast("bool") boolean CompressTensorProtoInPlace(@Cast("tensorflow::int64") long min_num_elements,
                                float min_compression_ratio,
                                TensorProto tensor);

@Namespace("tensorflow::tensor") public static native @Cast("bool") boolean CompressTensorProtoInPlace(TensorProto tensor);

  // namespace tensor
  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_TENSOR_UTIL_H_


// Parsed from tensorflow/core/framework/tensor_reference.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_FRAMEWORK_TENSOR_REFERENCE_H_
// #define TENSORFLOW_FRAMEWORK_TENSOR_REFERENCE_H_

// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/lib/gtl/inlined_vector.h"
// Targeting ../TensorReference.java



  // namespace tensorflow

// #endif  // TENSORFLOW_FRAMEWORK_TENSOR_REFERENCE_H_


// Parsed from tensorflow/core/framework/tensor.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_TENSOR_H_
// #define TENSORFLOW_CORE_FRAMEWORK_TENSOR_H_

// #include <cstdint>
// #include <type_traits>
// #include "third_party/eigen3/unsupported/Eigen/CXX11/Tensor"
// #include "tensorflow/core/framework/allocator.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/tensor_types.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/framework/types.pb.h"
// #include "tensorflow/core/lib/core/refcount.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/lib/gtl/inlined_vector.h"
// #include "tensorflow/core/platform/logging.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/mem.h"
// #include "tensorflow/core/platform/types.h"
// Targeting ../TensorCord.java


// Targeting ../Var.java


@Namespace("tensorflow::batch_util") public static native @ByVal Status CopyElementToSlice(@ByVal Tensor element, Tensor parent, @Cast("tensorflow::int64") long index);
@Namespace("tensorflow::batch_util") public static native @ByVal Status MaybeMoveSliceToElement(Tensor parent, Tensor element, @Cast("tensorflow::int64") long index);

// Targeting ../TensorBuffer.java


// Targeting ../Tensor.java



// Implementation details

// START_SKIP_DOXYGEN

































// #ifdef USE_TSTRING

// #endif  // USE_TSTRING



// #ifdef USE_TSTRING

// #endif  // USE_TSTRING

















// A packed representation for a single scalar value of type `T`, and a
// `TensorBuffer` implementation that describes (and manages the lifetime of)
// that value.

/* static */






// END_SKIP_DOXYGEN

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_TENSOR_H_


// Parsed from tensorflow/core/framework/attr_value.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/attr_value.proto

// #ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fattr_5fvalue_2eproto
// #define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fattr_5fvalue_2eproto

// #include <limits>
// #include <string>

// #include <google/protobuf/port_def.inc>
// #if PROTOBUF_VERSION < 3008000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please update
// #error your headers.
// #endif
// #if 3008000 < PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/port_undef.inc>
// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/generated_message_reflection.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/map.h>  // IWYU pragma: export
// #include <google/protobuf/map_entry.h>
// #include <google/protobuf/map_field_inl.h>
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/tensor.pb.h"
// #include "tensorflow/core/framework/tensor_shape.pb.h"
// #include "tensorflow/core/framework/types.pb.h"
// @@protoc_insertion_point(includes)
// #include <google/protobuf/port_def.inc>
// #define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcore_2fframework_2fattr_5fvalue_2eproto
  // namespace internal
 /* namespace protobuf */
   /* namespace google */

// Internal implementation detail -- do not use these members.
  // namespace tensorflow




 /* namespace protobuf */
   /* namespace google */
// Targeting ../AttrValue_ListValue.java


// Targeting ../AttrValue.java


// -------------------------------------------------------------------
// Targeting ../NameAttrList.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// AttrValue_ListValue

// repeated bytes s = 2;
















// repeated int64 i = 3 [packed = true];








// repeated float f = 4 [packed = true];








// repeated bool b = 5 [packed = true];








// repeated .tensorflow.DataType type = 6 [packed = true];








// repeated .tensorflow.TensorShapeProto shape = 7;







// repeated .tensorflow.TensorProto tensor = 8;







// repeated .tensorflow.NameAttrList func = 9;








// -------------------------------------------------------------------

// AttrValue

// bytes s = 2;














// int64 i = 3;






// float f = 4;






// bool b = 5;






// .tensorflow.DataType type = 6;






// .tensorflow.TensorShapeProto shape = 7;








// .tensorflow.TensorProto tensor = 8;








// .tensorflow.AttrValue.ListValue list = 1;









// .tensorflow.NameAttrList func = 10;









// string placeholder = 9;

















// -------------------------------------------------------------------

// -------------------------------------------------------------------

// NameAttrList

// string name = 1;












// map<string, .tensorflow.AttrValue> attr = 2;





// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #include <google/protobuf/port_undef.inc>
// #endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fattr_5fvalue_2eproto


// Parsed from tensorflow/core/framework/node_def.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/node_def.proto

// #ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fnode_5fdef_2eproto
// #define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fnode_5fdef_2eproto

// #include <limits>
// #include <string>

// #include <google/protobuf/port_def.inc>
// #if PROTOBUF_VERSION < 3008000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please update
// #error your headers.
// #endif
// #if 3008000 < PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/port_undef.inc>
// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/generated_message_reflection.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/map.h>  // IWYU pragma: export
// #include <google/protobuf/map_entry.h>
// #include <google/protobuf/map_field_inl.h>
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/attr_value.pb.h"
// @@protoc_insertion_point(includes)
// #include <google/protobuf/port_def.inc>
// #define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcore_2fframework_2fnode_5fdef_2eproto
  // namespace internal
 /* namespace protobuf */
   /* namespace google */

// Internal implementation detail -- do not use these members.
  // namespace tensorflow



 /* namespace protobuf */
   /* namespace google */

// ===================================================================
// Targeting ../NodeDef_ExperimentalDebugInfo.java


// Targeting ../NodeDef.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// -------------------------------------------------------------------

// NodeDef_ExperimentalDebugInfo

// repeated string original_node_names = 1;
















// repeated string original_func_names = 2;
















// -------------------------------------------------------------------

// NodeDef

// string name = 1;












// string op = 2;












// repeated string input = 3;
















// string device = 4;












// map<string, .tensorflow.AttrValue> attr = 5;




// .tensorflow.NodeDef.ExperimentalDebugInfo experimental_debug_info = 6;








// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #include <google/protobuf/port_undef.inc>
// #endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fnode_5fdef_2eproto


// Parsed from tensorflow/core/framework/api_def.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/api_def.proto

// #ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fapi_5fdef_2eproto
// #define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fapi_5fdef_2eproto

// #include <limits>
// #include <string>

// #include <google/protobuf/port_def.inc>
// #if PROTOBUF_VERSION < 3008000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please update
// #error your headers.
// #endif
// #if 3008000 < PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/port_undef.inc>
// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/generated_message_reflection.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/generated_enum_reflection.h>
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/attr_value.pb.h"
// @@protoc_insertion_point(includes)
// #include <google/protobuf/port_def.inc>
// #define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcore_2fframework_2fapi_5fdef_2eproto
  // namespace internal
 /* namespace protobuf */
   /* namespace google */

// Internal implementation detail -- do not use these members.
  // namespace tensorflow





 /* namespace protobuf */
   /* namespace google */

/** enum tensorflow::ApiDef_Visibility */
public static final int
  ApiDef_Visibility_DEFAULT_VISIBILITY = 0,
  ApiDef_Visibility_VISIBLE = 1,
  ApiDef_Visibility_SKIP = 2,
  ApiDef_Visibility_HIDDEN = 3;
@Name("tensorflow::ApiDef_Visibility_ApiDef_Visibility_INT_MIN_SENTINEL_DO_NOT_USE_") public static native @MemberGetter int ApiDef_Visibility_ApiDef_Visibility_INT_MIN_SENTINEL_DO_NOT_USE_();
public static final int
  ApiDef_Visibility_ApiDef_Visibility_INT_MIN_SENTINEL_DO_NOT_USE_ = ApiDef_Visibility_ApiDef_Visibility_INT_MIN_SENTINEL_DO_NOT_USE_();
@Name("tensorflow::ApiDef_Visibility_ApiDef_Visibility_INT_MAX_SENTINEL_DO_NOT_USE_") public static native @MemberGetter int ApiDef_Visibility_ApiDef_Visibility_INT_MAX_SENTINEL_DO_NOT_USE_();
public static final int
  ApiDef_Visibility_ApiDef_Visibility_INT_MAX_SENTINEL_DO_NOT_USE_ = ApiDef_Visibility_ApiDef_Visibility_INT_MAX_SENTINEL_DO_NOT_USE_();
@Namespace("tensorflow") public static native @Cast("bool") boolean ApiDef_Visibility_IsValid(int value);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::ApiDef_Visibility") int ApiDef_Visibility_Visibility_MIN();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::ApiDef_Visibility") int ApiDef_Visibility_Visibility_MAX();
@Namespace("tensorflow") @MemberGetter public static native int ApiDef_Visibility_Visibility_ARRAYSIZE();

@Namespace("tensorflow") public static native @Cast("const google::protobuf::EnumDescriptor*") Pointer ApiDef_Visibility_descriptor();
@Namespace("tensorflow") public static native @Cast("bool") boolean ApiDef_Visibility_Parse(
    @StdString BytePointer name, @Cast("tensorflow::ApiDef_Visibility*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean ApiDef_Visibility_Parse(
    @StdString String name, @Cast("tensorflow::ApiDef_Visibility*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean ApiDef_Visibility_Parse(
    @StdString BytePointer name, @Cast("tensorflow::ApiDef_Visibility*") int... value);
@Namespace("tensorflow") public static native @Cast("bool") boolean ApiDef_Visibility_Parse(
    @StdString String name, @Cast("tensorflow::ApiDef_Visibility*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean ApiDef_Visibility_Parse(
    @StdString BytePointer name, @Cast("tensorflow::ApiDef_Visibility*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean ApiDef_Visibility_Parse(
    @StdString String name, @Cast("tensorflow::ApiDef_Visibility*") int... value);
// Targeting ../ApiDef_Endpoint.java


// Targeting ../ApiDef_Arg.java


// Targeting ../ApiDef_Attr.java


// Targeting ../ApiDef.java


// Targeting ../ApiDefs.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// ApiDef_Endpoint

// string name = 1;












// bool deprecated = 3;




// int32 deprecation_version = 4;




// -------------------------------------------------------------------

// ApiDef_Arg

// string name = 1;












// string rename_to = 2;












// string description = 3;












// -------------------------------------------------------------------

// ApiDef_Attr

// string name = 1;












// string rename_to = 2;












// .tensorflow.AttrValue default_value = 3;







// string description = 4;












// -------------------------------------------------------------------

// ApiDef

// string graph_op_name = 1;












// string deprecation_message = 12;












// int32 deprecation_version = 13;




// .tensorflow.ApiDef.Visibility visibility = 2;




// repeated .tensorflow.ApiDef.Endpoint endpoint = 3;








// repeated .tensorflow.ApiDef.Arg in_arg = 4;








// repeated .tensorflow.ApiDef.Arg out_arg = 5;








// repeated string arg_order = 11;
















// repeated .tensorflow.ApiDef.Attr attr = 6;








// string summary = 7;












// string description = 8;












// string description_prefix = 9;












// string description_suffix = 10;












// -------------------------------------------------------------------

// ApiDefs

// repeated .tensorflow.ApiDef op = 1;








// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow


 /* namespace protobuf */
   /* namespace google */

// @@protoc_insertion_point(global_scope)

// #include <google/protobuf/port_undef.inc>
// #endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fapi_5fdef_2eproto


// Parsed from tensorflow/core/framework/op_def.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/op_def.proto

// #ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fop_5fdef_2eproto
// #define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fop_5fdef_2eproto

// #include <limits>
// #include <string>

// #include <google/protobuf/port_def.inc>
// #if PROTOBUF_VERSION < 3008000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please update
// #error your headers.
// #endif
// #if 3008000 < PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/port_undef.inc>
// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/generated_message_reflection.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/attr_value.pb.h"
// #include "tensorflow/core/framework/types.pb.h"
// @@protoc_insertion_point(includes)
// #include <google/protobuf/port_def.inc>
// #define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcore_2fframework_2fop_5fdef_2eproto
  // namespace internal
 /* namespace protobuf */
   /* namespace google */

// Internal implementation detail -- do not use these members.
  // namespace tensorflow





 /* namespace protobuf */
   /* namespace google */
// Targeting ../OpDef_ArgDef.java


// Targeting ../OpDef_AttrDef.java


// Targeting ../OpDef.java


// Targeting ../OpDeprecation.java


// Targeting ../OpList.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// OpDef_ArgDef

// string name = 1;












// string description = 2;












// .tensorflow.DataType type = 3;




// string type_attr = 4;












// string number_attr = 5;












// string type_list_attr = 6;












// bool is_ref = 16;




// -------------------------------------------------------------------

// OpDef_AttrDef

// string name = 1;












// string type = 2;












// .tensorflow.AttrValue default_value = 3;







// string description = 4;












// bool has_minimum = 5;




// int64 minimum = 6;




// .tensorflow.AttrValue allowed_values = 7;







// -------------------------------------------------------------------

// OpDef

// string name = 1;












// repeated .tensorflow.OpDef.ArgDef input_arg = 2;








// repeated .tensorflow.OpDef.ArgDef output_arg = 3;








// repeated string control_output = 20;
















// repeated .tensorflow.OpDef.AttrDef attr = 4;








// .tensorflow.OpDeprecation deprecation = 8;








// string summary = 5;












// string description = 6;












// bool is_commutative = 18;




// bool is_aggregate = 16;




// bool is_stateful = 17;




// bool allows_uninitialized_input = 19;




// -------------------------------------------------------------------

// OpDeprecation

// int32 version = 1;




// string explanation = 2;












// -------------------------------------------------------------------

// OpList

// repeated .tensorflow.OpDef op = 1;








// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #include <google/protobuf/port_undef.inc>
// #endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fop_5fdef_2eproto


// Parsed from tensorflow/core/framework/function.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/function.proto

// #ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2ffunction_2eproto
// #define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2ffunction_2eproto

// #include <limits>
// #include <string>

// #include <google/protobuf/port_def.inc>
// #if PROTOBUF_VERSION < 3008000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please update
// #error your headers.
// #endif
// #if 3008000 < PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/port_undef.inc>
// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/generated_message_reflection.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/map.h>  // IWYU pragma: export
// #include <google/protobuf/map_entry.h>
// #include <google/protobuf/map_field_inl.h>
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/attr_value.pb.h"
// #include "tensorflow/core/framework/node_def.pb.h"
// #include "tensorflow/core/framework/op_def.pb.h"
// @@protoc_insertion_point(includes)
// #include <google/protobuf/port_def.inc>
// #define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcore_2fframework_2ffunction_2eproto
  // namespace internal
 /* namespace protobuf */
   /* namespace google */

// Internal implementation detail -- do not use these members.
  // namespace tensorflow









 /* namespace protobuf */
   /* namespace google */
// Targeting ../FunctionDefLibrary.java


// -------------------------------------------------------------------

// -------------------------------------------------------------------
// Targeting ../FunctionDef_ArgAttrs.java


// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------
// Targeting ../FunctionDef.java


// Targeting ../GradientDef.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// FunctionDefLibrary

// repeated .tensorflow.FunctionDef function = 1;








// repeated .tensorflow.GradientDef gradient = 2;








// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// FunctionDef_ArgAttrs

// map<string, .tensorflow.AttrValue> attr = 1;




// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// FunctionDef

// .tensorflow.OpDef signature = 1;







// map<string, .tensorflow.AttrValue> attr = 5;




// map<uint32, .tensorflow.FunctionDef.ArgAttrs> arg_attr = 7;





// repeated .tensorflow.NodeDef node_def = 3;







// map<string, string> ret = 4;





// map<string, string> control_ret = 6;





// -------------------------------------------------------------------

// GradientDef

// string function_name = 1;












// string gradient_func = 2;












// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #include <google/protobuf/port_undef.inc>
// #endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2ffunction_2eproto


// Parsed from tensorflow/core/framework/graph.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/graph.proto

// #ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fgraph_2eproto
// #define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fgraph_2eproto

// #include <limits>
// #include <string>

// #include <google/protobuf/port_def.inc>
// #if PROTOBUF_VERSION < 3008000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please update
// #error your headers.
// #endif
// #if 3008000 < PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/port_undef.inc>
// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/generated_message_reflection.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/node_def.pb.h"
// #include "tensorflow/core/framework/function.pb.h"
// #include "tensorflow/core/framework/versions.pb.h"
// @@protoc_insertion_point(includes)
// #include <google/protobuf/port_def.inc>
// #define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcore_2fframework_2fgraph_2eproto
  // namespace internal
 /* namespace protobuf */
   /* namespace google */

// Internal implementation detail -- do not use these members.
  // namespace tensorflow

 /* namespace protobuf */
   /* namespace google */
// Targeting ../GraphDef.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// GraphDef

// repeated .tensorflow.NodeDef node = 1;







// .tensorflow.VersionDef versions = 4;







// int32 version = 3 [deprecated = true];




// .tensorflow.FunctionDefLibrary library = 2;







// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__

// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #include <google/protobuf/port_undef.inc>
// #endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fgraph_2eproto


// Parsed from tensorflow/core/framework/session_state.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_SESSION_STATE_H_
// #define TENSORFLOW_CORE_FRAMEWORK_SESSION_STATE_H_

// #include <string>
// #include <unordered_map>
// #include <vector>

// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/lib/core/errors.h"
// #include "tensorflow/core/platform/mutex.h"
// Targeting ../SessionState.java


// Targeting ../TensorStore.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_SESSION_STATE_H_


// Parsed from tensorflow/core/framework/types.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_TYPES_H_
// #define TENSORFLOW_CORE_FRAMEWORK_TYPES_H_

// #include <map>
// #include <set>
// #include <string>

// #include "third_party/eigen3/unsupported/Eigen/CXX11/Tensor"
// Disable clang-format to prevent 'FixedPoint' header from being included
// before 'Tensor' header on which it depends.
// clang-format off
// #include "third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint"
// clang-format on
// #include "tensorflow/core/framework/bfloat16.h"
// #include "tensorflow/core/framework/numeric_types.h"
// #include "tensorflow/core/framework/resource_handle.h"
// #include "tensorflow/core/framework/types.pb.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// #include "tensorflow/core/lib/gtl/inlined_vector.h"
// #include "tensorflow/core/platform/logging.h"
// #include "tensorflow/core/platform/types.h"
// Targeting ../Variant.java



// MemoryType is used to describe whether input or output Tensors of
// an OpKernel should reside in "Host memory" (e.g., CPU memory) or
// "Device" Memory (CPU memory for CPU devices, GPU memory for GPU
// devices).
/** enum tensorflow::MemoryType */
public static final int
  DEVICE_MEMORY = 0,
  HOST_MEMORY = 1;
// Targeting ../DeviceType.java


@Namespace("tensorflow") public static native @Cast("std::ostream*") @ByRef @Name("operator <<") Pointer shiftLeft(@Cast("std::ostream*") @ByRef Pointer os, @Const @ByRef DeviceType d);

// Convenient constants that can be passed to a DeviceType constructor
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer DEVICE_DEFAULT();  // "DEFAULT"
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer DEVICE_CPU();      // "CPU"
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer DEVICE_GPU();      // "GPU"
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer DEVICE_SYCL();
// Targeting ../DeviceName.java



// #if (defined(GOOGLE_CUDA) && GOOGLE_CUDA) ||
//     (defined(TENSORFLOW_USE_ROCM) && TENSORFLOW_USE_ROCM)
// #endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM

// #ifdef TENSORFLOW_USE_SYCL
// #endif  // TENSORFLOW_USE_SYCL

// Convert the enums to strings for errors:
@Namespace("tensorflow") public static native @StdString BytePointer DataTypeString(@Cast("tensorflow::DataType") int dtype);
@Namespace("tensorflow") public static native @StdString BytePointer DeviceTypeString(@Const @ByRef DeviceType device_type);
@Namespace("tensorflow") public static native @StdString BytePointer DataTypeSliceString(@ByVal @Cast("const tensorflow::DataTypeSlice*") DataTypeVector dtypes);
@Namespace("tensorflow") public static native @StdString BytePointer DataTypeVectorString(@Const @ByRef DataTypeVector dtypes);
// Targeting ../DataTypeSet.java



// If "sp" names a valid type, store it in "*dt" and return true.  Otherwise,
// return false.
@Namespace("tensorflow") public static native @Cast("bool") boolean DataTypeFromString(@StringPiece BytePointer sp, @Cast("tensorflow::DataType*") IntPointer dt);
@Namespace("tensorflow") public static native @Cast("bool") boolean DataTypeFromString(@StringPiece String sp, @Cast("tensorflow::DataType*") IntPointer dt);

@Namespace("tensorflow") public static native @Const @ByVal DataTypeSet ToSet(@Cast("tensorflow::DataType") int dt);

// DT_FLOAT + kDataTypeRefOffset == DT_FLOAT_REF, etc.
/** enum tensorflow:: */
public static final int kDataTypeRefOffset = 100;
@Namespace("tensorflow") public static native @Cast("bool") boolean IsRefType(@Cast("tensorflow::DataType") int dtype);
@Namespace("tensorflow") public static native @Cast("tensorflow::DataType") int MakeRefType(@Cast("tensorflow::DataType") int dtype);
@Namespace("tensorflow") public static native @Cast("tensorflow::DataType") int RemoveRefType(@Cast("tensorflow::DataType") int dtype);
@Namespace("tensorflow") public static native @Cast("tensorflow::DataType") int BaseType(@Cast("tensorflow::DataType") int dtype);

// Returns true if the actual type is the same as or ref of the expected type.
@Namespace("tensorflow") public static native @Cast("bool") boolean TypesCompatible(@Cast("tensorflow::DataType") int expected, @Cast("tensorflow::DataType") int actual);

// Does not include _ref types.
@Namespace("tensorflow") @MemberGetter public static native @Const @ByRef DataTypeSet kAllTypes();
@Namespace("tensorflow") public static native @Const @ByRef DataTypeSet AllTypes();

// #if !defined(IS_MOBILE_PLATFORM) || defined(SUPPORT_SELECTIVE_REGISTRATION)

// Types that support '<' and '>'.
@Namespace("tensorflow") @MemberGetter public static native @Const @ByRef DataTypeSet kRealNumberTypes();
@Namespace("tensorflow") public static native @Const @ByVal DataTypeSet RealNumberTypes();

// Return the list of all numeric types.
// Includes complex and quantized types.
// NOTE: On Android, we only include the float and int32 types for now.
@Namespace("tensorflow") @MemberGetter public static native @Const @ByRef DataTypeSet kNumberTypes();


@Namespace("tensorflow") @MemberGetter public static native @Const @ByRef DataTypeSet kQuantizedTypes();


// Types that support '<' and '>', including quantized types.
@Namespace("tensorflow") @MemberGetter public static native @Const @ByRef DataTypeSet kRealAndQuantizedTypes();


// #elif defined(__ANDROID_TYPES_FULL__)




// #else  // defined(IS_MOBILE_PLATFORM) && !defined(__ANDROID_TYPES_FULL__)




// #endif  // defined(IS_MOBILE_PLATFORM)

// Validates type T for whether it is a supported DataType.

// DataTypeToEnum<T>::v() and DataTypeToEnum<T>::value are the DataType
// constants for T, e.g. DataTypeToEnum<float>::v() is DT_FLOAT.  // Specializations below

// EnumToDataType<VALUE>::Type is the type for DataType constant VALUE, e.g.
// EnumToDataType<DT_FLOAT>::Type is float.  // Specializations below

// Template specialization for both DataTypeToEnum and EnumToDataType.
// #define MATCH_TYPE_AND_ENUM(TYPE, ENUM)
//   template <>
//   struct DataTypeToEnum<TYPE> {
//     static DataType v() { return ENUM; }
//     static DataType ref() { return MakeRefType(ENUM); }
//     static constexpr DataType value = ENUM;
//   };
//   template <>
//   struct IsValidDataType<TYPE> {
//     static constexpr bool value = true;
//   };
//   template <>
//   struct EnumToDataType<ENUM> {
//     typedef TYPE Type;
//   }
// Targeting ../DataTypeToEnum.java


// Targeting ../IsValidDataType.java


// Targeting ../EnumToDataType.java



// #undef MATCH_TYPE_AND_ENUM

// All types not specialized are marked invalid.

// Extra validity checking; not part of public API.

// TODO(jeff): Maybe unify this with Tensor::CanUseDMA, or the underlying
// is_simple<T> in tensor.cc (and possible choose a more general name?)
@Namespace("tensorflow") @MemberGetter public static native @Const @ByRef DataTypeSet kDataTypesCanUseMemcpy();
@Namespace("tensorflow") public static native @Cast("bool") boolean DataTypeCanUseMemcpy(@Cast("tensorflow::DataType") int dt);

// Returns true iff 'dt' is a real, non-quantized floating point type.
@Namespace("tensorflow") @MemberGetter public static native @Const @ByRef DataTypeSet kDataTypeIsFloating();
@Namespace("tensorflow") public static native @Cast("bool") boolean DataTypeIsFloating(@Cast("tensorflow::DataType") int dt);

// Returns true iff 'dt' is a complex type.
@Namespace("tensorflow") @MemberGetter public static native @Const @ByRef DataTypeSet kDataTypeIsComplex();
@Namespace("tensorflow") public static native @Cast("bool") boolean DataTypeIsComplex(@Cast("tensorflow::DataType") int dt);

@Namespace("tensorflow") public static native @Cast("bool") boolean DataTypeIsQuantized(@Cast("tensorflow::DataType") int dt);

// Is the dtype nonquantized integral?
@Namespace("tensorflow") @MemberGetter public static native @Const @ByRef DataTypeSet kDataTypeIsInteger();
@Namespace("tensorflow") public static native @Cast("bool") boolean DataTypeIsInteger(@Cast("tensorflow::DataType") int dt);

// Is the dtype a signed integral type?
@Namespace("tensorflow") @MemberGetter public static native @Const @ByRef DataTypeSet kDataTypeIsSigned();
@Namespace("tensorflow") public static native @Cast("bool") boolean DataTypeIsSigned(@Cast("tensorflow::DataType") int dt);

// Is the dtype an unsigned integral type?
@Namespace("tensorflow") @MemberGetter public static native @Const @ByRef DataTypeSet kDataTypeIsUnsigned();
@Namespace("tensorflow") public static native @Cast("bool") boolean DataTypeIsUnsigned(@Cast("tensorflow::DataType") int dt);

// Returns a 0 on failure
@Namespace("tensorflow") public static native int DataTypeSize(@Cast("tensorflow::DataType") int dt);

// Returns HOST_MEMORY if `dtype` is always on host or is a DT_INT32,
// DEVICE_MEMORY otherwise.
@Namespace("tensorflow") public static native @Cast("tensorflow::MemoryType") int MTypeFromDType(@Cast("const tensorflow::DataType") int dtype);

// Returns HOST_MEMORY if `dtype` is always on host, DEVICE_MEMORY otherwise.
// The reason we have MTypeFromDType() and MTypeFromDTypeIntsOnDevice(): for
// GPUs, we would like to keep int operations on host for performance concerns.
// But for TPUs (and other devices), int operations are placed on device.
@Namespace("tensorflow") public static native @Cast("tensorflow::MemoryType") int MTypeFromDTypeIntsOnDevice(@Cast("const tensorflow::DataType") int dtype);

// Types that always sit on host: DT_STRING, DT_STRING_REF, DT_RESOURCE.
// For DT_RESOURCE, the handle always sits on host (even if the underlying
// object has device-allocated resources).
@Namespace("tensorflow") public static native @Cast("bool") boolean DataTypeAlwaysOnHost(@Cast("tensorflow::DataType") int dt);

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_TYPES_H_


// Parsed from tensorflow/core/framework/control_flow.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_CONTROL_FLOW_H_
// #define TENSORFLOW_CORE_FRAMEWORK_CONTROL_FLOW_H_

// #include "tensorflow/core/lib/hash/hash.h"
// #include "tensorflow/core/platform/logging.h"
// #include "tensorflow/core/platform/types.h"

@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::uint64") long kIllegalFrameId();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::int64") long kIllegalIterId();
// Targeting ../FrameAndIter.java


// Targeting ../FrameAndIterHash.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_CONTROL_FLOW_H_


// Parsed from tensorflow/core/framework/kernel_def.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/kernel_def.proto

// #ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fkernel_5fdef_2eproto
// #define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fkernel_5fdef_2eproto

// #include <limits>
// #include <string>

// #include <google/protobuf/port_def.inc>
// #if PROTOBUF_VERSION < 3008000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please update
// #error your headers.
// #endif
// #if 3008000 < PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/port_undef.inc>
// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/generated_message_reflection.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/attr_value.pb.h"
// @@protoc_insertion_point(includes)
// #include <google/protobuf/port_def.inc>
// #define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcore_2fframework_2fkernel_5fdef_2eproto
  // namespace internal
 /* namespace protobuf */
   /* namespace google */

// Internal implementation detail -- do not use these members.
  // namespace tensorflow



 /* namespace protobuf */
   /* namespace google */
// Targeting ../KernelDef_AttrConstraint.java


// Targeting ../KernelDef.java


// Targeting ../KernelList.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// KernelDef_AttrConstraint

// string name = 1;












// .tensorflow.AttrValue allowed_values = 2;







// -------------------------------------------------------------------

// KernelDef

// string op = 1;












// string device_type = 2;












// repeated .tensorflow.KernelDef.AttrConstraint constraint = 3;








// repeated string host_memory_arg = 4;
















// string label = 5;












// int32 priority = 6;




// -------------------------------------------------------------------

// KernelList

// repeated .tensorflow.KernelDef kernel = 1;








// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #include <google/protobuf/port_undef.inc>
// #endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fkernel_5fdef_2eproto


// Parsed from tensorflow/core/framework/kernel_def_builder.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_KERNEL_DEF_BUILDER_H_
// #define TENSORFLOW_CORE_FRAMEWORK_KERNEL_DEF_BUILDER_H_

// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/types.h"

// Forward declare proto so that kernels don't need to depend on it
// Targeting ../KernelDefBuilder.java



// IMPLEMENTATION



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_KERNEL_DEF_BUILDER_H_


// Parsed from tensorflow/core/framework/tracking_allocator.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_TRACKING_ALLOCATOR_H_
// #define TENSORFLOW_CORE_FRAMEWORK_TRACKING_ALLOCATOR_H_

// #include <unordered_map>
// #include "tensorflow/core/framework/allocator.h"
// #include "tensorflow/core/lib/gtl/inlined_vector.h"
// #include "tensorflow/core/platform/mutex.h"
// #include "tensorflow/core/platform/thread_annotations.h"
// #include "tensorflow/core/platform/types.h"
// Targeting ../AllocRecord.java


// Targeting ../TrackingAllocator.java



  // end namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_TRACKING_ALLOCATOR_H_


// Parsed from tensorflow/core/framework/op_kernel.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_OP_KERNEL_H_
// #define TENSORFLOW_CORE_FRAMEWORK_OP_KERNEL_H_

// #include <atomic>
// #include <functional>
// #include <unordered_set>
// #include <utility>
// #include <vector>

// #include "tensorflow/core/framework/allocator.h"
// #include "tensorflow/core/framework/cancellation.h"
// #include "tensorflow/core/framework/control_flow.h"
// #include "tensorflow/core/framework/device_base.h"
// #include "tensorflow/core/framework/graph.pb.h"
// #include "tensorflow/core/framework/kernel_def.pb.h"
// #include "tensorflow/core/framework/kernel_def_builder.h"
// #include "tensorflow/core/framework/node_def.pb.h"
// #include "tensorflow/core/framework/node_def_util.h"
// #include "tensorflow/core/framework/op.h"  // TODO(b/62899350): Remove
// #include "tensorflow/core/framework/rendezvous.h"
// #include "tensorflow/core/framework/selective_registration.h"
// #include "tensorflow/core/framework/session_state.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/tensor_shape.pb.h"  // TODO(b/62899350): Remove
// #include "tensorflow/core/framework/tracking_allocator.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/framework/types.pb.h"
// #include "tensorflow/core/framework/unique_tensor_references.h"
// #include "tensorflow/core/lib/core/errors.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// #include "tensorflow/core/lib/gtl/manual_constructor.h"
// #include "tensorflow/core/platform/env.h"
// #include "tensorflow/core/platform/logging.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/mutex.h"
// #include "tensorflow/core/platform/profile_utils/cpu_utils.h"
// #include "tensorflow/core/platform/thread_annotations.h"
// #include "tensorflow/core/platform/types.h"
// #include "tensorflow/core/protobuf/config.pb.h"
// Targeting ../GpuDevice.java


// Targeting ../SyclDevice.java



// Targeting ../TensorSliceReaderCacheWrapper.java


  // namespace checkpoint  // declared below
// Targeting ../ResourceMgr.java


// Targeting ../ScopedStepContainer.java


// Targeting ../StepStatsCollectorInterface.java


// Targeting ../OpKernel.java


// Targeting ../AsyncOpKernel.java


// Targeting ../PersistentTensor.java


// Targeting ../OpKernelConstruction.java



// TODO(mrry): Consider converting to a random_access_iterator, and upgrading
// tensorflow::gtl::iterator_range to make the below container classes
// unnecessary.
// Targeting ../OpInputList.java


// Targeting ../OpMutableInputList.java


// Targeting ../OpOutputList.java


// Targeting ../TensorValue.java


// Targeting ../GraphCollector.java


// Targeting ../OpKernelContext.java







// #ifdef TENSORFLOW_USE_SYCL
// #endif

// Register your OpKernel by specifying the Op's name, the device the
// kernel runs on, any type attr constraints for this kernel, any
// host-memory args, and the class to instantiate.  Examples:
//
//  // A kernel that supports all types.
//  REGISTER_KERNEL_BUILDER(Name("Save").Device(DEVICE_CPU), SaveOp);
//
//  // The following are equivalent ways of specifying that the kernel only
//  // works if the "T" type attr is set to DT_FLOAT.
//  REGISTER_KERNEL_BUILDER(
//      Name("Sub").Device(DEVICE_CPU).TypeConstraint<float>("T"),
//      SubOp<float>);
//  // (You would then repeat this for every type supported by "Sub".)
//
//  // This form allows you to specify a list of types as the constraint.
//  REGISTER_KERNEL_BUILDER(Name("Sub")
//                              .Device(DEVICE_CPU)
//                              .TypeConstraint("T", {DT_FLOAT}),
//                          SubOp<float>);
//
//  // A kernel that expects one of the input tensors in host memory.
//  REGISTER_KERNEL_BUILDER(
//      Name("Reshape").Device(DEVICE_GPU).HostMemory("shape"), ReshapeOp);
//
// See kernel_def_builder for details.

// Instantiate an OpKernel that has been registered.  Returns nullptr
// if no operation for that type of device / input signature combination
// (and a NOT_FOUND *status), or there is an error in construction (and
// an INVALID_ARGUMENT *status).  Otherwise, the caller takes ownership
// of the returned pointer.
// EXPECTED USAGE: unique_ptr<OpKernel> op = CreateOpKernel(...);
// REQUIRES: def has all attrs specified (e.g. using AddDefaultsToNodeDef()).
@Namespace("tensorflow") public static native @MoveUniquePtr OpKernel CreateOpKernel(@ByVal DeviceType device_type,
                                         DeviceBase device,
                                         Allocator allocator,
                                         @Const @ByRef NodeDef def,
                                         int graph_def_version, Status status);
@Namespace("tensorflow") public static native @ByVal Status CreateOpKernel(@ByVal DeviceType device_type, DeviceBase device,
                      Allocator allocator, FunctionLibraryRuntime flib,
                      @Const @ByRef NodeDef def, int graph_def_version,
                      @Cast("tensorflow::OpKernel**") PointerPointer kernel);
@Namespace("tensorflow") public static native @ByVal Status CreateOpKernel(@ByVal DeviceType device_type, DeviceBase device,
                      Allocator allocator, FunctionLibraryRuntime flib,
                      @Const @ByRef NodeDef def, int graph_def_version,
                      @ByPtrPtr OpKernel kernel);

// Returns into 'device_types' the subset of prioritized_types that this
// binary has registered for the given NodeDef.
//
// REQUIRES: * 'device_types' is not nullptr.
//           * def has all attrs specified (e.g. using AddDefaultsToNodeDef()).
@Namespace("tensorflow") public static native @ByVal Status SupportedDeviceTypesForNode(
    @StdVector DeviceType prioritized_types, @Const @ByRef NodeDef def,
    @Cast("tensorflow::PrioritizedDeviceTypeVector*") TensorValueVector device_types,
    @Const DeviceNameUtils.ParsedName local_address_spec/*=nullptr*/);
@Namespace("tensorflow") public static native @ByVal Status SupportedDeviceTypesForNode(
    @StdVector DeviceType prioritized_types, @Const @ByRef NodeDef def,
    @Cast("tensorflow::PrioritizedDeviceTypeVector*") TensorValueVector device_types);

// Returns a message with a description of the kernels registered for op
// `op_name`.
@Namespace("tensorflow") public static native @StdString BytePointer KernelsRegisteredForOp(@StringPiece BytePointer op_name);
@Namespace("tensorflow") public static native @StdString String KernelsRegisteredForOp(@StringPiece String op_name);

// Call once after Op registration has completed.
@Namespace("tensorflow") public static native @ByVal Status ValidateKernelRegistrations(@Const @ByRef OpRegistryInterface op_registry);
// Targeting ../RegisterKernelName.java


// Targeting ../RegisterKernelSystemName.java



  // namespace system

  // namespace register_kernel

// #define REGISTER_KERNEL_BUILDER(kernel_builder, ...)
//   REGISTER_KERNEL_BUILDER_UNIQ_HELPER(__COUNTER__, kernel_builder, __VA_ARGS__)

// #define REGISTER_KERNEL_BUILDER_UNIQ_HELPER(ctr, kernel_builder, ...)
//   REGISTER_KERNEL_BUILDER_UNIQ(ctr, kernel_builder, __VA_ARGS__)

// #define REGISTER_KERNEL_BUILDER_UNIQ(ctr, kernel_builder, ...)
//   constexpr bool should_register_##ctr##__flag =
//       SHOULD_REGISTER_OP_KERNEL(#__VA_ARGS__);
//   static ::tensorflow::kernel_factory::OpKernelRegistrar
//       registrar__body__##ctr##__object(
//           should_register_##ctr##__flag
//               ? ::tensorflow::register_kernel::kernel_builder.Bid()
//               : nullptr,
//           #__VA_ARGS__,
//           [](::tensorflow::OpKernelConstruction* context)
//               -> ::tensorflow::OpKernel* {
//             return new __VA_ARGS__(context);
//           });

// The `REGISTER_SYSTEM_KERNEL_BUILDER()` macro acts as
// `REGISTER_KERNEL_BUILDER()` except that the kernel is registered
// unconditionally even when selective registration is used.
// #define REGISTER_SYSTEM_KERNEL_BUILDER(kernel_builder, ...)
//   REGISTER_SYSTEM_KERNEL_BUILDER_UNIQ_HELPER(__COUNTER__, kernel_builder,
//                                              __VA_ARGS__)

// #define REGISTER_SYSTEM_KERNEL_BUILDER_UNIQ_HELPER(ctr, kernel_builder, ...)
//   REGISTER_SYSTEM_KERNEL_BUILDER_UNIQ(ctr, kernel_builder, __VA_ARGS__)

// #define REGISTER_SYSTEM_KERNEL_BUILDER_UNIQ(ctr, kernel_builder, ...)
//   static ::tensorflow::kernel_factory::OpKernelRegistrar
//       registrar__body__##ctr##__object(
//           ::tensorflow::register_kernel::system::kernel_builder.Bid(),
//           #__VA_ARGS__,
//           [](::tensorflow::OpKernelConstruction* context)
//               -> ::tensorflow::OpKernel* {
//             return new __VA_ARGS__(context);
//           });

// Checks whether a given kernel is registered on device_type.
@Namespace("tensorflow") public static native @Cast("bool") boolean KernelDefAvailable(@Const @ByRef DeviceType device_type, @Const @ByRef NodeDef node_def);

// If node of node_name, experimental_debug_info, node_op, node_device and
// node_attrs has a corresponding kernel registered on device_type, returns OK
// and fill in the kernel def and kernel_class_name. <def> and
// <kernel_class_name> may be null.
@Namespace("tensorflow") public static native @ByVal Status FindKernelDef(
    @Const @ByRef DeviceType device_type, @StringPiece BytePointer node_name,
    @Cast("bool") boolean has_experimental_debug_info,
    @Const @ByRef NodeDef_ExperimentalDebugInfo experimental_debug_info,
    @StringPiece BytePointer node_op, @StringPiece BytePointer node_device, @ByVal AttrSlice node_attrs,
    @Cast("const tensorflow::KernelDef**") PointerPointer def, @StdString @Cast({"char*", "std::string*"}) BytePointer kernel_class_name);
@Namespace("tensorflow") public static native @ByVal Status FindKernelDef(
    @Const @ByRef DeviceType device_type, @StringPiece BytePointer node_name,
    @Cast("bool") boolean has_experimental_debug_info,
    @Const @ByRef NodeDef_ExperimentalDebugInfo experimental_debug_info,
    @StringPiece BytePointer node_op, @StringPiece BytePointer node_device, @ByVal AttrSlice node_attrs,
    @Const @ByPtrPtr KernelDef def, @StdString @Cast({"char*", "std::string*"}) BytePointer kernel_class_name);
@Namespace("tensorflow") public static native @ByVal Status FindKernelDef(
    @Const @ByRef DeviceType device_type, @StringPiece String node_name,
    @Cast("bool") boolean has_experimental_debug_info,
    @Const @ByRef NodeDef_ExperimentalDebugInfo experimental_debug_info,
    @StringPiece String node_op, @StringPiece String node_device, @ByVal AttrSlice node_attrs,
    @Const @ByPtrPtr KernelDef def, @StdString @Cast({"char*", "std::string*"}) BytePointer kernel_class_name);

// If node_def has a corresponding kernel registered on device_type,
// returns OK and fill in the kernel def and kernel_class_name. <def> and
// <kernel_class_name> may be null.
@Namespace("tensorflow") public static native @ByVal Status FindKernelDef(@Const @ByRef DeviceType device_type, @Const @ByRef NodeDef node_def,
                     @Cast("const tensorflow::KernelDef**") PointerPointer def, @StdString @Cast({"char*", "std::string*"}) BytePointer kernel_class_name);
@Namespace("tensorflow") public static native @ByVal Status FindKernelDef(@Const @ByRef DeviceType device_type, @Const @ByRef NodeDef node_def,
                     @Const @ByPtrPtr KernelDef def, @StdString @Cast({"char*", "std::string*"}) BytePointer kernel_class_name);

// Writes a list of all registered kernels to LOG(INFO), to help users debug
// missing kernel errors.
@Namespace("tensorflow") public static native void LogAllRegisteredKernels();

// Gets a list of all registered kernels.
@Namespace("tensorflow") public static native @ByVal KernelList GetAllRegisteredKernels();

// Gets a list of all registered kernels for which predicate returns true
@Namespace("tensorflow") public static native @ByVal KernelList GetFilteredRegisteredKernels(
    @Const @ByRef KernelDefPredicateFn predicate);

// Gets a list of all registered kernels for a given op
@Namespace("tensorflow") public static native @ByVal KernelList GetRegisteredKernelsForOp(@StringPiece BytePointer op_name);
@Namespace("tensorflow") public static native @ByVal KernelList GetRegisteredKernelsForOp(@StringPiece String op_name);
// Targeting ../OpKernelFactory.java


// Targeting ../OpKernelRegistrar.java



  // namespace kernel_factory

// -----------------------------------------------------------------------------
// Template and inline method implementations, please ignore

















// no input if tensor == nullptr.





































// Targeting ../XlaOpKernelContext.java


@Namespace("tensorflow") public static native void CheckNotInComputeAsync(XlaOpKernelContext arg0, @Cast("const char*") BytePointer arg1);
@Namespace("tensorflow") public static native void CheckNotInComputeAsync(XlaOpKernelContext arg0, String arg1);
@Namespace("tensorflow") public static native void CheckNotInComputeAsync(OpKernelConstruction arg0, @Cast("const char*") BytePointer arg1);
@Namespace("tensorflow") public static native void CheckNotInComputeAsync(OpKernelConstruction arg0, String arg1);
@Namespace("tensorflow") public static native void CheckNotInComputeAsync(OpKernelContext ctx,
                            @Cast("const char*") BytePointer correct_macro_name);
@Namespace("tensorflow") public static native void CheckNotInComputeAsync(OpKernelContext ctx,
                            String correct_macro_name);

// #define OP_REQUIRES(CTX, EXP, STATUS)
//   do {
//     if (!TF_PREDICT_TRUE(EXP)) {
//       CheckNotInComputeAsync((CTX), "OP_REQUIRES_ASYNC");
//       (CTX)->CtxFailure(__FILE__, __LINE__, (STATUS));
//       return;
//     }
//   } while (0)

// #define OP_REQUIRES_OK(CTX, ...)
//   do {
//     ::tensorflow::Status _s(__VA_ARGS__);
//     if (!TF_PREDICT_TRUE(_s.ok())) {
//       CheckNotInComputeAsync((CTX), "OP_REQUIRES_OK_ASYNC");
//       (CTX)->CtxFailureWithWarning(__FILE__, __LINE__, _s);
//       return;
//     }
//   } while (0)

// #define OP_REQUIRES_ASYNC(CTX, EXP, STATUS, CALLBACK)
//   do {
//     if (!TF_PREDICT_TRUE(EXP)) {
//       (CTX)->CtxFailure(__FILE__, __LINE__, (STATUS));
//       (CALLBACK)();
//       return;
//     }
//   } while (0)

// #define OP_REQUIRES_OK_ASYNC(CTX, STATUS, CALLBACK)
//   do {
//     ::tensorflow::Status _s(STATUS);
//     if (!TF_PREDICT_TRUE(_s.ok())) {
//       (CTX)->CtxFailureWithWarning(__FILE__, __LINE__, _s);
//       (CALLBACK)();
//       return;
//     }
//   } while (0)

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_OP_KERNEL_H_


// Parsed from tensorflow/core/framework/op_segment.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_FRAMEWORK_OP_SEGMENT_H_
// #define TENSORFLOW_FRAMEWORK_OP_SEGMENT_H_

// #include <string>
// #include <unordered_map>

// #include "tensorflow/core/framework/op_kernel.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/mutex.h"
// #include "tensorflow/core/platform/thread_annotations.h"
// #include "tensorflow/core/platform/types.h"
// Targeting ../OpSegment.java



  // end namespace tensorflow

// #endif  // TENSORFLOW_FRAMEWORK_OP_SEGMENT_H_


// Parsed from tensorflow/core/framework/shape_inference.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
// #ifndef TENSORFLOW_CORE_FRAMEWORK_SHAPE_INFERENCE_H_
// #define TENSORFLOW_CORE_FRAMEWORK_SHAPE_INFERENCE_H_

// #include <vector>

// #include "tensorflow/core/framework/node_def_util.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/lib/core/errors.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/gtl/inlined_vector.h"
// #include "tensorflow/core/platform/macros.h"
// Targeting ../ShapeRefinerTest.java


// Targeting ../GraphProperties.java


// Targeting ../SymbolicShapeManager.java


  // namespace grappler
// Targeting ../Dimension.java


// Targeting ../DimensionHandle.java


// Targeting ../Shape.java


// Targeting ../ShapeHandle.java


// Targeting ../DimensionOrConstant.java


// Targeting ../ShapeAndType.java


// Targeting ../InferenceContext.java



// -----------------------------------------------------------------------------
// Template and inline method implementations, please ignore













  // namespace shape_inference
  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_SHAPE_INFERENCE_H_


// Parsed from tensorflow/core/framework/partial_tensor_shape.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_PARTIAL_TENSOR_SHAPE_H_
// #define TENSORFLOW_CORE_FRAMEWORK_PARTIAL_TENSOR_SHAPE_H_

// TODO(irving): Remove this forwarding header
// #include "tensorflow/core/framework/tensor_shape.h"

// #endif  // TENSORFLOW_CORE_FRAMEWORK_PARTIAL_TENSOR_SHAPE_H_


// Parsed from tensorflow/core/framework/device_attributes.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/device_attributes.proto

// #ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fdevice_5fattributes_2eproto
// #define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fdevice_5fattributes_2eproto

// #include <limits>
// #include <string>

// #include <google/protobuf/port_def.inc>
// #if PROTOBUF_VERSION < 3008000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please update
// #error your headers.
// #endif
// #if 3008000 < PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/port_undef.inc>
// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/generated_message_reflection.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/unknown_field_set.h>
// @@protoc_insertion_point(includes)
// #include <google/protobuf/port_def.inc>
// #define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcore_2fframework_2fdevice_5fattributes_2eproto
  // namespace internal
 /* namespace protobuf */
   /* namespace google */

// Internal implementation detail -- do not use these members.
  // namespace tensorflow




 /* namespace protobuf */
   /* namespace google */
// Targeting ../InterconnectLink.java


// Targeting ../LocalLinks.java


// Targeting ../DeviceLocality.java


// Targeting ../DeviceAttributes.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// InterconnectLink

// int32 device_id = 1;




// string type = 2;












// int32 strength = 3;




// -------------------------------------------------------------------

// LocalLinks

// repeated .tensorflow.InterconnectLink link = 1;








// -------------------------------------------------------------------

// DeviceLocality

// int32 bus_id = 1;




// int32 numa_node = 2;




// .tensorflow.LocalLinks links = 3;








// -------------------------------------------------------------------

// DeviceAttributes

// string name = 1;












// string device_type = 2;












// int64 memory_limit = 4;




// .tensorflow.DeviceLocality locality = 5;








// fixed64 incarnation = 6;




// string physical_device_desc = 7;












// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #include <google/protobuf/port_undef.inc>
// #endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fdevice_5fattributes_2eproto


// Parsed from tensorflow/core/public/session.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_PUBLIC_SESSION_H_
// #define TENSORFLOW_CORE_PUBLIC_SESSION_H_

// #include <string>
// #include <vector>

// #include "tensorflow/core/framework/device_attributes.pb.h"
// #include "tensorflow/core/framework/graph.pb.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/platform/env.h"
// #include "tensorflow/core/protobuf/config.pb.h"
// #include "tensorflow/core/public/session_options.h"
// Targeting ../ThreadPoolOptions.java




// Targeting ../Session.java



/** \brief Create a new session with the given options.
 * 
 *  If session creation succeeds, the new {@code Session} will be stored in
 *  {@code *out_session}, the caller will take ownership of the returned
 *  {@code *out_session}, and this function will return {@code OK()}. Otherwise, this
 *  function will return an error status and set *out_session to nullptr. */

///
///
///
///
@Namespace("tensorflow") public static native @ByVal Status NewSession(@Const @ByRef SessionOptions options, @Cast("tensorflow::Session**") PointerPointer out_session);
@Namespace("tensorflow") public static native @ByVal Status NewSession(@Const @ByRef SessionOptions options, @ByPtrPtr Session out_session);

/** \brief Resets resource containers associated with a target.
 * 
 *  Reset() allows misbehaving or slow sessions to be aborted and closed, and
 *  causes their resources eventually to be released.  Reset() does not wait
 *  for the computations in old sessions to cease; it merely starts the
 *  process of tearing them down.  However, if a new session is started after
 *  a Reset(), the new session is isolated from changes that old sessions
 *  (started prior to the Reset()) may continue to make to resources, provided
 *  all those resources are in containers listed in "containers".
 * 
 *  Old sessions may continue to have side-effects on resources not in
 *  containers listed in "containers", and thus may affect future
 *  sessions' results in ways that are hard to predict.  Thus, if well-defined
 *  behavior is desired, it is recommended that all containers be listed in
 *  "containers".
 * 
 *  {@code containers} is a vector of string representation of resource container
 *  names. When a resource container is reset, the resources held by the
 *  container will be released. In particular, all Variables in the container
 *  will become undefined.  If the "containers" vector is empty, the default
 *  container is assumed.  If the "containers" vector is non-empty, the
 *  default container should be listed explicitly.
 * 
 *  If Reset succeeds, this function will return {@code OK()}. Otherwise, this
 *  function will return an error status. */

///
///
@Namespace("tensorflow") public static native @ByVal Status Reset(@Const @ByRef SessionOptions options,
             @Const @ByRef StringVector containers);

/** \brief Create a new session with the given options.
 * 
 *  If a new {@code Session} object could not be created, this function will
 *  return nullptr.
 * 
 *  *Strongly prefer* the version of NewSession that returns Status,
 *  which contains more helpful error information. */
@Namespace("tensorflow") public static native Session NewSession(@Const @ByRef SessionOptions options);

  // end namespace tensorflow

// #endif  // TENSORFLOW_CORE_PUBLIC_SESSION_H_


// Parsed from tensorflow/core/framework/tensor_slice.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/tensor_slice.proto

// #ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2ftensor_5fslice_2eproto
// #define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2ftensor_5fslice_2eproto

// #include <limits>
// #include <string>

// #include <google/protobuf/port_def.inc>
// #if PROTOBUF_VERSION < 3008000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please update
// #error your headers.
// #endif
// #if 3008000 < PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/port_undef.inc>
// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/generated_message_reflection.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/unknown_field_set.h>
// @@protoc_insertion_point(includes)
// #include <google/protobuf/port_def.inc>
// #define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcore_2fframework_2ftensor_5fslice_2eproto
  // namespace internal
 /* namespace protobuf */
   /* namespace google */

// Internal implementation detail -- do not use these members.
  // namespace tensorflow


 /* namespace protobuf */
   /* namespace google */
// Targeting ../TensorSliceProto_Extent.java


// Targeting ../TensorSliceProto.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// TensorSliceProto_Extent

// int64 start = 1;




// int64 length = 2;









// -------------------------------------------------------------------

// TensorSliceProto

// repeated .tensorflow.TensorSliceProto.Extent extent = 1;








// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #include <google/protobuf/port_undef.inc>
// #endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2ftensor_5fslice_2eproto


// Parsed from tensorflow/core/framework/tensor_slice.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_TENSOR_SLICE_H_
// #define TENSORFLOW_CORE_FRAMEWORK_TENSOR_SLICE_H_

// #include <string>
// #include "third_party/eigen3/unsupported/Eigen/CXX11/Tensor"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/tensor_slice.pb.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/lib/gtl/inlined_vector.h"
// #include "tensorflow/core/platform/logging.h"
// Targeting ../TensorSlice.java





  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_TENSOR_SLICE_H_


// Parsed from tensorflow/core/util/tensor_slice_set.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// A class to manage slices of a tensor. You can "register" set of slices for a
// tensor and then "query" if we have data for a given slice.

// #ifndef TENSORFLOW_CORE_UTIL_TENSOR_SLICE_SET_H_
// #define TENSORFLOW_CORE_UTIL_TENSOR_SLICE_SET_H_

// #include <string>  // for string
// #include <unordered_map>
// #include <vector>

// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/tensor_slice.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/core/status.h"       // for Status
// #include "tensorflow/core/lib/core/stringpiece.h"  // for StringPiece
// #include "tensorflow/core/platform/types.h"
// Targeting ../TensorSliceSet.java



// Registers "slice" in the TensorSliceSet stored in "tensor_slices", under key
// "name".  Other arguments are used for validations.  Does not modify the map
// or its values on non-OK.
// REQUIRES: tensor_slices != nullptr
@Namespace("tensorflow::checkpoint") public static native @ByVal Status RegisterTensorSlice(
    @StdString BytePointer name, @Const @ByRef TensorShape shape, @Cast("tensorflow::DataType") int type,
    @StdString BytePointer tag, @Const @ByRef TensorSlice slice,
    StringTensorSliceSetMap tensor_slices);
@Namespace("tensorflow::checkpoint") public static native @ByVal Status RegisterTensorSlice(
    @StdString String name, @Const @ByRef TensorShape shape, @Cast("tensorflow::DataType") int type,
    @StdString String tag, @Const @ByRef TensorSlice slice,
    StringTensorSliceSetMap tensor_slices);

  // namespace checkpoint

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_UTIL_TENSOR_SLICE_SET_H_


// Parsed from tensorflow/core/util/tensor_slice_util.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_UTIL_TENSOR_SLICE_UTIL_H_
// #define TENSORFLOW_CORE_UTIL_TENSOR_SLICE_UTIL_H_

// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/tensor_slice.h"
// #include "tensorflow/core/platform/logging.h"

// Some hackery to invoke eigen tensor to copy over tensor slices with variable
// dimension tensors.
// TODO(yangke): get rid of that once the variable dimension tensor support is
// in.
@Namespace("tensorflow") @MemberGetter public static native int kTensorSliceMaxRank();
public static final int kTensorSliceMaxRank = kTensorSliceMaxRank();

// Create a tensor map with the given shape: we support up to 8 dimensions. If
// the shape has less than 8 dimensions, we pad the remaining dimension with 1.

// For everything except string, a standard Eigen cast and assignment works
// Targeting ../CopyThatWorksWithStringPointer.java



// Checkpointing of half is done by storing the raw 16 bits as a signed 32bit
// integer. To restore the checkpoint we need to do the reverse operation by
// reinterpreting the integer as a 16 bit float. This prevents us from using
// the default cast operation.

// Given a tensor described by "shape", two slices "slice_s" and "slice_d",
// and two pointers "ptr_s" and "ptr_d", where "ptr_s" points to a chunk of
// memory that stores the data for "slice_s" and "ptr_d" points to a chunk of
// memory that stores the data for "slice_d". This function copies the data
// that belongs to the intersection of the two slices from slice_s to
// slice_d.  Uses Tensor cast<DstT>() to convert from SrcT to DstT. Returns true
// iff the two slices share any intersection (and thus some data is copied).
// TODO(yangke): figure out if we can make it private.

  // namespace

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_UTIL_TENSOR_SLICE_UTIL_H_


// Parsed from tensorflow/core/util/tensor_slice_reader.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// The utility to read checkpoints for google brain tensor ops and v3
// checkpoints for dist_belief.

// #ifndef TENSORFLOW_CORE_UTIL_TENSOR_SLICE_READER_H_
// #define TENSORFLOW_CORE_UTIL_TENSOR_SLICE_READER_H_

// #include <unordered_map>

// #include <vector>
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/tensor_slice.h"
// #include "tensorflow/core/framework/types.pb.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/lib/gtl/map_util.h"
// #include "tensorflow/core/platform/logging.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/mutex.h"
// #include "tensorflow/core/platform/protobuf.h"
// #include "tensorflow/core/platform/types.h"
// #include "tensorflow/core/util/saved_tensor_slice.pb.h"
// #include "tensorflow/core/util/saved_tensor_slice_util.h"
// #include "tensorflow/core/util/tensor_slice_set.h"
// #include "tensorflow/core/util/tensor_slice_util.h"
// Targeting ../TensorSliceReader.java



@Namespace("tensorflow::checkpoint") public static native @ByVal Status OpenTableTensorSliceReader(@StdString BytePointer fname,
                                  @Cast("tensorflow::checkpoint::TensorSliceReader::Table**") PointerPointer table);
@Namespace("tensorflow::checkpoint") public static native @ByVal Status OpenTableTensorSliceReader(@StdString BytePointer fname,
                                  @ByPtrPtr TensorSliceReader.Table table);
@Namespace("tensorflow::checkpoint") public static native @ByVal Status OpenTableTensorSliceReader(@StdString String fname,
                                  @ByPtrPtr TensorSliceReader.Table table);



  // namespace checkpoint

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_UTIL_TENSOR_SLICE_READER_H_


// Parsed from tensorflow/core/util/tensor_bundle/tensor_bundle.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// A tensor bundle is a set of immutable persistent files storing a set of named
// tensors.  It is designed for checkpointing TensorFlow tensors.
//
// The paths of the managed files share a common prefix; e.g., with the prefix:
//   /fs/model/train/ckpt-step/ckpt
//
// the bundle may contain a metadata file, and sharded data files:
//   /fs/model/train/ckpt-step/
//       ckpt.index
//       ckpt.data-00000-of-00020
//       ckpt.data-00001-of-00020
//       ...
//       ckpt.data-00019-of-00020
//
// The ".index" file is a string-string immutable table
// (tensorflow::table::Table).  Each key is a name of a tensor and its value is
// a serialized BundleEntryProto.  Each BundleEntryProto describes the metadata
// of a tensor: which of the "data" files contains the content of a tensor, the
// offset into that file, checksum, some auxiliary data, etc.
//
// A tensor bundle can be accessed randomly using a BundleReader.  Usage:
//
//   BundleReader reader(env, "/fs/model/train/ckpt-step/ckpt");
//   reader.Lookup("name", &tensor);
//
// A tensor bundle can be built using BundleWriter.  Each BundleWriter builds a
// single data file bundle.  Multiple bundles can then be merged by
// MergeBundles() without reading and writing large chunk of data: it reads the
// metadata files and outputs a single merged metadata.  Typical usage:
//
//   worker 0:
//     BundleWriter writer(env, "/fs/model/train/ckpt-step/tmp/worker0-step");
//     writer.Add(...);  // Adds the tensors on this worker.
//     writer.Finish();  // Flushes.
//   worker 1:
//     BundleWriter writer(env, "/fs/model/train/ckpt-step/tmp/worker1-step");
//     writer.Add(...);
//     writer.Finish();
//   worker 2:
//     MergeBundles(env,
//       {"/fs/model/train/ckpt-step/tmp/worker0-step",
//        "/fs/model/train/ckpt-step/tmp/worker1-step"},
//       "/fs/model/train/ckpt-step/ckpt" /* merged prefix */);
//

// #ifndef TENSORFLOW_CORE_UTIL_TENSOR_BUNDLE_TENSOR_BUNDLE_H_
// #define TENSORFLOW_CORE_UTIL_TENSOR_BUNDLE_TENSOR_BUNDLE_H_

// #include "tensorflow/core/protobuf/tensor_bundle.pb.h"

// #include <map>
// #include <string>
// #include <unordered_map>

// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/tensor_slice.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// #include "tensorflow/core/lib/io/inputbuffer.h"
// #include "tensorflow/core/lib/io/table.h"
// #include "tensorflow/core/platform/env.h"
// #include "tensorflow/core/platform/file_system.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/types.h"
// #include "tensorflow/core/util/tensor_bundle/naming.h"
// #include "tensorflow/core/util/tensor_slice_set.h"

// Versioning of the tensor bundle format.
// Follows the same rules as 3p/tf/core/public/version.h.
//
// History:
// 0. Any tensor bundles produced before this field was added.
// 1. Added this field (2016-09-14).
@Namespace("tensorflow") @MemberGetter public static native int kTensorBundleMinProducer();
@Namespace("tensorflow") @MemberGetter public static native int kTensorBundleMinConsumer();
@Namespace("tensorflow") @MemberGetter public static native int kTensorBundleVersion();

// The empty string, hence always the first key in the metadata table.  Its
// corresponding value is a BundleHeaderProto.
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer kHeaderEntryKey();
// Targeting ../BundleWriter.java



// Merges a set of bundles (given their prefixes) into a single bundle with the
// given "merged_prefix".  The merged metadata is guaranteed to be consistent.
//
// If there are N bundles in "prefixes", during the merge the data files will be
// renamed to contain a proper sharded file spec, with num_shards set to the sum
// of num_shards across the N input bundles.
//
// The caller should only rely on the metadata file of the merged bundle to
// query information about a tensor.  In particular, this function does not
// guarantee not to re-order the input data files.
//
// Once merged, makes a best effort to delete the old metadata files.
// Returns OK iff all bundles are successfully merged.
@Namespace("tensorflow") public static native @ByVal Status MergeBundles(Env env, @ByVal @Cast("tensorflow::gtl::ArraySlice<tensorflow::tstring>*") StringVector prefixes,
                    @StringPiece BytePointer merged_prefix);
@Namespace("tensorflow") public static native @ByVal Status MergeBundles(Env env, @ByVal @Cast("tensorflow::gtl::ArraySlice<tensorflow::tstring>*") StringVector prefixes,
                    @StringPiece String merged_prefix);
// Targeting ../BundleReader.java


// Targeting ../FileOutputBuffer.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_UTIL_TENSOR_BUNDLE_TENSOR_BUNDLE_H_


// Parsed from tensorflow/core/framework/summary.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/summary.proto

// #ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fsummary_2eproto
// #define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fsummary_2eproto

// #include <limits>
// #include <string>

// #include <google/protobuf/port_def.inc>
// #if PROTOBUF_VERSION < 3008000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please update
// #error your headers.
// #endif
// #if 3008000 < PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/port_undef.inc>
// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/generated_message_reflection.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/tensor.pb.h"
// @@protoc_insertion_point(includes)
// #include <google/protobuf/port_def.inc>
// #define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcore_2fframework_2fsummary_2eproto
  // namespace internal
 /* namespace protobuf */
   /* namespace google */

// Internal implementation detail -- do not use these members.
  // namespace tensorflow








 /* namespace protobuf */
   /* namespace google */
// Targeting ../SummaryDescription.java


// Targeting ../HistogramProto.java


// Targeting ../SummaryMetadata_PluginData.java


// Targeting ../SummaryMetadata.java


// Targeting ../Summary_Image.java


// Targeting ../Summary_Audio.java


// Targeting ../Summary_Value.java


// Targeting ../Summary.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// SummaryDescription

// string type_hint = 1;












// -------------------------------------------------------------------

// HistogramProto

// double min = 1;




// double max = 2;




// double num = 3;




// double sum = 4;




// double sum_squares = 5;




// repeated double bucket_limit = 6 [packed = true];








// repeated double bucket = 7 [packed = true];








// -------------------------------------------------------------------

// SummaryMetadata_PluginData

// string plugin_name = 1;












// bytes content = 2;












// -------------------------------------------------------------------

// SummaryMetadata

// .tensorflow.SummaryMetadata.PluginData plugin_data = 1;








// string display_name = 2;












// string summary_description = 3;












// -------------------------------------------------------------------

// Summary_Image

// int32 height = 1;




// int32 width = 2;




// int32 colorspace = 3;




// bytes encoded_image_string = 4;












// -------------------------------------------------------------------

// Summary_Audio

// float sample_rate = 1;




// int64 num_channels = 2;




// int64 length_frames = 3;




// bytes encoded_audio_string = 4;












// string content_type = 5;












// -------------------------------------------------------------------

// Summary_Value

// string node_name = 7;












// string tag = 1;












// .tensorflow.SummaryMetadata metadata = 9;








// float simple_value = 2;






// bytes obsolete_old_style_histogram = 3;














// .tensorflow.Summary.Image image = 4;









// .tensorflow.HistogramProto histo = 5;









// .tensorflow.Summary.Audio audio = 6;









// .tensorflow.TensorProto tensor = 8;











// -------------------------------------------------------------------

// Summary

// repeated .tensorflow.Summary.Value value = 1;








// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #include <google/protobuf/port_undef.inc>
// #endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fsummary_2eproto


// Parsed from tensorflow/core/lib/monitoring/counter.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_LIB_MONITORING_COUNTER_H_
// #define TENSORFLOW_CORE_LIB_MONITORING_COUNTER_H_

// clang-format off
// Required for IS_MOBILE_PLATFORM
// #include "tensorflow/core/platform/platform.h"
// clang-format on

// We replace this implementation with a null implementation for mobile
// platforms.
// #ifdef IS_MOBILE_PLATFORM
// #include "tensorflow/core/lib/monitoring/mobile_counter.h"
// #else

// #include <array>
// #include <atomic>
// #include <map>

// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/monitoring/collection_registry.h"
// #include "tensorflow/core/lib/monitoring/metric_def.h"
// #include "tensorflow/core/platform/logging.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/mutex.h"
// #include "tensorflow/core/platform/thread_annotations.h"
// Targeting ../CounterCell.java



// A stateful class for updating a cumulative integer metric.
//
// This class encapsulates a set of values (or a single value for a label-less
// metric). Each value is identified by a tuple of labels. The class allows the
// user to increment each value.
//
// Counter allocates storage and maintains a cell for each value. You can
// retrieve an individual cell using a label-tuple and update it separately.
// This improves performance since operations related to retrieval, like
// map-indexing and locking, are avoided.
//
// This class is thread-safe.

////
//  Implementation details follow. API readers may skip.
////









  // namespace monitoring
  // namespace tensorflow

// #endif  // IS_MOBILE_PLATFORM
// #endif  // TENSORFLOW_CORE_LIB_MONITORING_COUNTER_H_


// Parsed from tensorflow/core/lib/monitoring/gauge.h

/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_LIB_MONITORING_GAUGE_H_
// #define TENSORFLOW_CORE_LIB_MONITORING_GAUGE_H_

// clang-format off
// Required for IS_MOBILE_PLATFORM
// #include "tensorflow/core/platform/platform.h"
// clang-format on

// We replace this implementation with a null implementation for mobile
// platforms.
// #ifdef IS_MOBILE_PLATFORM
// #include "tensorflow/core/lib/monitoring/mobile_gauge.h"
// #else

// #include <array>
// #include <atomic>
// #include <map>

// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/monitoring/collection_registry.h"
// #include "tensorflow/core/lib/monitoring/metric_def.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/mutex.h"
// #include "tensorflow/core/platform/thread_annotations.h"
// #include "tensorflow/core/platform/types.h"
// Targeting ../BoolGaugeCell.java


// Targeting ../IntGaugeCell.java


// Targeting ../StringGaugeCell.java



// Explicit specialization of GaugeCell<int64>. Compared to the primary
// template, it uses atomic values as opposed to mutex. This class is
// thread-safe.

// Explicit specialization of GaugeCell<bool>. Compared to the primary
// template, it uses atomic values as opposed to mutex. This class is
// thread-safe.

// A stateful class for updating a gauge-like metric. Allowed ValueType are
// int64, string and bool.
//
// This class encapsulates a set of values (or a single value for a label-less
// metric). Each value is identified by a tuple of labels. The class allows the
// user to set each value.
//
// Gauge allocates storage and maintains a cell for each value. You can
// retrieve an individual cell using a label-tuple and update it separately.
// This improves performance since operations related to retrieval, like
// map-indexing and locking, are avoided.
//
// This class is thread-safe.

////
//  Implementation details follow. API readers may skip.
////
















  // namespace monitoring
  // namespace tensorflow

// #endif  // IS_MOBILE_PLATFORM
// #endif  // TENSORFLOW_CORE_LIB_MONITORING_GAUGE_H_


// Parsed from tensorflow/core/lib/monitoring/sampler.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_LIB_MONITORING_SAMPLER_H_
// #define TENSORFLOW_CORE_LIB_MONITORING_SAMPLER_H_

// clang-format off
// Required for IS_MOBILE_PLATFORM
// #include "tensorflow/core/platform/platform.h"
// clang-format on

// We replace this implementation with a null implementation for mobile
// platforms.
// #ifdef IS_MOBILE_PLATFORM
// #include "tensorflow/core/lib/monitoring/mobile_sampler.h"
// #else

// #include <float.h>

// #include <map>

// #include "tensorflow/core/framework/summary.pb.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/histogram/histogram.h"
// #include "tensorflow/core/lib/monitoring/collection_registry.h"
// #include "tensorflow/core/lib/monitoring/metric_def.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/mutex.h"
// #include "tensorflow/core/platform/thread_annotations.h"
// Targeting ../SamplerCell.java


// Targeting ../Buckets.java



// A stateful class for updating a cumulative histogram metric.
//
// This class encapsulates a set of histograms (or a single histogram for a
// label-less metric) configured with a list of increasing bucket boundaries.
// Each histogram is identified by a tuple of labels. The class allows the
// user to add a sample to each histogram value.
//
// Sampler allocates storage and maintains a cell for each value. You can
// retrieve an individual cell using a label-tuple and update it separately.
// This improves performance since operations related to retrieval, like
// map-indexing and locking, are avoided.
//
// This class is thread-safe.

////
//  Implementation details follow. API readers may skip.
////









  // namespace monitoring
  // namespace tensorflow

// #endif  // IS_MOBILE_PLATFORM
// #endif  // TENSORFLOW_CORE_LIB_MONITORING_SAMPLER_H_


// Parsed from tensorflow/core/profiler/internal/profiler_interface.h

/* Copyright 2016 The TensorFlow Authors All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
// #ifndef TENSORFLOW_CORE_PROFILER_INTERNAL_PROFILER_INTERFACE_H_
// #define TENSORFLOW_CORE_PROFILER_INTERNAL_PROFILER_INTERFACE_H_

// #include <memory>
// #include <vector>

// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/protobuf/config.pb.h"
// Targeting ../ProfilerInterface.java




// Targeting ../ProfilerFactory.java



@Namespace("tensorflow") public static native void RegisterProfilerFactory(@ByVal @Cast("tensorflow::ProfilerFactory") ProfilerFactory factory);

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_PROFILER_INTERNAL_PROFILER_INTERFACE_H_


// Parsed from tensorflow/core/profiler/lib/profiler_session.h

/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
// #ifndef TENSORFLOW_CORE_PROFILER_LIB_PROFILER_SESSION_H_
// #define TENSORFLOW_CORE_PROFILER_LIB_PROFILER_SESSION_H_

// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/platform/mutex.h"
// #include "tensorflow/core/platform/thread_annotations.h"
// #include "tensorflow/core/profiler/internal/profiler_interface.h"
// Targeting ../ProfilerSession.java



  // namespace tensorflow
// #endif  // TENSORFLOW_CORE_PROFILER_LIB_PROFILER_SESSION_H_


// Parsed from tensorflow/c/tf_attrtype.h

/* Copyright 2019 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
// #ifndef TENSORFLOW_C_TF_ATTRTYPE_H_
// #define TENSORFLOW_C_TF_ATTRTYPE_H_

// #ifdef __cplusplus
// #endif

// TF_AttrType describes the type of the value of an attribute on an operation.
/** enum TF_AttrType */
public static final int
  TF_ATTR_STRING = 0,
  TF_ATTR_INT = 1,
  TF_ATTR_FLOAT = 2,
  TF_ATTR_BOOL = 3,
  TF_ATTR_TYPE = 4,
  TF_ATTR_SHAPE = 5,
  TF_ATTR_TENSOR = 6,
  TF_ATTR_PLACEHOLDER = 7,
  TF_ATTR_FUNC = 8;

// #ifdef __cplusplus /* end extern "C" */
// #endif

// #endif  // TENSORFLOW_C_TF_ATTRTYPE_H_


// Parsed from tensorflow/c/tf_datatype.h

/* Copyright 2019 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_C_TF_DATATYPE_H_
// #define TENSORFLOW_C_TF_DATATYPE_H_

// #include <stddef.h>

// Macro to control visibility of exported symbols in the shared library (.so,
// .dylib, .dll).
// This duplicates the TF_EXPORT macro definition in
// tensorflow/core/platform/macros.h in order to keep this .h file independent
// of any other includes.
// #ifdef SWIG
// #define TF_CAPI_EXPORT
// #else
// #endif  // SWIG

// #ifdef __cplusplus
// #endif

// --------------------------------------------------------------------------
// TF_DataType holds the type for a scalar value.  E.g., one slot in a tensor.
// The enum values here are identical to corresponding values in types.proto.
/** enum TF_DataType */
public static final int
  TF_FLOAT = 1,
  TF_DOUBLE = 2,
  TF_INT32 = 3,  // Int32 tensors are always in 'host' memory.
  TF_UINT8 = 4,
  TF_INT16 = 5,
  TF_INT8 = 6,
  TF_STRING = 7,
  TF_COMPLEX64 = 8,  // Single-precision complex
  TF_COMPLEX = 8,    // Old identifier kept for API backwards compatibility
  TF_INT64 = 9,
  TF_BOOL = 10,
  TF_QINT8 = 11,     // Quantized int8
  TF_QUINT8 = 12,    // Quantized uint8
  TF_QINT32 = 13,    // Quantized int32
  TF_BFLOAT16 = 14,  // Float32 truncated to 16 bits.  Only for cast ops.
  TF_QINT16 = 15,    // Quantized int16
  TF_QUINT16 = 16,   // Quantized uint16
  TF_UINT16 = 17,
  TF_COMPLEX128 = 18,  // Double-precision complex
  TF_HALF = 19,
  TF_RESOURCE = 20,
  TF_VARIANT = 21,
  TF_UINT32 = 22,
  TF_UINT64 = 23;

// TF_DataTypeSize returns the sizeof() for the underlying type corresponding
// to the given TF_DataType enum value. Returns 0 for variable length types
// (eg. TF_STRING) or on failure.
public static native @Cast("size_t") long TF_DataTypeSize(@Cast("TF_DataType") int dt);

// #ifdef __cplusplus /* end extern "C" */
// #endif

// #endif  // TENSORFLOW_C_TF_DATATYPE_H_


// Parsed from tensorflow/c/tf_status.h

/* Copyright 2019 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_C_TF_STATUS_H_
// #define TENSORFLOW_C_TF_STATUS_H_

// #ifdef SWIG
// #define TF_CAPI_EXPORT
// #else
// #endif  // SWIG

// #ifdef __cplusplus
// #endif

// --------------------------------------------------------------------------
// TF_Code holds an error code.  The enum values here are identical to
// corresponding values in error_codes.proto.
/** enum TF_Code */
public static final int
  TF_OK = 0,
  TF_CANCELLED = 1,
  TF_UNKNOWN = 2,
  TF_INVALID_ARGUMENT = 3,
  TF_DEADLINE_EXCEEDED = 4,
  TF_NOT_FOUND = 5,
  TF_ALREADY_EXISTS = 6,
  TF_PERMISSION_DENIED = 7,
  TF_UNAUTHENTICATED = 16,
  TF_RESOURCE_EXHAUSTED = 8,
  TF_FAILED_PRECONDITION = 9,
  TF_ABORTED = 10,
  TF_OUT_OF_RANGE = 11,
  TF_UNIMPLEMENTED = 12,
  TF_INTERNAL = 13,
  TF_UNAVAILABLE = 14,
  TF_DATA_LOSS = 15;

// --------------------------------------------------------------------------

// Return a new status object.
public static native TF_Status TF_NewStatus();

// Delete a previously created status object.
public static native void TF_DeleteStatus(TF_Status arg0);

// Record <code, msg> in *s.  Any previous information is lost.
// A common use is to clear a status: TF_SetStatus(s, TF_OK, "");
public static native void TF_SetStatus(TF_Status s, @Cast("TF_Code") int code,
                                        @Cast("const char*") BytePointer msg);
public static native void TF_SetStatus(TF_Status s, @Cast("TF_Code") int code,
                                        String msg);

// Return the code record in *s.
public static native @Cast("TF_Code") int TF_GetCode(@Const TF_Status s);

// Return a pointer to the (null-terminated) error message in *s.  The
// return value points to memory that is only usable until the next
// mutation to *s.  Always returns an empty string if TF_GetCode(s) is
// TF_OK.
public static native @Cast("const char*") BytePointer TF_Message(@Const TF_Status s);

// #ifdef __cplusplus /* end extern "C" */
// #endif

// #endif  // TENSORFLOW_C_TF_STATUS_H_


// Parsed from tensorflow/c/tf_status_helper.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_C_TF_STATUS_HELPER_H_
// #define TENSORFLOW_C_TF_STATUS_HELPER_H_

// #include "tensorflow/c/tf_status.h"
// #include "tensorflow/core/lib/core/status.h"

// Set the attribute of "tf_status" from the attributes of "status".
@Namespace("tensorflow") public static native void Set_TF_Status_from_Status(TF_Status tf_status, @Const @ByRef Status status);

// Returns a "status" from "tf_status".
@Namespace("tensorflow") public static native @ByVal Status StatusFromTF_Status(@Const TF_Status tf_status);

  // namespace tensorflow

// #endif  // TENSORFLOW_C_TF_STATUS_HELPER_H_


// Parsed from tensorflow/c/tf_tensor.h

/* Copyright 2019 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_C_TF_TENSOR_H_
// #define TENSORFLOW_C_TF_TENSOR_H_

// #include <stdbool.h>
// #include <stdint.h>

// #include "tensorflow/c/tf_datatype.h"
// #include "tensorflow/c/tf_status.h"

// Macro to control visibility of exported symbols in the shared library (.so,
// .dylib, .dll).
// This duplicates the TF_EXPORT macro definition in
// tensorflow/core/platform/macros.h in order to keep this .h file independent
// of any other includes.
// #ifdef SWIG
// #define TF_CAPI_EXPORT
// #else
// #endif  // SWIG

// #ifdef __cplusplus
// #endif

// --------------------------------------------------------------------------
// TF_Tensor holds a multi-dimensional array of elements of a single data type.
// For all types other than TF_STRING, the data buffer stores elements
// in row major order.  E.g. if data is treated as a vector of TF_DataType:
//
//   element 0:   index (0, ..., 0)
//   element 1:   index (0, ..., 1)
//   ...
//
// The format for TF_STRING tensors is:
//   start_offset: array[uint64]
//   data:         byte[...]
//
//   The string length (as a varint), followed by the contents of the string
//   is encoded at data[start_offset[i]]]. TF_StringEncode and TF_StringDecode
//   facilitate this encoding.
// Targeting ../Deallocator_Pointer_long_Pointer.java


public static native TF_Tensor TF_NewTensor(
    @Cast("TF_DataType") int arg0, @Cast("const int64_t*") LongPointer dims, int num_dims, Pointer data, @Cast("size_t") long len,
    Deallocator_Pointer_long_Pointer deallocator,
    Pointer deallocator_arg);
public static native TF_Tensor TF_NewTensor(
    @Cast("TF_DataType") int arg0, @Cast("const int64_t*") LongBuffer dims, int num_dims, Pointer data, @Cast("size_t") long len,
    Deallocator_Pointer_long_Pointer deallocator,
    Pointer deallocator_arg);
public static native TF_Tensor TF_NewTensor(
    @Cast("TF_DataType") int arg0, @Cast("const int64_t*") long[] dims, int num_dims, Pointer data, @Cast("size_t") long len,
    Deallocator_Pointer_long_Pointer deallocator,
    Pointer deallocator_arg);

// Allocate and return a new Tensor.
//
// This function is an alternative to TF_NewTensor and should be used when
// memory is allocated to pass the Tensor to the C API. The allocated memory
// satisfies TensorFlow's memory alignment preferences and should be preferred
// over calling malloc and free.
//
// The caller must set the Tensor values by writing them to the pointer returned
// by TF_TensorData with length TF_TensorByteSize.
public static native TF_Tensor TF_AllocateTensor(@Cast("TF_DataType") int arg0,
                                                   @Cast("const int64_t*") LongPointer dims,
                                                   int num_dims, @Cast("size_t") long len);
public static native TF_Tensor TF_AllocateTensor(@Cast("TF_DataType") int arg0,
                                                   @Cast("const int64_t*") LongBuffer dims,
                                                   int num_dims, @Cast("size_t") long len);
public static native TF_Tensor TF_AllocateTensor(@Cast("TF_DataType") int arg0,
                                                   @Cast("const int64_t*") long[] dims,
                                                   int num_dims, @Cast("size_t") long len);

// Deletes `tensor` and returns a new TF_Tensor with the same content if
// possible. Returns nullptr and leaves `tensor` untouched if not.
public static native TF_Tensor TF_TensorMaybeMove(TF_Tensor tensor);

// Destroy a tensor.
public static native void TF_DeleteTensor(TF_Tensor arg0);

// Return the type of a tensor element.
public static native @Cast("TF_DataType") int TF_TensorType(@Const TF_Tensor arg0);

// Return the number of dimensions that the tensor has.
public static native int TF_NumDims(@Const TF_Tensor arg0);

// Return the length of the tensor in the "dim_index" dimension.
// REQUIRES: 0 <= dim_index < TF_NumDims(tensor)
public static native @Cast("int64_t") long TF_Dim(@Const TF_Tensor tensor, int dim_index);

// Return the size of the underlying data in bytes.
public static native @Cast("size_t") long TF_TensorByteSize(@Const TF_Tensor arg0);

// Return a pointer to the underlying data buffer.
public static native Pointer TF_TensorData(@Const TF_Tensor arg0);

// Returns the number of elements in the tensor.
public static native @Cast("int64_t") long TF_TensorElementCount(@Const TF_Tensor tensor);

// Copy the internal data representation of `from` to `to`. `new_dims` and
// `num_new_dims` specify the new shape of the `to` tensor, `type` specifies its
// data type. On success, *status is set to TF_OK and the two tensors share the
// same data buffer.
//
// This call requires that the `from` tensor and the given type and shape (dims
// and num_dims) are "compatible" (i.e. they occupy the same number of bytes).
// Specifically, given from_type_size = TF_DataTypeSize(TF_TensorType(from)):
//
// ShapeElementCount(dims, num_dims) * TF_DataTypeSize(type)
//
// must equal
//
// TF_TensorElementCount(from) * from_type_size
//
// where TF_ShapeElementCount would be the number of elements in a tensor with
// the given shape.
//
// In addition, this function requires:
//   * TF_DataTypeSize(TF_TensorType(from)) != 0
//   * TF_DataTypeSize(type) != 0
//
// If any of the requirements are not met, *status is set to
// TF_INVALID_ARGUMENT.
public static native void TF_TensorBitcastFrom(@Const TF_Tensor from,
                                                @Cast("TF_DataType") int type, TF_Tensor to,
                                                @Cast("const int64_t*") LongPointer new_dims,
                                                int num_new_dims,
                                                TF_Status status);
public static native void TF_TensorBitcastFrom(@Const TF_Tensor from,
                                                @Cast("TF_DataType") int type, TF_Tensor to,
                                                @Cast("const int64_t*") LongBuffer new_dims,
                                                int num_new_dims,
                                                TF_Status status);
public static native void TF_TensorBitcastFrom(@Const TF_Tensor from,
                                                @Cast("TF_DataType") int type, TF_Tensor to,
                                                @Cast("const int64_t*") long[] new_dims,
                                                int num_new_dims,
                                                TF_Status status);

// --------------------------------------------------------------------------
// Encode the string `src` (`src_len` bytes long) into `dst` in the format
// required by TF_STRING tensors. Does not write to memory more than `dst_len`
// bytes beyond `*dst`. `dst_len` should be at least
// TF_StringEncodedSize(src_len).
//
// On success returns the size in bytes of the encoded string.
// Returns an error into `status` otherwise.
public static native @Cast("size_t") long TF_StringEncode(@Cast("const char*") BytePointer src, @Cast("size_t") long src_len,
                                             @Cast("char*") BytePointer dst, @Cast("size_t") long dst_len,
                                             TF_Status status);
public static native @Cast("size_t") long TF_StringEncode(String src, @Cast("size_t") long src_len,
                                             @Cast("char*") ByteBuffer dst, @Cast("size_t") long dst_len,
                                             TF_Status status);
public static native @Cast("size_t") long TF_StringEncode(@Cast("const char*") BytePointer src, @Cast("size_t") long src_len,
                                             @Cast("char*") byte[] dst, @Cast("size_t") long dst_len,
                                             TF_Status status);
public static native @Cast("size_t") long TF_StringEncode(String src, @Cast("size_t") long src_len,
                                             @Cast("char*") BytePointer dst, @Cast("size_t") long dst_len,
                                             TF_Status status);
public static native @Cast("size_t") long TF_StringEncode(@Cast("const char*") BytePointer src, @Cast("size_t") long src_len,
                                             @Cast("char*") ByteBuffer dst, @Cast("size_t") long dst_len,
                                             TF_Status status);
public static native @Cast("size_t") long TF_StringEncode(String src, @Cast("size_t") long src_len,
                                             @Cast("char*") byte[] dst, @Cast("size_t") long dst_len,
                                             TF_Status status);

// Decode a string encoded using TF_StringEncode.
//
// On success, sets `*dst` to the start of the decoded string and `*dst_len` to
// its length. Returns the number of bytes starting at `src` consumed while
// decoding. `*dst` points to memory within the encoded buffer.  On failure,
// `*dst` and `*dst_len` are undefined and an error is set in `status`.
//
// Does not read memory more than `src_len` bytes beyond `src`.
public static native @Cast("size_t") long TF_StringDecode(@Cast("const char*") BytePointer src, @Cast("size_t") long src_len,
                                             @Cast("const char**") PointerPointer dst, @Cast("size_t*") SizeTPointer dst_len,
                                             TF_Status status);
public static native @Cast("size_t") long TF_StringDecode(@Cast("const char*") BytePointer src, @Cast("size_t") long src_len,
                                             @Cast("const char**") @ByPtrPtr BytePointer dst, @Cast("size_t*") SizeTPointer dst_len,
                                             TF_Status status);
public static native @Cast("size_t") long TF_StringDecode(String src, @Cast("size_t") long src_len,
                                             @Cast("const char**") @ByPtrPtr ByteBuffer dst, @Cast("size_t*") SizeTPointer dst_len,
                                             TF_Status status);
public static native @Cast("size_t") long TF_StringDecode(@Cast("const char*") BytePointer src, @Cast("size_t") long src_len,
                                             @Cast("const char**") @ByPtrPtr byte[] dst, @Cast("size_t*") SizeTPointer dst_len,
                                             TF_Status status);
public static native @Cast("size_t") long TF_StringDecode(String src, @Cast("size_t") long src_len,
                                             @Cast("const char**") @ByPtrPtr BytePointer dst, @Cast("size_t*") SizeTPointer dst_len,
                                             TF_Status status);
public static native @Cast("size_t") long TF_StringDecode(@Cast("const char*") BytePointer src, @Cast("size_t") long src_len,
                                             @Cast("const char**") @ByPtrPtr ByteBuffer dst, @Cast("size_t*") SizeTPointer dst_len,
                                             TF_Status status);
public static native @Cast("size_t") long TF_StringDecode(String src, @Cast("size_t") long src_len,
                                             @Cast("const char**") @ByPtrPtr byte[] dst, @Cast("size_t*") SizeTPointer dst_len,
                                             TF_Status status);

// Return the size in bytes required to encode a string `len` bytes long into a
// TF_STRING tensor.
public static native @Cast("size_t") long TF_StringEncodedSize(@Cast("size_t") long len);

// Returns bool iff this tensor is aligned.
public static native @Cast("bool") boolean TF_TensorIsAligned(@Const TF_Tensor arg0);

// #ifdef __cplusplus /* end extern "C" */
// #endif

// #endif  // TENSORFLOW_C_TF_TENSOR_H_


// Parsed from tensorflow/c/checkpoint_reader.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_C_CHECKPOINT_READER_H_
// #define TENSORFLOW_C_CHECKPOINT_READER_H_

// #include <memory>
// #include <string>

// #include "tensorflow/c/tf_status_helper.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/platform/types.h"
// #include "tensorflow/core/util/tensor_bundle/tensor_bundle.h"
// #include "tensorflow/core/util/tensor_slice_reader.h"
// Targeting ../CheckpointReader.java



  // namespace checkpoint
  // namespace tensorflow

// #endif  // TENSORFLOW_C_CHECKPOINT_READER_H_


// Parsed from tensorflow/c/c_api.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_C_C_API_H_
// #define TENSORFLOW_C_C_API_H_

// #include <stddef.h>
// #include <stdint.h>

// #include "tensorflow/c/tf_attrtype.h"
// #include "tensorflow/c/tf_datatype.h"
// #include "tensorflow/c/tf_status.h"
// #include "tensorflow/c/tf_tensor.h"

// --------------------------------------------------------------------------
// C API for TensorFlow.
//
// The API leans towards simplicity and uniformity instead of convenience
// since most usage will be by language specific wrappers.
//
// Conventions:
// * We use the prefix TF_ for everything in the API.
// * Objects are always passed around as pointers to opaque structs
//   and these structs are allocated/deallocated via the API.
// * TF_Status holds error information.  It is an object type
//   and therefore is passed around as a pointer to an opaque
//   struct as mentioned above.
// * Every call that has a TF_Status* argument clears it on success
//   and fills it with error info on failure.
// * unsigned char is used for booleans (instead of the 'bool' type).
//   In C++ bool is a keyword while in C99 bool is a macro defined
//   in stdbool.h. It is possible for the two to be inconsistent.
//   For example, neither the C99 nor the C++11 standard force a byte
//   size on the bool type, so the macro defined in stdbool.h could
//   be inconsistent with the bool keyword in C++. Thus, the use
//   of stdbool.h is avoided and unsigned char is used instead.
// * size_t is used to represent byte sizes of objects that are
//   materialized in the address space of the calling process.
// * int is used as an index into arrays.
// * Deletion functions are safe to call on nullptr.
//
// Questions left to address:
// * Might at some point need a way for callers to provide their own Env.
// * Maybe add TF_TensorShape that encapsulates dimension info.
//
// Design decisions made:
// * Backing store for tensor memory has an associated deallocation
//   function.  This deallocation function will point to client code
//   for tensors populated by the client.  So the client can do things
//   like shadowing a numpy array.
// * We do not provide TF_OK since it is not strictly necessary and we
//   are not optimizing for convenience.
// * We make assumption that one session has one graph.  This should be
//   fine since we have the ability to run sub-graphs.
// * We could allow NULL for some arguments (e.g., NULL options arg).
//   However since convenience is not a primary goal, we don't do this.
// * Devices are not in this API.  Instead, they are created/used internally
//   and the API just provides high level controls over the number of
//   devices of each type.

// Macro to control visibility of exported symbols in the shared library (.so,
// .dylib, .dll).
// This duplicates the TF_EXPORT macro definition in
// tensorflow/core/platform/macros.h in order to keep this .h file independent
// of any other includes.
// #ifdef SWIG
// #define TF_CAPI_EXPORT
// #else
// #endif  // SWIG

// #ifdef __cplusplus
// #endif

// --------------------------------------------------------------------------
// TF_Version returns a string describing version information of the
// TensorFlow library. TensorFlow using semantic versioning.
public static native @Cast("const char*") BytePointer TF_Version();
// Targeting ../TF_Buffer.java



// Makes a copy of the input and sets an appropriate deallocator.  Useful for
// passing in read-only, input protobufs.
public static native TF_Buffer TF_NewBufferFromString(@Const Pointer proto,
                                                        @Cast("size_t") long proto_len);

// Useful for passing *out* a protobuf.
public static native TF_Buffer TF_NewBuffer();

public static native void TF_DeleteBuffer(TF_Buffer arg0);

public static native @ByVal TF_Buffer TF_GetBuffer(TF_Buffer buffer);

// --------------------------------------------------------------------------
// TF_SessionOptions holds options that can be passed during session creation.

// Return a new options object.
public static native TF_SessionOptions TF_NewSessionOptions();

// Set the target in TF_SessionOptions.options.
// target can be empty, a single entry, or a comma separated list of entries.
// Each entry is in one of the following formats :
// "local"
// ip:port
// host:port
public static native void TF_SetTarget(TF_SessionOptions options,
                                        @Cast("const char*") BytePointer target);
public static native void TF_SetTarget(TF_SessionOptions options,
                                        String target);

// Set the config in TF_SessionOptions.options.
// config should be a serialized tensorflow.ConfigProto proto.
// If config was not parsed successfully as a ConfigProto, record the
// error information in *status.
public static native void TF_SetConfig(TF_SessionOptions options,
                                        @Const Pointer proto, @Cast("size_t") long proto_len,
                                        TF_Status status);

// Destroy an options object.
public static native void TF_DeleteSessionOptions(TF_SessionOptions arg0);

// TODO(jeff,sanjay):
// - export functions to set Config fields

// --------------------------------------------------------------------------
// The new graph construction API, still under development.

// Represents a computation graph.  Graphs may be shared between sessions.
// Graphs are thread-safe when used as directed below.

// Return a new graph object.
public static native TF_Graph TF_NewGraph();

// Destroy an options object.  Graph will be deleted once no more
// TFSession's are referencing it.
public static native void TF_DeleteGraph(TF_Graph arg0);

// Operation being built. The underlying graph must outlive this.

// Operation that has been added to the graph. Valid until the graph is
// deleted -- in particular adding a new operation to the graph does not
// invalidate old TF_Operation* pointers.
// Targeting ../TF_Input.java


// Targeting ../TF_Output.java



// TF_Function is a grouping of operations with defined inputs and outputs.
// Once created and added to graphs, functions can be invoked by creating an
// operation whose operation type matches the function name.
// Targeting ../TF_FunctionOptions.java



// Sets the shape of the Tensor referenced by `output` in `graph` to
// the shape described by `dims` and `num_dims`.
//
// If the number of dimensions is unknown, `num_dims` must be set to
// -1 and `dims` can be null. If a dimension is unknown, the
// corresponding entry in the `dims` array must be -1.
//
// This does not overwrite the existing shape associated with `output`,
// but merges the input shape with the existing shape.  For example,
// setting a shape of [-1, 2] with an existing shape [2, -1] would set
// a final shape of [2, 2] based on shape merging semantics.
//
// Returns an error into `status` if:
//   * `output` is not in `graph`.
//   * An invalid shape is being set (e.g., the shape being set
//     is incompatible with the existing shape).
public static native void TF_GraphSetTensorShape(TF_Graph graph,
                                                  @ByVal TF_Output output,
                                                  @Cast("const int64_t*") LongPointer dims,
                                                  int num_dims,
                                                  TF_Status status);
public static native void TF_GraphSetTensorShape(TF_Graph graph,
                                                  @ByVal TF_Output output,
                                                  @Cast("const int64_t*") LongBuffer dims,
                                                  int num_dims,
                                                  TF_Status status);
public static native void TF_GraphSetTensorShape(TF_Graph graph,
                                                  @ByVal TF_Output output,
                                                  @Cast("const int64_t*") long[] dims,
                                                  int num_dims,
                                                  TF_Status status);

// Returns the number of dimensions of the Tensor referenced by `output`
// in `graph`.
//
// If the number of dimensions in the shape is unknown, returns -1.
//
// Returns an error into `status` if:
//   * `output` is not in `graph`.
public static native int TF_GraphGetTensorNumDims(TF_Graph graph,
                                                   @ByVal TF_Output output,
                                                   TF_Status status);

// Returns the shape of the Tensor referenced by `output` in `graph`
// into `dims`. `dims` must be an array large enough to hold `num_dims`
// entries (e.g., the return value of TF_GraphGetTensorNumDims).
//
// If the number of dimensions in the shape is unknown or the shape is
// a scalar, `dims` will remain untouched. Otherwise, each element of
// `dims` will be set corresponding to the size of the dimension. An
// unknown dimension is represented by `-1`.
//
// Returns an error into `status` if:
//   * `output` is not in `graph`.
//   * `num_dims` does not match the actual number of dimensions.
public static native void TF_GraphGetTensorShape(TF_Graph graph,
                                                  @ByVal TF_Output output,
                                                  @Cast("int64_t*") LongPointer dims, int num_dims,
                                                  TF_Status status);
public static native void TF_GraphGetTensorShape(TF_Graph graph,
                                                  @ByVal TF_Output output,
                                                  @Cast("int64_t*") LongBuffer dims, int num_dims,
                                                  TF_Status status);
public static native void TF_GraphGetTensorShape(TF_Graph graph,
                                                  @ByVal TF_Output output,
                                                  @Cast("int64_t*") long[] dims, int num_dims,
                                                  TF_Status status);

// Operation will only be added to *graph when TF_FinishOperation() is
// called (assuming TF_FinishOperation() does not return an error).
// *graph must not be deleted until after TF_FinishOperation() is
// called.
public static native TF_OperationDescription TF_NewOperation(
    TF_Graph graph, @Cast("const char*") BytePointer op_type, @Cast("const char*") BytePointer oper_name);
public static native TF_OperationDescription TF_NewOperation(
    TF_Graph graph, String op_type, String oper_name);

// Specify the device for `desc`.  Defaults to empty, meaning unconstrained.
public static native void TF_SetDevice(TF_OperationDescription desc,
                                        @Cast("const char*") BytePointer device);
public static native void TF_SetDevice(TF_OperationDescription desc,
                                        String device);

// The calls to TF_AddInput and TF_AddInputList must match (in number,
// order, and type) the op declaration.  For example, the "Concat" op
// has registration:
//   REGISTER_OP("Concat")
//       .Input("concat_dim: int32")
//       .Input("values: N * T")
//       .Output("output: T")
//       .Attr("N: int >= 2")
//       .Attr("T: type");
// that defines two inputs, "concat_dim" and "values" (in that order).
// You must use TF_AddInput() for the first input (since it takes a
// single tensor), and TF_AddInputList() for the second input (since
// it takes a list, even if you were to pass a list with a single
// tensor), as in:
//   TF_OperationDescription* desc = TF_NewOperation(graph, "Concat", "c");
//   TF_Output concat_dim_input = {...};
//   TF_AddInput(desc, concat_dim_input);
//   TF_Output values_inputs[5] = {{...}, ..., {...}};
//   TF_AddInputList(desc, values_inputs, 5);

// For inputs that take a single tensor.
public static native void TF_AddInput(TF_OperationDescription desc,
                                       @ByVal TF_Output input);

// For inputs that take a list of tensors.
// inputs must point to TF_Output[num_inputs].
public static native void TF_AddInputList(TF_OperationDescription desc,
                                           @Const TF_Output inputs,
                                           int num_inputs);

// Call once per control input to `desc`.
public static native void TF_AddControlInput(TF_OperationDescription desc,
                                              TF_Operation input);

// Request that `desc` be co-located on the device where `op`
// is placed.
//
// Use of this is discouraged since the implementation of device placement is
// subject to change. Primarily intended for internal libraries
public static native void TF_ColocateWith(TF_OperationDescription desc,
                                           TF_Operation op);

// Call some TF_SetAttr*() function for every attr that is not
// inferred from an input and doesn't have a default value you wish to
// keep.

// `value` must point to a string of length `length` bytes.
public static native void TF_SetAttrString(TF_OperationDescription desc,
                                            @Cast("const char*") BytePointer attr_name,
                                            @Const Pointer value, @Cast("size_t") long length);
public static native void TF_SetAttrString(TF_OperationDescription desc,
                                            String attr_name,
                                            @Const Pointer value, @Cast("size_t") long length);
// `values` and `lengths` each must have lengths `num_values`.
// `values[i]` must point to a string of length `lengths[i]` bytes.
public static native void TF_SetAttrStringList(TF_OperationDescription desc,
                                                @Cast("const char*") BytePointer attr_name,
                                                @Cast("const void*const*") PointerPointer values,
                                                @Cast("const size_t*") SizeTPointer lengths,
                                                int num_values);
public static native void TF_SetAttrStringList(TF_OperationDescription desc,
                                                @Cast("const char*") BytePointer attr_name,
                                                @Cast("const void*const*") @ByPtrPtr Pointer values,
                                                @Cast("const size_t*") SizeTPointer lengths,
                                                int num_values);
public static native void TF_SetAttrStringList(TF_OperationDescription desc,
                                                String attr_name,
                                                @Cast("const void*const*") @ByPtrPtr Pointer values,
                                                @Cast("const size_t*") SizeTPointer lengths,
                                                int num_values);
public static native void TF_SetAttrInt(TF_OperationDescription desc,
                                         @Cast("const char*") BytePointer attr_name, @Cast("int64_t") long value);
public static native void TF_SetAttrInt(TF_OperationDescription desc,
                                         String attr_name, @Cast("int64_t") long value);
public static native void TF_SetAttrIntList(TF_OperationDescription desc,
                                             @Cast("const char*") BytePointer attr_name,
                                             @Cast("const int64_t*") LongPointer values,
                                             int num_values);
public static native void TF_SetAttrIntList(TF_OperationDescription desc,
                                             String attr_name,
                                             @Cast("const int64_t*") LongBuffer values,
                                             int num_values);
public static native void TF_SetAttrIntList(TF_OperationDescription desc,
                                             @Cast("const char*") BytePointer attr_name,
                                             @Cast("const int64_t*") long[] values,
                                             int num_values);
public static native void TF_SetAttrIntList(TF_OperationDescription desc,
                                             String attr_name,
                                             @Cast("const int64_t*") LongPointer values,
                                             int num_values);
public static native void TF_SetAttrIntList(TF_OperationDescription desc,
                                             @Cast("const char*") BytePointer attr_name,
                                             @Cast("const int64_t*") LongBuffer values,
                                             int num_values);
public static native void TF_SetAttrIntList(TF_OperationDescription desc,
                                             String attr_name,
                                             @Cast("const int64_t*") long[] values,
                                             int num_values);
public static native void TF_SetAttrFloat(TF_OperationDescription desc,
                                           @Cast("const char*") BytePointer attr_name, float value);
public static native void TF_SetAttrFloat(TF_OperationDescription desc,
                                           String attr_name, float value);
public static native void TF_SetAttrFloatList(TF_OperationDescription desc,
                                               @Cast("const char*") BytePointer attr_name,
                                               @Const FloatPointer values,
                                               int num_values);
public static native void TF_SetAttrFloatList(TF_OperationDescription desc,
                                               String attr_name,
                                               @Const FloatBuffer values,
                                               int num_values);
public static native void TF_SetAttrFloatList(TF_OperationDescription desc,
                                               @Cast("const char*") BytePointer attr_name,
                                               @Const float[] values,
                                               int num_values);
public static native void TF_SetAttrFloatList(TF_OperationDescription desc,
                                               String attr_name,
                                               @Const FloatPointer values,
                                               int num_values);
public static native void TF_SetAttrFloatList(TF_OperationDescription desc,
                                               @Cast("const char*") BytePointer attr_name,
                                               @Const FloatBuffer values,
                                               int num_values);
public static native void TF_SetAttrFloatList(TF_OperationDescription desc,
                                               String attr_name,
                                               @Const float[] values,
                                               int num_values);
public static native void TF_SetAttrBool(TF_OperationDescription desc,
                                          @Cast("const char*") BytePointer attr_name,
                                          @Cast("unsigned char") byte value);
public static native void TF_SetAttrBool(TF_OperationDescription desc,
                                          String attr_name,
                                          @Cast("unsigned char") byte value);
public static native void TF_SetAttrBoolList(TF_OperationDescription desc,
                                              @Cast("const char*") BytePointer attr_name,
                                              @Cast("const unsigned char*") BytePointer values,
                                              int num_values);
public static native void TF_SetAttrBoolList(TF_OperationDescription desc,
                                              String attr_name,
                                              @Cast("const unsigned char*") ByteBuffer values,
                                              int num_values);
public static native void TF_SetAttrBoolList(TF_OperationDescription desc,
                                              @Cast("const char*") BytePointer attr_name,
                                              @Cast("const unsigned char*") byte[] values,
                                              int num_values);
public static native void TF_SetAttrBoolList(TF_OperationDescription desc,
                                              String attr_name,
                                              @Cast("const unsigned char*") BytePointer values,
                                              int num_values);
public static native void TF_SetAttrBoolList(TF_OperationDescription desc,
                                              @Cast("const char*") BytePointer attr_name,
                                              @Cast("const unsigned char*") ByteBuffer values,
                                              int num_values);
public static native void TF_SetAttrBoolList(TF_OperationDescription desc,
                                              String attr_name,
                                              @Cast("const unsigned char*") byte[] values,
                                              int num_values);
public static native void TF_SetAttrType(TF_OperationDescription desc,
                                          @Cast("const char*") BytePointer attr_name,
                                          @Cast("TF_DataType") int value);
public static native void TF_SetAttrType(TF_OperationDescription desc,
                                          String attr_name,
                                          @Cast("TF_DataType") int value);
public static native void TF_SetAttrTypeList(TF_OperationDescription desc,
                                              @Cast("const char*") BytePointer attr_name,
                                              @Cast("const TF_DataType*") IntPointer values,
                                              int num_values);
public static native void TF_SetAttrTypeList(TF_OperationDescription desc,
                                              String attr_name,
                                              @Cast("const TF_DataType*") IntBuffer values,
                                              int num_values);
public static native void TF_SetAttrTypeList(TF_OperationDescription desc,
                                              @Cast("const char*") BytePointer attr_name,
                                              @Cast("const TF_DataType*") int[] values,
                                              int num_values);
public static native void TF_SetAttrTypeList(TF_OperationDescription desc,
                                              String attr_name,
                                              @Cast("const TF_DataType*") IntPointer values,
                                              int num_values);
public static native void TF_SetAttrTypeList(TF_OperationDescription desc,
                                              @Cast("const char*") BytePointer attr_name,
                                              @Cast("const TF_DataType*") IntBuffer values,
                                              int num_values);
public static native void TF_SetAttrTypeList(TF_OperationDescription desc,
                                              String attr_name,
                                              @Cast("const TF_DataType*") int[] values,
                                              int num_values);
public static native void TF_SetAttrPlaceholder(TF_OperationDescription desc,
                                                 @Cast("const char*") BytePointer attr_name,
                                                 @Cast("const char*") BytePointer placeholder);
public static native void TF_SetAttrPlaceholder(TF_OperationDescription desc,
                                                 String attr_name,
                                                 String placeholder);

// Set a 'func' attribute to the specified name.
// `value` must point to a string of length `length` bytes.
public static native void TF_SetAttrFuncName(TF_OperationDescription desc,
                                              @Cast("const char*") BytePointer attr_name,
                                              @Cast("const char*") BytePointer value, @Cast("size_t") long length);
public static native void TF_SetAttrFuncName(TF_OperationDescription desc,
                                              String attr_name,
                                              String value, @Cast("size_t") long length);

// Set `num_dims` to -1 to represent "unknown rank".  Otherwise,
// `dims` points to an array of length `num_dims`.  `dims[i]` must be
// >= -1, with -1 meaning "unknown dimension".
public static native void TF_SetAttrShape(TF_OperationDescription desc,
                                           @Cast("const char*") BytePointer attr_name,
                                           @Cast("const int64_t*") LongPointer dims, int num_dims);
public static native void TF_SetAttrShape(TF_OperationDescription desc,
                                           String attr_name,
                                           @Cast("const int64_t*") LongBuffer dims, int num_dims);
public static native void TF_SetAttrShape(TF_OperationDescription desc,
                                           @Cast("const char*") BytePointer attr_name,
                                           @Cast("const int64_t*") long[] dims, int num_dims);
public static native void TF_SetAttrShape(TF_OperationDescription desc,
                                           String attr_name,
                                           @Cast("const int64_t*") LongPointer dims, int num_dims);
public static native void TF_SetAttrShape(TF_OperationDescription desc,
                                           @Cast("const char*") BytePointer attr_name,
                                           @Cast("const int64_t*") LongBuffer dims, int num_dims);
public static native void TF_SetAttrShape(TF_OperationDescription desc,
                                           String attr_name,
                                           @Cast("const int64_t*") long[] dims, int num_dims);
// `dims` and `num_dims` must point to arrays of length `num_shapes`.
// Set `num_dims[i]` to -1 to represent "unknown rank".  Otherwise,
// `dims[i]` points to an array of length `num_dims[i]`.  `dims[i][j]`
// must be >= -1, with -1 meaning "unknown dimension".
public static native void TF_SetAttrShapeList(TF_OperationDescription desc,
                                               @Cast("const char*") BytePointer attr_name,
                                               @Cast("const int64_t*const*") PointerPointer dims,
                                               @Const IntPointer num_dims,
                                               int num_shapes);
public static native void TF_SetAttrShapeList(TF_OperationDescription desc,
                                               @Cast("const char*") BytePointer attr_name,
                                               @Cast("const int64_t*const*") @ByPtrPtr LongPointer dims,
                                               @Const IntPointer num_dims,
                                               int num_shapes);
public static native void TF_SetAttrShapeList(TF_OperationDescription desc,
                                               String attr_name,
                                               @Cast("const int64_t*const*") @ByPtrPtr LongBuffer dims,
                                               @Const IntBuffer num_dims,
                                               int num_shapes);
public static native void TF_SetAttrShapeList(TF_OperationDescription desc,
                                               @Cast("const char*") BytePointer attr_name,
                                               @Cast("const int64_t*const*") @ByPtrPtr long[] dims,
                                               @Const int[] num_dims,
                                               int num_shapes);
public static native void TF_SetAttrShapeList(TF_OperationDescription desc,
                                               String attr_name,
                                               @Cast("const int64_t*const*") @ByPtrPtr LongPointer dims,
                                               @Const IntPointer num_dims,
                                               int num_shapes);
public static native void TF_SetAttrShapeList(TF_OperationDescription desc,
                                               @Cast("const char*") BytePointer attr_name,
                                               @Cast("const int64_t*const*") @ByPtrPtr LongBuffer dims,
                                               @Const IntBuffer num_dims,
                                               int num_shapes);
public static native void TF_SetAttrShapeList(TF_OperationDescription desc,
                                               String attr_name,
                                               @Cast("const int64_t*const*") @ByPtrPtr long[] dims,
                                               @Const int[] num_dims,
                                               int num_shapes);
// `proto` must point to an array of `proto_len` bytes representing a
// binary-serialized TensorShapeProto.
public static native void TF_SetAttrTensorShapeProto(
    TF_OperationDescription desc, @Cast("const char*") BytePointer attr_name, @Const Pointer proto,
    @Cast("size_t") long proto_len, TF_Status status);
public static native void TF_SetAttrTensorShapeProto(
    TF_OperationDescription desc, String attr_name, @Const Pointer proto,
    @Cast("size_t") long proto_len, TF_Status status);
// `protos` and `proto_lens` must point to arrays of length `num_shapes`.
// `protos[i]` must point to an array of `proto_lens[i]` bytes
// representing a binary-serialized TensorShapeProto.
public static native void TF_SetAttrTensorShapeProtoList(
    TF_OperationDescription desc, @Cast("const char*") BytePointer attr_name,
    @Cast("const void*const*") PointerPointer protos, @Cast("const size_t*") SizeTPointer proto_lens, int num_shapes,
    TF_Status status);
public static native void TF_SetAttrTensorShapeProtoList(
    TF_OperationDescription desc, @Cast("const char*") BytePointer attr_name,
    @Cast("const void*const*") @ByPtrPtr Pointer protos, @Cast("const size_t*") SizeTPointer proto_lens, int num_shapes,
    TF_Status status);
public static native void TF_SetAttrTensorShapeProtoList(
    TF_OperationDescription desc, String attr_name,
    @Cast("const void*const*") @ByPtrPtr Pointer protos, @Cast("const size_t*") SizeTPointer proto_lens, int num_shapes,
    TF_Status status);

public static native void TF_SetAttrTensor(TF_OperationDescription desc,
                                            @Cast("const char*") BytePointer attr_name,
                                            TF_Tensor value,
                                            TF_Status status);
public static native void TF_SetAttrTensor(TF_OperationDescription desc,
                                            String attr_name,
                                            TF_Tensor value,
                                            TF_Status status);
public static native void TF_SetAttrTensorList(TF_OperationDescription desc,
                                                @Cast("const char*") BytePointer attr_name,
                                                @Cast("TF_Tensor*const*") PointerPointer values,
                                                int num_values,
                                                TF_Status status);
public static native void TF_SetAttrTensorList(TF_OperationDescription desc,
                                                @Cast("const char*") BytePointer attr_name,
                                                @ByPtrPtr TF_Tensor values,
                                                int num_values,
                                                TF_Status status);
public static native void TF_SetAttrTensorList(TF_OperationDescription desc,
                                                String attr_name,
                                                @ByPtrPtr TF_Tensor values,
                                                int num_values,
                                                TF_Status status);

// `proto` should point to a sequence of bytes of length `proto_len`
// representing a binary serialization of an AttrValue protocol
// buffer.
public static native void TF_SetAttrValueProto(TF_OperationDescription desc,
                                                @Cast("const char*") BytePointer attr_name,
                                                @Const Pointer proto,
                                                @Cast("size_t") long proto_len,
                                                TF_Status status);
public static native void TF_SetAttrValueProto(TF_OperationDescription desc,
                                                String attr_name,
                                                @Const Pointer proto,
                                                @Cast("size_t") long proto_len,
                                                TF_Status status);

// If this function succeeds:
//   * *status is set to an OK value,
//   * a TF_Operation is added to the graph,
//   * a non-null value pointing to the added operation is returned --
//     this value is valid until the underlying graph is deleted.
// Otherwise:
//   * *status is set to a non-OK value,
//   * the graph is not modified,
//   * a null value is returned.
// In either case, it deletes `desc`.
public static native TF_Operation TF_FinishOperation(
    TF_OperationDescription desc, TF_Status status);

// TF_Operation functions.  Operations are immutable once created, so
// these are all query functions.

public static native @Cast("const char*") BytePointer TF_OperationName(TF_Operation oper);
public static native @Cast("const char*") BytePointer TF_OperationOpType(TF_Operation oper);
public static native @Cast("const char*") BytePointer TF_OperationDevice(TF_Operation oper);

public static native int TF_OperationNumOutputs(TF_Operation oper);
public static native @Cast("TF_DataType") int TF_OperationOutputType(@ByVal TF_Output oper_out);
public static native int TF_OperationOutputListLength(TF_Operation oper,
                                                       @Cast("const char*") BytePointer arg_name,
                                                       TF_Status status);
public static native int TF_OperationOutputListLength(TF_Operation oper,
                                                       String arg_name,
                                                       TF_Status status);

public static native int TF_OperationNumInputs(TF_Operation oper);
public static native @Cast("TF_DataType") int TF_OperationInputType(@ByVal TF_Input oper_in);
public static native int TF_OperationInputListLength(TF_Operation oper,
                                                      @Cast("const char*") BytePointer arg_name,
                                                      TF_Status status);
public static native int TF_OperationInputListLength(TF_Operation oper,
                                                      String arg_name,
                                                      TF_Status status);

// In this code:
//   TF_Output producer = TF_OperationInput(consumer);
// There is an edge from producer.oper's output (given by
// producer.index) to consumer.oper's input (given by consumer.index).
public static native @ByVal TF_Output TF_OperationInput(@ByVal TF_Input oper_in);

// Get the number of current consumers of a specific output of an
// operation.  Note that this number can change when new operations
// are added to the graph.
public static native int TF_OperationOutputNumConsumers(@ByVal TF_Output oper_out);

// Get list of all current consumers of a specific output of an
// operation.  `consumers` must point to an array of length at least
// `max_consumers` (ideally set to
// TF_OperationOutputNumConsumers(oper_out)).  Beware that a concurrent
// modification of the graph can increase the number of consumers of
// an operation.  Returns the number of output consumers (should match
// TF_OperationOutputNumConsumers(oper_out)).
public static native int TF_OperationOutputConsumers(@ByVal TF_Output oper_out,
                                                      TF_Input consumers,
                                                      int max_consumers);

// Get the number of control inputs to an operation.
public static native int TF_OperationNumControlInputs(TF_Operation oper);

// Get list of all control inputs to an operation.  `control_inputs` must
// point to an array of length `max_control_inputs` (ideally set to
// TF_OperationNumControlInputs(oper)).  Returns the number of control
// inputs (should match TF_OperationNumControlInputs(oper)).
public static native int TF_OperationGetControlInputs(
    TF_Operation oper, @Cast("TF_Operation**") PointerPointer control_inputs, int max_control_inputs);
public static native int TF_OperationGetControlInputs(
    TF_Operation oper, @ByPtrPtr TF_Operation control_inputs, int max_control_inputs);

// Get the number of operations that have `*oper` as a control input.
// Note that this number can change when new operations are added to
// the graph.
public static native int TF_OperationNumControlOutputs(TF_Operation oper);

// Get the list of operations that have `*oper` as a control input.
// `control_outputs` must point to an array of length at least
// `max_control_outputs` (ideally set to
// TF_OperationNumControlOutputs(oper)). Beware that a concurrent
// modification of the graph can increase the number of control
// outputs.  Returns the number of control outputs (should match
// TF_OperationNumControlOutputs(oper)).
public static native int TF_OperationGetControlOutputs(
    TF_Operation oper, @Cast("TF_Operation**") PointerPointer control_outputs,
    int max_control_outputs);
public static native int TF_OperationGetControlOutputs(
    TF_Operation oper, @ByPtrPtr TF_Operation control_outputs,
    int max_control_outputs);
// Targeting ../TF_AttrMetadata.java



// Returns metadata about the value of the attribute `attr_name` of `oper`.
public static native @ByVal TF_AttrMetadata TF_OperationGetAttrMetadata(
    TF_Operation oper, @Cast("const char*") BytePointer attr_name, TF_Status status);
public static native @ByVal TF_AttrMetadata TF_OperationGetAttrMetadata(
    TF_Operation oper, String attr_name, TF_Status status);

// Fills in `value` with the value of the attribute `attr_name`.  `value` must
// point to an array of length at least `max_length` (ideally set to
// TF_AttrMetadata.total_size from TF_OperationGetAttrMetadata(oper,
// attr_name)).
public static native void TF_OperationGetAttrString(TF_Operation oper,
                                                     @Cast("const char*") BytePointer attr_name,
                                                     Pointer value,
                                                     @Cast("size_t") long max_length,
                                                     TF_Status status);
public static native void TF_OperationGetAttrString(TF_Operation oper,
                                                     String attr_name,
                                                     Pointer value,
                                                     @Cast("size_t") long max_length,
                                                     TF_Status status);

// Get the list of strings in the value of the attribute `attr_name`.  Fills in
// `values` and `lengths`, each of which must point to an array of length at
// least `max_values`.
//
// The elements of values will point to addresses in `storage` which must be at
// least `storage_size` bytes in length.  Ideally, max_values would be set to
// TF_AttrMetadata.list_size and `storage` would be at least
// TF_AttrMetadata.total_size, obtained from TF_OperationGetAttrMetadata(oper,
// attr_name).
//
// Fails if storage_size is too small to hold the requested number of strings.
public static native void TF_OperationGetAttrStringList(
    TF_Operation oper, @Cast("const char*") BytePointer attr_name, @Cast("void**") PointerPointer values, @Cast("size_t*") SizeTPointer lengths,
    int max_values, Pointer storage, @Cast("size_t") long storage_size, TF_Status status);
public static native void TF_OperationGetAttrStringList(
    TF_Operation oper, @Cast("const char*") BytePointer attr_name, @Cast("void**") @ByPtrPtr Pointer values, @Cast("size_t*") SizeTPointer lengths,
    int max_values, Pointer storage, @Cast("size_t") long storage_size, TF_Status status);
public static native void TF_OperationGetAttrStringList(
    TF_Operation oper, String attr_name, @Cast("void**") @ByPtrPtr Pointer values, @Cast("size_t*") SizeTPointer lengths,
    int max_values, Pointer storage, @Cast("size_t") long storage_size, TF_Status status);

public static native void TF_OperationGetAttrInt(TF_Operation oper,
                                                  @Cast("const char*") BytePointer attr_name,
                                                  @Cast("int64_t*") LongPointer value,
                                                  TF_Status status);
public static native void TF_OperationGetAttrInt(TF_Operation oper,
                                                  String attr_name,
                                                  @Cast("int64_t*") LongBuffer value,
                                                  TF_Status status);
public static native void TF_OperationGetAttrInt(TF_Operation oper,
                                                  @Cast("const char*") BytePointer attr_name,
                                                  @Cast("int64_t*") long[] value,
                                                  TF_Status status);
public static native void TF_OperationGetAttrInt(TF_Operation oper,
                                                  String attr_name,
                                                  @Cast("int64_t*") LongPointer value,
                                                  TF_Status status);
public static native void TF_OperationGetAttrInt(TF_Operation oper,
                                                  @Cast("const char*") BytePointer attr_name,
                                                  @Cast("int64_t*") LongBuffer value,
                                                  TF_Status status);
public static native void TF_OperationGetAttrInt(TF_Operation oper,
                                                  String attr_name,
                                                  @Cast("int64_t*") long[] value,
                                                  TF_Status status);

// Fills in `values` with the value of the attribute `attr_name` of `oper`.
// `values` must point to an array of length at least `max_values` (ideally set
// TF_AttrMetadata.list_size from TF_OperationGetAttrMetadata(oper,
// attr_name)).
public static native void TF_OperationGetAttrIntList(TF_Operation oper,
                                                      @Cast("const char*") BytePointer attr_name,
                                                      @Cast("int64_t*") LongPointer values,
                                                      int max_values,
                                                      TF_Status status);
public static native void TF_OperationGetAttrIntList(TF_Operation oper,
                                                      String attr_name,
                                                      @Cast("int64_t*") LongBuffer values,
                                                      int max_values,
                                                      TF_Status status);
public static native void TF_OperationGetAttrIntList(TF_Operation oper,
                                                      @Cast("const char*") BytePointer attr_name,
                                                      @Cast("int64_t*") long[] values,
                                                      int max_values,
                                                      TF_Status status);
public static native void TF_OperationGetAttrIntList(TF_Operation oper,
                                                      String attr_name,
                                                      @Cast("int64_t*") LongPointer values,
                                                      int max_values,
                                                      TF_Status status);
public static native void TF_OperationGetAttrIntList(TF_Operation oper,
                                                      @Cast("const char*") BytePointer attr_name,
                                                      @Cast("int64_t*") LongBuffer values,
                                                      int max_values,
                                                      TF_Status status);
public static native void TF_OperationGetAttrIntList(TF_Operation oper,
                                                      String attr_name,
                                                      @Cast("int64_t*") long[] values,
                                                      int max_values,
                                                      TF_Status status);

public static native void TF_OperationGetAttrFloat(TF_Operation oper,
                                                    @Cast("const char*") BytePointer attr_name,
                                                    FloatPointer value,
                                                    TF_Status status);
public static native void TF_OperationGetAttrFloat(TF_Operation oper,
                                                    String attr_name,
                                                    FloatBuffer value,
                                                    TF_Status status);
public static native void TF_OperationGetAttrFloat(TF_Operation oper,
                                                    @Cast("const char*") BytePointer attr_name,
                                                    float[] value,
                                                    TF_Status status);
public static native void TF_OperationGetAttrFloat(TF_Operation oper,
                                                    String attr_name,
                                                    FloatPointer value,
                                                    TF_Status status);
public static native void TF_OperationGetAttrFloat(TF_Operation oper,
                                                    @Cast("const char*") BytePointer attr_name,
                                                    FloatBuffer value,
                                                    TF_Status status);
public static native void TF_OperationGetAttrFloat(TF_Operation oper,
                                                    String attr_name,
                                                    float[] value,
                                                    TF_Status status);

// Fills in `values` with the value of the attribute `attr_name` of `oper`.
// `values` must point to an array of length at least `max_values` (ideally set
// to TF_AttrMetadata.list_size from TF_OperationGetAttrMetadata(oper,
// attr_name)).
public static native void TF_OperationGetAttrFloatList(TF_Operation oper,
                                                        @Cast("const char*") BytePointer attr_name,
                                                        FloatPointer values,
                                                        int max_values,
                                                        TF_Status status);
public static native void TF_OperationGetAttrFloatList(TF_Operation oper,
                                                        String attr_name,
                                                        FloatBuffer values,
                                                        int max_values,
                                                        TF_Status status);
public static native void TF_OperationGetAttrFloatList(TF_Operation oper,
                                                        @Cast("const char*") BytePointer attr_name,
                                                        float[] values,
                                                        int max_values,
                                                        TF_Status status);
public static native void TF_OperationGetAttrFloatList(TF_Operation oper,
                                                        String attr_name,
                                                        FloatPointer values,
                                                        int max_values,
                                                        TF_Status status);
public static native void TF_OperationGetAttrFloatList(TF_Operation oper,
                                                        @Cast("const char*") BytePointer attr_name,
                                                        FloatBuffer values,
                                                        int max_values,
                                                        TF_Status status);
public static native void TF_OperationGetAttrFloatList(TF_Operation oper,
                                                        String attr_name,
                                                        float[] values,
                                                        int max_values,
                                                        TF_Status status);

public static native void TF_OperationGetAttrBool(TF_Operation oper,
                                                   @Cast("const char*") BytePointer attr_name,
                                                   @Cast("unsigned char*") BytePointer value,
                                                   TF_Status status);
public static native void TF_OperationGetAttrBool(TF_Operation oper,
                                                   String attr_name,
                                                   @Cast("unsigned char*") ByteBuffer value,
                                                   TF_Status status);
public static native void TF_OperationGetAttrBool(TF_Operation oper,
                                                   @Cast("const char*") BytePointer attr_name,
                                                   @Cast("unsigned char*") byte[] value,
                                                   TF_Status status);
public static native void TF_OperationGetAttrBool(TF_Operation oper,
                                                   String attr_name,
                                                   @Cast("unsigned char*") BytePointer value,
                                                   TF_Status status);
public static native void TF_OperationGetAttrBool(TF_Operation oper,
                                                   @Cast("const char*") BytePointer attr_name,
                                                   @Cast("unsigned char*") ByteBuffer value,
                                                   TF_Status status);
public static native void TF_OperationGetAttrBool(TF_Operation oper,
                                                   String attr_name,
                                                   @Cast("unsigned char*") byte[] value,
                                                   TF_Status status);

// Fills in `values` with the value of the attribute `attr_name` of `oper`.
// `values` must point to an array of length at least `max_values` (ideally set
// to TF_AttrMetadata.list_size from TF_OperationGetAttrMetadata(oper,
// attr_name)).
public static native void TF_OperationGetAttrBoolList(TF_Operation oper,
                                                       @Cast("const char*") BytePointer attr_name,
                                                       @Cast("unsigned char*") BytePointer values,
                                                       int max_values,
                                                       TF_Status status);
public static native void TF_OperationGetAttrBoolList(TF_Operation oper,
                                                       String attr_name,
                                                       @Cast("unsigned char*") ByteBuffer values,
                                                       int max_values,
                                                       TF_Status status);
public static native void TF_OperationGetAttrBoolList(TF_Operation oper,
                                                       @Cast("const char*") BytePointer attr_name,
                                                       @Cast("unsigned char*") byte[] values,
                                                       int max_values,
                                                       TF_Status status);
public static native void TF_OperationGetAttrBoolList(TF_Operation oper,
                                                       String attr_name,
                                                       @Cast("unsigned char*") BytePointer values,
                                                       int max_values,
                                                       TF_Status status);
public static native void TF_OperationGetAttrBoolList(TF_Operation oper,
                                                       @Cast("const char*") BytePointer attr_name,
                                                       @Cast("unsigned char*") ByteBuffer values,
                                                       int max_values,
                                                       TF_Status status);
public static native void TF_OperationGetAttrBoolList(TF_Operation oper,
                                                       String attr_name,
                                                       @Cast("unsigned char*") byte[] values,
                                                       int max_values,
                                                       TF_Status status);

public static native void TF_OperationGetAttrType(TF_Operation oper,
                                                   @Cast("const char*") BytePointer attr_name,
                                                   @Cast("TF_DataType*") IntPointer value,
                                                   TF_Status status);
public static native void TF_OperationGetAttrType(TF_Operation oper,
                                                   String attr_name,
                                                   @Cast("TF_DataType*") IntBuffer value,
                                                   TF_Status status);
public static native void TF_OperationGetAttrType(TF_Operation oper,
                                                   @Cast("const char*") BytePointer attr_name,
                                                   @Cast("TF_DataType*") int[] value,
                                                   TF_Status status);
public static native void TF_OperationGetAttrType(TF_Operation oper,
                                                   String attr_name,
                                                   @Cast("TF_DataType*") IntPointer value,
                                                   TF_Status status);
public static native void TF_OperationGetAttrType(TF_Operation oper,
                                                   @Cast("const char*") BytePointer attr_name,
                                                   @Cast("TF_DataType*") IntBuffer value,
                                                   TF_Status status);
public static native void TF_OperationGetAttrType(TF_Operation oper,
                                                   String attr_name,
                                                   @Cast("TF_DataType*") int[] value,
                                                   TF_Status status);

// Fills in `values` with the value of the attribute `attr_name` of `oper`.
// `values` must point to an array of length at least `max_values` (ideally set
// to TF_AttrMetadata.list_size from TF_OperationGetAttrMetadata(oper,
// attr_name)).
public static native void TF_OperationGetAttrTypeList(TF_Operation oper,
                                                       @Cast("const char*") BytePointer attr_name,
                                                       @Cast("TF_DataType*") IntPointer values,
                                                       int max_values,
                                                       TF_Status status);
public static native void TF_OperationGetAttrTypeList(TF_Operation oper,
                                                       String attr_name,
                                                       @Cast("TF_DataType*") IntBuffer values,
                                                       int max_values,
                                                       TF_Status status);
public static native void TF_OperationGetAttrTypeList(TF_Operation oper,
                                                       @Cast("const char*") BytePointer attr_name,
                                                       @Cast("TF_DataType*") int[] values,
                                                       int max_values,
                                                       TF_Status status);
public static native void TF_OperationGetAttrTypeList(TF_Operation oper,
                                                       String attr_name,
                                                       @Cast("TF_DataType*") IntPointer values,
                                                       int max_values,
                                                       TF_Status status);
public static native void TF_OperationGetAttrTypeList(TF_Operation oper,
                                                       @Cast("const char*") BytePointer attr_name,
                                                       @Cast("TF_DataType*") IntBuffer values,
                                                       int max_values,
                                                       TF_Status status);
public static native void TF_OperationGetAttrTypeList(TF_Operation oper,
                                                       String attr_name,
                                                       @Cast("TF_DataType*") int[] values,
                                                       int max_values,
                                                       TF_Status status);

// Fills in `value` with the value of the attribute `attr_name` of `oper`.
// `values` must point to an array of length at least `num_dims` (ideally set to
// TF_Attr_Meta.size from TF_OperationGetAttrMetadata(oper, attr_name)).
public static native void TF_OperationGetAttrShape(TF_Operation oper,
                                                    @Cast("const char*") BytePointer attr_name,
                                                    @Cast("int64_t*") LongPointer value,
                                                    int num_dims,
                                                    TF_Status status);
public static native void TF_OperationGetAttrShape(TF_Operation oper,
                                                    String attr_name,
                                                    @Cast("int64_t*") LongBuffer value,
                                                    int num_dims,
                                                    TF_Status status);
public static native void TF_OperationGetAttrShape(TF_Operation oper,
                                                    @Cast("const char*") BytePointer attr_name,
                                                    @Cast("int64_t*") long[] value,
                                                    int num_dims,
                                                    TF_Status status);
public static native void TF_OperationGetAttrShape(TF_Operation oper,
                                                    String attr_name,
                                                    @Cast("int64_t*") LongPointer value,
                                                    int num_dims,
                                                    TF_Status status);
public static native void TF_OperationGetAttrShape(TF_Operation oper,
                                                    @Cast("const char*") BytePointer attr_name,
                                                    @Cast("int64_t*") LongBuffer value,
                                                    int num_dims,
                                                    TF_Status status);
public static native void TF_OperationGetAttrShape(TF_Operation oper,
                                                    String attr_name,
                                                    @Cast("int64_t*") long[] value,
                                                    int num_dims,
                                                    TF_Status status);

// Fills in `dims` with the list of shapes in the attribute `attr_name` of
// `oper` and `num_dims` with the corresponding number of dimensions. On return,
// for every i where `num_dims[i]` > 0, `dims[i]` will be an array of
// `num_dims[i]` elements. A value of -1 for `num_dims[i]` indicates that the
// i-th shape in the list is unknown.
//
// The elements of `dims` will point to addresses in `storage` which must be
// large enough to hold at least `storage_size` int64_ts.  Ideally, `num_shapes`
// would be set to TF_AttrMetadata.list_size and `storage_size` would be set to
// TF_AttrMetadata.total_size from TF_OperationGetAttrMetadata(oper,
// attr_name).
//
// Fails if storage_size is insufficient to hold the requested shapes.
public static native void TF_OperationGetAttrShapeList(
    TF_Operation oper, @Cast("const char*") BytePointer attr_name, @Cast("int64_t**") PointerPointer dims, IntPointer num_dims,
    int num_shapes, @Cast("int64_t*") LongPointer storage, int storage_size, TF_Status status);
public static native void TF_OperationGetAttrShapeList(
    TF_Operation oper, @Cast("const char*") BytePointer attr_name, @Cast("int64_t**") @ByPtrPtr LongPointer dims, IntPointer num_dims,
    int num_shapes, @Cast("int64_t*") LongPointer storage, int storage_size, TF_Status status);
public static native void TF_OperationGetAttrShapeList(
    TF_Operation oper, String attr_name, @Cast("int64_t**") @ByPtrPtr LongBuffer dims, IntBuffer num_dims,
    int num_shapes, @Cast("int64_t*") LongBuffer storage, int storage_size, TF_Status status);
public static native void TF_OperationGetAttrShapeList(
    TF_Operation oper, @Cast("const char*") BytePointer attr_name, @Cast("int64_t**") @ByPtrPtr long[] dims, int[] num_dims,
    int num_shapes, @Cast("int64_t*") long[] storage, int storage_size, TF_Status status);
public static native void TF_OperationGetAttrShapeList(
    TF_Operation oper, String attr_name, @Cast("int64_t**") @ByPtrPtr LongPointer dims, IntPointer num_dims,
    int num_shapes, @Cast("int64_t*") LongPointer storage, int storage_size, TF_Status status);
public static native void TF_OperationGetAttrShapeList(
    TF_Operation oper, @Cast("const char*") BytePointer attr_name, @Cast("int64_t**") @ByPtrPtr LongBuffer dims, IntBuffer num_dims,
    int num_shapes, @Cast("int64_t*") LongBuffer storage, int storage_size, TF_Status status);
public static native void TF_OperationGetAttrShapeList(
    TF_Operation oper, String attr_name, @Cast("int64_t**") @ByPtrPtr long[] dims, int[] num_dims,
    int num_shapes, @Cast("int64_t*") long[] storage, int storage_size, TF_Status status);

// Sets `value` to the binary-serialized TensorShapeProto of the value of
// `attr_name` attribute of `oper`'.
public static native void TF_OperationGetAttrTensorShapeProto(
    TF_Operation oper, @Cast("const char*") BytePointer attr_name, TF_Buffer value,
    TF_Status status);
public static native void TF_OperationGetAttrTensorShapeProto(
    TF_Operation oper, String attr_name, TF_Buffer value,
    TF_Status status);

// Fills in `values` with binary-serialized TensorShapeProto values of the
// attribute `attr_name` of `oper`. `values` must point to an array of length at
// least `num_values` (ideally set to TF_AttrMetadata.list_size from
// TF_OperationGetAttrMetadata(oper, attr_name)).
public static native void TF_OperationGetAttrTensorShapeProtoList(
    TF_Operation oper, @Cast("const char*") BytePointer attr_name, @Cast("TF_Buffer**") PointerPointer values,
    int max_values, TF_Status status);
public static native void TF_OperationGetAttrTensorShapeProtoList(
    TF_Operation oper, @Cast("const char*") BytePointer attr_name, @ByPtrPtr TF_Buffer values,
    int max_values, TF_Status status);
public static native void TF_OperationGetAttrTensorShapeProtoList(
    TF_Operation oper, String attr_name, @ByPtrPtr TF_Buffer values,
    int max_values, TF_Status status);

// Gets the TF_Tensor valued attribute of `attr_name` of `oper`.
//
// Allocates a new TF_Tensor which the caller is expected to take
// ownership of (and can deallocate using TF_DeleteTensor).
public static native void TF_OperationGetAttrTensor(TF_Operation oper,
                                                     @Cast("const char*") BytePointer attr_name,
                                                     @Cast("TF_Tensor**") PointerPointer value,
                                                     TF_Status status);
public static native void TF_OperationGetAttrTensor(TF_Operation oper,
                                                     @Cast("const char*") BytePointer attr_name,
                                                     @ByPtrPtr TF_Tensor value,
                                                     TF_Status status);
public static native void TF_OperationGetAttrTensor(TF_Operation oper,
                                                     String attr_name,
                                                     @ByPtrPtr TF_Tensor value,
                                                     TF_Status status);

// Fills in `values` with the TF_Tensor values of the attribute `attr_name` of
// `oper`. `values` must point to an array of TF_Tensor* of length at least
// `max_values` (ideally set to TF_AttrMetadata.list_size from
// TF_OperationGetAttrMetadata(oper, attr_name)).
//
// The caller takes ownership of all the non-null TF_Tensor* entries in `values`
// (which can be deleted using TF_DeleteTensor(values[i])).
public static native void TF_OperationGetAttrTensorList(TF_Operation oper,
                                                         @Cast("const char*") BytePointer attr_name,
                                                         @Cast("TF_Tensor**") PointerPointer values,
                                                         int max_values,
                                                         TF_Status status);
public static native void TF_OperationGetAttrTensorList(TF_Operation oper,
                                                         @Cast("const char*") BytePointer attr_name,
                                                         @ByPtrPtr TF_Tensor values,
                                                         int max_values,
                                                         TF_Status status);
public static native void TF_OperationGetAttrTensorList(TF_Operation oper,
                                                         String attr_name,
                                                         @ByPtrPtr TF_Tensor values,
                                                         int max_values,
                                                         TF_Status status);

// Sets `output_attr_value` to the binary-serialized AttrValue proto
// representation of the value of the `attr_name` attr of `oper`.
public static native void TF_OperationGetAttrValueProto(
    TF_Operation oper, @Cast("const char*") BytePointer attr_name, TF_Buffer output_attr_value,
    TF_Status status);
public static native void TF_OperationGetAttrValueProto(
    TF_Operation oper, String attr_name, TF_Buffer output_attr_value,
    TF_Status status);

// Returns the operation in the graph with `oper_name`. Returns nullptr if
// no operation found.
public static native TF_Operation TF_GraphOperationByName(
    TF_Graph graph, @Cast("const char*") BytePointer oper_name);
public static native TF_Operation TF_GraphOperationByName(
    TF_Graph graph, String oper_name);

// Iterate through the operations of a graph.  To use:
// size_t pos = 0;
// TF_Operation* oper;
// while ((oper = TF_GraphNextOperation(graph, &pos)) != nullptr) {
//   DoSomethingWithOperation(oper);
// }
public static native TF_Operation TF_GraphNextOperation(TF_Graph graph,
                                                          @Cast("size_t*") SizeTPointer pos);

// Write out a serialized representation of `graph` (as a GraphDef protocol
// message) to `output_graph_def` (allocated by TF_NewBuffer()).
// `output_graph_def`'s underlying buffer will be freed when TF_DeleteBuffer()
// is called.
//
// May fail on very large graphs in the future.
public static native void TF_GraphToGraphDef(TF_Graph graph,
                                              TF_Buffer output_graph_def,
                                              TF_Status status);

// Returns the serialized OpDef proto with name `op_name`, or a bad status if no
// such op exists. This can return OpDefs of functions copied into the graph.
public static native void TF_GraphGetOpDef(TF_Graph graph,
                                            @Cast("const char*") BytePointer op_name,
                                            TF_Buffer output_op_def,
                                            TF_Status status);
public static native void TF_GraphGetOpDef(TF_Graph graph,
                                            String op_name,
                                            TF_Buffer output_op_def,
                                            TF_Status status);

// Returns the serialized VersionDef proto for this graph.
public static native void TF_GraphVersions(TF_Graph graph,
                                            TF_Buffer output_version_def,
                                            TF_Status status);

// TF_ImportGraphDefOptions holds options that can be passed to
// TF_GraphImportGraphDef.

public static native TF_ImportGraphDefOptions TF_NewImportGraphDefOptions();
public static native void TF_DeleteImportGraphDefOptions(
    TF_ImportGraphDefOptions opts);

// Set the prefix to be prepended to the names of nodes in `graph_def` that will
// be imported into `graph`. `prefix` is copied and has no lifetime
// requirements.
public static native void TF_ImportGraphDefOptionsSetPrefix(
    TF_ImportGraphDefOptions opts, @Cast("const char*") BytePointer prefix);
public static native void TF_ImportGraphDefOptionsSetPrefix(
    TF_ImportGraphDefOptions opts, String prefix);

// Set the execution device for nodes in `graph_def`.
// Only applies to nodes where a device was not already explicitly specified.
// `device` is copied and has no lifetime requirements.
public static native void TF_ImportGraphDefOptionsSetDefaultDevice(
    TF_ImportGraphDefOptions opts, @Cast("const char*") BytePointer device);
public static native void TF_ImportGraphDefOptionsSetDefaultDevice(
    TF_ImportGraphDefOptions opts, String device);

// Set whether to uniquify imported operation names. If true, imported operation
// names will be modified if their name already exists in the graph. If false,
// conflicting names will be treated as an error. Note that this option has no
// effect if a prefix is set, since the prefix will guarantee all names are
// unique. Defaults to false.
public static native void TF_ImportGraphDefOptionsSetUniquifyNames(
    TF_ImportGraphDefOptions opts, @Cast("unsigned char") byte uniquify_names);

// If true, the specified prefix will be modified if it already exists as an
// operation name or prefix in the graph. If false, a conflicting prefix will be
// treated as an error. This option has no effect if no prefix is specified.
public static native void TF_ImportGraphDefOptionsSetUniquifyPrefix(
    TF_ImportGraphDefOptions opts, @Cast("unsigned char") byte uniquify_prefix);

// Set any imported nodes with input `src_name:src_index` to have that input
// replaced with `dst`. `src_name` refers to a node in the graph to be imported,
// `dst` references a node already existing in the graph being imported into.
// `src_name` is copied and has no lifetime requirements.
public static native void TF_ImportGraphDefOptionsAddInputMapping(
    TF_ImportGraphDefOptions opts, @Cast("const char*") BytePointer src_name, int src_index,
    @ByVal TF_Output dst);
public static native void TF_ImportGraphDefOptionsAddInputMapping(
    TF_ImportGraphDefOptions opts, String src_name, int src_index,
    @ByVal TF_Output dst);

// Set any imported nodes with control input `src_name` to have that input
// replaced with `dst`. `src_name` refers to a node in the graph to be imported,
// `dst` references an operation already existing in the graph being imported
// into. `src_name` is copied and has no lifetime requirements.
public static native void TF_ImportGraphDefOptionsRemapControlDependency(
    TF_ImportGraphDefOptions opts, @Cast("const char*") BytePointer src_name, TF_Operation dst);
public static native void TF_ImportGraphDefOptionsRemapControlDependency(
    TF_ImportGraphDefOptions opts, String src_name, TF_Operation dst);

// Cause the imported graph to have a control dependency on `oper`. `oper`
// should exist in the graph being imported into.
public static native void TF_ImportGraphDefOptionsAddControlDependency(
    TF_ImportGraphDefOptions opts, TF_Operation oper);

// Add an output in `graph_def` to be returned via the `return_outputs` output
// parameter of TF_GraphImportGraphDef(). If the output is remapped via an input
// mapping, the corresponding existing tensor in `graph` will be returned.
// `oper_name` is copied and has no lifetime requirements.
public static native void TF_ImportGraphDefOptionsAddReturnOutput(
    TF_ImportGraphDefOptions opts, @Cast("const char*") BytePointer oper_name, int index);
public static native void TF_ImportGraphDefOptionsAddReturnOutput(
    TF_ImportGraphDefOptions opts, String oper_name, int index);

// Returns the number of return outputs added via
// TF_ImportGraphDefOptionsAddReturnOutput().
public static native int TF_ImportGraphDefOptionsNumReturnOutputs(
    @Const TF_ImportGraphDefOptions opts);

// Add an operation in `graph_def` to be returned via the `return_opers` output
// parameter of TF_GraphImportGraphDef(). `oper_name` is copied and has no
// lifetime requirements.
public static native void TF_ImportGraphDefOptionsAddReturnOperation(
    TF_ImportGraphDefOptions opts, @Cast("const char*") BytePointer oper_name);
public static native void TF_ImportGraphDefOptionsAddReturnOperation(
    TF_ImportGraphDefOptions opts, String oper_name);

// Returns the number of return operations added via
// TF_ImportGraphDefOptionsAddReturnOperation().
public static native int TF_ImportGraphDefOptionsNumReturnOperations(
    @Const TF_ImportGraphDefOptions opts);

// TF_ImportGraphDefResults holds results that are generated by
// TF_GraphImportGraphDefWithResults().

// Fetches the return outputs requested via
// TF_ImportGraphDefOptionsAddReturnOutput(). The number of fetched outputs is
// returned in `num_outputs`. The array of return outputs is returned in
// `outputs`. `*outputs` is owned by and has the lifetime of `results`.
public static native void TF_ImportGraphDefResultsReturnOutputs(
    TF_ImportGraphDefResults results, IntPointer num_outputs, @Cast("TF_Output**") PointerPointer outputs);
public static native void TF_ImportGraphDefResultsReturnOutputs(
    TF_ImportGraphDefResults results, IntPointer num_outputs, @ByPtrPtr TF_Output outputs);
public static native void TF_ImportGraphDefResultsReturnOutputs(
    TF_ImportGraphDefResults results, IntBuffer num_outputs, @ByPtrPtr TF_Output outputs);
public static native void TF_ImportGraphDefResultsReturnOutputs(
    TF_ImportGraphDefResults results, int[] num_outputs, @ByPtrPtr TF_Output outputs);

// Fetches the return operations requested via
// TF_ImportGraphDefOptionsAddReturnOperation(). The number of fetched
// operations is returned in `num_opers`. The array of return operations is
// returned in `opers`. `*opers` is owned by and has the lifetime of `results`.
public static native void TF_ImportGraphDefResultsReturnOperations(
    TF_ImportGraphDefResults results, IntPointer num_opers, @Cast("TF_Operation***") @ByPtrPtr PointerPointer opers);
public static native void TF_ImportGraphDefResultsReturnOperations(
    TF_ImportGraphDefResults results, IntBuffer num_opers, @Cast("TF_Operation***") @ByPtrPtr PointerPointer opers);
public static native void TF_ImportGraphDefResultsReturnOperations(
    TF_ImportGraphDefResults results, int[] num_opers, @Cast("TF_Operation***") @ByPtrPtr PointerPointer opers);

// Fetches any input mappings requested via
// TF_ImportGraphDefOptionsAddInputMapping() that didn't appear in the GraphDef
// and weren't used as input to any node in the imported graph def. The number
// of fetched mappings is returned in `num_missing_unused_input_mappings`. The
// array of each mapping's source node name is returned in `src_names`, and the
// array of each mapping's source index is returned in `src_indexes`.
//
// `*src_names`, `*src_indexes`, and the memory backing each string in
// `src_names` are owned by and have the lifetime of `results`.
public static native void TF_ImportGraphDefResultsMissingUnusedInputMappings(
    TF_ImportGraphDefResults results, IntPointer num_missing_unused_input_mappings,
    @Cast("const char***") @ByPtrPtr PointerPointer src_names, @Cast("int**") PointerPointer src_indexes);
public static native void TF_ImportGraphDefResultsMissingUnusedInputMappings(
    TF_ImportGraphDefResults results, IntPointer num_missing_unused_input_mappings,
    @Cast("const char***") @ByPtrPtr PointerPointer src_names, @ByPtrPtr IntPointer src_indexes);
public static native void TF_ImportGraphDefResultsMissingUnusedInputMappings(
    TF_ImportGraphDefResults results, IntBuffer num_missing_unused_input_mappings,
    @Cast("const char***") @ByPtrPtr PointerPointer src_names, @ByPtrPtr IntBuffer src_indexes);
public static native void TF_ImportGraphDefResultsMissingUnusedInputMappings(
    TF_ImportGraphDefResults results, int[] num_missing_unused_input_mappings,
    @Cast("const char***") @ByPtrPtr PointerPointer src_names, @ByPtrPtr int... src_indexes);

// Deletes a results object returned by TF_GraphImportGraphDefWithResults().
public static native void TF_DeleteImportGraphDefResults(
    TF_ImportGraphDefResults results);

// Import the graph serialized in `graph_def` into `graph`.  Returns nullptr and
// a bad status on error. Otherwise, returns a populated
// TF_ImportGraphDefResults instance. The returned instance must be deleted via
// TF_DeleteImportGraphDefResults().
public static native TF_ImportGraphDefResults TF_GraphImportGraphDefWithResults(TF_Graph graph, @Const TF_Buffer graph_def,
                                  @Const TF_ImportGraphDefOptions options,
                                  TF_Status status);

// Import the graph serialized in `graph_def` into `graph`.
// Convenience function for when only return outputs are needed.
//
// `num_return_outputs` must be the number of return outputs added (i.e. the
// result of TF_ImportGraphDefOptionsNumReturnOutputs()).  If
// `num_return_outputs` is non-zero, `return_outputs` must be of length
// `num_return_outputs`. Otherwise it can be null.
public static native void TF_GraphImportGraphDefWithReturnOutputs(
    TF_Graph graph, @Const TF_Buffer graph_def,
    @Const TF_ImportGraphDefOptions options, TF_Output return_outputs,
    int num_return_outputs, TF_Status status);

// Import the graph serialized in `graph_def` into `graph`.
// Convenience function for when no results are needed.
public static native void TF_GraphImportGraphDef(
    TF_Graph graph, @Const TF_Buffer graph_def,
    @Const TF_ImportGraphDefOptions options, TF_Status status);

// Adds a copy of function `func` and optionally its gradient function `grad`
// to `g`. Once `func`/`grad` is added to `g`, it can be called by creating
// an operation using the function's name.
// Any changes to `func`/`grad` (including deleting it) done after this method
// returns, won't affect the copy of `func`/`grad` in `g`.
// If `func` or `grad` are already in `g`, TF_GraphCopyFunction has no
// effect on them, but can establish the function->gradient relationship
// between them if `func` does not already have a gradient. If `func` already
// has a gradient different from `grad`, an error is returned.
//
// `func` must not be null.
// If `grad` is null and `func` is not in `g`, `func` is added without a
// gradient.
// If `grad` is null and `func` is in `g`, TF_GraphCopyFunction is a noop.
// `grad` must have appropriate signature as described in the doc of
// GradientDef in tensorflow/core/framework/function.proto.
//
// If successful, status is set to OK and `func` and `grad` are added to `g`.
// Otherwise, status is set to the encountered error and `g` is unmodified.
public static native void TF_GraphCopyFunction(TF_Graph g,
                                                @Const TF_Function func,
                                                @Const TF_Function grad,
                                                TF_Status status);

// Returns the number of TF_Functions registered in `g`.
public static native int TF_GraphNumFunctions(TF_Graph g);

// Fills in `funcs` with the TF_Function* registered in `g`.
// `funcs` must point to an array of TF_Function* of length at least
// `max_func`. In usual usage, max_func should be set to the result of
// TF_GraphNumFunctions(g). In this case, all the functions registered in
// `g` will be returned. Else, an unspecified subset.
//
// If successful, returns the number of TF_Function* successfully set in
// `funcs` and sets status to OK. The caller takes ownership of
// all the returned TF_Functions. They must be deleted with TF_DeleteFunction.
// On error, returns 0, sets status to the encountered error, and the contents
// of funcs will be undefined.
public static native int TF_GraphGetFunctions(TF_Graph g, @Cast("TF_Function**") PointerPointer funcs,
                                               int max_func, TF_Status status);
public static native int TF_GraphGetFunctions(TF_Graph g, @ByPtrPtr TF_Function funcs,
                                               int max_func, TF_Status status);

// Note: The following function may fail on very large protos in the future.

public static native void TF_OperationToNodeDef(TF_Operation oper,
                                                 TF_Buffer output_node_def,
                                                 TF_Status status);
// Targeting ../TF_WhileParams.java



// Creates a TF_WhileParams for creating a while loop in `g`. `inputs` are
// outputs that already exist in `g` used as initial values for the loop
// variables.
//
// The returned TF_WhileParams will have all fields initialized except
// `cond_output`, `body_outputs`, and `name`. The `body_outputs` buffer will be
// allocated to size `ninputs`. The caller should build `cond_graph` and
// `body_graph` starting from the inputs, and store the final outputs in
// `cond_output` and `body_outputs`.
//
// If `status` is OK, the caller must call either TF_FinishWhile or
// TF_AbortWhile on the returned TF_WhileParams. If `status` isn't OK, the
// returned TF_WhileParams is not valid, and the caller should not call
// TF_FinishWhile() or TF_AbortWhile().
//
// Missing functionality (TODO):
// - Gradients
// - Reference-type inputs
// - Directly referencing external tensors from the cond/body graphs (this is
//   possible in the Python API)
public static native @ByVal TF_WhileParams TF_NewWhile(TF_Graph g, TF_Output inputs,
                                                 int ninputs,
                                                 TF_Status status);

// Builds the while loop specified by `params` and returns the output tensors of
// the while loop in `outputs`. `outputs` should be allocated to size
// `params.ninputs`.
//
// `params` is no longer valid once this returns.
//
// Either this or TF_AbortWhile() must be called after a successful
// TF_NewWhile() call.
public static native void TF_FinishWhile(@Const TF_WhileParams params,
                                          TF_Status status,
                                          TF_Output outputs);

// Frees `params`s resources without building a while loop. `params` is no
// longer valid after this returns. Either this or TF_FinishWhile() must be
// called after a successful TF_NewWhile() call.
public static native void TF_AbortWhile(@Const TF_WhileParams params);

// Adds operations to compute the partial derivatives of sum of `y`s w.r.t `x`s,
// i.e., d(y_1 + y_2 + ...)/dx_1, d(y_1 + y_2 + ...)/dx_2...
//
// `dx` are used as initial gradients (which represent the symbolic partial
// derivatives of some loss function `L` w.r.t. `y`).
// `dx` must be nullptr or have size `ny`.
// If `dx` is nullptr, the implementation will use dx of `OnesLike` for all
// shapes in `y`.
// The partial derivatives are returned in `dy`. `dy` should be allocated to
// size `nx`.
//
// Gradient nodes are automatically named under the "gradients/" prefix. To
// guarantee name uniqueness, subsequent calls to the same graph will
// append an incremental tag to the prefix: "gradients_1/", "gradients_2/", ...
// See TF_AddGradientsWithPrefix, which provides a means to specify a custom
// name prefix for operations added to a graph to compute the gradients.
//
// WARNING: This function does not yet support all the gradients that python
// supports. See
// https://www.tensorflow.org/code/tensorflow/cc/gradients/README.md
// for instructions on how to add C++ more gradients.
public static native void TF_AddGradients(TF_Graph g, TF_Output y, int ny,
                                    TF_Output x, int nx, TF_Output dx,
                                    TF_Status status, TF_Output dy);

// Adds operations to compute the partial derivatives of sum of `y`s w.r.t `x`s,
// i.e., d(y_1 + y_2 + ...)/dx_1, d(y_1 + y_2 + ...)/dx_2...
// This is a variant of TF_AddGradients that allows to caller to pass a custom
// name prefix to the operations added to a graph to compute the gradients.
//
// `dx` are used as initial gradients (which represent the symbolic partial
// derivatives of some loss function `L` w.r.t. `y`).
// `dx` must be nullptr or have size `ny`.
// If `dx` is nullptr, the implementation will use dx of `OnesLike` for all
// shapes in `y`.
// The partial derivatives are returned in `dy`. `dy` should be allocated to
// size `nx`.
// `prefix` names the scope into which all gradients operations are being added.
// `prefix` must be unique within the provided graph otherwise this operation
// will fail. If `prefix` is nullptr, the default prefixing behaviour takes
// place, see TF_AddGradients for more details.
//
// WARNING: This function does not yet support all the gradients that python
// supports. See
// https://www.tensorflow.org/code/tensorflow/cc/gradients/README.md
// for instructions on how to add C++ more gradients.
public static native void TF_AddGradientsWithPrefix(TF_Graph g, @Cast("const char*") BytePointer prefix,
                                              TF_Output y, int ny,
                                              TF_Output x, int nx,
                                              TF_Output dx, TF_Status status,
                                              TF_Output dy);
public static native void TF_AddGradientsWithPrefix(TF_Graph g, String prefix,
                                              TF_Output y, int ny,
                                              TF_Output x, int nx,
                                              TF_Output dx, TF_Status status,
                                              TF_Output dy);

// Create a TF_Function from a TF_Graph
//
// Params:
//  fn_body - the graph whose operations (or subset of whose operations) will be
//            converted to TF_Function.
//  fn_name - the name of the new TF_Function. Should match the operation
//            name (OpDef.name) regexp [A-Z][A-Za-z0-9_.\\-/]*.
//            If `append_hash_to_fn_name` is false, `fn_name` must be distinct
//            from other function and operation names (at least those
//            registered in graphs where this function will be used).
//  append_hash_to_fn_name - Must be 0 or 1. If set to 1, the actual name
//                           of the function will be `fn_name` appended with
//                           '_<hash_of_this_function's_definition>'.
//                           If set to 0, the function's name will be `fn_name`.
//  num_opers - `num_opers` contains the number of elements in the `opers` array
//              or a special value of -1 meaning that no array is given.
//              The distinction between an empty array of operations and no
//              array of operations is necessary to distinguish the case of
//              creating a function with no body (e.g. identity or permutation)
//              and the case of creating a function whose body contains all
//              the nodes in the graph (except for the automatic skipping, see
//              below).
//  opers - Array of operations to become the body of the function or null.
//          - If no array is given (`num_opers`  = -1), all the
//          operations in `fn_body` will become part of the function
//          except operations referenced in `inputs`. These operations
//          must have a single output (these operations are typically
//          placeholders created for the sole purpose of representing
//          an input. We can relax this constraint if there are
//          compelling use cases).
//          - If an array is given (`num_opers` >= 0), all operations
//          in it will become part of the function. In particular, no
//          automatic skipping of dummy input operations is performed.
//  ninputs - number of elements in `inputs` array
//  inputs - array of TF_Outputs that specify the inputs to the function.
//           If `ninputs` is zero (the function takes no inputs), `inputs`
//           can be null. The names used for function inputs are normalized
//           names of the operations (usually placeholders) pointed to by
//           `inputs`. These operation names should start with a letter.
//           Normalization will convert all letters to lowercase and
//           non-alphanumeric characters to '_' to make resulting names match
//           the "[a-z][a-z0-9_]*" pattern for operation argument names.
//           `inputs` cannot contain the same tensor twice.
//  noutputs - number of elements in `outputs` array
//  outputs - array of TF_Outputs that specify the outputs of the function.
//            If `noutputs` is zero (the function returns no outputs), `outputs`
//            can be null. `outputs` can contain the same tensor more than once.
//  output_names - The names of the function's outputs. `output_names` array
//                 must either have the same length as `outputs`
//                 (i.e. `noutputs`) or be null. In the former case,
//                 the names should match the regular expression for ArgDef
//                 names - "[a-z][a-z0-9_]*". In the latter case,
//                 names for outputs will be generated automatically.
//  opts - various options for the function, e.g. XLA's inlining control.
//  description - optional human-readable description of this function.
//  status - Set to OK on success and an appropriate error on failure.
//
// Note that when the same TF_Output is listed as both an input and an output,
// the corresponding function's output will equal to this input,
// instead of the original node's output.
//
// Callers must also satisfy the following constraints:
// - `inputs` cannot refer to TF_Outputs within a control flow context. For
//   example, one cannot use the output of "switch" node as input.
// - `inputs` and `outputs` cannot have reference types. Reference types are
//   not exposed through C API and are being replaced with Resources. We support
//   reference types inside function's body to support legacy code. Do not
//   use them in new code.
// - Every node in the function's body must have all of its inputs (including
//   control inputs). In other words, for every node in the body, each input
//   must be either listed in `inputs` or must come from another node in
//   the body. In particular, it is an error to have a control edge going from
//   a node outside of the body into a node in the body. This applies to control
//   edges going from nodes referenced in `inputs` to nodes in the body when
//   the former nodes are not in the body (automatically skipped or not
//   included in explicitly specified body).
//
// Returns:
//  On success, a newly created TF_Function instance. It must be deleted by
//  calling TF_DeleteFunction.
//
//  On failure, null.
public static native TF_Function TF_GraphToFunction(
    @Const TF_Graph fn_body, @Cast("const char*") BytePointer fn_name,
    @Cast("unsigned char") byte append_hash_to_fn_name, int num_opers,
    @Cast("const TF_Operation*const*") PointerPointer opers, int ninputs, @Const TF_Output inputs,
    int noutputs, @Const TF_Output outputs, @Cast("const char*const*") PointerPointer output_names,
    @Const TF_FunctionOptions opts, @Cast("const char*") BytePointer description, TF_Status status);
public static native TF_Function TF_GraphToFunction(
    @Const TF_Graph fn_body, @Cast("const char*") BytePointer fn_name,
    @Cast("unsigned char") byte append_hash_to_fn_name, int num_opers,
    @Const @ByPtrPtr TF_Operation opers, int ninputs, @Const TF_Output inputs,
    int noutputs, @Const TF_Output outputs, @Cast("const char*const*") @ByPtrPtr BytePointer output_names,
    @Const TF_FunctionOptions opts, @Cast("const char*") BytePointer description, TF_Status status);
public static native TF_Function TF_GraphToFunction(
    @Const TF_Graph fn_body, String fn_name,
    @Cast("unsigned char") byte append_hash_to_fn_name, int num_opers,
    @Const @ByPtrPtr TF_Operation opers, int ninputs, @Const TF_Output inputs,
    int noutputs, @Const TF_Output outputs, @Cast("const char*const*") @ByPtrPtr ByteBuffer output_names,
    @Const TF_FunctionOptions opts, String description, TF_Status status);
public static native TF_Function TF_GraphToFunction(
    @Const TF_Graph fn_body, @Cast("const char*") BytePointer fn_name,
    @Cast("unsigned char") byte append_hash_to_fn_name, int num_opers,
    @Const @ByPtrPtr TF_Operation opers, int ninputs, @Const TF_Output inputs,
    int noutputs, @Const TF_Output outputs, @Cast("const char*const*") @ByPtrPtr byte[] output_names,
    @Const TF_FunctionOptions opts, @Cast("const char*") BytePointer description, TF_Status status);
public static native TF_Function TF_GraphToFunction(
    @Const TF_Graph fn_body, String fn_name,
    @Cast("unsigned char") byte append_hash_to_fn_name, int num_opers,
    @Const @ByPtrPtr TF_Operation opers, int ninputs, @Const TF_Output inputs,
    int noutputs, @Const TF_Output outputs, @Cast("const char*const*") @ByPtrPtr BytePointer output_names,
    @Const TF_FunctionOptions opts, String description, TF_Status status);
public static native TF_Function TF_GraphToFunction(
    @Const TF_Graph fn_body, @Cast("const char*") BytePointer fn_name,
    @Cast("unsigned char") byte append_hash_to_fn_name, int num_opers,
    @Const @ByPtrPtr TF_Operation opers, int ninputs, @Const TF_Output inputs,
    int noutputs, @Const TF_Output outputs, @Cast("const char*const*") @ByPtrPtr ByteBuffer output_names,
    @Const TF_FunctionOptions opts, @Cast("const char*") BytePointer description, TF_Status status);
public static native TF_Function TF_GraphToFunction(
    @Const TF_Graph fn_body, String fn_name,
    @Cast("unsigned char") byte append_hash_to_fn_name, int num_opers,
    @Const @ByPtrPtr TF_Operation opers, int ninputs, @Const TF_Output inputs,
    int noutputs, @Const TF_Output outputs, @Cast("const char*const*") @ByPtrPtr byte[] output_names,
    @Const TF_FunctionOptions opts, String description, TF_Status status);

// Similar to TF_GraphToFunction but allows specifying control outputs of the
// function.
//
//  The arguments of TF_GraphToFunction have the same meaning, but the new
//  arguments are as follows:
//
//    ncontrol_outputs: Number of control outputs of the function.
//    control_outputs: vector of TF_Operation objects to be marked as control
//      outputs of the function. Operations marked as control outputs are
//      guaranteed to execute.
//    control_output_names: Optional. If not nullptr, vector of strings, one
//      per control output, with their names to be added to the function's
//      OpDef.
public static native TF_Function TF_GraphToFunctionWithControlOutputs(
    @Const TF_Graph fn_body, @Cast("const char*") BytePointer fn_name,
    @Cast("unsigned char") byte append_hash_to_fn_name, int num_opers,
    @Cast("const TF_Operation*const*") PointerPointer opers, int ninputs, @Const TF_Output inputs,
    int noutputs, @Const TF_Output outputs, @Cast("const char*const*") PointerPointer output_names,
    int ncontrol_outputs, @Cast("const TF_Operation*const*") PointerPointer control_outputs,
    @Cast("const char*const*") PointerPointer control_output_names, @Const TF_FunctionOptions opts,
    @Cast("const char*") BytePointer description, TF_Status status);
public static native TF_Function TF_GraphToFunctionWithControlOutputs(
    @Const TF_Graph fn_body, @Cast("const char*") BytePointer fn_name,
    @Cast("unsigned char") byte append_hash_to_fn_name, int num_opers,
    @Const @ByPtrPtr TF_Operation opers, int ninputs, @Const TF_Output inputs,
    int noutputs, @Const TF_Output outputs, @Cast("const char*const*") @ByPtrPtr BytePointer output_names,
    int ncontrol_outputs, @Const @ByPtrPtr TF_Operation control_outputs,
    @Cast("const char*const*") @ByPtrPtr BytePointer control_output_names, @Const TF_FunctionOptions opts,
    @Cast("const char*") BytePointer description, TF_Status status);
public static native TF_Function TF_GraphToFunctionWithControlOutputs(
    @Const TF_Graph fn_body, String fn_name,
    @Cast("unsigned char") byte append_hash_to_fn_name, int num_opers,
    @Const @ByPtrPtr TF_Operation opers, int ninputs, @Const TF_Output inputs,
    int noutputs, @Const TF_Output outputs, @Cast("const char*const*") @ByPtrPtr ByteBuffer output_names,
    int ncontrol_outputs, @Const @ByPtrPtr TF_Operation control_outputs,
    @Cast("const char*const*") @ByPtrPtr ByteBuffer control_output_names, @Const TF_FunctionOptions opts,
    String description, TF_Status status);
public static native TF_Function TF_GraphToFunctionWithControlOutputs(
    @Const TF_Graph fn_body, @Cast("const char*") BytePointer fn_name,
    @Cast("unsigned char") byte append_hash_to_fn_name, int num_opers,
    @Const @ByPtrPtr TF_Operation opers, int ninputs, @Const TF_Output inputs,
    int noutputs, @Const TF_Output outputs, @Cast("const char*const*") @ByPtrPtr byte[] output_names,
    int ncontrol_outputs, @Const @ByPtrPtr TF_Operation control_outputs,
    @Cast("const char*const*") @ByPtrPtr byte[] control_output_names, @Const TF_FunctionOptions opts,
    @Cast("const char*") BytePointer description, TF_Status status);
public static native TF_Function TF_GraphToFunctionWithControlOutputs(
    @Const TF_Graph fn_body, String fn_name,
    @Cast("unsigned char") byte append_hash_to_fn_name, int num_opers,
    @Const @ByPtrPtr TF_Operation opers, int ninputs, @Const TF_Output inputs,
    int noutputs, @Const TF_Output outputs, @Cast("const char*const*") @ByPtrPtr BytePointer output_names,
    int ncontrol_outputs, @Const @ByPtrPtr TF_Operation control_outputs,
    @Cast("const char*const*") @ByPtrPtr BytePointer control_output_names, @Const TF_FunctionOptions opts,
    String description, TF_Status status);
public static native TF_Function TF_GraphToFunctionWithControlOutputs(
    @Const TF_Graph fn_body, @Cast("const char*") BytePointer fn_name,
    @Cast("unsigned char") byte append_hash_to_fn_name, int num_opers,
    @Const @ByPtrPtr TF_Operation opers, int ninputs, @Const TF_Output inputs,
    int noutputs, @Const TF_Output outputs, @Cast("const char*const*") @ByPtrPtr ByteBuffer output_names,
    int ncontrol_outputs, @Const @ByPtrPtr TF_Operation control_outputs,
    @Cast("const char*const*") @ByPtrPtr ByteBuffer control_output_names, @Const TF_FunctionOptions opts,
    @Cast("const char*") BytePointer description, TF_Status status);
public static native TF_Function TF_GraphToFunctionWithControlOutputs(
    @Const TF_Graph fn_body, String fn_name,
    @Cast("unsigned char") byte append_hash_to_fn_name, int num_opers,
    @Const @ByPtrPtr TF_Operation opers, int ninputs, @Const TF_Output inputs,
    int noutputs, @Const TF_Output outputs, @Cast("const char*const*") @ByPtrPtr byte[] output_names,
    int ncontrol_outputs, @Const @ByPtrPtr TF_Operation control_outputs,
    @Cast("const char*const*") @ByPtrPtr byte[] control_output_names, @Const TF_FunctionOptions opts,
    String description, TF_Status status);

// Returns the name of the graph function.
// The return value points to memory that is only usable until the next
// mutation to *func.
public static native @Cast("const char*") BytePointer TF_FunctionName(TF_Function func);

// Write out a serialized representation of `func` (as a FunctionDef protocol
// message) to `output_func_def` (allocated by TF_NewBuffer()).
// `output_func_def`'s underlying buffer will be freed when TF_DeleteBuffer()
// is called.
//
// May fail on very large graphs in the future.
public static native void TF_FunctionToFunctionDef(TF_Function func,
                                                    TF_Buffer output_func_def,
                                                    TF_Status status);

// Construct and return the function whose FunctionDef representation is
// serialized in `proto`. `proto_len` must equal the number of bytes
// pointed to by `proto`.
// Returns:
//  On success, a newly created TF_Function instance. It must be deleted by
//  calling TF_DeleteFunction.
//
//  On failure, null.
public static native TF_Function TF_FunctionImportFunctionDef(
    @Const Pointer proto, @Cast("size_t") long proto_len, TF_Status status);

// Sets function attribute named `attr_name` to value stored in `proto`.
// If this attribute is already set to another value, it is overridden.
// `proto` should point to a sequence of bytes of length `proto_len`
// representing a binary serialization of an AttrValue protocol
// buffer.
public static native void TF_FunctionSetAttrValueProto(TF_Function func,
                                                        @Cast("const char*") BytePointer attr_name,
                                                        @Const Pointer proto,
                                                        @Cast("size_t") long proto_len,
                                                        TF_Status status);
public static native void TF_FunctionSetAttrValueProto(TF_Function func,
                                                        String attr_name,
                                                        @Const Pointer proto,
                                                        @Cast("size_t") long proto_len,
                                                        TF_Status status);

// Sets `output_attr_value` to the binary-serialized AttrValue proto
// representation of the value of the `attr_name` attr of `func`.
// If `attr_name` attribute is not present, status is set to an error.
public static native void TF_FunctionGetAttrValueProto(
    TF_Function func, @Cast("const char*") BytePointer attr_name, TF_Buffer output_attr_value,
    TF_Status status);
public static native void TF_FunctionGetAttrValueProto(
    TF_Function func, String attr_name, TF_Buffer output_attr_value,
    TF_Status status);

// Frees the memory used by the `func` struct.
// TF_DeleteFunction is a noop if `func` is null.
// Deleting a function does not remove it from any graphs it was copied to.
public static native void TF_DeleteFunction(TF_Function func);

// Attempts to evaluate `output`. This will only be possible if `output` doesn't
// depend on any graph inputs (this function is safe to call if this isn't the
// case though).
//
// If the evaluation is successful, this function returns true and `output`s
// value is returned in `result`. Otherwise returns false. An error status is
// returned if something is wrong with the graph or input. Note that this may
// return false even if no error status is set.
public static native @Cast("unsigned char") byte TF_TryEvaluateConstant(TF_Graph graph,
                                                           @ByVal TF_Output output,
                                                           @Cast("TF_Tensor**") PointerPointer result,
                                                           TF_Status status);
public static native @Cast("unsigned char") byte TF_TryEvaluateConstant(TF_Graph graph,
                                                           @ByVal TF_Output output,
                                                           @ByPtrPtr TF_Tensor result,
                                                           TF_Status status);

// TODO(josh11b): Register OpDef, available to all operations added
// to this graph.

// --------------------------------------------------------------------------
// API for driving Graph execution.

// Return a new execution session with the associated graph, or NULL on
// error. Does not take ownership of any input parameters.
//
// *`graph` must be a valid graph (not deleted or nullptr). `graph` will be be
// kept alive for the lifetime of the returned TF_Session. New nodes can still
// be added to `graph` after this call.
public static native TF_Session TF_NewSession(TF_Graph graph,
                                                @Const TF_SessionOptions opts,
                                                TF_Status status);

// This function creates a new TF_Session (which is created on success) using
// `session_options`, and then initializes state (restoring tensors and other
// assets) using `run_options`.
//
// Any NULL and non-NULL value combinations for (`run_options, `meta_graph_def`)
// are valid.
//
// - `export_dir` must be set to the path of the exported SavedModel.
// - `tags` must include the set of tags used to identify one MetaGraphDef in
//    the SavedModel.
// - `graph` must be a graph newly allocated with TF_NewGraph().
//
// If successful, populates `graph` with the contents of the Graph and
// `meta_graph_def` with the MetaGraphDef of the loaded model.
public static native @Platform(not="android") TF_Session TF_LoadSessionFromSavedModel(
    @Const TF_SessionOptions session_options, @Const TF_Buffer run_options,
    @Cast("const char*") BytePointer export_dir, @Cast("const char*const*") PointerPointer tags, int tags_len,
    TF_Graph graph, TF_Buffer meta_graph_def, TF_Status status);
public static native @Platform(not="android") TF_Session TF_LoadSessionFromSavedModel(
    @Const TF_SessionOptions session_options, @Const TF_Buffer run_options,
    @Cast("const char*") BytePointer export_dir, @Cast("const char*const*") @ByPtrPtr BytePointer tags, int tags_len,
    TF_Graph graph, TF_Buffer meta_graph_def, TF_Status status);
public static native @Platform(not="android") TF_Session TF_LoadSessionFromSavedModel(
    @Const TF_SessionOptions session_options, @Const TF_Buffer run_options,
    String export_dir, @Cast("const char*const*") @ByPtrPtr ByteBuffer tags, int tags_len,
    TF_Graph graph, TF_Buffer meta_graph_def, TF_Status status);
public static native @Platform(not="android") TF_Session TF_LoadSessionFromSavedModel(
    @Const TF_SessionOptions session_options, @Const TF_Buffer run_options,
    @Cast("const char*") BytePointer export_dir, @Cast("const char*const*") @ByPtrPtr byte[] tags, int tags_len,
    TF_Graph graph, TF_Buffer meta_graph_def, TF_Status status);
public static native @Platform(not="android") TF_Session TF_LoadSessionFromSavedModel(
    @Const TF_SessionOptions session_options, @Const TF_Buffer run_options,
    String export_dir, @Cast("const char*const*") @ByPtrPtr BytePointer tags, int tags_len,
    TF_Graph graph, TF_Buffer meta_graph_def, TF_Status status);
public static native @Platform(not="android") TF_Session TF_LoadSessionFromSavedModel(
    @Const TF_SessionOptions session_options, @Const TF_Buffer run_options,
    @Cast("const char*") BytePointer export_dir, @Cast("const char*const*") @ByPtrPtr ByteBuffer tags, int tags_len,
    TF_Graph graph, TF_Buffer meta_graph_def, TF_Status status);
public static native @Platform(not="android") TF_Session TF_LoadSessionFromSavedModel(
    @Const TF_SessionOptions session_options, @Const TF_Buffer run_options,
    String export_dir, @Cast("const char*const*") @ByPtrPtr byte[] tags, int tags_len,
    TF_Graph graph, TF_Buffer meta_graph_def, TF_Status status);

// Close a session.
//
// Contacts any other processes associated with the session, if applicable.
// May not be called after TF_DeleteSession().
public static native void TF_CloseSession(TF_Session arg0, TF_Status status);

// Destroy a session object.
//
// Even if error information is recorded in *status, this call discards all
// local resources associated with the session.  The session may not be used
// during or after this call (and the session drops its reference to the
// corresponding graph).
public static native void TF_DeleteSession(TF_Session arg0, TF_Status status);

// Run the graph associated with the session starting with the supplied inputs
// (inputs[0,ninputs-1] with corresponding values in input_values[0,ninputs-1]).
//
// Any NULL and non-NULL value combinations for (`run_options`,
// `run_metadata`) are valid.
//
//    - `run_options` may be NULL, in which case it will be ignored; or
//      non-NULL, in which case it must point to a `TF_Buffer` containing the
//      serialized representation of a `RunOptions` protocol buffer.
//    - `run_metadata` may be NULL, in which case it will be ignored; or
//      non-NULL, in which case it must point to an empty, freshly allocated
//      `TF_Buffer` that may be updated to contain the serialized representation
//      of a `RunMetadata` protocol buffer.
//
// The caller retains ownership of `input_values` (which can be deleted using
// TF_DeleteTensor). The caller also retains ownership of `run_options` and/or
// `run_metadata` (when not NULL) and should manually call TF_DeleteBuffer on
// them.
//
// On success, the tensors corresponding to outputs[0,noutputs-1] are placed in
// output_values[]. Ownership of the elements of output_values[] is transferred
// to the caller, which must eventually call TF_DeleteTensor on them.
//
// On failure, output_values[] contains NULLs.
public static native void TF_SessionRun(
    TF_Session session,
    @Const TF_Buffer run_options,
    @Const TF_Output inputs, @Cast("TF_Tensor*const*") PointerPointer input_values, int ninputs,
    @Const TF_Output outputs, @Cast("TF_Tensor**") PointerPointer output_values, int noutputs,
    @Cast("const TF_Operation*const*") PointerPointer target_opers, int ntargets,
    TF_Buffer run_metadata,
    TF_Status arg11);
public static native void TF_SessionRun(
    TF_Session session,
    @Const TF_Buffer run_options,
    @Const TF_Output inputs, @ByPtrPtr TF_Tensor input_values, int ninputs,
    @Const TF_Output outputs, @ByPtrPtr TF_Tensor output_values, int noutputs,
    @Const @ByPtrPtr TF_Operation target_opers, int ntargets,
    TF_Buffer run_metadata,
    TF_Status arg11);

// Set up the graph with the intended feeds (inputs) and fetches (outputs) for a
// sequence of partial run calls.
//
// On success, returns a handle that is used for subsequent PRun calls. The
// handle should be deleted with TF_DeletePRunHandle when it is no longer
// needed.
//
// On failure, out_status contains a tensorflow::Status with an error
// message. *handle is set to nullptr.
public static native void TF_SessionPRunSetup(
    TF_Session arg0,
    @Const TF_Output inputs, int ninputs,
    @Const TF_Output outputs, int noutputs,
    @Cast("const TF_Operation*const*") PointerPointer target_opers, int ntargets,
    @Cast("const char**") PointerPointer handle,
    TF_Status arg8);
public static native void TF_SessionPRunSetup(
    TF_Session arg0,
    @Const TF_Output inputs, int ninputs,
    @Const TF_Output outputs, int noutputs,
    @Const @ByPtrPtr TF_Operation target_opers, int ntargets,
    @Cast("const char**") @ByPtrPtr BytePointer handle,
    TF_Status arg8);
public static native void TF_SessionPRunSetup(
    TF_Session arg0,
    @Const TF_Output inputs, int ninputs,
    @Const TF_Output outputs, int noutputs,
    @Const @ByPtrPtr TF_Operation target_opers, int ntargets,
    @Cast("const char**") @ByPtrPtr ByteBuffer handle,
    TF_Status arg8);
public static native void TF_SessionPRunSetup(
    TF_Session arg0,
    @Const TF_Output inputs, int ninputs,
    @Const TF_Output outputs, int noutputs,
    @Const @ByPtrPtr TF_Operation target_opers, int ntargets,
    @Cast("const char**") @ByPtrPtr byte[] handle,
    TF_Status arg8);

// Continue to run the graph with additional feeds and fetches. The
// execution state is uniquely identified by the handle.
public static native void TF_SessionPRun(
    TF_Session arg0, @Cast("const char*") BytePointer handle,
    @Const TF_Output inputs, @Cast("TF_Tensor*const*") PointerPointer input_values, int ninputs,
    @Const TF_Output outputs, @Cast("TF_Tensor**") PointerPointer output_values, int noutputs,
    @Cast("const TF_Operation*const*") PointerPointer target_opers, int ntargets,
    TF_Status arg10);
public static native void TF_SessionPRun(
    TF_Session arg0, @Cast("const char*") BytePointer handle,
    @Const TF_Output inputs, @ByPtrPtr TF_Tensor input_values, int ninputs,
    @Const TF_Output outputs, @ByPtrPtr TF_Tensor output_values, int noutputs,
    @Const @ByPtrPtr TF_Operation target_opers, int ntargets,
    TF_Status arg10);
public static native void TF_SessionPRun(
    TF_Session arg0, String handle,
    @Const TF_Output inputs, @ByPtrPtr TF_Tensor input_values, int ninputs,
    @Const TF_Output outputs, @ByPtrPtr TF_Tensor output_values, int noutputs,
    @Const @ByPtrPtr TF_Operation target_opers, int ntargets,
    TF_Status arg10);

// Deletes a handle allocated by TF_SessionPRunSetup.
// Once called, no more calls to TF_SessionPRun should be made.
public static native void TF_DeletePRunHandle(@Cast("const char*") BytePointer handle);
public static native void TF_DeletePRunHandle(String handle);

// --------------------------------------------------------------------------
// The deprecated session API.  Please switch to the above instead of
// TF_ExtendGraph(). This deprecated API can be removed at any time without
// notice.

public static native TF_DeprecatedSession TF_NewDeprecatedSession(
    @Const TF_SessionOptions arg0, TF_Status status);
public static native void TF_CloseDeprecatedSession(TF_DeprecatedSession arg0,
                                                     TF_Status status);
public static native void TF_DeleteDeprecatedSession(TF_DeprecatedSession arg0,
                                                      TF_Status status);
public static native void TF_Reset(@Const TF_SessionOptions opt,
                                    @Cast("const char**") PointerPointer containers, int ncontainers,
                                    TF_Status status);
public static native void TF_Reset(@Const TF_SessionOptions opt,
                                    @Cast("const char**") @ByPtrPtr BytePointer containers, int ncontainers,
                                    TF_Status status);
public static native void TF_Reset(@Const TF_SessionOptions opt,
                                    @Cast("const char**") @ByPtrPtr ByteBuffer containers, int ncontainers,
                                    TF_Status status);
public static native void TF_Reset(@Const TF_SessionOptions opt,
                                    @Cast("const char**") @ByPtrPtr byte[] containers, int ncontainers,
                                    TF_Status status);
// Treat the bytes proto[0,proto_len-1] as a serialized GraphDef and
// add the nodes in that GraphDef to the graph for the session.
//
// Prefer use of TF_Session and TF_GraphImportGraphDef over this.
public static native void TF_ExtendGraph(TF_DeprecatedSession arg0,
                                          @Const Pointer proto, @Cast("size_t") long proto_len,
                                          TF_Status arg3);

// See TF_SessionRun() above.
public static native void TF_Run(TF_DeprecatedSession arg0,
                                  @Const TF_Buffer run_options,
                                  @Cast("const char**") PointerPointer input_names, @Cast("TF_Tensor**") PointerPointer inputs,
                                  int ninputs, @Cast("const char**") PointerPointer output_names,
                                  @Cast("TF_Tensor**") PointerPointer outputs, int noutputs,
                                  @Cast("const char**") PointerPointer target_oper_names, int ntargets,
                                  TF_Buffer run_metadata, TF_Status arg11);
public static native void TF_Run(TF_DeprecatedSession arg0,
                                  @Const TF_Buffer run_options,
                                  @Cast("const char**") @ByPtrPtr BytePointer input_names, @ByPtrPtr TF_Tensor inputs,
                                  int ninputs, @Cast("const char**") @ByPtrPtr BytePointer output_names,
                                  @ByPtrPtr TF_Tensor outputs, int noutputs,
                                  @Cast("const char**") @ByPtrPtr BytePointer target_oper_names, int ntargets,
                                  TF_Buffer run_metadata, TF_Status arg11);
public static native void TF_Run(TF_DeprecatedSession arg0,
                                  @Const TF_Buffer run_options,
                                  @Cast("const char**") @ByPtrPtr ByteBuffer input_names, @ByPtrPtr TF_Tensor inputs,
                                  int ninputs, @Cast("const char**") @ByPtrPtr ByteBuffer output_names,
                                  @ByPtrPtr TF_Tensor outputs, int noutputs,
                                  @Cast("const char**") @ByPtrPtr ByteBuffer target_oper_names, int ntargets,
                                  TF_Buffer run_metadata, TF_Status arg11);
public static native void TF_Run(TF_DeprecatedSession arg0,
                                  @Const TF_Buffer run_options,
                                  @Cast("const char**") @ByPtrPtr byte[] input_names, @ByPtrPtr TF_Tensor inputs,
                                  int ninputs, @Cast("const char**") @ByPtrPtr byte[] output_names,
                                  @ByPtrPtr TF_Tensor outputs, int noutputs,
                                  @Cast("const char**") @ByPtrPtr byte[] target_oper_names, int ntargets,
                                  TF_Buffer run_metadata, TF_Status arg11);

// See TF_SessionPRunSetup() above.
public static native void TF_PRunSetup(TF_DeprecatedSession arg0,
                                        @Cast("const char**") PointerPointer input_names, int ninputs,
                                        @Cast("const char**") PointerPointer output_names, int noutputs,
                                        @Cast("const char**") PointerPointer target_oper_names,
                                        int ntargets, @Cast("const char**") PointerPointer handle,
                                        TF_Status arg8);
public static native void TF_PRunSetup(TF_DeprecatedSession arg0,
                                        @Cast("const char**") @ByPtrPtr BytePointer input_names, int ninputs,
                                        @Cast("const char**") @ByPtrPtr BytePointer output_names, int noutputs,
                                        @Cast("const char**") @ByPtrPtr BytePointer target_oper_names,
                                        int ntargets, @Cast("const char**") @ByPtrPtr BytePointer handle,
                                        TF_Status arg8);
public static native void TF_PRunSetup(TF_DeprecatedSession arg0,
                                        @Cast("const char**") @ByPtrPtr ByteBuffer input_names, int ninputs,
                                        @Cast("const char**") @ByPtrPtr ByteBuffer output_names, int noutputs,
                                        @Cast("const char**") @ByPtrPtr ByteBuffer target_oper_names,
                                        int ntargets, @Cast("const char**") @ByPtrPtr ByteBuffer handle,
                                        TF_Status arg8);
public static native void TF_PRunSetup(TF_DeprecatedSession arg0,
                                        @Cast("const char**") @ByPtrPtr byte[] input_names, int ninputs,
                                        @Cast("const char**") @ByPtrPtr byte[] output_names, int noutputs,
                                        @Cast("const char**") @ByPtrPtr byte[] target_oper_names,
                                        int ntargets, @Cast("const char**") @ByPtrPtr byte[] handle,
                                        TF_Status arg8);

// See TF_SessionPRun above.
public static native void TF_PRun(TF_DeprecatedSession arg0, @Cast("const char*") BytePointer handle,
                                   @Cast("const char**") PointerPointer input_names, @Cast("TF_Tensor**") PointerPointer inputs,
                                   int ninputs, @Cast("const char**") PointerPointer output_names,
                                   @Cast("TF_Tensor**") PointerPointer outputs, int noutputs,
                                   @Cast("const char**") PointerPointer target_oper_names, int ntargets,
                                   TF_Status arg10);
public static native void TF_PRun(TF_DeprecatedSession arg0, @Cast("const char*") BytePointer handle,
                                   @Cast("const char**") @ByPtrPtr BytePointer input_names, @ByPtrPtr TF_Tensor inputs,
                                   int ninputs, @Cast("const char**") @ByPtrPtr BytePointer output_names,
                                   @ByPtrPtr TF_Tensor outputs, int noutputs,
                                   @Cast("const char**") @ByPtrPtr BytePointer target_oper_names, int ntargets,
                                   TF_Status arg10);
public static native void TF_PRun(TF_DeprecatedSession arg0, String handle,
                                   @Cast("const char**") @ByPtrPtr ByteBuffer input_names, @ByPtrPtr TF_Tensor inputs,
                                   int ninputs, @Cast("const char**") @ByPtrPtr ByteBuffer output_names,
                                   @ByPtrPtr TF_Tensor outputs, int noutputs,
                                   @Cast("const char**") @ByPtrPtr ByteBuffer target_oper_names, int ntargets,
                                   TF_Status arg10);
public static native void TF_PRun(TF_DeprecatedSession arg0, @Cast("const char*") BytePointer handle,
                                   @Cast("const char**") @ByPtrPtr byte[] input_names, @ByPtrPtr TF_Tensor inputs,
                                   int ninputs, @Cast("const char**") @ByPtrPtr byte[] output_names,
                                   @ByPtrPtr TF_Tensor outputs, int noutputs,
                                   @Cast("const char**") @ByPtrPtr byte[] target_oper_names, int ntargets,
                                   TF_Status arg10);
public static native void TF_PRun(TF_DeprecatedSession arg0, String handle,
                                   @Cast("const char**") @ByPtrPtr BytePointer input_names, @ByPtrPtr TF_Tensor inputs,
                                   int ninputs, @Cast("const char**") @ByPtrPtr BytePointer output_names,
                                   @ByPtrPtr TF_Tensor outputs, int noutputs,
                                   @Cast("const char**") @ByPtrPtr BytePointer target_oper_names, int ntargets,
                                   TF_Status arg10);
public static native void TF_PRun(TF_DeprecatedSession arg0, @Cast("const char*") BytePointer handle,
                                   @Cast("const char**") @ByPtrPtr ByteBuffer input_names, @ByPtrPtr TF_Tensor inputs,
                                   int ninputs, @Cast("const char**") @ByPtrPtr ByteBuffer output_names,
                                   @ByPtrPtr TF_Tensor outputs, int noutputs,
                                   @Cast("const char**") @ByPtrPtr ByteBuffer target_oper_names, int ntargets,
                                   TF_Status arg10);
public static native void TF_PRun(TF_DeprecatedSession arg0, String handle,
                                   @Cast("const char**") @ByPtrPtr byte[] input_names, @ByPtrPtr TF_Tensor inputs,
                                   int ninputs, @Cast("const char**") @ByPtrPtr byte[] output_names,
                                   @ByPtrPtr TF_Tensor outputs, int noutputs,
                                   @Cast("const char**") @ByPtrPtr byte[] target_oper_names, int ntargets,
                                   TF_Status arg10);

// Lists all devices in a TF_Session.
//
// Caller takes ownership of the returned TF_DeviceList* which must eventually
// be freed with a call to TF_DeleteDeviceList.
public static native TF_DeviceList TF_SessionListDevices(TF_Session session,
                                                           TF_Status status);

// Lists all devices in a TF_Session.
//
// Caller takes ownership of the returned TF_DeviceList* which must eventually
// be freed with a call to TF_DeleteDeviceList.
public static native TF_DeviceList TF_DeprecatedSessionListDevices(
    TF_DeprecatedSession session, TF_Status status);

// Deallocates the device list.
public static native void TF_DeleteDeviceList(TF_DeviceList list);

// Counts the number of elements in the device list.
public static native int TF_DeviceListCount(@Const TF_DeviceList list);

// Retrieves the full name of the device (e.g. /job:worker/replica:0/...)
// The return value will be a pointer to a null terminated string. The caller
// must not modify or delete the string. It will be deallocated upon a call to
// TF_DeleteDeviceList.
//
// If index is out of bounds, an error code will be set in the status object,
// and a null pointer will be returned.
public static native @Cast("const char*") BytePointer TF_DeviceListName(@Const TF_DeviceList list,
                                                    int index,
                                                    TF_Status status);

// Retrieves the type of the device at the given index.
//
// The caller must not modify or delete the string. It will be deallocated upon
// a call to TF_DeleteDeviceList.
//
// If index is out of bounds, an error code will be set in the status object,
// and a null pointer will be returned.
public static native @Cast("const char*") BytePointer TF_DeviceListType(@Const TF_DeviceList list,
                                                    int index,
                                                    TF_Status status);

// Retrieve the amount of memory associated with a given device.
//
// If index is out of bounds, an error code will be set in the status object,
// and -1 will be returned.
public static native @Cast("int64_t") long TF_DeviceListMemoryBytes(
    @Const TF_DeviceList list, int index, TF_Status status);

// Retrieve the incarnation number of a given device.
//
// If index is out of bounds, an error code will be set in the status object,
// and 0 will be returned.
public static native @Cast("uint64_t") long TF_DeviceListIncarnation(
    @Const TF_DeviceList list, int index, TF_Status status);

// --------------------------------------------------------------------------
// Load plugins containing custom ops and kernels

// TF_Library holds information about dynamically loaded TensorFlow plugins.

// Load the library specified by library_filename and register the ops and
// kernels present in that library.
//
// Pass "library_filename" to a platform-specific mechanism for dynamically
// loading a library. The rules for determining the exact location of the
// library are platform-specific and are not documented here.
//
// On success, place OK in status and return the newly created library handle.
// The caller owns the library handle.
//
// On failure, place an error status in status and return NULL.
public static native TF_Library TF_LoadLibrary(@Cast("const char*") BytePointer library_filename,
                                                 TF_Status status);
public static native TF_Library TF_LoadLibrary(String library_filename,
                                                 TF_Status status);

// Get the OpList of OpDefs defined in the library pointed by lib_handle.
//
// Returns a TF_Buffer. The memory pointed to by the result is owned by
// lib_handle. The data in the buffer will be the serialized OpList proto for
// ops defined in the library.
public static native @ByVal TF_Buffer TF_GetOpList(TF_Library lib_handle);

// Frees the memory associated with the library handle.
// Does NOT unload the library.
public static native void TF_DeleteLibraryHandle(TF_Library lib_handle);

// Get the OpList of all OpDefs defined in this address space.
// Returns a TF_Buffer, ownership of which is transferred to the caller
// (and can be freed using TF_DeleteBuffer).
//
// The data in the buffer will be the serialized OpList proto for ops registered
// in this address space.
public static native TF_Buffer TF_GetAllOpList();

// TF_ApiDefMap encapsulates a collection of API definitions for an operation.
//
// This object maps the name of a TensorFlow operation to a description of the
// API to generate for it, as defined by the ApiDef protocol buffer (
// https://www.tensorflow.org/code/tensorflow/core/framework/api_def.proto)
//
// The ApiDef messages are typically used to generate convenience wrapper
// functions for TensorFlow operations in various language bindings.

// Creates a new TF_ApiDefMap instance.
//
// Params:
//  op_list_buffer - TF_Buffer instance containing serialized OpList
//    protocol buffer. (See
//    https://www.tensorflow.org/code/tensorflow/core/framework/op_def.proto
//    for the OpList proto definition).
//  status - Set to OK on success and an appropriate error on failure.
public static native TF_ApiDefMap TF_NewApiDefMap(TF_Buffer op_list_buffer,
                                                    TF_Status status);

// Deallocates a TF_ApiDefMap.
public static native void TF_DeleteApiDefMap(TF_ApiDefMap apimap);

// Add ApiDefs to the map.
//
// `text` corresponds to a text representation of an ApiDefs protocol message.
// (https://www.tensorflow.org/code/tensorflow/core/framework/api_def.proto).
//
// The provided ApiDefs will be merged with existing ones in the map, with
// precedence given to the newly added version in case of conflicts with
// previous calls to TF_ApiDefMapPut.
public static native void TF_ApiDefMapPut(TF_ApiDefMap api_def_map,
                                           @Cast("const char*") BytePointer text, @Cast("size_t") long text_len,
                                           TF_Status status);
public static native void TF_ApiDefMapPut(TF_ApiDefMap api_def_map,
                                           String text, @Cast("size_t") long text_len,
                                           TF_Status status);

// Returns a serialized ApiDef protocol buffer for the TensorFlow operation
// named `name`.
public static native TF_Buffer TF_ApiDefMapGet(TF_ApiDefMap api_def_map,
                                                 @Cast("const char*") BytePointer name,
                                                 @Cast("size_t") long name_len,
                                                 TF_Status status);
public static native TF_Buffer TF_ApiDefMapGet(TF_ApiDefMap api_def_map,
                                                 String name,
                                                 @Cast("size_t") long name_len,
                                                 TF_Status status);

// --------------------------------------------------------------------------
// Kernel definition information.

// Returns a serialized KernelList protocol buffer containing KernelDefs for all
// registered kernels.
public static native TF_Buffer TF_GetAllRegisteredKernels(TF_Status status);

// Returns a serialized KernelList protocol buffer containing KernelDefs for all
// kernels registered for the operation named `name`.
public static native TF_Buffer TF_GetRegisteredKernelsForOp(
    @Cast("const char*") BytePointer name, TF_Status status);
public static native TF_Buffer TF_GetRegisteredKernelsForOp(
    String name, TF_Status status);

// --------------------------------------------------------------------------
// In-process TensorFlow server functionality, for use in distributed training.
// A Server instance encapsulates a set of devices and a Session target that
// can participate in distributed training. A server belongs to a cluster
// (specified by a ClusterSpec), and corresponds to a particular task in a
// named job. The server can communicate with any other server in the same
// cluster.

// In-process TensorFlow server.

// Creates a new in-process TensorFlow server configured using a serialized
// ServerDef protocol buffer provided via `proto` and `proto_len`.
//
// The server will not serve any requests until TF_ServerStart is invoked.
// The server will stop serving requests once TF_ServerStop or
// TF_DeleteServer is invoked.
public static native TF_Server TF_NewServer(@Const Pointer proto,
                                              @Cast("size_t") long proto_len,
                                              TF_Status status);

// Starts an in-process TensorFlow server.
public static native void TF_ServerStart(TF_Server server, TF_Status status);

// Stops an in-process TensorFlow server.
public static native void TF_ServerStop(TF_Server server, TF_Status status);

// Blocks until the server has been successfully stopped (via TF_ServerStop or
// TF_ServerClose).
public static native void TF_ServerJoin(TF_Server server, TF_Status status);

// Returns the target string that can be provided to TF_SetTarget() to connect
// a TF_Session to `server`.
//
// The returned string is valid only until TF_DeleteServer is invoked.
public static native @Cast("const char*") BytePointer TF_ServerTarget(TF_Server server);

// Destroy an in-process TensorFlow server, frees memory. If server is running
// it will be stopped and joined.
public static native void TF_DeleteServer(TF_Server server);
// Targeting ../Listener_BytePointer.java


public static native void TF_RegisterLogListener(
    Listener_BytePointer listener);
// Targeting ../Listener_String.java


public static native void TF_RegisterLogListener(
    Listener_String listener);

// #ifdef __cplusplus /* end extern "C" */
// #endif

// #endif  // TENSORFLOW_C_C_API_H_


// Parsed from tensorflow/c/c_api_internal.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_C_C_API_INTERNAL_H_
// #define TENSORFLOW_C_C_API_INTERNAL_H_

// #include "tensorflow/c/c_api.h"

// #include <list>
// #include <set>
// #include <string>
// #include <unordered_map>
// #include <vector>

// clang-format off
// Required for IS_MOBILE_PLATFORM
// #include "tensorflow/core/platform/platform.h"
// clang-format on

// #include "tensorflow/c/tf_status_internal.h"
// #include "tensorflow/c/tf_tensor_internal.h"
// #if !defined(IS_MOBILE_PLATFORM) && !defined(IS_SLIM_BUILD)
// #include "tensorflow/core/framework/op_gen_lib.h"
// #endif  // !defined(IS_MOBILE_PLATFORM) && !defined(IS_SLIM_BUILD)
// #include "tensorflow/core/common_runtime/shape_refiner.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/graph/graph.h"
// #include "tensorflow/core/graph/graph_constructor.h"
// #include "tensorflow/core/graph/node_builder.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/platform/mutex.h"
// #include "tensorflow/core/platform/types.h"
// #include "tensorflow/core/public/session.h"

// Targeting ../TF_SessionOptions.java


// Targeting ../TF_DeprecatedSession.java


// Targeting ../TF_Library.java


// Targeting ../TF_Graph.java


// Targeting ../TF_OperationDescription.java


// Targeting ../TF_Operation.java


// Targeting ../TF_Session.java


// Targeting ../TF_ImportGraphDefOptions.java


// Targeting ../TF_ImportGraphDefResults.java


// Targeting ../TF_DeviceList.java


// Targeting ../TF_Function.java


// Targeting ../TF_ApiDefMap.java


// Targeting ../TF_Server.java


// #endif  // !defined(IS_MOBILE_PLATFORM) && !defined(IS_SLIM_BUILD)

@Namespace("tensorflow") public static native @ByVal Status TF_TensorToTensor(@Const TF_Tensor src, Tensor dst);

@Namespace("tensorflow") public static native TF_Tensor TF_TensorFromTensor(@Const @ByRef Tensor src, TF_Status status);

@Namespace("tensorflow") public static native @ByVal Status MessageToBuffer(@Cast("const tensorflow::protobuf::MessageLite*") @ByRef MessageLite in,
                       TF_Buffer out);

// Set the shapes and types of the output's handle.
//
// The lengths of the arrays pointed to by `shapes`, `ranks`, and `types` must
// all be equal to `num_shapes_and_types`. If `ranks[i] != -1`, (i.e., if the
// rank is known), then it must be equal to the length of `shapes[i]`; if
// `ranks[i] == 1`, then `shapes[i]` may be nullptr.
//
// TODO(akshayka): Implement a corresponding getter method.
@Namespace("tensorflow") public static native void TF_GraphSetOutputHandleShapesAndTypes(TF_Graph graph, @ByVal TF_Output output,
                                           int num_shapes_and_types,
                                           @Cast("const int64_t**") PointerPointer shapes,
                                           @Const IntPointer ranks,
                                           @Cast("const TF_DataType*") IntPointer types,
                                           TF_Status status);
@Namespace("tensorflow") public static native void TF_GraphSetOutputHandleShapesAndTypes(TF_Graph graph, @ByVal TF_Output output,
                                           int num_shapes_and_types,
                                           @Cast("const int64_t**") @ByPtrPtr LongPointer shapes,
                                           @Const IntPointer ranks,
                                           @Cast("const TF_DataType*") IntPointer types,
                                           TF_Status status);
@Namespace("tensorflow") public static native void TF_GraphSetOutputHandleShapesAndTypes(TF_Graph graph, @ByVal TF_Output output,
                                           int num_shapes_and_types,
                                           @Cast("const int64_t**") @ByPtrPtr LongBuffer shapes,
                                           @Const IntBuffer ranks,
                                           @Cast("const TF_DataType*") IntBuffer types,
                                           TF_Status status);
@Namespace("tensorflow") public static native void TF_GraphSetOutputHandleShapesAndTypes(TF_Graph graph, @ByVal TF_Output output,
                                           int num_shapes_and_types,
                                           @Cast("const int64_t**") @ByPtrPtr long[] shapes,
                                           @Const int[] ranks,
                                           @Cast("const TF_DataType*") int[] types,
                                           TF_Status status);

@Namespace("tensorflow") public static native void RecordMutation(TF_Graph graph, @Const @ByRef TF_Operation op,
                    @Cast("const char*") BytePointer mutation_type);
@Namespace("tensorflow") public static native void RecordMutation(TF_Graph graph, @Const @ByRef TF_Operation op,
                    String mutation_type);

@Namespace("tensorflow") public static native @Cast("bool") boolean ExtendSessionGraphHelper(TF_Session session, TF_Status status);



  // end namespace tensorflow

// #endif  // TENSORFLOW_C_C_API_INTERNAL_H_


// Parsed from tensorflow/c/tf_status_internal.h

/* Copyright 2019 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_C_TF_STATUS_INTERNAL_H_
// #define TENSORFLOW_C_TF_STATUS_INTERNAL_H_

// #include "tensorflow/core/lib/core/status.h"
// Targeting ../TF_Status.java



// #endif  // TENSORFLOW_C_TF_STATUS_INTERNAL_H_


// Parsed from tensorflow/c/tf_tensor_internal.h

/* Copyright 2019 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_C_TF_TENSOR_INTERNAL_H_
// #define TENSORFLOW_C_TF_TENSOR_INTERNAL_H_

// #include "tensorflow/c/tf_datatype.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// Targeting ../TF_Tensor.java


// Targeting ../TensorCApi.java



// Allocates tensor data buffer using specified allocator.
// `operation` is a name for this operation.
@Namespace("tensorflow") public static native Pointer allocate_tensor(@Cast("const char*") BytePointer operation, @Cast("size_t") long len, Allocator allocator);
@Namespace("tensorflow") public static native Pointer allocate_tensor(String operation, @Cast("size_t") long len, Allocator allocator);

// Deallocates tensor data buffer.
// Defaults to deallocating using CPU allocator. You can pass pointer to
// a different Allocator as `arg`.
@Namespace("tensorflow") public static native void deallocate_buffer(Pointer data, @Cast("size_t") long len, Pointer arg);
  // namespace tensorflow
// #endif  // TENSORFLOW_C_TF_TENSOR_INTERNAL_H_


// Parsed from tensorflow/c/env.h

/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #include <stdbool.h>
// #include <stddef.h>
// #include <stdint.h>

// #ifndef TENSORFLOW_C_ENV_H_
// #define TENSORFLOW_C_ENV_H_

// #include "tensorflow/c/c_api.h"

// --------------------------------------------------------------------------
// C API for tensorflow::Env.

// #ifdef __cplusplus
// Targeting ../TF_WritableFileHandle.java


// Targeting ../TF_StringStream.java


// Targeting ../TF_Thread.java


// Targeting ../TF_FileStatistics.java


// Targeting ../TF_ThreadOptions.java



// Creates the specified directory. Typical status code are:
//  * TF_OK - successfully created the directory
//  * TF_ALREADY_EXISTS - directory already exists
//  * TF_PERMISSION_DENIED - dirname is not writable
public static native void TF_CreateDir(@Cast("const char*") BytePointer dirname, TF_Status status);
public static native void TF_CreateDir(String dirname, TF_Status status);

// Deletes the specified directory. Typical status codes are:
//  * TF_OK - successfully deleted the directory
//  * TF_FAILED_PRECONDITION - the directory is not empty
public static native void TF_DeleteDir(@Cast("const char*") BytePointer dirname, TF_Status status);
public static native void TF_DeleteDir(String dirname, TF_Status status);

// Deletes the specified directory and all subdirectories and files underneath
// it. This is accomplished by traversing the directory tree rooted at dirname
// and deleting entries as they are encountered.
//
// If dirname itself is not readable or does not exist, *undeleted_dir_count is
// set to 1, *undeleted_file_count is set to 0 and an appropriate status (e.g.
// TF_NOT_FOUND) is returned.
//
// If dirname and all its descendants were successfully deleted, TF_OK is
// returned and both error counters are set to zero.
//
// Otherwise, while traversing the tree, undeleted_file_count and
// undeleted_dir_count are updated if an entry of the corresponding type could
// not be deleted. The returned error status represents the reason that any one
// of these entries could not be deleted.
//
// Typical status codes:
//  * TF_OK - dirname exists and we were able to delete everything underneath
//  * TF_NOT_FOUND - dirname doesn't exist
//  * TF_PERMISSION_DENIED - dirname or some descendant is not writable
//  * TF_UNIMPLEMENTED - some underlying functions (like Delete) are not
//    implemented
public static native void TF_DeleteRecursively(@Cast("const char*") BytePointer dirname,
                                                @Cast("int64_t*") LongPointer undeleted_file_count,
                                                @Cast("int64_t*") LongPointer undeleted_dir_count,
                                                TF_Status status);
public static native void TF_DeleteRecursively(String dirname,
                                                @Cast("int64_t*") LongBuffer undeleted_file_count,
                                                @Cast("int64_t*") LongBuffer undeleted_dir_count,
                                                TF_Status status);
public static native void TF_DeleteRecursively(@Cast("const char*") BytePointer dirname,
                                                @Cast("int64_t*") long[] undeleted_file_count,
                                                @Cast("int64_t*") long[] undeleted_dir_count,
                                                TF_Status status);
public static native void TF_DeleteRecursively(String dirname,
                                                @Cast("int64_t*") LongPointer undeleted_file_count,
                                                @Cast("int64_t*") LongPointer undeleted_dir_count,
                                                TF_Status status);
public static native void TF_DeleteRecursively(@Cast("const char*") BytePointer dirname,
                                                @Cast("int64_t*") LongBuffer undeleted_file_count,
                                                @Cast("int64_t*") LongBuffer undeleted_dir_count,
                                                TF_Status status);
public static native void TF_DeleteRecursively(String dirname,
                                                @Cast("int64_t*") long[] undeleted_file_count,
                                                @Cast("int64_t*") long[] undeleted_dir_count,
                                                TF_Status status);

// Obtains statistics for the given path. If status is TF_OK, *stats is
// updated, otherwise it is not touched.
public static native void TF_FileStat(@Cast("const char*") BytePointer filename,
                                       TF_FileStatistics stats,
                                       TF_Status status);
public static native void TF_FileStat(String filename,
                                       TF_FileStatistics stats,
                                       TF_Status status);

// Creates or truncates the given filename and returns a handle to be used for
// appending data to the file. If status is TF_OK, *handle is updated and the
// caller is responsible for freeing it (see TF_CloseWritableFile).
public static native void TF_NewWritableFile(@Cast("const char*") BytePointer filename,
                                              @Cast("TF_WritableFileHandle**") PointerPointer handle,
                                              TF_Status status);
public static native void TF_NewWritableFile(@Cast("const char*") BytePointer filename,
                                              @ByPtrPtr TF_WritableFileHandle handle,
                                              TF_Status status);
public static native void TF_NewWritableFile(String filename,
                                              @ByPtrPtr TF_WritableFileHandle handle,
                                              TF_Status status);

// Closes the given handle and frees its memory. If there was a problem closing
// the file, it is indicated by status. Memory is freed in any case.
public static native void TF_CloseWritableFile(TF_WritableFileHandle handle,
                                                TF_Status status);

// Syncs content of the handle to the filesystem. Blocks waiting for the
// filesystem to indicate that the content has been persisted.
public static native void TF_SyncWritableFile(TF_WritableFileHandle handle,
                                               TF_Status status);

// Flush local buffers to the filesystem. If the process terminates after a
// successful flush, the contents may still be persisted, since the underlying
// filesystem may eventually flush the contents.  If the OS or machine crashes
// after a successful flush, the contents may or may not be persisted, depending
// on the implementation.
public static native void TF_FlushWritableFile(TF_WritableFileHandle handle,
                                                TF_Status status);

// Appends the given bytes to the file. Any failure to do so is indicated in
// status.
public static native void TF_AppendWritableFile(TF_WritableFileHandle handle,
                                                 @Cast("const char*") BytePointer data,
                                                 @Cast("size_t") long length,
                                                 TF_Status status);
public static native void TF_AppendWritableFile(TF_WritableFileHandle handle,
                                                 String data,
                                                 @Cast("size_t") long length,
                                                 TF_Status status);

// Deletes the named file and indicates whether successful in *status.
public static native void TF_DeleteFile(@Cast("const char*") BytePointer filename,
                                         TF_Status status);
public static native void TF_DeleteFile(String filename,
                                         TF_Status status);

// Retrieves the next item from the given TF_StringStream and places a pointer
// to it in *result. If no more items are in the list, *result is set to NULL
// and false is returned.
//
// Ownership of the items retrieved with this function remains with the library.
// Item points are invalidated after a call to TF_StringStreamDone.
public static native @Cast("bool") boolean TF_StringStreamNext(TF_StringStream list,
                                               @Cast("const char**") PointerPointer result);
public static native @Cast("bool") boolean TF_StringStreamNext(TF_StringStream list,
                                               @Cast("const char**") @ByPtrPtr BytePointer result);
public static native @Cast("bool") boolean TF_StringStreamNext(TF_StringStream list,
                                               @Cast("const char**") @ByPtrPtr ByteBuffer result);
public static native @Cast("bool") boolean TF_StringStreamNext(TF_StringStream list,
                                               @Cast("const char**") @ByPtrPtr byte[] result);

// Frees the resources associated with given string list. All pointers returned
// by TF_StringStreamNext are invalid after this call.
public static native void TF_StringStreamDone(TF_StringStream list);

// Retrieves the list of children of the given directory. You can iterate
// through the list with TF_StringStreamNext. The caller is responsible for
// freeing the list (see TF_StringStreamDone).
public static native TF_StringStream TF_GetChildren(@Cast("const char*") BytePointer filename,
                                                      TF_Status status);
public static native TF_StringStream TF_GetChildren(String filename,
                                                      TF_Status status);

// Retrieves a list of directory names on the local machine that may be used for
// temporary storage. You can iterate through the list with TF_StringStreamNext.
// The caller is responsible for freeing the list (see TF_StringStreamDone).
public static native TF_StringStream TF_GetLocalTempDirectories();

// Returns the number of nanoseconds since the Unix epoch.
public static native @Cast("uint64_t") long TF_NowNanos();

// Returns the number of microseconds since the Unix epoch.
public static native @Cast("uint64_t") long TF_NowMicros();

// Returns the number of seconds since the Unix epoch.
public static native @Cast("uint64_t") long TF_NowSeconds();

// Populates a TF_ThreadOptions struct with system-default values.
public static native void TF_DefaultThreadOptions(TF_ThreadOptions options);
// Targeting ../Work_func_Pointer.java


public static native TF_Thread TF_StartThread(@Const TF_ThreadOptions options,
                                                @Cast("const char*") BytePointer thread_name,
                                                Work_func_Pointer work_func,
                                                Pointer param);
public static native TF_Thread TF_StartThread(@Const TF_ThreadOptions options,
                                                String thread_name,
                                                Work_func_Pointer work_func,
                                                Pointer param);

// Waits for the given thread to finish execution, then deletes it.
public static native void TF_JoinThread(TF_Thread thread);

// #ifdef __cplusplus
// #endif

// #endif  // TENSORFLOW_C_ENV_H_


// Parsed from tensorflow/c/kernels.h

/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_C_KERNELS_H_
// #define TENSORFLOW_C_KERNELS_H_

// #include <stdint.h>

// #include "tensorflow/c/tf_datatype.h"
// #include "tensorflow/c/tf_status.h"

// Macro to control visibility of exported symbols in the shared library (.so,
// .dylib, .dll).
// This duplicates the TF_EXPORT macro definition in
// tensorflow/core/platform/macros.h in order to keep this .h file independent
// of any other includes.
// #ifdef SWIG
// #define TF_CAPI_EXPORT
// #else
// #endif  // SWIG

// #ifdef __cplusplus
// #endif
// Targeting ../TF_KernelBuilder.java


// Targeting ../TF_OpKernelConstruction.java


// Targeting ../TF_OpKernelContext.java


// Targeting ../Create_func_TF_OpKernelConstruction.java


// Targeting ../Compute_func_Pointer_TF_OpKernelContext.java


// Targeting ../Delete_func_Pointer.java


public static native TF_KernelBuilder TF_NewKernelBuilder(
    @Cast("const char*") BytePointer op_name, @Cast("const char*") BytePointer device_name,
    Create_func_TF_OpKernelConstruction create_func,
    Compute_func_Pointer_TF_OpKernelContext compute_func,
    Delete_func_Pointer delete_func);
public static native TF_KernelBuilder TF_NewKernelBuilder(
    String op_name, String device_name,
    Create_func_TF_OpKernelConstruction create_func,
    Compute_func_Pointer_TF_OpKernelContext compute_func,
    Delete_func_Pointer delete_func);

// Specifies that this kernel's attribute only supports the given type.
public static native void TF_KernelBuilder_TypeConstraint(
    TF_KernelBuilder kernel_builder, @Cast("const char*") BytePointer attr_name,
    @Cast("const TF_DataType") int type, TF_Status status);
public static native void TF_KernelBuilder_TypeConstraint(
    TF_KernelBuilder kernel_builder, String attr_name,
    @Cast("const TF_DataType") int type, TF_Status status);

// Specify that this kernel requires/provides an input/output arg
// in host memory (instead of the default, device memory).
public static native void TF_KernelBuilder_HostMemory(
    TF_KernelBuilder kernel_builder, @Cast("const char*") BytePointer arg_name);
public static native void TF_KernelBuilder_HostMemory(
    TF_KernelBuilder kernel_builder, String arg_name);

// Register the given kernel builder with the TensorFlow runtime. If
// registration fails, the given status will be populated.
//
// This call takes ownership of the `builder` pointer.
public static native void TF_RegisterKernelBuilder(@Cast("const char*") BytePointer kernel_name,
                                                    TF_KernelBuilder builder,
                                                    TF_Status status);
public static native void TF_RegisterKernelBuilder(String kernel_name,
                                                    TF_KernelBuilder builder,
                                                    TF_Status status);

// Deletes the given TF_KernelBuilder. This should be called only if the kernel
// builder is not registered with TensorFlow via TF_RegisterKernelBuilder.
public static native void TF_DeleteKernelBuilder(TF_KernelBuilder builder);

// --------------------------------------------------------------------------
// OpKernelContext routines

// TF_NumInputs returns the number of inputs available in ctx.
public static native int TF_NumInputs(TF_OpKernelContext ctx);

// TF_NumOutputs returns the number of outputs to be placed in *ctx by the
// kernel.
public static native int TF_NumOutputs(TF_OpKernelContext ctx);

// Retrieves the ith input from ctx. If TF_GetCode(status) is TF_OK, *tensor is
// populated and its ownership is passed to the caller. In any other case,
// *tensor is not modified.
//
// If i < 0 or i >= TF_NumInputs(ctx), *status is set to TF_OUT_OF_RANGE.
public static native void TF_GetInput(TF_OpKernelContext ctx, int i,
                                       @Cast("TF_Tensor**") PointerPointer tensor, TF_Status status);
public static native void TF_GetInput(TF_OpKernelContext ctx, int i,
                                       @ByPtrPtr TF_Tensor tensor, TF_Status status);

// Sets the ith output of ctx to tensor. If TF_GetCode(status) is anything but
// TF_OK, ctx is left unmodified.
//
// If i < 0 or i >= TF_NumOutputs(ctx), *status is set to TF_OUT_OF_RANGE.
public static native void TF_SetOutput(TF_OpKernelContext ctx, int i,
                                        @Const TF_Tensor tensor,
                                        TF_Status status);

// Notifies the given OpKernelConstruction that kernel construction has failed.
public static native void TF_OpKernelConstruction_Failure(
    TF_OpKernelConstruction ctx, TF_Status status);

// Notifies the given OpKernelContext that the kernel's compute function has
// failed.
public static native void TF_OpKernelContext_Failure(TF_OpKernelContext ctx,
                                                      TF_Status status);

// Returns the expected output data type of the ith output. If i < 0 or
// i >= TF_NumOutputs(ctx), the program aborts.
public static native @Cast("TF_DataType") int TF_ExpectedOutputDataType(
    TF_OpKernelContext ctx, int i);

// Returns the step ID of the given context.
public static native @Cast("int64_t") long TF_StepId(TF_OpKernelContext ctx);

// Interprets the named kernel construction attribute as a TF_DataType and
// places it into *val. *status is set to TF_OK.
//
// If the attribute could not be found or could not be interpreted as
// TF_DataType, *status is populated with an error.
public static native void TF_OpKernelConstruction_GetAttrType(
    TF_OpKernelConstruction ctx, @Cast("const char*") BytePointer attr_name, @Cast("TF_DataType*") IntPointer val,
    TF_Status status);
public static native void TF_OpKernelConstruction_GetAttrType(
    TF_OpKernelConstruction ctx, String attr_name, @Cast("TF_DataType*") IntBuffer val,
    TF_Status status);
public static native void TF_OpKernelConstruction_GetAttrType(
    TF_OpKernelConstruction ctx, @Cast("const char*") BytePointer attr_name, @Cast("TF_DataType*") int[] val,
    TF_Status status);
public static native void TF_OpKernelConstruction_GetAttrType(
    TF_OpKernelConstruction ctx, String attr_name, @Cast("TF_DataType*") IntPointer val,
    TF_Status status);
public static native void TF_OpKernelConstruction_GetAttrType(
    TF_OpKernelConstruction ctx, @Cast("const char*") BytePointer attr_name, @Cast("TF_DataType*") IntBuffer val,
    TF_Status status);
public static native void TF_OpKernelConstruction_GetAttrType(
    TF_OpKernelConstruction ctx, String attr_name, @Cast("TF_DataType*") int[] val,
    TF_Status status);

// Interprets the named kernel construction attribute as int32_t and
// places it into *val. *status is set to TF_OK.
//
// If the attribute could not be found or could not be interpreted as
// int32, *status is populated with an error.
public static native void TF_OpKernelConstruction_GetAttrInt32(
    TF_OpKernelConstruction ctx, @Cast("const char*") BytePointer attr_name, IntPointer val,
    TF_Status status);
public static native void TF_OpKernelConstruction_GetAttrInt32(
    TF_OpKernelConstruction ctx, String attr_name, IntBuffer val,
    TF_Status status);
public static native void TF_OpKernelConstruction_GetAttrInt32(
    TF_OpKernelConstruction ctx, @Cast("const char*") BytePointer attr_name, int[] val,
    TF_Status status);
public static native void TF_OpKernelConstruction_GetAttrInt32(
    TF_OpKernelConstruction ctx, String attr_name, IntPointer val,
    TF_Status status);
public static native void TF_OpKernelConstruction_GetAttrInt32(
    TF_OpKernelConstruction ctx, @Cast("const char*") BytePointer attr_name, IntBuffer val,
    TF_Status status);
public static native void TF_OpKernelConstruction_GetAttrInt32(
    TF_OpKernelConstruction ctx, String attr_name, int[] val,
    TF_Status status);

// Allocates Tensor for output at given index. Caller takes ownership of
// returned TF_Tensor and should deallocate it using TF_DeleteTensor(tensor).
//
// This function should be used to allocate outputs inside kernel
// compute function.
public static native TF_Tensor TF_AllocateOutput(TF_OpKernelContext context,
                                            int index, @Cast("TF_DataType") int dtype,
                                            @Cast("int64_t*") LongPointer dims, int num_dims,
                                            @Cast("size_t") long len);
public static native TF_Tensor TF_AllocateOutput(TF_OpKernelContext context,
                                            int index, @Cast("TF_DataType") int dtype,
                                            @Cast("int64_t*") LongBuffer dims, int num_dims,
                                            @Cast("size_t") long len);
public static native TF_Tensor TF_AllocateOutput(TF_OpKernelContext context,
                                            int index, @Cast("TF_DataType") int dtype,
                                            @Cast("int64_t*") long[] dims, int num_dims,
                                            @Cast("size_t") long len);

// #ifdef __cplusplus /* end extern "C" */
// #endif

// #endif  // TENSORFLOW_C_KERNELS_H_


// Parsed from tensorflow/c/ops.h

/* Copyright 2019 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// Routines for registering new ops and for implementing op shape inference
// functions.
//
// This API is alpha software and is subject to change.
//
// REGISTRATION
// ------------
//
// In order to register a new op, create a new TF_OpDefinitionBuilder:
//
// TF_OpDefinitionBuilder* builder = TF_NewOpDefinitionBuilder("OpName");
//
// Inputs, outputs and attributes can be added to the builder with the
// corresponding functions, e.g.
//
// TF_OpDefinitionBuilderAddInput(builder, "input1: int32");
// TF_OpDefinitionBuilderAddOutput(builder, "output1: int64");
// TF_OpDefinitionBuilderAddAttr(builder, "attr: int32");
//
// The builder may then be registered with TensorFlow using the
// TF_RegisterOpDefinition function. E.g.
//
// TF_Status* status = TF_NewStatus();
// TF_RegisterOpDefinition(builder, &status);
// if (TF_GetCode(status) != TF_OK) {
//   // handle error
// }
//
// SHAPE INFERENCE
// ---------------
//
// You can provide a shape inference function that TensorFlow will call when it
// wants to understand the shape of outputs that the op will produce. Use the
// TF_OpDefinitionBuilderSetShapeInferenceFunction function to register a shape
// inference function pointer with TensorFlow. The following is an example of a
// very simple shape inference function:
//
// void identity_shape_fn(TF_ShapeInferenceContext* ctx, TF_Status* status) {
//   TF_ShapeHandle* input = TF_NewShapeHandle();
//   TF_ShapeInferenceContextGetInput(ctx, 0, input, status);
//   if (TF_GetCode(status) == TF_OK) {
//     TF_ShapeInferenceContextSetOutput(ctx, 0, input, status);
//   }
//   TF_DeleteShapeHandle(input);
// }
//
// The following code registers the inference function with TensorFlow:
//
// TF_OpDefinitionBuilderSetShapeInferenceFunction(builder, &identity_shape_fn);
//
// For more details about shape inference, see the documentation for
// TF_OpDefinitionBuilderSetShapeInferenceFunction.

// #ifndef TENSORFLOW_C_OPS_H_
// #define TENSORFLOW_C_OPS_H_

// #include <stdbool.h>
// #include <stdint.h>
// #include <stdlib.h>

// #include "tensorflow/c/tf_datatype.h"
// #include "tensorflow/c/tf_status.h"

// #ifdef SWIG
// #define TF_CAPI_EXPORT
// #else
// #endif  // SWIG

// #ifdef __cplusplus
// Targeting ../TF_DimensionHandle.java


// Targeting ../TF_OpDefinitionBuilder.java


// Targeting ../TF_ShapeHandle.java


// Targeting ../TF_ShapeInferenceContext.java



// Returns a newly allocated op definition builder for the given op name. The
// returned builder may be customized with the `TF_OpDefinitionBuilder...`
// functions and then registered with TensorFlow with TF_RegisterOpDefinition.
//
// The returned pointer is either freed by a call to TF_RegisterOpDefinition, or
// can be manually deleted by TF_DeleteOpDefinitionBuilder if it is never
// registered.
public static native TF_OpDefinitionBuilder TF_NewOpDefinitionBuilder(
    @Cast("const char*") BytePointer op_name);
public static native TF_OpDefinitionBuilder TF_NewOpDefinitionBuilder(
    String op_name);

// Registers the given op builder with TensorFlow. Indicates success or
// otherwise in the given status.
//
// `builder` is freed whether the op was successfully registered or not. You
// must call either this function or TF_DeleteOpDefinitionBuilder to free the
// builder, but never both.
public static native void TF_RegisterOpDefinition(
    TF_OpDefinitionBuilder builder, TF_Status status);

// Frees the given op definition builder. You must call either this function or
// TF_RegisterOpDefinition to free the builder, but never both.
public static native void TF_DeleteOpDefinitionBuilder(
    TF_OpDefinitionBuilder builder);

//----------------------------------------------------
// Attribute functions.

// Adds an attr to the given TF_OpDefinitionBuilder. The spec has
// format "<name>:<type>" or "<name>:<type>=<default>"
// where <name> matches regexp [a-zA-Z][a-zA-Z0-9_]*.
// By convention, names containing only capital letters are reserved for
// attributes whose values can be inferred by the operator implementation if not
// supplied by the user. If the attribute name contains characters other than
// capital letters, the operator expects the user to provide the attribute value
// at operation runtime.
//
// <type> can be:
//   "string", "int", "float", "bool", "type", "shape", or "tensor"
//   "numbertype", "realnumbertype", "quantizedtype"
//       (meaning "type" with a restriction on valid values)
//   "{int32,int64}" or {realnumbertype,quantizedtype,string}"
//       (meaning "type" with a restriction containing unions of value types)
//   "{\"foo\", \"bar\n baz\"}", or "{'foo', 'bar\n baz'}"
//       (meaning "string" with a restriction on valid values)
//   "list(string)", ..., "list(tensor)", "list(numbertype)", ...
//       (meaning lists of the above types)
//   "int >= 2" (meaning "int" with a restriction on valid values)
//   "list(string) >= 2", "list(int) >= 2"
//       (meaning "list(string)" / "list(int)" with length at least 2)
// <default>, if included, should use the Proto text format
// of <type>.  For lists use [a, b, c] format.
//
// Note that any attr specifying the length of an input or output will
// get a default minimum of 1 unless the >= # syntax is used.
public static native void TF_OpDefinitionBuilderAddAttr(
    TF_OpDefinitionBuilder builder, @Cast("const char*") BytePointer attr_spec);
public static native void TF_OpDefinitionBuilderAddAttr(
    TF_OpDefinitionBuilder builder, String attr_spec);

// Adds an input to this TF_OpDefinitionBuilder.
// The spec has form "<name>:<type-expr>" or "<name>:Ref(<type-expr>)"
// where <name> matches regexp [a-z][a-z0-9_]* and <type-expr> can be:
// * For a single tensor: <type>
// * For a sequence of tensors with the same type: <number>*<type>
// * For a sequence of tensors with different types: <type-list>
// Where:
//   <type> is either one of "float", "int32", "string", ...
//          or the name of an attr (see TF_OpDefinitionBuilderAddAttr)
//          with type "type".
//   <number> is the name of an attr with type "int".
//   <type-list> is the name of an attr with type "list(type)".
public static native void TF_OpDefinitionBuilderAddInput(
    TF_OpDefinitionBuilder builder, @Cast("const char*") BytePointer input_spec);
public static native void TF_OpDefinitionBuilderAddInput(
    TF_OpDefinitionBuilder builder, String input_spec);

// Adds an output to this TF_OpDefinitionBuilder.
// The spec has form "<name>:<type-expr>" or "<name>:Ref(<type-expr>)"
// where <name> matches regexp [a-z][a-z0-9_]* and <type-expr> can be:
// * For a single tensor: <type>
// * For a sequence of tensors with the same type: <number>*<type>
// * For a sequence of tensors with different types: <type-list>
// Where:
//   <type> is either one of "float", "int32", "string", ...
//          or the name of an attr (see TF_OpDefinitionBuilderAddAttr)
//          with type "type".
//   <number> is the name of an attr with type "int".
//   <type-list> is the name of an attr with type "list(type)".
public static native void TF_OpDefinitionBuilderAddOutput(
    TF_OpDefinitionBuilder builder, @Cast("const char*") BytePointer output_spec);
public static native void TF_OpDefinitionBuilderAddOutput(
    TF_OpDefinitionBuilder builder, String output_spec);

// Sets the commutative property for the op built by the given builder.
public static native void TF_OpDefinitionBuilderSetIsCommutative(
    TF_OpDefinitionBuilder builder, @Cast("bool") boolean is_commutative);

// Sets the is_aggregate property of the builder to the given value.
//
// If is_aggregate is true, then the operation produced by this builder accepts
// N >= 2 inputs and produces 1 output all of the same type. Should be
// associative and commutative, and produce output with the same shape as the
// input. The optimizer may replace an aggregate op taking input from multiple
// devices with a tree of aggregate ops that aggregate locally within each
// device (and possibly within groups of nearby devices) before communicating.
public static native void TF_OpDefinitionBuilderSetIsAggregate(
    TF_OpDefinitionBuilder builder, @Cast("bool") boolean is_aggregate);

// Sets the is_stateful property of the builder to the given value.
//
// The op built by this builder is stateful if its behavior depends on some
// state beyond its input tensors (e.g. variable reading op) or if it has a
// side-effect (e.g. printing or asserting ops). Equivalently, stateless ops
// must always produce the same output for the same input and have no
// side-effects.
//
// By default Ops may be moved between devices. Stateful ops should either not
// be moved, or should only be moved if that state can also be moved (e.g. via
// some sort of save / restore). Stateful ops are guaranteed to never be
// optimized away by Common Subexpression Elimination (CSE).
public static native void TF_OpDefinitionBuilderSetIsStateful(
    TF_OpDefinitionBuilder builder, @Cast("bool") boolean is_stateful);

// Sets the allows_uninitialized_input property of the operation built by this
// builder.
//
// By default, all inputs to an Op must be initialized Tensors. Ops that may
// initialize tensors for the first time should set this field to true, to allow
// the Op to take an uninitialized Tensor as input.
public static native void TF_OpDefinitionBuilderSetAllowsUninitializedInput(
    TF_OpDefinitionBuilder builder, @Cast("bool") boolean allows_uninitialized_input);

// Adds a deprecation warning for the given op. This indicates to the user that
// `version` is the first TensorFlow GraphDef version for which the operation is
// deprecated. `explanation` should contain the reason for the deprecation and
// what to use instead.
//
// This function is only an indicator that the operation may disappear in a
// version of TensorFlow after `version`. It does not affect op registration.
public static native void TF_OpDefinitionBuilderDeprecated(
    TF_OpDefinitionBuilder builder, int version, @Cast("const char*") BytePointer explanation);
public static native void TF_OpDefinitionBuilderDeprecated(
    TF_OpDefinitionBuilder builder, int version, String explanation);
// Targeting ../Shape_inference_func_TF_ShapeInferenceContext_TF_Status.java


public static native void TF_OpDefinitionBuilderSetShapeInferenceFunction(
    TF_OpDefinitionBuilder builder,
    Shape_inference_func_TF_ShapeInferenceContext_TF_Status shape_inference_func);

//----------------------------------------------------
// Functions for TF_ShapeInferenceContext.
//
// Functions for implementing shape inference functions. TensorFlow uses these
// functions to determine the shape of tensors produced by an operation without
// having to actually run the operation. If an operation chooses to provide a
// shape inference function, it will be invoked by TensorFlow as needed.
//
// When invoked by TensorFlow, the shape inference function is provided with a
// TF_ShapeInferenceContext pointer. The function's implementation will use the
// accessor and mutator functions with names beginning with
// TF_ShapeInferenceContext to examine the input state and determine the output
// shape.

// Returns the number of inputs in the given shape inference context.
public static native @Cast("int64_t") long TF_ShapeInferenceContextNumInputs(
    TF_ShapeInferenceContext ctx);

// Returns a newly allocated shape handle. The shapes represented by these
// handles may be queried or mutated with the corresponding
// TF_ShapeInferenceContext...  functions.
public static native TF_ShapeHandle TF_NewShapeHandle();

// Places the ith input of the given shape inference context into the given
// shape handle, or returns a status other than TF_OK indicating why the input
// could not be retrieved
// (for example, if i < 0 || i >= TF_ShapeInferenceContextNumInputs(ctx)).
public static native void TF_ShapeInferenceContextGetInput(
    TF_ShapeInferenceContext ctx, int i, TF_ShapeHandle handle,
    TF_Status status);

// Places the given shape handle into the `i`th output position of the given
// context. Internally, the shape handle is copied; the caller may subsequently
// delete `handle`.
public static native void TF_ShapeInferenceContextSetOutput(TF_ShapeInferenceContext ctx,
                                              int i, TF_ShapeHandle handle,
                                              TF_Status status);

// Returns a newly-allocate shape handle representing a vector of the given
// size. The returned handle should be freed with TF_DeleteShapeHandle.
public static native TF_ShapeHandle TF_ShapeInferenceContextVectorFromSize(
    TF_ShapeInferenceContext ctx, @Cast("size_t") long size);

// Returns a newly allocated dimension handle. It must be freed with
// TF_DeleteDimensionHandle.
public static native TF_DimensionHandle TF_NewDimensionHandle();

// Interprets the named shape inference context attribute as a TF_DataType and
// places it into *val. *status is set to TF_OK.
//
// If the attribute could not be found or could not be interpreted as
// TF_DataType, *status is populated with an error.
public static native void TF_ShapeInferenceContext_GetAttrType(
    TF_ShapeInferenceContext ctx, @Cast("const char*") BytePointer attr_name, @Cast("TF_DataType*") IntPointer val,
    TF_Status status);
public static native void TF_ShapeInferenceContext_GetAttrType(
    TF_ShapeInferenceContext ctx, String attr_name, @Cast("TF_DataType*") IntBuffer val,
    TF_Status status);
public static native void TF_ShapeInferenceContext_GetAttrType(
    TF_ShapeInferenceContext ctx, @Cast("const char*") BytePointer attr_name, @Cast("TF_DataType*") int[] val,
    TF_Status status);
public static native void TF_ShapeInferenceContext_GetAttrType(
    TF_ShapeInferenceContext ctx, String attr_name, @Cast("TF_DataType*") IntPointer val,
    TF_Status status);
public static native void TF_ShapeInferenceContext_GetAttrType(
    TF_ShapeInferenceContext ctx, @Cast("const char*") BytePointer attr_name, @Cast("TF_DataType*") IntBuffer val,
    TF_Status status);
public static native void TF_ShapeInferenceContext_GetAttrType(
    TF_ShapeInferenceContext ctx, String attr_name, @Cast("TF_DataType*") int[] val,
    TF_Status status);

// Returns the rank of the shape represented by the given handle.
public static native @Cast("int64_t") long TF_ShapeInferenceContextRank(
    TF_ShapeInferenceContext ctx, TF_ShapeHandle handle);

// Returns 1 if `handle` has a known rank, 0 otherwise.
public static native int TF_ShapeInferenceContextRankKnown(
    TF_ShapeInferenceContext ctx, TF_ShapeHandle handle);

// If <handle> has rank <rank>, or its rank is unknown, return OK and return the
// shape with asserted rank in <*result>. Otherwise an error is placed into
// `status`.
public static native void TF_ShapeInferenceContextWithRank(
    TF_ShapeInferenceContext ctx, TF_ShapeHandle handle, @Cast("int64_t") long rank,
    TF_ShapeHandle result, TF_Status status);

// If <handle> has rank at least <rank>, or its rank is unknown, return OK and
// return the shape with asserted rank in <*result>. Otherwise an error is
// placed into `status`.
public static native void TF_ShapeInferenceContextWithRankAtLeast(
    TF_ShapeInferenceContext ctx, TF_ShapeHandle handle, @Cast("int64_t") long rank,
    TF_ShapeHandle result, TF_Status status);

// If <handle> has rank at most <rank>, or its rank is unknown, return OK and
// return the shape with asserted rank in <*result>. Otherwise an error is
// placed into `status`.
public static native void TF_ShapeInferenceContextWithRankAtMost(
    TF_ShapeInferenceContext ctx, TF_ShapeHandle handle, @Cast("int64_t") long rank,
    TF_ShapeHandle result, TF_Status status);

// Places a handle to the ith dimension of the given shape into *result.
public static native void TF_ShapeInferenceContextDim(
    TF_ShapeInferenceContext ctx, TF_ShapeHandle shape_handle, @Cast("int64_t") long i,
    TF_DimensionHandle result);

// Returns in <*result> a sub-shape of <shape_handle>, with dimensions
// [start:end]. <start> and <end> can be negative, to index from the end of the
// shape. <start> and <end> are set to the rank of <shape_handle> if > rank of
// <shape_handle>.
public static native void TF_ShapeInferenceContextSubshape(
    TF_ShapeInferenceContext ctx, TF_ShapeHandle shape_handle, @Cast("int64_t") long start,
    @Cast("int64_t") long end, TF_ShapeHandle result, TF_Status status);

// Places an unknown shape in all outputs for the given inference context. Used
// for shape inference functions with ops whose output shapes are unknown.
public static native void TF_ShapeInferenceContextSetUnknownShape(
    TF_ShapeInferenceContext ctx, TF_Status status);

// Returns whether the given handle represents a known dimension.
public static native int TF_DimensionHandleValueKnown(
    TF_DimensionHandle dim_handle);

// Returns the value of the given dimension.
public static native @Cast("int64_t") long TF_DimensionHandleValue(
    TF_DimensionHandle dim_handle);

// Returns in <*result> the result of appending the dimensions of <second> to
// those of <first>.
public static native void TF_ShapeInferenceContextConcatenateShapes(
    TF_ShapeInferenceContext ctx, TF_ShapeHandle first,
    TF_ShapeHandle second, TF_ShapeHandle result, TF_Status status);

// Frees the given shape handle.
public static native void TF_DeleteShapeHandle(TF_ShapeHandle handle);

// Frees the given dimension handle.
public static native void TF_DeleteDimensionHandle(TF_DimensionHandle handle);

// #ifdef __cplusplus /* end extern "C" */
// #endif

// #endif  // TENSORFLOW_C_OPS_H_


// Parsed from tensorflow/core/framework/op_def_builder.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// Class and associated machinery for specifying an Op's OpDef and shape
// inference function for Op registration.

// #ifndef TENSORFLOW_CORE_FRAMEWORK_OP_DEF_BUILDER_H_
// #define TENSORFLOW_CORE_FRAMEWORK_OP_DEF_BUILDER_H_

// #include <string>
// #include <vector>
// #include "tensorflow/core/framework/op_def.pb.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/platform/macros.h"

// Targeting ../OpRegistrationData.java


// Targeting ../OpDefBuilder.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_OP_DEF_BUILDER_H_


// Parsed from tensorflow/core/framework/op_def_util.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// TODO(josh11b): Probably not needed for OpKernel authors, so doesn't
// need to be as publicly accessible as other files in framework/.

// #ifndef TENSORFLOW_CORE_FRAMEWORK_OP_DEF_UTIL_H_
// #define TENSORFLOW_CORE_FRAMEWORK_OP_DEF_UTIL_H_

// #include <string>
// #include "tensorflow/core/framework/api_def.pb.h"
// #include "tensorflow/core/framework/op_def.pb.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/platform/protobuf.h"

// Performs a consistency check across the fields of the op_def.
@Namespace("tensorflow") public static native @ByVal Status ValidateOpDef(@Const @ByRef OpDef op_def);

// Check if an op is deprecated at the given GraphDef version.  If the op is
// deprecated at a future version, a warning will be logged.
@Namespace("tensorflow") public static native @ByVal Status CheckOpDeprecation(@Const @ByRef OpDef op_def, int graph_def_version);

// Validates that attr_value satisfies the type and constraints from attr.
// REQUIRES: attr has already been validated.
@Namespace("tensorflow") public static native @ByVal Status ValidateAttrValue(@Const @ByRef AttrValue attr_value,
                         @Cast("const tensorflow::OpDef::AttrDef*") @ByRef OpDef_AttrDef attr);

// The following search through op_def for an attr with the indicated name.
// Returns nullptr if no such attr is found.
@Namespace("tensorflow") public static native @Cast("const tensorflow::OpDef::AttrDef*") OpDef_AttrDef FindAttr(@StringPiece BytePointer name, @Const @ByRef OpDef op_def);
@Namespace("tensorflow") public static native @Cast("const tensorflow::OpDef::AttrDef*") OpDef_AttrDef FindAttr(@StringPiece String name, @Const @ByRef OpDef op_def);
@Namespace("tensorflow") public static native @Cast("tensorflow::OpDef::AttrDef*") OpDef_AttrDef FindAttrMutable(@StringPiece BytePointer name, OpDef op_def);
@Namespace("tensorflow") public static native @Cast("tensorflow::OpDef::AttrDef*") OpDef_AttrDef FindAttrMutable(@StringPiece String name, OpDef op_def);

// Searches op_def for input argument with the indicated name.
// Returns nullptr if no such attr is found.
@Namespace("tensorflow") public static native @Cast("const tensorflow::OpDef::ArgDef*") OpDef_ArgDef FindInputArg(@StringPiece BytePointer name, @Const @ByRef OpDef op_def);
@Namespace("tensorflow") public static native @Cast("const tensorflow::OpDef::ArgDef*") OpDef_ArgDef FindInputArg(@StringPiece String name, @Const @ByRef OpDef op_def);

// Searches api_def for input argument with the indicated name.
// Returns nullptr if no such attr is found.
@Namespace("tensorflow") public static native @Cast("const tensorflow::ApiDef::Arg*") ApiDef_Arg FindInputArg(@StringPiece BytePointer name, @Const @ByRef ApiDef api_def);
@Namespace("tensorflow") public static native @Cast("const tensorflow::ApiDef::Arg*") ApiDef_Arg FindInputArg(@StringPiece String name, @Const @ByRef ApiDef api_def);

// Produce a human-readable version of an op_def that is more concise
// than a text-format proto.  Excludes descriptions.
@Namespace("tensorflow") public static native @StdString BytePointer SummarizeOpDef(@Const @ByRef OpDef op_def);

// Returns an error if new_op is not backwards-compatible with (more
// accepting than) old_op.
// REQUIRES: old_op and new_op must pass validation.
@Namespace("tensorflow") public static native @ByVal Status OpDefCompatible(@Const @ByRef OpDef old_op, @Const @ByRef OpDef new_op);

// Returns an error if any attr in penultimate_op that is not in old_op
// has a different default value in new_op.  In general it is not safe
// to change the default for an attr that has been added to an op.
@Namespace("tensorflow") public static native @ByVal Status OpDefAddedDefaultsUnchanged(@Const @ByRef OpDef old_op,
                                   @Const @ByRef OpDef penultimate_op,
                                   @Const @ByRef OpDef new_op);

// Returns an error if the default value for any attr is added/removed/modified
// in new_op compared to old_op.
@Namespace("tensorflow") public static native @ByVal Status OpDefAttrDefaultsUnchanged(@Const @ByRef OpDef old_op, @Const @ByRef OpDef new_op);

// Remove all docs from *op_def / *op_list.
@Namespace("tensorflow") public static native void RemoveDescriptionsFromOpDef(OpDef op_def);
@Namespace("tensorflow") public static native void RemoveDescriptionsFromOpList(OpList op_list);

// Remove docs from *op_def but leave explanations of deprecations.
@Namespace("tensorflow") public static native void RemoveNonDeprecationDescriptionsFromOpDef(OpDef op_def);

// Returns true if `a1` is equal to `a2`.
// Equality includes all the fields.
@Namespace("tensorflow") public static native @Cast("bool") boolean AttrDefEqual(@Cast("const tensorflow::OpDef::AttrDef*") @ByRef OpDef_AttrDef a1, @Cast("const tensorflow::OpDef::AttrDef*") @ByRef OpDef_AttrDef a2);

// Returns hash of `a` that is consistent with AttrDefEqual.
@Namespace("tensorflow") public static native @Cast("tensorflow::uint64") long AttrDefHash(@Cast("const tensorflow::OpDef::AttrDef*") @ByRef OpDef_AttrDef a);

// Returns true if all AttrDefs in `a1` equal corresponding AttrDefs in
// `a2`. Correspondence is established by name.

// Returns hash of `a` that is consistent with RepeatedAttrDefEqual

// Returns true if `o1` is equal to `o2`.
// Equality includes all the fields. OpDef.attr field is treated as a set.
@Namespace("tensorflow") public static native @Cast("bool") boolean OpDefEqual(@Const @ByRef OpDef o1, @Const @ByRef OpDef o2);

// Returns hash of `o` that is consistent with AttrDefEqual.
@Namespace("tensorflow") public static native @Cast("tensorflow::uint64") long OpDefHash(@Const @ByRef OpDef o);

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_OP_DEF_UTIL_H_


// Parsed from tensorflow/core/framework/op.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_OP_H_
// #define TENSORFLOW_CORE_FRAMEWORK_OP_H_

// #include <functional>
// #include <unordered_map>

// #include <vector>
// #include "tensorflow/core/framework/op_def_builder.h"
// #include "tensorflow/core/framework/op_def_util.h"
// #include "tensorflow/core/framework/selective_registration.h"
// #include "tensorflow/core/lib/core/errors.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/strings/str_util.h"
// #include "tensorflow/core/lib/strings/strcat.h"
// #include "tensorflow/core/platform/logging.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/mutex.h"
// #include "tensorflow/core/platform/thread_annotations.h"
// #include "tensorflow/core/platform/types.h"
// Targeting ../OpRegistryInterface.java


// Targeting ../OpRegistry.java


// Targeting ../OpListOpRegistry.java



// Support for defining the OpDef (specifying the semantics of the Op and how
// it should be created) and registering it in the OpRegistry::Global()
// registry.  Usage:
//
// REGISTER_OP("my_op_name")
//     .Attr("<name>:<type>")
//     .Attr("<name>:<type>=<default>")
//     .Input("<name>:<type-expr>")
//     .Input("<name>:Ref(<type-expr>)")
//     .Output("<name>:<type-expr>")
//     .Doc(R"(
// <1-line summary>
// <rest of the description (potentially many lines)>
// <name-of-attr-input-or-output>: <description of name>
// <name-of-attr-input-or-output>: <description of name;
//   if long, indent the description on subsequent lines>
// )");
//
// Note: .Doc() should be last.
// For details, see the OpDefBuilder class in op_def_builder.h.

// OpDefBuilderWrapper is a templated class that is used in the REGISTER_OP
// calls. This allows the result of REGISTER_OP to be used in chaining, as in
// REGISTER_OP(a).Attr("...").Input("...");, while still allowing selective
// registration to turn the entire call-chain into a no-op.
// Targeting ../TrueOpDefBuilderWrapper.java


// Targeting ../FalseOpDefBuilderWrapper.java


// Targeting ../OpDefBuilderReceiver.java


  // namespace register_op

// #define REGISTER_OP(name) REGISTER_OP_UNIQ_HELPER(__COUNTER__, name)
// #define REGISTER_OP_UNIQ_HELPER(ctr, name) REGISTER_OP_UNIQ(ctr, name)
// #define REGISTER_OP_UNIQ(ctr, name)
//   static ::tensorflow::register_op::OpDefBuilderReceiver register_op##ctr
//       TF_ATTRIBUTE_UNUSED =
//           ::tensorflow::register_op::OpDefBuilderWrapper<SHOULD_REGISTER_OP(
//               name)>(name)

// The `REGISTER_SYSTEM_OP()` macro acts as `REGISTER_OP()` except
// that the op is registered unconditionally even when selective
// registration is used.
// #define REGISTER_SYSTEM_OP(name)
//   REGISTER_SYSTEM_OP_UNIQ_HELPER(__COUNTER__, name)
// #define REGISTER_SYSTEM_OP_UNIQ_HELPER(ctr, name)
//   REGISTER_SYSTEM_OP_UNIQ(ctr, name)
// #define REGISTER_SYSTEM_OP_UNIQ(ctr, name)
//   static ::tensorflow::register_op::OpDefBuilderReceiver register_op##ctr
//       TF_ATTRIBUTE_UNUSED =
//           ::tensorflow::register_op::OpDefBuilderWrapper<true>(name)

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_OP_H_


// Parsed from tensorflow/core/graph/edgeset.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_GRAPH_EDGESET_H_
// #define TENSORFLOW_GRAPH_EDGESET_H_

// #include <stddef.h>

// #include "tensorflow/core/lib/gtl/flatset.h"
// #include "tensorflow/core/platform/logging.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/types.h"
// Targeting ../EdgeSet.java


// Targeting ../EdgeSetIterator.java





















// gcc's set and multiset always use const_iterator since it will otherwise
// allow modification of keys.


// gcc's set and multiset always use const_iterator since it will otherwise
// allow modification of keys.




  // namespace tensorflow

// #endif  // TENSORFLOW_GRAPH_EDGESET_H_


// Parsed from tensorflow/core/lib/gtl/iterator_range.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// This provides a very simple, boring adaptor for a begin and end iterator
// into a range type. This should be used to build range views that work well
// with range based for loops and range based constructors.
//
// Note that code here follows more standards-based coding conventions as it
// is mirroring proposed interfaces for standardization.
//
// Converted from chandlerc@'s code to Google style by joshl@.

// #ifndef TENSORFLOW_LIB_GTL_ITERATOR_RANGE_H_
// #define TENSORFLOW_LIB_GTL_ITERATOR_RANGE_H_

// #include <utility>
// Targeting ../NeighborIterRange.java


// Targeting ../NodeIterRange.java



// Convenience function for iterating over sub-ranges.
//
// This provides a bit of syntactic sugar to make using sub-ranges
// in for loops a bit easier. Analogous to std::make_pair().

  // namespace gtl
  // namespace tensorflow

// #endif  // TENSORFLOW_LIB_GTL_ITERATOR_RANGE_H_


// Parsed from tensorflow/core/framework/function.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_FUNCTION_H_
// #define TENSORFLOW_CORE_FRAMEWORK_FUNCTION_H_

// #include <vector>

// #include "tensorflow/core/framework/attr_value.pb.h"
// #include "tensorflow/core/framework/attr_value_util.h"
// #include "tensorflow/core/framework/function.pb.h"
// #include "tensorflow/core/framework/node_def_util.h"
// #include "tensorflow/core/framework/op.h"
// #include "tensorflow/core/framework/op_kernel.h"
// #include "tensorflow/core/framework/selective_registration.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/flatmap.h"
// #include "tensorflow/core/lib/hash/hash.h"
// #include "tensorflow/core/lib/random/random.h"
// #include "tensorflow/core/platform/env.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/mutex.h"
// #include "tensorflow/core/platform/protobuf.h"
// #include "tensorflow/core/protobuf/config.pb.h"
// Targeting ../CancellationManager.java


// Targeting ../DeviceSet.java


// Targeting ../Rendezvous.java


// Targeting ../FunctionDefHelper.java









// Instantiate a function.
//
// "fdef" encodes a TF function with some attrs in fdef.signature.attr
// containing placeholders.  InstantiateFunction binds these
// placeholders and produces an instantiated function encoded in
// "result.gdef". The value to substitute a placeholder is given by
// "attr_values", which is a map from a placeholder name to an attr
// value.
//
// InstantiateFunction calls "get_function" to find signatures of other
// functions and primitive ops.

// GetFunctionSignature(func name, opdef) returns OK if the func name is found
// and opdef is filled with a pointer to the corresponding signature
// (a OpDef proto). Otherwise, returns an error.
// Targeting ../InstantiationResult.java


@Namespace("tensorflow") public static native @ByVal Status InstantiateFunction(@Const @ByRef FunctionDef fdef, @ByVal AttrSlice attr_values,
                           @ByVal @Cast("tensorflow::GetFunctionSignature*") Pointer get_function,
                           InstantiationResult result);

// Returns a debug string for a function definition.
//
// The returned text is multiple-line. It is intended to be
// human-readable rather than being friendly to parsers. It is _NOT_
// intended to be the canonical string representation of "func_def".
// Particularly, it may not include all information presented in
// "func_def" (e.g., comments, description of the function arguments,
// etc.)
@Namespace("tensorflow") public static native @StdString BytePointer DebugString(@Const @ByRef FunctionDef func_def);
@Namespace("tensorflow") public static native @StdString BytePointer DebugString(@Const @ByRef GraphDef instantiated_func_def);
@Namespace("tensorflow") public static native @StdString BytePointer DebugString(@ArraySlice NodeDef instantiated_func_nodes);

// Returns a debug string for a top level graph (the main program and
// its supporting functions defined in its library).
@Namespace("tensorflow") public static native @StdString BytePointer DebugStringWhole(@Const @ByRef GraphDef gdef);

// Returns true if f1 == f2. Compares all fields, including descriptions. Order
// of NodeDefs doesn't matter.
@Namespace("tensorflow") public static native @Cast("bool") boolean FunctionDefsEqual(@Const @ByRef FunctionDef f1, @Const @ByRef FunctionDef f2);

// Return a hash of `fdef` that is consistent with FunctionDefsEqual method.
// In other words, if two fdefs compare equal, their hash values will be the
// same.
@Namespace("tensorflow") public static native @Cast("tensorflow::uint64") long FunctionDefHash(@Const @ByRef FunctionDef fdef);
// Targeting ../CallFrameInterface.java


// Targeting ../FunctionCallFrame.java


// Targeting ../FunctionLibraryDefinition.java


// Targeting ../FunctionBody.java



// Forward declare. Defined in common_runtime/device.h
// Targeting ../FunctionLibraryRuntime.java



// Returns a canonicalized string for the instantiation of the
// function of the given "name", attributes "attrs", and "options".
//
// The returned string is guaranteed to be stable within one address
// space. But it may be change as the implementation
// evolves. Therefore, it should not be persisted or compared across
// address spaces.
@Namespace("tensorflow") public static native @StdString BytePointer Canonicalize(@StdString BytePointer funcname, @ByVal AttrSlice attrs,
                    @Const @ByRef FunctionLibraryRuntime.InstantiateOptions options);
@Namespace("tensorflow") public static native @StdString String Canonicalize(@StdString String funcname, @ByVal AttrSlice attrs,
                    @Const @ByRef FunctionLibraryRuntime.InstantiateOptions options);
@Namespace("tensorflow") public static native @StdString BytePointer Canonicalize(@StdString BytePointer funcname, @ByVal AttrSlice attrs);
@Namespace("tensorflow") public static native @StdString String Canonicalize(@StdString String funcname, @ByVal AttrSlice attrs);

@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::FunctionLibraryRuntime::Handle") long kInvalidHandle();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::FunctionLibraryRuntime::LocalHandle") long kInvalidLocalHandle();
// Targeting ../CustomKernelCreator.java


// Targeting ../DistributedFunctionLibraryRuntime.java



// Extracts the actual type from "attr_values" based on its definition
// "arg_def".
//
// If "arg_def" is a N*T type, *is_type_list is set to false, and
// *dtypes is set to be a vector of size N and each element is T.
//
// If "arg_def" is a list(type), *is_type_list is set to true, and
// *dtypes is set to be a vector of types specified in attrs for
// arg_def.
//
// Otherwise (arg_def is a simple type T), *is_type_list is set to
// false, and *dtypes is set to a single element vector, whose only
// element is T.
@Namespace("tensorflow") public static native @ByVal Status ArgNumType(@ByVal AttrSlice attrs, @Cast("const tensorflow::OpDef::ArgDef*") @ByRef OpDef_ArgDef arg_def,
                  @Cast("bool*") BoolPointer is_type_list, DataTypeVector dtypes);
@Namespace("tensorflow") public static native @ByVal Status ArgNumType(@ByVal AttrSlice attrs, @Cast("const tensorflow::OpDef::ArgDef*") @ByRef OpDef_ArgDef arg_def,
                  @Cast("bool*") boolean[] is_type_list, DataTypeVector dtypes);

// To register a gradient function for a builtin op, one should use
//   REGISTER_OP_GRADIENT(<op_name>, <c++ grad factory>);
//
// Typically, the c++ grad factory is a plan function that can be
// converted into ::tensorflow::gradient::Creator, which is
//   std::function<Status(const AttrSlice&, FunctionDef*)>.
//
// A ::tensorflow::gradient::Creator should populate in FunctionDef* with a
// definition of a brain function which compute the gradient for the
// <op_name> when the <op_name> is instantiated with the given attrs.
//
// E.g.,
//
// Status MatMulGrad(const AttrSlice& attrs, FunctionDef* g) {
//   bool transpose_a;
//   TF_RETURN_IF_ERROR(attrs.Get("transpose_a", &transpose_a));
//   bool transpose_b;
//   TF_RETURN_IF_ERROR(attrs.Get("transpose_b", &transpose_b));
//   DataType dtype;
//   TF_RETURN_IF_ERROR(attrs.Get("dtype", &dtype));
//   if (!transpose_a && !transpose_b) {
//     *g = FunctionDefHelper::Define(
//       "MatMulGrad",
//       {"x:T ", "y:T", "dz:T"},    // Inputs to this function
//       {"dx:T", "dy:T"},           // Outputs from this function
//       {"T: {float, double}"},     // Attributes needed by this function
//       {
//         {{"x_t"}, "Transpose", {"x"}, {{"T", "$T"}}},
//         {{"y_t"}, "Transpose", {"y"}, {{"T", "$T"}}},
//         {{"dx"}, "MatMul", {"dz", "y_t"}, {{"T", "$T"}}},
//         {{"dy"}, "MatMul", {"x_", "dz"}, {{"T", "$T"}}},
//       });
//   } else {
//     ... ...
//   }
//   return Status::OK();
// }
//
// NOTE: $T is substituted with the type variable "T" when the
// gradient function MatMul is instantiated.
//
// TODO(zhifengc): Better documentation somewhere.

// Macros to define a gradient function factory for a primitive
// operation.
// #define REGISTER_OP_GRADIENT(name, fn)
//   REGISTER_OP_GRADIENT_UNIQ_HELPER(__COUNTER__, name, fn)

// #define REGISTER_OP_NO_GRADIENT(name)
//   REGISTER_OP_GRADIENT_UNIQ_HELPER(__COUNTER__, name, nullptr)

// #define REGISTER_OP_GRADIENT_UNIQ_HELPER(ctr, name, fn)
//   REGISTER_OP_GRADIENT_UNIQ(ctr, name, fn)

// #define REGISTER_OP_GRADIENT_UNIQ(ctr, name, fn)
//   static bool unused_grad_##ctr TF_ATTRIBUTE_UNUSED =
//       SHOULD_REGISTER_OP_GRADIENT &&
//       ::tensorflow::gradient::RegisterOp(name, fn)
// Register a gradient creator for the "op".
@Namespace("tensorflow::gradient") public static native @Cast("bool") boolean RegisterOp(@StdString BytePointer op, @ByVal @Cast("tensorflow::gradient::Creator*") Pointer func);
@Namespace("tensorflow::gradient") public static native @Cast("bool") boolean RegisterOp(@StdString String op, @ByVal @Cast("tensorflow::gradient::Creator*") Pointer func);

// Returns OK the gradient creator for the "op" is found (may be
// nullptr if REGISTER_OP_NO_GRADIENT is used.
@Namespace("tensorflow::gradient") public static native @ByVal Status GetOpGradientCreator(@StdString BytePointer op, @Cast("tensorflow::gradient::Creator*") Pointer creator);
@Namespace("tensorflow::gradient") public static native @ByVal Status GetOpGradientCreator(@StdString String op, @Cast("tensorflow::gradient::Creator*") Pointer creator);
  // namespace gradient

// Declare explicit instantiations of GetAttr
// #define GET_ATTR(T)
//   extern template Status FunctionLibraryDefinition::GetAttr(
//       const Node&, const string&, T*) const;
//   extern template Status FunctionLibraryDefinition::GetAttr(
//       const NodeDef&, const string&, T*) const;

  

  
// #undef GET_ATTR

  // end namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_FUNCTION_H_


// Parsed from tensorflow/core/framework/device_base.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_DEVICE_BASE_H_
// #define TENSORFLOW_CORE_FRAMEWORK_DEVICE_BASE_H_

// #include <memory>
// #include <string>
// #include <vector>

// #include "absl/base/macros.h"
// #include "absl/strings/string_view.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/lib/core/errors.h"
// #include "tensorflow/core/lib/core/refcount.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/platform/logging.h"
// #ifdef TENSORFLOW_USE_SYCL
// #endif

// Targeting ../Stream.java



// Targeting ../EventMgr.java


// Targeting ../ScopedAllocatorMgr.java



// Targeting ../PerOpGpuDevice.java


// Targeting ../DeviceContext.java



// map[i] is the DeviceContext* for the node with id i, if i < map.size().
// Targeting ../DeviceBase.java



// Methods to create and check for Symbolic execution devices.
// Such devices are mostly used for TF-XLA bridge. TF should not treat these as
// normal devices.
@Namespace("tensorflow") public static native void AddSymbolicExecutionDevice(@StdString BytePointer device_name);
@Namespace("tensorflow") public static native void AddSymbolicExecutionDevice(@StdString String device_name);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsSymbolicExecutionDevice(@StdString BytePointer device_name);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsSymbolicExecutionDevice(@StdString String device_name);

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_DEVICE_BASE_H_


// Parsed from tensorflow/core/common_runtime/device.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// A Device is a something that can perform computations as part of a
// model.  Devices can be local (runs computation on this machine), or
// remote (contacts a device local to another machine using an RPC to
// do the work).  Devices are registered in a DeviceSet, which is also
// responsible for the Device <-> id mapping.
//
// Device names
// * Every Device should have a unique name with the format:
//     /job:___/replica:___/task:___/(gpu|cpu):___
//   An example name would be "/job:train/replica:0/task:3/device:GPU:2".
// * Task numbers are within the specified replica, so there are as
//   many "task zeros" as replicas.

// #ifndef TENSORFLOW_CORE_COMMON_RUNTIME_DEVICE_H_
// #define TENSORFLOW_CORE_COMMON_RUNTIME_DEVICE_H_

// #include <memory>
// #include <string>

// #include "tensorflow/core/framework/allocator.h"
// #include "tensorflow/core/framework/control_flow.h"
// #include "tensorflow/core/framework/device_attributes.pb_text.h"
// #include "tensorflow/core/framework/device_attributes.pb.h"
// #include "tensorflow/core/framework/device_base.h"
// #include "tensorflow/core/framework/graph.pb.h"
// #include "tensorflow/core/framework/op_kernel.h"
// #include "tensorflow/core/framework/op_segment.h"
// #include "tensorflow/core/framework/resource_mgr.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/graph/graph.h"
// #include "tensorflow/core/graph/types.h"
// #include "tensorflow/core/lib/core/errors.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/types.h"
// #include "tensorflow/core/util/device_name_utils.h"
// Targeting ../Device.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_COMMON_RUNTIME_DEVICE_H_


// Parsed from tensorflow/core/common_runtime/device_mgr.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_COMMON_RUNTIME_DEVICE_MGR_H_
// #define TENSORFLOW_CORE_COMMON_RUNTIME_DEVICE_MGR_H_

// #include <memory>
// #include <string>
// #include <unordered_map>
// #include <unordered_set>
// #include <vector>

// #include "tensorflow/core/common_runtime/device.h"
// #include "tensorflow/core/lib/core/arena.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/lib/gtl/inlined_vector.h"
// #include "tensorflow/core/platform/macros.h"
// Targeting ../DeviceMgr.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_COMMON_RUNTIME_DEVICE_MGR_H_


// Parsed from tensorflow/core/common_runtime/process_function_library_runtime.h

/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
// #ifndef TENSORFLOW_CORE_COMMON_RUNTIME_PROCESS_FUNCTION_LIBRARY_RUNTIME_H_
// #define TENSORFLOW_CORE_COMMON_RUNTIME_PROCESS_FUNCTION_LIBRARY_RUNTIME_H_

// #include <unordered_map>

// #include "tensorflow/core/common_runtime/device_mgr.h"
// #include "tensorflow/core/common_runtime/device_set.h"
// #include "tensorflow/core/framework/function.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/protobuf/config.pb.h"
// Targeting ../ProcessFunctionLibraryRuntime.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_COMMON_RUNTIME_PROCESS_FUNCTION_LIBRARY_RUNTIME_H_


// Parsed from tensorflow/core/graph/graph.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// A Graph describes a set of computations that are to be
// performed, as well as the dependencies between those
// computations. The basic model is a DAG (directed acyclic graph) with
// * internal nodes representing computational operations to be performed;
// * edges represent dependencies, indicating the target may only be
//   executed once the source has completed; and
// * predefined "source" (start) and "sink" (finish) nodes -- the source
//   should be the only node that doesn't depend on anything, and the sink
//   should be the only node that nothing depends on.
//
// Note: Node ids are intended to be relatively dense in the
// 0..max_id range, but there may be gaps since ids won't be reused.
//
// Note: Some dependencies between operations are due to one operation
// consuming the output of another. In fact operations can produce
// multiple outputs and consume multiple inputs, and some
// optimizations will care about which specific outputs are connected
// to which specific inputs.  We therefore represent data dependency
// between output O of layer A and input I of layer B using
// "input index" and "output index" labels per edge.

// #ifndef TENSORFLOW_CORE_GRAPH_GRAPH_H_
// #define TENSORFLOW_CORE_GRAPH_GRAPH_H_

// #include <functional>
// #include <string>
// #include <vector>

// #include "tensorflow/core/framework/function.h"
// #include "tensorflow/core/framework/node_def.pb.h"
// #include "tensorflow/core/framework/op.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/graph/edgeset.h"
// #include "tensorflow/core/lib/core/arena.h"
// #include "tensorflow/core/lib/core/refcount.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/gtl/iterator_range.h"
// #include "tensorflow/core/platform/logging.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/types.h"
// Targeting ../EdgeSetTest.java


// Targeting ../WhileContext.java


// Targeting ../NeighborIter.java


// Targeting ../NodeIter.java


// Targeting ../NodeProperties.java


// Targeting ../Node.java


// Targeting ../NodeDebugInfo.java


// Targeting ../InputTensor.java


// Targeting ../OutputTensor.java


// Targeting ../Edge.java


// Targeting ../GraphEdgesIterable.java


// Targeting ../Graph.java



// TODO(josh11b): We may want to support keeping an index on various
// node/edge attributes in a graph, particularly node names.

// Helper routines

@Namespace("tensorflow") public static native @Cast("bool") boolean IsSource(@Const Node node);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsSink(@Const Node node);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsSwitch(@Const Node node);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsMerge(@Const Node node);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsEnter(@Const Node node);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsExit(@Const Node node);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsNextIteration(@Const Node n);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsLoopCond(@Const Node node);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsControlTrigger(@Const Node n);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsSend(@Const Node node);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsRecv(@Const Node node);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsHostSend(@Const Node node);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsHostRecv(@Const Node node);

// True for Nodes that mediate the transfer of values between processes.
@Namespace("tensorflow") public static native @Cast("bool") boolean IsTransferNode(@Const Node n);

@Namespace("tensorflow") public static native @Cast("bool") boolean IsConstant(@Const Node node);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsVariable(@Const Node node);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsIdentity(@Const Node node);

// Returns true iff 'n' is a control flow node.
@Namespace("tensorflow") public static native @Cast("bool") boolean IsControlFlow(@Const Node n);

// Returns true if the node only depends on its input's metadata
// (shape).  Specifically, returns true for "Size", "Shape" and "Rank" ops.
@Namespace("tensorflow") public static native @Cast("bool") boolean IsMetadata(@Const Node n);

@Namespace("tensorflow") public static native @Cast("bool") boolean IsScopedAllocator(@Const Node n);

@Namespace("tensorflow") public static native @Cast("bool") boolean IsHostMemoryPreserving(@Const Node node);

// NOTE: We declare Reference type of NodeIter and NeighborIter as Node* (see
// https://en.cppreference.com/w/cpp/iterator/iterator).

// Iterator for stepping through the nodes of a graph.

// Iterator for stepping through the neighbors of a node.

// IMPLEMENTATION DETAILS, PLEASE IGNORE





































  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_GRAPH_GRAPH_H_


// Parsed from tensorflow/core/graph/tensor_id.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_GRAPH_TENSOR_ID_H_
// #define TENSORFLOW_CORE_GRAPH_TENSOR_ID_H_

// #include <string>

// #include "tensorflow/core/graph/graph.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/lib/hash/hash.h"
// #include "tensorflow/core/lib/strings/strcat.h"
// Targeting ../TensorId.java



@Namespace("tensorflow") public static native @ByVal TensorId ParseTensorName(@StdString BytePointer name);
@Namespace("tensorflow") public static native @ByVal TensorId ParseTensorName(@StdString String name);

@Namespace("tensorflow") public static native @Cast("bool") boolean IsTensorIdControl(@Const @ByRef TensorId tensor_id);
// Targeting ../SafeTensorId.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_GRAPH_TENSOR_ID_H_


// Parsed from tensorflow/core/common_runtime/graph_runner.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_COMMON_RUNTIME_GRAPH_RUNNER_H_
// #define TENSORFLOW_CORE_COMMON_RUNTIME_GRAPH_RUNNER_H_

// #include <memory>
// #include <string>
// #include <vector>

// #include "tensorflow/core/common_runtime/device.h"
// #include "tensorflow/core/framework/function.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/graph/graph.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/platform/env.h"
// Targeting ../GraphRunner.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_COMMON_RUNTIME_GRAPH_RUNNER_H_


// Parsed from tensorflow/core/common_runtime/shape_refiner.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
// #ifndef TENSORFLOW_CORE_COMMON_RUNTIME_SHAPE_REFINER_H_
// #define TENSORFLOW_CORE_COMMON_RUNTIME_SHAPE_REFINER_H_

// #include <vector>

// #include "tensorflow/core/common_runtime/graph_runner.h"
// #include "tensorflow/core/framework/function.pb.h"
// #include "tensorflow/core/framework/shape_inference.h"
// #include "tensorflow/core/graph/graph.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/platform/macros.h"


// This class stores extra inference information in addition to
// InferenceContext, such as inference tree for user-defined functions and node
// input and output types.
// Targeting ../ShapeRefiner.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_COMMON_RUNTIME_SHAPE_REFINER_H_


// Parsed from tensorflow/core/framework/node_def_builder.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_NODE_DEF_BUILDER_H_
// #define TENSORFLOW_CORE_FRAMEWORK_NODE_DEF_BUILDER_H_

// #include <functional>
// #include <vector>
// #include "tensorflow/core/framework/attr_value_util.h"
// #include "tensorflow/core/framework/node_def.pb.h"
// #include "tensorflow/core/framework/node_def_util.h"
// #include "tensorflow/core/framework/op.h"
// #include "tensorflow/core/framework/op_def.pb.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/graph/graph.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// #include "tensorflow/core/lib/strings/strcat.h"
// Targeting ../NodeDefBuilder.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_NODE_DEF_BUILDER_H_


// Parsed from tensorflow/core/framework/node_def_util.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_NODE_DEF_UTIL_H_
// #define TENSORFLOW_CORE_FRAMEWORK_NODE_DEF_UTIL_H_

// #include <string>
// #include <vector>

// #include "tensorflow/core/framework/attr_value_util.h"
// #include "tensorflow/core/framework/node_def.pb.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/lib/gtl/flatmap.h"
// #include "tensorflow/core/lib/hash/hash.h"
// #include "tensorflow/core/platform/protobuf.h"

// We forward declare protos so that kernels don't need to depend on them

// Name of the attribute used to encode node colocation constraints.
//
// Nodes can be co-located on the same device. Desire for explicit co-location
// is described by list(string) attribute containing the name of colocation
// groups.
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer kColocationAttrName();

// String prefix applied to the operation name for colocation constraints.
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer kColocationGroupPrefix();

// Produce a human-readable version of a Node or NodeDef that is more concise
// than a text-format proto.
@Namespace("tensorflow") public static native @StdString BytePointer SummarizeNode(@Const @ByRef Node node);
@Namespace("tensorflow") public static native @StdString BytePointer SummarizeNodeDef(@Const @ByRef NodeDef node_def);
@Namespace("tensorflow") public static native @StdString BytePointer SummarizeAttrs(@Const @ByRef NodeDef node_def);
@Namespace("tensorflow") public static native @StdString BytePointer SummarizeAttrsHelper(@ByVal AttrSlice attrs, @StringPiece BytePointer device);
@Namespace("tensorflow") public static native @StdString String SummarizeAttrsHelper(@ByVal AttrSlice attrs, @StringPiece String device);

// Produces a formatted string pattern from the node which can uniquely identify
// this node upstream to produce an informative error message. The pattern
// followed is: {{node <node_name>}}
@Namespace("tensorflow") public static native @StdString BytePointer FormatNodeForError(@Const @ByRef Node node);
@Namespace("tensorflow") public static native @StdString BytePointer FormatNodeDefForError(@Const @ByRef NodeDef node_def);
@Namespace("tensorflow") public static native @StdString BytePointer FormatNodeDefForError(
    @StringPiece BytePointer node_name, @Cast("bool") boolean has_experimental_debug_info,
    @Const @ByRef NodeDef_ExperimentalDebugInfo experimental_debug_info);
@Namespace("tensorflow") public static native @StdString String FormatNodeDefForError(
    @StringPiece String node_name, @Cast("bool") boolean has_experimental_debug_info,
    @Const @ByRef NodeDef_ExperimentalDebugInfo experimental_debug_info);

// Merges the original node names from the debug information of 'from' to the
// debug information of 'to'.
@Namespace("tensorflow") public static native void MergeDebugInfo(@Const @ByRef NodeDebugInfo from, Node to);
@Namespace("tensorflow") public static native void MergeDebugInfo(@Const @ByRef NodeDebugInfo from, NodeDef to);
@Namespace("tensorflow") public static native void MergeDebugInfo(@Const @ByRef NodeDef from, NodeDef to);

// Adds an attr with name <name> and value <value> to *node_def.
// The type of the attr is based on the type of value.
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @Const @ByRef AttrValue value, NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @Const @ByRef AttrValue value, NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @StringPiece BytePointer value, NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @StringPiece String value, NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, int value, NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, int value, NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @Cast("tensorflow::int64") long value, NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @Cast("tensorflow::int64") long value, NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, float value, NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, float value, NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, double value, NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, double value, NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @Cast("bool") boolean value, NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @Cast("bool") boolean value, NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @Const @ByRef PartialTensorShape value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @Const @ByRef PartialTensorShape value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @Const @ByRef Tensor value, NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @Const @ByRef Tensor value, NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @Const @ByRef TensorProto value, NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @Const @ByRef TensorProto value, NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @Const @ByRef NameAttrList value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @Const @ByRef NameAttrList value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @ByVal @Cast("tensorflow::gtl::ArraySlice<tensorflow::StringPiece>*") StringPieceVector value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @ByVal @Cast("tensorflow::gtl::ArraySlice<tensorflow::StringPiece>*") StringPieceVector value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @Cast("const char**") @ArraySlice PointerPointer value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @Cast("const char**") @ArraySlice @ByPtrPtr ByteBuffer value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @Cast("const char**") @ArraySlice @ByPtrPtr byte[] value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @Cast("const char**") @ArraySlice @ByPtrPtr BytePointer value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @Cast("const char**") @ArraySlice @ByPtrPtr ByteBuffer value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @Cast("const char**") @ArraySlice @ByPtrPtr byte[] value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @ByVal @Cast("tensorflow::gtl::ArraySlice<tensorflow::string>*") StringVector value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @ByVal @Cast("tensorflow::gtl::ArraySlice<tensorflow::string>*") StringVector value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @ArraySlice IntPointer value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @ArraySlice IntBuffer value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @ArraySlice int[] value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @ArraySlice IntPointer value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @ArraySlice IntBuffer value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @ArraySlice int[] value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @Cast("tensorflow::int64*") @ArraySlice LongPointer value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @Cast("tensorflow::int64*") @ArraySlice LongBuffer value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @Cast("tensorflow::int64*") @ArraySlice long[] value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @Cast("tensorflow::int64*") @ArraySlice LongPointer value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @Cast("tensorflow::int64*") @ArraySlice LongBuffer value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @Cast("tensorflow::int64*") @ArraySlice long[] value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @ArraySlice FloatPointer value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @ArraySlice FloatBuffer value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @ArraySlice float[] value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @ArraySlice FloatPointer value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @ArraySlice FloatBuffer value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @ArraySlice float[] value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @Cast("bool*") @ArraySlice BoolPointer value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @Cast("bool*") @ArraySlice boolean[] value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @ByVal @Cast("tensorflow::gtl::ArraySlice<tensorflow::TensorShape>*") TensorShapeVector value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @ByVal @Cast("tensorflow::gtl::ArraySlice<tensorflow::TensorShape>*") TensorShapeVector value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @ArraySlice TensorShapeProto value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @ArraySlice TensorShapeProto value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @ByVal TensorVector value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @ByVal TensorVector value,
                 NodeDef node_def);

// Version to workaround C++'s "perfect" forwarding not being able to
// forward {...} initialization.

// Adds an attr to an attr value map.
@Namespace("tensorflow") public static native void AddAttr(@StringPiece BytePointer name, @Const @ByRef AttrValue value, @Cast("tensorflow::AttrValueMap*") StringStringMap map);
@Namespace("tensorflow") public static native void AddAttr(@StringPiece String name, @Const @ByRef AttrValue value, @Cast("tensorflow::AttrValueMap*") StringStringMap map);
@Namespace("tensorflow") public static native void AddAttr(@StringPiece BytePointer name, @Cast("bool") boolean value, @Cast("tensorflow::AttrValueMap*") StringStringMap map);
@Namespace("tensorflow") public static native void AddAttr(@StringPiece String name, @Cast("bool") boolean value, @Cast("tensorflow::AttrValueMap*") StringStringMap map);
// Targeting ../AttrSlice.java



// Return true if the attr with the name attr_name is defined in node_def.
@Namespace("tensorflow") public static native @Cast("bool") boolean HasNodeAttr(@Const @ByRef NodeDef node_def, @StringPiece BytePointer attr_name);
@Namespace("tensorflow") public static native @Cast("bool") boolean HasNodeAttr(@Const @ByRef NodeDef node_def, @StringPiece String attr_name);

// Look up the attr with name attr_name and set *value to its value.  If no
// attr with attr_name is found in node_def, or the attr does not have
// a matching type, a non-ok status will be returned.
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   @StdString @Cast({"char*", "std::string*"}) BytePointer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   @StdString @Cast({"char*", "std::string*"}) BytePointer value);  // type: "string"
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   @Cast("tensorflow::int64*") LongPointer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   @Cast("tensorflow::int64*") LongBuffer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   @Cast("tensorflow::int64*") long... value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   @Cast("tensorflow::int64*") LongPointer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   @Cast("tensorflow::int64*") LongBuffer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   @Cast("tensorflow::int64*") long... value);  // type: "int"
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   IntPointer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   IntBuffer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   int... value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   IntPointer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   IntBuffer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   int... value);  // type: "int"
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   FloatPointer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   FloatBuffer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   float... value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   FloatPointer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   FloatBuffer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   float... value);  // type: "float"
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   @Cast("bool*") BoolPointer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   @Cast("bool*") boolean... value);  // type: "bool"  // type: "type"
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   TensorShapeProto value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   TensorShapeProto value);  // type: "shape"
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   TensorShape value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   TensorShape value);  // type: "shape"
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   PartialTensorShape value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   PartialTensorShape value);  // type: "shape"
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   Tensor value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   Tensor value);  // type: "tensor"
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   StringVector value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   StringVector value);  // type "list(string)"  // type "list(int)"  // type "list(int)"  // type "list(float)"  // type "list(bool)"  // type "list(type)"
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   DataTypeVector value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   DataTypeVector value);  // type "list(type)"  // type "list(shape)"
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   TensorShapeVector value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   TensorShapeVector value);  // type "list(shape)"  // type "list(shape)"
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   TensorVector value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   TensorVector value);  // type: "list(tensor)"

// This version avoids copying the TensorProto.
// REQUIRES: Must not use *value beyond the lifetime of node_def.
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   @Cast("const tensorflow::TensorProto**") PointerPointer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   @Const @ByPtrPtr TensorProto value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   @Const @ByPtrPtr TensorProto value);  // type: "tensor"
@Namespace("tensorflow") public static native @Cast("bool") boolean TryGetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                    @Cast("const tensorflow::TensorProto**") PointerPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean TryGetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                    @Const @ByPtrPtr TensorProto value);
@Namespace("tensorflow") public static native @Cast("bool") boolean TryGetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                    @Const @ByPtrPtr TensorProto value);  // type: "tensor"

// This version avoids copying the NameAttrList.
// REQUIRES: Must not use *value beyond the lifetime of node_def.
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   @Const @ByPtrPtr NameAttrList value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   @Const @ByPtrPtr NameAttrList value);  // type: "func"
@Namespace("tensorflow") public static native @Cast("bool") boolean TryGetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                    @Const @ByPtrPtr NameAttrList value);
@Namespace("tensorflow") public static native @Cast("bool") boolean TryGetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                    @Const @ByPtrPtr NameAttrList value);  // type: "func"

// These versions copies the NameAttrList(s).  // type: "func"  // type: "list(func)"

// Look up the attr with name attr_name and set *value to its value.  If no
// attr with attr_name is found in node_def, or the attr does not have
// a matching type, false is returned.
@Namespace("tensorflow") public static native @Cast("bool") boolean TryGetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                    @StdString @Cast({"char*", "std::string*"}) BytePointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean TryGetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                    @StdString @Cast({"char*", "std::string*"}) BytePointer value);  // type: "string"
@Namespace("tensorflow") public static native @Cast("bool") boolean TryGetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                    @Cast("tensorflow::int64*") LongPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean TryGetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                    @Cast("tensorflow::int64*") LongBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean TryGetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                    @Cast("tensorflow::int64*") long... value);
@Namespace("tensorflow") public static native @Cast("bool") boolean TryGetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                    @Cast("tensorflow::int64*") LongPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean TryGetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                    @Cast("tensorflow::int64*") LongBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean TryGetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                    @Cast("tensorflow::int64*") long... value);  // type: "int"  // type: "int"
@Namespace("tensorflow") public static native @Cast("bool") boolean TryGetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                    IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean TryGetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                    IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean TryGetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                    int... value);
@Namespace("tensorflow") public static native @Cast("bool") boolean TryGetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                    IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean TryGetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                    IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean TryGetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                    int... value);  // type: "int"
@Namespace("tensorflow") public static native @Cast("bool") boolean TryGetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                    FloatPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean TryGetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                    FloatBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean TryGetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                    float... value);
@Namespace("tensorflow") public static native @Cast("bool") boolean TryGetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                    FloatPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean TryGetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                    FloatBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean TryGetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                    float... value);  // type: "float"
@Namespace("tensorflow") public static native @Cast("bool") boolean TryGetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                    @Cast("bool*") BoolPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean TryGetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                    @Cast("bool*") boolean... value);  // type: "bool"  // type: "type"
@Namespace("tensorflow") public static native @Cast("bool") boolean TryGetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                    TensorShape value);
@Namespace("tensorflow") public static native @Cast("bool") boolean TryGetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                    TensorShape value);  // type: "shape"

@Namespace("tensorflow") public static native @Cast("bool") boolean TryGetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                    StringVector value);
@Namespace("tensorflow") public static native @Cast("bool") boolean TryGetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                    StringVector value);  // type: "list(string)"  // type: "list(int)"  // type: "list(float)"  // type: "list(bool)"  // type: "list(type)"
@Namespace("tensorflow") public static native @Cast("bool") boolean TryGetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                    TensorShapeVector value);
@Namespace("tensorflow") public static native @Cast("bool") boolean TryGetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                    TensorShapeVector value);  // type: "shape"

// Overloads of TryGetNodeAttr() that avoid copying the non-POD attribute
// values.  // type: "list(string)"
@Namespace("tensorflow") public static native @Cast("bool") boolean TryGetNodeAttr(
    @Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
    @Cast("std::vector<const tensorflow::TensorShapeProto*>*") TensorShapeProtoVector value);
@Namespace("tensorflow") public static native @Cast("bool") boolean TryGetNodeAttr(
    @Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
    @Cast("std::vector<const tensorflow::TensorShapeProto*>*") TensorShapeProtoVector value);  // type: "list(shape)"

// Look up the attr with name attr_name and return a reference to its value.
// If no attr with attr_name is found in node_def, or the attr does not have
// a matching type, a reference to an empty string is returned.
// REQUIRES: Must not use the returned value beyond the lifetime of node_def.
@Namespace("tensorflow") public static native @StdString BytePointer GetNodeAttrString(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name);
@Namespace("tensorflow") public static native @StdString String GetNodeAttrString(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name);

// Computes the input type for a specific node input.
// REQUIRES: ValidateOpDef(op_def).ok()
@Namespace("tensorflow") public static native @ByVal Status InputTypeForNode(@Const @ByRef NodeDef node_def, @Const @ByRef OpDef op_def,
                        int input_port, @Cast("tensorflow::DataType*") IntPointer input_type);
// Computes the input types for a specific node.
// REQUIRES: ValidateOpDef(op_def).ok()
@Namespace("tensorflow") public static native @ByVal Status InputTypesForNode(@Const @ByRef NodeDef node_def, @Const @ByRef OpDef op_def,
                         DataTypeVector inputs);
// Computes the output type for a specific node output.
// REQUIRES: ValidateOpDef(op_def).ok()
@Namespace("tensorflow") public static native @ByVal Status OutputTypeForNode(@Const @ByRef NodeDef node_def, @Const @ByRef OpDef op_def,
                         int output_port, @Cast("tensorflow::DataType*") IntPointer output_type);
// Computes the output types for a specific node.
// REQUIRES: ValidateOpDef(op_def).ok()
@Namespace("tensorflow") public static native @ByVal Status OutputTypesForNode(@Const @ByRef NodeDef node_def, @Const @ByRef OpDef op_def,
                          DataTypeVector outputs);
@Namespace("tensorflow") public static native @ByVal Status OutputTypesForNode(@Const @ByRef AttrSlice attrs, @Const @ByRef OpDef op_def,
                          DataTypeVector outputs);

// Computes the input and output types for a specific node.
// REQUIRES: ValidateOpDef(op_def).ok()
@Namespace("tensorflow") public static native @ByVal Status InOutTypesForNode(@Const @ByRef NodeDef node_def, @Const @ByRef OpDef op_def,
                         DataTypeVector inputs, DataTypeVector outputs);
// Computes the number of outputs for a specific node.
// REQUIRES: ValidateOpDef(op_def).ok()
@Namespace("tensorflow") public static native @ByVal Status NumOutputsForNode(@Const @ByRef NodeDef node_def, @Const @ByRef OpDef op_def,
                         IntPointer num_outputs);
@Namespace("tensorflow") public static native @ByVal Status NumOutputsForNode(@Const @ByRef NodeDef node_def, @Const @ByRef OpDef op_def,
                         IntBuffer num_outputs);
@Namespace("tensorflow") public static native @ByVal Status NumOutputsForNode(@Const @ByRef NodeDef node_def, @Const @ByRef OpDef op_def,
                         int... num_outputs);

// Validates that the NodeDef:
// * Defines all expected attrs from the OpDef.
// * All attrs satisfies constraints from the OpDef.
// * Has a signature matching SignatureForNode().
// etc.
@Namespace("tensorflow") public static native @ByVal Status ValidateNodeDef(@Const @ByRef NodeDef node_def, @Const @ByRef OpDef op_def);

// Computes the mapping from input/output argument name to the
// corresponding input/output index range.  For example,
// input "foo" corresponds to input indices
//   [ (*inputs)["foo"].first, (*inputs)["foo"].second ).
// NOTE(mrry): To reduce allocations when the map is used and save
// space, the returned `NameRangeMap` objects borrow the input/output
// argument names from `op_def`. The `op_def` must outlive the
// returned `NameRangeMap` objects.
@Namespace("tensorflow") public static native @ByVal Status NameRangesForNode(@Const @ByRef AttrSlice attrs, @Const @ByRef OpDef op_def,
                         NameRangeMap inputs, NameRangeMap outputs);
@Namespace("tensorflow") public static native @ByVal Status NameRangesForNode(@Const @ByRef Node node, @Const @ByRef OpDef op_def,
                         NameRangeMap inputs, NameRangeMap outputs);

// Adds default values to *node_def for unspecified attrs from op_def.
@Namespace("tensorflow") public static native void AddDefaultsToNodeDef(@Const @ByRef OpDef op_def, NodeDef node_def);

// Validates the syntax of a NodeDef provided externally.
//
// The following is an EBNF-style syntax for NodeDef objects. Note that
// Node objects are actually specified as tensorflow::NodeDef protocol buffers,
// which contain many other fields that are not (currently) validated.
//
// Node         = NodeName, Inputs
// Inputs       = ( DataInput * ), ( ControlInput * )
// DataInput    = NodeName, ( ":", [1-9], [0-9] * ) ?
// ControlInput = "^", NodeName
// NodeName     = [A-Za-z0-9.], [A-Za-z0-9_./] *
@Namespace("tensorflow") public static native @ByVal Status ValidateExternalNodeDefSyntax(@Const @ByRef NodeDef node_def);

// Returns "status" with formatted NodeDef attached as additional text
// in the error message. If 'allow_multiple_formatted_node' is false and there
// is already a formatted NodeDef present in 'status', we simply attach the name
// of the NodeDef instead of the formatted string.
@Namespace("tensorflow") public static native @ByVal Status AttachDef(@Const @ByRef Status status, @Const @ByRef NodeDef node_def,
                 @Cast("bool") boolean allow_multiple_formatted_node/*=false*/);
@Namespace("tensorflow") public static native @ByVal Status AttachDef(@Const @ByRef Status status, @Const @ByRef NodeDef node_def);
@Namespace("tensorflow") public static native @ByVal Status AttachDef(@Const @ByRef Status status, @Const @ByRef Node node,
                 @Cast("bool") boolean allow_multiple_formatted_node/*=false*/);
@Namespace("tensorflow") public static native @ByVal Status AttachDef(@Const @ByRef Status status, @Const @ByRef Node node);

// Appends the given prefix and suffix to the original node name in order to
// make the name unique. If it's an "Enter" node and uniquify_frame_name is
// true, use the same way to reset attribute "frame_name".
@Namespace("tensorflow") public static native @ByVal Status AddPrefixAndSuffixToNode(@StringPiece BytePointer prefix, @StringPiece BytePointer suffix,
                                NodeDef node_def,
                                @Cast("bool") boolean uniquify_frame_name/*=true*/);
@Namespace("tensorflow") public static native @ByVal Status AddPrefixAndSuffixToNode(@StringPiece BytePointer prefix, @StringPiece BytePointer suffix,
                                NodeDef node_def);
@Namespace("tensorflow") public static native @ByVal Status AddPrefixAndSuffixToNode(@StringPiece String prefix, @StringPiece String suffix,
                                NodeDef node_def,
                                @Cast("bool") boolean uniquify_frame_name/*=true*/);
@Namespace("tensorflow") public static native @ByVal Status AddPrefixAndSuffixToNode(@StringPiece String prefix, @StringPiece String suffix,
                                NodeDef node_def);
  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_NODE_DEF_UTIL_H_


// Parsed from tensorflow/core/framework/selective_registration.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_SELECTIVE_REGISTRATION_H_
// #define TENSORFLOW_CORE_FRAMEWORK_SELECTIVE_REGISTRATION_H_

// #include <string.h>

// #ifdef SELECTIVE_REGISTRATION

// Experimental selective registration support to reduce binary size.
//
// To use selective registration, when building:
// 1. define SELECTIVE_REGISTRATION, e.g. in gcc by passing
//    -DSELECTIVE_REGISTRATION to compilation.
// 2. Provide ops_to_register.h. This file is not included in the repo and must
//    be placed by the user or a tool where the compiler can find it.  It must
//    define the constants and functions used in the macros below. The
//    functions should be defined as valid constexpr functions, so that they are
//    evaluated at compile time: this is needed to make symbols referenced by
//    un-registered objects unused, and therefore allow the linker to strip them
//    out.  See python/tools/print_selective_registration_header.py for a tool
//    that can be used to generate ops_to_register.h.
//
// ops_to_register.h should define macros for:
//   // Ops for which this is false will not be registered.
//   SHOULD_REGISTER_OP(op)
//   // If this is false, then no gradient ops are registered.
//   SHOULD_REGISTER_OP_GRADIENT
//   // Op kernel classes where this is false won't be registered.
//   SHOULD_REGISTER_OP_KERNEL(clz)
// The macros should be defined using constexprs.

// #include "ops_to_register.h"

// #if (!defined(SHOULD_REGISTER_OP) || !defined(SHOULD_REGISTER_OP_GRADIENT) ||
//      !defined(SHOULD_REGISTER_OP_KERNEL))
// #endif
// #else
// #define SHOULD_REGISTER_OP(op) true
// #define SHOULD_REGISTER_OP_GRADIENT true
// #define SHOULD_REGISTER_OP_KERNEL(clz) true
// #endif

// #endif  // TENSORFLOW_CORE_FRAMEWORK_SELECTIVE_REGISTRATION_H_


// Parsed from tensorflow/core/graph/node_builder.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_GRAPH_NODE_BUILDER_H_
// #define TENSORFLOW_CORE_GRAPH_NODE_BUILDER_H_

// #include <vector>
// #include "tensorflow/core/framework/node_def_builder.h"
// #include "tensorflow/core/framework/op.h"
// #include "tensorflow/core/framework/op_def.pb.h"
// #include "tensorflow/core/graph/graph.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../NodeBuilder.java



// IMPLEMENTATION -------------------------------------------------------------





  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_GRAPH_NODE_BUILDER_H_


// Parsed from tensorflow/core/graph/graph_def_builder.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_GRAPH_GRAPH_DEF_BUILDER_H_
// #define TENSORFLOW_CORE_GRAPH_GRAPH_DEF_BUILDER_H_

// #include <vector>
// #include "tensorflow/core/framework/graph.pb.h"
// #include "tensorflow/core/framework/op.h"
// #include "tensorflow/core/graph/graph.h"
// #include "tensorflow/core/graph/node_builder.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../GraphDefBuilder.java



// A NodeOut may either be a regular input or back input.  Regular
// inputs are specified via either a Node* or a Node* and an output
// index.  Back inputs are specified by a node name, output index, and
// output type.

// For adding an Op with no inputs to a GraphDefBuilder.
@Namespace("tensorflow::ops") public static native Node SourceOp(@StdString BytePointer op_name, @Const @ByRef GraphDefBuilder.Options opts);
@Namespace("tensorflow::ops") public static native Node SourceOp(@StdString String op_name, @Const @ByRef GraphDefBuilder.Options opts);

// For adding an Op with one input to a GraphDefBuilder.
@Namespace("tensorflow::ops") public static native Node UnaryOp(@StdString BytePointer op_name, @ByVal NodeBuilder.NodeOut input,
              @Const @ByRef GraphDefBuilder.Options opts);
@Namespace("tensorflow::ops") public static native Node UnaryOp(@StdString String op_name, Node input,
              @Const @ByRef GraphDefBuilder.Options opts);

// For adding an Op with two inputs to a GraphDefBuilder.
@Namespace("tensorflow::ops") public static native Node BinaryOp(@StdString BytePointer op_name, @ByVal NodeBuilder.NodeOut a, @ByVal NodeBuilder.NodeOut b,
               @Const @ByRef GraphDefBuilder.Options opts);
@Namespace("tensorflow::ops") public static native Node BinaryOp(@StdString String op_name, Node a, Node b,
               @Const @ByRef GraphDefBuilder.Options opts);

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_GRAPH_GRAPH_DEF_BUILDER_H_


// Parsed from tensorflow/core/graph/default_device.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_GRAPH_DEFAULT_DEVICE_H_
// #define TENSORFLOW_CORE_GRAPH_DEFAULT_DEVICE_H_

// #include <string>

// #include "tensorflow/core/framework/graph.pb.h"
// #include "tensorflow/core/framework/node_def.pb.h"

// Sets the default device for all nodes in graph_def to "device",
// only if not already set.
@Namespace("tensorflow::graph") public static native void SetDefaultDevice(@StdString BytePointer device, GraphDef graph_def);
@Namespace("tensorflow::graph") public static native void SetDefaultDevice(@StdString String device, GraphDef graph_def);

  // namespace graph
  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_GRAPH_DEFAULT_DEVICE_H_


// Parsed from tensorflow/core/graph/graph_constructor.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_GRAPH_GRAPH_CONSTRUCTOR_H_
// #define TENSORFLOW_CORE_GRAPH_GRAPH_CONSTRUCTOR_H_

// #include "tensorflow/core/framework/graph.pb.h"
// #include "tensorflow/core/graph/graph.h"
// #include "tensorflow/core/graph/tensor_id.h"
// #include "tensorflow/core/lib/core/status.h"
// Targeting ../GraphConstructorOptions.java


@Namespace("tensorflow") public static native @ByVal Status ConvertGraphDefToGraph(@Const @ByRef GraphConstructorOptions opts,
                                     @Const @ByRef GraphDef gdef, Graph g);

// Same as ConvertGraphDefToGraph, but takes just nodes.  Used by function
// instantiation.
// TODO(irving): This will turn into std::vector<NodeInfoPtr> soon.
@Namespace("tensorflow") public static native @ByVal Status ConvertNodeDefsToGraph(@Const @ByRef GraphConstructorOptions opts,
                                     @ArraySlice NodeDef nodes, Graph g);
// Targeting ../ImportGraphDefOptions.java


// Targeting ../ImportGraphDefResults.java



// Adds the graph in GraphDef `gdef` into an existing Graph `*g`.
//
// On error, returns non-OK and leaves `*g` unmodified.
//
// `refiner` can be null. It should be non-null if the caller
// intends to add additional nodes to the graph after the import. This
// allows the caller to validate shapes of those nodes (since
// ShapeRefiner::AddNode must be called in topological order).
//
// `results` must be non-null if `opts.return_tensors` or `opts.result_nodes` is
// non-empty. It can also be set to fetch the unused input map keys. If it's
// non-null, all the vector fields must be empty.
//
// TODO(ashankar): Push this mechanism and get rid of Session::Extend()
// as a means of enhancing an existing Graph.
@Namespace("tensorflow") public static native @ByVal Status ImportGraphDef(@Const @ByRef ImportGraphDefOptions opts,
                             @Const @ByRef GraphDef gdef, Graph g,
                             ShapeRefiner refiner,
                             ImportGraphDefResults results/*=nullptr*/);
@Namespace("tensorflow") public static native @ByVal Status ImportGraphDef(@Const @ByRef ImportGraphDefOptions opts,
                             @Const @ByRef GraphDef gdef, Graph g,
                             ShapeRefiner refiner);

// Make a copy of "src" into "*dest".
//
// REQUIRES: "*dest" is a freshly allocated graph without any nodes or edges
// other than the implicit Source/Sink nodes.
@Namespace("tensorflow") public static native void CopyGraph(@Const @ByRef Graph src, Graph dest);

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_GRAPH_GRAPH_CONSTRUCTOR_H_


// Parsed from tensorflow/core/graph/gradients.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_GRAPH_GRADIENTS_H_
// #define TENSORFLOW_CORE_GRAPH_GRADIENTS_H_

// #include "tensorflow/core/graph/graph.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../NodeOut.java



// NOTE: This API is a work in progress and will likely be changing frequently.
//
// Given initial gradient-node outputs 'y_grad_node_outputs' (which compute the
// symbolic partial derivatives of some loss function 'L' w.r.t the node outputs
// 'y_node_outputs'), adds gradient nodes to 'graph' that compute the symbolic
// partial derivatives of 'L' w.r.t the node outputs 'x_node_outputs'.
//
// REQUIRES: Each node in 'x_node_outputs' to be unique, and so to have a single
// output (this restriction will be removed in a subsequent change).

// TODO(andydavis) Add symbolic gradient support for general graphs (the current
// implementation only supports gradients for functions). In particular,
// the nodes in 'x_nodes' are currently restricted to have one output.

@Namespace("tensorflow") public static native @ByVal Status AddSymbolicGradients(@ArraySlice NodeOut y_node_outputs,
                            @ArraySlice NodeOut x_node_outputs,
                            @ArraySlice NodeOut y_grad_node_outputs,
                            @StdVector NodeOut x_grad_node_outputs,
                            Graph graph);

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_GRAPH_GRADIENTS_H_


// Parsed from tensorflow/core/framework/variable.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/variable.proto

// #ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fvariable_2eproto
// #define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fvariable_2eproto

// #include <limits>
// #include <string>

// #include <google/protobuf/port_def.inc>
// #if PROTOBUF_VERSION < 3008000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please update
// #error your headers.
// #endif
// #if 3008000 < PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/port_undef.inc>
// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/generated_message_reflection.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/generated_enum_reflection.h>
// #include <google/protobuf/unknown_field_set.h>
// @@protoc_insertion_point(includes)
// #include <google/protobuf/port_def.inc>
// #define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcore_2fframework_2fvariable_2eproto
  // namespace internal
 /* namespace protobuf */
   /* namespace google */

// Internal implementation detail -- do not use these members.
  // namespace tensorflow


 /* namespace protobuf */
   /* namespace google */

/** enum tensorflow::VariableSynchronization */
public static final int
  VARIABLE_SYNCHRONIZATION_AUTO = 0,
  VARIABLE_SYNCHRONIZATION_NONE = 1,
  VARIABLE_SYNCHRONIZATION_ON_WRITE = 2,
  VARIABLE_SYNCHRONIZATION_ON_READ = 3;
@Name("tensorflow::VariableSynchronization_INT_MIN_SENTINEL_DO_NOT_USE_") public static native @MemberGetter int VariableSynchronization_INT_MIN_SENTINEL_DO_NOT_USE_();
public static final int
  VariableSynchronization_INT_MIN_SENTINEL_DO_NOT_USE_ = VariableSynchronization_INT_MIN_SENTINEL_DO_NOT_USE_();
@Name("tensorflow::VariableSynchronization_INT_MAX_SENTINEL_DO_NOT_USE_") public static native @MemberGetter int VariableSynchronization_INT_MAX_SENTINEL_DO_NOT_USE_();
public static final int
  VariableSynchronization_INT_MAX_SENTINEL_DO_NOT_USE_ = VariableSynchronization_INT_MAX_SENTINEL_DO_NOT_USE_();
@Namespace("tensorflow") public static native @Cast("bool") boolean VariableSynchronization_IsValid(int value);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::VariableSynchronization") int VariableSynchronization_MIN();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::VariableSynchronization") int VariableSynchronization_MAX();
@Namespace("tensorflow") @MemberGetter public static native int VariableSynchronization_ARRAYSIZE();

@Namespace("tensorflow") public static native @Cast("const google::protobuf::EnumDescriptor*") Pointer VariableSynchronization_descriptor();
@Namespace("tensorflow") public static native @Cast("bool") boolean VariableSynchronization_Parse(
    @StdString BytePointer name, @Cast("tensorflow::VariableSynchronization*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean VariableSynchronization_Parse(
    @StdString String name, @Cast("tensorflow::VariableSynchronization*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean VariableSynchronization_Parse(
    @StdString BytePointer name, @Cast("tensorflow::VariableSynchronization*") int... value);
@Namespace("tensorflow") public static native @Cast("bool") boolean VariableSynchronization_Parse(
    @StdString String name, @Cast("tensorflow::VariableSynchronization*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean VariableSynchronization_Parse(
    @StdString BytePointer name, @Cast("tensorflow::VariableSynchronization*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean VariableSynchronization_Parse(
    @StdString String name, @Cast("tensorflow::VariableSynchronization*") int... value);
/** enum tensorflow::VariableAggregation */
public static final int
  VARIABLE_AGGREGATION_NONE = 0,
  VARIABLE_AGGREGATION_SUM = 1,
  VARIABLE_AGGREGATION_MEAN = 2,
  VARIABLE_AGGREGATION_ONLY_FIRST_REPLICA = 3;
@Name("tensorflow::VariableAggregation_INT_MIN_SENTINEL_DO_NOT_USE_") public static native @MemberGetter int VariableAggregation_INT_MIN_SENTINEL_DO_NOT_USE_();
public static final int
  VariableAggregation_INT_MIN_SENTINEL_DO_NOT_USE_ = VariableAggregation_INT_MIN_SENTINEL_DO_NOT_USE_();
@Name("tensorflow::VariableAggregation_INT_MAX_SENTINEL_DO_NOT_USE_") public static native @MemberGetter int VariableAggregation_INT_MAX_SENTINEL_DO_NOT_USE_();
public static final int
  VariableAggregation_INT_MAX_SENTINEL_DO_NOT_USE_ = VariableAggregation_INT_MAX_SENTINEL_DO_NOT_USE_();
@Namespace("tensorflow") public static native @Cast("bool") boolean VariableAggregation_IsValid(int value);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::VariableAggregation") int VariableAggregation_MIN();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::VariableAggregation") int VariableAggregation_MAX();
@Namespace("tensorflow") @MemberGetter public static native int VariableAggregation_ARRAYSIZE();

@Namespace("tensorflow") public static native @Cast("const google::protobuf::EnumDescriptor*") Pointer VariableAggregation_descriptor();
@Namespace("tensorflow") public static native @Cast("bool") boolean VariableAggregation_Parse(
    @StdString BytePointer name, @Cast("tensorflow::VariableAggregation*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean VariableAggregation_Parse(
    @StdString String name, @Cast("tensorflow::VariableAggregation*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean VariableAggregation_Parse(
    @StdString BytePointer name, @Cast("tensorflow::VariableAggregation*") int... value);
@Namespace("tensorflow") public static native @Cast("bool") boolean VariableAggregation_Parse(
    @StdString String name, @Cast("tensorflow::VariableAggregation*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean VariableAggregation_Parse(
    @StdString BytePointer name, @Cast("tensorflow::VariableAggregation*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean VariableAggregation_Parse(
    @StdString String name, @Cast("tensorflow::VariableAggregation*") int... value);
// Targeting ../VariableDef.java


// Targeting ../SaveSliceInfoDef.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// VariableDef

// string variable_name = 1;












// string initial_value_name = 6;












// string initializer_name = 2;












// string snapshot_name = 3;












// .tensorflow.SaveSliceInfoDef save_slice_info_def = 4;








// bool is_resource = 5;




// bool trainable = 7;




// .tensorflow.VariableSynchronization synchronization = 8;




// .tensorflow.VariableAggregation aggregation = 9;




// -------------------------------------------------------------------

// SaveSliceInfoDef

// string full_name = 1;












// repeated int64 full_shape = 2;








// repeated int64 var_offset = 3;








// repeated int64 var_shape = 4;








// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow



 /* namespace protobuf */
   /* namespace google */

// @@protoc_insertion_point(global_scope)

// #include <google/protobuf/port_undef.inc>
// #endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fvariable_2eproto


// Parsed from tensorflow/core/protobuf/trackable_object_graph.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/protobuf/trackable_object_graph.proto

// #ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2ftrackable_5fobject_5fgraph_2eproto
// #define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2ftrackable_5fobject_5fgraph_2eproto

// #include <limits>
// #include <string>

// #include <google/protobuf/port_def.inc>
// #if PROTOBUF_VERSION < 3008000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please update
// #error your headers.
// #endif
// #if 3008000 < PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/port_undef.inc>
// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/generated_message_reflection.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/unknown_field_set.h>
// @@protoc_insertion_point(includes)
// #include <google/protobuf/port_def.inc>
// #define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcore_2fprotobuf_2ftrackable_5fobject_5fgraph_2eproto
  // namespace internal
 /* namespace protobuf */
   /* namespace google */

// Internal implementation detail -- do not use these members.
  // namespace tensorflow





 /* namespace protobuf */
   /* namespace google */
// Targeting ../TrackableObjectGraph_TrackableObject_ObjectReference.java


// Targeting ../TrackableObjectGraph_TrackableObject_SerializedTensor.java


// Targeting ../TrackableObjectGraph_TrackableObject_SlotVariableReference.java


// Targeting ../TrackableObjectGraph_TrackableObject.java


// Targeting ../TrackableObjectGraph.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// TrackableObjectGraph_TrackableObject_ObjectReference

// int32 node_id = 1;




// string local_name = 2;












// -------------------------------------------------------------------

// TrackableObjectGraph_TrackableObject_SerializedTensor

// string name = 1;












// string full_name = 2;












// string checkpoint_key = 3;












// bool optional_restore = 4;




// -------------------------------------------------------------------

// TrackableObjectGraph_TrackableObject_SlotVariableReference

// int32 original_variable_node_id = 1;




// string slot_name = 2;












// int32 slot_variable_node_id = 3;




// -------------------------------------------------------------------

// TrackableObjectGraph_TrackableObject

// repeated .tensorflow.TrackableObjectGraph.TrackableObject.ObjectReference children = 1;








// repeated .tensorflow.TrackableObjectGraph.TrackableObject.SerializedTensor attributes = 2;








// repeated .tensorflow.TrackableObjectGraph.TrackableObject.SlotVariableReference slot_variables = 3;








// -------------------------------------------------------------------

// TrackableObjectGraph

// repeated .tensorflow.TrackableObjectGraph.TrackableObject nodes = 1;








// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #include <google/protobuf/port_undef.inc>
// #endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2ftrackable_5fobject_5fgraph_2eproto


// Parsed from tensorflow/core/protobuf/struct.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/protobuf/struct.proto

// #ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fstruct_2eproto
// #define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fstruct_2eproto

// #include <limits>
// #include <string>

// #include <google/protobuf/port_def.inc>
// #if PROTOBUF_VERSION < 3008000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please update
// #error your headers.
// #endif
// #if 3008000 < PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/port_undef.inc>
// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/generated_message_reflection.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/map.h>  // IWYU pragma: export
// #include <google/protobuf/map_entry.h>
// #include <google/protobuf/map_field_inl.h>
// #include <google/protobuf/generated_enum_reflection.h>
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/tensor_shape.pb.h"
// #include "tensorflow/core/framework/types.pb.h"
// @@protoc_insertion_point(includes)
// #include <google/protobuf/port_def.inc>
// #define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcore_2fprotobuf_2fstruct_2eproto
  // namespace internal
 /* namespace protobuf */
   /* namespace google */

// Internal implementation detail -- do not use these members.
  // namespace tensorflow










 /* namespace protobuf */
   /* namespace google */

/** enum tensorflow::TypeSpecProto_TypeSpecClass */
public static final int
  TypeSpecProto_TypeSpecClass_UNKNOWN = 0,
  TypeSpecProto_TypeSpecClass_SPARSE_TENSOR_SPEC = 1,
  TypeSpecProto_TypeSpecClass_INDEXED_SLICES_SPEC = 2,
  TypeSpecProto_TypeSpecClass_RAGGED_TENSOR_SPEC = 3,
  TypeSpecProto_TypeSpecClass_TENSOR_ARRAY_SPEC = 4,
  TypeSpecProto_TypeSpecClass_DATA_DATASET_SPEC = 5,
  TypeSpecProto_TypeSpecClass_DATA_ITERATOR_SPEC = 6,
  TypeSpecProto_TypeSpecClass_OPTIONAL_SPEC = 7,
  TypeSpecProto_TypeSpecClass_PER_REPLICA_SPEC = 8;
@Name("tensorflow::TypeSpecProto_TypeSpecClass_TypeSpecProto_TypeSpecClass_INT_MIN_SENTINEL_DO_NOT_USE_") public static native @MemberGetter int TypeSpecProto_TypeSpecClass_TypeSpecProto_TypeSpecClass_INT_MIN_SENTINEL_DO_NOT_USE_();
public static final int
  TypeSpecProto_TypeSpecClass_TypeSpecProto_TypeSpecClass_INT_MIN_SENTINEL_DO_NOT_USE_ = TypeSpecProto_TypeSpecClass_TypeSpecProto_TypeSpecClass_INT_MIN_SENTINEL_DO_NOT_USE_();
@Name("tensorflow::TypeSpecProto_TypeSpecClass_TypeSpecProto_TypeSpecClass_INT_MAX_SENTINEL_DO_NOT_USE_") public static native @MemberGetter int TypeSpecProto_TypeSpecClass_TypeSpecProto_TypeSpecClass_INT_MAX_SENTINEL_DO_NOT_USE_();
public static final int
  TypeSpecProto_TypeSpecClass_TypeSpecProto_TypeSpecClass_INT_MAX_SENTINEL_DO_NOT_USE_ = TypeSpecProto_TypeSpecClass_TypeSpecProto_TypeSpecClass_INT_MAX_SENTINEL_DO_NOT_USE_();
@Namespace("tensorflow") public static native @Cast("bool") boolean TypeSpecProto_TypeSpecClass_IsValid(int value);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::TypeSpecProto_TypeSpecClass") int TypeSpecProto_TypeSpecClass_TypeSpecClass_MIN();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::TypeSpecProto_TypeSpecClass") int TypeSpecProto_TypeSpecClass_TypeSpecClass_MAX();
@Namespace("tensorflow") @MemberGetter public static native int TypeSpecProto_TypeSpecClass_TypeSpecClass_ARRAYSIZE();

@Namespace("tensorflow") public static native @Cast("const google::protobuf::EnumDescriptor*") Pointer TypeSpecProto_TypeSpecClass_descriptor();
@Namespace("tensorflow") public static native @Cast("bool") boolean TypeSpecProto_TypeSpecClass_Parse(
    @StdString BytePointer name, @Cast("tensorflow::TypeSpecProto_TypeSpecClass*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean TypeSpecProto_TypeSpecClass_Parse(
    @StdString String name, @Cast("tensorflow::TypeSpecProto_TypeSpecClass*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean TypeSpecProto_TypeSpecClass_Parse(
    @StdString BytePointer name, @Cast("tensorflow::TypeSpecProto_TypeSpecClass*") int... value);
@Namespace("tensorflow") public static native @Cast("bool") boolean TypeSpecProto_TypeSpecClass_Parse(
    @StdString String name, @Cast("tensorflow::TypeSpecProto_TypeSpecClass*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean TypeSpecProto_TypeSpecClass_Parse(
    @StdString BytePointer name, @Cast("tensorflow::TypeSpecProto_TypeSpecClass*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean TypeSpecProto_TypeSpecClass_Parse(
    @StdString String name, @Cast("tensorflow::TypeSpecProto_TypeSpecClass*") int... value);
// Targeting ../StructuredValue.java


// Targeting ../NoneValue.java


// Targeting ../ListValue.java


// Targeting ../TupleValue.java


// -------------------------------------------------------------------
// Targeting ../DictValue.java


// Targeting ../PairValue.java


// Targeting ../NamedTupleValue.java


// Targeting ../TensorSpecProto.java


// Targeting ../TypeSpecProto.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// StructuredValue

// .tensorflow.NoneValue none_value = 1;







// double float64_value = 11;






// sint64 int64_value = 12;






// string string_value = 13;












// bool bool_value = 14;






// .tensorflow.TensorShapeProto tensor_shape_value = 31;






// .tensorflow.DataType tensor_dtype_value = 32;






// .tensorflow.TensorSpecProto tensor_spec_value = 33;







// .tensorflow.TypeSpecProto type_spec_value = 34;







// .tensorflow.ListValue list_value = 51;







// .tensorflow.TupleValue tuple_value = 52;







// .tensorflow.DictValue dict_value = 53;







// .tensorflow.NamedTupleValue named_tuple_value = 54;










// -------------------------------------------------------------------

// NoneValue

// -------------------------------------------------------------------

// ListValue

// repeated .tensorflow.StructuredValue values = 1;








// -------------------------------------------------------------------

// TupleValue

// repeated .tensorflow.StructuredValue values = 1;








// -------------------------------------------------------------------

// -------------------------------------------------------------------

// DictValue

// map<string, .tensorflow.StructuredValue> fields = 1;





// -------------------------------------------------------------------

// PairValue

// string key = 1;










// .tensorflow.StructuredValue value = 2;







// -------------------------------------------------------------------

// NamedTupleValue

// string name = 1;










// repeated .tensorflow.PairValue values = 2;








// -------------------------------------------------------------------

// TensorSpecProto

// string name = 1;










// .tensorflow.TensorShapeProto shape = 2;






// .tensorflow.DataType dtype = 3;




// -------------------------------------------------------------------

// TypeSpecProto

// .tensorflow.TypeSpecProto.TypeSpecClass type_spec_class = 1;




// .tensorflow.StructuredValue type_state = 2;







// string type_spec_class_name = 3;










// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow


 /* namespace protobuf */
   /* namespace google */

// @@protoc_insertion_point(global_scope)

// #include <google/protobuf/port_undef.inc>
// #endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fstruct_2eproto


// Parsed from tensorflow/core/protobuf/saved_object_graph.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/protobuf/saved_object_graph.proto

// #ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fsaved_5fobject_5fgraph_2eproto
// #define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fsaved_5fobject_5fgraph_2eproto

// #include <limits>
// #include <string>

// #include <google/protobuf/port_def.inc>
// #if PROTOBUF_VERSION < 3008000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please update
// #error your headers.
// #endif
// #if 3008000 < PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/port_undef.inc>
// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/generated_message_reflection.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/map.h>  // IWYU pragma: export
// #include <google/protobuf/map_entry.h>
// #include <google/protobuf/map_field_inl.h>
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/protobuf/trackable_object_graph.pb.h"
// #include "tensorflow/core/protobuf/struct.pb.h"
// #include "tensorflow/core/framework/tensor_shape.pb.h"
// #include "tensorflow/core/framework/types.pb.h"
// #include "tensorflow/core/framework/versions.pb.h"
// #include "tensorflow/core/framework/variable.pb.h"
// @@protoc_insertion_point(includes)
// #include <google/protobuf/port_def.inc>
// #define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcore_2fprotobuf_2fsaved_5fobject_5fgraph_2eproto
  // namespace internal
 /* namespace protobuf */
   /* namespace google */

// Internal implementation detail -- do not use these members.
  // namespace tensorflow












 /* namespace protobuf */
   /* namespace google */

// ===================================================================
// Targeting ../SavedObjectGraph.java


// Targeting ../SavedObject.java


// Targeting ../SavedUserObject.java


// Targeting ../SavedAsset.java


// Targeting ../SavedFunction.java


// Targeting ../SavedConcreteFunction.java


// Targeting ../SavedBareConcreteFunction.java


// Targeting ../SavedConstant.java


// Targeting ../SavedVariable.java


// Targeting ../FunctionSpec.java


// Targeting ../SavedResource.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// -------------------------------------------------------------------

// SavedObjectGraph

// repeated .tensorflow.SavedObject nodes = 1;








// map<string, .tensorflow.SavedConcreteFunction> concrete_functions = 2;





// -------------------------------------------------------------------

// SavedObject

// repeated .tensorflow.TrackableObjectGraph.TrackableObject.ObjectReference children = 1;







// repeated .tensorflow.TrackableObjectGraph.TrackableObject.SlotVariableReference slot_variables = 3;







// .tensorflow.SavedUserObject user_object = 4;









// .tensorflow.SavedAsset asset = 5;









// .tensorflow.SavedFunction function = 6;









// .tensorflow.SavedVariable variable = 7;









// .tensorflow.SavedBareConcreteFunction bare_concrete_function = 8;









// .tensorflow.SavedConstant constant = 9;









// .tensorflow.SavedResource resource = 10;












// -------------------------------------------------------------------

// SavedUserObject

// string identifier = 1;












// .tensorflow.VersionDef version = 2;







// string metadata = 3;












// -------------------------------------------------------------------

// SavedAsset

// int32 asset_file_def_index = 1;




// -------------------------------------------------------------------

// SavedFunction

// repeated string concrete_functions = 1;
















// .tensorflow.FunctionSpec function_spec = 2;








// -------------------------------------------------------------------

// SavedConcreteFunction

// repeated int32 bound_inputs = 2;








// .tensorflow.StructuredValue canonicalized_input_signature = 3;







// .tensorflow.StructuredValue output_signature = 4;







// -------------------------------------------------------------------

// SavedBareConcreteFunction

// string concrete_function_name = 1;












// repeated string argument_keywords = 2;
















// int64 allowed_positional_arguments = 3;




// -------------------------------------------------------------------

// SavedConstant

// string operation = 1;












// -------------------------------------------------------------------

// SavedVariable

// .tensorflow.DataType dtype = 1;




// .tensorflow.TensorShapeProto shape = 2;







// bool trainable = 3;




// .tensorflow.VariableSynchronization synchronization = 4;




// .tensorflow.VariableAggregation aggregation = 5;




// string name = 6;












// -------------------------------------------------------------------

// FunctionSpec

// .tensorflow.StructuredValue fullargspec = 1;







// bool is_method = 2;




// .tensorflow.StructuredValue input_signature = 5;







// -------------------------------------------------------------------

// SavedResource

// string device = 1;












// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #include <google/protobuf/port_undef.inc>
// #endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fsaved_5fobject_5fgraph_2eproto


// Parsed from tensorflow/core/protobuf/saver.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/protobuf/saver.proto

// #ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fsaver_2eproto
// #define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fsaver_2eproto

// #include <limits>
// #include <string>

// #include <google/protobuf/port_def.inc>
// #if PROTOBUF_VERSION < 3008000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please update
// #error your headers.
// #endif
// #if 3008000 < PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/port_undef.inc>
// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/generated_message_reflection.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/generated_enum_reflection.h>
// #include <google/protobuf/unknown_field_set.h>
// @@protoc_insertion_point(includes)
// #include <google/protobuf/port_def.inc>
// #define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcore_2fprotobuf_2fsaver_2eproto
  // namespace internal
 /* namespace protobuf */
   /* namespace google */

// Internal implementation detail -- do not use these members.
  // namespace tensorflow

 /* namespace protobuf */
   /* namespace google */

/** enum tensorflow::SaverDef_CheckpointFormatVersion */
public static final int
  SaverDef_CheckpointFormatVersion_LEGACY = 0,
  SaverDef_CheckpointFormatVersion_V1 = 1,
  SaverDef_CheckpointFormatVersion_V2 = 2;
@Name("tensorflow::SaverDef_CheckpointFormatVersion_SaverDef_CheckpointFormatVersion_INT_MIN_SENTINEL_DO_NOT_USE_") public static native @MemberGetter int SaverDef_CheckpointFormatVersion_SaverDef_CheckpointFormatVersion_INT_MIN_SENTINEL_DO_NOT_USE_();
public static final int
  SaverDef_CheckpointFormatVersion_SaverDef_CheckpointFormatVersion_INT_MIN_SENTINEL_DO_NOT_USE_ = SaverDef_CheckpointFormatVersion_SaverDef_CheckpointFormatVersion_INT_MIN_SENTINEL_DO_NOT_USE_();
@Name("tensorflow::SaverDef_CheckpointFormatVersion_SaverDef_CheckpointFormatVersion_INT_MAX_SENTINEL_DO_NOT_USE_") public static native @MemberGetter int SaverDef_CheckpointFormatVersion_SaverDef_CheckpointFormatVersion_INT_MAX_SENTINEL_DO_NOT_USE_();
public static final int
  SaverDef_CheckpointFormatVersion_SaverDef_CheckpointFormatVersion_INT_MAX_SENTINEL_DO_NOT_USE_ = SaverDef_CheckpointFormatVersion_SaverDef_CheckpointFormatVersion_INT_MAX_SENTINEL_DO_NOT_USE_();
@Namespace("tensorflow") public static native @Cast("bool") boolean SaverDef_CheckpointFormatVersion_IsValid(int value);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::SaverDef_CheckpointFormatVersion") int SaverDef_CheckpointFormatVersion_CheckpointFormatVersion_MIN();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::SaverDef_CheckpointFormatVersion") int SaverDef_CheckpointFormatVersion_CheckpointFormatVersion_MAX();
@Namespace("tensorflow") @MemberGetter public static native int SaverDef_CheckpointFormatVersion_CheckpointFormatVersion_ARRAYSIZE();

@Namespace("tensorflow") public static native @Cast("const google::protobuf::EnumDescriptor*") Pointer SaverDef_CheckpointFormatVersion_descriptor();
@Namespace("tensorflow") public static native @Cast("bool") boolean SaverDef_CheckpointFormatVersion_Parse(
    @StdString BytePointer name, @Cast("tensorflow::SaverDef_CheckpointFormatVersion*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean SaverDef_CheckpointFormatVersion_Parse(
    @StdString String name, @Cast("tensorflow::SaverDef_CheckpointFormatVersion*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean SaverDef_CheckpointFormatVersion_Parse(
    @StdString BytePointer name, @Cast("tensorflow::SaverDef_CheckpointFormatVersion*") int... value);
@Namespace("tensorflow") public static native @Cast("bool") boolean SaverDef_CheckpointFormatVersion_Parse(
    @StdString String name, @Cast("tensorflow::SaverDef_CheckpointFormatVersion*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean SaverDef_CheckpointFormatVersion_Parse(
    @StdString BytePointer name, @Cast("tensorflow::SaverDef_CheckpointFormatVersion*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean SaverDef_CheckpointFormatVersion_Parse(
    @StdString String name, @Cast("tensorflow::SaverDef_CheckpointFormatVersion*") int... value);
// Targeting ../SaverDef.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// SaverDef

// string filename_tensor_name = 1;












// string save_tensor_name = 2;












// string restore_op_name = 3;












// int32 max_to_keep = 4;




// bool sharded = 5;




// float keep_checkpoint_every_n_hours = 6;




// .tensorflow.SaverDef.CheckpointFormatVersion version = 7;




// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__

// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow


 /* namespace protobuf */
   /* namespace google */

// @@protoc_insertion_point(global_scope)

// #include <google/protobuf/port_undef.inc>
// #endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fsaver_2eproto


// Parsed from tensorflow/core/protobuf/meta_graph.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/protobuf/meta_graph.proto

// #ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fmeta_5fgraph_2eproto
// #define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fmeta_5fgraph_2eproto

// #include <limits>
// #include <string>

// #include <google/protobuf/port_def.inc>
// #if PROTOBUF_VERSION < 3008000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please update
// #error your headers.
// #endif
// #if 3008000 < PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/port_undef.inc>
// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/generated_message_reflection.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/map.h>  // IWYU pragma: export
// #include <google/protobuf/map_entry.h>
// #include <google/protobuf/map_field_inl.h>
// #include <google/protobuf/unknown_field_set.h>
// #include <google/protobuf/any.pb.h>
// #include "tensorflow/core/framework/graph.pb.h"
// #include "tensorflow/core/framework/op_def.pb.h"
// #include "tensorflow/core/framework/tensor_shape.pb.h"
// #include "tensorflow/core/framework/types.pb.h"
// #include "tensorflow/core/protobuf/saved_object_graph.pb.h"
// #include "tensorflow/core/protobuf/saver.pb.h"
// #include "tensorflow/core/protobuf/struct.pb.h"
// @@protoc_insertion_point(includes)
// #include <google/protobuf/port_def.inc>
// #define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcore_2fprotobuf_2fmeta_5fgraph_2eproto
  // namespace internal
 /* namespace protobuf */
   /* namespace google */

// Internal implementation detail -- do not use these members.
  // namespace tensorflow

















 /* namespace protobuf */
   /* namespace google */
// Targeting ../MetaGraphDef_MetaInfoDef.java


// -------------------------------------------------------------------

// -------------------------------------------------------------------
// Targeting ../MetaGraphDef.java


// Targeting ../CollectionDef_NodeList.java


// Targeting ../CollectionDef_BytesList.java


// Targeting ../CollectionDef_Int64List.java


// Targeting ../CollectionDef_FloatList.java


// Targeting ../CollectionDef_AnyList.java


// Targeting ../CollectionDef.java


// Targeting ../TensorInfo_CooSparse.java


// Targeting ../TensorInfo_CompositeTensor.java


// Targeting ../TensorInfo.java


// -------------------------------------------------------------------

// -------------------------------------------------------------------
// Targeting ../SignatureDef.java


// Targeting ../AssetFileDef.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// MetaGraphDef_MetaInfoDef

// string meta_graph_version = 1;












// .tensorflow.OpList stripped_op_list = 2;







// .google.protobuf.Any any_info = 3;







// repeated string tags = 4;
















// string tensorflow_version = 5;












// string tensorflow_git_version = 6;












// bool stripped_default_attrs = 7;




// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// MetaGraphDef

// .tensorflow.MetaGraphDef.MetaInfoDef meta_info_def = 1;








// .tensorflow.GraphDef graph_def = 2;







// .tensorflow.SaverDef saver_def = 3;







// map<string, .tensorflow.CollectionDef> collection_def = 4;





// map<string, .tensorflow.SignatureDef> signature_def = 5;





// repeated .tensorflow.AssetFileDef asset_file_def = 6;








// .tensorflow.SavedObjectGraph object_graph_def = 7;







// -------------------------------------------------------------------

// CollectionDef_NodeList

// repeated string value = 1;
















// -------------------------------------------------------------------

// CollectionDef_BytesList

// repeated bytes value = 1;
















// -------------------------------------------------------------------

// CollectionDef_Int64List

// repeated int64 value = 1 [packed = true];








// -------------------------------------------------------------------

// CollectionDef_FloatList

// repeated float value = 1 [packed = true];








// -------------------------------------------------------------------

// CollectionDef_AnyList

// repeated .google.protobuf.Any value = 1;







// -------------------------------------------------------------------

// CollectionDef

// .tensorflow.CollectionDef.NodeList node_list = 1;









// .tensorflow.CollectionDef.BytesList bytes_list = 2;









// .tensorflow.CollectionDef.Int64List int64_list = 3;









// .tensorflow.CollectionDef.FloatList float_list = 4;









// .tensorflow.CollectionDef.AnyList any_list = 5;












// -------------------------------------------------------------------

// TensorInfo_CooSparse

// string values_tensor_name = 1;












// string indices_tensor_name = 2;












// string dense_shape_tensor_name = 3;












// -------------------------------------------------------------------

// TensorInfo_CompositeTensor

// .tensorflow.TypeSpecProto type_spec = 1;







// repeated .tensorflow.TensorInfo components = 2;








// -------------------------------------------------------------------

// TensorInfo

// string name = 1;














// .tensorflow.TensorInfo.CooSparse coo_sparse = 4;









// .tensorflow.TensorInfo.CompositeTensor composite_tensor = 5;









// .tensorflow.DataType dtype = 2;




// .tensorflow.TensorShapeProto tensor_shape = 3;










// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// SignatureDef

// map<string, .tensorflow.TensorInfo> inputs = 1;





// map<string, .tensorflow.TensorInfo> outputs = 2;





// string method_name = 3;












// -------------------------------------------------------------------

// AssetFileDef

// .tensorflow.TensorInfo tensor_info = 1;








// string filename = 2;












// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #include <google/protobuf/port_undef.inc>
// #endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fmeta_5fgraph_2eproto


// Parsed from tensorflow/cc/framework/scope.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CC_FRAMEWORK_SCOPE_H_
// #define TENSORFLOW_CC_FRAMEWORK_SCOPE_H_

// #include <memory>
// #include <string>
// #include <unordered_map>
// #include <unordered_set>
// #include <vector>

// #include "absl/strings/str_cat.h"
// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/core/graph/graph_constructor.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../Scope.java



/** A helper struct to hold the scopes that would be used by a function
 *  constructing a composite op. */

// Creates a node of the given operation, with the given inputs, and assigns the
// result to output. This does not support the ability to add additional
// attributes.
/** \} */

  // namespace tensorflow

// #endif  // TENSORFLOW_CC_FRAMEWORK_SCOPE_H_


// Parsed from tensorflow/cc/framework/ops.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CC_FRAMEWORK_OPS_H_
// #define TENSORFLOW_CC_FRAMEWORK_OPS_H_

// #include <type_traits>

// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor.pb.h"
// #include "tensorflow/core/graph/graph.h"
// #include "tensorflow/core/lib/hash/hash.h"
// #include "tensorflow/core/lib/strings/strcat.h"

/** \defgroup core Core Tensorflow API */
// Targeting ../Operation.java


// Targeting ../Output.java


// Targeting ../OutputHash.java


// Targeting ../Input.java



/** A type for representing the output of ops that produce more than one output,
 *  or a list of tensors. */
// Targeting ../InputList.java



/** \} */

  // namespace tensorflow

// #endif  // TENSORFLOW_CC_FRAMEWORK_OPS_H_


// Parsed from tensorflow/core/framework/op_gen_lib.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_OP_GEN_LIB_H_
// #define TENSORFLOW_CORE_FRAMEWORK_OP_GEN_LIB_H_

// #include <string>
// #include <unordered_map>
// #include "tensorflow/core/framework/api_def.pb.h"
// #include "tensorflow/core/framework/op_def.pb.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/platform/env.h"

// Forward declare protos so their symbols can be removed from .so exports

@Namespace("tensorflow") public static native @StdString BytePointer Spaces(int n);

// Wrap prefix + str to be at most width characters, indenting every line
// after the first by prefix.size() spaces.  Intended use case is something
// like prefix = "  Foo(" and str is a list of arguments (terminated by a ")").
// TODO(josh11b): Option to wrap on ", " instead of " " when possible.
@Namespace("tensorflow") public static native @StdString BytePointer WordWrap(@StringPiece BytePointer prefix, @StringPiece BytePointer str, int width);
@Namespace("tensorflow") public static native @StdString String WordWrap(@StringPiece String prefix, @StringPiece String str, int width);

// Looks for an "=" at the beginning of *description.  If found, strips it off
// (and any following spaces) from *description and return true.  Otherwise
// returns false.
@Namespace("tensorflow") public static native @Cast("bool") boolean ConsumeEquals(@StringPiece @Cast({"char*", "StringPiece*"}) BytePointer description);

// Convert text-serialized protobufs to/from multiline format.
@Namespace("tensorflow") public static native @StdString BytePointer PBTxtToMultiline(@StringPiece BytePointer pbtxt,
                        @Const @ByRef StringVector multi_line_fields);
@Namespace("tensorflow") public static native @StdString String PBTxtToMultiline(@StringPiece String pbtxt,
                        @Const @ByRef StringVector multi_line_fields);
@Namespace("tensorflow") public static native @StdString BytePointer PBTxtFromMultiline(@StringPiece BytePointer multiline_pbtxt);
@Namespace("tensorflow") public static native @StdString String PBTxtFromMultiline(@StringPiece String multiline_pbtxt);
// Targeting ../ApiDefMap.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_OP_GEN_LIB_H_


// Parsed from tensorflow/cc/framework/gradients.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CC_FRAMEWORK_GRADIENTS_H_
// #define TENSORFLOW_CC_FRAMEWORK_GRADIENTS_H_

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"

/** NOTE: This API is a work in progress and will likely be changing frequently.
 * 
 *  Given initial gradients 'grad_inputs' (which represent the symbolic partial
 *  derivatives of some loss function 'L' w.r.t 'outputs'), adds gradient nodes
 *  to the graph associated with 'scope', which compute (and return in
 *  'grad_outputs') the symbolic partial derivatives of 'L' w.r.t 'inputs'. */
@Namespace("tensorflow") public static native @ByVal Status AddSymbolicGradients(@Const @ByRef Scope scope,
                            @Const @ByRef OutputVector outputs,
                            @Const @ByRef OutputVector inputs,
                            @Const @ByRef OutputVector grad_inputs,
                            OutputVector grad_outputs);

// Same as above, but uses 'OnesLike' for all shapes in
// 'outputs' as grad_inputs.
@Namespace("tensorflow") public static native @ByVal Status AddSymbolicGradients(@Const @ByRef Scope scope,
                            @Const @ByRef OutputVector outputs,
                            @Const @ByRef OutputVector inputs,
                            OutputVector grad_outputs);

/** Returns a sentinel Output that represents 'no gradient' (i.e. no gradient
 *  flows along some graph edge during backpropagation).
 *  Can be returned in 'grad_outputs' by an invocation of 'AddSymbolicGradients'
 *  (note that gradient flow through an Output can be stopped through the use of
 *  the StopGradient node). */
@Namespace("tensorflow") public static native @ByVal Output NoGradient();

  // namespace tensorflow

// #endif  // TENSORFLOW_CC_FRAMEWORK_GRADIENTS_H_


// Parsed from tensorflow/cc/saved_model/loader.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

/** SavedModel loading functions and SavedModelBundle struct. */

// #ifndef TENSORFLOW_CC_SAVED_MODEL_LOADER_H_
// #define TENSORFLOW_CC_SAVED_MODEL_LOADER_H_

// #include <string>
// #include <unordered_set>

// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/protobuf/meta_graph.pb.h"
// #include "tensorflow/core/public/session.h"
// Targeting ../SavedModelBundle.java



/** Loads a SavedModel from the specified export directory. The meta graph def
 *  to be loaded is identified by the supplied tags, corresponding exactly to
 *  the set of tags used at SavedModel build time. Returns a SavedModel bundle
 *  with a session and the requested meta graph def, if found. */
@Namespace("tensorflow") public static native @ByVal Status LoadSavedModel(@Const @ByRef SessionOptions session_options,
                      @Const @ByRef RunOptions run_options, @StdString BytePointer export_dir,
                      @Const @ByRef StringUnorderedSet tags,
                      SavedModelBundle bundle);
@Namespace("tensorflow") public static native @ByVal Status LoadSavedModel(@Const @ByRef SessionOptions session_options,
                      @Const @ByRef RunOptions run_options, @StdString String export_dir,
                      @Const @ByRef StringUnorderedSet tags,
                      SavedModelBundle bundle);

/** Checks whether the provided directory could contain a SavedModel. Note that
 *  the method does not load any data by itself. If the method returns {@code false},
 *  the export directory definitely does not contain a SavedModel. If the method
 *  returns {@code true}, the export directory may contain a SavedModel but provides
 *  no guarantee that it can be loaded. */
@Namespace("tensorflow") public static native @Cast("bool") boolean MaybeSavedModelDirectory(@StdString BytePointer export_dir);
@Namespace("tensorflow") public static native @Cast("bool") boolean MaybeSavedModelDirectory(@StdString String export_dir);

  // namespace tensorflow

// #endif  // TENSORFLOW_CC_SAVED_MODEL_LOADER_H_


// Parsed from tensorflow/cc/saved_model/tag_constants.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CC_SAVED_MODEL_TAG_CONSTANTS_H_
// #define TENSORFLOW_CC_SAVED_MODEL_TAG_CONSTANTS_H_

/** Tag for the {@code gpu} graph. */
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char") byte kSavedModelTagGpu(int i);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer kSavedModelTagGpu();

/** Tag for the {@code tpu} graph. */
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char") byte kSavedModelTagTpu(int i);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer kSavedModelTagTpu();

/** Tag for the {@code serving} graph. */
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char") byte kSavedModelTagServe(int i);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer kSavedModelTagServe();

/** Tag for the {@code training} graph. */
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char") byte kSavedModelTagTrain(int i);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer kSavedModelTagTrain();

  // namespace tensorflow

// #endif  // TENSORFLOW_CC_SAVED_MODEL_TAG_CONSTANTS_H_


// Parsed from tensorflow/cc/saved_model/signature_constants.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CC_SAVED_MODEL_SIGNATURE_CONSTANTS_H_
// #define TENSORFLOW_CC_SAVED_MODEL_SIGNATURE_CONSTANTS_H_

/** Key in the signature def map for {@code default} serving signatures. The default
 *  signature is used in inference requests where a specific signature was not
 *  specified. */
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char") byte kDefaultServingSignatureDefKey(int i);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer kDefaultServingSignatureDefKey();

////////////////////////////////////////////////////////////////////////////////
/** Classification API constants.
 <p>
 *  Classification inputs. */
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char") byte kClassifyInputs(int i);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer kClassifyInputs();

/** Classification method name used in a SignatureDef. */
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char") byte kClassifyMethodName(int i);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer kClassifyMethodName();

/** Classification classes output. */
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char") byte kClassifyOutputClasses(int i);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer kClassifyOutputClasses();

/** Classification scores output. */
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char") byte kClassifyOutputScores(int i);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer kClassifyOutputScores();

////////////////////////////////////////////////////////////////////////////////
/** Predict API constants.
 <p>
 *  Predict inputs. */
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char") byte kPredictInputs(int i);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer kPredictInputs();

/** Predict method name used in a SignatureDef. */
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char") byte kPredictMethodName(int i);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer kPredictMethodName();

/** Predict outputs. */
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char") byte kPredictOutputs(int i);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer kPredictOutputs();

////////////////////////////////////////////////////////////////////////////////
/** Regression API constants.
 <p>
 *  Regression inputs. */
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char") byte kRegressInputs(int i);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer kRegressInputs();

/** Regression method name used in a SignatureDef. */
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char") byte kRegressMethodName(int i);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer kRegressMethodName();

/** Regression outputs. */
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char") byte kRegressOutputs(int i);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer kRegressOutputs();

////////////////////////////////////////////////////////////////////////////////

  // namespace tensorflow

// #endif  // TENSORFLOW_CC_SAVED_MODEL_SIGNATURE_CONSTANTS_H_


// Parsed from tensorflow/core/framework/collective.h

/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
// #ifndef TENSORFLOW_CORE_FRAMEWORK_COLLECTIVE_H_
// #define TENSORFLOW_CORE_FRAMEWORK_COLLECTIVE_H_

// #include <string>
// #include <vector>

// #include "tensorflow/core/framework/device_attributes.pb.h"
// #include "tensorflow/core/framework/device_base.h"
// #include "tensorflow/core/framework/op_kernel.h"
// #include "tensorflow/core/lib/core/refcount.h"
// #include "tensorflow/core/lib/core/status.h"
// Targeting ../BufRendezvous.java



// Types of supported collective operations.
/** enum tensorflow::CollectiveType */
public static final int
  REDUCTION_COLLECTIVE = 0,
  BROADCAST_COLLECTIVE = 1,
  GATHER_COLLECTIVE = 2,
  UNDEFINED_COLLECTIVE = 3;
// Targeting ../CollGroupRuntimeDetails.java


// Targeting ../CollGroupParams.java


// Targeting ../CollImplDetails.java


// Targeting ../CollInstanceParams.java


// Targeting ../CollTaskParams.java


// Targeting ../CollectiveParams.java


// Targeting ../DeviceResolverInterface.java


// Targeting ../ParamResolverInterface.java


// Targeting ../StepSequenceInterface.java


// Targeting ../CollectiveExecutorMgrInterface.java


// Targeting ../PeerAccessInterface.java


// Targeting ../CollectiveExecutor.java


// Targeting ../CollectiveRemoteAccess.java


// Targeting ../PerStepCollectiveRemoteAccess.java


// Targeting ../CollectiveContext.java


// Targeting ../CollectiveImplementationInterface.java


// Targeting ../CollectiveRegistry.java


// Targeting ../CollectiveRegistration.java



// #define REGISTER_COLLECTIVE(name, implementation)
//   static CollectiveRegistration register_##name##_collective(
//       #name, []() { return new implementation; });

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_COLLECTIVE_H_


// Parsed from tensorflow/core/platform/fingerprint.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_PLATFORM_FINGERPRINT_H_
// #define TENSORFLOW_CORE_PLATFORM_FINGERPRINT_H_

// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/platform/types.h"

// The following line is used by copybara to set or unset the USE_OSS_FARMHASH
// preprocessor symbol as needed. Please do not remove.
// #define USE_OSS_FARMHASH

// #ifdef USE_OSS_FARMHASH
// #else
// #include "util/hash/farmhash_fingerprint.h"
// Targeting ../Fprint128.java



@Namespace("tensorflow") public static native @Cast("bool") @Name("operator ==") boolean equals(@Const @ByRef Fprint128 lhs, @Const @ByRef Fprint128 rhs);
// Targeting ../Fprint128Hasher.java


// Mixes some of the bits that got propagated to the high bits back into the
// low bits.
@Namespace("tensorflow::internal") public static native @Cast("tensorflow::uint64") long ShiftMix(@Cast("const tensorflow::uint64") long val);
  // namespace internal

// This concatenates two 64-bit fingerprints. It is a convenience function to
// get a fingerprint for a combination of already fingerprinted components. For
// example this code is used to concatenate the hashes from each of the features
// on sparse crosses.
//
// One shouldn't expect FingerprintCat64(Fingerprint64(x), Fingerprint64(y))
// to indicate anything about FingerprintCat64(StrCat(x, y)). This operation
// is not commutative.
//
// From a security standpoint, we don't encourage this pattern to be used
// for everything as it is vulnerable to length-extension attacks and it
// is easier to compute multicollisions.
@Namespace("tensorflow") public static native @Cast("tensorflow::uint64") long FingerprintCat64(@Cast("const tensorflow::uint64") long fp1, @Cast("const tensorflow::uint64") long fp2);

// This is a portable fingerprint interface for strings that will never change.
// However, it is not suitable for cryptography.
@Namespace("tensorflow") public static native @Cast("tensorflow::uint64") long Fingerprint64(@StringPiece BytePointer s);
@Namespace("tensorflow") public static native @Cast("tensorflow::uint64") long Fingerprint64(@StringPiece String s);

// 128-bit variant of Fingerprint64 above (same properties and caveats apply).
@Namespace("tensorflow") public static native @ByVal Fprint128 Fingerprint128(@StringPiece BytePointer s);
@Namespace("tensorflow") public static native @ByVal Fprint128 Fingerprint128(@StringPiece String s);

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_PLATFORM_FINGERPRINT_H_


// Parsed from tensorflow/core/distributed_runtime/server_lib.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_DISTRIBUTED_RUNTIME_SERVER_LIB_H_
// #define TENSORFLOW_CORE_DISTRIBUTED_RUNTIME_SERVER_LIB_H_

// #include <memory>

// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/protobuf/tensorflow_server.pb.h"
// Targeting ../ServerInterface.java


// Targeting ../ServerFactory.java



// Creates a server based on the given `server_def`, and stores it in
// `*out_server`. Returns OK on success, otherwise returns an error.
@Namespace("tensorflow") public static native @ByVal Status NewServer(@Const @ByRef ServerDef server_def,
                 @UniquePtr ServerInterface out_server);

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_DISTRIBUTED_RUNTIME_SERVER_LIB_H_


// Parsed from tensorflow/core/distributed_runtime/eager/eager_client.h

/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_DISTRIBUTED_RUNTIME_EAGER_EAGER_CLIENT_H_
// #define TENSORFLOW_CORE_DISTRIBUTED_RUNTIME_EAGER_EAGER_CLIENT_H_

// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/platform/env.h"
// #include "tensorflow/core/protobuf/eager_service.pb.h"
// Targeting ../EagerClient.java


// Targeting ../EagerClientCache.java



  // namespace eager
  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_DISTRIBUTED_RUNTIME_EAGER_EAGER_CLIENT_H_


// Parsed from tensorflow/core/common_runtime/eager/tensor_handle_data.h

/* Copyright 2019 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
// #ifndef TENSORFLOW_CORE_COMMON_RUNTIME_EAGER_TENSOR_HANDLE_DATA_H_
// #define TENSORFLOW_CORE_COMMON_RUNTIME_EAGER_TENSOR_HANDLE_DATA_H_

// #include "tensorflow/core/common_runtime/eager/context.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/lib/core/status.h"
// Targeting ../TensorHandleData.java


// Targeting ../LocalTensorHandleData.java


// Targeting ../AsyncLocalTensorHandleData.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_COMMON_RUNTIME_EAGER_TENSOR_HANDLE_DATA_H_


// Parsed from tensorflow/core/distributed_runtime/eager/remote_tensor_handle_data.h

/* Copyright 2019 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
// #ifndef TENSORFLOW_CORE_DISTRIBUTED_RUNTIME_EAGER_REMOTE_TENSOR_HANDLE_DATA_H_
// #define TENSORFLOW_CORE_DISTRIBUTED_RUNTIME_EAGER_REMOTE_TENSOR_HANDLE_DATA_H_

// #include "tensorflow/core/common_runtime/eager/tensor_handle_data.h"
// #include "tensorflow/core/distributed_runtime/eager/eager_client.h"
// Targeting ../RemoteTensorHandleData.java


// Targeting ../UnshapedRemoteTensorHandleData.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_DISTRIBUTED_RUNTIME_EAGER_REMOTE_TENSOR_HANDLE_DATA_H_


// Parsed from tensorflow/core/protobuf/eager_service.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/protobuf/eager_service.proto

// #ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto
// #define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto

// #include <limits>
// #include <string>

// #include <google/protobuf/port_def.inc>
// #if PROTOBUF_VERSION < 3008000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please update
// #error your headers.
// #endif
// #if 3008000 < PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/port_undef.inc>
// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/generated_message_reflection.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/map.h>  // IWYU pragma: export
// #include <google/protobuf/map_entry.h>
// #include <google/protobuf/map_field_inl.h>
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/attr_value.pb.h"
// #include "tensorflow/core/framework/device_attributes.pb.h"
// #include "tensorflow/core/framework/function.pb.h"
// #include "tensorflow/core/framework/tensor.pb.h"
// #include "tensorflow/core/framework/tensor_shape.pb.h"
// #include "tensorflow/core/framework/types.pb.h"
// #include "tensorflow/core/framework/versions.pb.h"
// #include "tensorflow/core/protobuf/tensorflow_server.pb.h"
// @@protoc_insertion_point(includes)
// #include <google/protobuf/port_def.inc>
// #define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto
  // namespace internal
 /* namespace protobuf */
   /* namespace google */

// Internal implementation detail -- do not use these members.
  // namespace eager
  // namespace tensorflow




















 /* namespace protobuf */
   /* namespace google */
// Targeting ../RemoteTensorHandle.java


// -------------------------------------------------------------------
// Targeting ../Eager_Operation.java


// Targeting ../QueueItem.java


// Targeting ../QueueResponse.java


// Targeting ../CreateContextRequest.java


// Targeting ../CreateContextResponse.java


// Targeting ../EnqueueRequest.java


// Targeting ../EnqueueResponse.java


// Targeting ../WaitQueueDoneRequest.java


// Targeting ../WaitQueueDoneResponse.java


// Targeting ../KeepAliveRequest.java


// Targeting ../KeepAliveResponse.java


// Targeting ../CloseContextRequest.java


// Targeting ../CloseContextResponse.java


// Targeting ../RegisterFunctionRequest.java


// Targeting ../RegisterFunctionResponse.java


// Targeting ../SendTensorOp.java


// Targeting ../SendTensorRequest.java


// Targeting ../SendTensorResponse.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// RemoteTensorHandle

// int64 op_id = 1;




// int32 output_num = 2;




// string device = 3;










// string op_device = 4;










// .tensorflow.DataType dtype = 5;




// -------------------------------------------------------------------

// -------------------------------------------------------------------

// Operation

// int64 id = 1;




// string name = 2;










// repeated .tensorflow.eager.RemoteTensorHandle inputs = 3;








// repeated int64 control_op_ids = 4;








// map<string, .tensorflow.AttrValue> attrs = 5;




// string device = 6;










// -------------------------------------------------------------------

// QueueItem

// .tensorflow.eager.RemoteTensorHandle handle_to_decref = 1;







// .tensorflow.eager.Operation operation = 2;







// .tensorflow.eager.SendTensorOp send_tensor = 3;










// -------------------------------------------------------------------

// QueueResponse

// repeated .tensorflow.TensorShapeProto shape = 1;







// -------------------------------------------------------------------

// CreateContextRequest

// .tensorflow.ServerDef server_def = 1;






// bool async = 2;




// int64 keep_alive_secs = 3;




// .tensorflow.VersionDef version_def = 4;






// repeated .tensorflow.DeviceAttributes cluster_device_attributes = 6;







// fixed64 context_id = 7;




// -------------------------------------------------------------------

// CreateContextResponse

// repeated .tensorflow.DeviceAttributes device_attributes = 2;







// -------------------------------------------------------------------

// EnqueueRequest

// fixed64 context_id = 1;




// repeated .tensorflow.eager.QueueItem queue = 3;








// -------------------------------------------------------------------

// EnqueueResponse

// repeated .tensorflow.eager.QueueResponse queue_response = 1;








// -------------------------------------------------------------------

// WaitQueueDoneRequest

// fixed64 context_id = 1;




// repeated int64 op_id = 2;








// -------------------------------------------------------------------

// WaitQueueDoneResponse

// -------------------------------------------------------------------

// KeepAliveRequest

// fixed64 context_id = 1;




// -------------------------------------------------------------------

// KeepAliveResponse

// -------------------------------------------------------------------

// CloseContextRequest

// fixed64 context_id = 1;




// -------------------------------------------------------------------

// CloseContextResponse

// -------------------------------------------------------------------

// RegisterFunctionRequest

// fixed64 context_id = 1;




// .tensorflow.FunctionDef function_def = 2;






// -------------------------------------------------------------------

// RegisterFunctionResponse

// -------------------------------------------------------------------

// SendTensorOp

// int64 op_id = 1;




// repeated .tensorflow.TensorProto tensors = 2;







// string device_name = 3;










// -------------------------------------------------------------------

// SendTensorRequest

// fixed64 context_id = 1;




// int64 op_id = 2;




// repeated .tensorflow.TensorProto tensors = 3;







// string device_name = 4;










// -------------------------------------------------------------------

// SendTensorResponse

// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace eager
  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #include <google/protobuf/port_undef.inc>
// #endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto


// Parsed from tensorflow/core/protobuf/tensorflow_server.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/protobuf/tensorflow_server.proto

// #ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2ftensorflow_5fserver_2eproto
// #define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2ftensorflow_5fserver_2eproto

// #include <limits>
// #include <string>

// #include <google/protobuf/port_def.inc>
// #if PROTOBUF_VERSION < 3008000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please update
// #error your headers.
// #endif
// #if 3008000 < PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/port_undef.inc>
// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/generated_message_reflection.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/protobuf/config.pb.h"
// #include "tensorflow/core/protobuf/cluster.pb.h"
// @@protoc_insertion_point(includes)
// #include <google/protobuf/port_def.inc>
// #define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcore_2fprotobuf_2ftensorflow_5fserver_2eproto
  // namespace internal
 /* namespace protobuf */
   /* namespace google */

// Internal implementation detail -- do not use these members.
  // namespace tensorflow

 /* namespace protobuf */
   /* namespace google */
// Targeting ../ServerDef.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// ServerDef

// .tensorflow.ClusterDef cluster = 1;







// string job_name = 2;












// int32 task_index = 3;




// .tensorflow.ConfigProto default_session_config = 4;







// string protocol = 5;












// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__

// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #include <google/protobuf/port_undef.inc>
// #endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2ftensorflow_5fserver_2eproto


// Parsed from tensorflow/core/protobuf/named_tensor.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/protobuf/named_tensor.proto

// #ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fnamed_5ftensor_2eproto
// #define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fnamed_5ftensor_2eproto

// #include <limits>
// #include <string>

// #include <google/protobuf/port_def.inc>
// #if PROTOBUF_VERSION < 3008000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please update
// #error your headers.
// #endif
// #if 3008000 < PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/port_undef.inc>
// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/generated_message_reflection.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/tensor.pb.h"
// @@protoc_insertion_point(includes)
// #include <google/protobuf/port_def.inc>
// #define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcore_2fprotobuf_2fnamed_5ftensor_2eproto
  // namespace internal
 /* namespace protobuf */
   /* namespace google */

// Internal implementation detail -- do not use these members.
  // namespace tensorflow

 /* namespace protobuf */
   /* namespace google */
// Targeting ../NamedTensorProto.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// NamedTensorProto

// string name = 1;












// .tensorflow.TensorProto tensor = 2;







// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__

// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #include <google/protobuf/port_undef.inc>
// #endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fnamed_5ftensor_2eproto


// Parsed from tensorflow/core/protobuf/master.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/protobuf/master.proto

// #ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fmaster_2eproto
// #define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fmaster_2eproto

// #include <limits>
// #include <string>

// #include <google/protobuf/port_def.inc>
// #if PROTOBUF_VERSION < 3008000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please update
// #error your headers.
// #endif
// #if 3008000 < PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/port_undef.inc>
// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/generated_message_reflection.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/device_attributes.pb.h"
// #include "tensorflow/core/framework/graph.pb.h"
// #include "tensorflow/core/framework/tensor.pb.h"
// #include "tensorflow/core/lib/core/error_codes.pb.h"
// #include "tensorflow/core/protobuf/config.pb.h"
// #include "tensorflow/core/protobuf/named_tensor.pb.h"
// @@protoc_insertion_point(includes)
// #include <google/protobuf/port_def.inc>
// #define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcore_2fprotobuf_2fmaster_2eproto
  // namespace internal
 /* namespace protobuf */
   /* namespace google */

// Internal implementation detail -- do not use these members.
  // namespace tensorflow




















 /* namespace protobuf */
   /* namespace google */
// Targeting ../CreateSessionRequest.java


// Targeting ../CreateSessionResponse.java


// Targeting ../ExtendSessionRequest.java


// Targeting ../ExtendSessionResponse.java


// Targeting ../RunStepRequest.java


// Targeting ../RunStepResponse.java


// Targeting ../PartialRunSetupRequest.java


// Targeting ../PartialRunSetupResponse.java


// Targeting ../CloseSessionRequest.java


// Targeting ../CloseSessionResponse.java


// Targeting ../ResetRequest.java


// Targeting ../ResetResponse.java


// Targeting ../ListDevicesRequest.java


// Targeting ../ListDevicesResponse.java


// Targeting ../MakeCallableRequest.java


// Targeting ../MakeCallableResponse.java


// Targeting ../RunCallableRequest.java


// Targeting ../RunCallableResponse.java


// Targeting ../ReleaseCallableRequest.java


// Targeting ../ReleaseCallableResponse.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// CreateSessionRequest

// .tensorflow.GraphDef graph_def = 1;







// .tensorflow.ConfigProto config = 2;







// string target = 3;












// -------------------------------------------------------------------

// CreateSessionResponse

// string session_handle = 1;












// int64 graph_version = 2;




// -------------------------------------------------------------------

// ExtendSessionRequest

// string session_handle = 1;












// .tensorflow.GraphDef graph_def = 2;







// int64 current_graph_version = 3;




// -------------------------------------------------------------------

// ExtendSessionResponse

// int64 new_graph_version = 4;




// -------------------------------------------------------------------

// RunStepRequest

// string session_handle = 1;












// repeated .tensorflow.NamedTensorProto feed = 2;







// repeated string fetch = 3;
















// repeated string target = 4;
















// .tensorflow.RunOptions options = 5;







// string partial_run_handle = 6;












// bool store_errors_in_response_body = 7;




// int64 request_id = 8;




// -------------------------------------------------------------------

// RunStepResponse

// repeated .tensorflow.NamedTensorProto tensor = 1;







// .tensorflow.RunMetadata metadata = 2;







// .tensorflow.error.Code status_code = 3;




// string status_error_message = 4;












// -------------------------------------------------------------------

// PartialRunSetupRequest

// string session_handle = 1;












// repeated string feed = 2;
















// repeated string fetch = 3;
















// repeated string target = 4;
















// int64 request_id = 5;




// -------------------------------------------------------------------

// PartialRunSetupResponse

// string partial_run_handle = 1;












// -------------------------------------------------------------------

// CloseSessionRequest

// string session_handle = 1;












// -------------------------------------------------------------------

// CloseSessionResponse

// -------------------------------------------------------------------

// ResetRequest

// repeated string container = 1;
















// repeated string device_filters = 2;
















// -------------------------------------------------------------------

// ResetResponse

// -------------------------------------------------------------------

// ListDevicesRequest

// string session_handle = 1;












// -------------------------------------------------------------------

// ListDevicesResponse

// repeated .tensorflow.DeviceAttributes local_device = 1;







// repeated .tensorflow.DeviceAttributes remote_device = 2;







// -------------------------------------------------------------------

// MakeCallableRequest

// string session_handle = 1;












// .tensorflow.CallableOptions options = 2;







// int64 request_id = 3;




// -------------------------------------------------------------------

// MakeCallableResponse

// int64 handle = 1;




// -------------------------------------------------------------------

// RunCallableRequest

// string session_handle = 1;












// int64 handle = 2;




// repeated .tensorflow.TensorProto feed = 3;







// int64 request_id = 4;




// -------------------------------------------------------------------

// RunCallableResponse

// repeated .tensorflow.TensorProto fetch = 1;







// .tensorflow.RunMetadata metadata = 2;







// -------------------------------------------------------------------

// ReleaseCallableRequest

// string session_handle = 1;












// int64 handle = 2;




// -------------------------------------------------------------------

// ReleaseCallableResponse

// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #include <google/protobuf/port_undef.inc>
// #endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fmaster_2eproto


// Parsed from tensorflow/core/protobuf/worker.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/protobuf/worker.proto

// #ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fworker_2eproto
// #define GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fworker_2eproto

// #include <limits>
// #include <string>

// #include <google/protobuf/port_def.inc>
// #if PROTOBUF_VERSION < 3008000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please update
// #error your headers.
// #endif
// #if 3008000 < PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers. Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/port_undef.inc>
// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/generated_message_reflection.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/unknown_field_set.h>
// #include <google/protobuf/any.pb.h>
// #include "tensorflow/core/framework/cost_graph.pb.h"
// #include "tensorflow/core/framework/device_attributes.pb.h"
// #include "tensorflow/core/framework/graph.pb.h"
// #include "tensorflow/core/framework/step_stats.pb.h"
// #include "tensorflow/core/framework/tensor.pb.h"
// #include "tensorflow/core/framework/tensor_shape.pb.h"
// #include "tensorflow/core/framework/types.pb.h"
// #include "tensorflow/core/lib/core/error_codes.pb.h"
// #include "tensorflow/core/protobuf/config.pb.h"
// #include "tensorflow/core/protobuf/debug.pb.h"
// #include "tensorflow/core/protobuf/named_tensor.pb.h"
// #include "tensorflow/core/protobuf/tensorflow_server.pb.h"
// @@protoc_insertion_point(includes)
// #include <google/protobuf/port_def.inc>
// #define PROTOBUF_INTERNAL_EXPORT_tensorflow_2fcore_2fprotobuf_2fworker_2eproto
  // namespace internal
 /* namespace protobuf */
   /* namespace google */

// Internal implementation detail -- do not use these members.
  // namespace tensorflow




































 /* namespace protobuf */
   /* namespace google */
// Targeting ../GetStatusRequest.java


// Targeting ../GetStatusResponse.java


// Targeting ../CreateWorkerSessionRequest.java


// Targeting ../CreateWorkerSessionResponse.java


// Targeting ../DeleteWorkerSessionRequest.java


// Targeting ../DeleteWorkerSessionResponse.java


// Targeting ../RegisterGraphRequest.java


// Targeting ../RegisterGraphResponse.java


// Targeting ../DeregisterGraphRequest.java


// Targeting ../DeregisterGraphResponse.java


// Targeting ../CleanupAllRequest.java


// Targeting ../CleanupAllResponse.java


// Targeting ../ExecutorOpts.java


// Targeting ../RunGraphRequest.java


// Targeting ../RunGraphResponse.java


// Targeting ../CleanupGraphRequest.java


// Targeting ../CleanupGraphResponse.java


// Targeting ../RecvTensorRequest.java


// Targeting ../RecvTensorResponse.java


// Targeting ../MarkRecvFinishedRequest.java


// Targeting ../MarkRecvFinishedResponse.java


// Targeting ../LoggingRequest.java


// Targeting ../LabeledStepStats.java


// Targeting ../LoggingResponse.java


// Targeting ../TraceOpts.java


// Targeting ../TracingRequest.java


// Targeting ../TracingResponse.java


// Targeting ../RecvBufRequest.java


// Targeting ../RecvBufResponse.java


// Targeting ../CompleteGroupRequest.java


// Targeting ../CompleteGroupResponse.java


// Targeting ../CompleteInstanceRequest.java


// Targeting ../CompleteInstanceResponse.java


// Targeting ../GetStepSequenceRequest.java


// Targeting ../StepSequence.java


// Targeting ../GetStepSequenceResponse.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// GetStatusRequest

// -------------------------------------------------------------------

// GetStatusResponse

// repeated .tensorflow.DeviceAttributes device_attributes = 1;







// -------------------------------------------------------------------

// CreateWorkerSessionRequest

// string session_handle = 1;












// .tensorflow.ServerDef server_def = 2;







// bool isolate_session_state = 3;




// repeated .tensorflow.DeviceAttributes cluster_device_attributes = 4;







// -------------------------------------------------------------------

// CreateWorkerSessionResponse

// -------------------------------------------------------------------

// DeleteWorkerSessionRequest

// string session_handle = 1;












// -------------------------------------------------------------------

// DeleteWorkerSessionResponse

// -------------------------------------------------------------------

// RegisterGraphRequest

// string session_handle = 1;












// bool create_worker_session_called = 6;




// .tensorflow.GraphDef graph_def = 2;







// bool has_control_flow = 3 [deprecated = true];




// .tensorflow.GraphOptions graph_options = 4;







// .tensorflow.DebugOptions debug_options = 5;







// int64 collective_graph_key = 7;




// -------------------------------------------------------------------

// RegisterGraphResponse

// string graph_handle = 1;












// -------------------------------------------------------------------

// DeregisterGraphRequest

// string session_handle = 2;












// bool create_worker_session_called = 3;




// string graph_handle = 1;












// -------------------------------------------------------------------

// DeregisterGraphResponse

// -------------------------------------------------------------------

// CleanupAllRequest

// repeated string container = 1;
















// -------------------------------------------------------------------

// CleanupAllResponse

// -------------------------------------------------------------------

// ExecutorOpts

// bool record_costs = 1;




// bool record_timeline = 3;




// bool record_partition_graphs = 4;




// bool report_tensor_allocations_upon_oom = 5;




// -------------------------------------------------------------------

// RunGraphRequest

// string session_handle = 8;












// bool create_worker_session_called = 10;




// string graph_handle = 1;












// int64 step_id = 2;




// .tensorflow.ExecutorOpts exec_opts = 5;








// repeated .tensorflow.NamedTensorProto send = 3;







// repeated string recv_key = 4;
















// bool is_partial = 6;




// bool is_last_partial_run = 7;




// bool store_errors_in_response_body = 9;




// int64 request_id = 11;




// -------------------------------------------------------------------

// RunGraphResponse

// repeated .tensorflow.NamedTensorProto recv = 1;







// .tensorflow.StepStats step_stats = 2;







// .tensorflow.CostGraphDef cost_graph = 3;







// repeated .tensorflow.GraphDef partition_graph = 4;







// .tensorflow.error.Code status_code = 5;




// string status_error_message = 6;












// -------------------------------------------------------------------

// CleanupGraphRequest

// int64 step_id = 1;




// -------------------------------------------------------------------

// CleanupGraphResponse

// -------------------------------------------------------------------

// RecvTensorRequest

// int64 step_id = 1;




// string rendezvous_key = 2;












// bool dma_ok = 3;




// .tensorflow.DeviceLocality client_locality = 4;







// .tensorflow.DeviceLocality server_locality = 5;







// .google.protobuf.Any transport_options = 6;







// int64 request_id = 7;




// -------------------------------------------------------------------

// RecvTensorResponse

// .tensorflow.TensorProto tensor = 1;







// bool is_dead = 2;




// int64 send_start_micros = 3;




// .google.protobuf.Any transport_options = 4;







// bool require_ack = 5;




// -------------------------------------------------------------------

// MarkRecvFinishedRequest

// int64 request_id = 1;




// -------------------------------------------------------------------

// MarkRecvFinishedResponse

// -------------------------------------------------------------------

// LoggingRequest

// bool enable_rpc_logging = 1;




// bool disable_rpc_logging = 4;




// bool clear = 2;




// repeated int64 fetch_step_id = 3;








// -------------------------------------------------------------------

// LabeledStepStats

// int64 step_id = 1;




// .tensorflow.StepStats step_stats = 2;







// -------------------------------------------------------------------

// LoggingResponse

// repeated .tensorflow.LabeledStepStats step = 1;








// -------------------------------------------------------------------

// TraceOpts

// double duration = 1;




// bool use_step_profiler = 2;




// bool use_kernel_profiler = 3;




// bool use_extended_profiler = 4;




// bool use_gpu_profiler = 5;




// bool use_sample_profiler = 6;




// -------------------------------------------------------------------

// TracingRequest

// .tensorflow.TraceOpts options = 1;








// -------------------------------------------------------------------

// TracingResponse

// -------------------------------------------------------------------

// RecvBufRequest

// int64 step_id = 1;




// string buf_rendezvous_key = 2;












// int64 num_bytes = 3;




// fixed64 buf_ptr = 4;




// .tensorflow.DeviceLocality client_locality = 5;







// .tensorflow.DeviceLocality server_locality = 6;







// .google.protobuf.Any transport_options = 7;







// string src_device = 8;












// string dst_device = 9;












// int64 request_id = 10;




// uint64 src_incarnation = 11;




// -------------------------------------------------------------------

// RecvBufResponse

// fixed64 buf_ptr = 1;




// int64 num_bytes = 2;




// bool is_dead = 3;




// .google.protobuf.Any transport_options = 4;







// int64 send_start_micros = 5;




// bool require_ack = 6;




// -------------------------------------------------------------------

// CompleteGroupRequest

// int32 group_key = 1;




// int32 group_size = 2;




// string device_type = 3;












// repeated string device_name = 4;
















// int32 collective_type = 5;




// -------------------------------------------------------------------

// CompleteGroupResponse

// int32 group_key = 1;




// int32 group_size = 2;




// string device_type = 3;












// int32 num_tasks = 4;




// repeated string device_name = 5;
















// repeated string task_name = 6;
















// bytes communicator_key = 7;












// -------------------------------------------------------------------

// CompleteInstanceRequest

// string name = 1;












// int32 type = 2;




// .tensorflow.DataType data_type = 3;




// .tensorflow.TensorShapeProto shape = 4;







// int32 group_key = 5;




// int32 group_size = 6;




// int32 instance_key = 7;




// string device_type = 8;












// repeated int32 subdiv_offset = 9;








// string device = 10;












// bool is_source = 11;




// -------------------------------------------------------------------

// CompleteInstanceResponse

// int32 instance_key = 1;




// int32 source_rank = 2;




// -------------------------------------------------------------------

// GetStepSequenceRequest

// repeated int64 graph_key = 1;








// -------------------------------------------------------------------

// StepSequence

// int64 graph_key = 1;




// int64 next_step_id = 2;




// -------------------------------------------------------------------

// GetStepSequenceResponse

// repeated .tensorflow.StepSequence step_sequence = 1;








// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #include <google/protobuf/port_undef.inc>
// #endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fworker_2eproto


// Parsed from tensorflow/core/distributed_runtime/call_options.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_DISTRIBUTED_RUNTIME_CALL_OPTIONS_H_
// #define TENSORFLOW_CORE_DISTRIBUTED_RUNTIME_CALL_OPTIONS_H_

// #include <functional>

// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/mutex.h"
// #include "tensorflow/core/platform/thread_annotations.h"
// #include "tensorflow/core/platform/types.h"
// Targeting ../CallOptions.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_DISTRIBUTED_RUNTIME_CALL_OPTIONS_H_


// Parsed from tensorflow/core/distributed_runtime/message_wrappers.h

/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_DISTRIBUTED_RUNTIME_MESSAGE_WRAPPERS_H_
// #define TENSORFLOW_CORE_DISTRIBUTED_RUNTIME_MESSAGE_WRAPPERS_H_

// #include "tensorflow/core/framework/allocator.h"
// #include "tensorflow/core/framework/cost_graph.pb.h"
// #include "tensorflow/core/framework/graph.pb.h"
// #include "tensorflow/core/framework/step_stats.pb.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor.pb_text.h"
// #include "tensorflow/core/framework/versions.pb.h"
// #include "tensorflow/core/protobuf/config.pb.h"
// #include "tensorflow/core/protobuf/master.pb.h"
// #include "tensorflow/core/protobuf/worker.pb.h"
// Targeting ../RunStepRequestWrapper.java


// Targeting ../MutableRunStepRequestWrapper.java


// Targeting ../InMemoryRunStepRequest.java


// Targeting ../MutableProtoRunStepRequest.java


// Targeting ../ProtoRunStepRequest.java


// Targeting ../RunGraphRequestWrapper.java


// Targeting ../MutableRunGraphRequestWrapper.java


// Targeting ../InMemoryRunGraphRequest.java


// Targeting ../MutableProtoRunGraphRequest.java


// Targeting ../ProtoRunGraphRequest.java


// Targeting ../MutableRunGraphResponseWrapper.java


// Targeting ../InMemoryRunGraphResponse.java


// Targeting ../OwnedProtoRunGraphResponse.java


// Targeting ../NonOwnedProtoRunGraphResponse.java


// Targeting ../MutableRunStepResponseWrapper.java


// Targeting ../InMemoryRunStepResponse.java


// Targeting ../OwnedProtoRunStepResponse.java


// Targeting ../NonOwnedProtoRunStepResponse.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_DISTRIBUTED_RUNTIME_MESSAGE_WRAPPERS_H_


// Parsed from tensorflow/core/distributed_runtime/worker_interface.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_DISTRIBUTED_RUNTIME_WORKER_INTERFACE_H_
// #define TENSORFLOW_CORE_DISTRIBUTED_RUNTIME_WORKER_INTERFACE_H_

// #include <functional>

// #include "tensorflow/core/distributed_runtime/call_options.h"
// #include "tensorflow/core/distributed_runtime/message_wrappers.h"
// #include "tensorflow/core/lib/core/notification.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/platform/types.h"
// #include "tensorflow/core/protobuf/worker.pb.h"

// Status callback.
// Targeting ../TensorResponse.java


// Targeting ../WorkerInterface.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_DISTRIBUTED_RUNTIME_WORKER_INTERFACE_H_


// Parsed from tensorflow/core/distributed_runtime/worker_cache.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_DISTRIBUTED_RUNTIME_WORKER_CACHE_H_
// #define TENSORFLOW_CORE_DISTRIBUTED_RUNTIME_WORKER_CACHE_H_

// #include <string>
// #include <vector>

// #include "tensorflow/core/distributed_runtime/eager/eager_client.h"
// #include "tensorflow/core/distributed_runtime/worker_interface.h"
// #include "tensorflow/core/framework/device_attributes.pb.h"  // for DeviceLocality
// #include "tensorflow/core/lib/core/status.h"
// Targeting ../ChannelCache.java


// Targeting ../WorkerCacheInterface.java


  // namespace tensorflow
// #endif  // TENSORFLOW_CORE_DISTRIBUTED_RUNTIME_WORKER_CACHE_H_


// Parsed from tensorflow/core/distributed_runtime/worker_env.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_DISTRIBUTED_RUNTIME_WORKER_ENV_H_
// #define TENSORFLOW_CORE_DISTRIBUTED_RUNTIME_WORKER_ENV_H_

// #include <vector>
// #include "tensorflow/core/platform/types.h"

// Targeting ../RendezvousMgrInterface.java


// Targeting ../SessionMgr.java


// Targeting ../WorkerEnv.java



  // end namespace tensorflow

// #endif  // TENSORFLOW_CORE_DISTRIBUTED_RUNTIME_WORKER_ENV_H_


// Parsed from tensorflow/core/distributed_runtime/worker_session.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_DISTRIBUTED_RUNTIME_WORKER_SESSION_H_
// #define TENSORFLOW_CORE_DISTRIBUTED_RUNTIME_WORKER_SESSION_H_

// #include <string>

// #include "tensorflow/core/common_runtime/device_mgr.h"
// #include "tensorflow/core/distributed_runtime/cluster_function_library_runtime.h"
// #include "tensorflow/core/distributed_runtime/graph_mgr.h"
// #include "tensorflow/core/distributed_runtime/worker_cache.h"
// Targeting ../ClusterFunctionLibraryRuntime.java


// Targeting ../GraphMgr.java


// Targeting ../WorkerSession.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_DISTRIBUTED_RUNTIME_WORKER_SESSION_H_


// Parsed from tensorflow/core/common_runtime/eager/attr_builder.h

/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_COMMON_RUNTIME_EAGER_ATTR_BUILDER_H_
// #define TENSORFLOW_CORE_COMMON_RUNTIME_EAGER_ATTR_BUILDER_H_

// Support for eager execution of TensorFlow kernels.

// #include <memory>
// #include <unordered_map>

// #include "tensorflow/c/tf_attrtype.h"
// #include "tensorflow/core/common_runtime/device.h"
// #include "tensorflow/core/framework/node_def.pb.h"
// #include "tensorflow/core/framework/op_kernel.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/gtl/inlined_vector.h"
// #include "tensorflow/core/lib/gtl/optional.h"
// #include "tensorflow/core/platform/fingerprint.h"
// #include "tensorflow/core/util/tensor_slice_reader_cache.h"

// Maps attribute name to an encoding of the type of the attribute value.
// If the type is not a list type, the value is the same as the TF_AttrType type
// of the value. Else, the highest order bit is on, and the rest of the bits
// represent the TF_AttrType type of the values in the list.

// Look up OpDef for `op_name`.
@Namespace("tensorflow") public static native @ByVal Status OpDefForOp(@Cast("const char*") BytePointer op_name, @Cast("const tensorflow::OpDef**") PointerPointer op_def);
@Namespace("tensorflow") public static native @ByVal Status OpDefForOp(@Cast("const char*") BytePointer op_name, @Const @ByPtrPtr OpDef op_def);
@Namespace("tensorflow") public static native @ByVal Status OpDefForOp(String op_name, @Const @ByPtrPtr OpDef op_def);

// Returns the AttrTypeMap for the TensorFlow operation named op_name.
// If op_name is not registered in global op registry, AttrTypeMapForOp assumes
// the op to be a function and returns the default attributes for a function.
// `is_function` is set to true in this case.
@Namespace("tensorflow") public static native @ByVal Status AttrTypeMapForOp(@Cast("const char*") BytePointer op_name, @Cast("const tensorflow::AttrTypeMap**") PointerPointer out,
                        @Cast("bool*") BoolPointer is_function);
@Namespace("tensorflow") public static native @ByVal Status AttrTypeMapForOp(@Cast("const char*") BytePointer op_name, @Cast("const tensorflow::AttrTypeMap**") @ByPtrPtr StringIntUnorderedMap out,
                        @Cast("bool*") BoolPointer is_function);
@Namespace("tensorflow") public static native @ByVal Status AttrTypeMapForOp(String op_name, @Cast("const tensorflow::AttrTypeMap**") @ByPtrPtr StringIntUnorderedMap out,
                        @Cast("bool*") boolean... is_function);

// Looks for 'attr_name' in 'm' and sets 'out' and 'is_list'.
@Namespace("tensorflow") public static native @ByVal Status AttrTypeByName(@Cast("const tensorflow::AttrTypeMap*") @ByRef StringIntUnorderedMap m, @StdString BytePointer attr_name,
                      @Cast("TF_AttrType*") IntPointer out, @Cast("unsigned char*") BytePointer is_list);
@Namespace("tensorflow") public static native @ByVal Status AttrTypeByName(@Cast("const tensorflow::AttrTypeMap*") @ByRef StringIntUnorderedMap m, @StdString String attr_name,
                      @Cast("TF_AttrType*") IntBuffer out, @Cast("unsigned char*") ByteBuffer is_list);
@Namespace("tensorflow") public static native @ByVal Status AttrTypeByName(@Cast("const tensorflow::AttrTypeMap*") @ByRef StringIntUnorderedMap m, @StdString BytePointer attr_name,
                      @Cast("TF_AttrType*") int[] out, @Cast("unsigned char*") byte[] is_list);
@Namespace("tensorflow") public static native @ByVal Status AttrTypeByName(@Cast("const tensorflow::AttrTypeMap*") @ByRef StringIntUnorderedMap m, @StdString String attr_name,
                      @Cast("TF_AttrType*") IntPointer out, @Cast("unsigned char*") BytePointer is_list);
@Namespace("tensorflow") public static native @ByVal Status AttrTypeByName(@Cast("const tensorflow::AttrTypeMap*") @ByRef StringIntUnorderedMap m, @StdString BytePointer attr_name,
                      @Cast("TF_AttrType*") IntBuffer out, @Cast("unsigned char*") ByteBuffer is_list);
@Namespace("tensorflow") public static native @ByVal Status AttrTypeByName(@Cast("const tensorflow::AttrTypeMap*") @ByRef StringIntUnorderedMap m, @StdString String attr_name,
                      @Cast("TF_AttrType*") int[] out, @Cast("unsigned char*") byte[] is_list);
// Targeting ../AttrBuilder.java

  // namespace tensorflow











  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_COMMON_RUNTIME_EAGER_ATTR_BUILDER_H_


// Parsed from tensorflow/core/common_runtime/eager/context.h

/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
// #ifndef TENSORFLOW_CORE_COMMON_RUNTIME_EAGER_CONTEXT_H_
// #define TENSORFLOW_CORE_COMMON_RUNTIME_EAGER_CONTEXT_H_

// #include <algorithm>
// #include <cstddef>
// #include <map>
// #include <memory>
// #include <queue>
// #include <string>
// #include <vector>

// clang-format off
// Required for IS_MOBILE_PLATFORM
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/platform/platform.h"
// clang-format on

// #include "tensorflow/core/common_runtime/device_factory.h"
// #include "tensorflow/core/common_runtime/device_mgr.h"
// #include "tensorflow/core/common_runtime/eager/eager_executor.h"
// #include "tensorflow/core/common_runtime/eager/kernel_and_device.h"
// #include "tensorflow/core/common_runtime/function.h"
// #include "tensorflow/core/common_runtime/rendezvous_mgr.h"
// #include "tensorflow/core/example/example.pb.h"
// #include "tensorflow/core/framework/function.h"
// #include "tensorflow/core/platform/env.h"
// #include "tensorflow/core/util/device_name_utils.h"
// #if !defined(IS_MOBILE_PLATFORM)
// #include "tensorflow/core/distributed_runtime/eager/eager_client.h"
// #include "tensorflow/core/distributed_runtime/eager/remote_tensor_handle.h"
// #include "tensorflow/core/distributed_runtime/rendezvous_mgr_interface.h"
// #include "tensorflow/core/distributed_runtime/server_lib.h"
// #include "tensorflow/core/distributed_runtime/worker_cache.h"
// #include "tensorflow/core/distributed_runtime/worker_env.h"
// #endif  // !IS_MOBILE_PLATFORM
// #include "tensorflow/core/framework/collective.h"
// #include "tensorflow/core/framework/log_memory.h"
// #include "tensorflow/core/framework/rendezvous.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/lib/core/threadpool.h"
// #include "tensorflow/core/lib/gtl/flatmap.h"
// #include "tensorflow/core/lib/gtl/flatset.h"
// #include "tensorflow/core/lib/gtl/inlined_vector.h"
// #include "tensorflow/core/lib/gtl/map_util.h"
// #include "tensorflow/core/lib/gtl/stl_util.h"
// #include "tensorflow/core/platform/fingerprint.h"
// #include "tensorflow/core/platform/mutex.h"
// #include "tensorflow/core/platform/thread_annotations.h"
// #include "tensorflow/core/public/session_options.h"
// #include "tensorflow/core/public/version.h"
// Targeting ../RemoteMgr.java


  // namespace eager

// LINT.IfChange
// Note: Keep in sync with exported copy of enum in eager/c_api.h.
/** enum tensorflow::ContextDevicePlacementPolicy */
public static final int
  // Running operations with input tensors on the wrong device will fail.
  DEVICE_PLACEMENT_EXPLICIT = 0,
  // Copy the tensor to the right device but log a warning.
  DEVICE_PLACEMENT_WARN = 1,
  // Silently copy the tensor, which has a performance cost since the operation
  // will be blocked till the copy completes. This is the default policy.
  DEVICE_PLACEMENT_SILENT = 2,
  // Placement policy which silently copies int32 tensors but not other dtypes.
  DEVICE_PLACEMENT_SILENT_FOR_INT32 = 3;
// LINT.ThenChange(//tensorflow/c/eager/c_api.h)

// LINT.IfChange
// Note: Keep in sync with exported copy of enum in eager/c_api_experimental.h.
/** enum tensorflow::ContextMirroringPolicy */
public static final int
  // Do not maintain mirrors in a TensorHandle, instead make new TensorHandle
  // copies with their own lifetime.
  MIRRORING_NONE = 0,
  // Mirroring any remote tensor handles, associating them with the lifetime of
  // the local TensorHandle.
  MIRRORING_ALL = 1;
// Targeting ../RunMetadataListener.java


// Targeting ../EagerContext.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_COMMON_RUNTIME_EAGER_CONTEXT_H_


// Parsed from tensorflow/core/common_runtime/eager/eager_executor.h

/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
// #ifndef TENSORFLOW_CORE_COMMON_RUNTIME_EAGER_EAGER_EXECUTOR_H_
// #define TENSORFLOW_CORE_COMMON_RUNTIME_EAGER_EAGER_EXECUTOR_H_

// #include <algorithm>
// #include <cstddef>
// #include <map>
// #include <memory>
// #include <queue>
// #include <string>
// #include <vector>

// #include "tensorflow/core/common_runtime/device_factory.h"
// #include "tensorflow/core/common_runtime/function.h"
// #include "tensorflow/core/common_runtime/rendezvous_mgr.h"
// #include "tensorflow/core/framework/rendezvous.h"
// #include "tensorflow/core/lib/gtl/inlined_vector.h"
// #include "tensorflow/core/lib/gtl/map_util.h"
// #include "tensorflow/core/lib/gtl/stl_util.h"
// #include "tensorflow/core/platform/mutex.h"
// #include "tensorflow/core/platform/thread_annotations.h"
// #include "tensorflow/core/public/version.h"
// Targeting ../EagerNode.java


// Targeting ../EagerExecutor.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_COMMON_RUNTIME_EAGER_EAGER_EXECUTOR_H_


// Parsed from tensorflow/core/common_runtime/eager/eager_operation.h

/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
// #ifndef TENSORFLOW_CORE_COMMON_RUNTIME_EAGER_EAGER_OPERATION_H_
// #define TENSORFLOW_CORE_COMMON_RUNTIME_EAGER_EAGER_OPERATION_H_

// #include "tensorflow/core/common_runtime/eager/attr_builder.h"
// #include "tensorflow/core/common_runtime/eager/context.h"
// #include "tensorflow/core/common_runtime/eager/tensor_handle.h"
// #include "tensorflow/core/framework/cancellation.h"
// #include "tensorflow/core/util/device_name_utils.h"
// Targeting ../EagerOperation.java


  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_COMMON_RUNTIME_EAGER_EAGER_OPERATION_H_


// Parsed from tensorflow/core/common_runtime/eager/kernel_and_device.h

/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_COMMON_RUNTIME_EAGER_KERNEL_AND_DEVICE_H_
// #define TENSORFLOW_CORE_COMMON_RUNTIME_EAGER_KERNEL_AND_DEVICE_H_

// Support for eager execution of TensorFlow kernels.

// #include <memory>
// #include <unordered_map>

// #include "tensorflow/core/common_runtime/device.h"
// #include "tensorflow/core/framework/cancellation.h"
// #include "tensorflow/core/framework/collective.h"
// #include "tensorflow/core/framework/node_def.pb.h"
// #include "tensorflow/core/framework/op_kernel.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/gtl/inlined_vector.h"
// #include "tensorflow/core/platform/fingerprint.h"
// #include "tensorflow/core/util/tensor_slice_reader_cache.h"

// Forward declaration for proto class NodeExecStats so we do not need to
// include the proto header
// Targeting ../KernelAndDevice.java


// Targeting ../KernelAndDeviceOp.java


// Targeting ../KernelAndDeviceFunc.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_COMMON_RUNTIME_EAGER_KERNEL_AND_DEVICE_H_


// Parsed from tensorflow/core/common_runtime/eager/tensor_handle.h

/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
// #ifndef TENSORFLOW_CORE_COMMON_RUNTIME_EAGER_TENSOR_HANDLE_H_
// #define TENSORFLOW_CORE_COMMON_RUNTIME_EAGER_TENSOR_HANDLE_H_

// #include <algorithm>
// #include <cstddef>
// #include <map>
// #include <memory>
// #include <queue>
// #include <string>
// #include <vector>

// clang-format off
// Required for IS_MOBILE_PLATFORM
// #include "tensorflow/core/platform/platform.h"
// clang-format on

// #include "tensorflow/core/common_runtime/device.h"
// #include "tensorflow/core/common_runtime/device_factory.h"
// #include "tensorflow/core/common_runtime/eager/context.h"
// #include "tensorflow/core/common_runtime/eager/eager_executor.h"
// #include "tensorflow/core/common_runtime/eager/tensor_handle_data.h"
// #include "tensorflow/core/common_runtime/function.h"
// #include "tensorflow/core/common_runtime/rendezvous_mgr.h"
// #if !defined(IS_MOBILE_PLATFORM)
// #include "tensorflow/core/distributed_runtime/eager/eager_client.h"
// #include "tensorflow/core/distributed_runtime/eager/remote_tensor_handle_data.h"
// #endif  // IS_MOBILE_PLATFORM
// #include "tensorflow/core/framework/rendezvous.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/lib/gtl/inlined_vector.h"
// #include "tensorflow/core/lib/gtl/map_util.h"
// #include "tensorflow/core/lib/gtl/stl_util.h"
// #include "tensorflow/core/platform/fingerprint.h"
// #include "tensorflow/core/platform/mutex.h"
// #include "tensorflow/core/platform/notification.h"
// #include "tensorflow/core/platform/thread_annotations.h"
// #include "tensorflow/core/public/session_options.h"
// #include "tensorflow/core/public/version.h"
// Targeting ../OutputGraphNode.java


// Targeting ../TensorHandle.java



// Returns the device backing the resource. Else, returns nullptr.
@Namespace("tensorflow") public static native Device GetResourceDevice(@Const @ByRef ResourceHandle handle, EagerContext ctx);

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_COMMON_RUNTIME_EAGER_TENSOR_HANDLE_H_


// Parsed from tensorflow/c/eager/c_api.h

/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_C_EAGER_C_API_H_
// #define TENSORFLOW_C_EAGER_C_API_H_

// C API extensions to experiment with eager execution of kernels.
// WARNING: Unlike tensorflow/c/c_api.h, the API here is not guaranteed to be
// stable and can change without notice.

// #include "tensorflow/c/c_api.h"

// Macro to control visibility of exported symbols in the shared library (.so,
// .dylib, .dll).
// This duplicates the TF_EXPORT macro definition in
// tensorflow/core/platform/macros.h in order to keep this .h file independent
// of any other includes.$a
// #ifdef SWIG
// #define TF_CAPI_EXPORT
// #else
// #endif  // SWIG

// #ifdef __cplusplus
// #endif

// Return a new options object.
public static native TFE_ContextOptions TFE_NewContextOptions();

// Set the config in TF_ContextOptions.options.
// config should be a serialized tensorflow.ConfigProto proto.
// If config was not parsed successfully as a ConfigProto, record the
// error information in *status.
public static native void TFE_ContextOptionsSetConfig(
    TFE_ContextOptions options, @Const Pointer proto, @Cast("size_t") long proto_len,
    TF_Status status);

// Controls how to act when we try to run an operation on a given device but
// some input tensors are not on that device.
// LINT.IfChange
// Note: Keep in sync with internal copy of enum in eager/context.h.
/** enum TFE_ContextDevicePlacementPolicy */
public static final int
  // Running operations with input tensors on the wrong device will fail.
  TFE_DEVICE_PLACEMENT_EXPLICIT = 0,
  // Copy the tensor to the right device but log a warning.
  TFE_DEVICE_PLACEMENT_WARN = 1,
  // Silently copy the tensor, which has a performance cost since the operation
  // will be blocked till the copy completes. This is the default placement
  // policy.
  TFE_DEVICE_PLACEMENT_SILENT = 2,
  // Placement policy which silently copies int32 tensors but not other dtypes.
  TFE_DEVICE_PLACEMENT_SILENT_FOR_INT32 = 3;
// LINT.ThenChange(//tensorflow/core/common_runtime/eager/context.h)

// Sets the default execution mode (sync/async). Note that this can be
// overridden per thread using TFE_ContextSetExecutorForThread.
public static native void TFE_ContextOptionsSetAsync(TFE_ContextOptions arg0,
                                                      @Cast("unsigned char") byte enable);

public static native void TFE_ContextOptionsSetDevicePlacementPolicy(
    TFE_ContextOptions arg0, @Cast("TFE_ContextDevicePlacementPolicy") int arg1);

// Destroy an options object.
public static native void TFE_DeleteContextOptions(TFE_ContextOptions arg0);

// "Context" under which operations/functions are executed. It encapsulates
// things like the available devices, resource manager etc.
// TFE_Context must outlive all tensor handles created using it. In other
// words, TFE_DeleteContext() must be called after all tensor handles have
// been deleted (with TFE_DeleteTensorHandle).
//
// TODO(ashankar): Merge with TF_Session?

public static native TFE_Context TFE_NewContext(
    @Const TFE_ContextOptions opts, TF_Status status);
public static native void TFE_DeleteContext(TFE_Context ctx);
public static native TF_DeviceList TFE_ContextListDevices(TFE_Context ctx,
                                                            TF_Status status);

// Clears the internal caches in the TFE context. Useful when reseeding random
// ops.
public static native void TFE_ContextClearCaches(TFE_Context ctx);

// Sets a thread-local device placement policy. After this call, other calls to
// TFE_Execute in the same thread will use the device policy specified here
// instead of the device policy used to construct the context. This has no
// effect on the device policy used by other program threads.
public static native void TFE_ContextSetThreadLocalDevicePlacementPolicy(
    TFE_Context ctx, @Cast("TFE_ContextDevicePlacementPolicy") int policy);

// Returns the device placement policy to be used by this context in the current
// thread.
public static native @Cast("TFE_ContextDevicePlacementPolicy") int TFE_ContextGetDevicePlacementPolicy(TFE_Context ctx);

// A tensorflow.ServerDef specifies remote workers (in addition to the current
// workers name). Operations created on this context can then be executed on
// any of these remote workers by setting an appropriate device.
//
// If the following is set, all servers identified by the
// ServerDef must be up when the context is created.
public static native void TFE_ContextSetServerDef(TFE_Context ctx,
                                                   int keep_alive_secs,
                                                   @Const Pointer proto,
                                                   @Cast("size_t") long proto_len,
                                                   TF_Status status);

// A handle to a tensor on a device.
//
// Like a TF_Tensor, a TFE_TensorHandle refers to a tensor with a value, shape,
// type etc. Unlike a TF_Tensor, a TFE_TensorHandle may refer to such tensors
// placed in memory of different devices or remote address spaces.

public static native TFE_TensorHandle TFE_NewTensorHandle(TF_Tensor t,
                                                            TF_Status status);
// Indicates that the caller will not be using `h` any more.
public static native void TFE_DeleteTensorHandle(TFE_TensorHandle h);
public static native @Cast("TF_DataType") int TFE_TensorHandleDataType(TFE_TensorHandle h);
// This function will block till the operation that produces `h` has completed.
public static native int TFE_TensorHandleNumDims(TFE_TensorHandle h,
                                                  TF_Status status);
public static native @Cast("int64_t") long TFE_TensorHandleNumElements(TFE_TensorHandle h,
                                                          TF_Status status);
// This function will block till the operation that produces `h` has completed.
public static native @Cast("int64_t") long TFE_TensorHandleDim(TFE_TensorHandle h,
                                                  int dim_index,
                                                  TF_Status status);

// Returns the device of the operation that produced `h`. If `h` was produced by
// a copy, returns the destination device of the copy. Note that the returned
// device name is not always the device holding the tensor handle's memory. If
// you want the latter, use TFE_TensorHandleBackingDeviceName. This function
// will block till the operation that produces `h` has completed.
public static native @Cast("const char*") BytePointer TFE_TensorHandleDeviceName(
    TFE_TensorHandle h, TF_Status status);

// Returns the name of the device in whose memory `h` resides.
//
// This function will block till the operation that produces `h` has completed.
public static native @Cast("const char*") BytePointer TFE_TensorHandleBackingDeviceName(
    TFE_TensorHandle h, TF_Status status);

// Return a pointer to a new TFE_TensorHandle that shares the underlying tensor
// with `h`. On success, `status` is set to OK. On failure, `status` reflects
// the error and a nullptr is returned.
public static native TFE_TensorHandle TFE_TensorHandleCopySharingTensor(
    TFE_TensorHandle h, TF_Status status);

// This function will block till the operation that produces `h` has
// completed. The memory returned might alias the internal memory used by
// TensorFlow. Hence, callers should not mutate this memory (for example by
// modifying the memory region pointed to by TF_TensorData() on the returned
// TF_Tensor).
public static native TF_Tensor TFE_TensorHandleResolve(TFE_TensorHandle h,
                                                         TF_Status status);

// Create a new TFE_TensorHandle with the same contents as 'h' but placed
// in the memory of the device name 'device_name'.
// If source and destination are the same device, then this creates a new handle
// that shares the underlying buffer. Otherwise, it currently requires at least
// one of the source or destination devices to be CPU (i.e., for the source or
// destination tensor to be placed in host memory).
// If async execution is enabled, the copy may be enqueued and the call will
// return "non-ready" handle. Else, this function returns after the copy has
// been done.
public static native TFE_TensorHandle TFE_TensorHandleCopyToDevice(
    TFE_TensorHandle h, TFE_Context ctx, @Cast("const char*") BytePointer device_name,
    TF_Status status);
public static native TFE_TensorHandle TFE_TensorHandleCopyToDevice(
    TFE_TensorHandle h, TFE_Context ctx, String device_name,
    TF_Status status);

// Debugging/Profiling information for TFE_TensorHandle
//
// TFE_TensorDebugInfo contains information useful for debugging and
// profiling tensors.

// Retrieves TFE_TensorDebugInfo for `handle`.
// If TFE_TensorHandleTensorDebugInfo succeeds, `status` is set to OK and caller
// is responsible for deleting returned TFE_TensorDebugInfo.
// If TFE_TensorHandleTensorDebugInfo fails, `status` is set to appropriate
// error and nullptr is returned. This function can block till the operation
// that produces `handle` has completed.
public static native TFE_TensorDebugInfo TFE_TensorHandleTensorDebugInfo(
    TFE_TensorHandle handle, TF_Status status);

// Deletes `debug_info`.
public static native void TFE_DeleteTensorDebugInfo(
    TFE_TensorDebugInfo debug_info);

// Returns the number of dimensions used to represent the tensor on its device.
// The number of dimensions used to reprensent the tensor on device can be
// different from the number returned by TFE_TensorHandleNumDims.
// The return value was current at the time of TFE_TensorDebugInfo creation.
public static native int TFE_TensorDebugInfoOnDeviceNumDims(
    TFE_TensorDebugInfo debug_info);

// Returns the number of elements in dimension `dim_index`.
// Tensor representation on device can be transposed from its representation
// on host. The data contained in dimension `dim_index` on device
// can correspond to the data contained in another dimension in on-host
// representation. The dimensions are indexed using the standard TensorFlow
// major-to-minor order (slowest varying dimension first),
// not the XLA's minor-to-major order.
// On-device dimensions can be padded. TFE_TensorDebugInfoOnDeviceDim returns
// the number of elements in a dimension after padding.
// The return value was current at the time of TFE_TensorDebugInfo creation.
public static native @Cast("int64_t") long TFE_TensorDebugInfoOnDeviceDim(
    TFE_TensorDebugInfo debug_info, int dim_index);

// Description of the TensorFlow op to execute.
//
// Assumes that the provided 'ctx' outlives the returned TFE_Op, i.e.,
// TFE_DeleteOp() is called before TFE_DeleteContext().
//
// Very similar to TF_OperationDescription with some differences:
// (1) TF_Output or TFE_TensorHandle* as arguments to TF_AddInput,
//     TF_AddInputList
// (2) TF_ColocateWith, TF_AddControlInput etc. do not make sense.
// (3) Implementation detail: Avoid use of NodeBuilder/NodeDefBuilder since
//     the additional sanity checks there seem unnecessary;

public static native TFE_Op TFE_NewOp(TFE_Context ctx,
                                        @Cast("const char*") BytePointer op_or_function_name,
                                        TF_Status status);
public static native TFE_Op TFE_NewOp(TFE_Context ctx,
                                        String op_or_function_name,
                                        TF_Status status);

public static native void TFE_DeleteOp(TFE_Op op);

public static native void TFE_OpSetDevice(TFE_Op op, @Cast("const char*") BytePointer device_name,
                                           TF_Status status);
public static native void TFE_OpSetDevice(TFE_Op op, String device_name,
                                           TF_Status status);
// The returned string remains valid throughout the lifetime of 'op'.
public static native @Cast("const char*") BytePointer TFE_OpGetDevice(TFE_Op op,
                                                  TF_Status status);

// When 'enable' is set to 1, and if TensorFlow library is built with XLA
// support, a subsequent TFE_Execute() call on `op` will run the op via XLA.
//
// If the library is not built with XLA support, this call would be a no-op.
public static native void TFE_OpSetXLACompilation(TFE_Op op,
                                                   @Cast("unsigned char") byte enable);

public static native void TFE_OpAddInput(TFE_Op op, TFE_TensorHandle input,
                                          TF_Status status);

public static native void TFE_OpAddInputList(TFE_Op op,
                                              @Cast("TFE_TensorHandle**") PointerPointer inputs,
                                              int num_inputs,
                                              TF_Status status);
public static native void TFE_OpAddInputList(TFE_Op op,
                                              @ByPtrPtr TFE_TensorHandle inputs,
                                              int num_inputs,
                                              TF_Status status);

public static native @Cast("TF_AttrType") int TFE_OpGetAttrType(TFE_Op op,
                                                    @Cast("const char*") BytePointer attr_name,
                                                    @Cast("unsigned char*") BytePointer is_list,
                                                    TF_Status status);
public static native @Cast("TF_AttrType") int TFE_OpGetAttrType(TFE_Op op,
                                                    String attr_name,
                                                    @Cast("unsigned char*") ByteBuffer is_list,
                                                    TF_Status status);
public static native @Cast("TF_AttrType") int TFE_OpGetAttrType(TFE_Op op,
                                                    @Cast("const char*") BytePointer attr_name,
                                                    @Cast("unsigned char*") byte[] is_list,
                                                    TF_Status status);
public static native @Cast("TF_AttrType") int TFE_OpGetAttrType(TFE_Op op,
                                                    String attr_name,
                                                    @Cast("unsigned char*") BytePointer is_list,
                                                    TF_Status status);
public static native @Cast("TF_AttrType") int TFE_OpGetAttrType(TFE_Op op,
                                                    @Cast("const char*") BytePointer attr_name,
                                                    @Cast("unsigned char*") ByteBuffer is_list,
                                                    TF_Status status);
public static native @Cast("TF_AttrType") int TFE_OpGetAttrType(TFE_Op op,
                                                    String attr_name,
                                                    @Cast("unsigned char*") byte[] is_list,
                                                    TF_Status status);
// Get an attribute type given an op name; a fusion of TFE_NewOp and
// TFE_OpGetAttrType for use from Python without the overhead of the individual
// calls and memory management of TFE_Op.
public static native @Cast("TF_AttrType") int TFE_OpNameGetAttrType(
    TFE_Context ctx, @Cast("const char*") BytePointer op_or_function_name, @Cast("const char*") BytePointer attr_name,
    @Cast("unsigned char*") BytePointer is_list, TF_Status status);
public static native @Cast("TF_AttrType") int TFE_OpNameGetAttrType(
    TFE_Context ctx, String op_or_function_name, String attr_name,
    @Cast("unsigned char*") ByteBuffer is_list, TF_Status status);
public static native @Cast("TF_AttrType") int TFE_OpNameGetAttrType(
    TFE_Context ctx, @Cast("const char*") BytePointer op_or_function_name, @Cast("const char*") BytePointer attr_name,
    @Cast("unsigned char*") byte[] is_list, TF_Status status);
public static native @Cast("TF_AttrType") int TFE_OpNameGetAttrType(
    TFE_Context ctx, String op_or_function_name, String attr_name,
    @Cast("unsigned char*") BytePointer is_list, TF_Status status);
public static native @Cast("TF_AttrType") int TFE_OpNameGetAttrType(
    TFE_Context ctx, @Cast("const char*") BytePointer op_or_function_name, @Cast("const char*") BytePointer attr_name,
    @Cast("unsigned char*") ByteBuffer is_list, TF_Status status);
public static native @Cast("TF_AttrType") int TFE_OpNameGetAttrType(
    TFE_Context ctx, String op_or_function_name, String attr_name,
    @Cast("unsigned char*") byte[] is_list, TF_Status status);

public static native void TFE_OpSetAttrString(TFE_Op op,
                                               @Cast("const char*") BytePointer attr_name,
                                               @Const Pointer value,
                                               @Cast("size_t") long length);
public static native void TFE_OpSetAttrString(TFE_Op op,
                                               String attr_name,
                                               @Const Pointer value,
                                               @Cast("size_t") long length);
public static native void TFE_OpSetAttrInt(TFE_Op op, @Cast("const char*") BytePointer attr_name,
                                            @Cast("int64_t") long value);
public static native void TFE_OpSetAttrInt(TFE_Op op, String attr_name,
                                            @Cast("int64_t") long value);
public static native void TFE_OpSetAttrFloat(TFE_Op op, @Cast("const char*") BytePointer attr_name,
                                              float value);
public static native void TFE_OpSetAttrFloat(TFE_Op op, String attr_name,
                                              float value);
public static native void TFE_OpSetAttrBool(TFE_Op op, @Cast("const char*") BytePointer attr_name,
                                             @Cast("unsigned char") byte value);
public static native void TFE_OpSetAttrBool(TFE_Op op, String attr_name,
                                             @Cast("unsigned char") byte value);
public static native void TFE_OpSetAttrType(TFE_Op op, @Cast("const char*") BytePointer attr_name,
                                             @Cast("TF_DataType") int value);
public static native void TFE_OpSetAttrType(TFE_Op op, String attr_name,
                                             @Cast("TF_DataType") int value);
// If the number of dimensions is unknown, `num_dims` must be set to
// -1 and `dims` can be null.  If a dimension is unknown, the
// corresponding entry in the `dims` array must be -1.
public static native void TFE_OpSetAttrShape(TFE_Op op, @Cast("const char*") BytePointer attr_name,
                                              @Cast("const int64_t*") LongPointer dims,
                                              int num_dims,
                                              TF_Status out_status);
public static native void TFE_OpSetAttrShape(TFE_Op op, String attr_name,
                                              @Cast("const int64_t*") LongBuffer dims,
                                              int num_dims,
                                              TF_Status out_status);
public static native void TFE_OpSetAttrShape(TFE_Op op, @Cast("const char*") BytePointer attr_name,
                                              @Cast("const int64_t*") long[] dims,
                                              int num_dims,
                                              TF_Status out_status);
public static native void TFE_OpSetAttrShape(TFE_Op op, String attr_name,
                                              @Cast("const int64_t*") LongPointer dims,
                                              int num_dims,
                                              TF_Status out_status);
public static native void TFE_OpSetAttrShape(TFE_Op op, @Cast("const char*") BytePointer attr_name,
                                              @Cast("const int64_t*") LongBuffer dims,
                                              int num_dims,
                                              TF_Status out_status);
public static native void TFE_OpSetAttrShape(TFE_Op op, String attr_name,
                                              @Cast("const int64_t*") long[] dims,
                                              int num_dims,
                                              TF_Status out_status);

// Sets the attribute attr_name to be a function specified by 'function'.
//
// TODO(ashankar,iga): Add this functionality to the C API for graph
// construction. Perhaps we want an AttrValueMap equivalent in the C API?
public static native void TFE_OpSetAttrFunction(TFE_Op op,
                                                 @Cast("const char*") BytePointer attr_name,
                                                 @Const TFE_Op value);
public static native void TFE_OpSetAttrFunction(TFE_Op op,
                                                 String attr_name,
                                                 @Const TFE_Op value);

public static native void TFE_OpSetAttrFunctionName(TFE_Op op, @Cast("const char*") BytePointer attr_name,
                                              @Cast("const char*") BytePointer data, @Cast("size_t") long length);
public static native void TFE_OpSetAttrFunctionName(TFE_Op op, String attr_name,
                                              String data, @Cast("size_t") long length);

public static native void TFE_OpSetAttrTensor(TFE_Op op,
                                               @Cast("const char*") BytePointer attr_name,
                                               TF_Tensor tensor,
                                               TF_Status status);
public static native void TFE_OpSetAttrTensor(TFE_Op op,
                                               String attr_name,
                                               TF_Tensor tensor,
                                               TF_Status status);

public static native void TFE_OpSetAttrStringList(TFE_Op op,
                                                   @Cast("const char*") BytePointer attr_name,
                                                   @Cast("const void*const*") PointerPointer values,
                                                   @Cast("const size_t*") SizeTPointer lengths,
                                                   int num_values);
public static native void TFE_OpSetAttrStringList(TFE_Op op,
                                                   @Cast("const char*") BytePointer attr_name,
                                                   @Cast("const void*const*") @ByPtrPtr Pointer values,
                                                   @Cast("const size_t*") SizeTPointer lengths,
                                                   int num_values);
public static native void TFE_OpSetAttrStringList(TFE_Op op,
                                                   String attr_name,
                                                   @Cast("const void*const*") @ByPtrPtr Pointer values,
                                                   @Cast("const size_t*") SizeTPointer lengths,
                                                   int num_values);
public static native void TFE_OpSetAttrIntList(TFE_Op op,
                                                @Cast("const char*") BytePointer attr_name,
                                                @Cast("const int64_t*") LongPointer values,
                                                int num_values);
public static native void TFE_OpSetAttrIntList(TFE_Op op,
                                                String attr_name,
                                                @Cast("const int64_t*") LongBuffer values,
                                                int num_values);
public static native void TFE_OpSetAttrIntList(TFE_Op op,
                                                @Cast("const char*") BytePointer attr_name,
                                                @Cast("const int64_t*") long[] values,
                                                int num_values);
public static native void TFE_OpSetAttrIntList(TFE_Op op,
                                                String attr_name,
                                                @Cast("const int64_t*") LongPointer values,
                                                int num_values);
public static native void TFE_OpSetAttrIntList(TFE_Op op,
                                                @Cast("const char*") BytePointer attr_name,
                                                @Cast("const int64_t*") LongBuffer values,
                                                int num_values);
public static native void TFE_OpSetAttrIntList(TFE_Op op,
                                                String attr_name,
                                                @Cast("const int64_t*") long[] values,
                                                int num_values);
public static native void TFE_OpSetAttrFloatList(TFE_Op op,
                                                  @Cast("const char*") BytePointer attr_name,
                                                  @Const FloatPointer values,
                                                  int num_values);
public static native void TFE_OpSetAttrFloatList(TFE_Op op,
                                                  String attr_name,
                                                  @Const FloatBuffer values,
                                                  int num_values);
public static native void TFE_OpSetAttrFloatList(TFE_Op op,
                                                  @Cast("const char*") BytePointer attr_name,
                                                  @Const float[] values,
                                                  int num_values);
public static native void TFE_OpSetAttrFloatList(TFE_Op op,
                                                  String attr_name,
                                                  @Const FloatPointer values,
                                                  int num_values);
public static native void TFE_OpSetAttrFloatList(TFE_Op op,
                                                  @Cast("const char*") BytePointer attr_name,
                                                  @Const FloatBuffer values,
                                                  int num_values);
public static native void TFE_OpSetAttrFloatList(TFE_Op op,
                                                  String attr_name,
                                                  @Const float[] values,
                                                  int num_values);
public static native void TFE_OpSetAttrBoolList(TFE_Op op,
                                                 @Cast("const char*") BytePointer attr_name,
                                                 @Cast("const unsigned char*") BytePointer values,
                                                 int num_values);
public static native void TFE_OpSetAttrBoolList(TFE_Op op,
                                                 String attr_name,
                                                 @Cast("const unsigned char*") ByteBuffer values,
                                                 int num_values);
public static native void TFE_OpSetAttrBoolList(TFE_Op op,
                                                 @Cast("const char*") BytePointer attr_name,
                                                 @Cast("const unsigned char*") byte[] values,
                                                 int num_values);
public static native void TFE_OpSetAttrBoolList(TFE_Op op,
                                                 String attr_name,
                                                 @Cast("const unsigned char*") BytePointer values,
                                                 int num_values);
public static native void TFE_OpSetAttrBoolList(TFE_Op op,
                                                 @Cast("const char*") BytePointer attr_name,
                                                 @Cast("const unsigned char*") ByteBuffer values,
                                                 int num_values);
public static native void TFE_OpSetAttrBoolList(TFE_Op op,
                                                 String attr_name,
                                                 @Cast("const unsigned char*") byte[] values,
                                                 int num_values);
public static native void TFE_OpSetAttrTypeList(TFE_Op op,
                                                 @Cast("const char*") BytePointer attr_name,
                                                 @Cast("const TF_DataType*") IntPointer values,
                                                 int num_values);
public static native void TFE_OpSetAttrTypeList(TFE_Op op,
                                                 String attr_name,
                                                 @Cast("const TF_DataType*") IntBuffer values,
                                                 int num_values);
public static native void TFE_OpSetAttrTypeList(TFE_Op op,
                                                 @Cast("const char*") BytePointer attr_name,
                                                 @Cast("const TF_DataType*") int[] values,
                                                 int num_values);
public static native void TFE_OpSetAttrTypeList(TFE_Op op,
                                                 String attr_name,
                                                 @Cast("const TF_DataType*") IntPointer values,
                                                 int num_values);
public static native void TFE_OpSetAttrTypeList(TFE_Op op,
                                                 @Cast("const char*") BytePointer attr_name,
                                                 @Cast("const TF_DataType*") IntBuffer values,
                                                 int num_values);
public static native void TFE_OpSetAttrTypeList(TFE_Op op,
                                                 String attr_name,
                                                 @Cast("const TF_DataType*") int[] values,
                                                 int num_values);
public static native void TFE_OpSetAttrShapeList(
    TFE_Op op, @Cast("const char*") BytePointer attr_name, @Cast("const int64_t**") PointerPointer dims,
    @Const IntPointer num_dims, int num_values, TF_Status out_status);
public static native void TFE_OpSetAttrShapeList(
    TFE_Op op, @Cast("const char*") BytePointer attr_name, @Cast("const int64_t**") @ByPtrPtr LongPointer dims,
    @Const IntPointer num_dims, int num_values, TF_Status out_status);
public static native void TFE_OpSetAttrShapeList(
    TFE_Op op, String attr_name, @Cast("const int64_t**") @ByPtrPtr LongBuffer dims,
    @Const IntBuffer num_dims, int num_values, TF_Status out_status);
public static native void TFE_OpSetAttrShapeList(
    TFE_Op op, @Cast("const char*") BytePointer attr_name, @Cast("const int64_t**") @ByPtrPtr long[] dims,
    @Const int[] num_dims, int num_values, TF_Status out_status);
public static native void TFE_OpSetAttrShapeList(
    TFE_Op op, String attr_name, @Cast("const int64_t**") @ByPtrPtr LongPointer dims,
    @Const IntPointer num_dims, int num_values, TF_Status out_status);
public static native void TFE_OpSetAttrShapeList(
    TFE_Op op, @Cast("const char*") BytePointer attr_name, @Cast("const int64_t**") @ByPtrPtr LongBuffer dims,
    @Const IntBuffer num_dims, int num_values, TF_Status out_status);
public static native void TFE_OpSetAttrShapeList(
    TFE_Op op, String attr_name, @Cast("const int64_t**") @ByPtrPtr long[] dims,
    @Const int[] num_dims, int num_values, TF_Status out_status);
public static native void TFE_OpSetAttrFunctionList(TFE_Op op,
                                                     @Cast("const char*") BytePointer attr_name,
                                                     @Cast("const TFE_Op**") PointerPointer value,
                                                     int num_values);
public static native void TFE_OpSetAttrFunctionList(TFE_Op op,
                                                     @Cast("const char*") BytePointer attr_name,
                                                     @Const @ByPtrPtr TFE_Op value,
                                                     int num_values);
public static native void TFE_OpSetAttrFunctionList(TFE_Op op,
                                                     String attr_name,
                                                     @Const @ByPtrPtr TFE_Op value,
                                                     int num_values);

// Returns the length (number of tensors) of the input argument `input_name`
// found in the provided `op`.
public static native int TFE_OpGetInputLength(TFE_Op op,
                                               @Cast("const char*") BytePointer input_name,
                                               TF_Status status);
public static native int TFE_OpGetInputLength(TFE_Op op,
                                               String input_name,
                                               TF_Status status);

// Returns the length (number of tensors) of the output argument `output_name`
// found in the provided `op`.
public static native int TFE_OpGetOutputLength(TFE_Op op,
                                                @Cast("const char*") BytePointer output_name,
                                                TF_Status status);
public static native int TFE_OpGetOutputLength(TFE_Op op,
                                                String output_name,
                                                TF_Status status);

// Execute the operation defined by 'op' and return handles to computed
// tensors in `retvals`.
//
// 'retvals' must point to a pre-allocated array of TFE_TensorHandle* and
// '*num_retvals' should be set to the size of this array. It is an error if
// the size of 'retvals' is less than the number of outputs. This call sets
// *num_retvals to the number of outputs.
//
// If async execution is enabled, the call may simply enqueue the execution
// and return "non-ready" handles in `retvals`. Note that any handles contained
// in 'op' should not be mutated till the kernel execution actually finishes.
//
// For sync execution, if any of the inputs to `op` are not ready, this call
// will block till they become ready and then return when the kernel execution
// is done.
// TODO(agarwal): change num_retvals to int from int*.
public static native void TFE_Execute(TFE_Op op, @Cast("TFE_TensorHandle**") PointerPointer retvals,
                                       IntPointer num_retvals, TF_Status status);
public static native void TFE_Execute(TFE_Op op, @ByPtrPtr TFE_TensorHandle retvals,
                                       IntPointer num_retvals, TF_Status status);
public static native void TFE_Execute(TFE_Op op, @ByPtrPtr TFE_TensorHandle retvals,
                                       IntBuffer num_retvals, TF_Status status);
public static native void TFE_Execute(TFE_Op op, @ByPtrPtr TFE_TensorHandle retvals,
                                       int[] num_retvals, TF_Status status);

// Add a function (serialized FunctionDef protocol buffer) to ctx so
// that it can be invoked using TFE_Execute.
public static native void TFE_ContextAddFunctionDef(
    TFE_Context ctx, @Cast("const char*") BytePointer serialized_function_def, @Cast("size_t") long size,
    TF_Status status);
public static native void TFE_ContextAddFunctionDef(
    TFE_Context ctx, String serialized_function_def, @Cast("size_t") long size,
    TF_Status status);

// Adds a function (created from TF_GraphToFunction or
// TF_FunctionImportFunctionDef) to the context, allowing it to be executed with
// TFE_Execute by creating an op with the same name as the function.
public static native void TFE_ContextAddFunction(TFE_Context ctx,
                                                  TF_Function function,
                                                  TF_Status status);

// Removes a function from the context. Once removed, you can no longer
// TFE_Execute it or TFE_Execute any TFE_Op which has it as an attribute or any
// other function which calls it as an attribute.
public static native void TFE_ContextRemoveFunction(TFE_Context ctx,
                                                     @Cast("const char*") BytePointer name,
                                                     TF_Status status);
public static native void TFE_ContextRemoveFunction(TFE_Context ctx,
                                                     String name,
                                                     TF_Status status);

// Checks whether a function is registered under `name`.
public static native @Cast("unsigned char") byte TFE_ContextHasFunction(TFE_Context ctx,
                                                    @Cast("const char*") BytePointer name);
public static native @Cast("unsigned char") byte TFE_ContextHasFunction(TFE_Context ctx,
                                                    String name);

// Enables tracing of RunMetadata on the ops executed from this context.
public static native void TFE_ContextEnableRunMetadata(TFE_Context ctx);

// Disables tracing of RunMetadata on the ops executed from this context.
public static native void TFE_ContextDisableRunMetadata(TFE_Context ctx);

// Populates the passed-in buffer with a serialized RunMetadata protocol buffer
// containing any run metadata information accumulated so far and clears this
// information.
// If async mode is enabled, this call blocks till all currently pending ops are
// done.
public static native void TFE_ContextExportRunMetadata(TFE_Context ctx,
                                                        TF_Buffer buf,
                                                        TF_Status status);

// Some TF ops need a step container to be set to limit the lifetime of some
// resources (mostly TensorArray and Stack, used in while loop gradients in
// graph mode). Calling this on a context tells it to start a step.
public static native void TFE_ContextStartStep(TFE_Context ctx);

// Ends a step. When there is no active step (that is, every started step has
// been ended) step containers will be cleared. Note: it is not safe to call
// TFE_ContextEndStep while ops which rely on the step container may be running.
public static native void TFE_ContextEndStep(TFE_Context ctx);

// #ifdef __cplusplus /* end extern "C" */
// #endif

// #ifdef __cplusplus
// A workaround to ease conversion to and from numpy objects and
// TFE_TensorHandle's.
//
// TODO(ashankar): Figure out an alternative scheme that precludes the need for
// these API-boundary breaking methods.
  // namespace tensorflow

public static native TFE_TensorHandle TFE_NewTensorHandle(@Const @ByRef Tensor t,
                                      TF_Status status);
// #endif

// #endif  // TENSORFLOW_C_EAGER_C_API_H_


// Parsed from tensorflow/c/eager/c_api_internal.h

/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
// #ifndef TENSORFLOW_C_EAGER_C_API_INTERNAL_H_
// #define TENSORFLOW_C_EAGER_C_API_INTERNAL_H_

// #include <algorithm>
// #include <cstddef>
// #include <map>
// #include <memory>
// #include <queue>
// #include <string>
// #include <vector>

// #include "tensorflow/c/c_api.h"
// #include "tensorflow/c/c_api_internal.h"
// #include "tensorflow/c/eager/c_api.h"
// #include "tensorflow/c/eager/c_api_experimental.h"
// #include "tensorflow/core/common_runtime/device_factory.h"
// #include "tensorflow/core/common_runtime/eager/attr_builder.h"
// #include "tensorflow/core/common_runtime/eager/context.h"
// #include "tensorflow/core/common_runtime/eager/eager_executor.h"
// #include "tensorflow/core/common_runtime/eager/eager_operation.h"
// #include "tensorflow/core/common_runtime/eager/kernel_and_device.h"
// #include "tensorflow/core/common_runtime/eager/tensor_handle.h"
// #include "tensorflow/core/common_runtime/function.h"
// #include "tensorflow/core/common_runtime/rendezvous_mgr.h"
// #include "tensorflow/core/framework/cancellation.h"
// #include "tensorflow/core/framework/rendezvous.h"
// #include "tensorflow/core/lib/core/errors.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/lib/gtl/inlined_vector.h"
// #include "tensorflow/core/lib/gtl/map_util.h"
// #include "tensorflow/core/lib/gtl/stl_util.h"
// #include "tensorflow/core/lib/monitoring/counter.h"
// #include "tensorflow/core/lib/monitoring/gauge.h"
// #include "tensorflow/core/lib/monitoring/sampler.h"
// #include "tensorflow/core/platform/mutex.h"
// #include "tensorflow/core/platform/thread_annotations.h"
// #include "tensorflow/core/profiler/lib/profiler_session.h"
// #include "tensorflow/core/public/version.h"
// Targeting ../TFE_ContextOptions.java


// Targeting ../TFE_Context.java


// Targeting ../TFE_TensorHandle.java


// Targeting ../TFE_TensorDebugInfo.java


// Targeting ../TFE_OpInferenceContext.java


// Targeting ../TFE_Op.java


// Targeting ../TFE_Profiler.java


// Targeting ../TFE_MonitoringCounterCell.java


// Targeting ../TFE_MonitoringCounter0.java


// Targeting ../TFE_MonitoringCounter1.java


// Targeting ../TFE_MonitoringCounter2.java


// Targeting ../TFE_MonitoringIntGaugeCell.java


// Targeting ../TFE_MonitoringStringGaugeCell.java


// Targeting ../TFE_MonitoringBoolGaugeCell.java


// Targeting ../TFE_MonitoringIntGauge0.java


// Targeting ../TFE_MonitoringIntGauge1.java


// Targeting ../TFE_MonitoringIntGauge2.java


// Targeting ../TFE_MonitoringStringGauge0.java


// Targeting ../TFE_MonitoringStringGauge1.java


// Targeting ../TFE_MonitoringStringGauge2.java


// Targeting ../TFE_MonitoringBoolGauge0.java


// Targeting ../TFE_MonitoringBoolGauge1.java


// Targeting ../TFE_MonitoringBoolGauge2.java


// Targeting ../TFE_MonitoringBuckets.java


// Targeting ../TFE_MonitoringSamplerCell.java


// Targeting ../TFE_MonitoringSampler0.java


// Targeting ../TFE_MonitoringSampler1.java


// Targeting ../TFE_MonitoringSampler2.java


// Set an AttrValue on the op. Doesn't handle the list types.
@Namespace("tensorflow") public static native void SetOpAttrValueScalar(TFE_Context ctx, TFE_Op op,
                          @Const @ByRef AttrValue default_value,
                          @Cast("const char*") BytePointer attr_name, TF_Status status);
@Namespace("tensorflow") public static native void SetOpAttrValueScalar(TFE_Context ctx, TFE_Op op,
                          @Const @ByRef AttrValue default_value,
                          String attr_name, TF_Status status);

// Targeting ../TFE_TraceContext.java


// Targeting ../TFE_CancellationManager.java


// Targeting ../TFE_Executor.java



// #endif  // TENSORFLOW_C_EAGER_C_API_INTERNAL_H_


// Parsed from tensorflow/c/python_api.h

/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_C_PYTHON_API_H_
// #define TENSORFLOW_C_PYTHON_API_H_

// #include <string>

// #include "tensorflow/c/c_api.h"

// These functions can be removed without notice. They exist to facilitate some
// refactoring of graph construction code in the Python API.

@Namespace("tensorflow") public static native void AddControlInput(TF_Graph graph, TF_Operation op, TF_Operation input);

// Changes an attr value in the node_def Protocol Buffer and sets a status upon
// completion.
@Namespace("tensorflow") public static native void SetAttr(TF_Graph graph, TF_Operation op, @Cast("const char*") BytePointer attr_name,
             TF_Buffer attr_value_proto, TF_Status status);
@Namespace("tensorflow") public static native void SetAttr(TF_Graph graph, TF_Operation op, String attr_name,
             TF_Buffer attr_value_proto, TF_Status status);

// Clears the attr in the node_def Protocol Buffer and sets a status upon
// completion.
@Namespace("tensorflow") public static native void ClearAttr(TF_Graph graph, TF_Operation op, @Cast("const char*") BytePointer attr_name,
               TF_Status status);
@Namespace("tensorflow") public static native void ClearAttr(TF_Graph graph, TF_Operation op, String attr_name,
               TF_Status status);

@Namespace("tensorflow") public static native void SetRequestedDevice(TF_Graph graph, TF_Operation op, @Cast("const char*") BytePointer device);
@Namespace("tensorflow") public static native void SetRequestedDevice(TF_Graph graph, TF_Operation op, String device);

// Updates 'dst' to consume 'new_src'.
@Namespace("tensorflow") public static native void UpdateEdge(TF_Graph graph, @ByVal TF_Output new_src, @ByVal TF_Input dst,
                TF_Status status);

@Namespace("tensorflow") public static native void RemoveAllControlInputs(TF_Graph graph, TF_Operation op);

// Sets whether ops missing a shape inference function should trigger an
// error. The default is true.
@Namespace("tensorflow") public static native void SetRequireShapeInferenceFns(TF_Graph graph, @Cast("bool") boolean require);

// Extends `session` with any new operations added to its associated graph.
// Usually this happens automatically in TF_SessionRun. After this is called,
// TF_SessionRun will no longer extend the session on every call.
//
// We expose this here to allow fine-grained synchronization in multi-threaded
// workloads, which is required since the Python implementation depends on the
// above mutation methods. This allows us to prevent modifications to nodes in
// the graph after the session has been made aware of them.
@Namespace("tensorflow") public static native void ExtendSession(TF_Session session, TF_Status status);

// Returns the serialized CppShapeInferenceResult::HandleData proto for
// `output` if its a resource or variant tensor, or otherwise returns the empty
// string.
@Namespace("tensorflow") public static native @StdString BytePointer GetHandleShapeAndType(TF_Graph graph, @ByVal TF_Output output);

// Sets `output` based on `proto`, which should be a serialized
// CppShapeInferenceResult::HandleData proto. `output` should be a resource
// or variant tensor.
// NOTE(skyewm): `proto` is passed a void*/size_t pair instead of a std::string
// because I couldn't get SWIG to work otherwise.
@Namespace("tensorflow") public static native void SetHandleShapeAndType(TF_Graph graph, @ByVal TF_Output output, @Const Pointer proto,
                           @Cast("size_t") long proto_len, TF_Status status);

// This method is used to add a new input edge to 'dst', which must be a While
// op. The While op's "T" attribute must have already been updated to include
// the new edge. This is used to construct tf.while_loop gradients.
@Namespace("tensorflow") public static native void AddWhileInputHack(TF_Graph graph, @ByVal TF_Output new_src, TF_Operation dst,
                       TF_Status status);

  // namespace tensorflow

// #endif  // TENSORFLOW_C_PYTHON_API_H_


// Parsed from tensorflow/cc/ops/standard_ops.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CC_OPS_STANDARD_OPS_H_
// #define TENSORFLOW_CC_OPS_STANDARD_OPS_H_

// #include "tensorflow/cc/ops/array_ops.h"
// #include "tensorflow/cc/ops/candidate_sampling_ops.h"
// #include "tensorflow/cc/ops/const_op.h"
// #include "tensorflow/cc/ops/control_flow_ops.h"
// #include "tensorflow/cc/ops/data_flow_ops.h"
// #include "tensorflow/cc/ops/image_ops.h"
// #include "tensorflow/cc/ops/io_ops.h"
// #include "tensorflow/cc/ops/linalg_ops.h"
// #include "tensorflow/cc/ops/logging_ops.h"
// #include "tensorflow/cc/ops/lookup_ops.h"
// #include "tensorflow/cc/ops/math_ops.h"
// #include "tensorflow/cc/ops/nn_ops.h"
// #include "tensorflow/cc/ops/no_op.h"
// #include "tensorflow/cc/ops/parsing_ops.h"
// #include "tensorflow/cc/ops/random_ops.h"
// #include "tensorflow/cc/ops/sparse_ops.h"
// #include "tensorflow/cc/ops/state_ops.h"
// #include "tensorflow/cc/ops/string_ops.h"
// #include "tensorflow/cc/ops/training_ops.h"
// #include "tensorflow/cc/ops/user_ops.h"

// #endif  // TENSORFLOW_CC_OPS_STANDARD_OPS_H_


// Parsed from tensorflow/cc/ops/const_op.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CC_OPS_CONST_OP_H_
// #define TENSORFLOW_CC_OPS_CONST_OP_H_

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/graph/node_builder.h"

/** \defgroup const_op Const Op
 *  \{ */

@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, @Const @ByRef Input.Initializer val);
@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, @ByRef Tensor val);
@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, byte val);
@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, short val);
@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, int val);
@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, long val);
@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, float val);
@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, double val);
@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, boolean val);
@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, @StdString String val);
@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, @StdString BytePointer val);

@Namespace("tensorflow::ops") public static native @ByVal Output ConstFromProto(@Const @ByRef Scope scope, @Const @ByRef TensorProto proto);

@Namespace("tensorflow::ops") public static native @ByVal NodeBuilder.NodeOut AsNodeOut(@Const @ByRef Scope scope, @Const @ByRef Input inp);

@Namespace("tensorflow::ops") public static native @ByVal @Name("Const<unsigned char>") Output Const(@Const @ByRef Scope scope, @Cast("const unsigned char") byte v, @Const @ByVal TensorShape shape);

@Namespace("tensorflow::ops") public static native @ByVal @Name("Const<short>") Output Const(@Const @ByRef Scope scope, short v, @Const @ByVal TensorShape shape);

@Namespace("tensorflow::ops") public static native @ByVal @Name("Const<int>") Output Const(@Const @ByRef Scope scope, int v, @Const @ByVal TensorShape shape);

@Namespace("tensorflow::ops") public static native @ByVal @Name("Const<long long>") Output Const(@Const @ByRef Scope scope, @Cast("const long long") long v, @Const @ByVal TensorShape shape);

@Namespace("tensorflow::ops") public static native @ByVal @Name("Const<float>") Output Const(@Const @ByRef Scope scope, float v, @Const @ByVal TensorShape shape);

@Namespace("tensorflow::ops") public static native @ByVal @Name("Const<double>") Output Const(@Const @ByRef Scope scope, double v, @Const @ByVal TensorShape shape);

@Namespace("tensorflow::ops") public static native @ByVal @Name("Const<bool>") Output Const(@Const @ByRef Scope scope, @Cast("const bool") boolean v, @Const @ByVal TensorShape shape);

@Namespace("tensorflow::ops") public static native @ByVal @Name("Const<std::string>") Output Const(@Const @ByRef Scope scope, @StdString BytePointer v, @Const @ByVal TensorShape shape);
@Namespace("tensorflow::ops") public static native @ByVal @Name("Const<std::string>") Output Const(@Const @ByRef Scope scope, @StdString String v, @Const @ByVal TensorShape shape);

@Namespace("tensorflow::ops") public static native @ByVal NodeOutVector AsNodeOutList(@Const @ByRef Scope scope,
                                                @Const @ByRef InputList inp);

/** }\ */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_CONST_OP_H_


// Parsed from tensorflow/cc/ops/array_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_ARRAY_OPS_H_
// #define TENSORFLOW_CC_OPS_ARRAY_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../BatchToSpace.java


// Targeting ../BatchToSpaceND.java


// Targeting ../Bitcast.java


// Targeting ../BroadcastDynamicShape.java


// Targeting ../BroadcastTo.java


// Targeting ../CheckNumerics.java


// Targeting ../Concat.java


// Targeting ../ConjugateTranspose.java


// Targeting ../DebugGradientIdentity.java


// Targeting ../DebugGradientRefIdentity.java


// Targeting ../DeepCopy.java


// Targeting ../DepthToSpace.java


// Targeting ../Dequantize.java


// Targeting ../Diag.java


// Targeting ../DiagPart.java


// Targeting ../EditDistance.java


// Targeting ../Empty.java


// Targeting ../EnsureShape.java


// Targeting ../ExpandDims.java


// Targeting ../ExtractImagePatches.java


// Targeting ../ExtractVolumePatches.java


// Targeting ../FakeQuantWithMinMaxArgs.java


// Targeting ../FakeQuantWithMinMaxArgsGradient.java


// Targeting ../FakeQuantWithMinMaxVars.java


// Targeting ../FakeQuantWithMinMaxVarsGradient.java


// Targeting ../FakeQuantWithMinMaxVarsPerChannel.java


// Targeting ../FakeQuantWithMinMaxVarsPerChannelGradient.java


// Targeting ../Fill.java


// Targeting ../Fingerprint.java


// Targeting ../Gather.java


// Targeting ../GatherNd.java


// Targeting ../GatherV2.java


// Targeting ../GuaranteeConst.java


// Targeting ../Identity.java


// Targeting ../IdentityN.java


// Targeting ../ImmutableConst.java


// Targeting ../InplaceAdd.java


// Targeting ../InplaceSub.java


// Targeting ../InplaceUpdate.java


// Targeting ../InvertPermutation.java


// Targeting ../SetDiff1D.java


// Targeting ../MatrixBandPart.java


// Targeting ../MatrixDiag.java


// Targeting ../MatrixDiagPart.java


// Targeting ../MatrixDiagPartV2.java


// Targeting ../MatrixDiagV2.java


// Targeting ../MatrixSetDiag.java


// Targeting ../MatrixSetDiagV2.java


// Targeting ../MirrorPad.java


// Targeting ../OneHot.java


// Targeting ../OnesLike.java


// Targeting ../Stack.java


// Targeting ../Pad.java


// Targeting ../PadV2.java


// Targeting ../ParallelConcat.java


// Targeting ../Placeholder.java


// Targeting ../PlaceholderWithDefault.java


// Targeting ../PreventGradient.java


// Targeting ../QuantizeAndDequantizeV2.java


// Targeting ../QuantizeAndDequantizeV3.java


// Targeting ../QuantizeV2.java


// Targeting ../QuantizedConcat.java


// Targeting ../QuantizedInstanceNorm.java


// Targeting ../QuantizedReshape.java


// Targeting ../Rank.java


// Targeting ../Reshape.java


// Targeting ../ResourceStridedSliceAssign.java


// Targeting ../ReverseSequence.java


// Targeting ../Reverse.java


// Targeting ../ScatterNd.java


// Targeting ../ScatterNdNonAliasingAdd.java



/** Returns the shape of a tensor.
 * 
 *  This operation returns a 1-D integer tensor representing the shape of {@code input}.
 * 
 *  For example:
 * 
 *  <pre>{@code
 *  # 't' is [[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]]
 *  shape(t) ==> [2, 2, 3]
 *  }</pre>
 * 
 *  Arguments:
 *  * scope: A Scope object
 * 
 *  Returns:
 *  * {@code Output}: The output tensor. */
// Targeting ../ShapeN.java


// Targeting ../Size.java


// Targeting ../Slice.java


// Targeting ../Snapshot.java


// Targeting ../SpaceToBatch.java


// Targeting ../SpaceToBatchND.java


// Targeting ../SpaceToDepth.java


// Targeting ../Split.java


// Targeting ../SplitV.java


// Targeting ../Squeeze.java


// Targeting ../StopGradient.java


// Targeting ../StridedSlice.java


// Targeting ../StridedSliceAssign.java


// Targeting ../StridedSliceGrad.java


// Targeting ../TensorScatterAdd.java


// Targeting ../TensorScatterSub.java


// Targeting ../TensorScatterUpdate.java


// Targeting ../TensorStridedSliceUpdate.java


// Targeting ../Tile.java


// Targeting ../Transpose.java


// Targeting ../Unique.java


// Targeting ../UniqueV2.java


// Targeting ../UniqueWithCounts.java


// Targeting ../UniqueWithCountsV2.java


// Targeting ../Unstack.java


// Targeting ../UnravelIndex.java


// Targeting ../Where.java


// Targeting ../ZerosLike.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_ARRAY_OPS_H_


// Parsed from tensorflow/cc/ops/audio_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_AUDIO_OPS_H_
// #define TENSORFLOW_CC_OPS_AUDIO_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../AudioSpectrogram.java


// Targeting ../DecodeWav.java


// Targeting ../EncodeWav.java


// Targeting ../Mfcc.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_AUDIO_OPS_H_


// Parsed from tensorflow/cc/ops/candidate_sampling_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_CANDIDATE_SAMPLING_OPS_H_
// #define TENSORFLOW_CC_OPS_CANDIDATE_SAMPLING_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../AllCandidateSampler.java


// Targeting ../ComputeAccidentalHits.java


// Targeting ../FixedUnigramCandidateSampler.java


// Targeting ../LearnedUnigramCandidateSampler.java


// Targeting ../LogUniformCandidateSampler.java


// Targeting ../UniformCandidateSampler.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_CANDIDATE_SAMPLING_OPS_H_


// Parsed from tensorflow/cc/ops/control_flow_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_CONTROL_FLOW_OPS_H_
// #define TENSORFLOW_CC_OPS_CONTROL_FLOW_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../Abort.java


// Targeting ../ControlTrigger.java


// Targeting ../LoopCond.java


// Targeting ../Merge.java


// Targeting ../NextIteration.java


// Targeting ../RefNextIteration.java


// Targeting ../RefSelect.java


// Targeting ../RefSwitch.java


// Targeting ../Switch.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_CONTROL_FLOW_OPS_H_


// Parsed from tensorflow/cc/ops/data_flow_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_DATA_FLOW_OPS_H_
// #define TENSORFLOW_CC_OPS_DATA_FLOW_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../AccumulatorApplyGradient.java


// Targeting ../AccumulatorNumAccumulated.java


// Targeting ../AccumulatorSetGlobalStep.java


// Targeting ../AccumulatorTakeGradient.java


// Targeting ../Barrier.java


// Targeting ../BarrierClose.java


// Targeting ../BarrierIncompleteSize.java


// Targeting ../BarrierInsertMany.java


// Targeting ../BarrierReadySize.java


// Targeting ../BarrierTakeMany.java


// Targeting ../ConditionalAccumulator.java


// Targeting ../DeleteSessionTensor.java


// Targeting ../DynamicPartition.java


// Targeting ../DynamicStitch.java


// Targeting ../FIFOQueue.java


// Targeting ../GetSessionHandle.java


// Targeting ../GetSessionHandleV2.java


// Targeting ../GetSessionTensor.java


// Targeting ../MapClear.java


// Targeting ../MapIncompleteSize.java


// Targeting ../MapPeek.java


// Targeting ../MapSize.java


// Targeting ../MapStage.java


// Targeting ../MapUnstage.java


// Targeting ../MapUnstageNoKey.java


// Targeting ../OrderedMapClear.java


// Targeting ../OrderedMapIncompleteSize.java


// Targeting ../OrderedMapPeek.java


// Targeting ../OrderedMapSize.java


// Targeting ../OrderedMapStage.java


// Targeting ../OrderedMapUnstage.java


// Targeting ../OrderedMapUnstageNoKey.java


// Targeting ../PaddingFIFOQueue.java


// Targeting ../ParallelDynamicStitch.java


// Targeting ../PriorityQueue.java


// Targeting ../QueueClose.java


// Targeting ../QueueDequeueMany.java


// Targeting ../QueueDequeueUpTo.java


// Targeting ../QueueDequeue.java


// Targeting ../QueueEnqueueMany.java


// Targeting ../QueueEnqueue.java


// Targeting ../QueueIsClosed.java


// Targeting ../QueueIsClosedV2.java


// Targeting ../QueueSize.java


// Targeting ../RandomShuffleQueue.java


// Targeting ../RecordInput.java


// Targeting ../SparseAccumulatorApplyGradient.java


// Targeting ../SparseAccumulatorTakeGradient.java


// Targeting ../SparseConditionalAccumulator.java


// Targeting ../Stage.java


// Targeting ../StageClear.java


// Targeting ../StagePeek.java


// Targeting ../StageSize.java


// Targeting ../TensorArrayClose.java


// Targeting ../TensorArrayConcat.java


// Targeting ../TensorArrayGather.java


// Targeting ../TensorArrayGrad.java


// Targeting ../TensorArrayGradWithShape.java


// Targeting ../TensorArrayRead.java


// Targeting ../TensorArrayScatter.java


// Targeting ../TensorArraySize.java


// Targeting ../TensorArraySplit.java


// Targeting ../TensorArray.java


// Targeting ../TensorArrayWrite.java


// Targeting ../Unstage.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_DATA_FLOW_OPS_H_


// Parsed from tensorflow/cc/ops/image_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_IMAGE_OPS_H_
// #define TENSORFLOW_CC_OPS_IMAGE_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../AdjustContrast.java


// Targeting ../AdjustHue.java


// Targeting ../AdjustSaturation.java


// Targeting ../CombinedNonMaxSuppression.java


// Targeting ../CropAndResize.java


// Targeting ../CropAndResizeGradBoxes.java


// Targeting ../CropAndResizeGradImage.java


// Targeting ../DecodeAndCropJpeg.java


// Targeting ../DecodeBmp.java


// Targeting ../DecodeGif.java


// Targeting ../DecodeJpeg.java


// Targeting ../DecodePng.java


// Targeting ../DrawBoundingBoxes.java


// Targeting ../DrawBoundingBoxesV2.java


// Targeting ../EncodeJpeg.java


// Targeting ../EncodeJpegVariableQuality.java


// Targeting ../EncodePng.java


// Targeting ../ExtractGlimpse.java


// Targeting ../ExtractJpegShape.java


// Targeting ../HSVToRGB.java


// Targeting ../NonMaxSuppression.java


// Targeting ../NonMaxSuppressionV2.java


// Targeting ../NonMaxSuppressionV3.java


// Targeting ../NonMaxSuppressionV4.java


// Targeting ../NonMaxSuppressionV5.java


// Targeting ../NonMaxSuppressionWithOverlaps.java


// Targeting ../QuantizedResizeBilinear.java


// Targeting ../RGBToHSV.java


// Targeting ../ResizeArea.java


// Targeting ../ResizeBicubic.java


// Targeting ../ResizeBilinear.java


// Targeting ../ResizeNearestNeighbor.java


// Targeting ../SampleDistortedBoundingBox.java


// Targeting ../SampleDistortedBoundingBoxV2.java


// Targeting ../ScaleAndTranslate.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_IMAGE_OPS_H_


// Parsed from tensorflow/cc/ops/io_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_IO_OPS_H_
// #define TENSORFLOW_CC_OPS_IO_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../FixedLengthRecordReader.java


// Targeting ../IdentityReader.java


// Targeting ../LMDBReader.java


// Targeting ../MatchingFiles.java


// Targeting ../MergeV2Checkpoints.java


// Targeting ../ReadFile.java


// Targeting ../ReaderNumRecordsProduced.java


// Targeting ../ReaderNumWorkUnitsCompleted.java


// Targeting ../ReaderReadUpTo.java


// Targeting ../ReaderRead.java


// Targeting ../ReaderReset.java


// Targeting ../ReaderRestoreState.java


// Targeting ../ReaderSerializeState.java


// Targeting ../Restore.java


// Targeting ../RestoreSlice.java


// Targeting ../RestoreV2.java


// Targeting ../Save.java


// Targeting ../SaveSlices.java


// Targeting ../SaveV2.java


// Targeting ../ShardedFilename.java


// Targeting ../ShardedFilespec.java


// Targeting ../TFRecordReader.java


// Targeting ../TextLineReader.java


// Targeting ../WholeFileReader.java


// Targeting ../WriteFile.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_IO_OPS_H_


// Parsed from tensorflow/cc/ops/linalg_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_LINALG_OPS_H_
// #define TENSORFLOW_CC_OPS_LINALG_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../Cholesky.java


// Targeting ../CholeskyGrad.java


// Targeting ../Einsum.java


// Targeting ../LogMatrixDeterminant.java


// Targeting ../Lu.java


// Targeting ../MatrixDeterminant.java


// Targeting ../MatrixInverse.java


// Targeting ../MatrixSolve.java


// Targeting ../MatrixSolveLs.java


// Targeting ../MatrixSquareRoot.java


// Targeting ../MatrixTriangularSolve.java


// Targeting ../Qr.java


// Targeting ../SelfAdjointEig.java


// Targeting ../Svd.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_LINALG_OPS_H_


// Parsed from tensorflow/cc/ops/list_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_LIST_OPS_H_
// #define TENSORFLOW_CC_OPS_LIST_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../EmptyTensorList.java


// Targeting ../TensorListConcat.java


// Targeting ../TensorListConcatLists.java


// Targeting ../TensorListConcatV2.java


// Targeting ../TensorListElementShape.java


// Targeting ../TensorListFromTensor.java


// Targeting ../TensorListGather.java


// Targeting ../TensorListGetItem.java


// Targeting ../TensorListLength.java


// Targeting ../TensorListPopBack.java


// Targeting ../TensorListPushBack.java


// Targeting ../TensorListPushBackBatch.java


// Targeting ../TensorListReserve.java


// Targeting ../TensorListResize.java


// Targeting ../TensorListScatter.java


// Targeting ../TensorListScatterIntoExistingList.java


// Targeting ../TensorListScatterV2.java


// Targeting ../TensorListSetItem.java


// Targeting ../TensorListSplit.java


// Targeting ../TensorListStack.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_LIST_OPS_H_


// Parsed from tensorflow/cc/ops/logging_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_LOGGING_OPS_H_
// #define TENSORFLOW_CC_OPS_LOGGING_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../Assert.java


// Targeting ../AudioSummary.java


// Targeting ../HistogramSummary.java


// Targeting ../ImageSummary.java


// Targeting ../MergeSummary.java


// Targeting ../Print.java


// Targeting ../PrintV2.java


// Targeting ../ScalarSummary.java


// Targeting ../TensorSummary.java


// Targeting ../TensorSummaryV2.java


// Targeting ../Timestamp.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_LOGGING_OPS_H_


// Parsed from tensorflow/cc/ops/lookup_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_LOOKUP_OPS_H_
// #define TENSORFLOW_CC_OPS_LOOKUP_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../HashTable.java


// Targeting ../InitializeTableFromTextFile.java


// Targeting ../InitializeTable.java


// Targeting ../LookupTableExport.java


// Targeting ../LookupTableFind.java


// Targeting ../LookupTableImport.java


// Targeting ../LookupTableInsert.java


// Targeting ../LookupTableSize.java


// Targeting ../MutableDenseHashTable.java


// Targeting ../MutableHashTableOfTensors.java


// Targeting ../MutableHashTable.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_LOOKUP_OPS_H_


// Parsed from tensorflow/cc/ops/manip_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_MANIP_OPS_H_
// #define TENSORFLOW_CC_OPS_MANIP_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../Roll.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_MANIP_OPS_H_


// Parsed from tensorflow/cc/ops/math_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_MATH_OPS_H_
// #define TENSORFLOW_CC_OPS_MATH_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../Abs.java


// Targeting ../AccumulateNV2.java


// Targeting ../Acos.java


// Targeting ../Acosh.java


// Targeting ../Add.java


// Targeting ../AddN.java


// Targeting ../AddV2.java


// Targeting ../All.java



///
///
///
///
///
///
///
// Targeting ../Angle.java


// Targeting ../Any.java



///
///
// Targeting ../ApproximateEqual.java


// Targeting ../ArgMax.java


// Targeting ../ArgMin.java


// Targeting ../Asin.java


// Targeting ../Asinh.java


// Targeting ../Atan.java


// Targeting ../Atan2.java


// Targeting ../Atanh.java


// Targeting ../BatchMatMul.java


// Targeting ../BatchMatMulV2.java


// Targeting ../BesselI0e.java


// Targeting ../BesselI1e.java


// Targeting ../Betainc.java


// Targeting ../Bincount.java


// Targeting ../Bucketize.java


// Targeting ../CastOp.java


// Targeting ../Ceil.java


// Targeting ../ClipByValue.java


// Targeting ../CompareAndBitpack.java


// Targeting ../Complex.java


// Targeting ../ComplexAbs.java


// Targeting ../Conj.java


// Targeting ../Cos.java


// Targeting ../Cosh.java


// Targeting ../Cross.java


// Targeting ../Cumprod.java


// Targeting ../Cumsum.java


// Targeting ../Digamma.java


// Targeting ../Div.java


// Targeting ../DivNoNan.java


// Targeting ../Equal.java


// Targeting ../Erf.java


// Targeting ../Erfc.java


// Targeting ../EuclideanNorm.java


// Targeting ../Exp.java


// Targeting ../Expm1.java


// Targeting ../Floor.java


// Targeting ../FloorDiv.java


// Targeting ../FloorMod.java


// Targeting ../Greater.java


// Targeting ../GreaterEqual.java


// Targeting ../HistogramFixedWidth.java


// Targeting ../Igamma.java


// Targeting ../Igammac.java


// Targeting ../Imag.java


// Targeting ../Inv.java


// Targeting ../IsFinite.java


// Targeting ../IsInf.java


// Targeting ../IsNan.java


// Targeting ../Less.java


// Targeting ../LessEqual.java


// Targeting ../Lgamma.java


// Targeting ../LinSpace.java


// Targeting ../Log.java


// Targeting ../Log1p.java


// Targeting ../LogicalAnd.java


// Targeting ../LogicalNot.java


// Targeting ../LogicalOr.java


// Targeting ../MatMul.java


// Targeting ../Max.java



///
///
///
// Targeting ../Maximum.java


// Targeting ../Mean.java



///
///
///
///
///
// Targeting ../Min.java



///
///
///
// Targeting ../Minimum.java


// Targeting ../Mod.java


// Targeting ../Multiply.java



///
///
///
// Targeting ../MulNoNan.java


// Targeting ../Negate.java



///
///
///
///
///
// Targeting ../NextAfter.java


// Targeting ../NotEqual.java


// Targeting ../Polygamma.java


// Targeting ../Pow.java


// Targeting ../Prod.java



///
///
///
///
///
///
// Targeting ../QuantizeDownAndShrinkRange.java


// Targeting ../QuantizedAdd.java


// Targeting ../QuantizedMatMul.java


// Targeting ../QuantizedMul.java


// Targeting ../Range.java


// Targeting ../Real.java


// Targeting ../RealDiv.java


// Targeting ../Reciprocal.java


// Targeting ../RequantizationRange.java


// Targeting ../Requantize.java


// Targeting ../Rint.java


// Targeting ../Round.java


// Targeting ../Rsqrt.java


// Targeting ../SegmentMax.java


// Targeting ../SegmentMean.java


// Targeting ../SegmentMin.java


// Targeting ../SegmentProd.java


// Targeting ../SegmentSum.java


// Targeting ../Where3.java


// Targeting ../SelectV2.java


// Targeting ../Sigmoid.java


// Targeting ../Sign.java


// Targeting ../Sin.java


// Targeting ../Sinh.java


// Targeting ../SparseMatMul.java


// Targeting ../SparseSegmentMean.java


// Targeting ../SparseSegmentMeanGrad.java


// Targeting ../SparseSegmentMeanWithNumSegments.java


// Targeting ../SparseSegmentSqrtN.java


// Targeting ../SparseSegmentSqrtNGrad.java


// Targeting ../SparseSegmentSqrtNWithNumSegments.java


// Targeting ../SparseSegmentSum.java


// Targeting ../SparseSegmentSumWithNumSegments.java


// Targeting ../Sqrt.java


// Targeting ../Square.java


// Targeting ../SquaredDifference.java


// Targeting ../Subtract.java



///
///
///
///
///
// Targeting ../Sum.java



///
///
///
///
// Targeting ../Tan.java


// Targeting ../Tanh.java


// Targeting ../TruncateDiv.java


// Targeting ../TruncateMod.java


// Targeting ../UnsortedSegmentMax.java


// Targeting ../UnsortedSegmentMin.java


// Targeting ../UnsortedSegmentProd.java


// Targeting ../UnsortedSegmentSum.java


// Targeting ../Xdivy.java


// Targeting ../Xlogy.java


// Targeting ../Zeta.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_MATH_OPS_H_


// Parsed from tensorflow/cc/ops/nn_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_NN_OPS_H_
// #define TENSORFLOW_CC_OPS_NN_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../AvgPool.java


// Targeting ../AvgPool3D.java


// Targeting ../AvgPool3DGrad.java


// Targeting ../BiasAdd.java


// Targeting ../BiasAddGrad.java


// Targeting ../Conv2D.java


// Targeting ../Conv2DBackpropFilter.java


// Targeting ../Conv2DBackpropInput.java


// Targeting ../Conv3D.java


// Targeting ../Conv3DBackpropFilterV2.java


// Targeting ../Conv3DBackpropInputV2.java


// Targeting ../DataFormatDimMap.java


// Targeting ../DataFormatVecPermute.java


// Targeting ../DepthwiseConv2dNative.java


// Targeting ../DepthwiseConv2dNativeBackpropFilter.java


// Targeting ../DepthwiseConv2dNativeBackpropInput.java


// Targeting ../Dilation2D.java


// Targeting ../Dilation2DBackpropFilter.java


// Targeting ../Dilation2DBackpropInput.java


// Targeting ../Elu.java


// Targeting ../FractionalAvgPool.java


// Targeting ../FractionalMaxPool.java


// Targeting ../FusedBatchNorm.java


// Targeting ../FusedBatchNormGrad.java


// Targeting ../FusedBatchNormGradV2.java


// Targeting ../FusedBatchNormGradV3.java


// Targeting ../FusedBatchNormV2.java


// Targeting ../FusedBatchNormV3.java


// Targeting ../FusedPadConv2D.java


// Targeting ../FusedResizeAndPadConv2D.java


// Targeting ../InTopK.java


// Targeting ../InTopKV2.java


// Targeting ../L2Loss.java


// Targeting ../LRN.java


// Targeting ../LogSoftmax.java


// Targeting ../MaxPool.java


// Targeting ../MaxPool3D.java


// Targeting ../MaxPool3DGrad.java


// Targeting ../MaxPool3DGradGrad.java


// Targeting ../MaxPoolGradGrad.java


// Targeting ../MaxPoolGradGradV2.java


// Targeting ../MaxPoolGradGradWithArgmax.java


// Targeting ../MaxPoolGradV2.java


// Targeting ../MaxPoolV2.java


// Targeting ../MaxPoolWithArgmax.java


// Targeting ../NthElement.java


// Targeting ../QuantizedAvgPool.java


// Targeting ../QuantizedBatchNormWithGlobalNormalization.java


// Targeting ../QuantizedBiasAdd.java


// Targeting ../QuantizedConv2D.java


// Targeting ../QuantizedMaxPool.java


// Targeting ../QuantizedRelu.java


// Targeting ../QuantizedRelu6.java


// Targeting ../QuantizedReluX.java


// Targeting ../Relu.java


// Targeting ../Relu6.java


// Targeting ../Selu.java


// Targeting ../Softmax.java


// Targeting ../SoftmaxCrossEntropyWithLogits.java


// Targeting ../Softplus.java


// Targeting ../Softsign.java


// Targeting ../SparseSoftmaxCrossEntropyWithLogits.java


// Targeting ../TopK.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_NN_OPS_H_


// Parsed from tensorflow/cc/ops/nn_ops_internal.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_NN_OPS_INTERNAL_H_
// #define TENSORFLOW_CC_OPS_NN_OPS_INTERNAL_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../AvgPoolGrad.java


// Targeting ../EluGrad.java


// Targeting ../FractionalAvgPoolGrad.java


// Targeting ../FractionalMaxPoolGrad.java


// Targeting ../LRNGrad.java


// Targeting ../LeakyRelu.java


// Targeting ../LeakyReluGrad.java


// Targeting ../MaxPoolGrad.java


// Targeting ../MaxPoolGradWithArgmax.java


// Targeting ../QuantizedConv2DAndRelu.java


// Targeting ../QuantizedConv2DAndReluAndRequantize.java


// Targeting ../QuantizedConv2DAndRequantize.java


// Targeting ../QuantizedConv2DPerChannel.java


// Targeting ../QuantizedConv2DWithBias.java


// Targeting ../QuantizedConv2DWithBiasAndRelu.java


// Targeting ../QuantizedConv2DWithBiasAndReluAndRequantize.java


// Targeting ../QuantizedConv2DWithBiasAndRequantize.java


// Targeting ../QuantizedConv2DWithBiasSignedSumAndReluAndRequantize.java


// Targeting ../QuantizedConv2DWithBiasSumAndRelu.java


// Targeting ../QuantizedConv2DWithBiasSumAndReluAndRequantize.java


// Targeting ../QuantizedDepthwiseConv2D.java


// Targeting ../QuantizedDepthwiseConv2DWithBias.java


// Targeting ../QuantizedDepthwiseConv2DWithBiasAndRelu.java


// Targeting ../QuantizedDepthwiseConv2DWithBiasAndReluAndRequantize.java


// Targeting ../QuantizedMatMulWithBias.java


// Targeting ../QuantizedMatMulWithBiasAndRelu.java


// Targeting ../QuantizedMatMulWithBiasAndReluAndRequantize.java


// Targeting ../Relu6Grad.java


// Targeting ../ReluGrad.java


// Targeting ../SeluGrad.java


// Targeting ../SoftplusGrad.java


// Targeting ../SoftsignGrad.java



  // namespace internal
  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_NN_OPS_INTERNAL_H_


// Parsed from tensorflow/cc/ops/no_op.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_NO_OP_H_
// #define TENSORFLOW_CC_OPS_NO_OP_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../NoOp.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_NO_OP_H_


// Parsed from tensorflow/cc/ops/parsing_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_PARSING_OPS_H_
// #define TENSORFLOW_CC_OPS_PARSING_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../DecodeCSV.java


// Targeting ../DecodeCompressed.java


// Targeting ../DecodeJSONExample.java


// Targeting ../DecodePaddedRaw.java


// Targeting ../DecodeRaw.java


// Targeting ../ParseExample.java


// Targeting ../ParseSequenceExample.java


// Targeting ../ParseSingleExample.java


// Targeting ../ParseSingleSequenceExample.java


// Targeting ../ParseTensor.java


// Targeting ../SerializeTensor.java


// Targeting ../StringToNumber.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_PARSING_OPS_H_


// Parsed from tensorflow/cc/ops/random_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_RANDOM_OPS_H_
// #define TENSORFLOW_CC_OPS_RANDOM_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../Multinomial.java


// Targeting ../ParameterizedTruncatedNormal.java


// Targeting ../RandomGamma.java


// Targeting ../RandomPoissonV2.java


// Targeting ../RandomShuffle.java


// Targeting ../RandomNormal.java


// Targeting ../RandomUniform.java


// Targeting ../RandomUniformInt.java


// Targeting ../TruncatedNormal.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_RANDOM_OPS_H_


// Parsed from tensorflow/cc/ops/sparse_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_SPARSE_OPS_H_
// #define TENSORFLOW_CC_OPS_SPARSE_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../AddManySparseToTensorsMap.java


// Targeting ../AddSparseToTensorsMap.java


// Targeting ../DeserializeManySparse.java


// Targeting ../DeserializeSparse.java


// Targeting ../SerializeManySparse.java


// Targeting ../SerializeSparse.java


// Targeting ../SparseAdd.java


// Targeting ../SparseAddGrad.java


// Targeting ../SparseConcat.java


// Targeting ../SparseCross.java


// Targeting ../SparseDenseCwiseAdd.java


// Targeting ../SparseDenseCwiseDiv.java


// Targeting ../SparseDenseCwiseMul.java


// Targeting ../SparseFillEmptyRows.java


// Targeting ../SparseFillEmptyRowsGrad.java


// Targeting ../SparseReduceMax.java


// Targeting ../SparseReduceMaxSparse.java


// Targeting ../SparseReduceSum.java


// Targeting ../SparseReduceSumSparse.java


// Targeting ../SparseReorder.java


// Targeting ../SparseReshape.java


// Targeting ../SparseSlice.java


// Targeting ../SparseSliceGrad.java


// Targeting ../SparseSoftmax.java


// Targeting ../SparseSparseMaximum.java


// Targeting ../SparseSparseMinimum.java


// Targeting ../SparseSplit.java


// Targeting ../SparseTensorDenseAdd.java


// Targeting ../SparseTensorDenseMatMul.java


// Targeting ../SparseToDense.java


// Targeting ../TakeManySparseFromTensorsMap.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_SPARSE_OPS_H_


// Parsed from tensorflow/cc/ops/state_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_STATE_OPS_H_
// #define TENSORFLOW_CC_OPS_STATE_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../Assign.java


// Targeting ../AssignAdd.java


// Targeting ../AssignSub.java


// Targeting ../CountUpTo.java


// Targeting ../DestroyTemporaryVariable.java


// Targeting ../IsVariableInitialized.java


// Targeting ../ResourceCountUpTo.java


// Targeting ../ResourceScatterNdAdd.java


// Targeting ../ResourceScatterNdSub.java


// Targeting ../ResourceScatterNdUpdate.java


// Targeting ../ScatterAdd.java


// Targeting ../ScatterDiv.java


// Targeting ../ScatterMax.java


// Targeting ../ScatterMin.java


// Targeting ../ScatterMul.java


// Targeting ../ScatterNdAdd.java


// Targeting ../ScatterNdSub.java


// Targeting ../ScatterNdUpdate.java


// Targeting ../ScatterSub.java


// Targeting ../ScatterUpdate.java


// Targeting ../TemporaryVariable.java


// Targeting ../Variable.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_STATE_OPS_H_


// Parsed from tensorflow/cc/ops/string_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_STRING_OPS_H_
// #define TENSORFLOW_CC_OPS_STRING_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../AsString.java


// Targeting ../DecodeBase64.java


// Targeting ../EncodeBase64.java


// Targeting ../ReduceJoin.java


// Targeting ../RegexFullMatch.java


// Targeting ../RegexReplace.java


// Targeting ../StringFormat.java


// Targeting ../StringJoin.java


// Targeting ../StringLength.java


// Targeting ../StringLower.java


// Targeting ../StringNGrams.java


// Targeting ../StringSplit.java


// Targeting ../StringSplitV2.java


// Targeting ../StringStrip.java


// Targeting ../StringToHashBucket.java


// Targeting ../StringToHashBucketFast.java


// Targeting ../StringToHashBucketStrong.java


// Targeting ../StringUpper.java


// Targeting ../Substr.java


// Targeting ../UnicodeScript.java


// Targeting ../UnicodeTranscode.java


// Targeting ../UnsortedSegmentJoin.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_STRING_OPS_H_


// Parsed from tensorflow/cc/ops/training_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_TRAINING_OPS_H_
// #define TENSORFLOW_CC_OPS_TRAINING_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../ApplyAdadelta.java


// Targeting ../ApplyAdagrad.java


// Targeting ../ApplyAdagradDA.java


// Targeting ../ApplyAdam.java


// Targeting ../ApplyAddSign.java


// Targeting ../ApplyCenteredRMSProp.java


// Targeting ../ApplyFtrl.java


// Targeting ../ApplyFtrlV2.java


// Targeting ../ApplyGradientDescent.java


// Targeting ../ApplyMomentum.java


// Targeting ../ApplyPowerSign.java


// Targeting ../ApplyProximalAdagrad.java


// Targeting ../ApplyProximalGradientDescent.java


// Targeting ../ApplyRMSProp.java


// Targeting ../ResourceApplyAdadelta.java


// Targeting ../ResourceApplyAdagrad.java


// Targeting ../ResourceApplyAdagradDA.java


// Targeting ../ResourceApplyAdam.java


// Targeting ../ResourceApplyAdamWithAmsgrad.java


// Targeting ../ResourceApplyAddSign.java


// Targeting ../ResourceApplyCenteredRMSProp.java


// Targeting ../ResourceApplyFtrl.java


// Targeting ../ResourceApplyFtrlV2.java


// Targeting ../ResourceApplyGradientDescent.java


// Targeting ../ResourceApplyKerasMomentum.java


// Targeting ../ResourceApplyMomentum.java


// Targeting ../ResourceApplyPowerSign.java


// Targeting ../ResourceApplyProximalAdagrad.java


// Targeting ../ResourceApplyProximalGradientDescent.java


// Targeting ../ResourceApplyRMSProp.java


// Targeting ../ResourceSparseApplyAdadelta.java


// Targeting ../ResourceSparseApplyAdagrad.java


// Targeting ../ResourceSparseApplyAdagradDA.java


// Targeting ../ResourceSparseApplyCenteredRMSProp.java


// Targeting ../ResourceSparseApplyFtrl.java


// Targeting ../ResourceSparseApplyFtrlV2.java


// Targeting ../ResourceSparseApplyKerasMomentum.java


// Targeting ../ResourceSparseApplyMomentum.java


// Targeting ../ResourceSparseApplyProximalAdagrad.java


// Targeting ../ResourceSparseApplyProximalGradientDescent.java


// Targeting ../ResourceSparseApplyRMSProp.java


// Targeting ../SparseApplyAdadelta.java


// Targeting ../SparseApplyAdagrad.java


// Targeting ../SparseApplyAdagradDA.java


// Targeting ../SparseApplyCenteredRMSProp.java


// Targeting ../SparseApplyFtrl.java


// Targeting ../SparseApplyFtrlV2.java


// Targeting ../SparseApplyMomentum.java


// Targeting ../SparseApplyProximalAdagrad.java


// Targeting ../SparseApplyProximalGradientDescent.java


// Targeting ../SparseApplyRMSProp.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_TRAINING_OPS_H_


// Parsed from tensorflow/cc/ops/user_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_USER_OPS_H_
// #define TENSORFLOW_CC_OPS_USER_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../Fact.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_USER_OPS_H_


}
