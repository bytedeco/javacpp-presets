// Targeted by JavaCPP version 1.5-SNAPSHOT: DO NOT EDIT THIS FILE

package org.bytedeco.tensorflow.global;

import org.bytedeco.tensorflow.*;

import org.bytedeco.tensorflow.Allocator;
import java.nio.*;
import org.bytedeco.javacpp.*;
import org.bytedeco.javacpp.annotation.*;

public class tensorflow extends org.bytedeco.tensorflow.presets.tensorflow {
    static { Loader.load(); }

// Targeting ../AllocatorAttributesVector.java


// Targeting ../AllocRecordVector.java


// Targeting ../DeviceContextInlinedVector.java


// Targeting ../DeviceTypeVector.java


// Targeting ../TensorValueVector.java


// Targeting ../WrappedAllocatorVector.java


// Targeting ../LongVector.java


// Targeting ../DataTypeVector.java


// Targeting ../StringStringMap.java


// Targeting ../StringIntMap.java


// Targeting ../IntStringMap.java


// Targeting ../StringFeatureMap.java


// Targeting ../StringFeatureListMap.java


// Targeting ../StringCollectionDefMap.java


// Targeting ../StringSignatureDefMap.java


// Targeting ../StringTensorInfoMap.java


// Targeting ../StringAttrValueMap.java


// Targeting ../NameRangeMap.java


// Targeting ../TF_SessionStringMap.java


// Targeting ../StringList.java


// Targeting ../TensorIdTensorIdMap.java


// Targeting ../SafeTensorIdTensorIdMap.java


// Targeting ../StringSet.java


// Targeting ../StringPieceVector.java


// Targeting ../StringVector.java


// Targeting ../IntIntPairVector.java


// Targeting ../StringStringPairVector.java


// Targeting ../DeviceVector.java


// Targeting ../DeviceContextVector.java


// Targeting ../TensorVector.java


// Targeting ../TensorProtoVector.java


// Targeting ../TensorShapeVector.java


// Targeting ../NodeOutVector.java


// Targeting ../NodeVector.java


// Targeting ../NodeIntPairVector.java


// Targeting ../StringAttrPairVector.java


// Targeting ../ConstTensorPtrVector.java


// Targeting ../ConstDimensionPtrVector.java


// Targeting ../StringTensorPairVector.java


// Targeting ../EdgeVector.java


// Targeting ../OpDefVector.java


// Targeting ../OutputVector.java


// Targeting ../LongLongPair.java


// Targeting ../WrappedAllocator.java


// Targeting ../ShapeHandlePair.java


// Targeting ../DimensionHandlePair.java


// Targeting ../EdgeSetBoolPair.java


// Targeting ../StringIntPair.java


// Targeting ../StringPieceIntPair.java


// Targeting ../TensorSlideStringPair.java


// Targeting ../NodeIndexPair.java


// Targeting ../StringSliceInfoMap.java


// Targeting ../VarToShapeMap.java


// Targeting ../VarToDataTypeMap.java


// Targeting ../StringTensorSliceSetMap.java


// Targeting ../StringNodeMap.java


// Targeting ../StringUnorderedSet.java


// Parsed from google/protobuf/arena.h

// Protocol Buffers - Google's data interchange format
// Copyright 2008 Google Inc.  All rights reserved.
// https://developers.google.com/protocol-buffers/
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are
// met:
//
//     * Redistributions of source code must retain the above copyright
// notice, this list of conditions and the following disclaimer.
//     * Redistributions in binary form must reproduce the above
// copyright notice, this list of conditions and the following disclaimer
// in the documentation and/or other materials provided with the
// distribution.
//     * Neither the name of Google Inc. nor the names of its
// contributors may be used to endorse or promote products derived from
// this software without specific prior written permission.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
// "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

// This file defines an Arena allocator for better allocation performance.

// #ifndef GOOGLE_PROTOBUF_ARENA_H__
// #define GOOGLE_PROTOBUF_ARENA_H__

// #include <limits>
// #ifdef max
// #undef max  // Visual Studio defines this macro
// #endif
// #if defined(_MSC_VER) && !defined(_LIBCPP_STD_VER) && !_HAS_EXCEPTIONS
// Work around bugs in MSVC <typeinfo> header when _HAS_EXCEPTIONS=0.
// #include <exception>
// #include <typeinfo>

// #else
// #include <typeinfo>
// #endif

// #include <google/protobuf/arena_impl.h>
// #include <google/protobuf/stubs/port.h>
// #include <type_traits>  // defined below

  // namespace protobuf



  // namespace quality_webanswers          // defined below        // defined in message.h




// Targeting ../ArenaStringPtr.java


// Targeting ../LazyField.java

           // defined in lazy_field.h  // defined in repeated_field.h

// Templated cleanup methods.
@Namespace("google::protobuf::internal") public static native void arena_free(Pointer object, @Cast("size_t") long size);


// Targeting ../ArenaOptions.java



// Support for non-RTTI environments. (The metrics hooks API uses type
// information.)
// #ifndef GOOGLE_PROTOBUF_NO_RTTI
// #define RTTI_TYPE_ID(type) (&typeid(type))
// #else
// #define RTTI_TYPE_ID(type) (NULL)
// Targeting ../Arena.java



// Defined above for supporting environments without RTTI.
// #undef RTTI_TYPE_ID

  // namespace protobuf

  // namespace google
// #endif  // GOOGLE_PROTOBUF_ARENA_H__


// Parsed from google/protobuf/message_lite.h

// Protocol Buffers - Google's data interchange format
// Copyright 2008 Google Inc.  All rights reserved.
// https://developers.google.com/protocol-buffers/
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are
// met:
//
//     * Redistributions of source code must retain the above copyright
// notice, this list of conditions and the following disclaimer.
//     * Redistributions in binary form must reproduce the above
// copyright notice, this list of conditions and the following disclaimer
// in the documentation and/or other materials provided with the
// distribution.
//     * Neither the name of Google Inc. nor the names of its
// contributors may be used to endorse or promote products derived from
// this software without specific prior written permission.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
// "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

// Authors: wink@google.com (Wink Saville),
//          kenton@google.com (Kenton Varda)
//  Based on original Protocol Buffers design by
//  Sanjay Ghemawat, Jeff Dean, and others.
//
// Defines MessageLite, the abstract interface implemented by all (lite
// and non-lite) protocol message objects.

// #ifndef GOOGLE_PROTOBUF_MESSAGE_LITE_H__
// #define GOOGLE_PROTOBUF_MESSAGE_LITE_H__

// #include <climits>
// #include <google/protobuf/stubs/common.h>
// #include <google/protobuf/stubs/logging.h>
// #include <google/protobuf/stubs/once.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/stubs/port.h>
// Targeting ../CodedInputStream.java


// Targeting ../CodedOutputStream.java


// Targeting ../ZeroCopyInputStream.java


// Targeting ../ZeroCopyOutputStream.java



// Targeting ../RepeatedPtrFieldBase.java


// Targeting ../WireFormatLite.java


// Targeting ../WeakFieldMap.java



// #ifndef SWIG
// #endif  // SWIG

// Targeting ../MessageLite.java





// DO NOT USE: For migration only. Will be removed when Proto3 defaults to
// preserve unknowns.
@Namespace("google::protobuf::internal") public static native @Cast("bool") boolean GetProto3PreserveUnknownsDefault();

// DO NOT USE: For migration only. Will be removed when Proto3 defaults to
// preserve unknowns.
@Namespace("google::protobuf::internal") public static native void SetProto3PreserveUnknownsDefault(@Cast("bool") boolean preserve);
  // namespace internal


  // namespace protobuf

  // namespace google
// #endif  // GOOGLE_PROTOBUF_MESSAGE_LITE_H__


// Parsed from google/protobuf/unknown_field_set.h

// Protocol Buffers - Google's data interchange format
// Copyright 2008 Google Inc.  All rights reserved.
// https://developers.google.com/protocol-buffers/
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are
// met:
//
//     * Redistributions of source code must retain the above copyright
// notice, this list of conditions and the following disclaimer.
//     * Redistributions in binary form must reproduce the above
// copyright notice, this list of conditions and the following disclaimer
// in the documentation and/or other materials provided with the
// distribution.
//     * Neither the name of Google Inc. nor the names of its
// contributors may be used to endorse or promote products derived from
// this software without specific prior written permission.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
// "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

// Author: kenton@google.com (Kenton Varda)
//  Based on original Protocol Buffers design by
//  Sanjay Ghemawat, Jeff Dean, and others.
//
// Contains classes used to keep track of unrecognized fields seen while
// parsing a protocol message.

// #ifndef GOOGLE_PROTOBUF_UNKNOWN_FIELD_SET_H__
// #define GOOGLE_PROTOBUF_UNKNOWN_FIELD_SET_H__

// #include <assert.h>
// #include <string>
// #include <vector>
// #include <google/protobuf/stubs/common.h>
// #include <google/protobuf/stubs/logging.h>
// #include <google/protobuf/message_lite.h>         // coded_stream.h        // coded_stream.h      // zero_copy_stream.h
  
// Targeting ../InternalMetadataWithArena.java


// Targeting ../WireFormat.java


// Targeting ../MessageSetFieldSkipperUsingCord.java


                                    // extension_set_heavy.cc
                        // message.h
// Targeting ../UnknownFieldSet.java


// Targeting ../UnknownField.java



// ===================================================================
// inline implementations











































  // namespace protobuf

  // namespace google
// #endif  // GOOGLE_PROTOBUF_UNKNOWN_FIELD_SET_H__


// Parsed from tensorflow/core/platform/default/integral_types.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_PLATFORM_DEFAULT_INTEGRAL_TYPES_H_
// #define TENSORFLOW_CORE_PLATFORM_DEFAULT_INTEGRAL_TYPES_H_

// IWYU pragma: private, include "third_party/tensorflow/core/platform/types.h"
// IWYU pragma: friend third_party/tensorflow/core/platform/types.h

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_PLATFORM_DEFAULT_INTEGRAL_TYPES_H_


// Parsed from tensorflow/core/lib/bfloat16/bfloat16.h

/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_LIB_BFLOAT16_BFLOAT16_H_
// #define TENSORFLOW_CORE_LIB_BFLOAT16_BFLOAT16_H_

// #include <cmath>
// #include <complex>

// #include "tensorflow/core/platform/byte_order.h"

// #ifdef __CUDACC__
// All functions callable from CUDA code must be qualified with __device__
// #define B16_DEVICE_FUNC __host__ __device__

// #else
// #define B16_DEVICE_FUNC

// #endif


// Single precision complex.
// Double precision complex.
// Targeting ../bfloat16.java



@Namespace("tensorflow") public static native @Cast("std::ostream*") @ByRef @Name("operator <<") Pointer shiftLeft(@Cast("std::ostream*") @ByRef Pointer os,
                                                @Const @ByRef bfloat16 dt);

@Namespace("tensorflow") public static native @ByVal @Name("operator +") bfloat16 add(@ByVal bfloat16 a, @ByVal bfloat16 b);
@Namespace("tensorflow") public static native @ByVal @Name("operator +") bfloat16 add(@ByVal bfloat16 a, int b);
@Namespace("tensorflow") public static native @ByVal @Name("operator +") bfloat16 add(int a, @ByVal bfloat16 b);
@Namespace("tensorflow") public static native @ByVal @Name("operator -") bfloat16 subtract(@ByVal bfloat16 a, @ByVal bfloat16 b);
@Namespace("tensorflow") public static native @ByVal @Name("operator *") bfloat16 multiply(@ByVal bfloat16 a, @ByVal bfloat16 b);
@Namespace("tensorflow") public static native @ByVal @Name("operator /") bfloat16 divide(@ByVal bfloat16 a, @ByVal bfloat16 b);
@Namespace("tensorflow") public static native @ByVal @Name("operator -") bfloat16 subtract(@ByVal bfloat16 a);
@Namespace("tensorflow") public static native @Cast("bool") @Name("operator <") boolean lessThan(@ByVal bfloat16 a, @ByVal bfloat16 b);
@Namespace("tensorflow") public static native @Cast("bool") @Name("operator <=") boolean lessThanEquals(@ByVal bfloat16 a, @ByVal bfloat16 b);
@Namespace("tensorflow") public static native @Cast("bool") @Name("operator ==") boolean equals(@ByVal bfloat16 a, @ByVal bfloat16 b);
@Namespace("tensorflow") public static native @Cast("bool") @Name("operator !=") boolean notEquals(@ByVal bfloat16 a, @ByVal bfloat16 b);
@Namespace("tensorflow") public static native @Cast("bool") @Name("operator >") boolean greaterThan(@ByVal bfloat16 a, @ByVal bfloat16 b);
@Namespace("tensorflow") public static native @Cast("bool") @Name("operator >=") boolean greaterThanEquals(@ByVal bfloat16 a, @ByVal bfloat16 b);
@Namespace("tensorflow") public static native @ByRef @Name("operator +=") bfloat16 addPut(@ByRef bfloat16 a, @ByVal bfloat16 b);
@Namespace("tensorflow") public static native @ByRef @Name("operator -=") bfloat16 subtractPut(@ByRef bfloat16 a, @ByVal bfloat16 b);
@Namespace("tensorflow") public static native @ByVal @Name("operator ++") bfloat16 increment(@ByRef bfloat16 a);
@Namespace("tensorflow") public static native @ByVal @Name("operator --") bfloat16 decrement(@ByRef bfloat16 a);
@Namespace("tensorflow") public static native @ByVal @Name("operator ++") bfloat16 increment(@ByRef bfloat16 a, int arg1);
@Namespace("tensorflow") public static native @ByVal @Name("operator --") bfloat16 decrement(@ByRef bfloat16 a, int arg1);
@Namespace("tensorflow") public static native @ByRef @Name("operator *=") bfloat16 multiplyPut(@ByRef bfloat16 a, @ByVal bfloat16 b);
@Namespace("tensorflow") public static native @ByRef @Name("operator /=") bfloat16 dividePut(@ByRef bfloat16 a, @ByVal bfloat16 b);

// Targeting ../HalfHash.java


@Namespace("std") public static native @Cast("bool") boolean isinf(@Const @ByRef bfloat16 a);
@Namespace("std") public static native @Cast("bool") boolean isnan(@Const @ByRef bfloat16 a);
@Namespace("std") public static native @Cast("bool") boolean isfinite(@Const @ByRef bfloat16 a);
@Namespace("std") public static native @ByVal bfloat16 abs(@Const @ByRef bfloat16 a);
@Namespace("std") public static native @ByVal bfloat16 exp(@Const @ByRef bfloat16 a);
@Namespace("std") public static native @ByVal bfloat16 log(@Const @ByRef bfloat16 a);
@Namespace("std") public static native @ByVal bfloat16 log10(@Const @ByRef bfloat16 a);
@Namespace("std") public static native @ByVal bfloat16 sqrt(@Const @ByRef bfloat16 a);
@Namespace("std") public static native @ByVal bfloat16 pow(@Const @ByRef bfloat16 a, @Const @ByRef bfloat16 b);
@Namespace("std") public static native @ByVal bfloat16 sin(@Const @ByRef bfloat16 a);
@Namespace("std") public static native @ByVal bfloat16 cos(@Const @ByRef bfloat16 a);
@Namespace("std") public static native @ByVal bfloat16 tan(@Const @ByRef bfloat16 a);
@Namespace("std") public static native @ByVal bfloat16 tanh(@Const @ByRef bfloat16 a);
@Namespace("std") public static native @ByVal bfloat16 floor(@Const @ByRef bfloat16 a);
@Namespace("std") public static native @ByVal bfloat16 ceil(@Const @ByRef bfloat16 a);
  // namespace std

// #endif  // TENSORFLOW_CORE_LIB_BFLOAT16_BFLOAT16_H_


// Parsed from tensorflow/core/framework/numeric_types.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_NUMERIC_TYPES_H_
// #define TENSORFLOW_CORE_FRAMEWORK_NUMERIC_TYPES_H_

// #include <complex>
// #include "third_party/eigen3/unsupported/Eigen/CXX11/Tensor"
// Disable clang-format to prevent 'FixedPoint' header from being included
// before 'Tensor' header on which it depends.
// clang-format off
// #include "third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint"
// clang-format on

// #include "tensorflow/core/lib/bfloat16/bfloat16.h"
// #include "tensorflow/core/platform/types.h"

// Single precision complex.
// Double precision complex.

// We use Eigen's QInt implementations for our quantized int types.

  // namespace tensorflow




public static native @ByVal bfloat16 FloatToBFloat16(float float_val);
// Targeting ../bfloat16NumTraits.java



  // namespace numext
  // namespace Eigen

// #if defined(_MSC_VER) && !defined(__clang__)
  // namespace std
// #endif  // _MSC_VER

// #endif  // TENSORFLOW_CORE_FRAMEWORK_NUMERIC_TYPES_H_


// Parsed from tensorflow/core/platform/init_main.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_PLATFORM_INIT_MAIN_H_
// #define TENSORFLOW_CORE_PLATFORM_INIT_MAIN_H_

// Platform-specific initialization routine that should be invoked by a
// main() program that uses TensorFlow.
// This performs necessary initialization on some platforms; TensorFlow
// may not work unless it has been called.
@Namespace("tensorflow::port") public static native void InitMain(@Cast("const char*") BytePointer usage, IntPointer argc, @Cast("char***") @ByPtrPtr PointerPointer argv);
@Namespace("tensorflow::port") public static native void InitMain(String usage, IntBuffer argc, @Cast("char***") @ByPtrPtr PointerPointer argv);
@Namespace("tensorflow::port") public static native void InitMain(@Cast("const char*") BytePointer usage, int[] argc, @Cast("char***") @ByPtrPtr PointerPointer argv);
@Namespace("tensorflow::port") public static native void InitMain(String usage, IntPointer argc, @Cast("char***") @ByPtrPtr PointerPointer argv);
@Namespace("tensorflow::port") public static native void InitMain(@Cast("const char*") BytePointer usage, IntBuffer argc, @Cast("char***") @ByPtrPtr PointerPointer argv);
@Namespace("tensorflow::port") public static native void InitMain(String usage, int[] argc, @Cast("char***") @ByPtrPtr PointerPointer argv);

  // namespace port
  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_PLATFORM_INIT_MAIN_H_


// Parsed from tensorflow/core/platform/types.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_PLATFORM_TYPES_H_
// #define TENSORFLOW_CORE_PLATFORM_TYPES_H_

// #include <string>
// #include "tensorflow/core/platform/platform.h"

// Include appropriate platform-dependent implementations
// #if defined(PLATFORM_GOOGLE) || defined(GOOGLE_INTEGRAL_TYPES)
// #include "tensorflow/core/platform/google/integral_types.h"
// #elif defined(PLATFORM_WINDOWS)
// #include "tensorflow/core/platform/windows/integral_types.h"
// #elif defined(PLATFORM_POSIX) || defined(PLATFORM_POSIX_ANDROID) ||
//     defined(PLATFORM_GOOGLE_ANDROID)
// #include "tensorflow/core/platform/default/integral_types.h"
// #else
// #error Define the appropriate PLATFORM_<foo> macro for this platform
// #endif

// Define tensorflow::string to refer to appropriate platform specific type.
// TODO(josh11b): Move this into the platform/*/integral_types.h files
// above, and rename them platform/*/types.h.
// #if defined(PLATFORM_GOOGLE)
// #else
// #endif

@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::uint8") byte kuint8max();
public static final byte kuint8max = kuint8max();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::uint16") short kuint16max();
public static final short kuint16max = kuint16max();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::uint32") int kuint32max();
public static final int kuint32max = kuint32max();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::uint64") long kuint64max();
public static final long kuint64max = kuint64max();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::int8") byte kint8min();
public static final byte kint8min = kint8min();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::int8") byte kint8max();
public static final byte kint8max = kint8max();
@Namespace("tensorflow") @MemberGetter public static native short kint16min();
public static final short kint16min = kint16min();
@Namespace("tensorflow") @MemberGetter public static native short kint16max();
public static final short kint16max = kint16max();
@Namespace("tensorflow") @MemberGetter public static native int kint32min();
public static final int kint32min = kint32min();
@Namespace("tensorflow") @MemberGetter public static native int kint32max();
public static final int kint32max = kint32max();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::int64") long kint64min();
public static final long kint64min = kint64min();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::int64") long kint64max();
public static final long kint64max = kint64max();

// A typedef for a uint64 used as a short fingerprint.

  // namespace tensorflow

// Alias namespace ::stream_executor as ::tensorflow::se.

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_PLATFORM_TYPES_H_


// Parsed from tensorflow/core/platform/mutex.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_PLATFORM_MUTEX_H_
// #define TENSORFLOW_CORE_PLATFORM_MUTEX_H_

// #include "tensorflow/core/platform/platform.h"
// #include "tensorflow/core/platform/types.h"
/** enum tensorflow::ConditionResult */
public static final int kCond_Timeout = 0, kCond_MaybeNotified = 1;
  // namespace tensorflow

// Include appropriate platform-dependent implementations of mutex etc.
// #if defined(PLATFORM_GOOGLE)
// #elif defined(PLATFORM_POSIX) || defined(PLATFORM_POSIX_ANDROID) ||
//     defined(PLATFORM_GOOGLE_ANDROID) || defined(PLATFORM_WINDOWS)
// #include "tensorflow/core/platform/default/mutex.h"
// #else
// #error Define the appropriate PLATFORM_<foo> macro for this platform
// #endif

// The mutex library included above defines:
//   class mutex;
//   class mutex_lock;
//   class condition_variable;
// It also defines the following:

// Like "cv->wait(*mu)", except that it only waits for up to "ms" milliseconds.
//
// Returns kCond_Timeout if the timeout expired without this
// thread noticing a signal on the condition variable.  Otherwise may
// return either kCond_Timeout or kCond_MaybeNotified
@Namespace("tensorflow") public static native @Cast("tensorflow::ConditionResult") int WaitForMilliseconds(@Cast("tensorflow::mutex_lock*") Pointer mu, @Cast("tensorflow::condition_variable*") Pointer cv,
                                    @Cast("tensorflow::int64") long ms);
  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_PLATFORM_MUTEX_H_


// Parsed from tensorflow/core/platform/macros.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_PLATFORM_MACROS_H_
// #define TENSORFLOW_CORE_PLATFORM_MACROS_H_

// Compiler attributes
// #if (defined(__GNUC__) || defined(__APPLE__)) && !defined(SWIG)
// Compiler supports GCC-style attributes
// #define TF_ATTRIBUTE_NORETURN __attribute__((noreturn))
// #define TF_ATTRIBUTE_ALWAYS_INLINE __attribute__((always_inline))
// #define TF_ATTRIBUTE_NOINLINE __attribute__((noinline))
// #define TF_ATTRIBUTE_UNUSED __attribute__((unused))
// #define TF_ATTRIBUTE_COLD __attribute__((cold))
// #define TF_ATTRIBUTE_WEAK __attribute__((weak))
// #define TF_PACKED __attribute__((packed))
// #define TF_MUST_USE_RESULT __attribute__((warn_unused_result))
// #define TF_PRINTF_ATTRIBUTE(string_index, first_to_check)
//   __attribute__((__format__(__printf__, string_index, first_to_check)))
// #define TF_SCANF_ATTRIBUTE(string_index, first_to_check)
//   __attribute__((__format__(__scanf__, string_index, first_to_check)))
// #elif defined(_MSC_VER)
// Non-GCC equivalents
// #define TF_ATTRIBUTE_NORETURN __declspec(noreturn)
// #define TF_ATTRIBUTE_ALWAYS_INLINE __forceinline
// #define TF_ATTRIBUTE_NOINLINE
// #define TF_ATTRIBUTE_UNUSED
// #define TF_ATTRIBUTE_COLD
// #define TF_ATTRIBUTE_WEAK
// #define TF_MUST_USE_RESULT
// #define TF_PACKED
// #define TF_PRINTF_ATTRIBUTE(string_index, first_to_check)
// #define TF_SCANF_ATTRIBUTE(string_index, first_to_check)
// #else
// Non-GCC equivalents
// #define TF_ATTRIBUTE_NORETURN
// #define TF_ATTRIBUTE_ALWAYS_INLINE
// #define TF_ATTRIBUTE_NOINLINE
// #define TF_ATTRIBUTE_UNUSED
// #define TF_ATTRIBUTE_COLD
// #define TF_ATTRIBUTE_WEAK
// #define TF_MUST_USE_RESULT
// #define TF_PACKED
// #define TF_PRINTF_ATTRIBUTE(string_index, first_to_check)
// #define TF_SCANF_ATTRIBUTE(string_index, first_to_check)
// #endif

// Control visiblity outside .so
// #if defined(_WIN32)
// #ifdef TF_COMPILE_LIBRARY
// #define TF_EXPORT __declspec(dllexport)
// #else
// #define TF_EXPORT __declspec(dllimport)
// #endif  // TF_COMPILE_LIBRARY
// #else
// #define TF_EXPORT __attribute__((visibility("default")))
// #endif  // _WIN32

// #ifdef __has_builtin
// #define TF_HAS_BUILTIN(x) __has_builtin(x)
// #else
// #define TF_HAS_BUILTIN(x) 0
// #endif

// Compilers can be told that a certain branch is not likely to be taken
// (for instance, a CHECK failure), and use that information in static
// analysis. Giving it this information can help it optimize for the
// common case in the absence of better information (ie.
// -fprofile-arcs).
//
// We need to disable this for GPU builds, though, since nvcc8 and older
// don't recognize `__builtin_expect` as a builtin, and fail compilation.
// #if (!defined(__NVCC__)) &&
//     (TF_HAS_BUILTIN(__builtin_expect) || (defined(__GNUC__) && __GNUC__ >= 3))
// #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))
// #define TF_PREDICT_TRUE(x) (__builtin_expect(!!(x), 1))
// #else
// #define TF_PREDICT_FALSE(x) (x)
// #define TF_PREDICT_TRUE(x) (x)
// #endif

// A macro to disallow the copy constructor and operator= functions
// This is usually placed in the private: declarations for a class.
// #define TF_DISALLOW_COPY_AND_ASSIGN(TypeName)
//   TypeName(const TypeName&) = delete;
//   void operator=(const TypeName&) = delete

// The TF_ARRAYSIZE(arr) macro returns the # of elements in an array arr.
//
// The expression TF_ARRAYSIZE(a) is a compile-time constant of type
// size_t.
// #define TF_ARRAYSIZE(a)
//   ((sizeof(a) / sizeof(*(a))) /
//    static_cast<size_t>(!(sizeof(a) % sizeof(*(a)))))

// #if defined(__GXX_EXPERIMENTAL_CXX0X__) || __cplusplus >= 201103L ||
//     (defined(_MSC_VER) && _MSC_VER >= 1900)
// Define this to 1 if the code is compiled in C++11 mode; leave it
// undefined otherwise.  Do NOT define it to 0 -- that causes
// '#ifdef LANG_CXX11' to behave differently from '#if LANG_CXX11'.
public static final int LANG_CXX11 = 1;
// #endif

// #if defined(__clang__) && defined(LANG_CXX11) && defined(__has_warning)
// #if __has_feature(cxx_attributes) && __has_warning("-Wimplicit-fallthrough")
// #define TF_FALLTHROUGH_INTENDED [[clang::fallthrough]]  // NOLINT
// #endif
// #endif

// #ifndef TF_FALLTHROUGH_INTENDED
// #define TF_FALLTHROUGH_INTENDED
//   do {
//   } while (0)
// #endif

// #endif  // TENSORFLOW_CORE_PLATFORM_MACROS_H_


// Parsed from tensorflow/core/util/port.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_UTIL_PORT_H_
// #define TENSORFLOW_CORE_UTIL_PORT_H_

// Returns true if GOOGLE_CUDA is defined.
@Namespace("tensorflow") public static native @Cast("bool") boolean IsGoogleCudaEnabled();

// Returns true if GOOGLE_CUDA is defined, and the given CUDA version supports
// half-precision matrix multiplications and convolution operations.
@Namespace("tensorflow") public static native @Cast("bool") boolean CudaSupportsHalfMatMulAndConv();

// Returns true if INTEL_MKL is defined
@Namespace("tensorflow") public static native @Cast("bool") boolean IsMklEnabled();

  // end namespace tensorflow

// #endif  // TENSORFLOW_CORE_UTIL_PORT_H_


// Parsed from tensorflow/core/lib/core/error_codes.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/lib/core/error_codes.proto

// #ifndef PROTOBUF_INCLUDED_tensorflow_2fcore_2flib_2fcore_2ferror_5fcodes_2eproto
// #define PROTOBUF_INCLUDED_tensorflow_2fcore_2flib_2fcore_2ferror_5fcodes_2eproto

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3006001
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3006001 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/generated_enum_reflection.h>
// @@protoc_insertion_point(includes)
// #define PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_2fcore_2flib_2fcore_2ferror_5fcodes_2eproto
// Targeting ../TableStruct.java


@Namespace("protobuf_tensorflow_2fcore_2flib_2fcore_2ferror_5fcodes_2eproto") public static native void AddDescriptors();
  // namespace protobuf_tensorflow_2fcore_2flib_2fcore_2ferror_5fcodes_2eproto
  // namespace error
  // namespace tensorflow

/** enum tensorflow::error::Code */
public static final int
  OK = 0,
  CANCELLED = 1,
  UNKNOWN = 2,
  INVALID_ARGUMENT = 3,
  DEADLINE_EXCEEDED = 4,
  NOT_FOUND = 5,
  ALREADY_EXISTS = 6,
  PERMISSION_DENIED = 7,
  UNAUTHENTICATED = 16,
  RESOURCE_EXHAUSTED = 8,
  FAILED_PRECONDITION = 9,
  ABORTED = 10,
  OUT_OF_RANGE = 11,
  UNIMPLEMENTED = 12,
  INTERNAL = 13,
  UNAVAILABLE = 14,
  DATA_LOSS = 15,
  DO_NOT_USE_RESERVED_FOR_FUTURE_EXPANSION_USE_DEFAULT_IN_SWITCH_INSTEAD_ = 20,
  Code_INT_MIN_SENTINEL_DO_NOT_USE_ = kint32min,
  Code_INT_MAX_SENTINEL_DO_NOT_USE_ = kint32max;
@Namespace("tensorflow::error") public static native @Cast("bool") boolean Code_IsValid(int value);
@Namespace("tensorflow::error") @MemberGetter public static native @Cast("const tensorflow::error::Code") int Code_MIN();
@Namespace("tensorflow::error") @MemberGetter public static native @Cast("const tensorflow::error::Code") int Code_MAX();
@Namespace("tensorflow::error") @MemberGetter public static native int Code_ARRAYSIZE();

@Namespace("tensorflow::error") public static native @Cast("const google::protobuf::EnumDescriptor*") Pointer Code_descriptor();
@Namespace("tensorflow::error") public static native @StdString BytePointer Code_Name(@Cast("tensorflow::error::Code") int value);
@Namespace("tensorflow::error") public static native @Cast("bool") boolean Code_Parse(
    @StdString BytePointer name, @Cast("tensorflow::error::Code*") IntPointer value);
@Namespace("tensorflow::error") public static native @Cast("bool") boolean Code_Parse(
    @StdString String name, @Cast("tensorflow::error::Code*") IntBuffer value);
@Namespace("tensorflow::error") public static native @Cast("bool") boolean Code_Parse(
    @StdString BytePointer name, @Cast("tensorflow::error::Code*") int... value);
@Namespace("tensorflow::error") public static native @Cast("bool") boolean Code_Parse(
    @StdString String name, @Cast("tensorflow::error::Code*") IntPointer value);
@Namespace("tensorflow::error") public static native @Cast("bool") boolean Code_Parse(
    @StdString BytePointer name, @Cast("tensorflow::error::Code*") IntBuffer value);
@Namespace("tensorflow::error") public static native @Cast("bool") boolean Code_Parse(
    @StdString String name, @Cast("tensorflow::error::Code*") int... value);
// ===================================================================


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__

// @@protoc_insertion_point(namespace_scope)

  // namespace error
  // namespace tensorflow


  // namespace protobuf
  // namespace google

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_INCLUDED_tensorflow_2fcore_2flib_2fcore_2ferror_5fcodes_2eproto


// Parsed from tensorflow/core/platform/logging.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_PLATFORM_LOGGING_H_
// #define TENSORFLOW_CORE_PLATFORM_LOGGING_H_

// #include "tensorflow/core/platform/platform.h"  // To pick up PLATFORM_define

// #if defined(PLATFORM_GOOGLE) || defined(PLATFORM_GOOGLE_ANDROID) ||
//     defined(GOOGLE_LOGGING)
// #include "tensorflow/core/platform/google/build_config/logging.h"
// #else
// #include "tensorflow/core/platform/default/logging.h"
// #endif
// Emit "message" as a log message to the log for the specified
// "severity" as if it came from a LOG call at "fname:line"
@Namespace("tensorflow::internal") public static native void LogString(@Cast("const char*") BytePointer fname, int line, int severity,
               @StdString BytePointer message);
@Namespace("tensorflow::internal") public static native void LogString(String fname, int line, int severity,
               @StdString String message);
  // namespace internal

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_PLATFORM_LOGGING_H_


// Parsed from tensorflow/core/lib/core/status.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_LIB_CORE_STATUS_H_
// #define TENSORFLOW_CORE_LIB_CORE_STATUS_H_

// #include <functional>
// #include <iosfwd>
// #include <memory>
// #include <string>
// #include "tensorflow/core/lib/core/error_codes.pb.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/platform/logging.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/types.h"

// #if defined(__clang__)
// Only clang supports warn_unused_result as a type annotation.
// Targeting ../Status.java











/** \ingroup core */
@Namespace("tensorflow") public static native @Cast("std::ostream*") @ByRef @Name("operator <<") Pointer shiftLeft(@Cast("std::ostream*") @ByRef Pointer os, @Const @ByRef Status x);

@Namespace("tensorflow") public static native @StdString @Cast({"char*", "std::string*"}) BytePointer TfCheckOpHelperOutOfLine(
    @Const @ByRef Status v, @Cast("const char*") BytePointer msg);
@Namespace("tensorflow") public static native @StdString @Cast({"char*", "std::string*"}) BytePointer TfCheckOpHelperOutOfLine(
    @Const @ByRef Status v, String msg);

@Namespace("tensorflow") public static native @StdString @Cast({"char*", "std::string*"}) BytePointer TfCheckOpHelper(@ByVal Status v,
                                           @Cast("const char*") BytePointer msg);
@Namespace("tensorflow") public static native @StdString @Cast({"char*", "std::string*"}) BytePointer TfCheckOpHelper(@ByVal Status v,
                                           String msg);

// #define TF_DO_CHECK_OK(val, level)
//   while (auto _result = ::tensorflow::TfCheckOpHelper(val, #val))
//   LOG(level) << *(_result)

public static native void TF_CHECK_OK(@ByVal Status val);
public static native void TF_QCHECK_OK(@ByVal Status val);

// DEBUG only version of TF_CHECK_OK.  Compiler still parses 'val' even in opt
// mode.
// #ifndef NDEBUG
// #define TF_DCHECK_OK(val) TF_CHECK_OK(val)
// #else
// #define TF_DCHECK_OK(val)
//   while (false && (::tensorflow::Status::OK() == (val))) LOG(FATAL)
// #endif

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_LIB_CORE_STATUS_H_


// Parsed from tensorflow/core/lib/io/zlib_compression_options.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_LIB_IO_ZLIB_COMPRESSION_OPTIONS_H_
// #define TENSORFLOW_LIB_IO_ZLIB_COMPRESSION_OPTIONS_H_

// #include "tensorflow/core/platform/types.h"
// Targeting ../ZlibCompressionOptions.java









  // namespace io
  // namespace tensorflow

// #endif  // TENSORFLOW_LIB_IO_ZLIB_COMPRESSION_OPTIONS_H_


// Parsed from tensorflow/core/lib/io/zlib_outputbuffer.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_LIB_IO_COMPRESSED_OUTPUTBUFFER_H_
// #define TENSORFLOW_CORE_LIB_IO_COMPRESSED_OUTPUTBUFFER_H_

// #include <zlib.h>

// #include <string>

// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/io/zlib_compression_options.h"
// #include "tensorflow/core/platform/env.h"
// #include "tensorflow/core/platform/file_system.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/types.h"
// Targeting ../ZlibOutputBuffer.java



  // namespace io
  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_LIB_IO_COMPRESSED_OUTPUTBUFFER_H_


// Parsed from tensorflow/core/lib/io/inputstream_interface.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_LIB_IO_INPUTSTREAM_INTERFACE_H_
// #define TENSORFLOW_CORE_LIB_IO_INPUTSTREAM_INTERFACE_H_

// #include <string>
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/platform/types.h"
// Targeting ../InputStreamInterface.java



  // namespace io
  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_LIB_IO_INPUTSTREAM_INTERFACE_H_


// Parsed from tensorflow/core/lib/io/record_reader.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_LIB_IO_RECORD_READER_H_
// #define TENSORFLOW_CORE_LIB_IO_RECORD_READER_H_

// #include "tensorflow/core/lib/core/errors.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/lib/io/inputstream_interface.h"
// #if !defined(IS_SLIM_BUILD)
// #include "tensorflow/core/lib/io/zlib_compression_options.h"
// #include "tensorflow/core/lib/io/zlib_inputstream.h"
// #endif  // IS_SLIM_BUILD
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/types.h"
// Targeting ../RecordReaderOptions.java


// Targeting ../RecordReader.java


// Targeting ../SequentialRecordReader.java



  // namespace io
  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_LIB_IO_RECORD_READER_H_


// Parsed from tensorflow/core/lib/io/record_writer.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_LIB_IO_RECORD_WRITER_H_
// #define TENSORFLOW_CORE_LIB_IO_RECORD_WRITER_H_

// #include "tensorflow/core/lib/core/coding.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/lib/hash/crc32c.h"
// #if !defined(IS_SLIM_BUILD)
// #include "tensorflow/core/lib/io/zlib_compression_options.h"
// #include "tensorflow/core/lib/io/zlib_outputbuffer.h"
// #endif  // IS_SLIM_BUILD
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/types.h"
// Targeting ../RecordWriterOptions.java


// Targeting ../RecordWriter.java







  // namespace io
  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_LIB_IO_RECORD_WRITER_H_


// Parsed from tensorflow/core/platform/protobuf.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_PLATFORM_PROTOBUF_H_
// #define TENSORFLOW_CORE_PLATFORM_PROTOBUF_H_

// #include "tensorflow/core/platform/platform.h"
// #include "tensorflow/core/platform/types.h"

// Import whatever namespace protobuf comes from into the
// ::tensorflow::protobuf namespace.
//
// TensorFlow code should use the ::tensorflow::protobuf namespace to
// refer to all protobuf APIs.

// #if defined(PLATFORM_GOOGLE) && !defined(USE_DEFAULT_PROTOBUF)
// #include "tensorflow/core/platform/google/protobuf.h"
// #else
// #include "tensorflow/core/platform/default/protobuf.h"
// #endif
// Parses a protocol buffer contained in a string in the binary wire format.
// Returns true on success. Note: Unlike protobuf's builtin ParseFromString,
// this function has no size restrictions on the total size of the encoded
// protocol buffer.
@Namespace("tensorflow") public static native @Cast("bool") boolean ParseProtoUnlimited(@Cast("tensorflow::protobuf::MessageLite*") MessageLite proto,
                         @StdString BytePointer serialized);
@Namespace("tensorflow") public static native @Cast("bool") boolean ParseProtoUnlimited(@Cast("tensorflow::protobuf::MessageLite*") MessageLite proto,
                         @StdString String serialized);
@Namespace("tensorflow") public static native @Cast("bool") boolean ParseProtoUnlimited(@Cast("tensorflow::protobuf::MessageLite*") MessageLite proto, @Const Pointer serialized,
                         @Cast("size_t") long size);

// Returns the string value for the value of a string or bytes protobuf field.
@Namespace("tensorflow") public static native @StdString BytePointer ProtobufStringToString(@StdString BytePointer s);
@Namespace("tensorflow") public static native @StdString String ProtobufStringToString(@StdString String s);

// Set <dest> to <src>. Swapping is allowed, as <src> does not need to be
// preserved.
@Namespace("tensorflow") public static native void SetProtobufStringSwapAllowed(@StdString @Cast({"char*", "std::string*"}) BytePointer src, @StdString @Cast({"char*", "std::string*"}) BytePointer dest);

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_PLATFORM_PROTOBUF_H_


// Parsed from tensorflow/core/platform/file_system.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_PLATFORM_FILE_SYSTEM_H_
// #define TENSORFLOW_CORE_PLATFORM_FILE_SYSTEM_H_

// #include <stdint.h>
// #include <functional>
// #include <string>
// #include <unordered_map>
// #include <vector>
// #include "tensorflow/core/lib/core/errors.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/platform/cord.h"
// #include "tensorflow/core/platform/file_statistics.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/platform.h"
// #include "tensorflow/core/platform/types.h"

// #ifdef PLATFORM_WINDOWS
// #undef DeleteFile
// #endif
// Targeting ../FileSystem.java


// Targeting ../RandomAccessFile.java


// Targeting ../WritableFile.java


// Targeting ../ReadOnlyMemoryRegion.java


// Targeting ../FileSystemRegistry.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_PLATFORM_FILE_SYSTEM_H_


// Parsed from tensorflow/core/platform/file_statistics.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_PLATFORM_FILE_STATISTICS_H_
// #define TENSORFLOW_CORE_PLATFORM_FILE_STATISTICS_H_

// #include "tensorflow/core/platform/types.h"
// Targeting ../FileStatistics.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_PLATFORM_FILE_STATISTICS_H_


// Parsed from tensorflow/core/platform/env.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_PLATFORM_ENV_H_
// #define TENSORFLOW_CORE_PLATFORM_ENV_H_

// #include <stdint.h>
// #include <memory>
// #include <string>
// #include <unordered_map>
// #include <vector>
// #include "tensorflow/core/lib/core/errors.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/platform/env_time.h"
// #include "tensorflow/core/platform/file_system.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/mutex.h"
// #include "tensorflow/core/platform/numa.h"
// #include "tensorflow/core/platform/protobuf.h"
// #include "tensorflow/core/platform/types.h"
// Targeting ../Env.java


// Targeting ../EnvWrapper.java


// Targeting ../Thread.java


// Targeting ../ThreadOptions.java



/** A utility routine: copy contents of {@code src} in file system {@code src_fs}
 *  to {@code target} in file system {@code target_fs}. */
@Namespace("tensorflow") public static native @ByVal Status FileSystemCopyFile(FileSystem src_fs, @StdString BytePointer src,
                          FileSystem target_fs, @StdString BytePointer target);
@Namespace("tensorflow") public static native @ByVal Status FileSystemCopyFile(FileSystem src_fs, @StdString String src,
                          FileSystem target_fs, @StdString String target);

/** A utility routine: reads contents of named file into {@code *data} */
@Namespace("tensorflow") public static native @ByVal Status ReadFileToString(Env env, @StdString BytePointer fname, @StdString @Cast({"char*", "std::string*"}) BytePointer data);
@Namespace("tensorflow") public static native @ByVal Status ReadFileToString(Env env, @StdString String fname, @StdString @Cast({"char*", "std::string*"}) BytePointer data);

/** A utility routine: write contents of {@code data} to file named {@code fname}
 *  (overwriting existing contents, if any). */
@Namespace("tensorflow") public static native @ByVal Status WriteStringToFile(Env env, @StdString BytePointer fname,
                         @StringPiece BytePointer data);
@Namespace("tensorflow") public static native @ByVal Status WriteStringToFile(Env env, @StdString String fname,
                         @StringPiece String data);

/** Write binary representation of "proto" to the named file. */
@Namespace("tensorflow") public static native @ByVal Status WriteBinaryProto(Env env, @StdString BytePointer fname,
                        @Cast("const tensorflow::protobuf::MessageLite*") @ByRef MessageLite proto);
@Namespace("tensorflow") public static native @ByVal Status WriteBinaryProto(Env env, @StdString String fname,
                        @Cast("const tensorflow::protobuf::MessageLite*") @ByRef MessageLite proto);

/** Reads contents of named file and parse as binary encoded proto data
 *  and store into {@code *proto}. */
@Namespace("tensorflow") public static native @ByVal Status ReadBinaryProto(Env env, @StdString BytePointer fname,
                       @Cast("tensorflow::protobuf::MessageLite*") MessageLite proto);
@Namespace("tensorflow") public static native @ByVal Status ReadBinaryProto(Env env, @StdString String fname,
                       @Cast("tensorflow::protobuf::MessageLite*") MessageLite proto);

/** Write the text representation of "proto" to the named file. */
@Namespace("tensorflow") public static native @ByVal Status WriteTextProto(Env env, @StdString BytePointer fname,
                      @Cast("const tensorflow::protobuf::Message*") @ByRef MessageLite proto);
@Namespace("tensorflow") public static native @ByVal Status WriteTextProto(Env env, @StdString String fname,
                      @Cast("const tensorflow::protobuf::Message*") @ByRef MessageLite proto);

/** Read contents of named file and parse as text encoded proto data
 *  and store into {@code *proto}. */
@Namespace("tensorflow") public static native @ByVal Status ReadTextProto(Env env, @StdString BytePointer fname,
                     @Cast("tensorflow::protobuf::Message*") MessageLite proto);
@Namespace("tensorflow") public static native @ByVal Status ReadTextProto(Env env, @StdString String fname,
                     @Cast("tensorflow::protobuf::Message*") MessageLite proto);

// START_SKIP_DOXYGEN

  // namespace register_file_system

// END_SKIP_DOXYGEN

  // namespace tensorflow

// Register a FileSystem implementation for a scheme. Files with names that have
// "scheme://" prefixes are routed to use this implementation.
// #define REGISTER_FILE_SYSTEM_ENV(env, scheme, factory)
//   REGISTER_FILE_SYSTEM_UNIQ_HELPER(__COUNTER__, env, scheme, factory)
// #define REGISTER_FILE_SYSTEM_UNIQ_HELPER(ctr, env, scheme, factory)
//   REGISTER_FILE_SYSTEM_UNIQ(ctr, env, scheme, factory)
// #define REGISTER_FILE_SYSTEM_UNIQ(ctr, env, scheme, factory)
//   static ::tensorflow::register_file_system::Register<factory>
//       register_ff##ctr TF_ATTRIBUTE_UNUSED =
//           ::tensorflow::register_file_system::Register<factory>(env, scheme)

// #define REGISTER_FILE_SYSTEM(scheme, factory)
//   REGISTER_FILE_SYSTEM_ENV(::tensorflow::Env::Default(), scheme, factory);

// #endif  // TENSORFLOW_CORE_PLATFORM_ENV_H_


// Parsed from tensorflow/core/example/feature.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/example/feature.proto

// #ifndef PROTOBUF_INCLUDED_tensorflow_2fcore_2fexample_2ffeature_2eproto
// #define PROTOBUF_INCLUDED_tensorflow_2fcore_2fexample_2ffeature_2eproto

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3006001
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3006001 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/map.h>  // IWYU pragma: export
// #include <google/protobuf/map_entry.h>
// #include <google/protobuf/map_field_inl.h>
// #include <google/protobuf/unknown_field_set.h>
// @@protoc_insertion_point(includes)
// #define PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_2fcore_2fexample_2ffeature_2eproto
// Internal implementation detail -- do not use these members.
  // namespace protobuf_tensorflow_2fcore_2fexample_2ffeature_2eproto
// Targeting ../FeatureLists_FeatureListEntry_DoNotUse.java


// Targeting ../Features_FeatureEntry_DoNotUse.java


  // namespace tensorflow









  // namespace protobuf
  // namespace google
// Targeting ../BytesList.java


// Targeting ../FloatList.java


// Targeting ../Int64List.java


// Targeting ../Feature.java


// -------------------------------------------------------------------
// Targeting ../Features.java


// Targeting ../FeatureList.java


// -------------------------------------------------------------------
// Targeting ../FeatureLists.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// BytesList

// repeated bytes value = 1;





// #if LANG_CXX11

// #endif




// #if LANG_CXX11

// #endif





// -------------------------------------------------------------------

// FloatList

// repeated float value = 1 [packed = true];








// -------------------------------------------------------------------

// Int64List

// repeated int64 value = 1 [packed = true];








// -------------------------------------------------------------------

// Feature

// .tensorflow.BytesList bytes_list = 1;










// .tensorflow.FloatList float_list = 2;










// .tensorflow.Int64List int64_list = 3;













// -------------------------------------------------------------------

// -------------------------------------------------------------------

// Features

// map<string, .tensorflow.Feature> feature = 1;





// -------------------------------------------------------------------

// FeatureList

// repeated .tensorflow.Feature feature = 1;








// -------------------------------------------------------------------

// -------------------------------------------------------------------

// FeatureLists

// map<string, .tensorflow.FeatureList> feature_list = 1;





// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_INCLUDED_tensorflow_2fcore_2fexample_2ffeature_2eproto


// Parsed from tensorflow/core/example/example.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/example/example.proto

// #ifndef PROTOBUF_INCLUDED_tensorflow_2fcore_2fexample_2fexample_2eproto
// #define PROTOBUF_INCLUDED_tensorflow_2fcore_2fexample_2fexample_2eproto

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3006001
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3006001 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/example/feature.pb.h"
// @@protoc_insertion_point(includes)
// #define PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_2fcore_2fexample_2fexample_2eproto
// Internal implementation detail -- do not use these members.
  // namespace protobuf_tensorflow_2fcore_2fexample_2fexample_2eproto
  // namespace tensorflow


  // namespace protobuf
  // namespace google
// Targeting ../Example.java


// Targeting ../SequenceExample.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// Example

// .tensorflow.Features features = 1;








// -------------------------------------------------------------------

// SequenceExample

// .tensorflow.Features context = 1;








// .tensorflow.FeatureLists feature_lists = 2;








// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_INCLUDED_tensorflow_2fcore_2fexample_2fexample_2eproto


// Parsed from tensorflow/core/protobuf/debug.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/protobuf/debug.proto

// #ifndef PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fdebug_2eproto
// #define PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fdebug_2eproto

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3006001
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3006001 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/unknown_field_set.h>
// @@protoc_insertion_point(includes)
// #define PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_2fcore_2fprotobuf_2fdebug_2eproto
// Internal implementation detail -- do not use these members.
  // namespace protobuf_tensorflow_2fcore_2fprotobuf_2fdebug_2eproto
  // namespace tensorflow




  // namespace protobuf
  // namespace google
// Targeting ../DebugTensorWatch.java


// Targeting ../DebugOptions.java


// Targeting ../DebuggedSourceFile.java


// Targeting ../DebuggedSourceFiles.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// DebugTensorWatch

// string node_name = 1;



// #if LANG_CXX11

// #endif








// int32 output_slot = 2;




// repeated string debug_ops = 3;





// #if LANG_CXX11

// #endif




// #if LANG_CXX11

// #endif





// repeated string debug_urls = 4;





// #if LANG_CXX11

// #endif




// #if LANG_CXX11

// #endif





// bool tolerate_debug_op_creation_failures = 5;




// -------------------------------------------------------------------

// DebugOptions

// repeated .tensorflow.DebugTensorWatch debug_tensor_watch_opts = 4;








// int64 global_step = 10;




// bool reset_disk_byte_usage = 11;




// -------------------------------------------------------------------

// DebuggedSourceFile

// string host = 1;



// #if LANG_CXX11

// #endif








// string file_path = 2;



// #if LANG_CXX11

// #endif








// int64 last_modified = 3;




// int64 bytes = 4;




// repeated string lines = 5;





// #if LANG_CXX11

// #endif




// #if LANG_CXX11

// #endif





// -------------------------------------------------------------------

// DebuggedSourceFiles

// repeated .tensorflow.DebuggedSourceFile source_files = 1;








// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fdebug_2eproto


// Parsed from tensorflow/core/protobuf/cluster.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/protobuf/cluster.proto

// #ifndef PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fcluster_2eproto
// #define PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fcluster_2eproto

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3006001
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3006001 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/map.h>  // IWYU pragma: export
// #include <google/protobuf/map_entry.h>
// #include <google/protobuf/map_field_inl.h>
// #include <google/protobuf/unknown_field_set.h>
// @@protoc_insertion_point(includes)
// #define PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_2fcore_2fprotobuf_2fcluster_2eproto
// Internal implementation detail -- do not use these members.
  // namespace protobuf_tensorflow_2fcore_2fprotobuf_2fcluster_2eproto
// Targeting ../JobDef_TasksEntry_DoNotUse.java


  // namespace tensorflow



  // namespace protobuf
  // namespace google

// ===================================================================
// Targeting ../JobDef.java


// Targeting ../ClusterDef.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// -------------------------------------------------------------------

// JobDef

// string name = 1;



// #if LANG_CXX11

// #endif








// map<int32, string> tasks = 2;





// -------------------------------------------------------------------

// ClusterDef

// repeated .tensorflow.JobDef job = 1;








// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fcluster_2eproto


// Parsed from tensorflow/core/protobuf/rewriter_config.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/protobuf/rewriter_config.proto

// #ifndef PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto
// #define PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3006001
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3006001 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/map.h>  // IWYU pragma: export
// #include <google/protobuf/map_entry.h>
// #include <google/protobuf/map_field_inl.h>
// #include <google/protobuf/generated_enum_reflection.h>
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/attr_value.pb.h"
// @@protoc_insertion_point(includes)
// #define PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto
// Internal implementation detail -- do not use these members.
  // namespace protobuf_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto
// Targeting ../RewriterConfig_CustomGraphOptimizer_ParameterMapEntry_DoNotUse.java


  // namespace tensorflow





  // namespace protobuf
  // namespace google

/** enum tensorflow::RewriterConfig_Toggle */
public static final int
  RewriterConfig_Toggle_DEFAULT = 0,
  RewriterConfig_Toggle_ON = 1,
  RewriterConfig_Toggle_OFF = 2,
  RewriterConfig_Toggle_AGGRESSIVE = 3,
  RewriterConfig_Toggle_RewriterConfig_Toggle_INT_MIN_SENTINEL_DO_NOT_USE_ = kint32min,
  RewriterConfig_Toggle_RewriterConfig_Toggle_INT_MAX_SENTINEL_DO_NOT_USE_ = kint32max;
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_Toggle_IsValid(int value);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::RewriterConfig_Toggle") int RewriterConfig_Toggle_Toggle_MIN();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::RewriterConfig_Toggle") int RewriterConfig_Toggle_Toggle_MAX();
@Namespace("tensorflow") @MemberGetter public static native int RewriterConfig_Toggle_Toggle_ARRAYSIZE();

@Namespace("tensorflow") public static native @Cast("const google::protobuf::EnumDescriptor*") Pointer RewriterConfig_Toggle_descriptor();
@Namespace("tensorflow") public static native @StdString BytePointer RewriterConfig_Toggle_Name(@Cast("tensorflow::RewriterConfig_Toggle") int value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_Toggle_Parse(
    @StdString BytePointer name, @Cast("tensorflow::RewriterConfig_Toggle*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_Toggle_Parse(
    @StdString String name, @Cast("tensorflow::RewriterConfig_Toggle*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_Toggle_Parse(
    @StdString BytePointer name, @Cast("tensorflow::RewriterConfig_Toggle*") int... value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_Toggle_Parse(
    @StdString String name, @Cast("tensorflow::RewriterConfig_Toggle*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_Toggle_Parse(
    @StdString BytePointer name, @Cast("tensorflow::RewriterConfig_Toggle*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_Toggle_Parse(
    @StdString String name, @Cast("tensorflow::RewriterConfig_Toggle*") int... value);
/** enum tensorflow::RewriterConfig_NumIterationsType */
public static final int
  RewriterConfig_NumIterationsType_DEFAULT_NUM_ITERS = 0,
  RewriterConfig_NumIterationsType_ONE = 1,
  RewriterConfig_NumIterationsType_TWO = 2,
  RewriterConfig_NumIterationsType_RewriterConfig_NumIterationsType_INT_MIN_SENTINEL_DO_NOT_USE_ = kint32min,
  RewriterConfig_NumIterationsType_RewriterConfig_NumIterationsType_INT_MAX_SENTINEL_DO_NOT_USE_ = kint32max;
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_NumIterationsType_IsValid(int value);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::RewriterConfig_NumIterationsType") int RewriterConfig_NumIterationsType_NumIterationsType_MIN();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::RewriterConfig_NumIterationsType") int RewriterConfig_NumIterationsType_NumIterationsType_MAX();
@Namespace("tensorflow") @MemberGetter public static native int RewriterConfig_NumIterationsType_NumIterationsType_ARRAYSIZE();

@Namespace("tensorflow") public static native @Cast("const google::protobuf::EnumDescriptor*") Pointer RewriterConfig_NumIterationsType_descriptor();
@Namespace("tensorflow") public static native @StdString BytePointer RewriterConfig_NumIterationsType_Name(@Cast("tensorflow::RewriterConfig_NumIterationsType") int value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_NumIterationsType_Parse(
    @StdString BytePointer name, @Cast("tensorflow::RewriterConfig_NumIterationsType*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_NumIterationsType_Parse(
    @StdString String name, @Cast("tensorflow::RewriterConfig_NumIterationsType*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_NumIterationsType_Parse(
    @StdString BytePointer name, @Cast("tensorflow::RewriterConfig_NumIterationsType*") int... value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_NumIterationsType_Parse(
    @StdString String name, @Cast("tensorflow::RewriterConfig_NumIterationsType*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_NumIterationsType_Parse(
    @StdString BytePointer name, @Cast("tensorflow::RewriterConfig_NumIterationsType*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_NumIterationsType_Parse(
    @StdString String name, @Cast("tensorflow::RewriterConfig_NumIterationsType*") int... value);
/** enum tensorflow::RewriterConfig_MemOptType */
public static final int
  RewriterConfig_MemOptType_DEFAULT_MEM_OPT = 0,
  RewriterConfig_MemOptType_NO_MEM_OPT = 1,
  RewriterConfig_MemOptType_MANUAL = 2,
  RewriterConfig_MemOptType_SWAPPING_HEURISTICS = 4,
  RewriterConfig_MemOptType_RECOMPUTATION_HEURISTICS = 5,
  RewriterConfig_MemOptType_SCHEDULING_HEURISTICS = 6,
  RewriterConfig_MemOptType_HEURISTICS = 3,
  RewriterConfig_MemOptType_RewriterConfig_MemOptType_INT_MIN_SENTINEL_DO_NOT_USE_ = kint32min,
  RewriterConfig_MemOptType_RewriterConfig_MemOptType_INT_MAX_SENTINEL_DO_NOT_USE_ = kint32max;
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_MemOptType_IsValid(int value);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::RewriterConfig_MemOptType") int RewriterConfig_MemOptType_MemOptType_MIN();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::RewriterConfig_MemOptType") int RewriterConfig_MemOptType_MemOptType_MAX();
@Namespace("tensorflow") @MemberGetter public static native int RewriterConfig_MemOptType_MemOptType_ARRAYSIZE();

@Namespace("tensorflow") public static native @Cast("const google::protobuf::EnumDescriptor*") Pointer RewriterConfig_MemOptType_descriptor();
@Namespace("tensorflow") public static native @StdString BytePointer RewriterConfig_MemOptType_Name(@Cast("tensorflow::RewriterConfig_MemOptType") int value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_MemOptType_Parse(
    @StdString BytePointer name, @Cast("tensorflow::RewriterConfig_MemOptType*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_MemOptType_Parse(
    @StdString String name, @Cast("tensorflow::RewriterConfig_MemOptType*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_MemOptType_Parse(
    @StdString BytePointer name, @Cast("tensorflow::RewriterConfig_MemOptType*") int... value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_MemOptType_Parse(
    @StdString String name, @Cast("tensorflow::RewriterConfig_MemOptType*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_MemOptType_Parse(
    @StdString BytePointer name, @Cast("tensorflow::RewriterConfig_MemOptType*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RewriterConfig_MemOptType_Parse(
    @StdString String name, @Cast("tensorflow::RewriterConfig_MemOptType*") int... value);
// Targeting ../AutoParallelOptions.java


// Targeting ../ScopedAllocatorOptions.java


// -------------------------------------------------------------------
// Targeting ../RewriterConfig_CustomGraphOptimizer.java


// Targeting ../RewriterConfig.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// AutoParallelOptions

// bool enable = 1;




// int32 num_replicas = 2;




// -------------------------------------------------------------------

// ScopedAllocatorOptions

// repeated string enable_op = 1;





// #if LANG_CXX11

// #endif




// #if LANG_CXX11

// #endif





// -------------------------------------------------------------------

// -------------------------------------------------------------------

// RewriterConfig_CustomGraphOptimizer

// string name = 1;



// #if LANG_CXX11

// #endif








// map<string, .tensorflow.AttrValue> parameter_map = 2;




// -------------------------------------------------------------------

// RewriterConfig

// .tensorflow.RewriterConfig.Toggle layout_optimizer = 1;




// .tensorflow.RewriterConfig.Toggle constant_folding = 3;




// .tensorflow.RewriterConfig.Toggle shape_optimization = 13;




// .tensorflow.RewriterConfig.Toggle remapping = 14;




// .tensorflow.RewriterConfig.Toggle arithmetic_optimization = 7;




// .tensorflow.RewriterConfig.Toggle dependency_optimization = 8;




// .tensorflow.RewriterConfig.Toggle loop_optimization = 9;




// .tensorflow.RewriterConfig.Toggle function_optimization = 10;




// .tensorflow.RewriterConfig.Toggle debug_stripper = 11;




// bool disable_model_pruning = 2;




// .tensorflow.RewriterConfig.Toggle scoped_allocator_optimization = 15;




// .tensorflow.RewriterConfig.Toggle pin_to_host_optimization = 18;




// bool disable_meta_optimizer = 19;




// .tensorflow.RewriterConfig.NumIterationsType meta_optimizer_iterations = 12;




// int32 min_graph_nodes = 17;




// .tensorflow.RewriterConfig.MemOptType memory_optimization = 4;




// string memory_optimizer_target_node_name_scope = 6;



// #if LANG_CXX11

// #endif








// int64 meta_optimizer_timeout_ms = 20;




// .tensorflow.AutoParallelOptions auto_parallel = 5;









// bool fail_on_optimizer_errors = 21;




// .tensorflow.ScopedAllocatorOptions scoped_allocator_opts = 16;









// repeated string optimizers = 100;





// #if LANG_CXX11

// #endif




// #if LANG_CXX11

// #endif





// repeated .tensorflow.RewriterConfig.CustomGraphOptimizer custom_optimizers = 200;








// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow




  // namespace protobuf
  // namespace google

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto


// Parsed from tensorflow/core/protobuf/config.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/protobuf/config.proto

// #ifndef PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto
// #define PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3006001
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3006001 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/map.h>  // IWYU pragma: export
// #include <google/protobuf/map_entry.h>
// #include <google/protobuf/map_field_inl.h>
// #include <google/protobuf/generated_enum_reflection.h>
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/cost_graph.pb.h"
// #include "tensorflow/core/framework/graph.pb.h"
// #include "tensorflow/core/framework/step_stats.pb.h"
// #include "tensorflow/core/protobuf/debug.pb.h"
// #include "tensorflow/core/protobuf/cluster.pb.h"
// #include "tensorflow/core/protobuf/rewriter_config.pb.h"
// @@protoc_insertion_point(includes)
// #define PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto
// Internal implementation detail -- do not use these members.
  // namespace protobuf_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto
// Targeting ../CallableOptions_FeedDevicesEntry_DoNotUse.java


// Targeting ../CallableOptions_FetchDevicesEntry_DoNotUse.java


// Targeting ../ConfigProto_DeviceCountEntry_DoNotUse.java


  // namespace tensorflow

















  // namespace protobuf
  // namespace google

/** enum tensorflow::OptimizerOptions_Level */
public static final int
  OptimizerOptions_Level_L1 = 0,
  OptimizerOptions_Level_L0 = -1,
  OptimizerOptions_Level_OptimizerOptions_Level_INT_MIN_SENTINEL_DO_NOT_USE_ = kint32min,
  OptimizerOptions_Level_OptimizerOptions_Level_INT_MAX_SENTINEL_DO_NOT_USE_ = kint32max;
@Namespace("tensorflow") public static native @Cast("bool") boolean OptimizerOptions_Level_IsValid(int value);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::OptimizerOptions_Level") int OptimizerOptions_Level_Level_MIN();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::OptimizerOptions_Level") int OptimizerOptions_Level_Level_MAX();
@Namespace("tensorflow") @MemberGetter public static native int OptimizerOptions_Level_Level_ARRAYSIZE();

@Namespace("tensorflow") public static native @Cast("const google::protobuf::EnumDescriptor*") Pointer OptimizerOptions_Level_descriptor();
@Namespace("tensorflow") public static native @StdString BytePointer OptimizerOptions_Level_Name(@Cast("tensorflow::OptimizerOptions_Level") int value);
@Namespace("tensorflow") public static native @Cast("bool") boolean OptimizerOptions_Level_Parse(
    @StdString BytePointer name, @Cast("tensorflow::OptimizerOptions_Level*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean OptimizerOptions_Level_Parse(
    @StdString String name, @Cast("tensorflow::OptimizerOptions_Level*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean OptimizerOptions_Level_Parse(
    @StdString BytePointer name, @Cast("tensorflow::OptimizerOptions_Level*") int... value);
@Namespace("tensorflow") public static native @Cast("bool") boolean OptimizerOptions_Level_Parse(
    @StdString String name, @Cast("tensorflow::OptimizerOptions_Level*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean OptimizerOptions_Level_Parse(
    @StdString BytePointer name, @Cast("tensorflow::OptimizerOptions_Level*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean OptimizerOptions_Level_Parse(
    @StdString String name, @Cast("tensorflow::OptimizerOptions_Level*") int... value);
/** enum tensorflow::OptimizerOptions_GlobalJitLevel */
public static final int
  OptimizerOptions_GlobalJitLevel_DEFAULT = 0,
  OptimizerOptions_GlobalJitLevel_OFF = -1,
  OptimizerOptions_GlobalJitLevel_ON_1 = 1,
  OptimizerOptions_GlobalJitLevel_ON_2 = 2,
  OptimizerOptions_GlobalJitLevel_OptimizerOptions_GlobalJitLevel_INT_MIN_SENTINEL_DO_NOT_USE_ = kint32min,
  OptimizerOptions_GlobalJitLevel_OptimizerOptions_GlobalJitLevel_INT_MAX_SENTINEL_DO_NOT_USE_ = kint32max;
@Namespace("tensorflow") public static native @Cast("bool") boolean OptimizerOptions_GlobalJitLevel_IsValid(int value);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::OptimizerOptions_GlobalJitLevel") int OptimizerOptions_GlobalJitLevel_GlobalJitLevel_MIN();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::OptimizerOptions_GlobalJitLevel") int OptimizerOptions_GlobalJitLevel_GlobalJitLevel_MAX();
@Namespace("tensorflow") @MemberGetter public static native int OptimizerOptions_GlobalJitLevel_GlobalJitLevel_ARRAYSIZE();

@Namespace("tensorflow") public static native @Cast("const google::protobuf::EnumDescriptor*") Pointer OptimizerOptions_GlobalJitLevel_descriptor();
@Namespace("tensorflow") public static native @StdString BytePointer OptimizerOptions_GlobalJitLevel_Name(@Cast("tensorflow::OptimizerOptions_GlobalJitLevel") int value);
@Namespace("tensorflow") public static native @Cast("bool") boolean OptimizerOptions_GlobalJitLevel_Parse(
    @StdString BytePointer name, @Cast("tensorflow::OptimizerOptions_GlobalJitLevel*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean OptimizerOptions_GlobalJitLevel_Parse(
    @StdString String name, @Cast("tensorflow::OptimizerOptions_GlobalJitLevel*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean OptimizerOptions_GlobalJitLevel_Parse(
    @StdString BytePointer name, @Cast("tensorflow::OptimizerOptions_GlobalJitLevel*") int... value);
@Namespace("tensorflow") public static native @Cast("bool") boolean OptimizerOptions_GlobalJitLevel_Parse(
    @StdString String name, @Cast("tensorflow::OptimizerOptions_GlobalJitLevel*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean OptimizerOptions_GlobalJitLevel_Parse(
    @StdString BytePointer name, @Cast("tensorflow::OptimizerOptions_GlobalJitLevel*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean OptimizerOptions_GlobalJitLevel_Parse(
    @StdString String name, @Cast("tensorflow::OptimizerOptions_GlobalJitLevel*") int... value);
/** enum tensorflow::RunOptions_TraceLevel */
public static final int
  RunOptions_TraceLevel_NO_TRACE = 0,
  RunOptions_TraceLevel_SOFTWARE_TRACE = 1,
  RunOptions_TraceLevel_HARDWARE_TRACE = 2,
  RunOptions_TraceLevel_FULL_TRACE = 3,
  RunOptions_TraceLevel_RunOptions_TraceLevel_INT_MIN_SENTINEL_DO_NOT_USE_ = kint32min,
  RunOptions_TraceLevel_RunOptions_TraceLevel_INT_MAX_SENTINEL_DO_NOT_USE_ = kint32max;
@Namespace("tensorflow") public static native @Cast("bool") boolean RunOptions_TraceLevel_IsValid(int value);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::RunOptions_TraceLevel") int RunOptions_TraceLevel_TraceLevel_MIN();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::RunOptions_TraceLevel") int RunOptions_TraceLevel_TraceLevel_MAX();
@Namespace("tensorflow") @MemberGetter public static native int RunOptions_TraceLevel_TraceLevel_ARRAYSIZE();

@Namespace("tensorflow") public static native @Cast("const google::protobuf::EnumDescriptor*") Pointer RunOptions_TraceLevel_descriptor();
@Namespace("tensorflow") public static native @StdString BytePointer RunOptions_TraceLevel_Name(@Cast("tensorflow::RunOptions_TraceLevel") int value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RunOptions_TraceLevel_Parse(
    @StdString BytePointer name, @Cast("tensorflow::RunOptions_TraceLevel*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RunOptions_TraceLevel_Parse(
    @StdString String name, @Cast("tensorflow::RunOptions_TraceLevel*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RunOptions_TraceLevel_Parse(
    @StdString BytePointer name, @Cast("tensorflow::RunOptions_TraceLevel*") int... value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RunOptions_TraceLevel_Parse(
    @StdString String name, @Cast("tensorflow::RunOptions_TraceLevel*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RunOptions_TraceLevel_Parse(
    @StdString BytePointer name, @Cast("tensorflow::RunOptions_TraceLevel*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RunOptions_TraceLevel_Parse(
    @StdString String name, @Cast("tensorflow::RunOptions_TraceLevel*") int... value);
// Targeting ../GPUOptions_Experimental_VirtualDevices.java


// Targeting ../GPUOptions_Experimental.java


// Targeting ../GPUOptions.java


// Targeting ../OptimizerOptions.java


// Targeting ../GraphOptions.java


// Targeting ../ThreadPoolOptionProto.java


// Targeting ../RPCOptions.java


// -------------------------------------------------------------------
// Targeting ../ConfigProto_Experimental.java


// Targeting ../ConfigProto.java


// Targeting ../RunOptions_Experimental.java


// Targeting ../RunOptions.java


// Targeting ../RunMetadata.java


// Targeting ../TensorConnection.java


// -------------------------------------------------------------------

// -------------------------------------------------------------------
// Targeting ../CallableOptions.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// GPUOptions_Experimental_VirtualDevices

// repeated float memory_limit_mb = 1;








// -------------------------------------------------------------------

// GPUOptions_Experimental

// repeated .tensorflow.GPUOptions.Experimental.VirtualDevices virtual_devices = 1;








// bool use_unified_memory = 2;




// int32 num_dev_to_dev_copy_streams = 3;




// string collective_ring_order = 4;



// #if LANG_CXX11

// #endif








// -------------------------------------------------------------------

// GPUOptions

// double per_process_gpu_memory_fraction = 1;




// bool allow_growth = 4;




// string allocator_type = 2;



// #if LANG_CXX11

// #endif








// int64 deferred_deletion_bytes = 3;




// string visible_device_list = 5;



// #if LANG_CXX11

// #endif








// int32 polling_active_delay_usecs = 6;




// int32 polling_inactive_delay_msecs = 7;




// bool force_gpu_compatible = 8;




// .tensorflow.GPUOptions.Experimental experimental = 9;









// -------------------------------------------------------------------

// OptimizerOptions

// bool do_common_subexpression_elimination = 1;




// bool do_constant_folding = 2;




// int64 max_folded_constant_in_bytes = 6;




// bool do_function_inlining = 4;




// .tensorflow.OptimizerOptions.Level opt_level = 3;




// .tensorflow.OptimizerOptions.GlobalJitLevel global_jit_level = 5;




// -------------------------------------------------------------------

// GraphOptions

// bool enable_recv_scheduling = 2;




// .tensorflow.OptimizerOptions optimizer_options = 3;









// int64 build_cost_model = 4;




// int64 build_cost_model_after = 9;




// bool infer_shapes = 5;




// bool place_pruned_graph = 6;




// bool enable_bfloat16_sendrecv = 7;




// int32 timeline_step = 8;




// .tensorflow.RewriterConfig rewrite_options = 10;








// -------------------------------------------------------------------

// ThreadPoolOptionProto

// int32 num_threads = 1;




// string global_name = 2;



// #if LANG_CXX11

// #endif








// -------------------------------------------------------------------

// RPCOptions

// bool use_rpc_for_inprocess_master = 1;




// string compression_algorithm = 2;



// #if LANG_CXX11

// #endif








// int32 compression_level = 3;




// -------------------------------------------------------------------

// -------------------------------------------------------------------

// ConfigProto_Experimental

// string collective_group_leader = 1;



// #if LANG_CXX11

// #endif








// string executor_type = 3;



// #if LANG_CXX11

// #endif








// int32 recv_buf_max_chunk = 4;




// bool use_numa_affinity = 5;




// -------------------------------------------------------------------

// ConfigProto

// map<string, int32> device_count = 1;





// int32 intra_op_parallelism_threads = 2;




// int32 inter_op_parallelism_threads = 5;




// bool use_per_session_threads = 9;




// repeated .tensorflow.ThreadPoolOptionProto session_inter_op_thread_pool = 12;








// int32 placement_period = 3;




// repeated string device_filters = 4;





// #if LANG_CXX11

// #endif




// #if LANG_CXX11

// #endif





// .tensorflow.GPUOptions gpu_options = 6;









// bool allow_soft_placement = 7;




// bool log_device_placement = 8;




// .tensorflow.GraphOptions graph_options = 10;









// int64 operation_timeout_in_ms = 11;




// .tensorflow.RPCOptions rpc_options = 13;









// .tensorflow.ClusterDef cluster_def = 14;








// bool isolate_session_state = 15;




// .tensorflow.ConfigProto.Experimental experimental = 16;









// -------------------------------------------------------------------

// RunOptions_Experimental

// int64 collective_graph_key = 1;




// bool use_run_handler_pool = 2;




// -------------------------------------------------------------------

// RunOptions

// .tensorflow.RunOptions.TraceLevel trace_level = 1;




// int64 timeout_in_ms = 2;




// int32 inter_op_thread_pool = 3;




// bool output_partition_graphs = 5;




// .tensorflow.DebugOptions debug_options = 6;








// bool report_tensor_allocations_upon_oom = 7;




// .tensorflow.RunOptions.Experimental experimental = 8;









// -------------------------------------------------------------------

// RunMetadata

// .tensorflow.StepStats step_stats = 1;








// .tensorflow.CostGraphDef cost_graph = 2;








// repeated .tensorflow.GraphDef partition_graphs = 3;







// -------------------------------------------------------------------

// TensorConnection

// string from_tensor = 1;



// #if LANG_CXX11

// #endif








// string to_tensor = 2;



// #if LANG_CXX11

// #endif








// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// CallableOptions

// repeated string feed = 1;





// #if LANG_CXX11

// #endif




// #if LANG_CXX11

// #endif





// repeated string fetch = 2;





// #if LANG_CXX11

// #endif




// #if LANG_CXX11

// #endif





// repeated string target = 3;





// #if LANG_CXX11

// #endif




// #if LANG_CXX11

// #endif





// .tensorflow.RunOptions run_options = 4;









// repeated .tensorflow.TensorConnection tensor_connection = 5;








// map<string, string> feed_devices = 6;





// map<string, string> fetch_devices = 7;





// bool fetch_skip_sync = 8;




// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow




  // namespace protobuf
  // namespace google

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto


// Parsed from tensorflow/core/framework/cost_graph.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/cost_graph.proto

// #ifndef PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fcost_5fgraph_2eproto
// #define PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fcost_5fgraph_2eproto

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3006001
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3006001 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/tensor_shape.pb.h"
// #include "tensorflow/core/framework/types.pb.h"
// @@protoc_insertion_point(includes)
// #define PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_2fcore_2fframework_2fcost_5fgraph_2eproto
// Internal implementation detail -- do not use these members.
  // namespace protobuf_tensorflow_2fcore_2fframework_2fcost_5fgraph_2eproto
  // namespace tensorflow




  // namespace protobuf
  // namespace google
// Targeting ../CostGraphDef_Node_InputInfo.java


// Targeting ../CostGraphDef_Node_OutputInfo.java


// Targeting ../CostGraphDef_Node.java


// Targeting ../CostGraphDef.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// CostGraphDef_Node_InputInfo

// int32 preceding_node = 1;




// int32 preceding_port = 2;




// -------------------------------------------------------------------

// CostGraphDef_Node_OutputInfo

// int64 size = 1;




// int64 alias_input_port = 2;




// .tensorflow.TensorShapeProto shape = 3;








// .tensorflow.DataType dtype = 4;




// -------------------------------------------------------------------

// CostGraphDef_Node

// string name = 1;



// #if LANG_CXX11

// #endif








// string device = 2;



// #if LANG_CXX11

// #endif








// int32 id = 3;




// repeated .tensorflow.CostGraphDef.Node.InputInfo input_info = 4;








// repeated .tensorflow.CostGraphDef.Node.OutputInfo output_info = 5;








// int64 temporary_memory_size = 6;




// int64 persistent_memory_size = 12;




// int64 host_temp_memory_size = 10 [deprecated = true];




// int64 device_temp_memory_size = 11 [deprecated = true];




// int64 device_persistent_memory_size = 16 [deprecated = true];




// int64 compute_cost = 9;




// int64 compute_time = 14;




// int64 memory_time = 15;




// bool is_final = 7;




// repeated int32 control_input = 8;








// bool inaccurate = 17;




// -------------------------------------------------------------------

// CostGraphDef

// repeated .tensorflow.CostGraphDef.Node node = 1;








// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fcost_5fgraph_2eproto


// Parsed from tensorflow/core/framework/step_stats.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/step_stats.proto

// #ifndef PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto
// #define PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3006001
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3006001 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/allocation_description.pb.h"
// #include "tensorflow/core/framework/tensor_description.pb.h"
// @@protoc_insertion_point(includes)
// #define PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto
// Internal implementation detail -- do not use these members.
  // namespace protobuf_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto
  // namespace tensorflow







  // namespace protobuf
  // namespace google
// Targeting ../AllocationRecord.java


// Targeting ../AllocatorMemoryUsed.java


// Targeting ../NodeOutput.java


// Targeting ../MemoryStats.java


// Targeting ../NodeExecStats.java


// Targeting ../DeviceStepStats.java


// Targeting ../StepStats.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// AllocationRecord

// int64 alloc_micros = 1;




// int64 alloc_bytes = 2;




// -------------------------------------------------------------------

// AllocatorMemoryUsed

// string allocator_name = 1;



// #if LANG_CXX11

// #endif








// int64 total_bytes = 2;




// int64 peak_bytes = 3;




// int64 live_bytes = 4;




// repeated .tensorflow.AllocationRecord allocation_records = 6;








// int64 allocator_bytes_in_use = 5;




// -------------------------------------------------------------------

// NodeOutput

// int32 slot = 1;




// .tensorflow.TensorDescription tensor_description = 3;








// -------------------------------------------------------------------

// MemoryStats

// int64 temp_memory_size = 1;




// int64 persistent_memory_size = 3;




// repeated int64 persistent_tensor_alloc_ids = 5;








// int64 device_temp_memory_size = 2 [deprecated = true];




// int64 device_persistent_memory_size = 4 [deprecated = true];




// repeated int64 device_persistent_tensor_alloc_ids = 6 [deprecated = true];








// -------------------------------------------------------------------

// NodeExecStats

// string node_name = 1;



// #if LANG_CXX11

// #endif








// int64 all_start_micros = 2;




// int64 op_start_rel_micros = 3;




// int64 op_end_rel_micros = 4;




// int64 all_end_rel_micros = 5;




// repeated .tensorflow.AllocatorMemoryUsed memory = 6;








// repeated .tensorflow.NodeOutput output = 7;








// string timeline_label = 8;



// #if LANG_CXX11

// #endif








// int64 scheduled_micros = 9;




// uint32 thread_id = 10;




// repeated .tensorflow.AllocationDescription referenced_tensor = 11;







// .tensorflow.MemoryStats memory_stats = 12;









// int64 all_start_nanos = 13;




// int64 op_start_rel_nanos = 14;




// int64 op_end_rel_nanos = 15;




// int64 all_end_rel_nanos = 16;




// int64 scheduled_nanos = 17;




// -------------------------------------------------------------------

// DeviceStepStats

// string device = 1;



// #if LANG_CXX11

// #endif








// repeated .tensorflow.NodeExecStats node_stats = 2;








// -------------------------------------------------------------------

// StepStats

// repeated .tensorflow.DeviceStepStats dev_stats = 1;








// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto


// Parsed from tensorflow/core/framework/versions.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/versions.proto

// #ifndef PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fversions_2eproto
// #define PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fversions_2eproto

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3006001
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3006001 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/unknown_field_set.h>
// @@protoc_insertion_point(includes)
// #define PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_2fcore_2fframework_2fversions_2eproto
// Internal implementation detail -- do not use these members.
  // namespace protobuf_tensorflow_2fcore_2fframework_2fversions_2eproto
  // namespace tensorflow

  // namespace protobuf
  // namespace google
// Targeting ../VersionDef.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// VersionDef

// int32 producer = 1;




// int32 min_consumer = 2;




// repeated int32 bad_consumers = 3;








// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__

// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fversions_2eproto


// Parsed from tensorflow/core/public/session_options.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_PUBLIC_SESSION_OPTIONS_H_
// #define TENSORFLOW_PUBLIC_SESSION_OPTIONS_H_

// #include <string>
// #include "tensorflow/core/platform/types.h"
// #include "tensorflow/core/protobuf/config.pb.h"
// Targeting ../SessionOptions.java



  // end namespace tensorflow

// #endif  // TENSORFLOW_PUBLIC_SESSION_OPTIONS_H_


// Parsed from tensorflow/core/lib/core/threadpool.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_LIB_CORE_THREADPOOL_H_
// #define TENSORFLOW_CORE_LIB_CORE_THREADPOOL_H_

// #include <functional>
// #include <memory>
// #include "tensorflow/core/platform/env.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/types.h"

// Targeting ../ThreadPool.java



  // namespace thread
  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_LIB_CORE_THREADPOOL_H_


// Parsed from tensorflow/core/framework/allocation_description.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/allocation_description.proto

// #ifndef PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fallocation_5fdescription_2eproto
// #define PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fallocation_5fdescription_2eproto

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3006001
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3006001 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/unknown_field_set.h>
// @@protoc_insertion_point(includes)
// #define PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_2fcore_2fframework_2fallocation_5fdescription_2eproto
// Internal implementation detail -- do not use these members.
  // namespace protobuf_tensorflow_2fcore_2fframework_2fallocation_5fdescription_2eproto
  // namespace tensorflow

  // namespace protobuf
  // namespace google
// Targeting ../AllocationDescription.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// AllocationDescription

// int64 requested_bytes = 1;




// int64 allocated_bytes = 2;




// string allocator_name = 3;



// #if LANG_CXX11

// #endif








// int64 allocation_id = 4;




// bool has_single_reference = 5;




// uint64 ptr = 6;




// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__

// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fallocation_5fdescription_2eproto


// Parsed from tensorflow/core/platform/default/string_coding.h

/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
// #ifndef TENSORFLOW_CORE_PLATFORM_DEFAULT_STRING_CODING_H_
// #define TENSORFLOW_CORE_PLATFORM_DEFAULT_STRING_CODING_H_

// IWYU pragma: private, include "third_party/tensorflow/core/platform/tensor_coding.h"
// IWYU pragma: friend third_party/tensorflow/core/platform/tensor_coding.h

// #include "tensorflow/core/lib/core/coding.h"
// #include "tensorflow/core/lib/strings/strcat.h"
// #include "tensorflow/core/platform/protobuf.h"
// #include "tensorflow/core/platform/types.h"
// Targeting ../StringListEncoder.java


// Targeting ../StringListDecoder.java



@Namespace("tensorflow::port") public static native @MoveUniquePtr StringListEncoder NewStringListEncoder(@StdString @Cast({"char*", "std::string*"}) BytePointer out);
@Namespace("tensorflow::port") public static native @MoveUniquePtr StringListDecoder NewStringListDecoder(@StdString BytePointer in);
@Namespace("tensorflow::port") public static native @MoveUniquePtr StringListDecoder NewStringListDecoder(@StdString String in);

  // namespace port
  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_PLATFORM_DEFAULT_STRING_CODING_H_


// Parsed from tensorflow/core/framework/resource_handle.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_FRAMEWORK_RESOURCE_HANDLE_H_
// #define TENSORFLOW_FRAMEWORK_RESOURCE_HANDLE_H_

// #include "tensorflow/core/platform/tensor_coding.h"
// #include "tensorflow/core/platform/types.h"
// Targeting ../ResourceHandle.java



// For backwards compatibility for when this was a proto
@Namespace("tensorflow") public static native @StdString BytePointer ProtoDebugString(@Const @ByRef ResourceHandle handle);

// Encodes a list of ResourceHandle protos in the given StringListEncoder.
@Namespace("tensorflow") public static native void EncodeResourceHandleList(@Const ResourceHandle p, @Cast("tensorflow::int64") long n,
                              @MoveUniquePtr StringListEncoder e);

// Decodes a list of ResourceHandle protos from the given StringListDecoder.
@Namespace("tensorflow") public static native @Cast("bool") boolean DecodeResourceHandleList(@MoveUniquePtr StringListDecoder d,
                              ResourceHandle ps, @Cast("tensorflow::int64") long n);

  // namespace tensorflow

// #endif  // TENSORFLOW_FRAMEWORK_RESOURCE_HANDLE_H_


// Parsed from tensorflow/core/framework/allocator.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_ALLOCATOR_H_
// #define TENSORFLOW_CORE_FRAMEWORK_ALLOCATOR_H_

// #include <stdlib.h>

// #include <limits>

// #include "tensorflow/core/framework/numeric_types.h"
// #include "tensorflow/core/framework/resource_handle.h"
// #include "tensorflow/core/framework/type_traits.h"
// #include "tensorflow/core/platform/logging.h"
// #include "tensorflow/core/platform/mutex.h"
// #include "tensorflow/core/platform/types.h"
// Targeting ../Variant.java


// Targeting ../AllocationAttributes.java


// Targeting ../AllocatorStats.java


// Targeting ../Allocator.java



// Allocator-specific constructors and destructors are used for
// strings











// Targeting ../AllocatorWrapper.java


// Targeting ../AllocatorAttributes.java



// Returns a trivial implementation of Allocator, which is a process singleton.
// Access through this function is only intended for use in tests and auxiliary
// processing.  Performance sensitive uses should always obtain allocators from
// ProcessState.
@Namespace("tensorflow") public static native Allocator cpu_allocator();

// If 'enable' is true, the default CPU allocator implementation will collect
// AllocatorStats. By default, it's disabled.
@Namespace("tensorflow") public static native void EnableCPUAllocatorStats(@Cast("bool") boolean enable);
@Namespace("tensorflow") public static native @Cast("bool") boolean CPUAllocatorStatsEnabled();

// If 'enable' is true, the default CPU allocator implementation will collect
// full statistics. By default, it's disabled.
@Namespace("tensorflow") public static native void EnableCPUAllocatorFullStats(@Cast("bool") boolean enable);
@Namespace("tensorflow") public static native @Cast("bool") boolean CPUAllocatorFullStatsEnabled();
// Targeting ../SubAllocator.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_ALLOCATOR_H_


// Parsed from tensorflow/core/framework/tensor_shape.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/tensor_shape.proto

// #ifndef PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2ftensor_5fshape_2eproto
// #define PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2ftensor_5fshape_2eproto

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3006001
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3006001 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/unknown_field_set.h>
// @@protoc_insertion_point(includes)
// #define PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_2fcore_2fframework_2ftensor_5fshape_2eproto
// Internal implementation detail -- do not use these members.
  // namespace protobuf_tensorflow_2fcore_2fframework_2ftensor_5fshape_2eproto
  // namespace tensorflow


  // namespace protobuf
  // namespace google
// Targeting ../TensorShapeProto_Dim.java


// Targeting ../TensorShapeProto.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// TensorShapeProto_Dim

// int64 size = 1;




// string name = 2;



// #if LANG_CXX11

// #endif








// -------------------------------------------------------------------

// TensorShapeProto

// repeated .tensorflow.TensorShapeProto.Dim dim = 2;








// bool unknown_rank = 3;




// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2ftensor_5fshape_2eproto


// Parsed from tensorflow/core/framework/types.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/types.proto

// #ifndef PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2ftypes_2eproto
// #define PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2ftypes_2eproto

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3006001
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3006001 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/generated_enum_reflection.h>
// @@protoc_insertion_point(includes)
// #define PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_2fcore_2fframework_2ftypes_2eproto
// Internal implementation detail -- do not use these members.
  // namespace protobuf_tensorflow_2fcore_2fframework_2ftypes_2eproto
  // namespace tensorflow

/** enum tensorflow::DataType */
public static final int
  DT_INVALID = 0,
  DT_FLOAT = 1,
  DT_DOUBLE = 2,
  DT_INT32 = 3,
  DT_UINT8 = 4,
  DT_INT16 = 5,
  DT_INT8 = 6,
  DT_STRING = 7,
  DT_COMPLEX64 = 8,
  DT_INT64 = 9,
  DT_BOOL = 10,
  DT_QINT8 = 11,
  DT_QUINT8 = 12,
  DT_QINT32 = 13,
  DT_BFLOAT16 = 14,
  DT_QINT16 = 15,
  DT_QUINT16 = 16,
  DT_UINT16 = 17,
  DT_COMPLEX128 = 18,
  DT_HALF = 19,
  DT_RESOURCE = 20,
  DT_VARIANT = 21,
  DT_UINT32 = 22,
  DT_UINT64 = 23,
  DT_FLOAT_REF = 101,
  DT_DOUBLE_REF = 102,
  DT_INT32_REF = 103,
  DT_UINT8_REF = 104,
  DT_INT16_REF = 105,
  DT_INT8_REF = 106,
  DT_STRING_REF = 107,
  DT_COMPLEX64_REF = 108,
  DT_INT64_REF = 109,
  DT_BOOL_REF = 110,
  DT_QINT8_REF = 111,
  DT_QUINT8_REF = 112,
  DT_QINT32_REF = 113,
  DT_BFLOAT16_REF = 114,
  DT_QINT16_REF = 115,
  DT_QUINT16_REF = 116,
  DT_UINT16_REF = 117,
  DT_COMPLEX128_REF = 118,
  DT_HALF_REF = 119,
  DT_RESOURCE_REF = 120,
  DT_VARIANT_REF = 121,
  DT_UINT32_REF = 122,
  DT_UINT64_REF = 123,
  DataType_INT_MIN_SENTINEL_DO_NOT_USE_ = kint32min,
  DataType_INT_MAX_SENTINEL_DO_NOT_USE_ = kint32max;
@Namespace("tensorflow") public static native @Cast("bool") boolean DataType_IsValid(int value);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::DataType") int DataType_MIN();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::DataType") int DataType_MAX();
@Namespace("tensorflow") @MemberGetter public static native int DataType_ARRAYSIZE();

@Namespace("tensorflow") public static native @Cast("const google::protobuf::EnumDescriptor*") Pointer DataType_descriptor();
@Namespace("tensorflow") public static native @StdString BytePointer DataType_Name(@Cast("tensorflow::DataType") int value);
@Namespace("tensorflow") public static native @Cast("bool") boolean DataType_Parse(
    @StdString BytePointer name, @Cast("tensorflow::DataType*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean DataType_Parse(
    @StdString String name, @Cast("tensorflow::DataType*") IntPointer value);
// ===================================================================


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__

// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow


  // namespace protobuf
  // namespace google

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2ftypes_2eproto


// Parsed from tensorflow/core/framework/resource_handle.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/resource_handle.proto

// #ifndef PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fresource_5fhandle_2eproto
// #define PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fresource_5fhandle_2eproto

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3006001
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3006001 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/unknown_field_set.h>
// @@protoc_insertion_point(includes)
// #define PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_2fcore_2fframework_2fresource_5fhandle_2eproto
// Internal implementation detail -- do not use these members.
  // namespace protobuf_tensorflow_2fcore_2fframework_2fresource_5fhandle_2eproto
  // namespace tensorflow

  // namespace protobuf
  // namespace google
// Targeting ../ResourceHandleProto.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// ResourceHandleProto

// string device = 1;



// #if LANG_CXX11

// #endif








// string container = 2;



// #if LANG_CXX11

// #endif








// string name = 3;



// #if LANG_CXX11

// #endif








// uint64 hash_code = 4;




// string maybe_type_name = 5;



// #if LANG_CXX11

// #endif








// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__

// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fresource_5fhandle_2eproto


// Parsed from tensorflow/core/framework/tensor.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/tensor.proto

// #ifndef PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2ftensor_2eproto
// #define PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2ftensor_2eproto

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3006001
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3006001 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/resource_handle.pb.h"
// #include "tensorflow/core/framework/tensor_shape.pb.h"
// #include "tensorflow/core/framework/types.pb.h"
// @@protoc_insertion_point(includes)
// #define PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_2fcore_2fframework_2ftensor_2eproto
// Internal implementation detail -- do not use these members.
  // namespace protobuf_tensorflow_2fcore_2fframework_2ftensor_2eproto
  // namespace tensorflow


  // namespace protobuf
  // namespace google
// Targeting ../TensorProto.java


// Targeting ../VariantTensorDataProto.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// TensorProto

// .tensorflow.DataType dtype = 1;




// .tensorflow.TensorShapeProto tensor_shape = 2;








// int32 version_number = 3;




// bytes tensor_content = 4;



// #if LANG_CXX11

// #endif








// repeated int32 half_val = 13 [packed = true];








// repeated float float_val = 5 [packed = true];








// repeated double double_val = 6 [packed = true];








// repeated int32 int_val = 7 [packed = true];








// repeated bytes string_val = 8;





// #if LANG_CXX11

// #endif




// #if LANG_CXX11

// #endif





// repeated float scomplex_val = 9 [packed = true];








// repeated int64 int64_val = 10 [packed = true];








// repeated bool bool_val = 11 [packed = true];








// repeated double dcomplex_val = 12 [packed = true];








// repeated .tensorflow.ResourceHandleProto resource_handle_val = 14;







// repeated .tensorflow.VariantTensorDataProto variant_val = 15;








// repeated uint32 uint32_val = 16 [packed = true];








// repeated uint64 uint64_val = 17 [packed = true];








// -------------------------------------------------------------------

// VariantTensorDataProto

// string type_name = 1;



// #if LANG_CXX11

// #endif








// bytes metadata = 2;



// #if LANG_CXX11

// #endif








// repeated .tensorflow.TensorProto tensors = 3;








// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2ftensor_2eproto


// Parsed from tensorflow/core/framework/tensor_description.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/tensor_description.proto

// #ifndef PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2ftensor_5fdescription_2eproto
// #define PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2ftensor_5fdescription_2eproto

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3006001
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3006001 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/types.pb.h"
// #include "tensorflow/core/framework/tensor_shape.pb.h"
// #include "tensorflow/core/framework/allocation_description.pb.h"
// @@protoc_insertion_point(includes)
// #define PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_2fcore_2fframework_2ftensor_5fdescription_2eproto
// Internal implementation detail -- do not use these members.
  // namespace protobuf_tensorflow_2fcore_2fframework_2ftensor_5fdescription_2eproto
  // namespace tensorflow

  // namespace protobuf
  // namespace google
// Targeting ../TensorDescription.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// TensorDescription

// .tensorflow.DataType dtype = 1;




// .tensorflow.TensorShapeProto shape = 2;








// .tensorflow.AllocationDescription allocation_description = 4;








// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__

// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2ftensor_5fdescription_2eproto


// Parsed from tensorflow/core/framework/tensor_types.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_TENSOR_TYPES_H_
// #define TENSORFLOW_CORE_FRAMEWORK_TENSOR_TYPES_H_

// #include "third_party/eigen3/unsupported/Eigen/CXX11/Tensor"

// Helper to define Tensor types given that the scalar is of type T.

  // namespace tensorflow
// #endif  // TENSORFLOW_CORE_FRAMEWORK_TENSOR_TYPES_H_


// Parsed from tensorflow/core/framework/tensor_shape.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_TENSOR_SHAPE_H_
// #define TENSORFLOW_CORE_FRAMEWORK_TENSOR_SHAPE_H_

// #include <string>

// #include "third_party/eigen3/unsupported/Eigen/CXX11/Tensor"
// #include "tensorflow/core/framework/types.pb.h"
// #include "tensorflow/core/lib/core/errors.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// #include "tensorflow/core/lib/gtl/inlined_vector.h"
// #include "tensorflow/core/lib/strings/str_util.h"
// #include "tensorflow/core/platform/logging.h"

// START_SKIP_DOXYGEN
// Targeting ../TensorShapeRep.java


// Targeting ../TensorShapeBase.java



/** Outputs {@code TensorShapeBase} to {@code std::ostream}. */
// Targeting ../TensorShape.java


// Targeting ../TensorShapeDim.java


// Targeting ../TensorShapeIter.java


// Targeting ../TensorShapeUtils.java


// Targeting ../PartialTensorShape.java


// Targeting ../PartialTensorShapeUtils.java



// ----------------------------------------------------------------------------
// Template method implementation details below
// ----------------------------------------------------------------------------





// ----------------------------------------------------------------------------
// Inlining of some performance critical routines
// ----------------------------------------------------------------------------













// Declare explicit instantiations in .cc file

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_TENSOR_SHAPE_H_


// Parsed from tensorflow/core/framework/tensor_util.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_TENSOR_UTIL_H_
// #define TENSORFLOW_CORE_FRAMEWORK_TENSOR_UTIL_H_

// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor.pb.h"
// #include "tensorflow/core/framework/tensor_shape.pb.h"

// #include <vector>

// DeepCopy returns a tensor whose contents are a deep copy of the
// contents of 'other'.  This function is intended only for
// convenience, not speed.
//
// REQUIRES: 'other' must point to data stored in CPU memory.
// REQUIRES: 'other' must be a Tensor of a copy-able type if
//           'other' is not appropriately memory-aligned.
@Namespace("tensorflow::tensor") public static native @ByVal Tensor DeepCopy(@Const @ByRef Tensor other);

// Concatenates 'tensors' into a single tensor, along their 0th dimension.
//
// REQUIRES: All members of 'tensors' must have the same data type parameter.
// REQUIRES: Each member of 'tensors' must have at least one dimension.
// REQUIRES: Each member of 'tensors' must point to data stored in CPU memory.
// REQUIRES: Each member of 'tensors' must be a Tensor of a copy-able type if it
//           is not appropriately memory-aligned.
@Namespace("tensorflow::tensor") public static native @ByVal Status Concat(@Const @ByRef TensorVector tensors,
              Tensor result);

// Splits 'tensor' into 'sizes.size()' individual tensors, along the 0th
// dimension. The ith output tensor has 0th-dimension size 'sizes[i]'.
//
// REQUIRES: 'tensor' must have at least one dimension.
// REQUIRES: 'tensor.dim_size(0)' must equal the sum of the elements of 'sizes'.
// REQUIRES: 'tensor' must point to data stored in CPU memory.
// REQUIRES: 'tensor' must be a Tensor of a copy-able type if it is not
//           appropriately memory-aligned.
//
// Split() and Concat() are inverse operations.
@Namespace("tensorflow::tensor") public static native @ByVal Status Split(@Const @ByRef Tensor tensor, @Cast("tensorflow::int64*") @ArraySlice LongPointer sizes,
             TensorVector result);
@Namespace("tensorflow::tensor") public static native @ByVal Status Split(@Const @ByRef Tensor tensor, @Cast("tensorflow::int64*") @ArraySlice LongBuffer sizes,
             TensorVector result);
@Namespace("tensorflow::tensor") public static native @ByVal Status Split(@Const @ByRef Tensor tensor, @Cast("tensorflow::int64*") @ArraySlice long[] sizes,
             TensorVector result);
@Namespace("tensorflow::tensor::internal") public static native void SetTensorProtoShape(@Cast("size_t*") @StdVector SizeTPointer shape,
                         TensorShapeProto shape_proto);

// Defines value type dependent methods to manipulate `TensorProto`.
// Class specializations has to define following methods:
//   static DataType GetDataType()
//   static void AddValue(Type value, TensorProto* proto)
  // namespace internal

// Creates a 'TensorProto' with specified shape and values.
// The dtype and a field to represent data values of the returned 'TensorProto'
// are determined based on type of the 'values' parameter.

  // namespace tensor
  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_TENSOR_UTIL_H_


// Parsed from tensorflow/core/framework/tensor_reference.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_FRAMEWORK_TENSOR_REFERENCE_H_
// #define TENSORFLOW_FRAMEWORK_TENSOR_REFERENCE_H_

// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/lib/gtl/inlined_vector.h"
// Targeting ../TensorReference.java



  // namespace tensorflow

// #endif  // TENSORFLOW_FRAMEWORK_TENSOR_REFERENCE_H_


// Parsed from tensorflow/core/framework/tensor.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_TENSOR_H_
// #define TENSORFLOW_CORE_FRAMEWORK_TENSOR_H_

// #include <cstdint>
// #include <type_traits>
// #include "third_party/eigen3/unsupported/Eigen/CXX11/Tensor"
// #include "tensorflow/core/framework/allocator.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/tensor_types.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/framework/types.pb.h"
// #include "tensorflow/core/lib/core/refcount.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/lib/gtl/inlined_vector.h"
// #include "tensorflow/core/platform/logging.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/mem.h"
// #include "tensorflow/core/platform/types.h"
// Targeting ../Var.java


@Namespace("tensorflow::batch_util") public static native @ByVal Status CopyElementToSlice(@ByVal Tensor element, Tensor parent, @Cast("tensorflow::int64") long index);
@Namespace("tensorflow::batch_util") public static native @ByVal Status MaybeMoveSliceToElement(Tensor parent, Tensor element, @Cast("tensorflow::int64") long index);

// Targeting ../Tensor.java


// Targeting ../TensorBuffer.java





















































// A packed representation for a single scalar value of type `T`, and a
// `TensorBuffer` implementation that describes (and manages the lifetime of)
// that value.

/* static */






// END_SKIP_DOXYGEN

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_TENSOR_H_


// Parsed from tensorflow/core/framework/attr_value.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/attr_value.proto

// #ifndef PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fattr_5fvalue_2eproto
// #define PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fattr_5fvalue_2eproto

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3006001
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3006001 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/map.h>  // IWYU pragma: export
// #include <google/protobuf/map_entry.h>
// #include <google/protobuf/map_field_inl.h>
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/tensor.pb.h"
// #include "tensorflow/core/framework/tensor_shape.pb.h"
// #include "tensorflow/core/framework/types.pb.h"
// @@protoc_insertion_point(includes)
// #define PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_2fcore_2fframework_2fattr_5fvalue_2eproto
// Internal implementation detail -- do not use these members.
  // namespace protobuf_tensorflow_2fcore_2fframework_2fattr_5fvalue_2eproto
// Targeting ../NameAttrList_AttrEntry_DoNotUse.java


  // namespace tensorflow




  // namespace protobuf
  // namespace google
// Targeting ../AttrValue_ListValue.java


// Targeting ../AttrValue.java


// -------------------------------------------------------------------
// Targeting ../NameAttrList.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// AttrValue_ListValue

// repeated bytes s = 2;





// #if LANG_CXX11

// #endif




// #if LANG_CXX11

// #endif





// repeated int64 i = 3 [packed = true];








// repeated float f = 4 [packed = true];








// repeated bool b = 5 [packed = true];








// repeated .tensorflow.DataType type = 6 [packed = true];








// repeated .tensorflow.TensorShapeProto shape = 7;







// repeated .tensorflow.TensorProto tensor = 8;







// repeated .tensorflow.NameAttrList func = 9;








// -------------------------------------------------------------------

// AttrValue

// bytes s = 2;





// #if LANG_CXX11

// #endif








// int64 i = 3;






// float f = 4;






// bool b = 5;






// .tensorflow.DataType type = 6;






// .tensorflow.TensorShapeProto shape = 7;









// .tensorflow.TensorProto tensor = 8;









// .tensorflow.AttrValue.ListValue list = 1;










// .tensorflow.NameAttrList func = 10;










// string placeholder = 9;





// #if LANG_CXX11

// #endif











// -------------------------------------------------------------------

// -------------------------------------------------------------------

// NameAttrList

// string name = 1;



// #if LANG_CXX11

// #endif








// map<string, .tensorflow.AttrValue> attr = 2;





// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fattr_5fvalue_2eproto


// Parsed from tensorflow/core/framework/node_def.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/node_def.proto

// #ifndef PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fnode_5fdef_2eproto
// #define PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fnode_5fdef_2eproto

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3006001
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3006001 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/map.h>  // IWYU pragma: export
// #include <google/protobuf/map_entry.h>
// #include <google/protobuf/map_field_inl.h>
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/attr_value.pb.h"
// @@protoc_insertion_point(includes)
// #define PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_2fcore_2fframework_2fnode_5fdef_2eproto
// Internal implementation detail -- do not use these members.
  // namespace protobuf_tensorflow_2fcore_2fframework_2fnode_5fdef_2eproto
// Targeting ../NodeDef_AttrEntry_DoNotUse.java


  // namespace tensorflow



  // namespace protobuf
  // namespace google

// ===================================================================
// Targeting ../NodeDef_ExperimentalDebugInfo.java


// Targeting ../NodeDef.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// -------------------------------------------------------------------

// NodeDef_ExperimentalDebugInfo

// repeated string original_node_names = 1;





// #if LANG_CXX11

// #endif




// #if LANG_CXX11

// #endif





// -------------------------------------------------------------------

// NodeDef

// string name = 1;



// #if LANG_CXX11

// #endif








// string op = 2;



// #if LANG_CXX11

// #endif








// repeated string input = 3;





// #if LANG_CXX11

// #endif




// #if LANG_CXX11

// #endif





// string device = 4;



// #if LANG_CXX11

// #endif








// map<string, .tensorflow.AttrValue> attr = 5;




// .tensorflow.NodeDef.ExperimentalDebugInfo experimental_debug_info = 6;









// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fnode_5fdef_2eproto


// Parsed from tensorflow/core/framework/api_def.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/api_def.proto

// #ifndef PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fapi_5fdef_2eproto
// #define PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fapi_5fdef_2eproto

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3006001
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3006001 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/generated_enum_reflection.h>
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/attr_value.pb.h"
// @@protoc_insertion_point(includes)
// #define PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_2fcore_2fframework_2fapi_5fdef_2eproto
// Internal implementation detail -- do not use these members.
  // namespace protobuf_tensorflow_2fcore_2fframework_2fapi_5fdef_2eproto
  // namespace tensorflow





  // namespace protobuf
  // namespace google

/** enum tensorflow::ApiDef_Visibility */
public static final int
  ApiDef_Visibility_DEFAULT_VISIBILITY = 0,
  ApiDef_Visibility_VISIBLE = 1,
  ApiDef_Visibility_SKIP = 2,
  ApiDef_Visibility_HIDDEN = 3,
  ApiDef_Visibility_ApiDef_Visibility_INT_MIN_SENTINEL_DO_NOT_USE_ = kint32min,
  ApiDef_Visibility_ApiDef_Visibility_INT_MAX_SENTINEL_DO_NOT_USE_ = kint32max;
@Namespace("tensorflow") public static native @Cast("bool") boolean ApiDef_Visibility_IsValid(int value);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::ApiDef_Visibility") int ApiDef_Visibility_Visibility_MIN();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::ApiDef_Visibility") int ApiDef_Visibility_Visibility_MAX();
@Namespace("tensorflow") @MemberGetter public static native int ApiDef_Visibility_Visibility_ARRAYSIZE();

@Namespace("tensorflow") public static native @Cast("const google::protobuf::EnumDescriptor*") Pointer ApiDef_Visibility_descriptor();
@Namespace("tensorflow") public static native @StdString BytePointer ApiDef_Visibility_Name(@Cast("tensorflow::ApiDef_Visibility") int value);
@Namespace("tensorflow") public static native @Cast("bool") boolean ApiDef_Visibility_Parse(
    @StdString BytePointer name, @Cast("tensorflow::ApiDef_Visibility*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean ApiDef_Visibility_Parse(
    @StdString String name, @Cast("tensorflow::ApiDef_Visibility*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean ApiDef_Visibility_Parse(
    @StdString BytePointer name, @Cast("tensorflow::ApiDef_Visibility*") int... value);
@Namespace("tensorflow") public static native @Cast("bool") boolean ApiDef_Visibility_Parse(
    @StdString String name, @Cast("tensorflow::ApiDef_Visibility*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean ApiDef_Visibility_Parse(
    @StdString BytePointer name, @Cast("tensorflow::ApiDef_Visibility*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean ApiDef_Visibility_Parse(
    @StdString String name, @Cast("tensorflow::ApiDef_Visibility*") int... value);
// Targeting ../ApiDef_Endpoint.java


// Targeting ../ApiDef_Arg.java


// Targeting ../ApiDef_Attr.java


// Targeting ../ApiDef.java


// Targeting ../ApiDefs.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// ApiDef_Endpoint

// string name = 1;



// #if LANG_CXX11

// #endif








// bool deprecated = 3;




// int32 deprecation_version = 4;




// -------------------------------------------------------------------

// ApiDef_Arg

// string name = 1;



// #if LANG_CXX11

// #endif








// string rename_to = 2;



// #if LANG_CXX11

// #endif








// string description = 3;



// #if LANG_CXX11

// #endif








// -------------------------------------------------------------------

// ApiDef_Attr

// string name = 1;



// #if LANG_CXX11

// #endif








// string rename_to = 2;



// #if LANG_CXX11

// #endif








// .tensorflow.AttrValue default_value = 3;








// string description = 4;



// #if LANG_CXX11

// #endif








// -------------------------------------------------------------------

// ApiDef

// string graph_op_name = 1;



// #if LANG_CXX11

// #endif








// string deprecation_message = 12;



// #if LANG_CXX11

// #endif








// int32 deprecation_version = 13;




// .tensorflow.ApiDef.Visibility visibility = 2;




// repeated .tensorflow.ApiDef.Endpoint endpoint = 3;








// repeated .tensorflow.ApiDef.Arg in_arg = 4;








// repeated .tensorflow.ApiDef.Arg out_arg = 5;








// repeated string arg_order = 11;





// #if LANG_CXX11

// #endif




// #if LANG_CXX11

// #endif





// repeated .tensorflow.ApiDef.Attr attr = 6;








// string summary = 7;



// #if LANG_CXX11

// #endif








// string description = 8;



// #if LANG_CXX11

// #endif








// string description_prefix = 9;



// #if LANG_CXX11

// #endif








// string description_suffix = 10;



// #if LANG_CXX11

// #endif








// -------------------------------------------------------------------

// ApiDefs

// repeated .tensorflow.ApiDef op = 1;








// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow


  // namespace protobuf
  // namespace google

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fapi_5fdef_2eproto


// Parsed from tensorflow/core/framework/op_def.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/op_def.proto

// #ifndef PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fop_5fdef_2eproto
// #define PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fop_5fdef_2eproto

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3006001
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3006001 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/attr_value.pb.h"
// #include "tensorflow/core/framework/types.pb.h"
// @@protoc_insertion_point(includes)
// #define PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_2fcore_2fframework_2fop_5fdef_2eproto
// Internal implementation detail -- do not use these members.
  // namespace protobuf_tensorflow_2fcore_2fframework_2fop_5fdef_2eproto
  // namespace tensorflow





  // namespace protobuf
  // namespace google
// Targeting ../OpDef_ArgDef.java


// Targeting ../OpDef_AttrDef.java


// Targeting ../OpDef.java


// Targeting ../OpDeprecation.java


// Targeting ../OpList.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// OpDef_ArgDef

// string name = 1;



// #if LANG_CXX11

// #endif








// string description = 2;



// #if LANG_CXX11

// #endif








// .tensorflow.DataType type = 3;




// string type_attr = 4;



// #if LANG_CXX11

// #endif








// string number_attr = 5;



// #if LANG_CXX11

// #endif








// string type_list_attr = 6;



// #if LANG_CXX11

// #endif








// bool is_ref = 16;




// -------------------------------------------------------------------

// OpDef_AttrDef

// string name = 1;



// #if LANG_CXX11

// #endif








// string type = 2;



// #if LANG_CXX11

// #endif








// .tensorflow.AttrValue default_value = 3;








// string description = 4;



// #if LANG_CXX11

// #endif








// bool has_minimum = 5;




// int64 minimum = 6;




// .tensorflow.AttrValue allowed_values = 7;








// -------------------------------------------------------------------

// OpDef

// string name = 1;



// #if LANG_CXX11

// #endif








// repeated .tensorflow.OpDef.ArgDef input_arg = 2;








// repeated .tensorflow.OpDef.ArgDef output_arg = 3;








// repeated .tensorflow.OpDef.AttrDef attr = 4;








// .tensorflow.OpDeprecation deprecation = 8;









// string summary = 5;



// #if LANG_CXX11

// #endif








// string description = 6;



// #if LANG_CXX11

// #endif








// bool is_commutative = 18;




// bool is_aggregate = 16;




// bool is_stateful = 17;




// bool allows_uninitialized_input = 19;




// -------------------------------------------------------------------

// OpDeprecation

// int32 version = 1;




// string explanation = 2;



// #if LANG_CXX11

// #endif








// -------------------------------------------------------------------

// OpList

// repeated .tensorflow.OpDef op = 1;








// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fop_5fdef_2eproto


// Parsed from tensorflow/core/framework/function.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/function.proto

// #ifndef PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2ffunction_2eproto
// #define PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2ffunction_2eproto

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3006001
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3006001 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/map.h>  // IWYU pragma: export
// #include <google/protobuf/map_entry.h>
// #include <google/protobuf/map_field_inl.h>
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/attr_value.pb.h"
// #include "tensorflow/core/framework/node_def.pb.h"
// #include "tensorflow/core/framework/op_def.pb.h"
// @@protoc_insertion_point(includes)
// #define PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_2fcore_2fframework_2ffunction_2eproto
// Internal implementation detail -- do not use these members.
  // namespace protobuf_tensorflow_2fcore_2fframework_2ffunction_2eproto
// Targeting ../FunctionDef_AttrEntry_DoNotUse.java


// Targeting ../FunctionDef_RetEntry_DoNotUse.java


  // namespace tensorflow





  // namespace protobuf
  // namespace google
// Targeting ../FunctionDefLibrary.java


// -------------------------------------------------------------------

// -------------------------------------------------------------------
// Targeting ../FunctionDef.java


// Targeting ../GradientDef.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// FunctionDefLibrary

// repeated .tensorflow.FunctionDef function = 1;








// repeated .tensorflow.GradientDef gradient = 2;








// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// FunctionDef

// .tensorflow.OpDef signature = 1;








// map<string, .tensorflow.AttrValue> attr = 5;




// repeated .tensorflow.NodeDef node_def = 3;







// map<string, string> ret = 4;





// -------------------------------------------------------------------

// GradientDef

// string function_name = 1;



// #if LANG_CXX11

// #endif








// string gradient_func = 2;



// #if LANG_CXX11

// #endif








// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2ffunction_2eproto


// Parsed from tensorflow/core/framework/graph.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/graph.proto

// #ifndef PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fgraph_2eproto
// #define PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fgraph_2eproto

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3006001
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3006001 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/node_def.pb.h"
// #include "tensorflow/core/framework/function.pb.h"
// #include "tensorflow/core/framework/versions.pb.h"
// @@protoc_insertion_point(includes)
// #define PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_2fcore_2fframework_2fgraph_2eproto
// Internal implementation detail -- do not use these members.
  // namespace protobuf_tensorflow_2fcore_2fframework_2fgraph_2eproto
  // namespace tensorflow

  // namespace protobuf
  // namespace google
// Targeting ../GraphDef.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// GraphDef

// repeated .tensorflow.NodeDef node = 1;







// .tensorflow.VersionDef versions = 4;








// int32 version = 3 [deprecated = true];




// .tensorflow.FunctionDefLibrary library = 2;








// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__

// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fgraph_2eproto


// Parsed from tensorflow/core/framework/session_state.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_SESSION_STATE_H_
// #define TENSORFLOW_CORE_FRAMEWORK_SESSION_STATE_H_

// #include <string>
// #include <unordered_map>
// #include <vector>

// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/lib/core/errors.h"
// #include "tensorflow/core/platform/mutex.h"
// Targeting ../SessionState.java


// Targeting ../TensorStore.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_SESSION_STATE_H_


// Parsed from tensorflow/core/framework/types.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_TYPES_H_
// #define TENSORFLOW_CORE_FRAMEWORK_TYPES_H_

// #include <map>
// #include <set>
// #include <string>

// #include "third_party/eigen3/unsupported/Eigen/CXX11/Tensor"
// Disable clang-format to prevent 'FixedPoint' header from being included
// before 'Tensor' header on which it depends.
// clang-format off
// #include "third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint"
// clang-format on
// #include "tensorflow/core/framework/bfloat16.h"
// #include "tensorflow/core/framework/numeric_types.h"
// #include "tensorflow/core/framework/resource_handle.h"
// #include "tensorflow/core/framework/types.pb.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// #include "tensorflow/core/lib/gtl/inlined_vector.h"
// #include "tensorflow/core/platform/logging.h"
// #include "tensorflow/core/platform/types.h"

// MemoryType is used to describe whether input or output Tensors of
// an OpKernel should reside in "Host memory" (e.g., CPU memory) or
// "Device" Memory (CPU memory for CPU devices, GPU memory for GPU
// devices).
/** enum tensorflow::MemoryType */
public static final int
  DEVICE_MEMORY = 0,
  HOST_MEMORY = 1;
// Targeting ../DeviceType.java


@Namespace("tensorflow") public static native @Cast("std::ostream*") @ByRef @Name("operator <<") Pointer shiftLeft(@Cast("std::ostream*") @ByRef Pointer os, @Const @ByRef DeviceType d);

// Convenient constants that can be passed to a DeviceType constructor
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer DEVICE_CPU();   // "CPU"
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer DEVICE_GPU();   // "GPU"
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer DEVICE_SYCL();
// Targeting ../DeviceName.java



// #if GOOGLE_CUDA
// #endif  // GOOGLE_CUDA

// #ifdef TENSORFLOW_USE_SYCL
// #endif  // TENSORFLOW_USE_SYCL

// Convert the enums to strings for errors:
@Namespace("tensorflow") public static native @StdString BytePointer DataTypeString(@Cast("tensorflow::DataType") int dtype);
@Namespace("tensorflow") public static native @StdString BytePointer DeviceTypeString(@Const @ByRef DeviceType device_type);
@Namespace("tensorflow") public static native @StdString BytePointer DataTypeSliceString(@ByVal @Cast("const tensorflow::DataTypeSlice*") DataTypeVector dtypes);
@Namespace("tensorflow") public static native @StdString BytePointer DataTypeVectorString(@Const @ByRef DataTypeVector dtypes);
// Targeting ../DataTypeSet.java



// If "sp" names a valid type, store it in "*dt" and return true.  Otherwise,
// return false.
@Namespace("tensorflow") public static native @Cast("bool") boolean DataTypeFromString(@StringPiece BytePointer sp, @Cast("tensorflow::DataType*") IntPointer dt);
@Namespace("tensorflow") public static native @Cast("bool") boolean DataTypeFromString(@StringPiece String sp, @Cast("tensorflow::DataType*") IntPointer dt);

@Namespace("tensorflow") public static native @Const @ByVal DataTypeSet ToSet(@Cast("tensorflow::DataType") int dt);

// DT_FLOAT + kDataTypeRefOffset == DT_FLOAT_REF, etc.
/** enum tensorflow:: */
public static final int kDataTypeRefOffset = 100;
@Namespace("tensorflow") public static native @Cast("bool") boolean IsRefType(@Cast("tensorflow::DataType") int dtype);
@Namespace("tensorflow") public static native @Cast("tensorflow::DataType") int MakeRefType(@Cast("tensorflow::DataType") int dtype);
@Namespace("tensorflow") public static native @Cast("tensorflow::DataType") int RemoveRefType(@Cast("tensorflow::DataType") int dtype);
@Namespace("tensorflow") public static native @Cast("tensorflow::DataType") int BaseType(@Cast("tensorflow::DataType") int dtype);

// Returns true if the actual type is the same as or ref of the expected type.
@Namespace("tensorflow") public static native @Cast("bool") boolean TypesCompatible(@Cast("tensorflow::DataType") int expected, @Cast("tensorflow::DataType") int actual);

// Does not include _ref types.
@Namespace("tensorflow") @MemberGetter public static native @Const @ByRef DataTypeSet kAllTypes();
@Namespace("tensorflow") public static native @Const @ByRef DataTypeSet AllTypes();

// #if !defined(IS_MOBILE_PLATFORM) || defined(SUPPORT_SELECTIVE_REGISTRATION)

// Types that support '<' and '>'.
@Namespace("tensorflow") @MemberGetter public static native @Const @ByRef DataTypeSet kRealNumberTypes();
@Namespace("tensorflow") public static native @Const @ByVal DataTypeSet RealNumberTypes();

// Return the list of all numeric types.
// Includes complex and quantized types.
// NOTE: On Android, we only include the float and int32 types for now.
@Namespace("tensorflow") @MemberGetter public static native @Const @ByRef DataTypeSet kNumberTypes();


@Namespace("tensorflow") @MemberGetter public static native @Const @ByRef DataTypeSet kQuantizedTypes();


// Types that support '<' and '>', including quantized types.
@Namespace("tensorflow") @MemberGetter public static native @Const @ByRef DataTypeSet kRealAndQuantizedTypes();


// #elif defined(__ANDROID_TYPES_FULL__)




// #else  // defined(IS_MOBILE_PLATFORM) && !defined(__ANDROID_TYPES_FULL__)




// #endif  // defined(IS_MOBILE_PLATFORM)

// Validates type T for whether it is a supported DataType.

// DataTypeToEnum<T>::v() and DataTypeToEnum<T>::value are the DataType
// constants for T, e.g. DataTypeToEnum<float>::v() is DT_FLOAT.  // Specializations below

// EnumToDataType<VALUE>::Type is the type for DataType constant VALUE, e.g.
// EnumToDataType<DT_FLOAT>::Type is float.  // Specializations below

// Template specialization for both DataTypeToEnum and EnumToDataType.
// #define MATCH_TYPE_AND_ENUM(TYPE, ENUM)
//   template <>
//   struct DataTypeToEnum<TYPE> {
//     static DataType v() { return ENUM; }
//     static DataType ref() { return MakeRefType(ENUM); }
//     static constexpr DataType value = ENUM;
//   };
//   template <>
//   struct IsValidDataType<TYPE> {
//     static constexpr bool value = true;
//   };
//   template <>
//   struct EnumToDataType<ENUM> {
//     typedef TYPE Type;
//   }
// Targeting ../DataTypeToEnum.java


// Targeting ../IsValidDataType.java


// Targeting ../EnumToDataType.java



// #undef MATCH_TYPE_AND_ENUM

// All types not specialized are marked invalid.

// Extra validity checking; not part of public API.

// TODO(jeff): Maybe unify this with Tensor::CanUseDMA, or the underlying
// is_simple<T> in tensor.cc (and possible choose a more general name?)
@Namespace("tensorflow") @MemberGetter public static native @Const @ByRef DataTypeSet kDataTypesCanUseMemcpy();
@Namespace("tensorflow") public static native @Cast("bool") boolean DataTypeCanUseMemcpy(@Cast("tensorflow::DataType") int dt);

// Returns true iff 'dt' is a real, non-quantized floating point type.
@Namespace("tensorflow") @MemberGetter public static native @Const @ByRef DataTypeSet kDataTypeIsFloating();
@Namespace("tensorflow") public static native @Cast("bool") boolean DataTypeIsFloating(@Cast("tensorflow::DataType") int dt);

// Returns true iff 'dt' is a complex type.
@Namespace("tensorflow") @MemberGetter public static native @Const @ByRef DataTypeSet kDataTypeIsComplex();
@Namespace("tensorflow") public static native @Cast("bool") boolean DataTypeIsComplex(@Cast("tensorflow::DataType") int dt);

@Namespace("tensorflow") public static native @Cast("bool") boolean DataTypeIsQuantized(@Cast("tensorflow::DataType") int dt);

// Is the dtype nonquantized integral?
@Namespace("tensorflow") @MemberGetter public static native @Const @ByRef DataTypeSet kDataTypeIsInteger();
@Namespace("tensorflow") public static native @Cast("bool") boolean DataTypeIsInteger(@Cast("tensorflow::DataType") int dt);

// Is the dtype a signed integral type?
@Namespace("tensorflow") @MemberGetter public static native @Const @ByRef DataTypeSet kDataTypeIsSigned();
@Namespace("tensorflow") public static native @Cast("bool") boolean DataTypeIsSigned(@Cast("tensorflow::DataType") int dt);

// Is the dtype an unsigned integral type?
@Namespace("tensorflow") @MemberGetter public static native @Const @ByRef DataTypeSet kDataTypeIsUnsigned();
@Namespace("tensorflow") public static native @Cast("bool") boolean DataTypeIsUnsigned(@Cast("tensorflow::DataType") int dt);

// Returns a 0 on failure
@Namespace("tensorflow") public static native int DataTypeSize(@Cast("tensorflow::DataType") int dt);

// Returns HOST_MEMORY if `dtype` is always on host or is a DT_INT32,
// DEVICE_MEMORY otherwise.
@Namespace("tensorflow") public static native @Cast("tensorflow::MemoryType") int MTypeFromDType(@Cast("const tensorflow::DataType") int dtype);

// Types that always sit on host: DT_STRING, DT_STRING_REF, DT_RESOURCE.
// For DT_RESOURCE, the handle always sits on host (even if the underlying
// object has device-allocated resources).
@Namespace("tensorflow") public static native @Cast("bool") boolean DataTypeAlwaysOnHost(@Cast("tensorflow::DataType") int dt);

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_TYPES_H_


// Parsed from tensorflow/core/framework/control_flow.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_CONTROL_FLOW_H_
// #define TENSORFLOW_CORE_FRAMEWORK_CONTROL_FLOW_H_

// #include "tensorflow/core/lib/hash/hash.h"
// #include "tensorflow/core/platform/logging.h"
// #include "tensorflow/core/platform/types.h"

@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::uint64") long kIllegalFrameId();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::int64") long kIllegalIterId();
// Targeting ../FrameAndIter.java


// Targeting ../FrameAndIterHash.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_CONTROL_FLOW_H_


// Parsed from tensorflow/core/framework/kernel_def.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/kernel_def.proto

// #ifndef PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fkernel_5fdef_2eproto
// #define PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fkernel_5fdef_2eproto

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3006001
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3006001 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/attr_value.pb.h"
// @@protoc_insertion_point(includes)
// #define PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_2fcore_2fframework_2fkernel_5fdef_2eproto
// Internal implementation detail -- do not use these members.
  // namespace protobuf_tensorflow_2fcore_2fframework_2fkernel_5fdef_2eproto
  // namespace tensorflow



  // namespace protobuf
  // namespace google
// Targeting ../KernelDef_AttrConstraint.java


// Targeting ../KernelDef.java


// Targeting ../KernelList.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// KernelDef_AttrConstraint

// string name = 1;



// #if LANG_CXX11

// #endif








// .tensorflow.AttrValue allowed_values = 2;








// -------------------------------------------------------------------

// KernelDef

// string op = 1;



// #if LANG_CXX11

// #endif








// string device_type = 2;



// #if LANG_CXX11

// #endif








// repeated .tensorflow.KernelDef.AttrConstraint constraint = 3;








// repeated string host_memory_arg = 4;





// #if LANG_CXX11

// #endif




// #if LANG_CXX11

// #endif





// string label = 5;



// #if LANG_CXX11

// #endif








// int32 priority = 6;




// -------------------------------------------------------------------

// KernelList

// repeated .tensorflow.KernelDef kernel = 1;








// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fkernel_5fdef_2eproto


// Parsed from tensorflow/core/framework/kernel_def_builder.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_KERNEL_DEF_BUILDER_H_
// #define TENSORFLOW_CORE_FRAMEWORK_KERNEL_DEF_BUILDER_H_

// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/types.h"

// Forward declare proto so that kernels don't need to depend on it
// Targeting ../KernelDefBuilder.java



// IMPLEMENTATION



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_KERNEL_DEF_BUILDER_H_


// Parsed from tensorflow/core/framework/tracking_allocator.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_TRACKING_ALLOCATOR_H_
// #define TENSORFLOW_CORE_FRAMEWORK_TRACKING_ALLOCATOR_H_

// #include <unordered_map>
// #include "tensorflow/core/framework/allocator.h"
// #include "tensorflow/core/lib/core/refcount.h"
// #include "tensorflow/core/lib/gtl/inlined_vector.h"
// #include "tensorflow/core/platform/mutex.h"
// #include "tensorflow/core/platform/thread_annotations.h"
// #include "tensorflow/core/platform/types.h"
// Targeting ../AllocRecord.java


// Targeting ../TrackingAllocator.java



  // end namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_TRACKING_ALLOCATOR_H_


// Parsed from tensorflow/core/framework/op_kernel.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_OP_KERNEL_H_
// #define TENSORFLOW_CORE_FRAMEWORK_OP_KERNEL_H_

// #include <functional>

// #include <utility>
// #include <vector>
// #include "tensorflow/core/framework/allocator.h"
// #include "tensorflow/core/framework/cancellation.h"
// #include "tensorflow/core/framework/control_flow.h"
// #include "tensorflow/core/framework/device_base.h"
// #include "tensorflow/core/framework/graph.pb.h"
// #include "tensorflow/core/framework/kernel_def.pb.h"
// #include "tensorflow/core/framework/kernel_def_builder.h"
// #include "tensorflow/core/framework/node_def_util.h"
// #include "tensorflow/core/framework/op.h"  // TODO(b/62899350): Remove
// #include "tensorflow/core/framework/rendezvous.h"
// #include "tensorflow/core/framework/selective_registration.h"
// #include "tensorflow/core/framework/session_state.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/tensor_shape.pb.h"  // TODO(b/62899350): Remove
// #include "tensorflow/core/framework/tracking_allocator.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/framework/types.pb.h"
// #include "tensorflow/core/framework/unique_tensor_references.h"
// #include "tensorflow/core/lib/core/errors.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// #include "tensorflow/core/lib/gtl/manual_constructor.h"
// #include "tensorflow/core/platform/env.h"
// #include "tensorflow/core/platform/logging.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/mutex.h"
// #include "tensorflow/core/platform/thread_annotations.h"
// #include "tensorflow/core/platform/types.h"
// Targeting ../ThreadPoolDevice.java


// Targeting ../GpuDevice.java


// Targeting ../SyclDevice.java



// Targeting ../TensorSliceReaderCacheWrapper.java


  // namespace checkpoint  // declared below
// Targeting ../ResourceMgr.java


// Targeting ../ScopedStepContainer.java


// Targeting ../CollectiveExecutor.java


// Targeting ../StepStatsCollectorInterface.java


// Targeting ../OpKernel.java


// Targeting ../AsyncOpKernel.java


// Targeting ../PersistentTensor.java


// Targeting ../OpKernelConstruction.java



// TODO(mrry): Consider converting to a random_access_iterator, and upgrading
// tensorflow::gtl::iterator_range to make the below container classes
// unnecessary.
// Targeting ../OpInputList.java


// Targeting ../OpMutableInputList.java


// Targeting ../OpOutputList.java


// Targeting ../TensorValue.java


// Targeting ../GraphCollector.java


// Targeting ../OpKernelContext.java



// Register your OpKernel by specifying the Op's name, the device the
// kernel runs on, any type attr constraints for this kernel, any
// host-memory args, and the class to instantiate.  Examples:
//
//  // A kernel that supports all types.
//  REGISTER_KERNEL_BUILDER(Name("Save").Device(DEVICE_CPU), SaveOp);
//
//  // The following are equivalent ways of specifying that the kernel only
//  // works if the "T" type attr is set to DT_FLOAT.
//  REGISTER_KERNEL_BUILDER(
//      Name("Sub").Device(DEVICE_CPU).TypeConstraint<float>("T"),
//      SubOp<float>);
//  // (You would then repeat this for every type supported by "Sub".)
//
//  // This form allows you to specify a list of types as the constraint.
//  REGISTER_KERNEL_BUILDER(Name("Sub")
//                              .Device(DEVICE_CPU)
//                              .TypeConstraint("T", {DT_FLOAT}),
//                          SubOp<float>);
//
//  // A kernel that expects one of the input tensors in host memory.
//  REGISTER_KERNEL_BUILDER(
//      Name("Reshape").Device(DEVICE_GPU).HostMemory("shape"), ReshapeOp);
//
// See kernel_def_builder for details.

// Instantiate an OpKernel that has been registered.  Returns nullptr
// if no operation for that type of device / input signature combination
// (and a NOT_FOUND *status), or there is an error in construction (and
// an INVALID_ARGUMENT *status).  Otherwise, the caller takes ownership
// of the returned pointer.
// EXPECTED USAGE: unique_ptr<OpKernel> op = CreateOpKernel(...);
// REQUIRES: def has all attrs specified (e.g. using AddDefaultsToNodeDef()).
@Namespace("tensorflow") public static native @UniquePtr OpKernel CreateOpKernel(@ByVal DeviceType device_type,
                                         DeviceBase device,
                                         Allocator allocator,
                                         @Const @ByRef NodeDef def,
                                         int graph_def_version, Status status);
@Namespace("tensorflow") public static native @ByVal Status CreateOpKernel(@ByVal DeviceType device_type, DeviceBase device,
                      Allocator allocator, FunctionLibraryRuntime flib,
                      @Const @ByRef NodeDef def, int graph_def_version,
                      @Cast("tensorflow::OpKernel**") PointerPointer kernel);
@Namespace("tensorflow") public static native @ByVal Status CreateOpKernel(@ByVal DeviceType device_type, DeviceBase device,
                      Allocator allocator, FunctionLibraryRuntime flib,
                      @Const @ByRef NodeDef def, int graph_def_version,
                      @ByPtrPtr OpKernel kernel);

// Returns into 'device_types' the subset of prioritized_types that this
// binary has registered for the given NodeDef.
//
// REQUIRES: * 'device_types' is not nullptr.
//           * def has all attrs specified (e.g. using AddDefaultsToNodeDef()).
@Namespace("tensorflow") public static native @ByVal Status SupportedDeviceTypesForNode(
    @StdVector DeviceType prioritized_types, @Const @ByRef NodeDef def,
    @Cast("tensorflow::PrioritizedDeviceTypeVector*") AllocatorAttributesVector device_types);

// Returns a message with a description of the kernels registered for op
// `op_name`.
@Namespace("tensorflow") public static native @StdString BytePointer KernelsRegisteredForOp(@StringPiece BytePointer op_name);
@Namespace("tensorflow") public static native @StdString String KernelsRegisteredForOp(@StringPiece String op_name);

// Call once after Op registration has completed.
@Namespace("tensorflow") public static native @ByVal Status ValidateKernelRegistrations(@Const @ByRef OpRegistryInterface op_registry);
// Targeting ../RegisterKernelName.java


// Targeting ../RegisterKernelSystemName.java



  // namespace system

  // namespace register_kernel

// #define REGISTER_KERNEL_BUILDER(kernel_builder, ...)
//   REGISTER_KERNEL_BUILDER_UNIQ_HELPER(__COUNTER__, kernel_builder, __VA_ARGS__)

// #define REGISTER_KERNEL_BUILDER_UNIQ_HELPER(ctr, kernel_builder, ...)
//   REGISTER_KERNEL_BUILDER_UNIQ(ctr, kernel_builder, __VA_ARGS__)

// #define REGISTER_KERNEL_BUILDER_UNIQ(ctr, kernel_builder, ...)
//   constexpr bool should_register_##ctr##__flag =
//       SHOULD_REGISTER_OP_KERNEL(#__VA_ARGS__);
//   static ::tensorflow::kernel_factory::OpKernelRegistrar
//       registrar__body__##ctr##__object(
//           should_register_##ctr##__flag
//               ? ::tensorflow::register_kernel::kernel_builder.Bid()
//               : nullptr,
//           #__VA_ARGS__,
//           [](::tensorflow::OpKernelConstruction* context)
//               -> ::tensorflow::OpKernel* {
//             return new __VA_ARGS__(context);
//           });

// The `REGISTER_SYSTEM_KERNEL_BUILDER()` macro acts as
// `REGISTER_KERNEL_BUILDER()` except that the kernel is registered
// unconditionally even when selective registration is used.
// #define REGISTER_SYSTEM_KERNEL_BUILDER(kernel_builder, ...)
//   REGISTER_SYSTEM_KERNEL_BUILDER_UNIQ_HELPER(__COUNTER__, kernel_builder,
//                                              __VA_ARGS__)

// #define REGISTER_SYSTEM_KERNEL_BUILDER_UNIQ_HELPER(ctr, kernel_builder, ...)
//   REGISTER_SYSTEM_KERNEL_BUILDER_UNIQ(ctr, kernel_builder, __VA_ARGS__)

// #define REGISTER_SYSTEM_KERNEL_BUILDER_UNIQ(ctr, kernel_builder, ...)
//   static ::tensorflow::kernel_factory::OpKernelRegistrar
//       registrar__body__##ctr##__object(
//           ::tensorflow::register_kernel::system::kernel_builder.Bid(),
//           #__VA_ARGS__,
//           [](::tensorflow::OpKernelConstruction* context)
//               -> ::tensorflow::OpKernel* {
//             return new __VA_ARGS__(context);
//           });

// Checks whether a given kernel is registered on device_type.
@Namespace("tensorflow") public static native @Cast("bool") boolean KernelDefAvailable(@Const @ByRef DeviceType device_type, @Const @ByRef NodeDef node_def);

// If node_def has a corresponding kernel registered on device_type,
// returns OK and fill in the kernel def and kernel_class_name. <def> and
// <kernel_class_name> may be null.
@Namespace("tensorflow") public static native @ByVal Status FindKernelDef(@Const @ByRef DeviceType device_type, @Const @ByRef NodeDef node_def,
                     @Cast("const tensorflow::KernelDef**") PointerPointer def, @StdString @Cast({"char*", "std::string*"}) BytePointer kernel_class_name);
@Namespace("tensorflow") public static native @ByVal Status FindKernelDef(@Const @ByRef DeviceType device_type, @Const @ByRef NodeDef node_def,
                     @Const @ByPtrPtr KernelDef def, @StdString @Cast({"char*", "std::string*"}) BytePointer kernel_class_name);

// Writes a list of all registered kernels to LOG(INFO), to help users debug
// missing kernel errors.
@Namespace("tensorflow") public static native void LogAllRegisteredKernels();

// Gets a list of all registered kernels.
@Namespace("tensorflow") public static native @ByVal KernelList GetAllRegisteredKernels();

// Gets a list of all registered kernels for which predicate returns true
@Namespace("tensorflow") public static native @ByVal KernelList GetFilteredRegisteredKernels(
    @Const @ByRef KernelDefPredicateFn predicate);

// Gets a list of all registered kernels for a given op
@Namespace("tensorflow") public static native @ByVal KernelList GetRegisteredKernelsForOp(@StringPiece BytePointer op_name);
@Namespace("tensorflow") public static native @ByVal KernelList GetRegisteredKernelsForOp(@StringPiece String op_name);
// Targeting ../OpKernelFactory.java


// Targeting ../OpKernelRegistrar.java



  // namespace kernel_factory

// -----------------------------------------------------------------------------
// Template and inline method implementations, please ignore

















// no input if tensor == nullptr.





































// Targeting ../XlaOpKernelContext.java


@Namespace("tensorflow") public static native void CheckNotInComputeAsync(XlaOpKernelContext arg0, @Cast("const char*") BytePointer arg1);
@Namespace("tensorflow") public static native void CheckNotInComputeAsync(XlaOpKernelContext arg0, String arg1);
@Namespace("tensorflow") public static native void CheckNotInComputeAsync(OpKernelConstruction arg0, @Cast("const char*") BytePointer arg1);
@Namespace("tensorflow") public static native void CheckNotInComputeAsync(OpKernelConstruction arg0, String arg1);
@Namespace("tensorflow") public static native void CheckNotInComputeAsync(OpKernelContext ctx,
                            @Cast("const char*") BytePointer correct_macro_name);
@Namespace("tensorflow") public static native void CheckNotInComputeAsync(OpKernelContext ctx,
                            String correct_macro_name);

// #define OP_REQUIRES(CTX, EXP, STATUS)
//   do {
//     if (!TF_PREDICT_TRUE(EXP)) {
//       CheckNotInComputeAsync((CTX), "OP_REQUIRES_ASYNC");
//       (CTX)->CtxFailure(__FILE__, __LINE__, (STATUS));
//       return;
//     }
//   } while (0)

// #define OP_REQUIRES_OK(CTX, ...)
//   do {
//     ::tensorflow::Status _s(__VA_ARGS__);
//     if (!TF_PREDICT_TRUE(_s.ok())) {
//       CheckNotInComputeAsync((CTX), "OP_REQUIRES_OK_ASYNC");
//       (CTX)->CtxFailureWithWarning(__FILE__, __LINE__, _s);
//       return;
//     }
//   } while (0)

// #define OP_REQUIRES_ASYNC(CTX, EXP, STATUS, CALLBACK)
//   do {
//     if (!TF_PREDICT_TRUE(EXP)) {
//       (CTX)->CtxFailure(__FILE__, __LINE__, (STATUS));
//       (CALLBACK)();
//       return;
//     }
//   } while (0)

// #define OP_REQUIRES_OK_ASYNC(CTX, STATUS, CALLBACK)
//   do {
//     ::tensorflow::Status _s(STATUS);
//     if (!TF_PREDICT_TRUE(_s.ok())) {
//       (CTX)->CtxFailureWithWarning(__FILE__, __LINE__, _s);
//       (CALLBACK)();
//       return;
//     }
//   } while (0)

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_OP_KERNEL_H_


// Parsed from tensorflow/core/framework/op_segment.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_FRAMEWORK_OP_SEGMENT_H_
// #define TENSORFLOW_FRAMEWORK_OP_SEGMENT_H_

// #include <string>
// #include <unordered_map>

// #include "tensorflow/core/framework/op_kernel.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/mutex.h"
// #include "tensorflow/core/platform/thread_annotations.h"
// #include "tensorflow/core/platform/types.h"
// Targeting ../OpSegment.java



  // end namespace tensorflow

// #endif  // TENSORFLOW_FRAMEWORK_OP_SEGMENT_H_


// Parsed from tensorflow/core/framework/shape_inference.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
// #ifndef TENSORFLOW_CORE_FRAMEWORK_SHAPE_INFERENCE_H_
// #define TENSORFLOW_CORE_FRAMEWORK_SHAPE_INFERENCE_H_

// #include <vector>

// #include "tensorflow/core/framework/node_def_util.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/lib/core/errors.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/gtl/inlined_vector.h"
// #include "tensorflow/core/platform/macros.h"
// Targeting ../ShapeRefinerTest.java


// Targeting ../GraphProperties.java


// Targeting ../SymbolicShapeManager.java


  // namespace grappler
// Targeting ../Dimension.java


// Targeting ../DimensionHandle.java


// Targeting ../Shape.java


// Targeting ../ShapeHandle.java


// Targeting ../DimensionOrConstant.java


// Targeting ../ShapeAndType.java


// Targeting ../InferenceContext.java



// -----------------------------------------------------------------------------
// Template and inline method implementations, please ignore













  // namespace shape_inference
  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_SHAPE_INFERENCE_H_


// Parsed from tensorflow/core/framework/partial_tensor_shape.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_PARTIAL_TENSOR_SHAPE_H_
// #define TENSORFLOW_CORE_FRAMEWORK_PARTIAL_TENSOR_SHAPE_H_

// TODO(irving): Remove this forwarding header
// #include "tensorflow/core/framework/tensor_shape.h"

// #endif  // TENSORFLOW_CORE_FRAMEWORK_PARTIAL_TENSOR_SHAPE_H_


// Parsed from tensorflow/core/framework/device_attributes.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/device_attributes.proto

// #ifndef PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fdevice_5fattributes_2eproto
// #define PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fdevice_5fattributes_2eproto

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3006001
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3006001 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/unknown_field_set.h>
// @@protoc_insertion_point(includes)
// #define PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_2fcore_2fframework_2fdevice_5fattributes_2eproto
// Internal implementation detail -- do not use these members.
  // namespace protobuf_tensorflow_2fcore_2fframework_2fdevice_5fattributes_2eproto
  // namespace tensorflow




  // namespace protobuf
  // namespace google
// Targeting ../InterconnectLink.java


// Targeting ../LocalLinks.java


// Targeting ../DeviceLocality.java


// Targeting ../DeviceAttributes.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// InterconnectLink

// int32 device_id = 1;




// string type = 2;



// #if LANG_CXX11

// #endif








// int32 strength = 3;




// -------------------------------------------------------------------

// LocalLinks

// repeated .tensorflow.InterconnectLink link = 1;








// -------------------------------------------------------------------

// DeviceLocality

// int32 bus_id = 1;




// int32 numa_node = 2;




// .tensorflow.LocalLinks links = 3;









// -------------------------------------------------------------------

// DeviceAttributes

// string name = 1;



// #if LANG_CXX11

// #endif








// string device_type = 2;



// #if LANG_CXX11

// #endif








// int64 memory_limit = 4;




// .tensorflow.DeviceLocality locality = 5;









// fixed64 incarnation = 6;




// string physical_device_desc = 7;



// #if LANG_CXX11

// #endif








// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2fdevice_5fattributes_2eproto


// Parsed from tensorflow/core/public/session.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_PUBLIC_SESSION_H_
// #define TENSORFLOW_CORE_PUBLIC_SESSION_H_

// #include <string>
// #include <vector>

// #include "tensorflow/core/framework/device_attributes.pb.h"
// #include "tensorflow/core/framework/graph.pb.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/platform/env.h"
// #include "tensorflow/core/protobuf/config.pb.h"
// #include "tensorflow/core/public/session_options.h"
// Targeting ../Session.java



/** \brief Create a new session with the given options.
 * 
 *  If session creation succeeds, the new {@code Session} will be stored in
 *  {@code *out_session}, the caller will take ownership of the returned
 *  {@code *out_session}, and this function will return {@code OK()}. Otherwise, this
 *  function will return an error status and set *out_session to nullptr. */

///
///
///
///
@Namespace("tensorflow") public static native @ByVal Status NewSession(@Const @ByRef SessionOptions options, @Cast("tensorflow::Session**") PointerPointer out_session);
@Namespace("tensorflow") public static native @ByVal Status NewSession(@Const @ByRef SessionOptions options, @ByPtrPtr Session out_session);

/** \brief Resets resource containers associated with a target.
 * 
 *  Reset() allows misbehaving or slow sessions to be aborted and closed, and
 *  causes their resources eventually to be released.  Reset() does not wait
 *  for the computations in old sessions to cease; it merely starts the
 *  process of tearing them down.  However, if a new session is started after
 *  a Reset(), the new session is isolated from changes that old sessions
 *  (started prior to the Reset()) may continue to make to resources, provided
 *  all those resources are in containers listed in "containers".
 * 
 *  Old sessions may continue to have side-effects on resources not in
 *  containers listed in "containers", and thus may affect future
 *  sessions' results in ways that are hard to predict.  Thus, if well-defined
 *  behavior is desired, it is recommended that all containers be listed in
 *  "containers".
 * 
 *  {@code containers} is a vector of string representation of resource container
 *  names. When a resource container is reset, the resources held by the
 *  container will be released. In particular, all Variables in the container
 *  will become undefined.  If the "containers" vector is empty, the default
 *  container is assumed.  If the "containers" vector is non-empty, the
 *  default container should be listed explicitly.
 * 
 *  If Reset succeeds, this function will return {@code OK()}. Otherwise, this
 *  function will return an error status. */

///
///
@Namespace("tensorflow") public static native @ByVal Status Reset(@Const @ByRef SessionOptions options,
             @Const @ByRef StringVector containers);

/** \brief Create a new session with the given options.
 * 
 *  If a new {@code Session} object could not be created, this function will
 *  return nullptr.
 * 
 *  *Strongly prefer* the version of NewSession that returns Status,
 *  which contains more helpful error information. */
@Namespace("tensorflow") public static native Session NewSession(@Const @ByRef SessionOptions options);

  // end namespace tensorflow

// #endif  // TENSORFLOW_CORE_PUBLIC_SESSION_H_


// Parsed from tensorflow/core/framework/tensor_slice.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/tensor_slice.proto

// #ifndef PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2ftensor_5fslice_2eproto
// #define PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2ftensor_5fslice_2eproto

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3006001
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3006001 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/unknown_field_set.h>
// @@protoc_insertion_point(includes)
// #define PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_2fcore_2fframework_2ftensor_5fslice_2eproto
// Internal implementation detail -- do not use these members.
  // namespace protobuf_tensorflow_2fcore_2fframework_2ftensor_5fslice_2eproto
  // namespace tensorflow


  // namespace protobuf
  // namespace google
// Targeting ../TensorSliceProto_Extent.java


// Targeting ../TensorSliceProto.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// TensorSliceProto_Extent

// int64 start = 1;




// int64 length = 2;









// -------------------------------------------------------------------

// TensorSliceProto

// repeated .tensorflow.TensorSliceProto.Extent extent = 1;








// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_INCLUDED_tensorflow_2fcore_2fframework_2ftensor_5fslice_2eproto


// Parsed from tensorflow/core/framework/tensor_slice.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_TENSOR_SLICE_H_
// #define TENSORFLOW_CORE_FRAMEWORK_TENSOR_SLICE_H_

// #include <string>
// #include "third_party/eigen3/unsupported/Eigen/CXX11/Tensor"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/tensor_slice.pb.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/lib/gtl/inlined_vector.h"
// #include "tensorflow/core/platform/logging.h"
// Targeting ../TensorSlice.java





  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_TENSOR_SLICE_H_


// Parsed from tensorflow/core/util/tensor_slice_set.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// A class to manage slices of a tensor. You can "register" set of slices for a
// tensor and then "query" if we have data for a given slice.

// TODO(yangke): consider moving it to a more private place so that we don't
// need to expose the API.

// #ifndef TENSORFLOW_UTIL_TENSOR_SLICE_SET_H_
// #define TENSORFLOW_UTIL_TENSOR_SLICE_SET_H_

// #include <string>  // for string
// #include <unordered_map>
// #include <vector>

// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/tensor_slice.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/core/status.h"       // for Status
// #include "tensorflow/core/lib/core/stringpiece.h"  // for StringPiece
// #include "tensorflow/core/platform/types.h"
// Targeting ../TensorSliceSet.java



// Registers "slice" in the TensorSliceSet stored in "tensor_slices", under key
// "name".  Other arguments are used for validations.  Does not modify the map
// or its values on non-OK.
// REQUIRES: tensor_slices != nullptr
@Namespace("tensorflow::checkpoint") public static native @ByVal Status RegisterTensorSlice(
    @StdString BytePointer name, @Const @ByRef TensorShape shape, @Cast("tensorflow::DataType") int type,
    @StdString BytePointer tag, @Const @ByRef TensorSlice slice,
    StringTensorSliceSetMap tensor_slices);
@Namespace("tensorflow::checkpoint") public static native @ByVal Status RegisterTensorSlice(
    @StdString String name, @Const @ByRef TensorShape shape, @Cast("tensorflow::DataType") int type,
    @StdString String tag, @Const @ByRef TensorSlice slice,
    StringTensorSliceSetMap tensor_slices);

  // namespace checkpoint

  // namespace tensorflow

// #endif  // TENSORFLOW_UTIL_TENSOR_SLICE_SET_H_


// Parsed from tensorflow/core/util/tensor_slice_util.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_UTIL_TENSOR_SLICE_UTIL_H_
// #define TENSORFLOW_UTIL_TENSOR_SLICE_UTIL_H_

// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/tensor_slice.h"
// #include "tensorflow/core/platform/logging.h"

// Some hackery to invoke eigen tensor to copy over tensor slices with variable
// dimension tensors.
// TODO(yangke): get rid of that once the variable dimension tensor support is
// in.
@Namespace("tensorflow") @MemberGetter public static native int kTensorSliceMaxRank();
public static final int kTensorSliceMaxRank = kTensorSliceMaxRank();

// Create a tensor map with the given shape: we support up to 8 dimensions. If
// the shape has less than 8 dimensions, we pad the remaining dimension with 1.

// For everything except string, a standard Eigen cast and assignment works
// Targeting ../CopyThatWorksWithStringPointer.java



// Checkpointing of half is done by storing the raw 16 bits as a signed 32bit
// integer. To restore the checkpoint we need to do the reverse operation by
// reinterpreting the integer as a 16 bit float. This prevents us from using
// the default cast operation.

// Given a tensor described by "shape", two slices "slice_s" and "slice_d",
// and two pointers "ptr_s" and "ptr_d", where "ptr_s" points to a chunk of
// memory that stores the data for "slice_s" and "ptr_d" points to a chunk of
// memory that stores the data for "slice_d". This function copies the data
// that belongs to the intersection of the two slices from slice_s to
// slice_d.  Uses Tensor cast<DstT>() to convert from SrcT to DstT. Returns true
// iff the two slices share any intersection (and thus some data is copied).
// TODO(yangke): figure out if we can make it private.

  // namespace

  // namespace tensorflow

// #endif  // TENSORFLOW_UTIL_TENSOR_SLICE_UTIL_H_


// Parsed from tensorflow/core/util/tensor_slice_reader.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// The utility to read checkpoints for google brain tensor ops and v3
// checkpoints for dist_belief.

// #ifndef TENSORFLOW_CORE_UTIL_TENSOR_SLICE_READER_H_
// #define TENSORFLOW_CORE_UTIL_TENSOR_SLICE_READER_H_

// #include <unordered_map>

// #include <vector>
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/tensor_slice.h"
// #include "tensorflow/core/framework/types.pb.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/lib/gtl/map_util.h"
// #include "tensorflow/core/platform/logging.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/mutex.h"
// #include "tensorflow/core/platform/protobuf.h"
// #include "tensorflow/core/platform/types.h"
// #include "tensorflow/core/util/saved_tensor_slice.pb.h"
// #include "tensorflow/core/util/saved_tensor_slice_util.h"
// #include "tensorflow/core/util/tensor_slice_set.h"
// #include "tensorflow/core/util/tensor_slice_util.h"
// Targeting ../TensorSliceReader.java



@Namespace("tensorflow::checkpoint") public static native @ByVal Status OpenTableTensorSliceReader(@StdString BytePointer fname,
                                  @Cast("tensorflow::checkpoint::TensorSliceReader::Table**") PointerPointer table);
@Namespace("tensorflow::checkpoint") public static native @ByVal Status OpenTableTensorSliceReader(@StdString BytePointer fname,
                                  @ByPtrPtr TensorSliceReader.Table table);
@Namespace("tensorflow::checkpoint") public static native @ByVal Status OpenTableTensorSliceReader(@StdString String fname,
                                  @ByPtrPtr TensorSliceReader.Table table);



  // namespace checkpoint

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_UTIL_TENSOR_SLICE_READER_H_


// Parsed from tensorflow/core/util/tensor_bundle/tensor_bundle.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// A tensor bundle is a set of immutable persistent files storing a set of named
// tensors.  It is designed for checkpointing TensorFlow tensors.
//
// The paths of the managed files share a common prefix; e.g., with the prefix:
//   /fs/model/train/ckpt-step/ckpt
//
// the bundle may contain a metadata file, and sharded data files:
//   /fs/model/train/ckpt-step/
//       ckpt.index
//       ckpt.data-00000-of-00020
//       ckpt.data-00001-of-00020
//       ...
//       ckpt.data-00019-of-00020
//
// The ".index" file is a string-string immutable table
// (tensorflow::table::Table).  Each key is a name of a tensor and its value is
// a serialized BundleEntryProto.  Each BundleEntryProto describes the metadata
// of a tensor: which of the "data" files contains the content of a tensor, the
// offset into that file, checksum, some auxiliary data, etc.
//
// A tensor bundle can be accessed randomly using a BundleReader.  Usage:
//
//   BundleReader reader(env, "/fs/model/train/ckpt-step/ckpt");
//   reader.Lookup("name", &tensor);
//
// A tensor bundle can be built using BundleWriter.  Each BundleWriter builds a
// single data file bundle.  Multiple bundles can then be merged by
// MergeBundles() without reading and writing large chunk of data: it reads the
// metadata files and outputs a single merged metadata.  Typical usage:
//
//   worker 0:
//     BundleWriter writer(env, "/fs/model/train/ckpt-step/tmp/worker0-step");
//     writer.Add(...);  // Adds the tensors on this worker.
//     writer.Finish();  // Flushes.
//   worker 1:
//     BundleWriter writer(env, "/fs/model/train/ckpt-step/tmp/worker1-step");
//     writer.Add(...);
//     writer.Finish();
//   worker 2:
//     MergeBundles(env,
//       {"/fs/model/train/ckpt-step/tmp/worker0-step",
//        "/fs/model/train/ckpt-step/tmp/worker1-step"},
//       "/fs/model/train/ckpt-step/ckpt" /* merged prefix */);
//

// #ifndef TENSORFLOW_CORE_UTIL_TENSOR_BUNDLE_TENSOR_BUNDLE_H_
// #define TENSORFLOW_CORE_UTIL_TENSOR_BUNDLE_TENSOR_BUNDLE_H_

// #include "tensorflow/core/protobuf/tensor_bundle.pb.h"

// #include <map>
// #include <string>
// #include <unordered_map>

// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/tensor_slice.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// #include "tensorflow/core/lib/io/inputbuffer.h"
// #include "tensorflow/core/lib/io/table.h"
// #include "tensorflow/core/platform/env.h"
// #include "tensorflow/core/platform/file_system.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/types.h"
// #include "tensorflow/core/util/tensor_bundle/naming.h"
// #include "tensorflow/core/util/tensor_slice_set.h"

// Versioning of the tensor bundle format.
// Follows the same rules as 3p/tf/core/public/version.h.
//
// History:
// 0. Any tensor bundles produced before this field was added.
// 1. Added this field (2016-09-14).
@Namespace("tensorflow") @MemberGetter public static native int kTensorBundleMinProducer();
@Namespace("tensorflow") @MemberGetter public static native int kTensorBundleMinConsumer();
@Namespace("tensorflow") @MemberGetter public static native int kTensorBundleVersion();

// The empty string, hence always the first key in the metadata table.  Its
// corresponding value is a BundleHeaderProto.
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer kHeaderEntryKey();
// Targeting ../BundleWriter.java



// Merges a set of bundles (given their prefixes) into a single bundle with the
// given "merged_prefix".  The merged metadata is guaranteed to be consistent.
//
// If there are N bundles in "prefixes", during the merge the data files will be
// renamed to contain a proper sharded file spec, with num_shards set to the sum
// of num_shards across the N input bundles.
//
// The caller should only rely on the metadata file of the merged bundle to
// query information about a tensor.  In particular, this function does not
// guarantee not to re-order the input data files.
//
// Once merged, makes a best effort to delete the old metadata files.
// Returns OK iff all bundles are successfully merged.
@Namespace("tensorflow") public static native @ByVal Status MergeBundles(Env env, @ByVal @Cast("tensorflow::gtl::ArraySlice<tensorflow::string>*") StringVector prefixes,
                    @StringPiece BytePointer merged_prefix);
@Namespace("tensorflow") public static native @ByVal Status MergeBundles(Env env, @ByVal @Cast("tensorflow::gtl::ArraySlice<tensorflow::string>*") StringVector prefixes,
                    @StringPiece String merged_prefix);
// Targeting ../BundleReader.java


// Targeting ../FileOutputBuffer.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_UTIL_TENSOR_BUNDLE_TENSOR_BUNDLE_H_


// Parsed from tensorflow/core/protobuf/tensorflow_server.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/protobuf/tensorflow_server.proto

// #ifndef PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2ftensorflow_5fserver_2eproto
// #define PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2ftensorflow_5fserver_2eproto

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3006001
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3006001 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/protobuf/config.pb.h"
// #include "tensorflow/core/protobuf/cluster.pb.h"
// @@protoc_insertion_point(includes)
// #define PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_2fcore_2fprotobuf_2ftensorflow_5fserver_2eproto
// Internal implementation detail -- do not use these members.
  // namespace protobuf_tensorflow_2fcore_2fprotobuf_2ftensorflow_5fserver_2eproto
  // namespace tensorflow

  // namespace protobuf
  // namespace google
// Targeting ../ServerDef.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// ServerDef

// .tensorflow.ClusterDef cluster = 1;








// string job_name = 2;



// #if LANG_CXX11

// #endif








// int32 task_index = 3;




// .tensorflow.ConfigProto default_session_config = 4;








// string protocol = 5;



// #if LANG_CXX11

// #endif








// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__

// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2ftensorflow_5fserver_2eproto


// Parsed from tensorflow/core/distributed_runtime/server_lib.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_DISTRIBUTED_RUNTIME_SERVER_LIB_H_
// #define TENSORFLOW_CORE_DISTRIBUTED_RUNTIME_SERVER_LIB_H_

// #include <memory>

// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/protobuf/tensorflow_server.pb.h"
// Targeting ../ServerInterface.java


// Targeting ../ServerFactory.java



// Creates a server based on the given `server_def`, and stores it in
// `*out_server`. Returns OK on success, otherwise returns an error.
@Namespace("tensorflow") public static native @ByVal Status NewServer(@Const @ByRef ServerDef server_def,
                 @UniquePtr ServerInterface out_server);

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_DISTRIBUTED_RUNTIME_SERVER_LIB_H_


// Parsed from tensorflow/c/tf_status_helper.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_C_TF_STATUS_HELPER_H_
// #define TENSORFLOW_C_TF_STATUS_HELPER_H_

// #include "tensorflow/c/c_api.h"
// #include "tensorflow/core/lib/core/status.h"

// Set the attribute of "tf_status" from the attributes of "status".
@Namespace("tensorflow") public static native void Set_TF_Status_from_Status(TF_Status tf_status, @Const @ByRef Status status);

// Returns a "status" from "tf_status".
@Namespace("tensorflow") public static native @ByVal Status StatusFromTF_Status(@Const TF_Status tf_status);

  // namespace tensorflow

// #endif  // TENSORFLOW_C_TF_STATUS_HELPER_H_


// Parsed from tensorflow/c/checkpoint_reader.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_C_CHECKPOINT_READER_H_
// #define TENSORFLOW_C_CHECKPOINT_READER_H_

// #include <memory>
// #include <string>

// #include "tensorflow/c/tf_status_helper.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/platform/types.h"
// #include "tensorflow/core/util/tensor_bundle/tensor_bundle.h"
// #include "tensorflow/core/util/tensor_slice_reader.h"
// Targeting ../CheckpointReader.java



  // namespace checkpoint
  // namespace tensorflow

// #endif  // TENSORFLOW_C_CHECKPOINT_READER_H_


// Parsed from tensorflow/c/c_api.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_C_C_API_H_
// #define TENSORFLOW_C_C_API_H_

// #include <stddef.h>
// #include <stdint.h>

// --------------------------------------------------------------------------
// C API for TensorFlow.
//
// The API leans towards simplicity and uniformity instead of convenience
// since most usage will be by language specific wrappers.
//
// Conventions:
// * We use the prefix TF_ for everything in the API.
// * Objects are always passed around as pointers to opaque structs
//   and these structs are allocated/deallocated via the API.
// * TF_Status holds error information.  It is an object type
//   and therefore is passed around as a pointer to an opaque
//   struct as mentioned above.
// * Every call that has a TF_Status* argument clears it on success
//   and fills it with error info on failure.
// * unsigned char is used for booleans (instead of the 'bool' type).
//   In C++ bool is a keyword while in C99 bool is a macro defined
//   in stdbool.h. It is possible for the two to be inconsistent.
//   For example, neither the C99 nor the C++11 standard force a byte
//   size on the bool type, so the macro defined in stdbool.h could
//   be inconsistent with the bool keyword in C++. Thus, the use
//   of stdbool.h is avoided and unsigned char is used instead.
// * size_t is used to represent byte sizes of objects that are
//   materialized in the address space of the calling process.
// * int is used as an index into arrays.
// * Deletion functions are safe to call on nullptr.
//
// Questions left to address:
// * Might at some point need a way for callers to provide their own Env.
// * Maybe add TF_TensorShape that encapsulates dimension info.
//
// Design decisions made:
// * Backing store for tensor memory has an associated deallocation
//   function.  This deallocation function will point to client code
//   for tensors populated by the client.  So the client can do things
//   like shadowing a numpy array.
// * We do not provide TF_OK since it is not strictly necessary and we
//   are not optimizing for convenience.
// * We make assumption that one session has one graph.  This should be
//   fine since we have the ability to run sub-graphs.
// * We could allow NULL for some arguments (e.g., NULL options arg).
//   However since convenience is not a primary goal, we don't do this.
// * Devices are not in this API.  Instead, they are created/used internally
//   and the API just provides high level controls over the number of
//   devices of each type.

// Macro to control visibility of exported symbols in the shared library (.so,
// .dylib, .dll).
// This duplicates the TF_EXPORT macro definition in
// tensorflow/core/platform/macros.h in order to keep this .h file independent
// of any other includes.$a
// #ifdef SWIG
// #define TF_CAPI_EXPORT
// #else
// #endif  // SWIG

// #ifdef __cplusplus
// #endif

// --------------------------------------------------------------------------
// TF_Version returns a string describing version information of the
// TensorFlow library. TensorFlow using semantic versioning.
public static native @Cast("const char*") BytePointer TF_Version();

// --------------------------------------------------------------------------
// TF_DataType holds the type for a scalar value.  E.g., one slot in a tensor.
// The enum values here are identical to corresponding values in types.proto.
/** enum TF_DataType */
public static final int
  TF_FLOAT = 1,
  TF_DOUBLE = 2,
  TF_INT32 = 3,  // Int32 tensors are always in 'host' memory.
  TF_UINT8 = 4,
  TF_INT16 = 5,
  TF_INT8 = 6,
  TF_STRING = 7,
  TF_COMPLEX64 = 8,  // Single-precision complex
  TF_COMPLEX = 8,    // Old identifier kept for API backwards compatibility
  TF_INT64 = 9,
  TF_BOOL = 10,
  TF_QINT8 = 11,     // Quantized int8
  TF_QUINT8 = 12,    // Quantized uint8
  TF_QINT32 = 13,    // Quantized int32
  TF_BFLOAT16 = 14,  // Float32 truncated to 16 bits.  Only for cast ops.
  TF_QINT16 = 15,    // Quantized int16
  TF_QUINT16 = 16,   // Quantized uint16
  TF_UINT16 = 17,
  TF_COMPLEX128 = 18,  // Double-precision complex
  TF_HALF = 19,
  TF_RESOURCE = 20,
  TF_VARIANT = 21,
  TF_UINT32 = 22,
  TF_UINT64 = 23;

// TF_DataTypeSize returns the sizeof() for the underlying type corresponding
// to the given TF_DataType enum value. Returns 0 for variable length types
// (eg. TF_STRING) or on failure.
public static native @Cast("size_t") long TF_DataTypeSize(@Cast("TF_DataType") int dt);

// --------------------------------------------------------------------------
// TF_Code holds an error code.  The enum values here are identical to
// corresponding values in error_codes.proto.
/** enum TF_Code */
public static final int
  TF_OK = 0,
  TF_CANCELLED = 1,
  TF_UNKNOWN = 2,
  TF_INVALID_ARGUMENT = 3,
  TF_DEADLINE_EXCEEDED = 4,
  TF_NOT_FOUND = 5,
  TF_ALREADY_EXISTS = 6,
  TF_PERMISSION_DENIED = 7,
  TF_UNAUTHENTICATED = 16,
  TF_RESOURCE_EXHAUSTED = 8,
  TF_FAILED_PRECONDITION = 9,
  TF_ABORTED = 10,
  TF_OUT_OF_RANGE = 11,
  TF_UNIMPLEMENTED = 12,
  TF_INTERNAL = 13,
  TF_UNAVAILABLE = 14,
  TF_DATA_LOSS = 15;

// --------------------------------------------------------------------------
// TF_Status holds error information.  It either has an OK code, or
// else an error code with an associated error message.

// Return a new status object.
public static native TF_Status TF_NewStatus();

// Delete a previously created status object.
public static native void TF_DeleteStatus(TF_Status arg0);

// Record <code, msg> in *s.  Any previous information is lost.
// A common use is to clear a status: TF_SetStatus(s, TF_OK, "");
public static native void TF_SetStatus(TF_Status s, @Cast("TF_Code") int code,
                                        @Cast("const char*") BytePointer msg);
public static native void TF_SetStatus(TF_Status s, @Cast("TF_Code") int code,
                                        String msg);

// Return the code record in *s.
public static native @Cast("TF_Code") int TF_GetCode(@Const TF_Status s);

// Return a pointer to the (null-terminated) error message in *s.  The
// return value points to memory that is only usable until the next
// mutation to *s.  Always returns an empty string if TF_GetCode(s) is
// TF_OK.
public static native @Cast("const char*") BytePointer TF_Message(@Const TF_Status s);
// Targeting ../TF_Buffer.java



// Makes a copy of the input and sets an appropriate deallocator.  Useful for
// passing in read-only, input protobufs.
public static native TF_Buffer TF_NewBufferFromString(@Const Pointer proto,
                                                        @Cast("size_t") long proto_len);

// Useful for passing *out* a protobuf.
public static native TF_Buffer TF_NewBuffer();

public static native void TF_DeleteBuffer(TF_Buffer arg0);

public static native @ByVal TF_Buffer TF_GetBuffer(TF_Buffer buffer);

// --------------------------------------------------------------------------
// TF_Tensor holds a multi-dimensional array of elements of a single data type.
// For all types other than TF_STRING, the data buffer stores elements
// in row major order.  E.g. if data is treated as a vector of TF_DataType:
//
//   element 0:   index (0, ..., 0)
//   element 1:   index (0, ..., 1)
//   ...
//
// The format for TF_STRING tensors is:
//   start_offset: array[uint64]
//   data:         byte[...]
//
//   The string length (as a varint), followed by the contents of the string
//   is encoded at data[start_offset[i]]]. TF_StringEncode and TF_StringDecode
//   facilitate this encoding.
// Targeting ../Deallocator_Pointer_long_Pointer.java


public static native TF_Tensor TF_NewTensor(
    @Cast("TF_DataType") int arg0, @Cast("const int64_t*") LongPointer dims, int num_dims, Pointer data, @Cast("size_t") long len,
    Deallocator_Pointer_long_Pointer deallocator,
    Pointer deallocator_arg);
public static native TF_Tensor TF_NewTensor(
    @Cast("TF_DataType") int arg0, @Cast("const int64_t*") LongBuffer dims, int num_dims, Pointer data, @Cast("size_t") long len,
    Deallocator_Pointer_long_Pointer deallocator,
    Pointer deallocator_arg);
public static native TF_Tensor TF_NewTensor(
    @Cast("TF_DataType") int arg0, @Cast("const int64_t*") long[] dims, int num_dims, Pointer data, @Cast("size_t") long len,
    Deallocator_Pointer_long_Pointer deallocator,
    Pointer deallocator_arg);

// Allocate and return a new Tensor.
//
// This function is an alternative to TF_NewTensor and should be used when
// memory is allocated to pass the Tensor to the C API. The allocated memory
// satisfies TensorFlow's memory alignment preferences and should be preferred
// over calling malloc and free.
//
// The caller must set the Tensor values by writing them to the pointer returned
// by TF_TensorData with length TF_TensorByteSize.
public static native TF_Tensor TF_AllocateTensor(@Cast("TF_DataType") int arg0,
                                                   @Cast("const int64_t*") LongPointer dims,
                                                   int num_dims, @Cast("size_t") long len);
public static native TF_Tensor TF_AllocateTensor(@Cast("TF_DataType") int arg0,
                                                   @Cast("const int64_t*") LongBuffer dims,
                                                   int num_dims, @Cast("size_t") long len);
public static native TF_Tensor TF_AllocateTensor(@Cast("TF_DataType") int arg0,
                                                   @Cast("const int64_t*") long[] dims,
                                                   int num_dims, @Cast("size_t") long len);

// Deletes `tensor` and returns a new TF_Tensor with the same content if
// possible. Returns nullptr and leaves `tensor` untouched if not.
public static native TF_Tensor TF_TensorMaybeMove(TF_Tensor tensor);

// Destroy a tensor.
public static native void TF_DeleteTensor(TF_Tensor arg0);

// Return the type of a tensor element.
public static native @Cast("TF_DataType") int TF_TensorType(@Const TF_Tensor arg0);

// Return the number of dimensions that the tensor has.
public static native int TF_NumDims(@Const TF_Tensor arg0);

// Return the length of the tensor in the "dim_index" dimension.
// REQUIRES: 0 <= dim_index < TF_NumDims(tensor)
public static native @Cast("int64_t") long TF_Dim(@Const TF_Tensor tensor, int dim_index);

// Return the size of the underlying data in bytes.
public static native @Cast("size_t") long TF_TensorByteSize(@Const TF_Tensor arg0);

// Return a pointer to the underlying data buffer.
public static native Pointer TF_TensorData(@Const TF_Tensor arg0);

// --------------------------------------------------------------------------
// Encode the string `src` (`src_len` bytes long) into `dst` in the format
// required by TF_STRING tensors. Does not write to memory more than `dst_len`
// bytes beyond `*dst`. `dst_len` should be at least
// TF_StringEncodedSize(src_len).
//
// On success returns the size in bytes of the encoded string.
// Returns an error into `status` otherwise.
public static native @Cast("size_t") long TF_StringEncode(@Cast("const char*") BytePointer src, @Cast("size_t") long src_len,
                                             @Cast("char*") BytePointer dst, @Cast("size_t") long dst_len,
                                             TF_Status status);
public static native @Cast("size_t") long TF_StringEncode(String src, @Cast("size_t") long src_len,
                                             @Cast("char*") ByteBuffer dst, @Cast("size_t") long dst_len,
                                             TF_Status status);
public static native @Cast("size_t") long TF_StringEncode(@Cast("const char*") BytePointer src, @Cast("size_t") long src_len,
                                             @Cast("char*") byte[] dst, @Cast("size_t") long dst_len,
                                             TF_Status status);
public static native @Cast("size_t") long TF_StringEncode(String src, @Cast("size_t") long src_len,
                                             @Cast("char*") BytePointer dst, @Cast("size_t") long dst_len,
                                             TF_Status status);
public static native @Cast("size_t") long TF_StringEncode(@Cast("const char*") BytePointer src, @Cast("size_t") long src_len,
                                             @Cast("char*") ByteBuffer dst, @Cast("size_t") long dst_len,
                                             TF_Status status);
public static native @Cast("size_t") long TF_StringEncode(String src, @Cast("size_t") long src_len,
                                             @Cast("char*") byte[] dst, @Cast("size_t") long dst_len,
                                             TF_Status status);

// Decode a string encoded using TF_StringEncode.
//
// On success, sets `*dst` to the start of the decoded string and `*dst_len` to
// its length. Returns the number of bytes starting at `src` consumed while
// decoding. `*dst` points to memory within the encoded buffer.  On failure,
// `*dst` and `*dst_len` are undefined and an error is set in `status`.
//
// Does not read memory more than `src_len` bytes beyond `src`.
public static native @Cast("size_t") long TF_StringDecode(@Cast("const char*") BytePointer src, @Cast("size_t") long src_len,
                                             @Cast("const char**") PointerPointer dst, @Cast("size_t*") SizeTPointer dst_len,
                                             TF_Status status);
public static native @Cast("size_t") long TF_StringDecode(@Cast("const char*") BytePointer src, @Cast("size_t") long src_len,
                                             @Cast("const char**") @ByPtrPtr BytePointer dst, @Cast("size_t*") SizeTPointer dst_len,
                                             TF_Status status);
public static native @Cast("size_t") long TF_StringDecode(String src, @Cast("size_t") long src_len,
                                             @Cast("const char**") @ByPtrPtr ByteBuffer dst, @Cast("size_t*") SizeTPointer dst_len,
                                             TF_Status status);
public static native @Cast("size_t") long TF_StringDecode(@Cast("const char*") BytePointer src, @Cast("size_t") long src_len,
                                             @Cast("const char**") @ByPtrPtr byte[] dst, @Cast("size_t*") SizeTPointer dst_len,
                                             TF_Status status);
public static native @Cast("size_t") long TF_StringDecode(String src, @Cast("size_t") long src_len,
                                             @Cast("const char**") @ByPtrPtr BytePointer dst, @Cast("size_t*") SizeTPointer dst_len,
                                             TF_Status status);
public static native @Cast("size_t") long TF_StringDecode(@Cast("const char*") BytePointer src, @Cast("size_t") long src_len,
                                             @Cast("const char**") @ByPtrPtr ByteBuffer dst, @Cast("size_t*") SizeTPointer dst_len,
                                             TF_Status status);
public static native @Cast("size_t") long TF_StringDecode(String src, @Cast("size_t") long src_len,
                                             @Cast("const char**") @ByPtrPtr byte[] dst, @Cast("size_t*") SizeTPointer dst_len,
                                             TF_Status status);

// Return the size in bytes required to encode a string `len` bytes long into a
// TF_STRING tensor.
public static native @Cast("size_t") long TF_StringEncodedSize(@Cast("size_t") long len);

// --------------------------------------------------------------------------
// TF_SessionOptions holds options that can be passed during session creation.

// Return a new options object.
public static native TF_SessionOptions TF_NewSessionOptions();

// Set the target in TF_SessionOptions.options.
// target can be empty, a single entry, or a comma separated list of entries.
// Each entry is in one of the following formats :
// "local"
// ip:port
// host:port
public static native void TF_SetTarget(TF_SessionOptions options,
                                        @Cast("const char*") BytePointer target);
public static native void TF_SetTarget(TF_SessionOptions options,
                                        String target);

// Set the config in TF_SessionOptions.options.
// config should be a serialized tensorflow.ConfigProto proto.
// If config was not parsed successfully as a ConfigProto, record the
// error information in *status.
public static native void TF_SetConfig(TF_SessionOptions options,
                                        @Const Pointer proto, @Cast("size_t") long proto_len,
                                        TF_Status status);

// Destroy an options object.
public static native void TF_DeleteSessionOptions(TF_SessionOptions arg0);

// TODO(jeff,sanjay):
// - export functions to set Config fields

// --------------------------------------------------------------------------
// The new graph construction API, still under development.

// Represents a computation graph.  Graphs may be shared between sessions.
// Graphs are thread-safe when used as directed below.

// Return a new graph object.
public static native TF_Graph TF_NewGraph();

// Destroy an options object.  Graph will be deleted once no more
// TFSession's are referencing it.
public static native void TF_DeleteGraph(TF_Graph arg0);

// Operation being built. The underlying graph must outlive this.

// Operation that has been added to the graph. Valid until the graph is
// deleted -- in particular adding a new operation to the graph does not
// invalidate old TF_Operation* pointers.
// Targeting ../TF_Input.java


// Targeting ../TF_Output.java



// TF_Function is a grouping of operations with defined inputs and outputs.
// Once created and added to graphs, functions can be invoked by creating an
// operation whose operation type matches the function name.
// Targeting ../TF_FunctionOptions.java



// Sets the shape of the Tensor referenced by `output` in `graph` to
// the shape described by `dims` and `num_dims`.
//
// If the number of dimensions is unknown, `num_dims` must be set to
// -1 and `dims` can be null. If a dimension is unknown, the
// corresponding entry in the `dims` array must be -1.
//
// This does not overwrite the existing shape associated with `output`,
// but merges the input shape with the existing shape.  For example,
// setting a shape of [-1, 2] with an existing shape [2, -1] would set
// a final shape of [2, 2] based on shape merging semantics.
//
// Returns an error into `status` if:
//   * `output` is not in `graph`.
//   * An invalid shape is being set (e.g., the shape being set
//     is incompatible with the existing shape).
public static native void TF_GraphSetTensorShape(TF_Graph graph,
                                                  @ByVal TF_Output output,
                                                  @Cast("const int64_t*") LongPointer dims,
                                                  int num_dims,
                                                  TF_Status status);
public static native void TF_GraphSetTensorShape(TF_Graph graph,
                                                  @ByVal TF_Output output,
                                                  @Cast("const int64_t*") LongBuffer dims,
                                                  int num_dims,
                                                  TF_Status status);
public static native void TF_GraphSetTensorShape(TF_Graph graph,
                                                  @ByVal TF_Output output,
                                                  @Cast("const int64_t*") long[] dims,
                                                  int num_dims,
                                                  TF_Status status);

// Returns the number of dimensions of the Tensor referenced by `output`
// in `graph`.
//
// If the number of dimensions in the shape is unknown, returns -1.
//
// Returns an error into `status` if:
//   * `output` is not in `graph`.
public static native int TF_GraphGetTensorNumDims(TF_Graph graph,
                                                   @ByVal TF_Output output,
                                                   TF_Status status);

// Returns the shape of the Tensor referenced by `output` in `graph`
// into `dims`. `dims` must be an array large enough to hold `num_dims`
// entries (e.g., the return value of TF_GraphGetTensorNumDims).
//
// If the number of dimensions in the shape is unknown or the shape is
// a scalar, `dims` will remain untouched. Otherwise, each element of
// `dims` will be set corresponding to the size of the dimension. An
// unknown dimension is represented by `-1`.
//
// Returns an error into `status` if:
//   * `output` is not in `graph`.
//   * `num_dims` does not match the actual number of dimensions.
public static native void TF_GraphGetTensorShape(TF_Graph graph,
                                                  @ByVal TF_Output output,
                                                  @Cast("int64_t*") LongPointer dims, int num_dims,
                                                  TF_Status status);
public static native void TF_GraphGetTensorShape(TF_Graph graph,
                                                  @ByVal TF_Output output,
                                                  @Cast("int64_t*") LongBuffer dims, int num_dims,
                                                  TF_Status status);
public static native void TF_GraphGetTensorShape(TF_Graph graph,
                                                  @ByVal TF_Output output,
                                                  @Cast("int64_t*") long[] dims, int num_dims,
                                                  TF_Status status);

// Operation will only be added to *graph when TF_FinishOperation() is
// called (assuming TF_FinishOperation() does not return an error).
// *graph must not be deleted until after TF_FinishOperation() is
// called.
public static native TF_OperationDescription TF_NewOperation(
    TF_Graph graph, @Cast("const char*") BytePointer op_type, @Cast("const char*") BytePointer oper_name);
public static native TF_OperationDescription TF_NewOperation(
    TF_Graph graph, String op_type, String oper_name);

// Specify the device for `desc`.  Defaults to empty, meaning unconstrained.
public static native void TF_SetDevice(TF_OperationDescription desc,
                                        @Cast("const char*") BytePointer device);
public static native void TF_SetDevice(TF_OperationDescription desc,
                                        String device);

// The calls to TF_AddInput and TF_AddInputList must match (in number,
// order, and type) the op declaration.  For example, the "Concat" op
// has registration:
//   REGISTER_OP("Concat")
//       .Input("concat_dim: int32")
//       .Input("values: N * T")
//       .Output("output: T")
//       .Attr("N: int >= 2")
//       .Attr("T: type");
// that defines two inputs, "concat_dim" and "values" (in that order).
// You must use TF_AddInput() for the first input (since it takes a
// single tensor), and TF_AddInputList() for the second input (since
// it takes a list, even if you were to pass a list with a single
// tensor), as in:
//   TF_OperationDescription* desc = TF_NewOperation(graph, "Concat", "c");
//   TF_Output concat_dim_input = {...};
//   TF_AddInput(desc, concat_dim_input);
//   TF_Output values_inputs[5] = {{...}, ..., {...}};
//   TF_AddInputList(desc, values_inputs, 5);

// For inputs that take a single tensor.
public static native void TF_AddInput(TF_OperationDescription desc,
                                       @ByVal TF_Output input);

// For inputs that take a list of tensors.
// inputs must point to TF_Output[num_inputs].
public static native void TF_AddInputList(TF_OperationDescription desc,
                                           @Const TF_Output inputs,
                                           int num_inputs);

// Call once per control input to `desc`.
public static native void TF_AddControlInput(TF_OperationDescription desc,
                                              TF_Operation input);

// Request that `desc` be co-located on the device where `op`
// is placed.
//
// Use of this is discouraged since the implementation of device placement is
// subject to change. Primarily intended for internal libraries
public static native void TF_ColocateWith(TF_OperationDescription desc,
                                           TF_Operation op);

// Call some TF_SetAttr*() function for every attr that is not
// inferred from an input and doesn't have a default value you wish to
// keep.

// `value` must point to a string of length `length` bytes.
public static native void TF_SetAttrString(TF_OperationDescription desc,
                                            @Cast("const char*") BytePointer attr_name,
                                            @Const Pointer value, @Cast("size_t") long length);
public static native void TF_SetAttrString(TF_OperationDescription desc,
                                            String attr_name,
                                            @Const Pointer value, @Cast("size_t") long length);
// `values` and `lengths` each must have lengths `num_values`.
// `values[i]` must point to a string of length `lengths[i]` bytes.
public static native void TF_SetAttrStringList(TF_OperationDescription desc,
                                                @Cast("const char*") BytePointer attr_name,
                                                @Cast("const void*const*") PointerPointer values,
                                                @Cast("const size_t*") SizeTPointer lengths,
                                                int num_values);
public static native void TF_SetAttrStringList(TF_OperationDescription desc,
                                                @Cast("const char*") BytePointer attr_name,
                                                @Cast("const void*const*") @ByPtrPtr Pointer values,
                                                @Cast("const size_t*") SizeTPointer lengths,
                                                int num_values);
public static native void TF_SetAttrStringList(TF_OperationDescription desc,
                                                String attr_name,
                                                @Cast("const void*const*") @ByPtrPtr Pointer values,
                                                @Cast("const size_t*") SizeTPointer lengths,
                                                int num_values);
public static native void TF_SetAttrInt(TF_OperationDescription desc,
                                         @Cast("const char*") BytePointer attr_name, @Cast("int64_t") long value);
public static native void TF_SetAttrInt(TF_OperationDescription desc,
                                         String attr_name, @Cast("int64_t") long value);
public static native void TF_SetAttrIntList(TF_OperationDescription desc,
                                             @Cast("const char*") BytePointer attr_name,
                                             @Cast("const int64_t*") LongPointer values,
                                             int num_values);
public static native void TF_SetAttrIntList(TF_OperationDescription desc,
                                             String attr_name,
                                             @Cast("const int64_t*") LongBuffer values,
                                             int num_values);
public static native void TF_SetAttrIntList(TF_OperationDescription desc,
                                             @Cast("const char*") BytePointer attr_name,
                                             @Cast("const int64_t*") long[] values,
                                             int num_values);
public static native void TF_SetAttrIntList(TF_OperationDescription desc,
                                             String attr_name,
                                             @Cast("const int64_t*") LongPointer values,
                                             int num_values);
public static native void TF_SetAttrIntList(TF_OperationDescription desc,
                                             @Cast("const char*") BytePointer attr_name,
                                             @Cast("const int64_t*") LongBuffer values,
                                             int num_values);
public static native void TF_SetAttrIntList(TF_OperationDescription desc,
                                             String attr_name,
                                             @Cast("const int64_t*") long[] values,
                                             int num_values);
public static native void TF_SetAttrFloat(TF_OperationDescription desc,
                                           @Cast("const char*") BytePointer attr_name, float value);
public static native void TF_SetAttrFloat(TF_OperationDescription desc,
                                           String attr_name, float value);
public static native void TF_SetAttrFloatList(TF_OperationDescription desc,
                                               @Cast("const char*") BytePointer attr_name,
                                               @Const FloatPointer values,
                                               int num_values);
public static native void TF_SetAttrFloatList(TF_OperationDescription desc,
                                               String attr_name,
                                               @Const FloatBuffer values,
                                               int num_values);
public static native void TF_SetAttrFloatList(TF_OperationDescription desc,
                                               @Cast("const char*") BytePointer attr_name,
                                               @Const float[] values,
                                               int num_values);
public static native void TF_SetAttrFloatList(TF_OperationDescription desc,
                                               String attr_name,
                                               @Const FloatPointer values,
                                               int num_values);
public static native void TF_SetAttrFloatList(TF_OperationDescription desc,
                                               @Cast("const char*") BytePointer attr_name,
                                               @Const FloatBuffer values,
                                               int num_values);
public static native void TF_SetAttrFloatList(TF_OperationDescription desc,
                                               String attr_name,
                                               @Const float[] values,
                                               int num_values);
public static native void TF_SetAttrBool(TF_OperationDescription desc,
                                          @Cast("const char*") BytePointer attr_name,
                                          @Cast("unsigned char") byte value);
public static native void TF_SetAttrBool(TF_OperationDescription desc,
                                          String attr_name,
                                          @Cast("unsigned char") byte value);
public static native void TF_SetAttrBoolList(TF_OperationDescription desc,
                                              @Cast("const char*") BytePointer attr_name,
                                              @Cast("const unsigned char*") BytePointer values,
                                              int num_values);
public static native void TF_SetAttrBoolList(TF_OperationDescription desc,
                                              String attr_name,
                                              @Cast("const unsigned char*") ByteBuffer values,
                                              int num_values);
public static native void TF_SetAttrBoolList(TF_OperationDescription desc,
                                              @Cast("const char*") BytePointer attr_name,
                                              @Cast("const unsigned char*") byte[] values,
                                              int num_values);
public static native void TF_SetAttrBoolList(TF_OperationDescription desc,
                                              String attr_name,
                                              @Cast("const unsigned char*") BytePointer values,
                                              int num_values);
public static native void TF_SetAttrBoolList(TF_OperationDescription desc,
                                              @Cast("const char*") BytePointer attr_name,
                                              @Cast("const unsigned char*") ByteBuffer values,
                                              int num_values);
public static native void TF_SetAttrBoolList(TF_OperationDescription desc,
                                              String attr_name,
                                              @Cast("const unsigned char*") byte[] values,
                                              int num_values);
public static native void TF_SetAttrType(TF_OperationDescription desc,
                                          @Cast("const char*") BytePointer attr_name,
                                          @Cast("TF_DataType") int value);
public static native void TF_SetAttrType(TF_OperationDescription desc,
                                          String attr_name,
                                          @Cast("TF_DataType") int value);
public static native void TF_SetAttrTypeList(TF_OperationDescription desc,
                                              @Cast("const char*") BytePointer attr_name,
                                              @Cast("const TF_DataType*") IntPointer values,
                                              int num_values);
public static native void TF_SetAttrTypeList(TF_OperationDescription desc,
                                              String attr_name,
                                              @Cast("const TF_DataType*") IntBuffer values,
                                              int num_values);
public static native void TF_SetAttrTypeList(TF_OperationDescription desc,
                                              @Cast("const char*") BytePointer attr_name,
                                              @Cast("const TF_DataType*") int[] values,
                                              int num_values);
public static native void TF_SetAttrTypeList(TF_OperationDescription desc,
                                              String attr_name,
                                              @Cast("const TF_DataType*") IntPointer values,
                                              int num_values);
public static native void TF_SetAttrTypeList(TF_OperationDescription desc,
                                              @Cast("const char*") BytePointer attr_name,
                                              @Cast("const TF_DataType*") IntBuffer values,
                                              int num_values);
public static native void TF_SetAttrTypeList(TF_OperationDescription desc,
                                              String attr_name,
                                              @Cast("const TF_DataType*") int[] values,
                                              int num_values);
// Set a 'func' attribute to the specified name.
// `value` must point to a string of length `length` bytes.
public static native void TF_SetAttrFuncName(TF_OperationDescription desc,
                                              @Cast("const char*") BytePointer attr_name,
                                              @Cast("const char*") BytePointer value, @Cast("size_t") long length);
public static native void TF_SetAttrFuncName(TF_OperationDescription desc,
                                              String attr_name,
                                              String value, @Cast("size_t") long length);

// Set `num_dims` to -1 to represent "unknown rank".  Otherwise,
// `dims` points to an array of length `num_dims`.  `dims[i]` must be
// >= -1, with -1 meaning "unknown dimension".
public static native void TF_SetAttrShape(TF_OperationDescription desc,
                                           @Cast("const char*") BytePointer attr_name,
                                           @Cast("const int64_t*") LongPointer dims, int num_dims);
public static native void TF_SetAttrShape(TF_OperationDescription desc,
                                           String attr_name,
                                           @Cast("const int64_t*") LongBuffer dims, int num_dims);
public static native void TF_SetAttrShape(TF_OperationDescription desc,
                                           @Cast("const char*") BytePointer attr_name,
                                           @Cast("const int64_t*") long[] dims, int num_dims);
public static native void TF_SetAttrShape(TF_OperationDescription desc,
                                           String attr_name,
                                           @Cast("const int64_t*") LongPointer dims, int num_dims);
public static native void TF_SetAttrShape(TF_OperationDescription desc,
                                           @Cast("const char*") BytePointer attr_name,
                                           @Cast("const int64_t*") LongBuffer dims, int num_dims);
public static native void TF_SetAttrShape(TF_OperationDescription desc,
                                           String attr_name,
                                           @Cast("const int64_t*") long[] dims, int num_dims);
// `dims` and `num_dims` must point to arrays of length `num_shapes`.
// Set `num_dims[i]` to -1 to represent "unknown rank".  Otherwise,
// `dims[i]` points to an array of length `num_dims[i]`.  `dims[i][j]`
// must be >= -1, with -1 meaning "unknown dimension".
public static native void TF_SetAttrShapeList(TF_OperationDescription desc,
                                               @Cast("const char*") BytePointer attr_name,
                                               @Cast("const int64_t*const*") PointerPointer dims,
                                               @Const IntPointer num_dims,
                                               int num_shapes);
public static native void TF_SetAttrShapeList(TF_OperationDescription desc,
                                               @Cast("const char*") BytePointer attr_name,
                                               @Cast("const int64_t*const*") @ByPtrPtr LongPointer dims,
                                               @Const IntPointer num_dims,
                                               int num_shapes);
public static native void TF_SetAttrShapeList(TF_OperationDescription desc,
                                               String attr_name,
                                               @Cast("const int64_t*const*") @ByPtrPtr LongBuffer dims,
                                               @Const IntBuffer num_dims,
                                               int num_shapes);
public static native void TF_SetAttrShapeList(TF_OperationDescription desc,
                                               @Cast("const char*") BytePointer attr_name,
                                               @Cast("const int64_t*const*") @ByPtrPtr long[] dims,
                                               @Const int[] num_dims,
                                               int num_shapes);
public static native void TF_SetAttrShapeList(TF_OperationDescription desc,
                                               String attr_name,
                                               @Cast("const int64_t*const*") @ByPtrPtr LongPointer dims,
                                               @Const IntPointer num_dims,
                                               int num_shapes);
public static native void TF_SetAttrShapeList(TF_OperationDescription desc,
                                               @Cast("const char*") BytePointer attr_name,
                                               @Cast("const int64_t*const*") @ByPtrPtr LongBuffer dims,
                                               @Const IntBuffer num_dims,
                                               int num_shapes);
public static native void TF_SetAttrShapeList(TF_OperationDescription desc,
                                               String attr_name,
                                               @Cast("const int64_t*const*") @ByPtrPtr long[] dims,
                                               @Const int[] num_dims,
                                               int num_shapes);
// `proto` must point to an array of `proto_len` bytes representing a
// binary-serialized TensorShapeProto.
public static native void TF_SetAttrTensorShapeProto(
    TF_OperationDescription desc, @Cast("const char*") BytePointer attr_name, @Const Pointer proto,
    @Cast("size_t") long proto_len, TF_Status status);
public static native void TF_SetAttrTensorShapeProto(
    TF_OperationDescription desc, String attr_name, @Const Pointer proto,
    @Cast("size_t") long proto_len, TF_Status status);
// `protos` and `proto_lens` must point to arrays of length `num_shapes`.
// `protos[i]` must point to an array of `proto_lens[i]` bytes
// representing a binary-serialized TensorShapeProto.
public static native void TF_SetAttrTensorShapeProtoList(
    TF_OperationDescription desc, @Cast("const char*") BytePointer attr_name,
    @Cast("const void*const*") PointerPointer protos, @Cast("const size_t*") SizeTPointer proto_lens, int num_shapes,
    TF_Status status);
public static native void TF_SetAttrTensorShapeProtoList(
    TF_OperationDescription desc, @Cast("const char*") BytePointer attr_name,
    @Cast("const void*const*") @ByPtrPtr Pointer protos, @Cast("const size_t*") SizeTPointer proto_lens, int num_shapes,
    TF_Status status);
public static native void TF_SetAttrTensorShapeProtoList(
    TF_OperationDescription desc, String attr_name,
    @Cast("const void*const*") @ByPtrPtr Pointer protos, @Cast("const size_t*") SizeTPointer proto_lens, int num_shapes,
    TF_Status status);

public static native void TF_SetAttrTensor(TF_OperationDescription desc,
                                            @Cast("const char*") BytePointer attr_name,
                                            TF_Tensor value,
                                            TF_Status status);
public static native void TF_SetAttrTensor(TF_OperationDescription desc,
                                            String attr_name,
                                            TF_Tensor value,
                                            TF_Status status);
public static native void TF_SetAttrTensorList(TF_OperationDescription desc,
                                                @Cast("const char*") BytePointer attr_name,
                                                @Cast("TF_Tensor*const*") PointerPointer values,
                                                int num_values,
                                                TF_Status status);
public static native void TF_SetAttrTensorList(TF_OperationDescription desc,
                                                @Cast("const char*") BytePointer attr_name,
                                                @ByPtrPtr TF_Tensor values,
                                                int num_values,
                                                TF_Status status);
public static native void TF_SetAttrTensorList(TF_OperationDescription desc,
                                                String attr_name,
                                                @ByPtrPtr TF_Tensor values,
                                                int num_values,
                                                TF_Status status);

// `proto` should point to a sequence of bytes of length `proto_len`
// representing a binary serialization of an AttrValue protocol
// buffer.
public static native void TF_SetAttrValueProto(TF_OperationDescription desc,
                                                @Cast("const char*") BytePointer attr_name,
                                                @Const Pointer proto,
                                                @Cast("size_t") long proto_len,
                                                TF_Status status);
public static native void TF_SetAttrValueProto(TF_OperationDescription desc,
                                                String attr_name,
                                                @Const Pointer proto,
                                                @Cast("size_t") long proto_len,
                                                TF_Status status);

// If this function succeeds:
//   * *status is set to an OK value,
//   * a TF_Operation is added to the graph,
//   * a non-null value pointing to the added operation is returned --
//     this value is valid until the underlying graph is deleted.
// Otherwise:
//   * *status is set to a non-OK value,
//   * the graph is not modified,
//   * a null value is returned.
// In either case, it deletes `desc`.
public static native TF_Operation TF_FinishOperation(
    TF_OperationDescription desc, TF_Status status);

// TF_Operation functions.  Operations are immutable once created, so
// these are all query functions.

public static native @Cast("const char*") BytePointer TF_OperationName(TF_Operation oper);
public static native @Cast("const char*") BytePointer TF_OperationOpType(TF_Operation oper);
public static native @Cast("const char*") BytePointer TF_OperationDevice(TF_Operation oper);

public static native int TF_OperationNumOutputs(TF_Operation oper);
public static native @Cast("TF_DataType") int TF_OperationOutputType(@ByVal TF_Output oper_out);
public static native int TF_OperationOutputListLength(TF_Operation oper,
                                                       @Cast("const char*") BytePointer arg_name,
                                                       TF_Status status);
public static native int TF_OperationOutputListLength(TF_Operation oper,
                                                       String arg_name,
                                                       TF_Status status);

public static native int TF_OperationNumInputs(TF_Operation oper);
public static native @Cast("TF_DataType") int TF_OperationInputType(@ByVal TF_Input oper_in);
public static native int TF_OperationInputListLength(TF_Operation oper,
                                                      @Cast("const char*") BytePointer arg_name,
                                                      TF_Status status);
public static native int TF_OperationInputListLength(TF_Operation oper,
                                                      String arg_name,
                                                      TF_Status status);

// In this code:
//   TF_Output producer = TF_OperationInput(consumer);
// There is an edge from producer.oper's output (given by
// producer.index) to consumer.oper's input (given by consumer.index).
public static native @ByVal TF_Output TF_OperationInput(@ByVal TF_Input oper_in);

// Get the number of current consumers of a specific output of an
// operation.  Note that this number can change when new operations
// are added to the graph.
public static native int TF_OperationOutputNumConsumers(@ByVal TF_Output oper_out);

// Get list of all current consumers of a specific output of an
// operation.  `consumers` must point to an array of length at least
// `max_consumers` (ideally set to
// TF_OperationOutputNumConsumers(oper_out)).  Beware that a concurrent
// modification of the graph can increase the number of consumers of
// an operation.  Returns the number of output consumers (should match
// TF_OperationOutputNumConsumers(oper_out)).
public static native int TF_OperationOutputConsumers(@ByVal TF_Output oper_out,
                                                      TF_Input consumers,
                                                      int max_consumers);

// Get the number of control inputs to an operation.
public static native int TF_OperationNumControlInputs(TF_Operation oper);

// Get list of all control inputs to an operation.  `control_inputs` must
// point to an array of length `max_control_inputs` (ideally set to
// TF_OperationNumControlInputs(oper)).  Returns the number of control
// inputs (should match TF_OperationNumControlInputs(oper)).
public static native int TF_OperationGetControlInputs(
    TF_Operation oper, @Cast("TF_Operation**") PointerPointer control_inputs, int max_control_inputs);
public static native int TF_OperationGetControlInputs(
    TF_Operation oper, @ByPtrPtr TF_Operation control_inputs, int max_control_inputs);

// Get the number of operations that have `*oper` as a control input.
// Note that this number can change when new operations are added to
// the graph.
public static native int TF_OperationNumControlOutputs(TF_Operation oper);

// Get the list of operations that have `*oper` as a control input.
// `control_outputs` must point to an array of length at least
// `max_control_outputs` (ideally set to
// TF_OperationNumControlOutputs(oper)). Beware that a concurrent
// modification of the graph can increase the number of control
// outputs.  Returns the number of control outputs (should match
// TF_OperationNumControlOutputs(oper)).
public static native int TF_OperationGetControlOutputs(
    TF_Operation oper, @Cast("TF_Operation**") PointerPointer control_outputs,
    int max_control_outputs);
public static native int TF_OperationGetControlOutputs(
    TF_Operation oper, @ByPtrPtr TF_Operation control_outputs,
    int max_control_outputs);

// TF_AttrType describes the type of the value of an attribute on an operation.
/** enum TF_AttrType */
public static final int
  TF_ATTR_STRING = 0,
  TF_ATTR_INT = 1,
  TF_ATTR_FLOAT = 2,
  TF_ATTR_BOOL = 3,
  TF_ATTR_TYPE = 4,
  TF_ATTR_SHAPE = 5,
  TF_ATTR_TENSOR = 6,
  TF_ATTR_PLACEHOLDER = 7,
  TF_ATTR_FUNC = 8;
// Targeting ../TF_AttrMetadata.java



// Returns metadata about the value of the attribute `attr_name` of `oper`.
public static native @ByVal TF_AttrMetadata TF_OperationGetAttrMetadata(
    TF_Operation oper, @Cast("const char*") BytePointer attr_name, TF_Status status);
public static native @ByVal TF_AttrMetadata TF_OperationGetAttrMetadata(
    TF_Operation oper, String attr_name, TF_Status status);

// Fills in `value` with the value of the attribute `attr_name`.  `value` must
// point to an array of length at least `max_length` (ideally set to
// TF_AttrMetadata.total_size from TF_OperationGetAttrMetadata(oper,
// attr_name)).
public static native void TF_OperationGetAttrString(TF_Operation oper,
                                                     @Cast("const char*") BytePointer attr_name,
                                                     Pointer value,
                                                     @Cast("size_t") long max_length,
                                                     TF_Status status);
public static native void TF_OperationGetAttrString(TF_Operation oper,
                                                     String attr_name,
                                                     Pointer value,
                                                     @Cast("size_t") long max_length,
                                                     TF_Status status);

// Get the list of strings in the value of the attribute `attr_name`.  Fills in
// `values` and `lengths`, each of which must point to an array of length at
// least `max_values`.
//
// The elements of values will point to addresses in `storage` which must be at
// least `storage_size` bytes in length.  Ideally, max_values would be set to
// TF_AttrMetadata.list_size and `storage` would be at least
// TF_AttrMetadata.total_size, obtained from TF_OperationGetAttrMetadata(oper,
// attr_name).
//
// Fails if storage_size is too small to hold the requested number of strings.
public static native void TF_OperationGetAttrStringList(
    TF_Operation oper, @Cast("const char*") BytePointer attr_name, @Cast("void**") PointerPointer values, @Cast("size_t*") SizeTPointer lengths,
    int max_values, Pointer storage, @Cast("size_t") long storage_size, TF_Status status);
public static native void TF_OperationGetAttrStringList(
    TF_Operation oper, @Cast("const char*") BytePointer attr_name, @Cast("void**") @ByPtrPtr Pointer values, @Cast("size_t*") SizeTPointer lengths,
    int max_values, Pointer storage, @Cast("size_t") long storage_size, TF_Status status);
public static native void TF_OperationGetAttrStringList(
    TF_Operation oper, String attr_name, @Cast("void**") @ByPtrPtr Pointer values, @Cast("size_t*") SizeTPointer lengths,
    int max_values, Pointer storage, @Cast("size_t") long storage_size, TF_Status status);

public static native void TF_OperationGetAttrInt(TF_Operation oper,
                                                  @Cast("const char*") BytePointer attr_name,
                                                  @Cast("int64_t*") LongPointer value,
                                                  TF_Status status);
public static native void TF_OperationGetAttrInt(TF_Operation oper,
                                                  String attr_name,
                                                  @Cast("int64_t*") LongBuffer value,
                                                  TF_Status status);
public static native void TF_OperationGetAttrInt(TF_Operation oper,
                                                  @Cast("const char*") BytePointer attr_name,
                                                  @Cast("int64_t*") long[] value,
                                                  TF_Status status);
public static native void TF_OperationGetAttrInt(TF_Operation oper,
                                                  String attr_name,
                                                  @Cast("int64_t*") LongPointer value,
                                                  TF_Status status);
public static native void TF_OperationGetAttrInt(TF_Operation oper,
                                                  @Cast("const char*") BytePointer attr_name,
                                                  @Cast("int64_t*") LongBuffer value,
                                                  TF_Status status);
public static native void TF_OperationGetAttrInt(TF_Operation oper,
                                                  String attr_name,
                                                  @Cast("int64_t*") long[] value,
                                                  TF_Status status);

// Fills in `values` with the value of the attribute `attr_name` of `oper`.
// `values` must point to an array of length at least `max_values` (ideally set
// TF_AttrMetadata.list_size from TF_OperationGetAttrMetadata(oper,
// attr_name)).
public static native void TF_OperationGetAttrIntList(TF_Operation oper,
                                                      @Cast("const char*") BytePointer attr_name,
                                                      @Cast("int64_t*") LongPointer values,
                                                      int max_values,
                                                      TF_Status status);
public static native void TF_OperationGetAttrIntList(TF_Operation oper,
                                                      String attr_name,
                                                      @Cast("int64_t*") LongBuffer values,
                                                      int max_values,
                                                      TF_Status status);
public static native void TF_OperationGetAttrIntList(TF_Operation oper,
                                                      @Cast("const char*") BytePointer attr_name,
                                                      @Cast("int64_t*") long[] values,
                                                      int max_values,
                                                      TF_Status status);
public static native void TF_OperationGetAttrIntList(TF_Operation oper,
                                                      String attr_name,
                                                      @Cast("int64_t*") LongPointer values,
                                                      int max_values,
                                                      TF_Status status);
public static native void TF_OperationGetAttrIntList(TF_Operation oper,
                                                      @Cast("const char*") BytePointer attr_name,
                                                      @Cast("int64_t*") LongBuffer values,
                                                      int max_values,
                                                      TF_Status status);
public static native void TF_OperationGetAttrIntList(TF_Operation oper,
                                                      String attr_name,
                                                      @Cast("int64_t*") long[] values,
                                                      int max_values,
                                                      TF_Status status);

public static native void TF_OperationGetAttrFloat(TF_Operation oper,
                                                    @Cast("const char*") BytePointer attr_name,
                                                    FloatPointer value,
                                                    TF_Status status);
public static native void TF_OperationGetAttrFloat(TF_Operation oper,
                                                    String attr_name,
                                                    FloatBuffer value,
                                                    TF_Status status);
public static native void TF_OperationGetAttrFloat(TF_Operation oper,
                                                    @Cast("const char*") BytePointer attr_name,
                                                    float[] value,
                                                    TF_Status status);
public static native void TF_OperationGetAttrFloat(TF_Operation oper,
                                                    String attr_name,
                                                    FloatPointer value,
                                                    TF_Status status);
public static native void TF_OperationGetAttrFloat(TF_Operation oper,
                                                    @Cast("const char*") BytePointer attr_name,
                                                    FloatBuffer value,
                                                    TF_Status status);
public static native void TF_OperationGetAttrFloat(TF_Operation oper,
                                                    String attr_name,
                                                    float[] value,
                                                    TF_Status status);

// Fills in `values` with the value of the attribute `attr_name` of `oper`.
// `values` must point to an array of length at least `max_values` (ideally set
// to TF_AttrMetadata.list_size from TF_OperationGetAttrMetadata(oper,
// attr_name)).
public static native void TF_OperationGetAttrFloatList(TF_Operation oper,
                                                        @Cast("const char*") BytePointer attr_name,
                                                        FloatPointer values,
                                                        int max_values,
                                                        TF_Status status);
public static native void TF_OperationGetAttrFloatList(TF_Operation oper,
                                                        String attr_name,
                                                        FloatBuffer values,
                                                        int max_values,
                                                        TF_Status status);
public static native void TF_OperationGetAttrFloatList(TF_Operation oper,
                                                        @Cast("const char*") BytePointer attr_name,
                                                        float[] values,
                                                        int max_values,
                                                        TF_Status status);
public static native void TF_OperationGetAttrFloatList(TF_Operation oper,
                                                        String attr_name,
                                                        FloatPointer values,
                                                        int max_values,
                                                        TF_Status status);
public static native void TF_OperationGetAttrFloatList(TF_Operation oper,
                                                        @Cast("const char*") BytePointer attr_name,
                                                        FloatBuffer values,
                                                        int max_values,
                                                        TF_Status status);
public static native void TF_OperationGetAttrFloatList(TF_Operation oper,
                                                        String attr_name,
                                                        float[] values,
                                                        int max_values,
                                                        TF_Status status);

public static native void TF_OperationGetAttrBool(TF_Operation oper,
                                                   @Cast("const char*") BytePointer attr_name,
                                                   @Cast("unsigned char*") BytePointer value,
                                                   TF_Status status);
public static native void TF_OperationGetAttrBool(TF_Operation oper,
                                                   String attr_name,
                                                   @Cast("unsigned char*") ByteBuffer value,
                                                   TF_Status status);
public static native void TF_OperationGetAttrBool(TF_Operation oper,
                                                   @Cast("const char*") BytePointer attr_name,
                                                   @Cast("unsigned char*") byte[] value,
                                                   TF_Status status);
public static native void TF_OperationGetAttrBool(TF_Operation oper,
                                                   String attr_name,
                                                   @Cast("unsigned char*") BytePointer value,
                                                   TF_Status status);
public static native void TF_OperationGetAttrBool(TF_Operation oper,
                                                   @Cast("const char*") BytePointer attr_name,
                                                   @Cast("unsigned char*") ByteBuffer value,
                                                   TF_Status status);
public static native void TF_OperationGetAttrBool(TF_Operation oper,
                                                   String attr_name,
                                                   @Cast("unsigned char*") byte[] value,
                                                   TF_Status status);

// Fills in `values` with the value of the attribute `attr_name` of `oper`.
// `values` must point to an array of length at least `max_values` (ideally set
// to TF_AttrMetadata.list_size from TF_OperationGetAttrMetadata(oper,
// attr_name)).
public static native void TF_OperationGetAttrBoolList(TF_Operation oper,
                                                       @Cast("const char*") BytePointer attr_name,
                                                       @Cast("unsigned char*") BytePointer values,
                                                       int max_values,
                                                       TF_Status status);
public static native void TF_OperationGetAttrBoolList(TF_Operation oper,
                                                       String attr_name,
                                                       @Cast("unsigned char*") ByteBuffer values,
                                                       int max_values,
                                                       TF_Status status);
public static native void TF_OperationGetAttrBoolList(TF_Operation oper,
                                                       @Cast("const char*") BytePointer attr_name,
                                                       @Cast("unsigned char*") byte[] values,
                                                       int max_values,
                                                       TF_Status status);
public static native void TF_OperationGetAttrBoolList(TF_Operation oper,
                                                       String attr_name,
                                                       @Cast("unsigned char*") BytePointer values,
                                                       int max_values,
                                                       TF_Status status);
public static native void TF_OperationGetAttrBoolList(TF_Operation oper,
                                                       @Cast("const char*") BytePointer attr_name,
                                                       @Cast("unsigned char*") ByteBuffer values,
                                                       int max_values,
                                                       TF_Status status);
public static native void TF_OperationGetAttrBoolList(TF_Operation oper,
                                                       String attr_name,
                                                       @Cast("unsigned char*") byte[] values,
                                                       int max_values,
                                                       TF_Status status);

public static native void TF_OperationGetAttrType(TF_Operation oper,
                                                   @Cast("const char*") BytePointer attr_name,
                                                   @Cast("TF_DataType*") IntPointer value,
                                                   TF_Status status);
public static native void TF_OperationGetAttrType(TF_Operation oper,
                                                   String attr_name,
                                                   @Cast("TF_DataType*") IntBuffer value,
                                                   TF_Status status);
public static native void TF_OperationGetAttrType(TF_Operation oper,
                                                   @Cast("const char*") BytePointer attr_name,
                                                   @Cast("TF_DataType*") int[] value,
                                                   TF_Status status);
public static native void TF_OperationGetAttrType(TF_Operation oper,
                                                   String attr_name,
                                                   @Cast("TF_DataType*") IntPointer value,
                                                   TF_Status status);
public static native void TF_OperationGetAttrType(TF_Operation oper,
                                                   @Cast("const char*") BytePointer attr_name,
                                                   @Cast("TF_DataType*") IntBuffer value,
                                                   TF_Status status);
public static native void TF_OperationGetAttrType(TF_Operation oper,
                                                   String attr_name,
                                                   @Cast("TF_DataType*") int[] value,
                                                   TF_Status status);

// Fills in `values` with the value of the attribute `attr_name` of `oper`.
// `values` must point to an array of length at least `max_values` (ideally set
// to TF_AttrMetadata.list_size from TF_OperationGetAttrMetadata(oper,
// attr_name)).
public static native void TF_OperationGetAttrTypeList(TF_Operation oper,
                                                       @Cast("const char*") BytePointer attr_name,
                                                       @Cast("TF_DataType*") IntPointer values,
                                                       int max_values,
                                                       TF_Status status);
public static native void TF_OperationGetAttrTypeList(TF_Operation oper,
                                                       String attr_name,
                                                       @Cast("TF_DataType*") IntBuffer values,
                                                       int max_values,
                                                       TF_Status status);
public static native void TF_OperationGetAttrTypeList(TF_Operation oper,
                                                       @Cast("const char*") BytePointer attr_name,
                                                       @Cast("TF_DataType*") int[] values,
                                                       int max_values,
                                                       TF_Status status);
public static native void TF_OperationGetAttrTypeList(TF_Operation oper,
                                                       String attr_name,
                                                       @Cast("TF_DataType*") IntPointer values,
                                                       int max_values,
                                                       TF_Status status);
public static native void TF_OperationGetAttrTypeList(TF_Operation oper,
                                                       @Cast("const char*") BytePointer attr_name,
                                                       @Cast("TF_DataType*") IntBuffer values,
                                                       int max_values,
                                                       TF_Status status);
public static native void TF_OperationGetAttrTypeList(TF_Operation oper,
                                                       String attr_name,
                                                       @Cast("TF_DataType*") int[] values,
                                                       int max_values,
                                                       TF_Status status);

// Fills in `value` with the value of the attribute `attr_name` of `oper`.
// `values` must point to an array of length at least `num_dims` (ideally set to
// TF_Attr_Meta.size from TF_OperationGetAttrMetadata(oper, attr_name)).
public static native void TF_OperationGetAttrShape(TF_Operation oper,
                                                    @Cast("const char*") BytePointer attr_name,
                                                    @Cast("int64_t*") LongPointer value,
                                                    int num_dims,
                                                    TF_Status status);
public static native void TF_OperationGetAttrShape(TF_Operation oper,
                                                    String attr_name,
                                                    @Cast("int64_t*") LongBuffer value,
                                                    int num_dims,
                                                    TF_Status status);
public static native void TF_OperationGetAttrShape(TF_Operation oper,
                                                    @Cast("const char*") BytePointer attr_name,
                                                    @Cast("int64_t*") long[] value,
                                                    int num_dims,
                                                    TF_Status status);
public static native void TF_OperationGetAttrShape(TF_Operation oper,
                                                    String attr_name,
                                                    @Cast("int64_t*") LongPointer value,
                                                    int num_dims,
                                                    TF_Status status);
public static native void TF_OperationGetAttrShape(TF_Operation oper,
                                                    @Cast("const char*") BytePointer attr_name,
                                                    @Cast("int64_t*") LongBuffer value,
                                                    int num_dims,
                                                    TF_Status status);
public static native void TF_OperationGetAttrShape(TF_Operation oper,
                                                    String attr_name,
                                                    @Cast("int64_t*") long[] value,
                                                    int num_dims,
                                                    TF_Status status);

// Fills in `dims` with the list of shapes in the attribute `attr_name` of
// `oper` and `num_dims` with the corresponding number of dimensions. On return,
// for every i where `num_dims[i]` > 0, `dims[i]` will be an array of
// `num_dims[i]` elements. A value of -1 for `num_dims[i]` indicates that the
// i-th shape in the list is unknown.
//
// The elements of `dims` will point to addresses in `storage` which must be
// large enough to hold at least `storage_size` int64_ts.  Ideally, `num_shapes`
// would be set to TF_AttrMetadata.list_size and `storage_size` would be set to
// TF_AttrMetadata.total_size from TF_OperationGetAttrMetadata(oper,
// attr_name).
//
// Fails if storage_size is insufficient to hold the requested shapes.
public static native void TF_OperationGetAttrShapeList(
    TF_Operation oper, @Cast("const char*") BytePointer attr_name, @Cast("int64_t**") PointerPointer dims, IntPointer num_dims,
    int num_shapes, @Cast("int64_t*") LongPointer storage, int storage_size, TF_Status status);
public static native void TF_OperationGetAttrShapeList(
    TF_Operation oper, @Cast("const char*") BytePointer attr_name, @Cast("int64_t**") @ByPtrPtr LongPointer dims, IntPointer num_dims,
    int num_shapes, @Cast("int64_t*") LongPointer storage, int storage_size, TF_Status status);
public static native void TF_OperationGetAttrShapeList(
    TF_Operation oper, String attr_name, @Cast("int64_t**") @ByPtrPtr LongBuffer dims, IntBuffer num_dims,
    int num_shapes, @Cast("int64_t*") LongBuffer storage, int storage_size, TF_Status status);
public static native void TF_OperationGetAttrShapeList(
    TF_Operation oper, @Cast("const char*") BytePointer attr_name, @Cast("int64_t**") @ByPtrPtr long[] dims, int[] num_dims,
    int num_shapes, @Cast("int64_t*") long[] storage, int storage_size, TF_Status status);
public static native void TF_OperationGetAttrShapeList(
    TF_Operation oper, String attr_name, @Cast("int64_t**") @ByPtrPtr LongPointer dims, IntPointer num_dims,
    int num_shapes, @Cast("int64_t*") LongPointer storage, int storage_size, TF_Status status);
public static native void TF_OperationGetAttrShapeList(
    TF_Operation oper, @Cast("const char*") BytePointer attr_name, @Cast("int64_t**") @ByPtrPtr LongBuffer dims, IntBuffer num_dims,
    int num_shapes, @Cast("int64_t*") LongBuffer storage, int storage_size, TF_Status status);
public static native void TF_OperationGetAttrShapeList(
    TF_Operation oper, String attr_name, @Cast("int64_t**") @ByPtrPtr long[] dims, int[] num_dims,
    int num_shapes, @Cast("int64_t*") long[] storage, int storage_size, TF_Status status);

// Sets `value` to the binary-serialized TensorShapeProto of the value of
// `attr_name` attribute of `oper`'.
public static native void TF_OperationGetAttrTensorShapeProto(
    TF_Operation oper, @Cast("const char*") BytePointer attr_name, TF_Buffer value,
    TF_Status status);
public static native void TF_OperationGetAttrTensorShapeProto(
    TF_Operation oper, String attr_name, TF_Buffer value,
    TF_Status status);

// Fills in `values` with binary-serialized TensorShapeProto values of the
// attribute `attr_name` of `oper`. `values` must point to an array of length at
// least `num_values` (ideally set to TF_AttrMetadata.list_size from
// TF_OperationGetAttrMetadata(oper, attr_name)).
public static native void TF_OperationGetAttrTensorShapeProtoList(
    TF_Operation oper, @Cast("const char*") BytePointer attr_name, @Cast("TF_Buffer**") PointerPointer values,
    int max_values, TF_Status status);
public static native void TF_OperationGetAttrTensorShapeProtoList(
    TF_Operation oper, @Cast("const char*") BytePointer attr_name, @ByPtrPtr TF_Buffer values,
    int max_values, TF_Status status);
public static native void TF_OperationGetAttrTensorShapeProtoList(
    TF_Operation oper, String attr_name, @ByPtrPtr TF_Buffer values,
    int max_values, TF_Status status);

// Gets the TF_Tensor valued attribute of `attr_name` of `oper`.
//
// Allocates a new TF_Tensor which the caller is expected to take
// ownership of (and can deallocate using TF_DeleteTensor).
public static native void TF_OperationGetAttrTensor(TF_Operation oper,
                                                     @Cast("const char*") BytePointer attr_name,
                                                     @Cast("TF_Tensor**") PointerPointer value,
                                                     TF_Status status);
public static native void TF_OperationGetAttrTensor(TF_Operation oper,
                                                     @Cast("const char*") BytePointer attr_name,
                                                     @ByPtrPtr TF_Tensor value,
                                                     TF_Status status);
public static native void TF_OperationGetAttrTensor(TF_Operation oper,
                                                     String attr_name,
                                                     @ByPtrPtr TF_Tensor value,
                                                     TF_Status status);

// Fills in `values` with the TF_Tensor values of the attribute `attr_name` of
// `oper`. `values` must point to an array of TF_Tensor* of length at least
// `max_values` (ideally set to TF_AttrMetadata.list_size from
// TF_OperationGetAttrMetadata(oper, attr_name)).
//
// The caller takes ownership of all the non-null TF_Tensor* entries in `values`
// (which can be deleted using TF_DeleteTensor(values[i])).
public static native void TF_OperationGetAttrTensorList(TF_Operation oper,
                                                         @Cast("const char*") BytePointer attr_name,
                                                         @Cast("TF_Tensor**") PointerPointer values,
                                                         int max_values,
                                                         TF_Status status);
public static native void TF_OperationGetAttrTensorList(TF_Operation oper,
                                                         @Cast("const char*") BytePointer attr_name,
                                                         @ByPtrPtr TF_Tensor values,
                                                         int max_values,
                                                         TF_Status status);
public static native void TF_OperationGetAttrTensorList(TF_Operation oper,
                                                         String attr_name,
                                                         @ByPtrPtr TF_Tensor values,
                                                         int max_values,
                                                         TF_Status status);

// Sets `output_attr_value` to the binary-serialized AttrValue proto
// representation of the value of the `attr_name` attr of `oper`.
public static native void TF_OperationGetAttrValueProto(
    TF_Operation oper, @Cast("const char*") BytePointer attr_name, TF_Buffer output_attr_value,
    TF_Status status);
public static native void TF_OperationGetAttrValueProto(
    TF_Operation oper, String attr_name, TF_Buffer output_attr_value,
    TF_Status status);

// Returns the operation in the graph with `oper_name`. Returns nullptr if
// no operation found.
public static native TF_Operation TF_GraphOperationByName(
    TF_Graph graph, @Cast("const char*") BytePointer oper_name);
public static native TF_Operation TF_GraphOperationByName(
    TF_Graph graph, String oper_name);

// Iterate through the operations of a graph.  To use:
// size_t pos = 0;
// TF_Operation* oper;
// while ((oper = TF_GraphNextOperation(graph, &pos)) != nullptr) {
//   DoSomethingWithOperation(oper);
// }
public static native TF_Operation TF_GraphNextOperation(TF_Graph graph,
                                                          @Cast("size_t*") SizeTPointer pos);

// Write out a serialized representation of `graph` (as a GraphDef protocol
// message) to `output_graph_def` (allocated by TF_NewBuffer()).
// `output_graph_def`'s underlying buffer will be freed when TF_DeleteBuffer()
// is called.
//
// May fail on very large graphs in the future.
public static native void TF_GraphToGraphDef(TF_Graph graph,
                                              TF_Buffer output_graph_def,
                                              TF_Status status);

// Returns the serialized OpDef proto with name `op_name`, or a bad status if no
// such op exists. This can return OpDefs of functions copied into the graph.
public static native void TF_GraphGetOpDef(TF_Graph graph,
                                            @Cast("const char*") BytePointer op_name,
                                            TF_Buffer output_op_def,
                                            TF_Status status);
public static native void TF_GraphGetOpDef(TF_Graph graph,
                                            String op_name,
                                            TF_Buffer output_op_def,
                                            TF_Status status);

// Returns the serialized VersionDef proto for this graph.
public static native void TF_GraphVersions(TF_Graph graph,
                                            TF_Buffer output_version_def,
                                            TF_Status status);

// TF_ImportGraphDefOptions holds options that can be passed to
// TF_GraphImportGraphDef.

public static native TF_ImportGraphDefOptions TF_NewImportGraphDefOptions();
public static native void TF_DeleteImportGraphDefOptions(
    TF_ImportGraphDefOptions opts);

// Set the prefix to be prepended to the names of nodes in `graph_def` that will
// be imported into `graph`. `prefix` is copied and has no lifetime
// requirements.
public static native void TF_ImportGraphDefOptionsSetPrefix(
    TF_ImportGraphDefOptions opts, @Cast("const char*") BytePointer prefix);
public static native void TF_ImportGraphDefOptionsSetPrefix(
    TF_ImportGraphDefOptions opts, String prefix);

// Set the execution device for nodes in `graph_def`.
// Only applies to nodes where a device was not already explicitly specified.
// `device` is copied and has no lifetime requirements.
public static native void TF_ImportGraphDefOptionsSetDefaultDevice(
    TF_ImportGraphDefOptions opts, @Cast("const char*") BytePointer device);
public static native void TF_ImportGraphDefOptionsSetDefaultDevice(
    TF_ImportGraphDefOptions opts, String device);

// Set whether to uniquify imported operation names. If true, imported operation
// names will be modified if their name already exists in the graph. If false,
// conflicting names will be treated as an error. Note that this option has no
// effect if a prefix is set, since the prefix will guarantee all names are
// unique. Defaults to false.
public static native void TF_ImportGraphDefOptionsSetUniquifyNames(
    TF_ImportGraphDefOptions opts, @Cast("unsigned char") byte uniquify_names);

// If true, the specified prefix will be modified if it already exists as an
// operation name or prefix in the graph. If false, a conflicting prefix will be
// treated as an error. This option has no effect if no prefix is specified.
public static native void TF_ImportGraphDefOptionsSetUniquifyPrefix(
    TF_ImportGraphDefOptions opts, @Cast("unsigned char") byte uniquify_prefix);

// Set any imported nodes with input `src_name:src_index` to have that input
// replaced with `dst`. `src_name` refers to a node in the graph to be imported,
// `dst` references a node already existing in the graph being imported into.
// `src_name` is copied and has no lifetime requirements.
public static native void TF_ImportGraphDefOptionsAddInputMapping(
    TF_ImportGraphDefOptions opts, @Cast("const char*") BytePointer src_name, int src_index,
    @ByVal TF_Output dst);
public static native void TF_ImportGraphDefOptionsAddInputMapping(
    TF_ImportGraphDefOptions opts, String src_name, int src_index,
    @ByVal TF_Output dst);

// Set any imported nodes with control input `src_name` to have that input
// replaced with `dst`. `src_name` refers to a node in the graph to be imported,
// `dst` references an operation already existing in the graph being imported
// into. `src_name` is copied and has no lifetime requirements.
public static native void TF_ImportGraphDefOptionsRemapControlDependency(
    TF_ImportGraphDefOptions opts, @Cast("const char*") BytePointer src_name, TF_Operation dst);
public static native void TF_ImportGraphDefOptionsRemapControlDependency(
    TF_ImportGraphDefOptions opts, String src_name, TF_Operation dst);

// Cause the imported graph to have a control dependency on `oper`. `oper`
// should exist in the graph being imported into.
public static native void TF_ImportGraphDefOptionsAddControlDependency(
    TF_ImportGraphDefOptions opts, TF_Operation oper);

// Add an output in `graph_def` to be returned via the `return_outputs` output
// parameter of TF_GraphImportGraphDef(). If the output is remapped via an input
// mapping, the corresponding existing tensor in `graph` will be returned.
// `oper_name` is copied and has no lifetime requirements.
public static native void TF_ImportGraphDefOptionsAddReturnOutput(
    TF_ImportGraphDefOptions opts, @Cast("const char*") BytePointer oper_name, int index);
public static native void TF_ImportGraphDefOptionsAddReturnOutput(
    TF_ImportGraphDefOptions opts, String oper_name, int index);

// Returns the number of return outputs added via
// TF_ImportGraphDefOptionsAddReturnOutput().
public static native int TF_ImportGraphDefOptionsNumReturnOutputs(
    @Const TF_ImportGraphDefOptions opts);

// Add an operation in `graph_def` to be returned via the `return_opers` output
// parameter of TF_GraphImportGraphDef(). `oper_name` is copied and has no
// lifetime requirements.
public static native void TF_ImportGraphDefOptionsAddReturnOperation(
    TF_ImportGraphDefOptions opts, @Cast("const char*") BytePointer oper_name);
public static native void TF_ImportGraphDefOptionsAddReturnOperation(
    TF_ImportGraphDefOptions opts, String oper_name);

// Returns the number of return operations added via
// TF_ImportGraphDefOptionsAddReturnOperation().
public static native int TF_ImportGraphDefOptionsNumReturnOperations(
    @Const TF_ImportGraphDefOptions opts);

// TF_ImportGraphDefResults holds results that are generated by
// TF_GraphImportGraphDefWithResults().

// Fetches the return outputs requested via
// TF_ImportGraphDefOptionsAddReturnOutput(). The number of fetched outputs is
// returned in `num_outputs`. The array of return outputs is returned in
// `outputs`. `*outputs` is owned by and has the lifetime of `results`.
public static native void TF_ImportGraphDefResultsReturnOutputs(
    TF_ImportGraphDefResults results, IntPointer num_outputs, @Cast("TF_Output**") PointerPointer outputs);
public static native void TF_ImportGraphDefResultsReturnOutputs(
    TF_ImportGraphDefResults results, IntPointer num_outputs, @ByPtrPtr TF_Output outputs);
public static native void TF_ImportGraphDefResultsReturnOutputs(
    TF_ImportGraphDefResults results, IntBuffer num_outputs, @ByPtrPtr TF_Output outputs);
public static native void TF_ImportGraphDefResultsReturnOutputs(
    TF_ImportGraphDefResults results, int[] num_outputs, @ByPtrPtr TF_Output outputs);

// Fetches the return operations requested via
// TF_ImportGraphDefOptionsAddReturnOperation(). The number of fetched
// operations is returned in `num_opers`. The array of return operations is
// returned in `opers`. `*opers` is owned by and has the lifetime of `results`.
public static native void TF_ImportGraphDefResultsReturnOperations(
    TF_ImportGraphDefResults results, IntPointer num_opers, @Cast("TF_Operation***") @ByPtrPtr PointerPointer opers);
public static native void TF_ImportGraphDefResultsReturnOperations(
    TF_ImportGraphDefResults results, IntBuffer num_opers, @Cast("TF_Operation***") @ByPtrPtr PointerPointer opers);
public static native void TF_ImportGraphDefResultsReturnOperations(
    TF_ImportGraphDefResults results, int[] num_opers, @Cast("TF_Operation***") @ByPtrPtr PointerPointer opers);

// Fetches any input mappings requested via
// TF_ImportGraphDefOptionsAddInputMapping() that didn't appear in the GraphDef
// and weren't used as input to any node in the imported graph def. The number
// of fetched mappings is returned in `num_missing_unused_input_mappings`. The
// array of each mapping's source node name is returned in `src_names`, and the
// array of each mapping's source index is returned in `src_indexes`.
//
// `*src_names`, `*src_indexes`, and the memory backing each string in
// `src_names` are owned by and have the lifetime of `results`.
public static native void TF_ImportGraphDefResultsMissingUnusedInputMappings(
    TF_ImportGraphDefResults results, IntPointer num_missing_unused_input_mappings,
    @Cast("const char***") @ByPtrPtr PointerPointer src_names, @Cast("int**") PointerPointer src_indexes);
public static native void TF_ImportGraphDefResultsMissingUnusedInputMappings(
    TF_ImportGraphDefResults results, IntPointer num_missing_unused_input_mappings,
    @Cast("const char***") @ByPtrPtr PointerPointer src_names, @ByPtrPtr IntPointer src_indexes);
public static native void TF_ImportGraphDefResultsMissingUnusedInputMappings(
    TF_ImportGraphDefResults results, IntBuffer num_missing_unused_input_mappings,
    @Cast("const char***") @ByPtrPtr PointerPointer src_names, @ByPtrPtr IntBuffer src_indexes);
public static native void TF_ImportGraphDefResultsMissingUnusedInputMappings(
    TF_ImportGraphDefResults results, int[] num_missing_unused_input_mappings,
    @Cast("const char***") @ByPtrPtr PointerPointer src_names, @ByPtrPtr int... src_indexes);

// Deletes a results object returned by TF_GraphImportGraphDefWithResults().
public static native void TF_DeleteImportGraphDefResults(
    TF_ImportGraphDefResults results);

// Import the graph serialized in `graph_def` into `graph`.  Returns nullptr and
// a bad status on error. Otherwise, returns a populated
// TF_ImportGraphDefResults instance. The returned instance must be deleted via
// TF_DeleteImportGraphDefResults().
public static native TF_ImportGraphDefResults TF_GraphImportGraphDefWithResults(TF_Graph graph, @Const TF_Buffer graph_def,
                                  @Const TF_ImportGraphDefOptions options,
                                  TF_Status status);

// Import the graph serialized in `graph_def` into `graph`.
// Convenience function for when only return outputs are needed.
//
// `num_return_outputs` must be the number of return outputs added (i.e. the
// result of TF_ImportGraphDefOptionsNumReturnOutputs()).  If
// `num_return_outputs` is non-zero, `return_outputs` must be of length
// `num_return_outputs`. Otherwise it can be null.
public static native void TF_GraphImportGraphDefWithReturnOutputs(
    TF_Graph graph, @Const TF_Buffer graph_def,
    @Const TF_ImportGraphDefOptions options, TF_Output return_outputs,
    int num_return_outputs, TF_Status status);

// Import the graph serialized in `graph_def` into `graph`.
// Convenience function for when no results are needed.
public static native void TF_GraphImportGraphDef(
    TF_Graph graph, @Const TF_Buffer graph_def,
    @Const TF_ImportGraphDefOptions options, TF_Status status);

// Adds a copy of function `func` and optionally its gradient function `grad`
// to `g`. Once `func`/`grad` is added to `g`, it can be called by creating
// an operation using the function's name.
// Any changes to `func`/`grad` (including deleting it) done after this method
// returns, won't affect the copy of `func`/`grad` in `g`.
// If `func` or `grad` are already in `g`, TF_GraphCopyFunction has no
// effect on them, but can establish the function->gradient relationship
// between them if `func` does not already have a gradient. If `func` already
// has a gradient different from `grad`, an error is returned.
//
// `func` must not be null.
// If `grad` is null and `func` is not in `g`, `func` is added without a
// gradient.
// If `grad` is null and `func` is in `g`, TF_GraphCopyFunction is a noop.
// `grad` must have appropriate signature as described in the doc of
// GradientDef in tensorflow/core/framework/function.proto.
//
// If successful, status is set to OK and `func` and `grad` are added to `g`.
// Otherwise, status is set to the encountered error and `g` is unmodified.
public static native void TF_GraphCopyFunction(TF_Graph g,
                                                @Const TF_Function func,
                                                @Const TF_Function grad,
                                                TF_Status status);

// Returns the number of TF_Functions registered in `g`.
public static native int TF_GraphNumFunctions(TF_Graph g);

// Fills in `funcs` with the TF_Function* registered in `g`.
// `funcs` must point to an array of TF_Function* of length at least
// `max_func`. In usual usage, max_func should be set to the result of
// TF_GraphNumFunctions(g). In this case, all the functions registered in
// `g` will be returned. Else, an unspecified subset.
//
// If successful, returns the number of TF_Function* successfully set in
// `funcs` and sets status to OK. The caller takes ownership of
// all the returned TF_Functions. They must be deleted with TF_DeleteFunction.
// On error, returns 0, sets status to the encountered error, and the contents
// of funcs will be undefined.
public static native int TF_GraphGetFunctions(TF_Graph g, @Cast("TF_Function**") PointerPointer funcs,
                                               int max_func, TF_Status status);
public static native int TF_GraphGetFunctions(TF_Graph g, @ByPtrPtr TF_Function funcs,
                                               int max_func, TF_Status status);

// Note: The following function may fail on very large protos in the future.

public static native void TF_OperationToNodeDef(TF_Operation oper,
                                                 TF_Buffer output_node_def,
                                                 TF_Status status);
// Targeting ../TF_WhileParams.java



// Creates a TF_WhileParams for creating a while loop in `g`. `inputs` are
// outputs that already exist in `g` used as initial values for the loop
// variables.
//
// The returned TF_WhileParams will have all fields initialized except
// `cond_output`, `body_outputs`, and `name`. The `body_outputs` buffer will be
// allocated to size `ninputs`. The caller should build `cond_graph` and
// `body_graph` starting from the inputs, and store the final outputs in
// `cond_output` and `body_outputs`.
//
// If `status` is OK, the caller must call either TF_FinishWhile or
// TF_AbortWhile on the returned TF_WhileParams. If `status` isn't OK, the
// returned TF_WhileParams is not valid, and the caller should not call
// TF_FinishWhile() or TF_AbortWhile().
//
// Missing functionality (TODO):
// - Gradients
// - Reference-type inputs
// - Directly referencing external tensors from the cond/body graphs (this is
//   possible in the Python API)
public static native @ByVal TF_WhileParams TF_NewWhile(TF_Graph g, TF_Output inputs,
                                                 int ninputs,
                                                 TF_Status status);

// Builds the while loop specified by `params` and returns the output tensors of
// the while loop in `outputs`. `outputs` should be allocated to size
// `params.ninputs`.
//
// `params` is no longer valid once this returns.
//
// Either this or TF_AbortWhile() must be called after a successful
// TF_NewWhile() call.
public static native void TF_FinishWhile(@Const TF_WhileParams params,
                                          TF_Status status,
                                          TF_Output outputs);

// Frees `params`s resources without building a while loop. `params` is no
// longer valid after this returns. Either this or TF_FinishWhile() must be
// called after a successful TF_NewWhile() call.
public static native void TF_AbortWhile(@Const TF_WhileParams params);

// Adds operations to compute the partial derivatives of sum of `y`s w.r.t `x`s,
// i.e., d(y_1 + y_2 + ...)/dx_1, d(y_1 + y_2 + ...)/dx_2...
//
// `dx` are used as initial gradients (which represent the symbolic partial
// derivatives of some loss function `L` w.r.t. `y`).
// `dx` must be nullptr or have size `ny`.
// If `dx` is nullptr, the implementation will use dx of `OnesLike` for all
// shapes in `y`.
// The partial derivatives are returned in `dy`. `dy` should be allocated to
// size `nx`.
//
// Gradient nodes are automatically named under the "gradients/" prefix. To
// guarantee name uniqueness, subsequent calls to the same graph will
// append an incremental tag to the prefix: "gradients_1/", "gradients_2/", ...
// See TF_AddGradientsWithPrefix, which provides a means to specify a custom
// name prefix for operations added to a graph to compute the gradients.
//
// WARNING: This function does not yet support all the gradients that python
// supports. See
// https://www.tensorflow.org/code/tensorflow/cc/gradients/README.md
// for instructions on how to add C++ more gradients.
public static native void TF_AddGradients(TF_Graph g, TF_Output y, int ny,
                                    TF_Output x, int nx, TF_Output dx,
                                    TF_Status status, TF_Output dy);

// Adds operations to compute the partial derivatives of sum of `y`s w.r.t `x`s,
// i.e., d(y_1 + y_2 + ...)/dx_1, d(y_1 + y_2 + ...)/dx_2...
// This is a variant of TF_AddGradients that allows to caller to pass a custom
// name prefix to the operations added to a graph to compute the gradients.
//
// `dx` are used as initial gradients (which represent the symbolic partial
// derivatives of some loss function `L` w.r.t. `y`).
// `dx` must be nullptr or have size `ny`.
// If `dx` is nullptr, the implementation will use dx of `OnesLike` for all
// shapes in `y`.
// The partial derivatives are returned in `dy`. `dy` should be allocated to
// size `nx`.
// `prefix` names the scope into which all gradients operations are being added.
// `prefix` must be unique within the provided graph otherwise this operation
// will fail. If `prefix` is nullptr, the default prefixing behaviour takes
// place, see TF_AddGradients for more details.
//
// WARNING: This function does not yet support all the gradients that python
// supports. See
// https://www.tensorflow.org/code/tensorflow/cc/gradients/README.md
// for instructions on how to add C++ more gradients.
public static native void TF_AddGradientsWithPrefix(TF_Graph g, @Cast("const char*") BytePointer prefix,
                                              TF_Output y, int ny,
                                              TF_Output x, int nx,
                                              TF_Output dx, TF_Status status,
                                              TF_Output dy);
public static native void TF_AddGradientsWithPrefix(TF_Graph g, String prefix,
                                              TF_Output y, int ny,
                                              TF_Output x, int nx,
                                              TF_Output dx, TF_Status status,
                                              TF_Output dy);

// Create a TF_Function from a TF_Graph
//
// Params:
//  fn_body - the graph whose operations (or subset of whose operations) will be
//            converted to TF_Function.
//  fn_name - the name of the new TF_Function. Should match the operation
//            name (OpDef.name) regexp [A-Z][A-Za-z0-9_.\\-/]*.
//            If `append_hash_to_fn_name` is false, `fn_name` must be distinct
//            from other function and operation names (at least those
//            registered in graphs where this function will be used).
//  append_hash_to_fn_name - Must be 0 or 1. If set to 1, the actual name
//                           of the function will be `fn_name` appended with
//                           '_<hash_of_this_function's_definition>'.
//                           If set to 0, the function's name will be `fn_name`.
//  num_opers - `num_opers` contains the number of elements in the `opers` array
//              or a special value of -1 meaning that no array is given.
//              The distinction between an empty array of operations and no
//              array of operations is necessary to distinguish the case of
//              creating a function with no body (e.g. identity or permutation)
//              and the case of creating a function whose body contains all
//              the nodes in the graph (except for the automatic skipping, see
//              below).
//  opers - Array of operations to become the body of the function or null.
//          - If no array is given (`num_opers`  = -1), all the
//          operations in `fn_body` will become part of the function
//          except operations referenced in `inputs`. These operations
//          must have a single output (these operations are typically
//          placeholders created for the sole purpose of representing
//          an input. We can relax this constraint if there are
//          compelling use cases).
//          - If an array is given (`num_opers` >= 0), all operations
//          in it will become part of the function. In particular, no
//          automatic skipping of dummy input operations is performed.
//  ninputs - number of elements in `inputs` array
//  inputs - array of TF_Outputs that specify the inputs to the function.
//           If `ninputs` is zero (the function takes no inputs), `inputs`
//           can be null. The names used for function inputs are normalized
//           names of the operations (usually placeholders) pointed to by
//           `inputs`. These operation names should start with a letter.
//           Normalization will convert all letters to lowercase and
//           non-alphanumeric characters to '_' to make resulting names match
//           the "[a-z][a-z0-9_]*" pattern for operation argument names.
//           `inputs` cannot contain the same tensor twice.
//  noutputs - number of elements in `outputs` array
//  outputs - array of TF_Outputs that specify the outputs of the function.
//            If `noutputs` is zero (the function returns no outputs), `outputs`
//            can be null. `outputs` can contain the same tensor more than once.
//  output_names - The names of the function's outputs. `output_names` array
//                 must either have the same length as `outputs`
//                 (i.e. `noutputs`) or be null. In the former case,
//                 the names should match the regular expression for ArgDef
//                 names - "[a-z][a-z0-9_]*". In the latter case,
//                 names for outputs will be generated automatically.
//  opts - various options for the function, e.g. XLA's inlining control.
//  description - optional human-readable description of this function.
//  status - Set to OK on success and an appropriate error on failure.
//
// Note that when the same TF_Output is listed as both an input and an output,
// the corresponding function's output will equal to this input,
// instead of the original node's output.
//
// Callers must also satisfy the following constraints:
// - `inputs` cannot refer to TF_Outputs within a control flow context. For
//   example, one cannot use the output of "switch" node as input.
// - `inputs` and `outputs` cannot have reference types. Reference types are
//   not exposed through C API and are being replaced with Resources. We support
//   reference types inside function's body to support legacy code. Do not
//   use them in new code.
// - Every node in the function's body must have all of its inputs (including
//   control inputs). In other words, for every node in the body, each input
//   must be either listed in `inputs` or must come from another node in
//   the body. In particular, it is an error to have a control edge going from
//   a node outside of the body into a node in the body. This applies to control
//   edges going from nodes referenced in `inputs` to nodes in the body when
//   the former nodes are not in the body (automatically skipped or not
//   included in explicitly specified body).
//
// Returns:
//  On success, a newly created TF_Function instance. It must be deleted by
//  calling TF_DeleteFunction.
//
//  On failure, null.
public static native TF_Function TF_GraphToFunction(
    @Const TF_Graph fn_body, @Cast("const char*") BytePointer fn_name,
    @Cast("unsigned char") byte append_hash_to_fn_name, int num_opers,
    @Cast("const TF_Operation*const*") PointerPointer opers, int ninputs, @Const TF_Output inputs,
    int noutputs, @Const TF_Output outputs, @Cast("const char*const*") PointerPointer output_names,
    @Const TF_FunctionOptions opts, @Cast("const char*") BytePointer description, TF_Status status);
public static native TF_Function TF_GraphToFunction(
    @Const TF_Graph fn_body, @Cast("const char*") BytePointer fn_name,
    @Cast("unsigned char") byte append_hash_to_fn_name, int num_opers,
    @Const @ByPtrPtr TF_Operation opers, int ninputs, @Const TF_Output inputs,
    int noutputs, @Const TF_Output outputs, @Cast("const char*const*") @ByPtrPtr BytePointer output_names,
    @Const TF_FunctionOptions opts, @Cast("const char*") BytePointer description, TF_Status status);
public static native TF_Function TF_GraphToFunction(
    @Const TF_Graph fn_body, String fn_name,
    @Cast("unsigned char") byte append_hash_to_fn_name, int num_opers,
    @Const @ByPtrPtr TF_Operation opers, int ninputs, @Const TF_Output inputs,
    int noutputs, @Const TF_Output outputs, @Cast("const char*const*") @ByPtrPtr ByteBuffer output_names,
    @Const TF_FunctionOptions opts, String description, TF_Status status);
public static native TF_Function TF_GraphToFunction(
    @Const TF_Graph fn_body, @Cast("const char*") BytePointer fn_name,
    @Cast("unsigned char") byte append_hash_to_fn_name, int num_opers,
    @Const @ByPtrPtr TF_Operation opers, int ninputs, @Const TF_Output inputs,
    int noutputs, @Const TF_Output outputs, @Cast("const char*const*") @ByPtrPtr byte[] output_names,
    @Const TF_FunctionOptions opts, @Cast("const char*") BytePointer description, TF_Status status);
public static native TF_Function TF_GraphToFunction(
    @Const TF_Graph fn_body, String fn_name,
    @Cast("unsigned char") byte append_hash_to_fn_name, int num_opers,
    @Const @ByPtrPtr TF_Operation opers, int ninputs, @Const TF_Output inputs,
    int noutputs, @Const TF_Output outputs, @Cast("const char*const*") @ByPtrPtr BytePointer output_names,
    @Const TF_FunctionOptions opts, String description, TF_Status status);
public static native TF_Function TF_GraphToFunction(
    @Const TF_Graph fn_body, @Cast("const char*") BytePointer fn_name,
    @Cast("unsigned char") byte append_hash_to_fn_name, int num_opers,
    @Const @ByPtrPtr TF_Operation opers, int ninputs, @Const TF_Output inputs,
    int noutputs, @Const TF_Output outputs, @Cast("const char*const*") @ByPtrPtr ByteBuffer output_names,
    @Const TF_FunctionOptions opts, @Cast("const char*") BytePointer description, TF_Status status);
public static native TF_Function TF_GraphToFunction(
    @Const TF_Graph fn_body, String fn_name,
    @Cast("unsigned char") byte append_hash_to_fn_name, int num_opers,
    @Const @ByPtrPtr TF_Operation opers, int ninputs, @Const TF_Output inputs,
    int noutputs, @Const TF_Output outputs, @Cast("const char*const*") @ByPtrPtr byte[] output_names,
    @Const TF_FunctionOptions opts, String description, TF_Status status);

// Returns the name of the graph function.
// The return value points to memory that is only usable until the next
// mutation to *func.
public static native @Cast("const char*") BytePointer TF_FunctionName(TF_Function func);

// Write out a serialized representation of `func` (as a FunctionDef protocol
// message) to `output_func_def` (allocated by TF_NewBuffer()).
// `output_func_def`'s underlying buffer will be freed when TF_DeleteBuffer()
// is called.
//
// May fail on very large graphs in the future.
public static native void TF_FunctionToFunctionDef(TF_Function func,
                                                    TF_Buffer output_func_def,
                                                    TF_Status status);

// Construct and return the function whose FunctionDef representation is
// serialized in `proto`. `proto_len` must equal the number of bytes
// pointed to by `proto`.
// Returns:
//  On success, a newly created TF_Function instance. It must be deleted by
//  calling TF_DeleteFunction.
//
//  On failure, null.
public static native TF_Function TF_FunctionImportFunctionDef(
    @Const Pointer proto, @Cast("size_t") long proto_len, TF_Status status);

// Sets function attribute named `attr_name` to value stored in `proto`.
// If this attribute is already set to another value, it is overridden.
// `proto` should point to a sequence of bytes of length `proto_len`
// representing a binary serialization of an AttrValue protocol
// buffer.
public static native void TF_FunctionSetAttrValueProto(TF_Function func,
                                                        @Cast("const char*") BytePointer attr_name,
                                                        @Const Pointer proto,
                                                        @Cast("size_t") long proto_len,
                                                        TF_Status status);
public static native void TF_FunctionSetAttrValueProto(TF_Function func,
                                                        String attr_name,
                                                        @Const Pointer proto,
                                                        @Cast("size_t") long proto_len,
                                                        TF_Status status);

// Sets `output_attr_value` to the binary-serialized AttrValue proto
// representation of the value of the `attr_name` attr of `func`.
// If `attr_name` attribute is not present, status is set to an error.
public static native void TF_FunctionGetAttrValueProto(
    TF_Function func, @Cast("const char*") BytePointer attr_name, TF_Buffer output_attr_value,
    TF_Status status);
public static native void TF_FunctionGetAttrValueProto(
    TF_Function func, String attr_name, TF_Buffer output_attr_value,
    TF_Status status);

// Frees the memory used by the `func` struct.
// TF_DeleteFunction is a noop if `func` is null.
// Deleting a function does not remove it from any graphs it was copied to.
public static native void TF_DeleteFunction(TF_Function func);

// Attempts to evaluate `output`. This will only be possible if `output` doesn't
// depend on any graph inputs (this function is safe to call if this isn't the
// case though).
//
// If the evaluation is successful, this function returns true and `output`s
// value is returned in `result`. Otherwise returns false. An error status is
// returned if something is wrong with the graph or input. Note that this may
// return false even if no error status is set.
public static native @Cast("unsigned char") byte TF_TryEvaluateConstant(TF_Graph graph,
                                                           @ByVal TF_Output output,
                                                           @Cast("TF_Tensor**") PointerPointer result,
                                                           TF_Status status);
public static native @Cast("unsigned char") byte TF_TryEvaluateConstant(TF_Graph graph,
                                                           @ByVal TF_Output output,
                                                           @ByPtrPtr TF_Tensor result,
                                                           TF_Status status);

// TODO(josh11b): Register OpDef, available to all operations added
// to this graph.

// --------------------------------------------------------------------------
// API for driving Graph execution.

// Return a new execution session with the associated graph, or NULL on
// error. Does not take ownership of any input parameters.
//
// *`graph` must be a valid graph (not deleted or nullptr). `graph` will be be
// kept alive for the lifetime of the returned TF_Session. New nodes can still
// be added to `graph` after this call.
public static native TF_Session TF_NewSession(TF_Graph graph,
                                                @Const TF_SessionOptions opts,
                                                TF_Status status);

// This function creates a new TF_Session (which is created on success) using
// `session_options`, and then initializes state (restoring tensors and other
// assets) using `run_options`.
//
// Any NULL and non-NULL value combinations for (`run_options, `meta_graph_def`)
// are valid.
//
// - `export_dir` must be set to the path of the exported SavedModel.
// - `tags` must include the set of tags used to identify one MetaGraphDef in
//    the SavedModel.
// - `graph` must be a graph newly allocated with TF_NewGraph().
//
// If successful, populates `graph` with the contents of the Graph and
// `meta_graph_def` with the MetaGraphDef of the loaded model.
public static native @Platform(not="android") TF_Session TF_LoadSessionFromSavedModel(
    @Const TF_SessionOptions session_options, @Const TF_Buffer run_options,
    @Cast("const char*") BytePointer export_dir, @Cast("const char*const*") PointerPointer tags, int tags_len,
    TF_Graph graph, TF_Buffer meta_graph_def, TF_Status status);
public static native @Platform(not="android") TF_Session TF_LoadSessionFromSavedModel(
    @Const TF_SessionOptions session_options, @Const TF_Buffer run_options,
    @Cast("const char*") BytePointer export_dir, @Cast("const char*const*") @ByPtrPtr BytePointer tags, int tags_len,
    TF_Graph graph, TF_Buffer meta_graph_def, TF_Status status);
public static native @Platform(not="android") TF_Session TF_LoadSessionFromSavedModel(
    @Const TF_SessionOptions session_options, @Const TF_Buffer run_options,
    String export_dir, @Cast("const char*const*") @ByPtrPtr ByteBuffer tags, int tags_len,
    TF_Graph graph, TF_Buffer meta_graph_def, TF_Status status);
public static native @Platform(not="android") TF_Session TF_LoadSessionFromSavedModel(
    @Const TF_SessionOptions session_options, @Const TF_Buffer run_options,
    @Cast("const char*") BytePointer export_dir, @Cast("const char*const*") @ByPtrPtr byte[] tags, int tags_len,
    TF_Graph graph, TF_Buffer meta_graph_def, TF_Status status);
public static native @Platform(not="android") TF_Session TF_LoadSessionFromSavedModel(
    @Const TF_SessionOptions session_options, @Const TF_Buffer run_options,
    String export_dir, @Cast("const char*const*") @ByPtrPtr BytePointer tags, int tags_len,
    TF_Graph graph, TF_Buffer meta_graph_def, TF_Status status);
public static native @Platform(not="android") TF_Session TF_LoadSessionFromSavedModel(
    @Const TF_SessionOptions session_options, @Const TF_Buffer run_options,
    @Cast("const char*") BytePointer export_dir, @Cast("const char*const*") @ByPtrPtr ByteBuffer tags, int tags_len,
    TF_Graph graph, TF_Buffer meta_graph_def, TF_Status status);
public static native @Platform(not="android") TF_Session TF_LoadSessionFromSavedModel(
    @Const TF_SessionOptions session_options, @Const TF_Buffer run_options,
    String export_dir, @Cast("const char*const*") @ByPtrPtr byte[] tags, int tags_len,
    TF_Graph graph, TF_Buffer meta_graph_def, TF_Status status);

// Close a session.
//
// Contacts any other processes associated with the session, if applicable.
// May not be called after TF_DeleteSession().
public static native void TF_CloseSession(TF_Session arg0, TF_Status status);

// Destroy a session object.
//
// Even if error information is recorded in *status, this call discards all
// local resources associated with the session.  The session may not be used
// during or after this call (and the session drops its reference to the
// corresponding graph).
public static native void TF_DeleteSession(TF_Session arg0, TF_Status status);

// Run the graph associated with the session starting with the supplied inputs
// (inputs[0,ninputs-1] with corresponding values in input_values[0,ninputs-1]).
//
// Any NULL and non-NULL value combinations for (`run_options`,
// `run_metadata`) are valid.
//
//    - `run_options` may be NULL, in which case it will be ignored; or
//      non-NULL, in which case it must point to a `TF_Buffer` containing the
//      serialized representation of a `RunOptions` protocol buffer.
//    - `run_metadata` may be NULL, in which case it will be ignored; or
//      non-NULL, in which case it must point to an empty, freshly allocated
//      `TF_Buffer` that may be updated to contain the serialized representation
//      of a `RunMetadata` protocol buffer.
//
// The caller retains ownership of `input_values` (which can be deleted using
// TF_DeleteTensor). The caller also retains ownership of `run_options` and/or
// `run_metadata` (when not NULL) and should manually call TF_DeleteBuffer on
// them.
//
// On success, the tensors corresponding to outputs[0,noutputs-1] are placed in
// output_values[]. Ownership of the elements of output_values[] is transferred
// to the caller, which must eventually call TF_DeleteTensor on them.
//
// On failure, output_values[] contains NULLs.
public static native void TF_SessionRun(
    TF_Session session,
    @Const TF_Buffer run_options,
    @Const TF_Output inputs, @Cast("TF_Tensor*const*") PointerPointer input_values, int ninputs,
    @Const TF_Output outputs, @Cast("TF_Tensor**") PointerPointer output_values, int noutputs,
    @Cast("const TF_Operation*const*") PointerPointer target_opers, int ntargets,
    TF_Buffer run_metadata,
    TF_Status arg11);
public static native void TF_SessionRun(
    TF_Session session,
    @Const TF_Buffer run_options,
    @Const TF_Output inputs, @ByPtrPtr TF_Tensor input_values, int ninputs,
    @Const TF_Output outputs, @ByPtrPtr TF_Tensor output_values, int noutputs,
    @Const @ByPtrPtr TF_Operation target_opers, int ntargets,
    TF_Buffer run_metadata,
    TF_Status arg11);

// Set up the graph with the intended feeds (inputs) and fetches (outputs) for a
// sequence of partial run calls.
//
// On success, returns a handle that is used for subsequent PRun calls. The
// handle should be deleted with TF_DeletePRunHandle when it is no longer
// needed.
//
// On failure, out_status contains a tensorflow::Status with an error
// message. *handle is set to nullptr.
public static native void TF_SessionPRunSetup(
    TF_Session arg0,
    @Const TF_Output inputs, int ninputs,
    @Const TF_Output outputs, int noutputs,
    @Cast("const TF_Operation*const*") PointerPointer target_opers, int ntargets,
    @Cast("const char**") PointerPointer handle,
    TF_Status arg8);
public static native void TF_SessionPRunSetup(
    TF_Session arg0,
    @Const TF_Output inputs, int ninputs,
    @Const TF_Output outputs, int noutputs,
    @Const @ByPtrPtr TF_Operation target_opers, int ntargets,
    @Cast("const char**") @ByPtrPtr BytePointer handle,
    TF_Status arg8);
public static native void TF_SessionPRunSetup(
    TF_Session arg0,
    @Const TF_Output inputs, int ninputs,
    @Const TF_Output outputs, int noutputs,
    @Const @ByPtrPtr TF_Operation target_opers, int ntargets,
    @Cast("const char**") @ByPtrPtr ByteBuffer handle,
    TF_Status arg8);
public static native void TF_SessionPRunSetup(
    TF_Session arg0,
    @Const TF_Output inputs, int ninputs,
    @Const TF_Output outputs, int noutputs,
    @Const @ByPtrPtr TF_Operation target_opers, int ntargets,
    @Cast("const char**") @ByPtrPtr byte[] handle,
    TF_Status arg8);

// Continue to run the graph with additional feeds and fetches. The
// execution state is uniquely identified by the handle.
public static native void TF_SessionPRun(
    TF_Session arg0, @Cast("const char*") BytePointer handle,
    @Const TF_Output inputs, @Cast("TF_Tensor*const*") PointerPointer input_values, int ninputs,
    @Const TF_Output outputs, @Cast("TF_Tensor**") PointerPointer output_values, int noutputs,
    @Cast("const TF_Operation*const*") PointerPointer target_opers, int ntargets,
    TF_Status arg10);
public static native void TF_SessionPRun(
    TF_Session arg0, @Cast("const char*") BytePointer handle,
    @Const TF_Output inputs, @ByPtrPtr TF_Tensor input_values, int ninputs,
    @Const TF_Output outputs, @ByPtrPtr TF_Tensor output_values, int noutputs,
    @Const @ByPtrPtr TF_Operation target_opers, int ntargets,
    TF_Status arg10);
public static native void TF_SessionPRun(
    TF_Session arg0, String handle,
    @Const TF_Output inputs, @ByPtrPtr TF_Tensor input_values, int ninputs,
    @Const TF_Output outputs, @ByPtrPtr TF_Tensor output_values, int noutputs,
    @Const @ByPtrPtr TF_Operation target_opers, int ntargets,
    TF_Status arg10);

// Deletes a handle allocated by TF_SessionPRunSetup.
// Once called, no more calls to TF_SessionPRun should be made.
public static native void TF_DeletePRunHandle(@Cast("const char*") BytePointer handle);
public static native void TF_DeletePRunHandle(String handle);

// --------------------------------------------------------------------------
// The deprecated session API.  Please switch to the above instead of
// TF_ExtendGraph(). This deprecated API can be removed at any time without
// notice.

public static native TF_DeprecatedSession TF_NewDeprecatedSession(
    @Const TF_SessionOptions arg0, TF_Status status);
public static native void TF_CloseDeprecatedSession(TF_DeprecatedSession arg0,
                                                     TF_Status status);
public static native void TF_DeleteDeprecatedSession(TF_DeprecatedSession arg0,
                                                      TF_Status status);
public static native void TF_Reset(@Const TF_SessionOptions opt,
                                    @Cast("const char**") PointerPointer containers, int ncontainers,
                                    TF_Status status);
public static native void TF_Reset(@Const TF_SessionOptions opt,
                                    @Cast("const char**") @ByPtrPtr BytePointer containers, int ncontainers,
                                    TF_Status status);
public static native void TF_Reset(@Const TF_SessionOptions opt,
                                    @Cast("const char**") @ByPtrPtr ByteBuffer containers, int ncontainers,
                                    TF_Status status);
public static native void TF_Reset(@Const TF_SessionOptions opt,
                                    @Cast("const char**") @ByPtrPtr byte[] containers, int ncontainers,
                                    TF_Status status);
// Treat the bytes proto[0,proto_len-1] as a serialized GraphDef and
// add the nodes in that GraphDef to the graph for the session.
//
// Prefer use of TF_Session and TF_GraphImportGraphDef over this.
public static native void TF_ExtendGraph(TF_DeprecatedSession arg0,
                                          @Const Pointer proto, @Cast("size_t") long proto_len,
                                          TF_Status arg3);

// See TF_SessionRun() above.
public static native void TF_Run(TF_DeprecatedSession arg0,
                                  @Const TF_Buffer run_options,
                                  @Cast("const char**") PointerPointer input_names, @Cast("TF_Tensor**") PointerPointer inputs,
                                  int ninputs, @Cast("const char**") PointerPointer output_names,
                                  @Cast("TF_Tensor**") PointerPointer outputs, int noutputs,
                                  @Cast("const char**") PointerPointer target_oper_names, int ntargets,
                                  TF_Buffer run_metadata, TF_Status arg11);
public static native void TF_Run(TF_DeprecatedSession arg0,
                                  @Const TF_Buffer run_options,
                                  @Cast("const char**") @ByPtrPtr BytePointer input_names, @ByPtrPtr TF_Tensor inputs,
                                  int ninputs, @Cast("const char**") @ByPtrPtr BytePointer output_names,
                                  @ByPtrPtr TF_Tensor outputs, int noutputs,
                                  @Cast("const char**") @ByPtrPtr BytePointer target_oper_names, int ntargets,
                                  TF_Buffer run_metadata, TF_Status arg11);
public static native void TF_Run(TF_DeprecatedSession arg0,
                                  @Const TF_Buffer run_options,
                                  @Cast("const char**") @ByPtrPtr ByteBuffer input_names, @ByPtrPtr TF_Tensor inputs,
                                  int ninputs, @Cast("const char**") @ByPtrPtr ByteBuffer output_names,
                                  @ByPtrPtr TF_Tensor outputs, int noutputs,
                                  @Cast("const char**") @ByPtrPtr ByteBuffer target_oper_names, int ntargets,
                                  TF_Buffer run_metadata, TF_Status arg11);
public static native void TF_Run(TF_DeprecatedSession arg0,
                                  @Const TF_Buffer run_options,
                                  @Cast("const char**") @ByPtrPtr byte[] input_names, @ByPtrPtr TF_Tensor inputs,
                                  int ninputs, @Cast("const char**") @ByPtrPtr byte[] output_names,
                                  @ByPtrPtr TF_Tensor outputs, int noutputs,
                                  @Cast("const char**") @ByPtrPtr byte[] target_oper_names, int ntargets,
                                  TF_Buffer run_metadata, TF_Status arg11);

// See TF_SessionPRunSetup() above.
public static native void TF_PRunSetup(TF_DeprecatedSession arg0,
                                        @Cast("const char**") PointerPointer input_names, int ninputs,
                                        @Cast("const char**") PointerPointer output_names, int noutputs,
                                        @Cast("const char**") PointerPointer target_oper_names,
                                        int ntargets, @Cast("const char**") PointerPointer handle,
                                        TF_Status arg8);
public static native void TF_PRunSetup(TF_DeprecatedSession arg0,
                                        @Cast("const char**") @ByPtrPtr BytePointer input_names, int ninputs,
                                        @Cast("const char**") @ByPtrPtr BytePointer output_names, int noutputs,
                                        @Cast("const char**") @ByPtrPtr BytePointer target_oper_names,
                                        int ntargets, @Cast("const char**") @ByPtrPtr BytePointer handle,
                                        TF_Status arg8);
public static native void TF_PRunSetup(TF_DeprecatedSession arg0,
                                        @Cast("const char**") @ByPtrPtr ByteBuffer input_names, int ninputs,
                                        @Cast("const char**") @ByPtrPtr ByteBuffer output_names, int noutputs,
                                        @Cast("const char**") @ByPtrPtr ByteBuffer target_oper_names,
                                        int ntargets, @Cast("const char**") @ByPtrPtr ByteBuffer handle,
                                        TF_Status arg8);
public static native void TF_PRunSetup(TF_DeprecatedSession arg0,
                                        @Cast("const char**") @ByPtrPtr byte[] input_names, int ninputs,
                                        @Cast("const char**") @ByPtrPtr byte[] output_names, int noutputs,
                                        @Cast("const char**") @ByPtrPtr byte[] target_oper_names,
                                        int ntargets, @Cast("const char**") @ByPtrPtr byte[] handle,
                                        TF_Status arg8);

// See TF_SessionPRun above.
public static native void TF_PRun(TF_DeprecatedSession arg0, @Cast("const char*") BytePointer handle,
                                   @Cast("const char**") PointerPointer input_names, @Cast("TF_Tensor**") PointerPointer inputs,
                                   int ninputs, @Cast("const char**") PointerPointer output_names,
                                   @Cast("TF_Tensor**") PointerPointer outputs, int noutputs,
                                   @Cast("const char**") PointerPointer target_oper_names, int ntargets,
                                   TF_Status arg10);
public static native void TF_PRun(TF_DeprecatedSession arg0, @Cast("const char*") BytePointer handle,
                                   @Cast("const char**") @ByPtrPtr BytePointer input_names, @ByPtrPtr TF_Tensor inputs,
                                   int ninputs, @Cast("const char**") @ByPtrPtr BytePointer output_names,
                                   @ByPtrPtr TF_Tensor outputs, int noutputs,
                                   @Cast("const char**") @ByPtrPtr BytePointer target_oper_names, int ntargets,
                                   TF_Status arg10);
public static native void TF_PRun(TF_DeprecatedSession arg0, String handle,
                                   @Cast("const char**") @ByPtrPtr ByteBuffer input_names, @ByPtrPtr TF_Tensor inputs,
                                   int ninputs, @Cast("const char**") @ByPtrPtr ByteBuffer output_names,
                                   @ByPtrPtr TF_Tensor outputs, int noutputs,
                                   @Cast("const char**") @ByPtrPtr ByteBuffer target_oper_names, int ntargets,
                                   TF_Status arg10);
public static native void TF_PRun(TF_DeprecatedSession arg0, @Cast("const char*") BytePointer handle,
                                   @Cast("const char**") @ByPtrPtr byte[] input_names, @ByPtrPtr TF_Tensor inputs,
                                   int ninputs, @Cast("const char**") @ByPtrPtr byte[] output_names,
                                   @ByPtrPtr TF_Tensor outputs, int noutputs,
                                   @Cast("const char**") @ByPtrPtr byte[] target_oper_names, int ntargets,
                                   TF_Status arg10);
public static native void TF_PRun(TF_DeprecatedSession arg0, String handle,
                                   @Cast("const char**") @ByPtrPtr BytePointer input_names, @ByPtrPtr TF_Tensor inputs,
                                   int ninputs, @Cast("const char**") @ByPtrPtr BytePointer output_names,
                                   @ByPtrPtr TF_Tensor outputs, int noutputs,
                                   @Cast("const char**") @ByPtrPtr BytePointer target_oper_names, int ntargets,
                                   TF_Status arg10);
public static native void TF_PRun(TF_DeprecatedSession arg0, @Cast("const char*") BytePointer handle,
                                   @Cast("const char**") @ByPtrPtr ByteBuffer input_names, @ByPtrPtr TF_Tensor inputs,
                                   int ninputs, @Cast("const char**") @ByPtrPtr ByteBuffer output_names,
                                   @ByPtrPtr TF_Tensor outputs, int noutputs,
                                   @Cast("const char**") @ByPtrPtr ByteBuffer target_oper_names, int ntargets,
                                   TF_Status arg10);
public static native void TF_PRun(TF_DeprecatedSession arg0, String handle,
                                   @Cast("const char**") @ByPtrPtr byte[] input_names, @ByPtrPtr TF_Tensor inputs,
                                   int ninputs, @Cast("const char**") @ByPtrPtr byte[] output_names,
                                   @ByPtrPtr TF_Tensor outputs, int noutputs,
                                   @Cast("const char**") @ByPtrPtr byte[] target_oper_names, int ntargets,
                                   TF_Status arg10);

// Lists all devices in a TF_Session.
//
// Caller takes ownership of the returned TF_DeviceList* which must eventually
// be freed with a call to TF_DeleteDeviceList.
public static native TF_DeviceList TF_SessionListDevices(TF_Session session,
                                                           TF_Status status);

// Lists all devices in a TF_Session.
//
// Caller takes ownership of the returned TF_DeviceList* which must eventually
// be freed with a call to TF_DeleteDeviceList.
public static native TF_DeviceList TF_DeprecatedSessionListDevices(
    TF_DeprecatedSession session, TF_Status status);

// Deallocates the device list.
public static native void TF_DeleteDeviceList(TF_DeviceList list);

// Counts the number of elements in the device list.
public static native int TF_DeviceListCount(@Const TF_DeviceList list);

// Retrieves the full name of the device (e.g. /job:worker/replica:0/...)
// The return value will be a pointer to a null terminated string. The caller
// must not modify or delete the string. It will be deallocated upon a call to
// TF_DeleteDeviceList.
//
// If index is out of bounds, an error code will be set in the status object,
// and a null pointer will be returned.
public static native @Cast("const char*") BytePointer TF_DeviceListName(@Const TF_DeviceList list,
                                                    int index,
                                                    TF_Status status);

// Retrieves the type of the device at the given index.
//
// The caller must not modify or delete the string. It will be deallocated upon
// a call to TF_DeleteDeviceList.
//
// If index is out of bounds, an error code will be set in the status object,
// and a null pointer will be returned.
public static native @Cast("const char*") BytePointer TF_DeviceListType(@Const TF_DeviceList list,
                                                    int index,
                                                    TF_Status status);

// Retrieve the amount of memory associated with a given device.
//
// If index is out of bounds, an error code will be set in the status object,
// and -1 will be returned.
public static native @Cast("int64_t") long TF_DeviceListMemoryBytes(
    @Const TF_DeviceList list, int index, TF_Status status);

// Retrieve the incarnation number of a given device.
//
// If index is out of bounds, an error code will be set in the status object,
// and 0 will be returned.
public static native @Cast("uint64_t") long TF_DeviceListIncarnation(
    @Const TF_DeviceList list, int index, TF_Status status);

// --------------------------------------------------------------------------
// Load plugins containing custom ops and kernels

// TF_Library holds information about dynamically loaded TensorFlow plugins.

// Load the library specified by library_filename and register the ops and
// kernels present in that library.
//
// Pass "library_filename" to a platform-specific mechanism for dynamically
// loading a library. The rules for determining the exact location of the
// library are platform-specific and are not documented here.
//
// On success, place OK in status and return the newly created library handle.
// The caller owns the library handle.
//
// On failure, place an error status in status and return NULL.
public static native TF_Library TF_LoadLibrary(@Cast("const char*") BytePointer library_filename,
                                                 TF_Status status);
public static native TF_Library TF_LoadLibrary(String library_filename,
                                                 TF_Status status);

// Get the OpList of OpDefs defined in the library pointed by lib_handle.
//
// Returns a TF_Buffer. The memory pointed to by the result is owned by
// lib_handle. The data in the buffer will be the serialized OpList proto for
// ops defined in the library.
public static native @ByVal TF_Buffer TF_GetOpList(TF_Library lib_handle);

// Frees the memory associated with the library handle.
// Does NOT unload the library.
public static native void TF_DeleteLibraryHandle(TF_Library lib_handle);

// Get the OpList of all OpDefs defined in this address space.
// Returns a TF_Buffer, ownership of which is transferred to the caller
// (and can be freed using TF_DeleteBuffer).
//
// The data in the buffer will be the serialized OpList proto for ops registered
// in this address space.
public static native TF_Buffer TF_GetAllOpList();

// TF_ApiDefMap encapsulates a collection of API definitions for an operation.
//
// This object maps the name of a TensorFlow operation to a description of the
// API to generate for it, as defined by the ApiDef protocol buffer (
// https://www.tensorflow.org/code/tensorflow/core/framework/api_def.proto)
//
// The ApiDef messages are typically used to generate convenience wrapper
// functions for TensorFlow operations in various language bindings.

// Creates a new TF_ApiDefMap instance.
//
// Params:
//  op_list_buffer - TF_Buffer instance containing serialized OpList
//    protocol buffer. (See
//    https://www.tensorflow.org/code/tensorflow/core/framework/op_def.proto
//    for the OpList proto definition).
//  status - Set to OK on success and an appropriate error on failure.
public static native TF_ApiDefMap TF_NewApiDefMap(TF_Buffer op_list_buffer,
                                                    TF_Status status);

// Deallocates a TF_ApiDefMap.
public static native void TF_DeleteApiDefMap(TF_ApiDefMap apimap);

// Add ApiDefs to the map.
//
// `text` corresponds to a text representation of an ApiDefs protocol message.
// (https://www.tensorflow.org/code/tensorflow/core/framework/api_def.proto).
//
// The provided ApiDefs will be merged with existing ones in the map, with
// precedence given to the newly added version in case of conflicts with
// previous calls to TF_ApiDefMapPut.
public static native void TF_ApiDefMapPut(TF_ApiDefMap api_def_map,
                                           @Cast("const char*") BytePointer text, @Cast("size_t") long text_len,
                                           TF_Status status);
public static native void TF_ApiDefMapPut(TF_ApiDefMap api_def_map,
                                           String text, @Cast("size_t") long text_len,
                                           TF_Status status);

// Returns a serialized ApiDef protocol buffer for the TensorFlow operation
// named `name`.
public static native TF_Buffer TF_ApiDefMapGet(TF_ApiDefMap api_def_map,
                                                 @Cast("const char*") BytePointer name,
                                                 @Cast("size_t") long name_len,
                                                 TF_Status status);
public static native TF_Buffer TF_ApiDefMapGet(TF_ApiDefMap api_def_map,
                                                 String name,
                                                 @Cast("size_t") long name_len,
                                                 TF_Status status);

// --------------------------------------------------------------------------
// Kernel definition information.

// Returns a serialized KernelList protocol buffer containing KernelDefs for all
// registered kernels.
public static native TF_Buffer TF_GetAllRegisteredKernels(TF_Status status);

// Returns a serialized KernelList protocol buffer containing KernelDefs for all
// kernels registered for the operation named `name`.
public static native TF_Buffer TF_GetRegisteredKernelsForOp(
    @Cast("const char*") BytePointer name, TF_Status status);
public static native TF_Buffer TF_GetRegisteredKernelsForOp(
    String name, TF_Status status);

// --------------------------------------------------------------------------
// In-process TensorFlow server functionality, for use in distributed training.
// A Server instance encapsulates a set of devices and a Session target that
// can participate in distributed training. A server belongs to a cluster
// (specified by a ClusterSpec), and corresponds to a particular task in a
// named job. The server can communicate with any other server in the same
// cluster.

// In-process TensorFlow server.

// Creates a new in-process TensorFlow server configured using a serialized
// ServerDef protocol buffer provided via `proto` and `proto_len`.
//
// The server will not serve any requests until TF_ServerStart is invoked.
// The server will stop serving requests once TF_ServerStop or
// TF_DeleteServer is invoked.
public static native TF_Server TF_NewServer(@Const Pointer proto,
                                              @Cast("size_t") long proto_len,
                                              TF_Status status);

// Starts an in-process TensorFlow server.
public static native void TF_ServerStart(TF_Server server, TF_Status status);

// Stops an in-process TensorFlow server.
public static native void TF_ServerStop(TF_Server server, TF_Status status);

// Blocks until the server has been successfully stopped (via TF_ServerStop or
// TF_ServerClose).
public static native void TF_ServerJoin(TF_Server server, TF_Status status);

// Returns the target string that can be provided to TF_SetTarget() to connect
// a TF_Session to `server`.
//
// The returned string is valid only until TF_DeleteServer is invoked.
public static native @Cast("const char*") BytePointer TF_ServerTarget(TF_Server server);

// Destroy an in-process TensorFlow server, frees memory. If server is running
// it will be stopped and joined.
public static native void TF_DeleteServer(TF_Server server);

// #ifdef __cplusplus /* end extern "C" */
// #endif

// #endif  // TENSORFLOW_C_C_API_H_


// Parsed from tensorflow/c/c_api_internal.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_C_C_API_INTERNAL_H_
// #define TENSORFLOW_C_C_API_INTERNAL_H_

// #include "tensorflow/c/c_api.h"

// #include <list>
// #include <set>
// #include <string>
// #include <unordered_map>
// #include <vector>

// #ifndef __ANDROID__
// #include "tensorflow/core/distributed_runtime/server_lib.h"
// #include "tensorflow/core/framework/op_gen_lib.h"
// #endif
// #include "tensorflow/core/common_runtime/shape_refiner.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/graph/graph.h"
// #include "tensorflow/core/graph/graph_constructor.h"
// #include "tensorflow/core/graph/node_builder.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/platform/mutex.h"
// #include "tensorflow/core/platform/types.h"
// #include "tensorflow/core/public/session.h"

// Targeting ../TF_Status.java


// Targeting ../TF_Tensor.java


// Targeting ../TF_SessionOptions.java


// Targeting ../TF_DeprecatedSession.java


// Targeting ../TF_Library.java


// Targeting ../TF_Graph.java


// Targeting ../TF_OperationDescription.java


// Targeting ../TF_Operation.java


// Targeting ../TF_Session.java


// Targeting ../TF_ImportGraphDefOptions.java


// Targeting ../TF_ImportGraphDefResults.java


// Targeting ../TF_DeviceList.java


// Targeting ../TF_Function.java


// Targeting ../TF_ApiDefMap.java


// Targeting ../TF_Server.java


// Targeting ../TensorCApi.java



@Namespace("tensorflow") public static native @ByVal Status TF_TensorToTensor(@Const TF_Tensor src, Tensor dst);

@Namespace("tensorflow") public static native TF_Tensor TF_TensorFromTensor(@Const @ByRef Tensor src, TF_Status status);

@Namespace("tensorflow") public static native @ByVal Status MessageToBuffer(@Cast("const tensorflow::protobuf::Message*") @ByRef MessageLite in, TF_Buffer out);

// Set the shapes and types of the output's handle.
//
// The lengths of the arrays pointed to by `shapes`, `ranks`, and `types` must
// all be equal to `num_shapes_and_types`. If `ranks[i] != -1`, (i.e., if the
// rank is known), then it must be equal to the length of `shapes[i]`; if
// `ranks[i] == 1`, then `shapes[i]` may be nullptr.
//
// TODO(akshayka): Implement a corresponding getter method.
@Namespace("tensorflow") public static native void TF_GraphSetOutputHandleShapesAndTypes(TF_Graph graph, @ByVal TF_Output output,
                                           int num_shapes_and_types,
                                           @Cast("const int64_t**") PointerPointer shapes,
                                           @Const IntPointer ranks,
                                           @Cast("const TF_DataType*") IntPointer types,
                                           TF_Status status);
@Namespace("tensorflow") public static native void TF_GraphSetOutputHandleShapesAndTypes(TF_Graph graph, @ByVal TF_Output output,
                                           int num_shapes_and_types,
                                           @Cast("const int64_t**") @ByPtrPtr LongPointer shapes,
                                           @Const IntPointer ranks,
                                           @Cast("const TF_DataType*") IntPointer types,
                                           TF_Status status);
@Namespace("tensorflow") public static native void TF_GraphSetOutputHandleShapesAndTypes(TF_Graph graph, @ByVal TF_Output output,
                                           int num_shapes_and_types,
                                           @Cast("const int64_t**") @ByPtrPtr LongBuffer shapes,
                                           @Const IntBuffer ranks,
                                           @Cast("const TF_DataType*") IntBuffer types,
                                           TF_Status status);
@Namespace("tensorflow") public static native void TF_GraphSetOutputHandleShapesAndTypes(TF_Graph graph, @ByVal TF_Output output,
                                           int num_shapes_and_types,
                                           @Cast("const int64_t**") @ByPtrPtr long[] shapes,
                                           @Const int[] ranks,
                                           @Cast("const TF_DataType*") int[] types,
                                           TF_Status status);

@Namespace("tensorflow") public static native void RecordMutation(TF_Graph graph, @Const @ByRef TF_Operation op,
                    @Cast("const char*") BytePointer mutation_type);
@Namespace("tensorflow") public static native void RecordMutation(TF_Graph graph, @Const @ByRef TF_Operation op,
                    String mutation_type);

@Namespace("tensorflow") public static native @Cast("bool") boolean ExtendSessionGraphHelper(TF_Session session, TF_Status status);

  // end namespace tensorflow

// #endif  // TENSORFLOW_C_C_API_INTERNAL_H_


// Parsed from tensorflow/c/python_api.h

/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_C_PYTHON_API_H_
// #define TENSORFLOW_C_PYTHON_API_H_

// #include <string>

// #include "tensorflow/c/c_api.h"

// These functions can be removed without notice. They exist to facilitate some
// refactoring of graph construction code in the Python API.

@Namespace("tensorflow") public static native void AddControlInput(TF_Graph graph, TF_Operation op, TF_Operation input);

// Changes an attr value in the node_def Protocol Buffer and sets a status upon
// completion.
@Namespace("tensorflow") public static native void SetAttr(TF_Graph graph, TF_Operation op, @Cast("const char*") BytePointer attr_name,
             TF_Buffer attr_value_proto, TF_Status status);
@Namespace("tensorflow") public static native void SetAttr(TF_Graph graph, TF_Operation op, String attr_name,
             TF_Buffer attr_value_proto, TF_Status status);

@Namespace("tensorflow") public static native void SetRequestedDevice(TF_Graph graph, TF_Operation op, @Cast("const char*") BytePointer device);
@Namespace("tensorflow") public static native void SetRequestedDevice(TF_Graph graph, TF_Operation op, String device);

// Updates 'dst' to consume 'new_src'.
@Namespace("tensorflow") public static native void UpdateEdge(TF_Graph graph, @ByVal TF_Output new_src, @ByVal TF_Input dst,
                TF_Status status);

@Namespace("tensorflow") public static native void RemoveAllControlInputs(TF_Graph graph, TF_Operation op);

// Sets whether ops missing a shape inference function should trigger an
// error. The default is true.
@Namespace("tensorflow") public static native void SetRequireShapeInferenceFns(TF_Graph graph, @Cast("bool") boolean require);

// Extends `session` with any new operations added to its associated graph.
// Usually this happens automatically in TF_SessionRun. After this is called,
// TF_SessionRun will no longer extend the session on every call.
//
// We expose this here to allow fine-grained synchronization in multi-threaded
// workloads, which is required since the Python implementation depends on the
// above mutation methods. This allows us to prevent modifications to nodes in
// the graph after the session has been made aware of them.
@Namespace("tensorflow") public static native void ExtendSession(TF_Session session, TF_Status status);

// Returns the serialized CppShapeInferenceResult::HandleData proto for
// `output` if its a resource or variant tensor, or otherwise returns the empty
// string.
@Namespace("tensorflow") public static native @StdString BytePointer GetHandleShapeAndType(TF_Graph graph, @ByVal TF_Output output);

// Sets `output` based on `proto`, which should be a serialized
// CppShapeInferenceResult::HandleData proto. `output` should be a resource
// or variant tensor.
// NOTE(skyewm): `proto` is passed a void*/size_t pair instead of a std::string
// because I couldn't get SWIG to work otherwise.
@Namespace("tensorflow") public static native void SetHandleShapeAndType(TF_Graph graph, @ByVal TF_Output output, @Const Pointer proto,
                           @Cast("size_t") long proto_len, TF_Status status);

// This method is used to add a new input edge to 'dst', which must be a While
// op. The While op's "T" attribute must have already been updated to include
// the new edge. This is used to construct tf.while_loop gradients.
@Namespace("tensorflow") public static native void AddWhileInputHack(TF_Graph graph, @ByVal TF_Output new_src, TF_Operation dst,
                       TF_Status status);

  // namespace tensorflow

// #endif  // TENSORFLOW_C_PYTHON_API_H_


// Parsed from tensorflow/core/framework/op_def_builder.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// Class and associated machinery for specifying an Op's OpDef and shape
// inference function for Op registration.

// #ifndef TENSORFLOW_CORE_FRAMEWORK_OP_DEF_BUILDER_H_
// #define TENSORFLOW_CORE_FRAMEWORK_OP_DEF_BUILDER_H_

// #include <string>
// #include <vector>
// #include "tensorflow/core/framework/op_def.pb.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/platform/macros.h"

// Targeting ../OpRegistrationData.java


// Targeting ../OpDefBuilder.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_OP_DEF_BUILDER_H_


// Parsed from tensorflow/core/framework/op_def_util.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// TODO(josh11b): Probably not needed for OpKernel authors, so doesn't
// need to be as publicly accessible as other files in framework/.

// #ifndef TENSORFLOW_CORE_FRAMEWORK_OP_DEF_UTIL_H_
// #define TENSORFLOW_CORE_FRAMEWORK_OP_DEF_UTIL_H_

// #include <string>
// #include "tensorflow/core/framework/api_def.pb.h"
// #include "tensorflow/core/framework/op_def.pb.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/platform/protobuf.h"

// Performs a consistency check across the fields of the op_def.
@Namespace("tensorflow") public static native @ByVal Status ValidateOpDef(@Const @ByRef OpDef op_def);

// Check if an op is deprecated at the given GraphDef version.  If the op is
// deprecated at a future version, a warning will be logged.
@Namespace("tensorflow") public static native @ByVal Status CheckOpDeprecation(@Const @ByRef OpDef op_def, int graph_def_version);

// Validates that attr_value satisfies the type and constraints from attr.
// REQUIRES: attr has already been validated.
@Namespace("tensorflow") public static native @ByVal Status ValidateAttrValue(@Const @ByRef AttrValue attr_value,
                         @Cast("const tensorflow::OpDef::AttrDef*") @ByRef OpDef_AttrDef attr);

// The following search through op_def for an attr with the indicated name.
// Returns nullptr if no such attr is found.
@Namespace("tensorflow") public static native @Cast("const tensorflow::OpDef::AttrDef*") OpDef_AttrDef FindAttr(@StringPiece BytePointer name, @Const @ByRef OpDef op_def);
@Namespace("tensorflow") public static native @Cast("const tensorflow::OpDef::AttrDef*") OpDef_AttrDef FindAttr(@StringPiece String name, @Const @ByRef OpDef op_def);
@Namespace("tensorflow") public static native @Cast("tensorflow::OpDef::AttrDef*") OpDef_AttrDef FindAttrMutable(@StringPiece BytePointer name, OpDef op_def);
@Namespace("tensorflow") public static native @Cast("tensorflow::OpDef::AttrDef*") OpDef_AttrDef FindAttrMutable(@StringPiece String name, OpDef op_def);

// Searches op_def for input argument with the indicated name.
// Returns nullptr if no such attr is found.
@Namespace("tensorflow") public static native @Cast("const tensorflow::OpDef::ArgDef*") OpDef_ArgDef FindInputArg(@StringPiece BytePointer name, @Const @ByRef OpDef op_def);
@Namespace("tensorflow") public static native @Cast("const tensorflow::OpDef::ArgDef*") OpDef_ArgDef FindInputArg(@StringPiece String name, @Const @ByRef OpDef op_def);

// Searches api_def for input argument with the indicated name.
// Returns nullptr if no such attr is found.
@Namespace("tensorflow") public static native @Cast("const tensorflow::ApiDef::Arg*") ApiDef_Arg FindInputArg(@StringPiece BytePointer name, @Const @ByRef ApiDef api_def);
@Namespace("tensorflow") public static native @Cast("const tensorflow::ApiDef::Arg*") ApiDef_Arg FindInputArg(@StringPiece String name, @Const @ByRef ApiDef api_def);

// Produce a human-readable version of an op_def that is more concise
// than a text-format proto.  Excludes descriptions.
@Namespace("tensorflow") public static native @StdString BytePointer SummarizeOpDef(@Const @ByRef OpDef op_def);

// Returns an error if new_op is not backwards-compatible with (more
// accepting than) old_op.
// REQUIRES: old_op and new_op must pass validation.
@Namespace("tensorflow") public static native @ByVal Status OpDefCompatible(@Const @ByRef OpDef old_op, @Const @ByRef OpDef new_op);

// Returns an error if any attr in penultimate_op that is not in old_op
// has a different default value in new_op.  In general it is not safe
// to change the default for an attr that has been added to an op.
@Namespace("tensorflow") public static native @ByVal Status OpDefAddedDefaultsUnchanged(@Const @ByRef OpDef old_op,
                                   @Const @ByRef OpDef penultimate_op,
                                   @Const @ByRef OpDef new_op);

// Returns an error if the default value for any attr is added/removed/modified
// in new_op compared to old_op.
@Namespace("tensorflow") public static native @ByVal Status OpDefAttrDefaultsUnchanged(@Const @ByRef OpDef old_op, @Const @ByRef OpDef new_op);

// Remove all docs from *op_def / *op_list.
@Namespace("tensorflow") public static native void RemoveDescriptionsFromOpDef(OpDef op_def);
@Namespace("tensorflow") public static native void RemoveDescriptionsFromOpList(OpList op_list);

// Remove docs from *op_def but leave explanations of deprecations.
@Namespace("tensorflow") public static native void RemoveNonDeprecationDescriptionsFromOpDef(OpDef op_def);

// Returns true if `a1` is equal to `a2`.
// Equality includes all the fields.
@Namespace("tensorflow") public static native @Cast("bool") boolean AttrDefEqual(@Cast("const tensorflow::OpDef::AttrDef*") @ByRef OpDef_AttrDef a1, @Cast("const tensorflow::OpDef::AttrDef*") @ByRef OpDef_AttrDef a2);

// Returns hash of `a` that is consistent with AttrDefEqual.
@Namespace("tensorflow") public static native @Cast("tensorflow::uint64") long AttrDefHash(@Cast("const tensorflow::OpDef::AttrDef*") @ByRef OpDef_AttrDef a);

// Returns true if all AttrDefs in `a1` equal corresponding AttrDefs in
// `a2`. Correspondence is established by name.

// Returns hash of `a` that is consistent with RepeatedAttrDefEqual

// Returns true if `o1` is equal to `o2`.
// Equality includes all the fields. OpDef.attr field is treated as a set.
@Namespace("tensorflow") public static native @Cast("bool") boolean OpDefEqual(@Const @ByRef OpDef o1, @Const @ByRef OpDef o2);

// Returns hash of `o` that is consistent with AttrDefEqual.
@Namespace("tensorflow") public static native @Cast("tensorflow::uint64") long OpDefHash(@Const @ByRef OpDef o);

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_OP_DEF_UTIL_H_


// Parsed from tensorflow/core/framework/op.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_OP_H_
// #define TENSORFLOW_CORE_FRAMEWORK_OP_H_

// #include <functional>
// #include <unordered_map>

// #include <vector>
// #include "tensorflow/core/framework/op_def_builder.h"
// #include "tensorflow/core/framework/op_def_util.h"
// #include "tensorflow/core/framework/selective_registration.h"
// #include "tensorflow/core/lib/core/errors.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/strings/str_util.h"
// #include "tensorflow/core/lib/strings/strcat.h"
// #include "tensorflow/core/platform/logging.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/mutex.h"
// #include "tensorflow/core/platform/thread_annotations.h"
// #include "tensorflow/core/platform/types.h"
// Targeting ../OpRegistryInterface.java


// Targeting ../OpRegistry.java


// Targeting ../OpListOpRegistry.java



// Support for defining the OpDef (specifying the semantics of the Op and how
// it should be created) and registering it in the OpRegistry::Global()
// registry.  Usage:
//
// REGISTER_OP("my_op_name")
//     .Attr("<name>:<type>")
//     .Attr("<name>:<type>=<default>")
//     .Input("<name>:<type-expr>")
//     .Input("<name>:Ref(<type-expr>)")
//     .Output("<name>:<type-expr>")
//     .Doc(R"(
// <1-line summary>
// <rest of the description (potentially many lines)>
// <name-of-attr-input-or-output>: <description of name>
// <name-of-attr-input-or-output>: <description of name;
//   if long, indent the description on subsequent lines>
// )");
//
// Note: .Doc() should be last.
// For details, see the OpDefBuilder class in op_def_builder.h.

// OpDefBuilderWrapper is a templated class that is used in the REGISTER_OP
// calls. This allows the result of REGISTER_OP to be used in chaining, as in
// REGISTER_OP(a).Attr("...").Input("...");, while still allowing selective
// registration to turn the entire call-chain into a no-op.
// Targeting ../TrueOpDefBuilderWrapper.java


// Targeting ../FalseOpDefBuilderWrapper.java


// Targeting ../OpDefBuilderReceiver.java


  // namespace register_op

// #define REGISTER_OP(name) REGISTER_OP_UNIQ_HELPER(__COUNTER__, name)
// #define REGISTER_OP_UNIQ_HELPER(ctr, name) REGISTER_OP_UNIQ(ctr, name)
// #define REGISTER_OP_UNIQ(ctr, name)
//   static ::tensorflow::register_op::OpDefBuilderReceiver register_op##ctr
//       TF_ATTRIBUTE_UNUSED =
//           ::tensorflow::register_op::OpDefBuilderWrapper<SHOULD_REGISTER_OP(
//               name)>(name)

// The `REGISTER_SYSTEM_OP()` macro acts as `REGISTER_OP()` except
// that the op is registered unconditionally even when selective
// registration is used.
// #define REGISTER_SYSTEM_OP(name)
//   REGISTER_SYSTEM_OP_UNIQ_HELPER(__COUNTER__, name)
// #define REGISTER_SYSTEM_OP_UNIQ_HELPER(ctr, name)
//   REGISTER_SYSTEM_OP_UNIQ(ctr, name)
// #define REGISTER_SYSTEM_OP_UNIQ(ctr, name)
//   static ::tensorflow::register_op::OpDefBuilderReceiver register_op##ctr
//       TF_ATTRIBUTE_UNUSED =
//           ::tensorflow::register_op::OpDefBuilderWrapper<true>(name)

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_OP_H_


// Parsed from tensorflow/core/graph/edgeset.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_GRAPH_EDGESET_H_
// #define TENSORFLOW_GRAPH_EDGESET_H_

// #include <stddef.h>
// #include <set>
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/types.h"

// #include "tensorflow/core/platform/logging.h"
// Targeting ../EdgeSet.java


// Targeting ../EdgeSetIterator.java





















// gcc's set and multiset always use const_iterator since it will otherwise
// allow modification of keys.


// gcc's set and multiset always use const_iterator since it will otherwise
// allow modification of keys.




  // namespace tensorflow

// #endif  // TENSORFLOW_GRAPH_EDGESET_H_


// Parsed from tensorflow/core/lib/gtl/iterator_range.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// This provides a very simple, boring adaptor for a begin and end iterator
// into a range type. This should be used to build range views that work well
// with range based for loops and range based constructors.
//
// Note that code here follows more standards-based coding conventions as it
// is mirroring proposed interfaces for standardization.
//
// Converted from chandlerc@'s code to Google style by joshl@.

// #ifndef TENSORFLOW_LIB_GTL_ITERATOR_RANGE_H_
// #define TENSORFLOW_LIB_GTL_ITERATOR_RANGE_H_

// #include <utility>
// Targeting ../NeighborIterRange.java


// Targeting ../NodeIterRange.java



// Convenience function for iterating over sub-ranges.
//
// This provides a bit of syntactic sugar to make using sub-ranges
// in for loops a bit easier. Analogous to std::make_pair().

  // namespace gtl
  // namespace tensorflow

// #endif  // TENSORFLOW_LIB_GTL_ITERATOR_RANGE_H_


// Parsed from tensorflow/core/framework/function.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_FUNCTION_H_
// #define TENSORFLOW_CORE_FRAMEWORK_FUNCTION_H_

// #include <vector>
// #include "tensorflow/core/framework/attr_value.pb.h"
// #include "tensorflow/core/framework/attr_value_util.h"
// #include "tensorflow/core/framework/function.pb.h"
// #include "tensorflow/core/framework/node_def_util.h"
// #include "tensorflow/core/framework/op.h"
// #include "tensorflow/core/framework/selective_registration.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/flatmap.h"
// #include "tensorflow/core/lib/hash/hash.h"
// #include "tensorflow/core/platform/env.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/mutex.h"
// #include "tensorflow/core/platform/protobuf.h"
// Targeting ../CancellationManager.java


// Targeting ../Rendezvous.java


// Targeting ../FunctionDefHelper.java









// Instantiate a function.
//
// "fdef" encodes a TF function with some attrs in fdef.signature.attr
// containing placeholders.  InstantiateFunction binds these
// placeholders and produces an instantiated function encoded in
// "result.gdef". The value to substitute a placeholder is given by
// "attr_values", which is a map from a placeholder name to an attr
// value.
//
// InstantiateFunction calls "get_function" to find signatures of other
// functions and primitive ops.

// GetFunctionSignature(func name, opdef) returns OK if the func name is found
// and opdef is filled with a pointer to the corresponding signature
// (a OpDef proto). Otherwise, returns an error.
// Targeting ../InstantiationResult.java


@Namespace("tensorflow") public static native @ByVal Status InstantiateFunction(@Const @ByRef FunctionDef fdef, @ByVal AttrSlice attr_values,
                           @ByVal @Cast("tensorflow::GetFunctionSignature*") Pointer get_function,
                           InstantiationResult result);

// Returns a debug string for a function definition.
//
// The returned text is multiple-line. It is intended to be
// human-readable rather than being friendly to parsers. It is _NOT_
// intended to be the canonical string representation of "func_def".
// Particularly, it may not include all information presented in
// "func_def" (e.g., comments, description of the function arguments,
// etc.)
@Namespace("tensorflow") public static native @StdString BytePointer DebugString(@Const @ByRef FunctionDef func_def);
@Namespace("tensorflow") public static native @StdString BytePointer DebugString(@Const @ByRef GraphDef instantiated_func_def);
@Namespace("tensorflow") public static native @StdString BytePointer DebugString(@ArraySlice NodeDef instantiated_func_nodes);

// Returns a debug string for a top level graph (the main program and
// its supporting functions defined in its library).
@Namespace("tensorflow") public static native @StdString BytePointer DebugStringWhole(@Const @ByRef GraphDef gdef);

// Returns true if f1 == f2. Compares all fields, including descriptions. Order
// of NodeDefs doesn't matter.
@Namespace("tensorflow") public static native @Cast("bool") boolean FunctionDefsEqual(@Const @ByRef FunctionDef f1, @Const @ByRef FunctionDef f2);

// Return a hash of `fdef` that is consistent with FunctionDefsEqual method.
// In other words, if two fdefs compare equal, their hash values will be the
// same.
@Namespace("tensorflow") public static native @Cast("tensorflow::uint64") long FunctionDefHash(@Const @ByRef FunctionDef fdef);
// Targeting ../CallFrameInterface.java


// Targeting ../FunctionCallFrame.java


// Targeting ../FunctionLibraryDefinition.java


// Targeting ../FunctionBody.java



// Forward declare. Defined in common_runtime/device.h
// Targeting ../FunctionLibraryRuntime.java



// Returns a canonicalized string for the instantiation of the
// function of the given "name", attributes "attrs", and "options".
//
// The returned string is guaranteed to be stable within one address
// space. But it may be change as the implementation
// evolves. Therefore, it should not be persisted or compared across
// address spaces.
@Namespace("tensorflow") public static native @StdString BytePointer Canonicalize(@StdString BytePointer funcname, @ByVal AttrSlice attrs,
                    @Const @ByRef FunctionLibraryRuntime.InstantiateOptions options);
@Namespace("tensorflow") public static native @StdString String Canonicalize(@StdString String funcname, @ByVal AttrSlice attrs,
                    @Const @ByRef FunctionLibraryRuntime.InstantiateOptions options);
@Namespace("tensorflow") public static native @StdString BytePointer Canonicalize(@StdString BytePointer funcname, @ByVal AttrSlice attrs);
@Namespace("tensorflow") public static native @StdString String Canonicalize(@StdString String funcname, @ByVal AttrSlice attrs);

@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::FunctionLibraryRuntime::Handle") long kInvalidHandle();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::FunctionLibraryRuntime::LocalHandle") long kInvalidLocalHandle();
// Targeting ../DistributedFunctionLibraryRuntime.java



// Extracts the actual type from "attr_values" based on its definition
// "arg_def".
//
// If "arg_def" is a N*T type, *is_type_list is set to false, and
// *dtypes is set to be a vector of size N and each element is T.
//
// If "arg_def" is a list(type), *is_type_list is set to true, and
// *dtypes is set to be a vector of types specified in attrs for
// arg_def.
//
// Otherwise (arg_def is a simple type T), *is_type_list is set to
// false, and *dtypes is set to a single element vector, whose only
// element is T.
@Namespace("tensorflow") public static native @ByVal Status ArgNumType(@ByVal AttrSlice attrs, @Cast("const tensorflow::OpDef::ArgDef*") @ByRef OpDef_ArgDef arg_def,
                  @Cast("bool*") BoolPointer is_type_list, DataTypeVector dtypes);
@Namespace("tensorflow") public static native @ByVal Status ArgNumType(@ByVal AttrSlice attrs, @Cast("const tensorflow::OpDef::ArgDef*") @ByRef OpDef_ArgDef arg_def,
                  @Cast("bool*") boolean[] is_type_list, DataTypeVector dtypes);

// To register a gradient function for a builtin op, one should use
//   REGISTER_OP_GRADIENT(<op_name>, <c++ grad factory>);
//
// Typically, the c++ grad factory is a plan function that can be
// converted into ::tensorflow::gradient::Creator, which is
//   std::function<Status(const AttrSlice&, FunctionDef*)>.
//
// A ::tensorflow::gradient::Creator should populate in FunctionDef* with a
// definition of a brain function which compute the gradient for the
// <op_name> when the <op_name> is instantiated with the given attrs.
//
// E.g.,
//
// Status MatMulGrad(const AttrSlice& attrs, FunctionDef* g) {
//   bool transpose_a;
//   TF_RETURN_IF_ERROR(attrs.Get("transpose_a", &transpose_a));
//   bool transpose_b;
//   TF_RETURN_IF_ERROR(attrs.Get("transpose_b", &transpose_b));
//   DataType dtype;
//   TF_RETURN_IF_ERROR(attrs.Get("dtype", &dtype));
//   if (!transpose_a && !transpose_b) {
//     *g = FunctionDefHelper::Define(
//       "MatMulGrad",
//       {"x:T ", "y:T", "dz:T"},    // Inputs to this function
//       {"dx:T", "dy:T"},           // Outputs from this function
//       {"T: {float, double}"},     // Attributes needed by this function
//       {
//         {{"x_t"}, "Transpose", {"x"}, {{"T", "$T"}}},
//         {{"y_t"}, "Transpose", {"y"}, {{"T", "$T"}}},
//         {{"dx"}, "MatMul", {"dz", "y_t"}, {{"T", "$T"}}},
//         {{"dy"}, "MatMul", {"x_", "dz"}, {{"T", "$T"}}},
//       });
//   } else {
//     ... ...
//   }
//   return Status::OK();
// }
//
// NOTE: $T is substituted with the type variable "T" when the
// gradient function MatMul is instantiated.
//
// TODO(zhifengc): Better documentation somewhere.

// Macros to define a gradient function factory for a primitive
// operation.
// #define REGISTER_OP_GRADIENT(name, fn)
//   REGISTER_OP_GRADIENT_UNIQ_HELPER(__COUNTER__, name, fn)

// #define REGISTER_OP_NO_GRADIENT(name)
//   REGISTER_OP_GRADIENT_UNIQ_HELPER(__COUNTER__, name, nullptr)

// #define REGISTER_OP_GRADIENT_UNIQ_HELPER(ctr, name, fn)
//   REGISTER_OP_GRADIENT_UNIQ(ctr, name, fn)

// #define REGISTER_OP_GRADIENT_UNIQ(ctr, name, fn)
//   static bool unused_grad_##ctr TF_ATTRIBUTE_UNUSED =
//       SHOULD_REGISTER_OP_GRADIENT &&
//       ::tensorflow::gradient::RegisterOp(name, fn)
// Register a gradient creator for the "op".
@Namespace("tensorflow::gradient") public static native @Cast("bool") boolean RegisterOp(@StdString BytePointer op, @ByVal @Cast("tensorflow::gradient::Creator*") Pointer func);
@Namespace("tensorflow::gradient") public static native @Cast("bool") boolean RegisterOp(@StdString String op, @ByVal @Cast("tensorflow::gradient::Creator*") Pointer func);

// Returns OK the gradient creator for the "op" is found (may be
// nullptr if REGISTER_OP_NO_GRADIENT is used.
@Namespace("tensorflow::gradient") public static native @ByVal Status GetOpGradientCreator(@StdString BytePointer op, @Cast("tensorflow::gradient::Creator*") Pointer creator);
@Namespace("tensorflow::gradient") public static native @ByVal Status GetOpGradientCreator(@StdString String op, @Cast("tensorflow::gradient::Creator*") Pointer creator);
  // namespace gradient

// Declare explicit instantiations of GetAttr
// #define GET_ATTR(T)
//   extern template Status FunctionLibraryDefinition::GetAttr(
//       const Node&, const string&, T*) const;
//   extern template Status FunctionLibraryDefinition::GetAttr(
//       const NodeDef&, const string&, T*) const;

  

  
// #undef GET_ATTR

  // end namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_FUNCTION_H_


// Parsed from tensorflow/core/util/device_name_utils.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_UTIL_DEVICE_NAME_UTILS_H_
// #define TENSORFLOW_CORE_UTIL_DEVICE_NAME_UTILS_H_

// #include <string>

// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// Targeting ../DeviceNameUtils.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_UTIL_DEVICE_NAME_UTILS_H_


// Parsed from tensorflow/core/framework/device_base.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_DEVICE_BASE_H_
// #define TENSORFLOW_CORE_FRAMEWORK_DEVICE_BASE_H_

// #include <memory>
// #include <string>
// #include <vector>

// #include "absl/base/macros.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/lib/core/errors.h"
// #include "tensorflow/core/lib/core/refcount.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/platform/logging.h"
// #ifdef TENSORFLOW_USE_SYCL
// #endif

// Targeting ../Stream.java



// Targeting ../EventMgr.java


// Targeting ../ScopedAllocatorMgr.java



// Targeting ../PerOpGpuDevice.java


// Targeting ../DeviceContext.java



// map[i] is the DeviceContext* for the node with id i, if i < map.size().
// Targeting ../DeviceBase.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_DEVICE_BASE_H_


// Parsed from tensorflow/core/common_runtime/device.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// A Device is a something that can perform computations as part of a
// model.  Devices can be local (runs computation on this machine), or
// remote (contacts a device local to another machine using an RPC to
// do the work).  Devices are registered in a DeviceSet, which is also
// responsible for the Device <-> id mapping.
//
// Device names
// * Every Device should have a unique name with the format:
//     /job:___/replica:___/task:___/(gpu|cpu):___
//   An example name would be "/job:train/replica:0/task:3/device:GPU:2".
// * Task numbers are within the specified replica, so there are as
//   many "task zeros" as replicas.

// #ifndef TENSORFLOW_CORE_COMMON_RUNTIME_DEVICE_H_
// #define TENSORFLOW_CORE_COMMON_RUNTIME_DEVICE_H_

// #include <memory>
// #include <string>

// #include "tensorflow/core/framework/allocator.h"
// #include "tensorflow/core/framework/control_flow.h"
// #include "tensorflow/core/framework/device_attributes.pb_text.h"
// #include "tensorflow/core/framework/device_attributes.pb.h"
// #include "tensorflow/core/framework/device_base.h"
// #include "tensorflow/core/framework/graph.pb.h"
// #include "tensorflow/core/framework/op_kernel.h"
// #include "tensorflow/core/framework/op_segment.h"
// #include "tensorflow/core/framework/resource_mgr.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/graph/graph.h"
// #include "tensorflow/core/graph/types.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/types.h"
// #include "tensorflow/core/util/device_name_utils.h"
// Targeting ../Device.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_COMMON_RUNTIME_DEVICE_H_


// Parsed from tensorflow/core/common_runtime/device_mgr.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_COMMON_RUNTIME_DEVICE_MGR_H_
// #define TENSORFLOW_CORE_COMMON_RUNTIME_DEVICE_MGR_H_

// #include <memory>
// #include <string>
// #include <unordered_map>
// #include <unordered_set>
// #include <vector>

// #include "tensorflow/core/common_runtime/device.h"
// #include "tensorflow/core/lib/core/arena.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/lib/gtl/inlined_vector.h"
// #include "tensorflow/core/platform/macros.h"
// Targeting ../DeviceMgr.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_COMMON_RUNTIME_DEVICE_MGR_H_


// Parsed from tensorflow/core/common_runtime/process_function_library_runtime.h

/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
// #ifndef TENSORFLOW_CORE_COMMON_RUNTIME_PROCESS_FUNCTION_LIBRARY_RUNTIME_H_
// #define TENSORFLOW_CORE_COMMON_RUNTIME_PROCESS_FUNCTION_LIBRARY_RUNTIME_H_

// #include <unordered_map>

// #include "tensorflow/core/common_runtime/device_mgr.h"
// #include "tensorflow/core/framework/function.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/protobuf/config.pb.h"
// Targeting ../ProcessFunctionLibraryRuntime.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_COMMON_RUNTIME_PROCESS_FUNCTION_LIBRARY_RUNTIME_H_


// Parsed from tensorflow/core/graph/graph.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// A Graph describes a set of computations that are to be
// performed, as well as the dependencies between those
// computations. The basic model is a DAG (directed acyclic graph) with
// * internal nodes representing computational operations to be performed;
// * edges represent dependencies, indicating the target may only be
//   executed once the source has completed; and
// * predefined "source" (start) and "sink" (finish) nodes -- the source
//   should be the only node that doesn't depend on anything, and the sink
//   should be the only node that nothing depends on.
//
// Note: Node ids are intended to be relatively dense in the
// 0..max_id range, but there may be gaps since ids won't be reused.
//
// Note: Some dependencies between operations are due to one operation
// consuming the output of another. In fact operations can produce
// multiple outputs and consume multiple inputs, and some
// optimizations will care about which specific outputs are connected
// to which specific inputs.  We therefore represent data dependency
// between output O of layer A and input I of layer B using
// "input index" and "output index" labels per edge.

// #ifndef TENSORFLOW_CORE_GRAPH_GRAPH_H_
// #define TENSORFLOW_CORE_GRAPH_GRAPH_H_

// #include <functional>
// #include <string>
// #include <vector>
// #include "tensorflow/core/framework/function.h"
// #include "tensorflow/core/framework/op.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/graph/edgeset.h"
// #include "tensorflow/core/lib/core/arena.h"
// #include "tensorflow/core/lib/core/refcount.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/gtl/iterator_range.h"
// #include "tensorflow/core/platform/logging.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/types.h"
// Targeting ../EdgeSetTest.java


// Targeting ../WhileContext.java

    // Declared below
// Targeting ../NodeProperties.java


// Targeting ../Node.java


// Targeting ../NodeDebugInfo.java


// Targeting ../InputTensor.java


// Targeting ../OutputTensor.java


// Targeting ../Edge.java


// Targeting ../GraphEdgesIterable.java


// Targeting ../Graph.java



// TODO(josh11b): We may want to support keeping an index on various
// node/edge attributes in a graph, particularly node names.

// Helper routines

@Namespace("tensorflow") public static native @Cast("bool") boolean IsSource(@Const Node node);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsSink(@Const Node node);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsSwitch(@Const Node node);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsMerge(@Const Node node);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsEnter(@Const Node node);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsExit(@Const Node node);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsNextIteration(@Const Node n);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsLoopCond(@Const Node node);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsControlTrigger(@Const Node n);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsSend(@Const Node node);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsRecv(@Const Node node);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsHostSend(@Const Node node);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsHostRecv(@Const Node node);

// True for Nodes that mediate the transfer of values between processes.
@Namespace("tensorflow") public static native @Cast("bool") boolean IsTransferNode(@Const Node n);

@Namespace("tensorflow") public static native @Cast("bool") boolean IsConstant(@Const Node node);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsVariable(@Const Node node);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsIdentity(@Const Node node);

// Returns true iff 'n' is a control flow node.
@Namespace("tensorflow") public static native @Cast("bool") boolean IsControlFlow(@Const Node n);

// Returns true if the node only depends on its input's metadata
// (shape).  Specifically, returns true for "Size", "Shape" and "Rank" ops.
@Namespace("tensorflow") public static native @Cast("bool") boolean IsMetadata(@Const Node n);

@Namespace("tensorflow") public static native @Cast("bool") boolean IsScopedAllocator(@Const Node n);

@Namespace("tensorflow") public static native @Cast("bool") boolean IsHostMemoryPreserving(@Const Node node);
// Targeting ../NodeIter.java


// Targeting ../NeighborIter.java



// IMPLEMENTATION DETAILS, PLEASE IGNORE





































  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_GRAPH_GRAPH_H_


// Parsed from tensorflow/core/graph/tensor_id.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_GRAPH_TENSOR_ID_H_
// #define TENSORFLOW_GRAPH_TENSOR_ID_H_

// #include <string>

// #include "tensorflow/core/graph/graph.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/lib/hash/hash.h"
// #include "tensorflow/core/lib/strings/strcat.h"
// Targeting ../TensorId.java



@Namespace("tensorflow") public static native @ByVal TensorId ParseTensorName(@StdString BytePointer name);
@Namespace("tensorflow") public static native @ByVal TensorId ParseTensorName(@StdString String name);
// Targeting ../SafeTensorId.java



  // namespace tensorflow

// #endif  // TENSORFLOW_GRAPH_TENSOR_ID_H_


// Parsed from tensorflow/core/common_runtime/graph_runner.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_COMMON_RUNTIME_GRAPH_RUNNER_H_
// #define TENSORFLOW_CORE_COMMON_RUNTIME_GRAPH_RUNNER_H_

// #include <memory>
// #include <string>
// #include <vector>

// #include "tensorflow/core/common_runtime/device.h"
// #include "tensorflow/core/framework/function.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/graph/graph.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/platform/env.h"
// Targeting ../GraphRunner.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_COMMON_RUNTIME_GRAPH_RUNNER_H_


// Parsed from tensorflow/core/common_runtime/shape_refiner.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
// #ifndef TENSORFLOW_CORE_COMMON_RUNTIME_SHAPE_REFINER_H_
// #define TENSORFLOW_CORE_COMMON_RUNTIME_SHAPE_REFINER_H_

// #include <vector>

// #include "tensorflow/core/common_runtime/graph_runner.h"
// #include "tensorflow/core/framework/function.pb.h"
// #include "tensorflow/core/framework/shape_inference.h"
// #include "tensorflow/core/graph/graph.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/platform/macros.h"


// This class stores extra inference information in addition to
// InferenceContext, such as inference tree for user-defined functions and node
// input and output types.
// Targeting ../ShapeRefiner.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_COMMON_RUNTIME_SHAPE_REFINER_H_


// Parsed from tensorflow/core/framework/node_def_builder.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_NODE_DEF_BUILDER_H_
// #define TENSORFLOW_CORE_FRAMEWORK_NODE_DEF_BUILDER_H_

// #include <functional>
// #include <vector>
// #include "tensorflow/core/framework/attr_value_util.h"
// #include "tensorflow/core/framework/node_def.pb.h"
// #include "tensorflow/core/framework/node_def_util.h"
// #include "tensorflow/core/framework/op.h"
// #include "tensorflow/core/framework/op_def.pb.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/graph/graph.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// #include "tensorflow/core/lib/strings/strcat.h"
// Targeting ../NodeDefBuilder.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_NODE_DEF_BUILDER_H_


// Parsed from tensorflow/core/framework/node_def_util.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_NODE_DEF_UTIL_H_
// #define TENSORFLOW_CORE_FRAMEWORK_NODE_DEF_UTIL_H_

// #include <string>
// #include <vector>

// #include "tensorflow/core/framework/attr_value_util.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/lib/gtl/flatmap.h"
// #include "tensorflow/core/lib/hash/hash.h"
// #include "tensorflow/core/platform/protobuf.h"

// We forward declare protos so that kernels don't need to depend on them

// Name of the attribute used to encode node colocation constraints.
//
// Nodes can be co-located on the same device. Desire for explicit co-location
// is described by list(string) attribute containing the name of colocation
// groups.
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer kColocationAttrName();

// String prefix applied to the operation name for colocation constraints.
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer kColocationGroupPrefix();

// Produce a human-readable version of a Node or NodeDef that is more concise
// than a text-format proto.
@Namespace("tensorflow") public static native @StdString BytePointer SummarizeNode(@Const @ByRef Node node);
@Namespace("tensorflow") public static native @StdString BytePointer SummarizeNodeDef(@Const @ByRef NodeDef node_def);
@Namespace("tensorflow") public static native @StdString BytePointer SummarizeAttrs(@Const @ByRef NodeDef node_def);

// Produces a formatted string pattern from the node which can uniquely identify
// this node upstream to produce an informative error message. The pattern
// followed is: {{node <node_name>}}
@Namespace("tensorflow") public static native @StdString BytePointer FormatNodeForError(@Const @ByRef Node node);
@Namespace("tensorflow") public static native @StdString BytePointer FormatNodeDefForError(@Const @ByRef NodeDef node_def);

// Merges the original node names from the debug information of 'from' to the
// debug information of 'to'.
@Namespace("tensorflow") public static native void MergeDebugInfo(@Const @ByRef NodeDebugInfo from, Node to);
@Namespace("tensorflow") public static native void MergeDebugInfo(@Const @ByRef NodeDebugInfo from, NodeDef to);
@Namespace("tensorflow") public static native void MergeDebugInfo(@Const @ByRef NodeDef from, NodeDef to);

// Adds an attr with name <name> and value <value> to *node_def.
// The type of the attr is based on the type of value.
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @Const @ByRef AttrValue value, NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @Const @ByRef AttrValue value, NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @StringPiece BytePointer value, NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @StringPiece String value, NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, int value, NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, int value, NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @Cast("tensorflow::int64") long value, NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @Cast("tensorflow::int64") long value, NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, float value, NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, float value, NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, double value, NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, double value, NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @Cast("bool") boolean value, NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @Cast("bool") boolean value, NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @Const @ByRef PartialTensorShape value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @Const @ByRef PartialTensorShape value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @Const @ByRef Tensor value, NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @Const @ByRef Tensor value, NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @Const @ByRef TensorProto value, NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @Const @ByRef TensorProto value, NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @Const @ByRef NameAttrList value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @Const @ByRef NameAttrList value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @ByVal @Cast("tensorflow::gtl::ArraySlice<tensorflow::StringPiece>*") StringPieceVector value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @ByVal @Cast("tensorflow::gtl::ArraySlice<tensorflow::StringPiece>*") StringPieceVector value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @Cast("const char**") @ArraySlice PointerPointer value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @Cast("const char**") @ArraySlice @ByPtrPtr ByteBuffer value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @Cast("const char**") @ArraySlice @ByPtrPtr byte[] value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @Cast("const char**") @ArraySlice @ByPtrPtr BytePointer value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @Cast("const char**") @ArraySlice @ByPtrPtr ByteBuffer value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @Cast("const char**") @ArraySlice @ByPtrPtr byte[] value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @ByVal @Cast("tensorflow::gtl::ArraySlice<tensorflow::string>*") StringVector value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @ByVal @Cast("tensorflow::gtl::ArraySlice<tensorflow::string>*") StringVector value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @ArraySlice IntPointer value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @ArraySlice IntBuffer value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @ArraySlice int[] value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @ArraySlice IntPointer value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @ArraySlice IntBuffer value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @ArraySlice int[] value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @Cast("tensorflow::int64*") @ArraySlice LongPointer value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @Cast("tensorflow::int64*") @ArraySlice LongBuffer value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @Cast("tensorflow::int64*") @ArraySlice long[] value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @Cast("tensorflow::int64*") @ArraySlice LongPointer value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @Cast("tensorflow::int64*") @ArraySlice LongBuffer value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @Cast("tensorflow::int64*") @ArraySlice long[] value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @ArraySlice FloatPointer value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @ArraySlice FloatBuffer value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @ArraySlice float[] value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @ArraySlice FloatPointer value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @ArraySlice FloatBuffer value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @ArraySlice float[] value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @Cast("bool*") @ArraySlice BoolPointer value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @Cast("bool*") @ArraySlice boolean[] value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @ByVal @Cast("tensorflow::gtl::ArraySlice<tensorflow::TensorShape>*") TensorShapeVector value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @ByVal @Cast("tensorflow::gtl::ArraySlice<tensorflow::TensorShape>*") TensorShapeVector value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @ArraySlice TensorShapeProto value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @ArraySlice TensorShapeProto value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece BytePointer name, @ByVal TensorVector value,
                 NodeDef node_def);
@Namespace("tensorflow") public static native void AddNodeAttr(@StringPiece String name, @ByVal TensorVector value,
                 NodeDef node_def);

// Version to workaround C++'s "perfect" forwarding not being able to
// forward {...} initialization.

// Adds an attr to an attr value map.
@Namespace("tensorflow") public static native void AddAttr(@StringPiece BytePointer name, @Const @ByRef AttrValue value, @Cast("tensorflow::AttrValueMap*") StringAttrValueMap map);
@Namespace("tensorflow") public static native void AddAttr(@StringPiece String name, @Const @ByRef AttrValue value, @Cast("tensorflow::AttrValueMap*") StringAttrValueMap map);
@Namespace("tensorflow") public static native void AddAttr(@StringPiece BytePointer name, @Cast("bool") boolean value, @Cast("tensorflow::AttrValueMap*") StringAttrValueMap map);
@Namespace("tensorflow") public static native void AddAttr(@StringPiece String name, @Cast("bool") boolean value, @Cast("tensorflow::AttrValueMap*") StringAttrValueMap map);
// Targeting ../AttrSlice.java



// Return true if the attr with the name attr_name is defined in node_def.
@Namespace("tensorflow") public static native @Cast("bool") boolean HasNodeAttr(@Const @ByRef NodeDef node_def, @StringPiece BytePointer attr_name);
@Namespace("tensorflow") public static native @Cast("bool") boolean HasNodeAttr(@Const @ByRef NodeDef node_def, @StringPiece String attr_name);

// Look up the attr with name attr_name and set *value to its value.  If no
// attr with attr_name is found in node_def, or the attr does not have
// a matching type, a non-ok status will be returned.
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   @StdString @Cast({"char*", "std::string*"}) BytePointer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   @StdString @Cast({"char*", "std::string*"}) BytePointer value);  // type: "string"
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   @Cast("tensorflow::int64*") LongPointer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   @Cast("tensorflow::int64*") LongBuffer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   @Cast("tensorflow::int64*") long... value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   @Cast("tensorflow::int64*") LongPointer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   @Cast("tensorflow::int64*") LongBuffer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   @Cast("tensorflow::int64*") long... value);  // type: "int"
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   IntPointer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   IntBuffer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   int... value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   IntPointer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   IntBuffer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   int... value);  // type: "int"
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   FloatPointer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   FloatBuffer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   float... value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   FloatPointer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   FloatBuffer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   float... value);  // type: "float"
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   @Cast("bool*") BoolPointer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   @Cast("bool*") boolean... value);  // type: "bool"  // type: "type"
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   TensorShapeProto value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   TensorShapeProto value);  // type: "shape"
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   TensorShape value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   TensorShape value);  // type: "shape"
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   PartialTensorShape value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   PartialTensorShape value);  // type: "shape"
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   Tensor value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   Tensor value);  // type: "tensor"
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   StringVector value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   StringVector value);  // type "list(string)"  // type "list(int)"  // type "list(int)"  // type "list(float)"  // type "list(bool)"  // type "list(type)"
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   DataTypeVector value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   DataTypeVector value);  // type "list(type)"  // type "list(shape)"
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   TensorShapeVector value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   TensorShapeVector value);  // type "list(shape)"  // type "list(shape)"
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   TensorVector value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   TensorVector value);  // type: "list(tensor)"

// This version avoids copying the TensorProto.
// REQUIRES: Must not use *value beyond the lifetime of node_def.
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   @Cast("const tensorflow::TensorProto**") PointerPointer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   @Const @ByPtrPtr TensorProto value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   @Const @ByPtrPtr TensorProto value);  // type: "tensor"

// This version avoids copying the NameAttrList.
// REQUIRES: Must not use *value beyond the lifetime of node_def.
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   @Const @ByPtrPtr NameAttrList value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   @Const @ByPtrPtr NameAttrList value);  // type: "func"

// These versions copies the NameAttrList(s).  // type: "func"  // type: "list(func)"

// Look up the attr with name attr_name and set *value to its value.  If no
// attr with attr_name is found in node_def, or the attr does not have
// a matching type, false is returned.
@Namespace("tensorflow") public static native @Cast("bool") boolean GetNodeAttrSimple(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                       @StdString @Cast({"char*", "std::string*"}) BytePointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean GetNodeAttrSimple(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                       @StdString @Cast({"char*", "std::string*"}) BytePointer value);  // type: "string"
@Namespace("tensorflow") public static native @Cast("bool") boolean GetNodeAttrSimple(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                       StringVector value);
@Namespace("tensorflow") public static native @Cast("bool") boolean GetNodeAttrSimple(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                       StringVector value);  // type: "string"

// Look up the attr with name attr_name and return a reference to its value.
// If no attr with attr_name is found in node_def, or the attr does not have
// a matching type, a reference to an empty string is returned.
// REQUIRES: Must not use the returned value beyond the lifetime of node_def.
@Namespace("tensorflow") public static native @StdString BytePointer GetNodeAttrString(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name);
@Namespace("tensorflow") public static native @StdString String GetNodeAttrString(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name);

// Computes the input type for a specific node input.
// REQUIRES: ValidateOpDef(op_def).ok()
@Namespace("tensorflow") public static native @ByVal Status InputTypeForNode(@Const @ByRef NodeDef node_def, @Const @ByRef OpDef op_def,
                        int input_port, @Cast("tensorflow::DataType*") IntPointer input_type);
// Computes the input types for a specific node.
// REQUIRES: ValidateOpDef(op_def).ok()
@Namespace("tensorflow") public static native @ByVal Status InputTypesForNode(@Const @ByRef NodeDef node_def, @Const @ByRef OpDef op_def,
                         DataTypeVector inputs);
// Computes the output type for a specific node output.
// REQUIRES: ValidateOpDef(op_def).ok()
@Namespace("tensorflow") public static native @ByVal Status OutputTypeForNode(@Const @ByRef NodeDef node_def, @Const @ByRef OpDef op_def,
                         int output_port, @Cast("tensorflow::DataType*") IntPointer output_type);
// Computes the output types for a specific node.
// REQUIRES: ValidateOpDef(op_def).ok()
@Namespace("tensorflow") public static native @ByVal Status OutputTypesForNode(@Const @ByRef NodeDef node_def, @Const @ByRef OpDef op_def,
                          DataTypeVector outputs);
// Computes the input and output types for a specific node.
// REQUIRES: ValidateOpDef(op_def).ok()
@Namespace("tensorflow") public static native @ByVal Status InOutTypesForNode(@Const @ByRef NodeDef node_def, @Const @ByRef OpDef op_def,
                         DataTypeVector inputs, DataTypeVector outputs);
// Computes the number of outputs for a specific node.
// REQUIRES: ValidateOpDef(op_def).ok()
@Namespace("tensorflow") public static native @ByVal Status NumOutputsForNode(@Const @ByRef NodeDef node_def, @Const @ByRef OpDef op_def,
                         IntPointer num_outputs);
@Namespace("tensorflow") public static native @ByVal Status NumOutputsForNode(@Const @ByRef NodeDef node_def, @Const @ByRef OpDef op_def,
                         IntBuffer num_outputs);
@Namespace("tensorflow") public static native @ByVal Status NumOutputsForNode(@Const @ByRef NodeDef node_def, @Const @ByRef OpDef op_def,
                         int... num_outputs);

// Validates that the NodeDef:
// * Defines all expected attrs from the OpDef.
// * All attrs satisfies constraints from the OpDef.
// * Has a signature matching SignatureForNode().
// etc.
@Namespace("tensorflow") public static native @ByVal Status ValidateNodeDef(@Const @ByRef NodeDef node_def, @Const @ByRef OpDef op_def);

// Computes the mapping from input/output argument name to the
// corresponding input/output index range.  For example,
// input "foo" corresponds to input indices
//   [ (*inputs)["foo"].first, (*inputs)["foo"].second ).
// NOTE(mrry): To reduce allocations when the map is used and save
// space, the returned `NameRangeMap` objects borrow the input/output
// argument names from `op_def`. The `op_def` must outlive the
// returned `NameRangeMap` objects.
@Namespace("tensorflow") public static native @ByVal Status NameRangesForNode(@Const @ByRef NodeDef node_def, @Const @ByRef OpDef op_def,
                         NameRangeMap inputs, NameRangeMap outputs);
@Namespace("tensorflow") public static native @ByVal Status NameRangesForNode(@Const @ByRef Node node, @Const @ByRef OpDef op_def,
                         NameRangeMap inputs, NameRangeMap outputs);

// Adds default values to *node_def for unspecified attrs from op_def.
@Namespace("tensorflow") public static native void AddDefaultsToNodeDef(@Const @ByRef OpDef op_def, NodeDef node_def);

// Validates the syntax of a NodeDef provided externally.
//
// The following is an EBNF-style syntax for NodeDef objects. Note that
// Node objects are actually specified as tensorflow::NodeDef protocol buffers,
// which contain many other fields that are not (currently) validated.
//
// Node         = NodeName, Inputs
// Inputs       = ( DataInput * ), ( ControlInput * )
// DataInput    = NodeName, ( ":", [1-9], [0-9] * ) ?
// ControlInput = "^", NodeName
// NodeName     = [A-Za-z0-9.], [A-Za-z0-9_./] *
@Namespace("tensorflow") public static native @ByVal Status ValidateExternalNodeDefSyntax(@Const @ByRef NodeDef node_def);

// Returns "status" with kernel's NodeDef attached as additional text
// in the error message.
@Namespace("tensorflow") public static native @ByVal Status AttachDef(@Const @ByRef Status status, @Const @ByRef NodeDef node_def);
@Namespace("tensorflow") public static native @ByVal Status AttachDef(@Const @ByRef Status status, @Const @ByRef Node node);

// Appends the given prefix and suffix to the original node name in order to
// make the name unique. If it's an "Enter" node, use the same way to reset
// attribute "frame_name".
@Namespace("tensorflow") public static native @ByVal Status AddPrefixAndSuffixToNode(@StringPiece BytePointer prefix, @StringPiece BytePointer suffix,
                                NodeDef node_def);
@Namespace("tensorflow") public static native @ByVal Status AddPrefixAndSuffixToNode(@StringPiece String prefix, @StringPiece String suffix,
                                NodeDef node_def);
  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_NODE_DEF_UTIL_H_


// Parsed from tensorflow/core/framework/selective_registration.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_SELECTIVE_REGISTRATION_H_
// #define TENSORFLOW_CORE_FRAMEWORK_SELECTIVE_REGISTRATION_H_

// #include <string.h>

// #ifdef SELECTIVE_REGISTRATION

// Experimental selective registration support to reduce binary size.
//
// To use selective registration, when building:
// 1. define SELECTIVE_REGISTRATION, e.g. in gcc by passing
//    -DSELECTIVE_REGISTRATION to compilation.
// 2. Provide ops_to_register.h. This file is not included in the repo and must
//    be placed by the user or a tool where the compiler can find it.  It must
//    define the constants and functions used in the macros below. The
//    functions should be defined as valid constexpr functions, so that they are
//    evaluated at compile time: this is needed to make symbols referenced by
//    un-registered objects unused, and therefore allow the linker to strip them
//    out.  See python/tools/print_selective_registration_header.py for a tool
//    that can be used to generate ops_to_register.h.
//
// ops_to_register.h should define macros for:
//   // Ops for which this is false will not be registered.
//   SHOULD_REGISTER_OP(op)
//   // If this is false, then no gradient ops are registered.
//   SHOULD_REGISTER_OP_GRADIENT
//   // Op kernel classes where this is false won't be registered.
//   SHOULD_REGISTER_OP_KERNEL(clz)
// The macros should be defined using constexprs.

// #include "ops_to_register.h"

// #if (!defined(SHOULD_REGISTER_OP) || !defined(SHOULD_REGISTER_OP_GRADIENT) ||
//      !defined(SHOULD_REGISTER_OP_KERNEL))
// #endif
// #else
// #define SHOULD_REGISTER_OP(op) true
// #define SHOULD_REGISTER_OP_GRADIENT true
// #define SHOULD_REGISTER_OP_KERNEL(clz) true
// #endif

// #endif  // TENSORFLOW_CORE_FRAMEWORK_SELECTIVE_REGISTRATION_H_


// Parsed from tensorflow/core/graph/node_builder.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_GRAPH_NODE_BUILDER_H_
// #define TENSORFLOW_CORE_GRAPH_NODE_BUILDER_H_

// #include <vector>
// #include "tensorflow/core/framework/node_def_builder.h"
// #include "tensorflow/core/framework/op.h"
// #include "tensorflow/core/framework/op_def.pb.h"
// #include "tensorflow/core/graph/graph.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../NodeBuilder.java



// IMPLEMENTATION -------------------------------------------------------------





  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_GRAPH_NODE_BUILDER_H_


// Parsed from tensorflow/core/graph/graph_def_builder.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_GRAPH_GRAPH_DEF_BUILDER_H_
// #define TENSORFLOW_CORE_GRAPH_GRAPH_DEF_BUILDER_H_

// #include <vector>
// #include "tensorflow/core/framework/graph.pb.h"
// #include "tensorflow/core/framework/op.h"
// #include "tensorflow/core/graph/graph.h"
// #include "tensorflow/core/graph/node_builder.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../GraphDefBuilder.java



// A NodeOut may either be a regular input or back input.  Regular
// inputs are specified via either a Node* or a Node* and an output
// index.  Back inputs are specified by a node name, output index, and
// output type.

// For adding an Op with no inputs to a GraphDefBuilder.
@Namespace("tensorflow::ops") public static native Node SourceOp(@StdString BytePointer op_name, @Const @ByRef GraphDefBuilder.Options opts);
@Namespace("tensorflow::ops") public static native Node SourceOp(@StdString String op_name, @Const @ByRef GraphDefBuilder.Options opts);

// For adding an Op with one input to a GraphDefBuilder.
@Namespace("tensorflow::ops") public static native Node UnaryOp(@StdString BytePointer op_name, @ByVal NodeBuilder.NodeOut input,
              @Const @ByRef GraphDefBuilder.Options opts);
@Namespace("tensorflow::ops") public static native Node UnaryOp(@StdString String op_name, Node input,
              @Const @ByRef GraphDefBuilder.Options opts);

// For adding an Op with two inputs to a GraphDefBuilder.
@Namespace("tensorflow::ops") public static native Node BinaryOp(@StdString BytePointer op_name, @ByVal NodeBuilder.NodeOut a, @ByVal NodeBuilder.NodeOut b,
               @Const @ByRef GraphDefBuilder.Options opts);
@Namespace("tensorflow::ops") public static native Node BinaryOp(@StdString String op_name, Node a, Node b,
               @Const @ByRef GraphDefBuilder.Options opts);

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_GRAPH_GRAPH_DEF_BUILDER_H_


// Parsed from tensorflow/core/graph/default_device.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_GRAPH_DEFAULT_DEVICE_H_
// #define TENSORFLOW_CORE_GRAPH_DEFAULT_DEVICE_H_

// #include <string>

// #include "tensorflow/core/framework/graph.pb.h"
// #include "tensorflow/core/framework/node_def.pb.h"

// Sets the default device for all nodes in graph_def to "device",
// only if not already set.
@Namespace("tensorflow::graph") public static native void SetDefaultDevice(@StdString BytePointer device, GraphDef graph_def);
@Namespace("tensorflow::graph") public static native void SetDefaultDevice(@StdString String device, GraphDef graph_def);

  // namespace graph
  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_GRAPH_DEFAULT_DEVICE_H_


// Parsed from tensorflow/core/graph/graph_constructor.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_GRAPH_GRAPH_CONSTRUCTOR_H_
// #define TENSORFLOW_CORE_GRAPH_GRAPH_CONSTRUCTOR_H_

// #include "tensorflow/core/framework/graph.pb.h"
// #include "tensorflow/core/graph/graph.h"
// #include "tensorflow/core/graph/tensor_id.h"
// #include "tensorflow/core/lib/core/status.h"
// Targeting ../GraphConstructorOptions.java


@Namespace("tensorflow") public static native @ByVal Status ConvertGraphDefToGraph(@Const @ByRef GraphConstructorOptions opts,
                                     @Const @ByRef GraphDef gdef, Graph g);

// Same as ConvertGraphDefToGraph, but takes just nodes.  Used by function
// instantiation.
// TODO(irving): This will turn into std::vector<NodeInfoPtr> soon.
@Namespace("tensorflow") public static native @ByVal Status ConvertNodeDefsToGraph(@Const @ByRef GraphConstructorOptions opts,
                                     @ArraySlice NodeDef nodes, Graph g);
// Targeting ../ImportGraphDefOptions.java


// Targeting ../ImportGraphDefResults.java



// Adds the graph in GraphDef `gdef` into an existing Graph `*g`.
//
// On error, returns non-OK and leaves `*g` unmodified.
//
// `refiner` can be null. It should be non-null if the caller
// intends to add additional nodes to the graph after the import. This
// allows the caller to validate shapes of those nodes (since
// ShapeRefiner::AddNode must be called in topological order).
//
// `results` must be non-null if `opts.return_tensors` or `opts.result_nodes` is
// non-empty. It can also be set to fetch the unused input map keys. If it's
// non-null, all the vector fields must be empty.
//
// TODO(ashankar): Push this mechanism and get rid of Session::Extend()
// as a means of enhancing an existing Graph.
@Namespace("tensorflow") public static native @ByVal Status ImportGraphDef(@Const @ByRef ImportGraphDefOptions opts,
                             @Const @ByRef GraphDef gdef, Graph g,
                             ShapeRefiner refiner,
                             ImportGraphDefResults results/*=nullptr*/);
@Namespace("tensorflow") public static native @ByVal Status ImportGraphDef(@Const @ByRef ImportGraphDefOptions opts,
                             @Const @ByRef GraphDef gdef, Graph g,
                             ShapeRefiner refiner);

// Make a copy of "src" into "*dest".
//
// REQUIRES: "*dest" is a freshly allocated graph without any nodes or edges
// other than the implicit Source/Sink nodes.
@Namespace("tensorflow") public static native void CopyGraph(@Const @ByRef Graph src, Graph dest);

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_GRAPH_GRAPH_CONSTRUCTOR_H_


// Parsed from tensorflow/core/graph/gradients.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_GRAPH_GRADIENTS_H_
// #define TENSORFLOW_CORE_GRAPH_GRADIENTS_H_

// #include "tensorflow/core/graph/graph.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../NodeOut.java



// NOTE: This API is a work in progress and will likely be changing frequently.
//
// Given initial gradient-node outputs 'y_grad_node_outputs' (which compute the
// symbolic partial derivatives of some loss function 'L' w.r.t the node outputs
// 'y_node_outputs'), adds gradient nodes to 'graph' that compute the symbolic
// partial derivatives of 'L' w.r.t the node outputs 'x_node_outputs'.
//
// REQUIRES: Each node in 'x_node_outputs' to be unique, and so to have a single
// output (this restriction will be removed in a subsequent change).

// TODO(andydavis) Add symbolic gradient support for general graphs (the current
// implementation only supports gradients for functions). In particular,
// the nodes in 'x_nodes' are currently restricted to have one output.

@Namespace("tensorflow") public static native @ByVal Status AddSymbolicGradients(@ArraySlice NodeOut y_node_outputs,
                            @ArraySlice NodeOut x_node_outputs,
                            @ArraySlice NodeOut y_grad_node_outputs,
                            @StdVector NodeOut x_grad_node_outputs,
                            Graph graph);

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_GRAPH_GRADIENTS_H_


// Parsed from tensorflow/cc/framework/scope.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CC_FRAMEWORK_SCOPE_H_
// #define TENSORFLOW_CC_FRAMEWORK_SCOPE_H_

// #include <memory>
// #include <string>
// #include <unordered_map>
// #include <unordered_set>
// #include <vector>

// #include "absl/strings/str_cat.h"
// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../Scope.java



/** A helper struct to hold the scopes that would be used by a function
 *  constructing a composite op. */

/** \} */

  // namespace tensorflow

// #endif  // TENSORFLOW_CC_FRAMEWORK_SCOPE_H_


// Parsed from tensorflow/cc/framework/ops.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CC_FRAMEWORK_OPS_H_
// #define TENSORFLOW_CC_FRAMEWORK_OPS_H_

// #include <type_traits>

// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor.pb.h"
// #include "tensorflow/core/graph/graph.h"
// #include "tensorflow/core/lib/hash/hash.h"
// #include "tensorflow/core/lib/strings/strcat.h"

/** \defgroup core Core Tensorflow API */
// Targeting ../Operation.java


// Targeting ../Output.java


// Targeting ../OutputHash.java


// Targeting ../Input.java



/** A type for representing the output of ops that produce more than one output,
 *  or a list of tensors. */
// Targeting ../InputList.java



/** \} */

  // namespace tensorflow

// #endif  // TENSORFLOW_CC_FRAMEWORK_OPS_H_


// Parsed from tensorflow/core/framework/op_gen_lib.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_OP_GEN_LIB_H_
// #define TENSORFLOW_CORE_FRAMEWORK_OP_GEN_LIB_H_

// #include <string>
// #include <unordered_map>
// #include "tensorflow/core/framework/api_def.pb.h"
// #include "tensorflow/core/framework/op_def.pb.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/platform/env.h"

// Forward declare protos so their symbols can be removed from .so exports

@Namespace("tensorflow") public static native @StdString BytePointer Spaces(int n);

// Wrap prefix + str to be at most width characters, indenting every line
// after the first by prefix.size() spaces.  Intended use case is something
// like prefix = "  Foo(" and str is a list of arguments (terminated by a ")").
// TODO(josh11b): Option to wrap on ", " instead of " " when possible.
@Namespace("tensorflow") public static native @StdString BytePointer WordWrap(@StringPiece BytePointer prefix, @StringPiece BytePointer str, int width);
@Namespace("tensorflow") public static native @StdString String WordWrap(@StringPiece String prefix, @StringPiece String str, int width);

// Looks for an "=" at the beginning of *description.  If found, strips it off
// (and any following spaces) from *description and return true.  Otherwise
// returns false.
@Namespace("tensorflow") public static native @Cast("bool") boolean ConsumeEquals(@StringPiece @Cast({"char*", "StringPiece*"}) BytePointer description);

// Convert text-serialized protobufs to/from multiline format.
@Namespace("tensorflow") public static native @StdString BytePointer PBTxtToMultiline(@StringPiece BytePointer pbtxt,
                        @Const @ByRef StringVector multi_line_fields);
@Namespace("tensorflow") public static native @StdString String PBTxtToMultiline(@StringPiece String pbtxt,
                        @Const @ByRef StringVector multi_line_fields);
@Namespace("tensorflow") public static native @StdString BytePointer PBTxtFromMultiline(@StringPiece BytePointer multiline_pbtxt);
@Namespace("tensorflow") public static native @StdString String PBTxtFromMultiline(@StringPiece String multiline_pbtxt);
// Targeting ../ApiDefMap.java



  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_OP_GEN_LIB_H_


// Parsed from tensorflow/cc/framework/gradients.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CC_FRAMEWORK_GRADIENTS_H_
// #define TENSORFLOW_CC_FRAMEWORK_GRADIENTS_H_

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"

/** NOTE: This API is a work in progress and will likely be changing frequently.
 * 
 *  Given initial gradients 'grad_inputs' (which represent the symbolic partial
 *  derivatives of some loss function 'L' w.r.t 'outputs'), adds gradient nodes
 *  to the graph associated with 'scope', which compute (and return in
 *  'grad_outputs') the symbolic partial derivatives of 'L' w.r.t 'inputs'. */
@Namespace("tensorflow") public static native @ByVal Status AddSymbolicGradients(@Const @ByRef Scope scope,
                            @Const @ByRef OutputVector outputs,
                            @Const @ByRef OutputVector inputs,
                            @Const @ByRef OutputVector grad_inputs,
                            OutputVector grad_outputs);

// Same as above, but uses 'OnesLike' for all shapes in
// 'outputs' as grad_inputs.
@Namespace("tensorflow") public static native @ByVal Status AddSymbolicGradients(@Const @ByRef Scope scope,
                            @Const @ByRef OutputVector outputs,
                            @Const @ByRef OutputVector inputs,
                            OutputVector grad_outputs);

/** Returns a sentinel Output that represents 'no gradient' (i.e. no gradient
 *  flows along some graph edge during backpropagation).
 *  Can be returned in 'grad_outputs' by an invocation of 'AddSymbolicGradients'
 *  (note that gradient flow through an Output can be stopped through the use of
 *  the StopGradient node). */
@Namespace("tensorflow") public static native @ByVal Output NoGradient();

  // namespace tensorflow

// #endif  // TENSORFLOW_CC_FRAMEWORK_GRADIENTS_H_


// Parsed from tensorflow/core/protobuf/saver.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/protobuf/saver.proto

// #ifndef PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fsaver_2eproto
// #define PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fsaver_2eproto

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3006001
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3006001 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/generated_enum_reflection.h>
// #include <google/protobuf/unknown_field_set.h>
// @@protoc_insertion_point(includes)
// #define PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_2fcore_2fprotobuf_2fsaver_2eproto
// Internal implementation detail -- do not use these members.
  // namespace protobuf_tensorflow_2fcore_2fprotobuf_2fsaver_2eproto
  // namespace tensorflow

  // namespace protobuf
  // namespace google

/** enum tensorflow::SaverDef_CheckpointFormatVersion */
public static final int
  SaverDef_CheckpointFormatVersion_LEGACY = 0,
  SaverDef_CheckpointFormatVersion_V1 = 1,
  SaverDef_CheckpointFormatVersion_V2 = 2,
  SaverDef_CheckpointFormatVersion_SaverDef_CheckpointFormatVersion_INT_MIN_SENTINEL_DO_NOT_USE_ = kint32min,
  SaverDef_CheckpointFormatVersion_SaverDef_CheckpointFormatVersion_INT_MAX_SENTINEL_DO_NOT_USE_ = kint32max;
@Namespace("tensorflow") public static native @Cast("bool") boolean SaverDef_CheckpointFormatVersion_IsValid(int value);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::SaverDef_CheckpointFormatVersion") int SaverDef_CheckpointFormatVersion_CheckpointFormatVersion_MIN();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::SaverDef_CheckpointFormatVersion") int SaverDef_CheckpointFormatVersion_CheckpointFormatVersion_MAX();
@Namespace("tensorflow") @MemberGetter public static native int SaverDef_CheckpointFormatVersion_CheckpointFormatVersion_ARRAYSIZE();

@Namespace("tensorflow") public static native @Cast("const google::protobuf::EnumDescriptor*") Pointer SaverDef_CheckpointFormatVersion_descriptor();
@Namespace("tensorflow") public static native @StdString BytePointer SaverDef_CheckpointFormatVersion_Name(@Cast("tensorflow::SaverDef_CheckpointFormatVersion") int value);
@Namespace("tensorflow") public static native @Cast("bool") boolean SaverDef_CheckpointFormatVersion_Parse(
    @StdString BytePointer name, @Cast("tensorflow::SaverDef_CheckpointFormatVersion*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean SaverDef_CheckpointFormatVersion_Parse(
    @StdString String name, @Cast("tensorflow::SaverDef_CheckpointFormatVersion*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean SaverDef_CheckpointFormatVersion_Parse(
    @StdString BytePointer name, @Cast("tensorflow::SaverDef_CheckpointFormatVersion*") int... value);
@Namespace("tensorflow") public static native @Cast("bool") boolean SaverDef_CheckpointFormatVersion_Parse(
    @StdString String name, @Cast("tensorflow::SaverDef_CheckpointFormatVersion*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean SaverDef_CheckpointFormatVersion_Parse(
    @StdString BytePointer name, @Cast("tensorflow::SaverDef_CheckpointFormatVersion*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean SaverDef_CheckpointFormatVersion_Parse(
    @StdString String name, @Cast("tensorflow::SaverDef_CheckpointFormatVersion*") int... value);
// Targeting ../SaverDef.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// SaverDef

// string filename_tensor_name = 1;



// #if LANG_CXX11

// #endif








// string save_tensor_name = 2;



// #if LANG_CXX11

// #endif








// string restore_op_name = 3;



// #if LANG_CXX11

// #endif








// int32 max_to_keep = 4;




// bool sharded = 5;




// float keep_checkpoint_every_n_hours = 6;




// .tensorflow.SaverDef.CheckpointFormatVersion version = 7;




// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__

// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow


  // namespace protobuf
  // namespace google

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fsaver_2eproto


// Parsed from tensorflow/core/protobuf/meta_graph.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/protobuf/meta_graph.proto

// #ifndef PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fmeta_5fgraph_2eproto
// #define PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fmeta_5fgraph_2eproto

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3006001
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3006001 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/io/coded_stream.h>
// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_table_driven.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/inlined_string_field.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>  // IWYU pragma: export
// #include <google/protobuf/extension_set.h>  // IWYU pragma: export
// #include <google/protobuf/map.h>  // IWYU pragma: export
// #include <google/protobuf/map_entry.h>
// #include <google/protobuf/map_field_inl.h>
// #include <google/protobuf/unknown_field_set.h>
// #include <google/protobuf/any.pb.h>
// #include "tensorflow/core/framework/graph.pb.h"
// #include "tensorflow/core/framework/op_def.pb.h"
// #include "tensorflow/core/framework/tensor_shape.pb.h"
// #include "tensorflow/core/framework/types.pb.h"
// #include "tensorflow/core/protobuf/saver.pb.h"
// @@protoc_insertion_point(includes)
// #define PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_2fcore_2fprotobuf_2fmeta_5fgraph_2eproto
// Internal implementation detail -- do not use these members.
  // namespace protobuf_tensorflow_2fcore_2fprotobuf_2fmeta_5fgraph_2eproto
// Targeting ../MetaGraphDef_CollectionDefEntry_DoNotUse.java


// Targeting ../MetaGraphDef_SignatureDefEntry_DoNotUse.java


// Targeting ../SignatureDef_InputsEntry_DoNotUse.java


// Targeting ../SignatureDef_OutputsEntry_DoNotUse.java


  // namespace tensorflow
















  // namespace protobuf
  // namespace google
// Targeting ../MetaGraphDef_MetaInfoDef.java


// -------------------------------------------------------------------

// -------------------------------------------------------------------
// Targeting ../MetaGraphDef.java


// Targeting ../CollectionDef_NodeList.java


// Targeting ../CollectionDef_BytesList.java


// Targeting ../CollectionDef_Int64List.java


// Targeting ../CollectionDef_FloatList.java


// Targeting ../CollectionDef_AnyList.java


// Targeting ../CollectionDef.java


// Targeting ../TensorInfo_CooSparse.java


// Targeting ../TensorInfo.java


// -------------------------------------------------------------------

// -------------------------------------------------------------------
// Targeting ../SignatureDef.java


// Targeting ../AssetFileDef.java


// ===================================================================


// ===================================================================

// #ifdef __GNUC__
//   #pragma GCC diagnostic push
//   #pragma GCC diagnostic ignored "-Wstrict-aliasing"
// #endif  // __GNUC__
// MetaGraphDef_MetaInfoDef

// string meta_graph_version = 1;



// #if LANG_CXX11

// #endif








// .tensorflow.OpList stripped_op_list = 2;








// .google.protobuf.Any any_info = 3;








// repeated string tags = 4;





// #if LANG_CXX11

// #endif




// #if LANG_CXX11

// #endif





// string tensorflow_version = 5;



// #if LANG_CXX11

// #endif








// string tensorflow_git_version = 6;



// #if LANG_CXX11

// #endif








// bool stripped_default_attrs = 7;




// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// MetaGraphDef

// .tensorflow.MetaGraphDef.MetaInfoDef meta_info_def = 1;









// .tensorflow.GraphDef graph_def = 2;








// .tensorflow.SaverDef saver_def = 3;








// map<string, .tensorflow.CollectionDef> collection_def = 4;





// map<string, .tensorflow.SignatureDef> signature_def = 5;





// repeated .tensorflow.AssetFileDef asset_file_def = 6;








// -------------------------------------------------------------------

// CollectionDef_NodeList

// repeated string value = 1;





// #if LANG_CXX11

// #endif




// #if LANG_CXX11

// #endif





// -------------------------------------------------------------------

// CollectionDef_BytesList

// repeated bytes value = 1;





// #if LANG_CXX11

// #endif




// #if LANG_CXX11

// #endif





// -------------------------------------------------------------------

// CollectionDef_Int64List

// repeated int64 value = 1 [packed = true];








// -------------------------------------------------------------------

// CollectionDef_FloatList

// repeated float value = 1 [packed = true];








// -------------------------------------------------------------------

// CollectionDef_AnyList

// repeated .google.protobuf.Any value = 1;







// -------------------------------------------------------------------

// CollectionDef

// .tensorflow.CollectionDef.NodeList node_list = 1;










// .tensorflow.CollectionDef.BytesList bytes_list = 2;










// .tensorflow.CollectionDef.Int64List int64_list = 3;










// .tensorflow.CollectionDef.FloatList float_list = 4;










// .tensorflow.CollectionDef.AnyList any_list = 5;













// -------------------------------------------------------------------

// TensorInfo_CooSparse

// string values_tensor_name = 1;



// #if LANG_CXX11

// #endif








// string indices_tensor_name = 2;



// #if LANG_CXX11

// #endif








// string dense_shape_tensor_name = 3;



// #if LANG_CXX11

// #endif








// -------------------------------------------------------------------

// TensorInfo

// string name = 1;





// #if LANG_CXX11

// #endif








// .tensorflow.TensorInfo.CooSparse coo_sparse = 4;










// .tensorflow.DataType dtype = 2;




// .tensorflow.TensorShapeProto tensor_shape = 3;











// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// SignatureDef

// map<string, .tensorflow.TensorInfo> inputs = 1;





// map<string, .tensorflow.TensorInfo> outputs = 2;





// string method_name = 3;



// #if LANG_CXX11

// #endif








// -------------------------------------------------------------------

// AssetFileDef

// .tensorflow.TensorInfo tensor_info = 1;









// string filename = 2;



// #if LANG_CXX11

// #endif








// #ifdef __GNUC__
//   #pragma GCC diagnostic pop
// #endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_INCLUDED_tensorflow_2fcore_2fprotobuf_2fmeta_5fgraph_2eproto


// Parsed from tensorflow/cc/saved_model/loader.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

/** SavedModel loading functions and SavedModelBundle struct. */

// #ifndef TENSORFLOW_CC_SAVED_MODEL_LOADER_H_
// #define TENSORFLOW_CC_SAVED_MODEL_LOADER_H_

// #include <string>
// #include <unordered_set>

// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/protobuf/meta_graph.pb.h"
// #include "tensorflow/core/public/session.h"
// Targeting ../SavedModelBundle.java



/** Loads a SavedModel from the specified export directory. The meta graph def
 *  to be loaded is identified by the supplied tags, corresponding exactly to
 *  the set of tags used at SavedModel build time. Returns a SavedModel bundle
 *  with a session and the requested meta graph def, if found. */
@Namespace("tensorflow") public static native @ByVal Status LoadSavedModel(@Const @ByRef SessionOptions session_options,
                      @Const @ByRef RunOptions run_options, @StdString BytePointer export_dir,
                      @Const @ByRef StringUnorderedSet tags,
                      SavedModelBundle bundle);
@Namespace("tensorflow") public static native @ByVal Status LoadSavedModel(@Const @ByRef SessionOptions session_options,
                      @Const @ByRef RunOptions run_options, @StdString String export_dir,
                      @Const @ByRef StringUnorderedSet tags,
                      SavedModelBundle bundle);

/** Checks whether the provided directory could contain a SavedModel. Note that
 *  the method does not load any data by itself. If the method returns {@code false},
 *  the export directory definitely does not contain a SavedModel. If the method
 *  returns {@code true}, the export directory may contain a SavedModel but provides
 *  no guarantee that it can be loaded. */
@Namespace("tensorflow") public static native @Cast("bool") boolean MaybeSavedModelDirectory(@StdString BytePointer export_dir);
@Namespace("tensorflow") public static native @Cast("bool") boolean MaybeSavedModelDirectory(@StdString String export_dir);

  // namespace tensorflow

// #endif  // TENSORFLOW_CC_SAVED_MODEL_LOADER_H_


// Parsed from tensorflow/cc/saved_model/tag_constants.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CC_SAVED_MODEL_TAG_CONSTANTS_H_
// #define TENSORFLOW_CC_SAVED_MODEL_TAG_CONSTANTS_H_

/** Tag for the {@code gpu} graph. */
@Namespace("tensorflow") @MemberGetter public static native byte kSavedModelTagGpu(int i);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer kSavedModelTagGpu();

/** Tag for the {@code tpu} graph. */
@Namespace("tensorflow") @MemberGetter public static native byte kSavedModelTagTpu(int i);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer kSavedModelTagTpu();

/** Tag for the {@code serving} graph. */
@Namespace("tensorflow") @MemberGetter public static native byte kSavedModelTagServe(int i);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer kSavedModelTagServe();

/** Tag for the {@code training} graph. */
@Namespace("tensorflow") @MemberGetter public static native byte kSavedModelTagTrain(int i);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer kSavedModelTagTrain();

  // namespace tensorflow

// #endif  // TENSORFLOW_CC_SAVED_MODEL_TAG_CONSTANTS_H_


// Parsed from tensorflow/cc/saved_model/signature_constants.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CC_SAVED_MODEL_SIGNATURE_CONSTANTS_H_
// #define TENSORFLOW_CC_SAVED_MODEL_SIGNATURE_CONSTANTS_H_

/** Key in the signature def map for {@code default} serving signatures. The default
 *  signature is used in inference requests where a specific signature was not
 *  specified. */
@Namespace("tensorflow") @MemberGetter public static native byte kDefaultServingSignatureDefKey(int i);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer kDefaultServingSignatureDefKey();

////////////////////////////////////////////////////////////////////////////////
/** Classification API constants.
 <p>
 *  Classification inputs. */
@Namespace("tensorflow") @MemberGetter public static native byte kClassifyInputs(int i);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer kClassifyInputs();

/** Classification method name used in a SignatureDef. */
@Namespace("tensorflow") @MemberGetter public static native byte kClassifyMethodName(int i);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer kClassifyMethodName();

/** Classification classes output. */
@Namespace("tensorflow") @MemberGetter public static native byte kClassifyOutputClasses(int i);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer kClassifyOutputClasses();

/** Classification scores output. */
@Namespace("tensorflow") @MemberGetter public static native byte kClassifyOutputScores(int i);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer kClassifyOutputScores();

////////////////////////////////////////////////////////////////////////////////
/** Predict API constants.
 <p>
 *  Predict inputs. */
@Namespace("tensorflow") @MemberGetter public static native byte kPredictInputs(int i);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer kPredictInputs();

/** Predict method name used in a SignatureDef. */
@Namespace("tensorflow") @MemberGetter public static native byte kPredictMethodName(int i);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer kPredictMethodName();

/** Predict outputs. */
@Namespace("tensorflow") @MemberGetter public static native byte kPredictOutputs(int i);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer kPredictOutputs();

////////////////////////////////////////////////////////////////////////////////
/** Regression API constants.
 <p>
 *  Regression inputs. */
@Namespace("tensorflow") @MemberGetter public static native byte kRegressInputs(int i);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer kRegressInputs();

/** Regression method name used in a SignatureDef. */
@Namespace("tensorflow") @MemberGetter public static native byte kRegressMethodName(int i);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer kRegressMethodName();

/** Regression outputs. */
@Namespace("tensorflow") @MemberGetter public static native byte kRegressOutputs(int i);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer kRegressOutputs();

////////////////////////////////////////////////////////////////////////////////

  // namespace tensorflow

// #endif  // TENSORFLOW_CC_SAVED_MODEL_SIGNATURE_CONSTANTS_H_


// Parsed from tensorflow/cc/ops/standard_ops.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CC_OPS_STANDARD_OPS_H_
// #define TENSORFLOW_CC_OPS_STANDARD_OPS_H_

// #include "tensorflow/cc/ops/array_ops.h"
// #include "tensorflow/cc/ops/candidate_sampling_ops.h"
// #include "tensorflow/cc/ops/const_op.h"
// #include "tensorflow/cc/ops/control_flow_ops.h"
// #include "tensorflow/cc/ops/data_flow_ops.h"
// #include "tensorflow/cc/ops/image_ops.h"
// #include "tensorflow/cc/ops/io_ops.h"
// #include "tensorflow/cc/ops/linalg_ops.h"
// #include "tensorflow/cc/ops/logging_ops.h"
// #include "tensorflow/cc/ops/lookup_ops.h"
// #include "tensorflow/cc/ops/math_ops.h"
// #include "tensorflow/cc/ops/nn_ops.h"
// #include "tensorflow/cc/ops/no_op.h"
// #include "tensorflow/cc/ops/parsing_ops.h"
// #include "tensorflow/cc/ops/random_ops.h"
// #include "tensorflow/cc/ops/sparse_ops.h"
// #include "tensorflow/cc/ops/state_ops.h"
// #include "tensorflow/cc/ops/string_ops.h"
// #include "tensorflow/cc/ops/training_ops.h"
// #include "tensorflow/cc/ops/user_ops.h"

// #endif  // TENSORFLOW_CC_OPS_STANDARD_OPS_H_


// Parsed from tensorflow/cc/ops/const_op.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CC_OPS_CONST_OP_H_
// #define TENSORFLOW_CC_OPS_CONST_OP_H_

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/graph/node_builder.h"

/** \defgroup const_op Const Op
 *  \{ */

@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, @Const @ByRef Input.Initializer val);
@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, @ByRef Tensor val);
@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, byte val);
@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, short val);
@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, int val);
@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, long val);
@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, float val);
@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, double val);
@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, boolean val);
@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, @StdString String val);
@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, @StdString BytePointer val);

@Namespace("tensorflow::ops") public static native @ByVal Output ConstFromProto(@Const @ByRef Scope scope, @Const @ByRef TensorProto proto);

@Namespace("tensorflow::ops") public static native @ByVal NodeBuilder.NodeOut AsNodeOut(@Const @ByRef Scope scope, @Const @ByRef Input inp);

@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, @Cast("const unsigned char") byte v, @Const @ByVal TensorShape shape);

@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, short v, @Const @ByVal TensorShape shape);

@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, int v, @Const @ByVal TensorShape shape);

@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, @Cast("const long long") long v, @Const @ByVal TensorShape shape);

@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, float v, @Const @ByVal TensorShape shape);

@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, double v, @Const @ByVal TensorShape shape);

@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, @Cast("const bool") boolean v, @Const @ByVal TensorShape shape);

@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, @StdString BytePointer v, @Const @ByVal TensorShape shape);
@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, @StdString String v, @Const @ByVal TensorShape shape);

@Namespace("tensorflow::ops") public static native @ByVal NodeOutVector AsNodeOutList(@Const @ByRef Scope scope,
                                                @Const @ByRef InputList inp);

/** }\ */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_CONST_OP_H_


// Parsed from tensorflow/cc/ops/array_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_ARRAY_OPS_H_
// #define TENSORFLOW_CC_OPS_ARRAY_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../BatchToSpace.java


// Targeting ../BatchToSpaceND.java


// Targeting ../Bitcast.java


// Targeting ../BroadcastDynamicShape.java


// Targeting ../BroadcastTo.java


// Targeting ../CheckNumerics.java


// Targeting ../Concat.java


// Targeting ../ConjugateTranspose.java


// Targeting ../DebugGradientIdentity.java


// Targeting ../DebugGradientRefIdentity.java


// Targeting ../DeepCopy.java


// Targeting ../DepthToSpace.java


// Targeting ../Dequantize.java


// Targeting ../Diag.java


// Targeting ../DiagPart.java


// Targeting ../EditDistance.java


// Targeting ../Empty.java


// Targeting ../EnsureShape.java


// Targeting ../ExpandDims.java


// Targeting ../ExtractImagePatches.java


// Targeting ../ExtractVolumePatches.java


// Targeting ../FakeQuantWithMinMaxArgs.java


// Targeting ../FakeQuantWithMinMaxArgsGradient.java


// Targeting ../FakeQuantWithMinMaxVars.java


// Targeting ../FakeQuantWithMinMaxVarsGradient.java


// Targeting ../FakeQuantWithMinMaxVarsPerChannel.java


// Targeting ../FakeQuantWithMinMaxVarsPerChannelGradient.java


// Targeting ../Fill.java


// Targeting ../Gather.java


// Targeting ../GatherNd.java


// Targeting ../GatherV2.java


// Targeting ../GuaranteeConst.java


// Targeting ../Identity.java


// Targeting ../IdentityN.java


// Targeting ../ImmutableConst.java


// Targeting ../InplaceAdd.java


// Targeting ../InplaceSub.java


// Targeting ../InplaceUpdate.java


// Targeting ../InvertPermutation.java


// Targeting ../SetDiff1D.java


// Targeting ../MatrixBandPart.java


// Targeting ../MatrixDiag.java


// Targeting ../MatrixDiagPart.java


// Targeting ../MatrixSetDiag.java


// Targeting ../MirrorPad.java


// Targeting ../OneHot.java


// Targeting ../OnesLike.java


// Targeting ../Stack.java


// Targeting ../Pad.java


// Targeting ../PadV2.java


// Targeting ../ParallelConcat.java


// Targeting ../Placeholder.java


// Targeting ../PlaceholderWithDefault.java


// Targeting ../PreventGradient.java


// Targeting ../QuantizeAndDequantizeV2.java


// Targeting ../QuantizeAndDequantizeV3.java


// Targeting ../QuantizeV2.java


// Targeting ../QuantizedConcat.java


// Targeting ../QuantizedInstanceNorm.java


// Targeting ../QuantizedReshape.java


// Targeting ../Rank.java


// Targeting ../Reshape.java


// Targeting ../ResourceStridedSliceAssign.java


// Targeting ../ReverseSequence.java


// Targeting ../Reverse.java


// Targeting ../ScatterNd.java


// Targeting ../ScatterNdNonAliasingAdd.java



/** Returns the shape of a tensor.
 * 
 *  This operation returns a 1-D integer tensor representing the shape of {@code input}.
 * 
 *  For example:
 * 
 *  <pre>{@code
 *  # 't' is [[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]]
 *  shape(t) ==> [2, 2, 3]
 *  }</pre>
 * 
 *  Arguments:
 *  * scope: A Scope object
 * 
 *  Returns:
 *  * {@code Output}: The output tensor. */
// Targeting ../ShapeN.java


// Targeting ../Size.java


// Targeting ../Slice.java


// Targeting ../Snapshot.java


// Targeting ../SpaceToBatch.java


// Targeting ../SpaceToBatchND.java


// Targeting ../SpaceToDepth.java


// Targeting ../Split.java


// Targeting ../SplitV.java


// Targeting ../Squeeze.java


// Targeting ../StopGradient.java


// Targeting ../StridedSlice.java


// Targeting ../StridedSliceAssign.java


// Targeting ../StridedSliceGrad.java


// Targeting ../TensorScatterAdd.java


// Targeting ../TensorScatterSub.java


// Targeting ../TensorScatterUpdate.java


// Targeting ../Tile.java


// Targeting ../Transpose.java


// Targeting ../Unique.java


// Targeting ../UniqueV2.java


// Targeting ../UniqueWithCounts.java


// Targeting ../UniqueWithCountsV2.java


// Targeting ../Unstack.java


// Targeting ../UnravelIndex.java


// Targeting ../Where.java


// Targeting ../ZerosLike.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_ARRAY_OPS_H_


// Parsed from tensorflow/cc/ops/candidate_sampling_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_CANDIDATE_SAMPLING_OPS_H_
// #define TENSORFLOW_CC_OPS_CANDIDATE_SAMPLING_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../AllCandidateSampler.java


// Targeting ../ComputeAccidentalHits.java


// Targeting ../FixedUnigramCandidateSampler.java


// Targeting ../LearnedUnigramCandidateSampler.java


// Targeting ../LogUniformCandidateSampler.java


// Targeting ../UniformCandidateSampler.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_CANDIDATE_SAMPLING_OPS_H_


// Parsed from tensorflow/cc/ops/control_flow_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_CONTROL_FLOW_OPS_H_
// #define TENSORFLOW_CC_OPS_CONTROL_FLOW_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../Abort.java


// Targeting ../ControlTrigger.java


// Targeting ../LoopCond.java


// Targeting ../Merge.java


// Targeting ../NextIteration.java


// Targeting ../RefNextIteration.java


// Targeting ../RefSelect.java


// Targeting ../RefSwitch.java


// Targeting ../Switch.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_CONTROL_FLOW_OPS_H_


// Parsed from tensorflow/cc/ops/data_flow_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_DATA_FLOW_OPS_H_
// #define TENSORFLOW_CC_OPS_DATA_FLOW_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../AccumulatorApplyGradient.java


// Targeting ../AccumulatorNumAccumulated.java


// Targeting ../AccumulatorSetGlobalStep.java


// Targeting ../AccumulatorTakeGradient.java


// Targeting ../Barrier.java


// Targeting ../BarrierClose.java


// Targeting ../BarrierIncompleteSize.java


// Targeting ../BarrierInsertMany.java


// Targeting ../BarrierReadySize.java


// Targeting ../BarrierTakeMany.java


// Targeting ../ConditionalAccumulator.java


// Targeting ../DeleteSessionTensor.java


// Targeting ../DynamicPartition.java


// Targeting ../DynamicStitch.java


// Targeting ../FIFOQueue.java


// Targeting ../GetSessionHandle.java


// Targeting ../GetSessionHandleV2.java


// Targeting ../GetSessionTensor.java


// Targeting ../MapClear.java


// Targeting ../MapIncompleteSize.java


// Targeting ../MapPeek.java


// Targeting ../MapSize.java


// Targeting ../MapStage.java


// Targeting ../MapUnstage.java


// Targeting ../MapUnstageNoKey.java


// Targeting ../OrderedMapClear.java


// Targeting ../OrderedMapIncompleteSize.java


// Targeting ../OrderedMapPeek.java


// Targeting ../OrderedMapSize.java


// Targeting ../OrderedMapStage.java


// Targeting ../OrderedMapUnstage.java


// Targeting ../OrderedMapUnstageNoKey.java


// Targeting ../PaddingFIFOQueue.java


// Targeting ../ParallelDynamicStitch.java


// Targeting ../PriorityQueue.java


// Targeting ../QueueClose.java


// Targeting ../QueueDequeueMany.java


// Targeting ../QueueDequeueUpTo.java


// Targeting ../QueueDequeue.java


// Targeting ../QueueEnqueueMany.java


// Targeting ../QueueEnqueue.java


// Targeting ../QueueIsClosed.java


// Targeting ../QueueIsClosedV2.java


// Targeting ../QueueSize.java


// Targeting ../RandomShuffleQueue.java


// Targeting ../RecordInput.java


// Targeting ../SparseAccumulatorApplyGradient.java


// Targeting ../SparseAccumulatorTakeGradient.java


// Targeting ../SparseConditionalAccumulator.java


// Targeting ../Stage.java


// Targeting ../StageClear.java


// Targeting ../StagePeek.java


// Targeting ../StageSize.java


// Targeting ../TensorArrayClose.java


// Targeting ../TensorArrayConcat.java


// Targeting ../TensorArrayGather.java


// Targeting ../TensorArrayGrad.java


// Targeting ../TensorArrayGradWithShape.java


// Targeting ../TensorArrayRead.java


// Targeting ../TensorArrayScatter.java


// Targeting ../TensorArraySize.java


// Targeting ../TensorArraySplit.java


// Targeting ../TensorArray.java


// Targeting ../TensorArrayWrite.java


// Targeting ../Unstage.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_DATA_FLOW_OPS_H_


// Parsed from tensorflow/cc/ops/image_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_IMAGE_OPS_H_
// #define TENSORFLOW_CC_OPS_IMAGE_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../AdjustContrast.java


// Targeting ../AdjustHue.java


// Targeting ../AdjustSaturation.java


// Targeting ../CropAndResize.java


// Targeting ../CropAndResizeGradBoxes.java


// Targeting ../CropAndResizeGradImage.java


// Targeting ../DecodeAndCropJpeg.java


// Targeting ../DecodeBmp.java


// Targeting ../DecodeGif.java


// Targeting ../DecodeJpeg.java


// Targeting ../DecodePng.java


// Targeting ../DrawBoundingBoxes.java


// Targeting ../EncodeJpeg.java


// Targeting ../EncodePng.java


// Targeting ../ExtractGlimpse.java


// Targeting ../ExtractJpegShape.java


// Targeting ../HSVToRGB.java


// Targeting ../NonMaxSuppression.java


// Targeting ../NonMaxSuppressionV2.java


// Targeting ../NonMaxSuppressionV3.java


// Targeting ../NonMaxSuppressionV4.java


// Targeting ../NonMaxSuppressionWithOverlaps.java


// Targeting ../QuantizedResizeBilinear.java


// Targeting ../RGBToHSV.java


// Targeting ../ResizeArea.java


// Targeting ../ResizeBicubic.java


// Targeting ../ResizeBilinear.java


// Targeting ../ResizeNearestNeighbor.java


// Targeting ../SampleDistortedBoundingBox.java


// Targeting ../SampleDistortedBoundingBoxV2.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_IMAGE_OPS_H_


// Parsed from tensorflow/cc/ops/io_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_IO_OPS_H_
// #define TENSORFLOW_CC_OPS_IO_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../FixedLengthRecordReader.java


// Targeting ../IdentityReader.java


// Targeting ../LMDBReader.java


// Targeting ../MatchingFiles.java


// Targeting ../MergeV2Checkpoints.java


// Targeting ../ReadFile.java


// Targeting ../ReaderNumRecordsProduced.java


// Targeting ../ReaderNumWorkUnitsCompleted.java


// Targeting ../ReaderReadUpTo.java


// Targeting ../ReaderRead.java


// Targeting ../ReaderReset.java


// Targeting ../ReaderRestoreState.java


// Targeting ../ReaderSerializeState.java


// Targeting ../Restore.java


// Targeting ../RestoreSlice.java


// Targeting ../RestoreV2.java


// Targeting ../Save.java


// Targeting ../SaveSlices.java


// Targeting ../SaveV2.java


// Targeting ../ShardedFilename.java


// Targeting ../ShardedFilespec.java


// Targeting ../TFRecordReader.java


// Targeting ../TextLineReader.java


// Targeting ../WholeFileReader.java


// Targeting ../WriteFile.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_IO_OPS_H_


// Parsed from tensorflow/cc/ops/linalg_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_LINALG_OPS_H_
// #define TENSORFLOW_CC_OPS_LINALG_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../Cholesky.java


// Targeting ../CholeskyGrad.java


// Targeting ../LogMatrixDeterminant.java


// Targeting ../Lu.java


// Targeting ../MatrixDeterminant.java


// Targeting ../MatrixInverse.java


// Targeting ../MatrixSolve.java


// Targeting ../MatrixSolveLs.java


// Targeting ../MatrixSquareRoot.java


// Targeting ../MatrixTriangularSolve.java


// Targeting ../Qr.java


// Targeting ../SelfAdjointEig.java


// Targeting ../Svd.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_LINALG_OPS_H_


// Parsed from tensorflow/cc/ops/logging_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_LOGGING_OPS_H_
// #define TENSORFLOW_CC_OPS_LOGGING_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../Assert.java


// Targeting ../AudioSummary.java


// Targeting ../HistogramSummary.java


// Targeting ../ImageSummary.java


// Targeting ../MergeSummary.java


// Targeting ../Print.java


// Targeting ../PrintV2.java


// Targeting ../ScalarSummary.java


// Targeting ../TensorSummary.java


// Targeting ../TensorSummaryV2.java


// Targeting ../Timestamp.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_LOGGING_OPS_H_


// Parsed from tensorflow/cc/ops/math_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_MATH_OPS_H_
// #define TENSORFLOW_CC_OPS_MATH_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../Abs.java


// Targeting ../AccumulateNV2.java


// Targeting ../Acos.java


// Targeting ../Acosh.java


// Targeting ../Add.java


// Targeting ../AddN.java


// Targeting ../AddV2.java


// Targeting ../All.java



///
///
///
///
///
///
///
// Targeting ../Angle.java


// Targeting ../Any.java



///
///
// Targeting ../ApproximateEqual.java


// Targeting ../ArgMax.java


// Targeting ../ArgMin.java


// Targeting ../Asin.java


// Targeting ../Asinh.java


// Targeting ../Atan.java


// Targeting ../Atan2.java


// Targeting ../Atanh.java


// Targeting ../BatchMatMul.java


// Targeting ../BesselI0e.java


// Targeting ../BesselI1e.java


// Targeting ../Betainc.java


// Targeting ../Bincount.java


// Targeting ../Bucketize.java


// Targeting ../CastOp.java


// Targeting ../Ceil.java


// Targeting ../ClipByValue.java


// Targeting ../CompareAndBitpack.java


// Targeting ../Complex.java


// Targeting ../ComplexAbs.java


// Targeting ../Conj.java


// Targeting ../Cos.java


// Targeting ../Cosh.java


// Targeting ../Cross.java


// Targeting ../Cumprod.java


// Targeting ../Cumsum.java


// Targeting ../Digamma.java


// Targeting ../Div.java


// Targeting ../DivNoNan.java


// Targeting ../Equal.java


// Targeting ../Erf.java


// Targeting ../Erfc.java


// Targeting ../Exp.java


// Targeting ../Expm1.java


// Targeting ../Floor.java


// Targeting ../FloorDiv.java


// Targeting ../FloorMod.java


// Targeting ../Greater.java


// Targeting ../GreaterEqual.java


// Targeting ../HistogramFixedWidth.java


// Targeting ../Igamma.java


// Targeting ../Igammac.java


// Targeting ../Imag.java


// Targeting ../Inv.java


// Targeting ../IsFinite.java


// Targeting ../IsInf.java


// Targeting ../IsNan.java


// Targeting ../Less.java


// Targeting ../LessEqual.java


// Targeting ../Lgamma.java


// Targeting ../LinSpace.java


// Targeting ../Log.java


// Targeting ../Log1p.java


// Targeting ../LogicalAnd.java


// Targeting ../LogicalNot.java


// Targeting ../LogicalOr.java


// Targeting ../MatMul.java


// Targeting ../Max.java



///
///
///
// Targeting ../Maximum.java


// Targeting ../Mean.java



///
///
///
///
///
// Targeting ../Min.java



///
///
///
// Targeting ../Minimum.java


// Targeting ../Mod.java


// Targeting ../Multiply.java



///
///
///
///
// Targeting ../Negate.java



///
///
///
// Targeting ../NotEqual.java


// Targeting ../Polygamma.java


// Targeting ../Pow.java


// Targeting ../Prod.java



///
///
///
///
///
///
// Targeting ../QuantizeDownAndShrinkRange.java


// Targeting ../QuantizedAdd.java


// Targeting ../QuantizedMatMul.java


// Targeting ../QuantizedMul.java


// Targeting ../Range.java


// Targeting ../Real.java


// Targeting ../RealDiv.java


// Targeting ../Reciprocal.java


// Targeting ../RequantizationRange.java


// Targeting ../Requantize.java


// Targeting ../Rint.java


// Targeting ../Round.java


// Targeting ../Rsqrt.java


// Targeting ../SegmentMax.java


// Targeting ../SegmentMean.java


// Targeting ../SegmentMin.java


// Targeting ../SegmentProd.java


// Targeting ../SegmentSum.java


// Targeting ../Where3.java


// Targeting ../Sigmoid.java


// Targeting ../Sign.java


// Targeting ../Sin.java


// Targeting ../Sinh.java


// Targeting ../SparseMatMul.java


// Targeting ../SparseSegmentMean.java


// Targeting ../SparseSegmentMeanGrad.java


// Targeting ../SparseSegmentMeanWithNumSegments.java


// Targeting ../SparseSegmentSqrtN.java


// Targeting ../SparseSegmentSqrtNGrad.java


// Targeting ../SparseSegmentSqrtNWithNumSegments.java


// Targeting ../SparseSegmentSum.java


// Targeting ../SparseSegmentSumWithNumSegments.java


// Targeting ../Sqrt.java


// Targeting ../Square.java


// Targeting ../SquaredDifference.java


// Targeting ../Subtract.java



///
///
///
///
///
// Targeting ../Sum.java



///
///
// Targeting ../Tan.java


// Targeting ../Tanh.java


// Targeting ../TruncateDiv.java


// Targeting ../TruncateMod.java


// Targeting ../UnsortedSegmentMax.java


// Targeting ../UnsortedSegmentMin.java


// Targeting ../UnsortedSegmentProd.java


// Targeting ../UnsortedSegmentSum.java


// Targeting ../Xdivy.java


// Targeting ../Xlogy.java


// Targeting ../Zeta.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_MATH_OPS_H_


// Parsed from tensorflow/cc/ops/nn_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_NN_OPS_H_
// #define TENSORFLOW_CC_OPS_NN_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../AvgPool.java


// Targeting ../AvgPool3D.java


// Targeting ../AvgPool3DGrad.java


// Targeting ../BiasAdd.java


// Targeting ../BiasAddGrad.java


// Targeting ../Conv2D.java


// Targeting ../Conv2DBackpropFilter.java


// Targeting ../Conv2DBackpropInput.java


// Targeting ../Conv3D.java


// Targeting ../Conv3DBackpropFilterV2.java


// Targeting ../Conv3DBackpropInputV2.java


// Targeting ../DataFormatDimMap.java


// Targeting ../DataFormatVecPermute.java


// Targeting ../DepthwiseConv2dNative.java


// Targeting ../DepthwiseConv2dNativeBackpropFilter.java


// Targeting ../DepthwiseConv2dNativeBackpropInput.java


// Targeting ../Dilation2D.java


// Targeting ../Dilation2DBackpropFilter.java


// Targeting ../Dilation2DBackpropInput.java


// Targeting ../Elu.java


// Targeting ../FractionalAvgPool.java


// Targeting ../FractionalMaxPool.java


// Targeting ../FusedBatchNorm.java


// Targeting ../FusedBatchNormGrad.java


// Targeting ../FusedBatchNormGradV2.java


// Targeting ../FusedBatchNormV2.java


// Targeting ../FusedPadConv2D.java


// Targeting ../FusedResizeAndPadConv2D.java


// Targeting ../InTopK.java


// Targeting ../InTopKV2.java


// Targeting ../L2Loss.java


// Targeting ../LRN.java


// Targeting ../LogSoftmax.java


// Targeting ../MaxPool.java


// Targeting ../MaxPool3D.java


// Targeting ../MaxPool3DGrad.java


// Targeting ../MaxPool3DGradGrad.java


// Targeting ../MaxPoolGradGrad.java


// Targeting ../MaxPoolGradGradV2.java


// Targeting ../MaxPoolGradGradWithArgmax.java


// Targeting ../MaxPoolGradV2.java


// Targeting ../MaxPoolV2.java


// Targeting ../MaxPoolWithArgmax.java


// Targeting ../NthElement.java


// Targeting ../QuantizedAvgPool.java


// Targeting ../QuantizedBatchNormWithGlobalNormalization.java


// Targeting ../QuantizedBiasAdd.java


// Targeting ../QuantizedConv2D.java


// Targeting ../QuantizedConv2DAndRelu.java


// Targeting ../QuantizedConv2DAndReluAndRequantize.java


// Targeting ../QuantizedConv2DAndRequantize.java


// Targeting ../QuantizedConv2DWithBias.java


// Targeting ../QuantizedConv2DWithBiasAndRelu.java


// Targeting ../QuantizedConv2DWithBiasAndReluAndRequantize.java


// Targeting ../QuantizedConv2DWithBiasAndRequantize.java


// Targeting ../QuantizedConv2DWithBiasSignedSumAndReluAndRequantize.java


// Targeting ../QuantizedConv2DWithBiasSumAndRelu.java


// Targeting ../QuantizedConv2DWithBiasSumAndReluAndRequantize.java


// Targeting ../QuantizedMaxPool.java


// Targeting ../QuantizedRelu.java


// Targeting ../QuantizedRelu6.java


// Targeting ../QuantizedReluX.java


// Targeting ../Relu.java


// Targeting ../Relu6.java


// Targeting ../Selu.java


// Targeting ../Softmax.java


// Targeting ../SoftmaxCrossEntropyWithLogits.java


// Targeting ../Softplus.java


// Targeting ../Softsign.java


// Targeting ../SparseSoftmaxCrossEntropyWithLogits.java


// Targeting ../TopK.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_NN_OPS_H_


// Parsed from tensorflow/cc/ops/no_op.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_NO_OP_H_
// #define TENSORFLOW_CC_OPS_NO_OP_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../NoOp.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_NO_OP_H_


// Parsed from tensorflow/cc/ops/parsing_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_PARSING_OPS_H_
// #define TENSORFLOW_CC_OPS_PARSING_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../DecodeCSV.java


// Targeting ../DecodeCompressed.java


// Targeting ../DecodeJSONExample.java


// Targeting ../DecodeRaw.java


// Targeting ../ParseExample.java


// Targeting ../ParseSequenceExample.java


// Targeting ../ParseSingleExample.java


// Targeting ../ParseSingleSequenceExample.java


// Targeting ../ParseTensor.java


// Targeting ../SerializeTensor.java


// Targeting ../StringToNumber.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_PARSING_OPS_H_


// Parsed from tensorflow/cc/ops/random_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_RANDOM_OPS_H_
// #define TENSORFLOW_CC_OPS_RANDOM_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../Multinomial.java


// Targeting ../ParameterizedTruncatedNormal.java


// Targeting ../RandomGamma.java


// Targeting ../RandomPoissonV2.java


// Targeting ../RandomShuffle.java


// Targeting ../RandomNormal.java


// Targeting ../RandomUniform.java


// Targeting ../RandomUniformInt.java


// Targeting ../TruncatedNormal.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_RANDOM_OPS_H_


// Parsed from tensorflow/cc/ops/sparse_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_SPARSE_OPS_H_
// #define TENSORFLOW_CC_OPS_SPARSE_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../AddManySparseToTensorsMap.java


// Targeting ../AddSparseToTensorsMap.java


// Targeting ../DeserializeManySparse.java


// Targeting ../DeserializeSparse.java


// Targeting ../SerializeManySparse.java


// Targeting ../SerializeSparse.java


// Targeting ../SparseAdd.java


// Targeting ../SparseAddGrad.java


// Targeting ../SparseConcat.java


// Targeting ../SparseCross.java


// Targeting ../SparseDenseCwiseAdd.java


// Targeting ../SparseDenseCwiseDiv.java


// Targeting ../SparseDenseCwiseMul.java


// Targeting ../SparseFillEmptyRows.java


// Targeting ../SparseFillEmptyRowsGrad.java


// Targeting ../SparseReduceMax.java


// Targeting ../SparseReduceMaxSparse.java


// Targeting ../SparseReduceSum.java


// Targeting ../SparseReduceSumSparse.java


// Targeting ../SparseReorder.java


// Targeting ../SparseReshape.java


// Targeting ../SparseSlice.java


// Targeting ../SparseSliceGrad.java


// Targeting ../SparseSoftmax.java


// Targeting ../SparseSparseMaximum.java


// Targeting ../SparseSparseMinimum.java


// Targeting ../SparseSplit.java


// Targeting ../SparseTensorDenseAdd.java


// Targeting ../SparseTensorDenseMatMul.java


// Targeting ../SparseToDense.java


// Targeting ../TakeManySparseFromTensorsMap.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_SPARSE_OPS_H_


// Parsed from tensorflow/cc/ops/state_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_STATE_OPS_H_
// #define TENSORFLOW_CC_OPS_STATE_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../Assign.java


// Targeting ../AssignAdd.java


// Targeting ../AssignSub.java


// Targeting ../CountUpTo.java


// Targeting ../DestroyTemporaryVariable.java


// Targeting ../IsVariableInitialized.java


// Targeting ../ResourceCountUpTo.java


// Targeting ../ResourceScatterNdAdd.java


// Targeting ../ResourceScatterNdUpdate.java


// Targeting ../ScatterAdd.java


// Targeting ../ScatterDiv.java


// Targeting ../ScatterMax.java


// Targeting ../ScatterMin.java


// Targeting ../ScatterMul.java


// Targeting ../ScatterNdAdd.java


// Targeting ../ScatterNdSub.java


// Targeting ../ScatterNdUpdate.java


// Targeting ../ScatterSub.java


// Targeting ../ScatterUpdate.java


// Targeting ../TemporaryVariable.java


// Targeting ../Variable.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_STATE_OPS_H_


// Parsed from tensorflow/cc/ops/string_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_STRING_OPS_H_
// #define TENSORFLOW_CC_OPS_STRING_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../AsString.java


// Targeting ../DecodeBase64.java


// Targeting ../EncodeBase64.java


// Targeting ../ReduceJoin.java


// Targeting ../RegexFullMatch.java


// Targeting ../RegexReplace.java


// Targeting ../StringFormat.java


// Targeting ../StringJoin.java


// Targeting ../StringLength.java


// Targeting ../StringSplit.java


// Targeting ../StringSplitV2.java


// Targeting ../StringStrip.java


// Targeting ../StringToHashBucket.java


// Targeting ../StringToHashBucketFast.java


// Targeting ../StringToHashBucketStrong.java


// Targeting ../Substr.java


// Targeting ../UnicodeScript.java


// Targeting ../UnicodeTranscode.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_STRING_OPS_H_


// Parsed from tensorflow/cc/ops/training_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_TRAINING_OPS_H_
// #define TENSORFLOW_CC_OPS_TRAINING_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../ApplyAdadelta.java


// Targeting ../ApplyAdagrad.java


// Targeting ../ApplyAdagradDA.java


// Targeting ../ApplyAdam.java


// Targeting ../ApplyAddSign.java


// Targeting ../ApplyCenteredRMSProp.java


// Targeting ../ApplyFtrl.java


// Targeting ../ApplyFtrlV2.java


// Targeting ../ApplyGradientDescent.java


// Targeting ../ApplyMomentum.java


// Targeting ../ApplyPowerSign.java


// Targeting ../ApplyProximalAdagrad.java


// Targeting ../ApplyProximalGradientDescent.java


// Targeting ../ApplyRMSProp.java


// Targeting ../ResourceApplyAdadelta.java


// Targeting ../ResourceApplyAdagrad.java


// Targeting ../ResourceApplyAdagradDA.java


// Targeting ../ResourceApplyAdam.java


// Targeting ../ResourceApplyAdamWithAmsgrad.java


// Targeting ../ResourceApplyAddSign.java


// Targeting ../ResourceApplyCenteredRMSProp.java


// Targeting ../ResourceApplyFtrl.java


// Targeting ../ResourceApplyFtrlV2.java


// Targeting ../ResourceApplyGradientDescent.java


// Targeting ../ResourceApplyKerasMomentum.java


// Targeting ../ResourceApplyMomentum.java


// Targeting ../ResourceApplyPowerSign.java


// Targeting ../ResourceApplyProximalAdagrad.java


// Targeting ../ResourceApplyProximalGradientDescent.java


// Targeting ../ResourceApplyRMSProp.java


// Targeting ../ResourceSparseApplyAdadelta.java


// Targeting ../ResourceSparseApplyAdagrad.java


// Targeting ../ResourceSparseApplyAdagradDA.java


// Targeting ../ResourceSparseApplyCenteredRMSProp.java


// Targeting ../ResourceSparseApplyFtrl.java


// Targeting ../ResourceSparseApplyFtrlV2.java


// Targeting ../ResourceSparseApplyKerasMomentum.java


// Targeting ../ResourceSparseApplyMomentum.java


// Targeting ../ResourceSparseApplyProximalAdagrad.java


// Targeting ../ResourceSparseApplyProximalGradientDescent.java


// Targeting ../ResourceSparseApplyRMSProp.java


// Targeting ../SparseApplyAdadelta.java


// Targeting ../SparseApplyAdagrad.java


// Targeting ../SparseApplyAdagradDA.java


// Targeting ../SparseApplyCenteredRMSProp.java


// Targeting ../SparseApplyFtrl.java


// Targeting ../SparseApplyFtrlV2.java


// Targeting ../SparseApplyMomentum.java


// Targeting ../SparseApplyProximalAdagrad.java


// Targeting ../SparseApplyProximalGradientDescent.java


// Targeting ../SparseApplyRMSProp.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_TRAINING_OPS_H_


// Parsed from tensorflow/cc/ops/user_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_USER_OPS_H_
// #define TENSORFLOW_CC_OPS_USER_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// Targeting ../Fact.java



/** \} */

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_USER_OPS_H_


}
