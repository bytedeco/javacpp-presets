// Targeted by JavaCPP version 1.3: DO NOT EDIT THIS FILE

package org.bytedeco.javacpp;

import java.nio.*;
import org.bytedeco.javacpp.*;
import org.bytedeco.javacpp.annotation.*;

public class tensorflow extends org.bytedeco.javacpp.helper.tensorflow {
    static { Loader.load(); }

@Name("tensorflow::gtl::InlinedVector<tensorflow::int64,4>") public static class LongVector extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public LongVector(Pointer p) { super(p); }
    public LongVector()       { allocate();  }
    private native void allocate();
    public native @Name("operator=") @ByRef LongVector put(@ByRef LongVector x);

    public native long size();

    @Index public native @Cast("tensorflow::int64") long get(@Cast("size_t") long i);
    public native LongVector put(@Cast("size_t") long i, long value);
}

@Name("tensorflow::gtl::InlinedVector<tensorflow::DataType,4>") public static class DataTypeVector extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public DataTypeVector(Pointer p) { super(p); }
    public DataTypeVector()       { allocate();  }
    private native void allocate();
    public native @Name("operator=") @ByRef DataTypeVector put(@ByRef DataTypeVector x);

    public native long size();

    @Index public native @Cast("tensorflow::DataType") int get(@Cast("size_t") long i);
    public native DataTypeVector put(@Cast("size_t") long i, int value);
}

@Name("google::protobuf::Map<std::string,tensorflow::AttrValue>") public static class StringAttrValueMap extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public StringAttrValueMap(Pointer p) { super(p); }
    public StringAttrValueMap()       { allocate();  }
    private native void allocate();
    public native @Name("operator=") @ByRef StringAttrValueMap put(@ByRef StringAttrValueMap x);

    public native long size();

    @Index public native @ByRef AttrValue get(@StdString BytePointer i);
    public native StringAttrValueMap put(@StdString BytePointer i, AttrValue value);

    public native @ByVal Iterator begin();
    public native @ByVal Iterator end();
    @NoOffset @Name("iterator") public static class Iterator extends Pointer {
        public Iterator(Pointer p) { super(p); }
        public Iterator() { }

        public native @Name("operator++") @ByRef Iterator increment();
        public native @Name("operator==") boolean equals(@ByRef Iterator it);
        public native @Name("operator*().first") @MemberGetter @StdString BytePointer first();
        public native @Name("operator*().second") @MemberGetter @ByRef AttrValue second();
    }
}

@Name("std::vector<std::string>") public static class StringVector extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public StringVector(Pointer p) { super(p); }
    public StringVector(BytePointer ... array) { this(array.length); put(array); }
    public StringVector(String ... array) { this(array.length); put(array); }
    public StringVector()       { allocate();  }
    public StringVector(long n) { allocate(n); }
    private native void allocate();
    private native void allocate(@Cast("size_t") long n);
    public native @Name("operator=") @ByRef StringVector put(@ByRef StringVector x);

    public native long size();
    public native void resize(@Cast("size_t") long n);

    @Index public native @StdString BytePointer get(@Cast("size_t") long i);
    public native StringVector put(@Cast("size_t") long i, BytePointer value);
    @ValueSetter @Index public native StringVector put(@Cast("size_t") long i, @StdString String value);

    public StringVector put(BytePointer ... array) {
        if (size() != array.length) { resize(array.length); }
        for (int i = 0; i < array.length; i++) {
            put(i, array[i]);
        }
        return this;
    }

    public StringVector put(String ... array) {
        if (size() != array.length) { resize(array.length); }
        for (int i = 0; i < array.length; i++) {
            put(i, array[i]);
        }
        return this;
    }
}

@Name("std::vector<tensorflow::Tensor>") public static class TensorVector extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TensorVector(Pointer p) { super(p); }
    public TensorVector(Tensor ... array) { this(array.length); put(array); }
    public TensorVector()       { allocate();  }
    public TensorVector(long n) { allocate(n); }
    private native void allocate();
    private native void allocate(@Cast("size_t") long n);
    public native @Name("operator=") @ByRef TensorVector put(@ByRef TensorVector x);

    public native long size();
    public native void resize(@Cast("size_t") long n);

    @Index public native @ByRef Tensor get(@Cast("size_t") long i);
    public native TensorVector put(@Cast("size_t") long i, Tensor value);

    public TensorVector put(Tensor ... array) {
        if (size() != array.length) { resize(array.length); }
        for (int i = 0; i < array.length; i++) {
            put(i, array[i]);
        }
        return this;
    }
}

@Name("std::vector<tensorflow::TensorProto>") public static class TensorProtoVector extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TensorProtoVector(Pointer p) { super(p); }
    public TensorProtoVector(TensorProto ... array) { this(array.length); put(array); }
    public TensorProtoVector()       { allocate();  }
    public TensorProtoVector(long n) { allocate(n); }
    private native void allocate();
    private native void allocate(@Cast("size_t") long n);
    public native @Name("operator=") @ByRef TensorProtoVector put(@ByRef TensorProtoVector x);

    public native long size();
    public native void resize(@Cast("size_t") long n);

    @Index public native @ByRef TensorProto get(@Cast("size_t") long i);
    public native TensorProtoVector put(@Cast("size_t") long i, TensorProto value);

    public TensorProtoVector put(TensorProto ... array) {
        if (size() != array.length) { resize(array.length); }
        for (int i = 0; i < array.length; i++) {
            put(i, array[i]);
        }
        return this;
    }
}

@Name("std::vector<tensorflow::TensorShape>") public static class TensorShapeVector extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TensorShapeVector(Pointer p) { super(p); }
    public TensorShapeVector(TensorShape ... array) { this(array.length); put(array); }
    public TensorShapeVector()       { allocate();  }
    public TensorShapeVector(long n) { allocate(n); }
    private native void allocate();
    private native void allocate(@Cast("size_t") long n);
    public native @Name("operator=") @ByRef TensorShapeVector put(@ByRef TensorShapeVector x);

    public native long size();
    public native void resize(@Cast("size_t") long n);

    @Index public native @ByRef TensorShape get(@Cast("size_t") long i);
    public native TensorShapeVector put(@Cast("size_t") long i, TensorShape value);

    public TensorShapeVector put(TensorShape ... array) {
        if (size() != array.length) { resize(array.length); }
        for (int i = 0; i < array.length; i++) {
            put(i, array[i]);
        }
        return this;
    }
}

@Name("std::vector<tensorflow::NodeBuilder::NodeOut>") public static class NodeOutVector extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public NodeOutVector(Pointer p) { super(p); }
    public NodeOutVector(NodeBuilder.NodeOut ... array) { this(array.length); put(array); }
    public NodeOutVector()       { allocate();  }
    public NodeOutVector(long n) { allocate(n); }
    private native void allocate();
    private native void allocate(@Cast("size_t") long n);
    public native @Name("operator=") @ByRef NodeOutVector put(@ByRef NodeOutVector x);

    public native long size();
    public native void resize(@Cast("size_t") long n);

    @Index public native @ByRef NodeBuilder.NodeOut get(@Cast("size_t") long i);
    public native NodeOutVector put(@Cast("size_t") long i, NodeBuilder.NodeOut value);

    public NodeOutVector put(NodeBuilder.NodeOut ... array) {
        if (size() != array.length) { resize(array.length); }
        for (int i = 0; i < array.length; i++) {
            put(i, array[i]);
        }
        return this;
    }
}

@Name("std::vector<tensorflow::Node*>") public static class NodeVector extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public NodeVector(Pointer p) { super(p); }
    public NodeVector(Node ... array) { this(array.length); put(array); }
    public NodeVector()       { allocate();  }
    public NodeVector(long n) { allocate(n); }
    private native void allocate();
    private native void allocate(@Cast("size_t") long n);
    public native @Name("operator=") @ByRef NodeVector put(@ByRef NodeVector x);

    public native long size();
    public native void resize(@Cast("size_t") long n);

    @Index public native Node get(@Cast("size_t") long i);
    public native NodeVector put(@Cast("size_t") long i, Node value);

    public NodeVector put(Node ... array) {
        if (size() != array.length) { resize(array.length); }
        for (int i = 0; i < array.length; i++) {
            put(i, array[i]);
        }
        return this;
    }
}

@Name("std::vector<const tensorflow::Tensor*>") public static class ConstTensorPtrVector extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ConstTensorPtrVector(Pointer p) { super(p); }
    public ConstTensorPtrVector(Tensor ... array) { this(array.length); put(array); }
    public ConstTensorPtrVector()       { allocate();  }
    public ConstTensorPtrVector(long n) { allocate(n); }
    private native void allocate();
    private native void allocate(@Cast("size_t") long n);
    public native @Name("operator=") @ByRef ConstTensorPtrVector put(@ByRef ConstTensorPtrVector x);

    public native long size();
    public native void resize(@Cast("size_t") long n);

    @Index public native @Const Tensor get(@Cast("size_t") long i);
    public native ConstTensorPtrVector put(@Cast("size_t") long i, Tensor value);

    public ConstTensorPtrVector put(Tensor ... array) {
        if (size() != array.length) { resize(array.length); }
        for (int i = 0; i < array.length; i++) {
            put(i, array[i]);
        }
        return this;
    }
}

@Name("std::vector<const tensorflow::shape_inference::Dimension*>") public static class ConstDimensionPtrVector extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ConstDimensionPtrVector(Pointer p) { super(p); }
    public ConstDimensionPtrVector(Dimension ... array) { this(array.length); put(array); }
    public ConstDimensionPtrVector()       { allocate();  }
    public ConstDimensionPtrVector(long n) { allocate(n); }
    private native void allocate();
    private native void allocate(@Cast("size_t") long n);
    public native @Name("operator=") @ByRef ConstDimensionPtrVector put(@ByRef ConstDimensionPtrVector x);

    public native long size();
    public native void resize(@Cast("size_t") long n);

    @Index public native @Const Dimension get(@Cast("size_t") long i);
    public native ConstDimensionPtrVector put(@Cast("size_t") long i, Dimension value);

    public ConstDimensionPtrVector put(Dimension ... array) {
        if (size() != array.length) { resize(array.length); }
        for (int i = 0; i < array.length; i++) {
            put(i, array[i]);
        }
        return this;
    }
}

@Name("std::vector<std::pair<std::string,tensorflow::Tensor> >") public static class StringTensorPairVector extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public StringTensorPairVector(Pointer p) { super(p); }
    public StringTensorPairVector(BytePointer[] firstValue, Tensor[] secondValue) { this(Math.min(firstValue.length, secondValue.length)); put(firstValue, secondValue); }
    public StringTensorPairVector(String[] firstValue, Tensor[] secondValue) { this(Math.min(firstValue.length, secondValue.length)); put(firstValue, secondValue); }
    public StringTensorPairVector()       { allocate();  }
    public StringTensorPairVector(long n) { allocate(n); }
    private native void allocate();
    private native void allocate(@Cast("size_t") long n);
    public native @Name("operator=") @ByRef StringTensorPairVector put(@ByRef StringTensorPairVector x);

    public native long size();
    public native void resize(@Cast("size_t") long n);

    @Index public native @StdString BytePointer first(@Cast("size_t") long i); public native StringTensorPairVector first(@Cast("size_t") long i, BytePointer first);
    @Index public native @ByRef Tensor second(@Cast("size_t") long i);  public native StringTensorPairVector second(@Cast("size_t") long i, Tensor second);
    @MemberSetter @Index public native StringTensorPairVector first(@Cast("size_t") long i, @StdString String first);

    public StringTensorPairVector put(BytePointer[] firstValue, Tensor[] secondValue) {
        for (int i = 0; i < firstValue.length && i < secondValue.length; i++) {
            first(i, firstValue[i]);
            second(i, secondValue[i]);
        }
        return this;
    }

    public StringTensorPairVector put(String[] firstValue, Tensor[] secondValue) {
        for (int i = 0; i < firstValue.length && i < secondValue.length; i++) {
            first(i, firstValue[i]);
            second(i, secondValue[i]);
        }
        return this;
    }
}

@NoOffset @Name("std::pair<tensorflow::EdgeSet::iterator,bool>") public static class EdgeSetBoolPair extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public EdgeSetBoolPair(Pointer p) { super(p); }
    public EdgeSetBoolPair(EdgeSetIterator firstValue, boolean secondValue) { this(); put(firstValue, secondValue); }
    public EdgeSetBoolPair()       { allocate();  }
    private native void allocate();
    public native @Name("operator=") @ByRef EdgeSetBoolPair put(@ByRef EdgeSetBoolPair x);


    @MemberGetter public native @ByRef EdgeSetIterator first(); public native EdgeSetBoolPair first(EdgeSetIterator first);
    @MemberGetter public native @Cast("bool") boolean second();  public native EdgeSetBoolPair second(boolean second);

    public EdgeSetBoolPair put(EdgeSetIterator firstValue, boolean secondValue) {
        first(firstValue);
        second(secondValue);
        return this;
    }
}

@Name("std::unordered_map<std::string,std::pair<int,int> >") public static class NameRangeMap extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public NameRangeMap(Pointer p) { super(p); }
    public NameRangeMap()       { allocate();  }
    private native void allocate();
    public native @Name("operator=") @ByRef NameRangeMap put(@ByRef NameRangeMap x);

    public native long size();

    @Index public native int first(@StdString BytePointer i); public native NameRangeMap first(@StdString BytePointer i, int first);
    @Index public native int second(@StdString BytePointer i);  public native NameRangeMap second(@StdString BytePointer i, int second);
}

// Parsed from tensorflow/core/platform/default/integral_types.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_PLATFORM_DEFAULT_INTEGRAL_TYPES_H_
// #define TENSORFLOW_PLATFORM_DEFAULT_INTEGRAL_TYPES_H_

// IWYU pragma: private, include "third_party/tensorflow/core/platform/types.h"
// IWYU pragma: friend third_party/tensorflow/core/platform/types.h

  // namespace tensorflow

// #endif  // TENSORFLOW_PLATFORM_DEFAULT_INTEGRAL_TYPES_H_


// Parsed from tensorflow/core/framework/numeric_types.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_FRAMEWORK_NUMERIC_TYPES_H_
// #define TENSORFLOW_FRAMEWORK_NUMERIC_TYPES_H_

// #include <complex>

// #include "tensorflow/core/platform/types.h"

// Single precision complex.
// Double precision complex.

  // end namespace tensorflow

// #endif  // TENSORFLOW_FRAMEWORK_NUMERIC_TYPES_H_


// Parsed from tensorflow/core/platform/init_main.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_PLATFORM_INIT_MAIN_H_
// #define TENSORFLOW_PLATFORM_INIT_MAIN_H_

// Platform-specific initialization routine that may be invoked by a
// main() program that uses TensorFlow.
//
// Default implementation does nothing.
@Namespace("tensorflow::port") public static native void InitMain(@Cast("const char*") BytePointer usage, IntPointer argc, @Cast("char***") PointerPointer argv);
@Namespace("tensorflow::port") public static native void InitMain(String usage, IntBuffer argc, @Cast("char***") PointerPointer argv);
@Namespace("tensorflow::port") public static native void InitMain(@Cast("const char*") BytePointer usage, int[] argc, @Cast("char***") PointerPointer argv);
@Namespace("tensorflow::port") public static native void InitMain(String usage, IntPointer argc, @Cast("char***") PointerPointer argv);
@Namespace("tensorflow::port") public static native void InitMain(@Cast("const char*") BytePointer usage, IntBuffer argc, @Cast("char***") PointerPointer argv);
@Namespace("tensorflow::port") public static native void InitMain(String usage, int[] argc, @Cast("char***") PointerPointer argv);

  // namespace port
  // namespace tensorflow

// #endif  // TENSORFLOW_PLATFORM_INIT_MAIN_H_


// Parsed from tensorflow/core/platform/types.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_PLATFORM_TYPES_H_
// #define TENSORFLOW_PLATFORM_TYPES_H_

// #include <string>
// #include "tensorflow/core/platform/platform.h"

// Include appropriate platform-dependent implementations
// #if defined(PLATFORM_GOOGLE) || defined(GOOGLE_INTEGRAL_TYPES)
// #include "tensorflow/core/platform/google/integral_types.h"
// #elif defined(PLATFORM_POSIX) || defined(PLATFORM_POSIX_ANDROID) ||
//     defined(PLATFORM_GOOGLE_ANDROID)
// #include "tensorflow/core/platform/default/integral_types.h"
// #else
// #error Define the appropriate PLATFORM_<foo> macro for this platform
// #endif

// Define tensorflow::string to refer to appropriate platform specific type.
// TODO(josh11b): Move this into the platform/*/integral_types.h files
// above, and rename them platform/*/types.h.
// #if defined(PLATFORM_GOOGLE)
// #else
// #endif

@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::uint8") byte kuint8max();
public static final byte kuint8max = kuint8max();
@Namespace("tensorflow") @MemberGetter public static native short kuint16max();
public static final short kuint16max = kuint16max();
@Namespace("tensorflow") @MemberGetter public static native int kuint32max();
public static final int kuint32max = kuint32max();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::uint64") long kuint64max();
public static final long kuint64max = kuint64max();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::int8") byte kint8min();
public static final byte kint8min = kint8min();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::int8") byte kint8max();
public static final byte kint8max = kint8max();
@Namespace("tensorflow") @MemberGetter public static native short kint16min();
public static final short kint16min = kint16min();
@Namespace("tensorflow") @MemberGetter public static native short kint16max();
public static final short kint16max = kint16max();
@Namespace("tensorflow") @MemberGetter public static native int kint32min();
public static final int kint32min = kint32min();
@Namespace("tensorflow") @MemberGetter public static native int kint32max();
public static final int kint32max = kint32max();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::int64") long kint64min();
public static final long kint64min = kint64min();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::int64") long kint64max();
public static final long kint64max = kint64max();

// A typedef for a uint64 used as a short fingerprint.

  // namespace tensorflow

// #endif  // TENSORFLOW_PLATFORM_TYPES_H_


// Parsed from tensorflow/core/platform/mutex.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_PLATFORM_MUTEX_H_
// #define TENSORFLOW_PLATFORM_MUTEX_H_

// #include "tensorflow/core/platform/platform.h"
// #include "tensorflow/core/platform/types.h"
/** enum tensorflow::ConditionResult */
public static final int kCond_Timeout = 0, kCond_MaybeNotified = 1;
  // namespace tensorflow

// Include appropriate platform-dependent implementations of mutex etc.
// #if defined(PLATFORM_GOOGLE)
// #include "tensorflow/core/platform/google/mutex.h"
// #elif defined(PLATFORM_POSIX) || defined(PLATFORM_POSIX_ANDROID) ||
//     defined(PLATFORM_GOOGLE_ANDROID)
// #include "tensorflow/core/platform/default/mutex.h"
// #else
// #error Define the appropriate PLATFORM_<foo> macro for this platform
// #endif

// The mutex library included above defines:
//   class mutex;
//   class mutex_lock;
//   class condition_variable;
// It also defines the following:

// Like "cv->wait(*mu)", except that it only waits for up to "ms" milliseconds.
//
// Returns kCond_Timeout if the timeout expired without this
// thread noticing a signal on the condition variable.  Otherwise may
// return either kCond_Timeout or kCond_MaybeNotified
@Namespace("tensorflow") public static native @Cast("tensorflow::ConditionResult") int WaitForMilliseconds(@Cast("tensorflow::mutex_lock*") Pointer mu, @Cast("tensorflow::condition_variable*") Pointer cv,
                                    @Cast("tensorflow::int64") long ms);
  // namespace tensorflow

// #endif  // TENSORFLOW_PLATFORM_MUTEX_H_


// Parsed from tensorflow/core/platform/macros.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_PLATFORM_MACROS_H_
// #define TENSORFLOW_PLATFORM_MACROS_H_

// Compiler attributes
// #if (defined(__GNUC__) || defined(__APPLE__)) && !defined(SWIG)
// Compiler supports GCC-style attributes
// #define TF_ATTRIBUTE_NORETURN __attribute__((noreturn))
// #define TF_ATTRIBUTE_NOINLINE __attribute__((noinline))
// #define TF_ATTRIBUTE_UNUSED __attribute__((unused))
// #define TF_ATTRIBUTE_COLD __attribute__((cold))
// #define TF_PACKED __attribute__((packed))
// #define TF_MUST_USE_RESULT __attribute__((warn_unused_result))
// #define TF_PRINTF_ATTRIBUTE(string_index, first_to_check)
//   __attribute__((__format__(__printf__, string_index, first_to_check)))
// #define TF_SCANF_ATTRIBUTE(string_index, first_to_check)
//   __attribute__((__format__(__scanf__, string_index, first_to_check)))

// #else
// Non-GCC equivalents
// #define TF_ATTRIBUTE_NORETURN
// #define TF_ATTRIBUTE_NOINLINE
// #define TF_ATTRIBUTE_UNUSED
// #define TF_ATTRIBUTE_COLD
// #define TF_MUST_USE_RESULT
// #define TF_PACKED
// #define TF_PRINTF_ATTRIBUTE(string_index, first_to_check)
// #define TF_SCANF_ATTRIBUTE(string_index, first_to_check)
// #endif

// GCC can be told that a certain branch is not likely to be taken (for
// instance, a CHECK failure), and use that information in static analysis.
// Giving it this information can help it optimize for the common case in
// the absence of better information (ie. -fprofile-arcs).
// #if defined(COMPILER_GCC3)
// #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))
// #define TF_PREDICT_TRUE(x) (__builtin_expect(!!(x), 1))
// #else
// #define TF_PREDICT_FALSE(x) (x)
// #define TF_PREDICT_TRUE(x) (x)
// #endif

// A macro to disallow the copy constructor and operator= functions
// This is usually placed in the private: declarations for a class.
// #define TF_DISALLOW_COPY_AND_ASSIGN(TypeName)
//   TypeName(const TypeName&) = delete;
//   void operator=(const TypeName&) = delete

// The TF_ARRAYSIZE(arr) macro returns the # of elements in an array arr.
//
// The expression TF_ARRAYSIZE(a) is a compile-time constant of type
// size_t.
// #define TF_ARRAYSIZE(a)
//   ((sizeof(a) / sizeof(*(a))) /
//    static_cast<size_t>(!(sizeof(a) % sizeof(*(a)))))

// #if defined(__GXX_EXPERIMENTAL_CXX0X__) || __cplusplus >= 201103L
// Define this to 1 if the code is compiled in C++11 mode; leave it
// undefined otherwise.  Do NOT define it to 0 -- that causes
// '#ifdef LANG_CXX11' to behave differently from '#if LANG_CXX11'.
public static final int LANG_CXX11 = 1;
// #endif

// #if defined(__clang__) && defined(LANG_CXX11) && defined(__has_warning)
// #if __has_feature(cxx_attributes) && __has_warning("-Wimplicit-fallthrough")
// #define TF_FALLTHROUGH_INTENDED [[clang::fallthrough]]  // NOLINT
// #endif
// #endif

// #ifndef TF_FALLTHROUGH_INTENDED
// #define TF_FALLTHROUGH_INTENDED
//   do {
//   } while (0)
// #endif

// #endif  // TENSORFLOW_PLATFORM_MACROS_H_


// Parsed from tensorflow/core/util/port.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_UTIL_PORT_H_
// #define TENSORFLOW_UTIL_PORT_H_

// Returns true if GOOGLE_CUDA is defined.
@Namespace("tensorflow") public static native @Cast("bool") boolean IsGoogleCudaEnabled();

// Returns true if GOOGLE_CUDA is defined, and the given CUDA version supports
// half-precision matrix multiplications and convolution operations.
@Namespace("tensorflow") public static native @Cast("bool") boolean CudaSupportsHalfMatMulAndConv();

  // end namespace tensorflow

// #endif  // TENSORFLOW_UTIL_PORT_H_


// Parsed from tensorflow/core/lib/core/error_codes.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/lib/core/error_codes.proto

// #ifndef PROTOBUF_tensorflow_2fcore_2flib_2fcore_2ferror_5fcodes_2eproto__INCLUDED
// #define PROTOBUF_tensorflow_2fcore_2flib_2fcore_2ferror_5fcodes_2eproto__INCLUDED

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3000000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3000000 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/repeated_field.h>
// #include <google/protobuf/extension_set.h>
// #include <google/protobuf/generated_enum_reflection.h>
// @@protoc_insertion_point(includes)

// Internal implementation detail -- do not call these.
@Namespace("tensorflow::error") public static native void protobuf_AddDesc_tensorflow_2fcore_2flib_2fcore_2ferror_5fcodes_2eproto();
@Namespace("tensorflow::error") public static native void protobuf_AssignDesc_tensorflow_2fcore_2flib_2fcore_2ferror_5fcodes_2eproto();
@Namespace("tensorflow::error") public static native void protobuf_ShutdownFile_tensorflow_2fcore_2flib_2fcore_2ferror_5fcodes_2eproto();


/** enum tensorflow::error::Code */
public static final int
  OK = 0,
  CANCELLED = 1,
  UNKNOWN = 2,
  INVALID_ARGUMENT = 3,
  DEADLINE_EXCEEDED = 4,
  NOT_FOUND = 5,
  ALREADY_EXISTS = 6,
  PERMISSION_DENIED = 7,
  UNAUTHENTICATED = 16,
  RESOURCE_EXHAUSTED = 8,
  FAILED_PRECONDITION = 9,
  ABORTED = 10,
  OUT_OF_RANGE = 11,
  UNIMPLEMENTED = 12,
  INTERNAL = 13,
  UNAVAILABLE = 14,
  DATA_LOSS = 15,
  DO_NOT_USE_RESERVED_FOR_FUTURE_EXPANSION_USE_DEFAULT_IN_SWITCH_INSTEAD_ = 20,
  Code_INT_MIN_SENTINEL_DO_NOT_USE_ =kint32min,
  Code_INT_MAX_SENTINEL_DO_NOT_USE_ =kint32max;
@Namespace("tensorflow::error") public static native @Cast("bool") boolean Code_IsValid(int value);
@Namespace("tensorflow::error") @MemberGetter public static native @Cast("const tensorflow::error::Code") int Code_MIN();
@Namespace("tensorflow::error") @MemberGetter public static native @Cast("const tensorflow::error::Code") int Code_MAX();
@Namespace("tensorflow::error") @MemberGetter public static native int Code_ARRAYSIZE();

@Namespace("tensorflow::error") public static native @Cast("const google::protobuf::EnumDescriptor*") Pointer Code_descriptor();
@Namespace("tensorflow::error") public static native @StdString BytePointer Code_Name(@Cast("tensorflow::error::Code") int value);
@Namespace("tensorflow::error") public static native @Cast("bool") boolean Code_Parse(
    @StdString BytePointer name, @Cast("tensorflow::error::Code*") IntPointer value);
@Namespace("tensorflow::error") public static native @Cast("bool") boolean Code_Parse(
    @StdString String name, @Cast("tensorflow::error::Code*") IntBuffer value);
@Namespace("tensorflow::error") public static native @Cast("bool") boolean Code_Parse(
    @StdString BytePointer name, @Cast("tensorflow::error::Code*") int... value);
@Namespace("tensorflow::error") public static native @Cast("bool") boolean Code_Parse(
    @StdString String name, @Cast("tensorflow::error::Code*") IntPointer value);
@Namespace("tensorflow::error") public static native @Cast("bool") boolean Code_Parse(
    @StdString BytePointer name, @Cast("tensorflow::error::Code*") IntBuffer value);
@Namespace("tensorflow::error") public static native @Cast("bool") boolean Code_Parse(
    @StdString String name, @Cast("tensorflow::error::Code*") int... value);
// ===================================================================


// ===================================================================


// ===================================================================

// #if !PROTOBUF_INLINE_NOT_IN_HEADERS
// #endif  // !PROTOBUF_INLINE_NOT_IN_HEADERS

// @@protoc_insertion_point(namespace_scope)

  // namespace error
  // namespace tensorflow

// #ifndef SWIG
// #endif  // SWIG

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_tensorflow_2fcore_2flib_2fcore_2ferror_5fcodes_2eproto__INCLUDED


// Parsed from tensorflow/core/platform/logging.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_PLATFORM_LOGGING_H_
// #define TENSORFLOW_PLATFORM_LOGGING_H_

// #include "tensorflow/core/platform/platform.h"  // To pick up PLATFORM_define

// #if defined(PLATFORM_GOOGLE) || defined(PLATFORM_GOOGLE_ANDROID) ||
//     defined(GOOGLE_LOGGING)
// #include "tensorflow/core/platform/google/build_config/logging.h"
// #else
// #include "tensorflow/core/platform/default/logging.h"
// #endif

// Some platforms require that filenames be of a certain form when
// used for logging.  This function is invoked to allow platforms to
// adjust the filename used for logging appropriately, if necessary
// (most ports can just do nothing).  If any changes are necessary, the
// implementation should mutate "*filename" appropriately.
@Namespace("tensorflow::port") public static native void AdjustFilenameForLogging(@StdString @Cast({"char*", "std::string*"}) BytePointer filename);

  // namespace port
  // namespace tensorflow

// #endif  // TENSORFLOW_PLATFORM_LOGGING_H_


// Parsed from tensorflow/core/lib/core/status.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_LIB_CORE_STATUS_H_
// #define TENSORFLOW_CORE_LIB_CORE_STATUS_H_

// #include <functional>
// #include <iosfwd>
// #include <string>
// #include "tensorflow/core/lib/core/error_codes.pb.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/platform/logging.h"

/** Denotes success or failure of a call in Tensorflow. */
@Namespace("tensorflow") @NoOffset public static class Status extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Status(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public Status(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public Status position(long position) {
        return (Status)super.position(position);
    }

  /** Create a success status. */
  public Status() { super((Pointer)null); allocate(); }
  private native void allocate();

  /** \brief Create a status with the specified error code and msg as a
   *  human-readable string containing more detailed information. */
  public Status(@Cast("tensorflow::error::Code") int code, @StringPiece BytePointer msg) { super((Pointer)null); allocate(code, msg); }
  private native void allocate(@Cast("tensorflow::error::Code") int code, @StringPiece BytePointer msg);
  public Status(@Cast("tensorflow::error::Code") int code, @StringPiece String msg) { super((Pointer)null); allocate(code, msg); }
  private native void allocate(@Cast("tensorflow::error::Code") int code, @StringPiece String msg);

  /** Copy the specified status. */
  public Status(@Const @ByRef Status s) { super((Pointer)null); allocate(s); }
  private native void allocate(@Const @ByRef Status s);
  public native @Name("operator =") void put(@Const @ByRef Status s);

  public static native @ByVal Status OK();

  /** Returns true iff the status indicates success. */
  public native @Cast("bool") boolean ok();

  public native @Cast("tensorflow::error::Code") int code();

  public native @StdString BytePointer error_message();

  public native @Cast("bool") @Name("operator ==") boolean equals(@Const @ByRef Status x);
  
  ///
  public native @Cast("bool") @Name("operator !=") boolean notEquals(@Const @ByRef Status x);

  /** \brief If {@code ok()}, stores {@code new_status} into {@code *this}.  If {@code !ok()},
   *  preserves the current status, but may augment with additional
   *  information about {@code new_status}.
   * 
   *  Convenient way of keeping track of the first error encountered.
   *  Instead of:
   *    {@code if (overall_status.ok()) overall_status = new_status}
   *  Use:
   *    {@code overall_status.Update(new_status);} */
  public native void Update(@Const @ByRef Status new_status);

  /** \brief Return a string representation of this status suitable for
   *  printing. Returns the string {@code "OK"} for success. */
  public native @StdString BytePointer ToString();
}









@Namespace("tensorflow") public static native @Cast("std::ostream*") @ByRef @Name("operator <<") Pointer shiftLeft(@Cast("std::ostream*") @ByRef Pointer os, @Const @ByRef Status x);

public static native void TF_CHECK_OK(@ByVal Status val);
public static native void TF_QCHECK_OK(@ByVal Status val);

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_LIB_CORE_STATUS_H_


// Parsed from tensorflow/core/platform/protobuf.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_PLATFORM_PROTOBUF_H_
// #define TENSORFLOW_PLATFORM_PROTOBUF_H_

// #include "google/protobuf/any.pb.h"
// #include "tensorflow/core/lib/core/errors.h"
// #include "tensorflow/core/platform/platform.h"
// #include "tensorflow/core/platform/types.h"

// Import whatever namespace protobuf comes from into the
// ::tensorflow::protobuf namespace.
//
// TensorFlow code should use the ::tensorflow::protobuf namespace to
// refer to all protobuf APIs.

// #if defined(PLATFORM_GOOGLE)
// #include "tensorflow/core/platform/google/protobuf.h"
// #else
// #include "tensorflow/core/platform/default/protobuf.h"
// #endif
// Parses a protocol buffer contained in a string in the binary wire format.
// Returns true on success. Note: Unlike protobuf's builtin ParseFromString,
// this function has no size restrictions on the total size of the encoded
// protocol buffer.
@Namespace("tensorflow") public static native @Cast("bool") boolean ParseProtoUnlimited(@Cast("tensorflow::protobuf::MessageLite*") Pointer proto,
                         @StdString BytePointer serialized);
@Namespace("tensorflow") public static native @Cast("bool") boolean ParseProtoUnlimited(@Cast("tensorflow::protobuf::MessageLite*") Pointer proto,
                         @StdString String serialized);
@Namespace("tensorflow") public static native @Cast("bool") boolean ParseProtoUnlimited(@Cast("tensorflow::protobuf::MessageLite*") Pointer proto, @Const Pointer serialized,
                         @Cast("size_t") long size);

// Returns the string value for the value of a string or bytes protobuf field.
@Namespace("tensorflow") public static native @StdString BytePointer ProtobufStringToString(@StdString BytePointer s);
@Namespace("tensorflow") public static native @StdString String ProtobufStringToString(@StdString String s);

// Set <dest> to <src>. Swapping is allowed, as <src> does not need to be
// preserved.
@Namespace("tensorflow") public static native void SetProtobufStringSwapAllowed(@StdString @Cast({"char*", "std::string*"}) BytePointer src, @StdString @Cast({"char*", "std::string*"}) BytePointer dest);

// Returns the DebugString when available, or a stub message otherwise. Useful
// for messages that are incompatible with proto_text (e.g. those using Any).
// #ifdef TENSORFLOW_LITE_PROTOS
// #else
// #endif  // defined(TENSORFLOW_LITE_PROTOS)

// Utility for parsing an Any value with full or lite protos.

  // namespace tensorflow

// #endif  // TENSORFLOW_PLATFORM_PROTOBUF_H_


// Parsed from tensorflow/core/platform/file_system.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_PLATFORM_FILE_SYSTEM_H_
// #define TENSORFLOW_CORE_PLATFORM_FILE_SYSTEM_H_

// #include <stdint.h>
// #include <functional>
// #include <string>
// #include <unordered_map>
// #include <vector>
// #include "tensorflow/core/lib/core/errors.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/platform/file_statistics.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/protobuf.h"
// #include "tensorflow/core/platform/types.h"

/** A generic interface for accessing a file system. */
@Namespace("tensorflow") public static class FileSystem extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public FileSystem(Pointer p) { super(p); }


  /** The following functions are the implementations used by the corresponding
   *  functions in the Env class. */
  public native @ByVal Status NewRandomAccessFile(
        @StdString BytePointer fname, @UniquePtr RandomAccessFile result);
  public native @ByVal Status NewRandomAccessFile(
        @StdString String fname, @UniquePtr RandomAccessFile result);

  public native @ByVal Status NewWritableFile(@StdString BytePointer fname,
                                   @UniquePtr WritableFile result);
  public native @ByVal Status NewWritableFile(@StdString String fname,
                                   @UniquePtr WritableFile result);

  public native @ByVal Status NewAppendableFile(@StdString BytePointer fname,
                                     @UniquePtr WritableFile result);
  public native @ByVal Status NewAppendableFile(@StdString String fname,
                                     @UniquePtr WritableFile result);

  public native @ByVal Status NewReadOnlyMemoryRegionFromFile(
        @StdString BytePointer fname, @UniquePtr ReadOnlyMemoryRegion result);
  public native @ByVal Status NewReadOnlyMemoryRegionFromFile(
        @StdString String fname, @UniquePtr ReadOnlyMemoryRegion result);

  
  ///
  public native @Cast("bool") boolean FileExists(@StdString BytePointer fname);
  public native @Cast("bool") boolean FileExists(@StdString String fname);

  /** \brief Returns the immediate children in the given directory.
   * 
   *  The returned paths are relative to 'dir'. */
  
  ///
  public native @ByVal Status GetChildren(@StdString BytePointer dir,
                               StringVector result);
  public native @ByVal Status GetChildren(@StdString String dir,
                               StringVector result);

  /** \brief Recursively returns all the files in the given directory.
   * 
   *  The returned paths are relative to 'dir'. */
  public native @ByVal Status GetChildrenRecursively(@StdString BytePointer dir,
                                          StringVector result);
  public native @ByVal Status GetChildrenRecursively(@StdString String dir,
                                          StringVector result);

  public native @ByVal Status Stat(@StdString BytePointer fname, FileStatistics stat);
  public native @ByVal Status Stat(@StdString String fname, FileStatistics stat);

  public native @ByVal Status DeleteFile(@StdString BytePointer fname);
  public native @ByVal Status DeleteFile(@StdString String fname);

  public native @ByVal Status CreateDir(@StdString BytePointer dirname);
  public native @ByVal Status CreateDir(@StdString String dirname);

  public native @ByVal Status DeleteDir(@StdString BytePointer dirname);
  public native @ByVal Status DeleteDir(@StdString String dirname);

  public native @ByVal Status GetFileSize(@StdString BytePointer fname, @Cast("tensorflow::uint64*") LongPointer file_size);
  public native @ByVal Status GetFileSize(@StdString String fname, @Cast("tensorflow::uint64*") LongBuffer file_size);
  public native @ByVal Status GetFileSize(@StdString BytePointer fname, @Cast("tensorflow::uint64*") long... file_size);
  public native @ByVal Status GetFileSize(@StdString String fname, @Cast("tensorflow::uint64*") LongPointer file_size);
  public native @ByVal Status GetFileSize(@StdString BytePointer fname, @Cast("tensorflow::uint64*") LongBuffer file_size);
  public native @ByVal Status GetFileSize(@StdString String fname, @Cast("tensorflow::uint64*") long... file_size);

  // Overwrites the target if it exists.
  public native @ByVal Status RenameFile(@StdString BytePointer src, @StdString BytePointer target);
  public native @ByVal Status RenameFile(@StdString String src, @StdString String target);

  // Translate an URI to a filename usable by the FileSystem implementation. The
  // implementation in this class cleans up the path, removing duplicate /'s,
  // resolving .. and . (more details in tensorflow::lib::io::CleanPath).
  public native @StdString BytePointer TranslateName(@StdString BytePointer name);
  public native @StdString String TranslateName(@StdString String name);

  // Returns whether the given path is a directory or not.
  // Typical return codes (not guaranteed exhaustive):
  //  * OK - The path exists and is a directory.
  //  * FAILED_PRECONDITION - The path exists and is not a directory.
  //  * NOT_FOUND - The path entry does not exist.
  //  * PERMISSION_DENIED - Insufficient permissions.
  //  * UNIMPLEMENTED - The file factory doesn't support directories.
  public native @ByVal Status IsDirectory(@StdString BytePointer fname);
  public native @ByVal Status IsDirectory(@StdString String fname);
}

// START_SKIP_DOXYGEN

// #ifndef SWIG
// #endif

// END_SKIP_DOXYGEN

/** A file abstraction for randomly reading the contents of a file. */
@Namespace("tensorflow") public static class RandomAccessFile extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public RandomAccessFile(Pointer p) { super(p); }


  /** \brief Reads up to {@code n} bytes from the file starting at {@code offset}.
   * 
   *  {@code scratch[0..n-1]} may be written by this routine.  Sets {@code *result}
   *  to the data that was read (including if fewer than {@code n} bytes were
   *  successfully read).  May set {@code *result} to point at data in
   *  {@code scratch[0..n-1]}, so {@code scratch[0..n-1]} must be live when
   *  {@code *result} is used.
   * 
   *  On OK returned status: {@code n} bytes have been stored in {@code *result}.
   *  On non-OK returned status: {@code [0..n]} bytes have been stored in {@code *result}.
   * 
   *  Returns {@code OUT_OF_RANGE} if fewer than n bytes were stored in {@code *result}
   *  because of EOF.
   * 
   *  Safe for concurrent use by multiple threads. */
  public native @ByVal Status Read(@Cast("tensorflow::uint64") long offset, @Cast("size_t") long n, @StringPiece BytePointer result,
                        @Cast("char*") BytePointer scratch);
  public native @ByVal Status Read(@Cast("tensorflow::uint64") long offset, @Cast("size_t") long n, @StringPiece BytePointer result,
                        @Cast("char*") ByteBuffer scratch);
  public native @ByVal Status Read(@Cast("tensorflow::uint64") long offset, @Cast("size_t") long n, @StringPiece BytePointer result,
                        @Cast("char*") byte[] scratch);
}

/** \brief A file abstraction for sequential writing.
 * 
 *  The implementation must provide buffering since callers may append
 *  small fragments at a time to the file. */
@Namespace("tensorflow") public static class WritableFile extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public WritableFile(Pointer p) { super(p); }


  public native @ByVal Status Append(@StringPiece BytePointer data);
  public native @ByVal Status Append(@StringPiece String data);
  public native @ByVal Status Close();
  public native @ByVal Status Flush();
  public native @ByVal Status Sync();
}

/** \brief A readonly memmapped file abstraction.
 * 
 *  The implementation must guarantee that all memory is accessable when the
 *  object exists, independently from the Env that created it. */
@Namespace("tensorflow") public static class ReadOnlyMemoryRegion extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ReadOnlyMemoryRegion(Pointer p) { super(p); }

  public native @Const Pointer data();
  public native @Cast("tensorflow::uint64") long length();
}

/** \brief A registry for file system implementations.
 * 
 *  Filenames are specified as an URI, which is of the form
 *  [scheme://]<filename>.
 *  File system implementations are registered using the REGISTER_FILE_SYSTEM
 *  macro, providing the 'scheme' as the key. */
@Namespace("tensorflow") public static class FileSystemRegistry extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public FileSystemRegistry(Pointer p) { super(p); }

  public native @ByVal Status Register(@StdString BytePointer scheme, @ByVal @Cast("tensorflow::FileSystemRegistry::Factory*") Fn factory);
  public native @ByVal Status Register(@StdString String scheme, @ByVal @Cast("tensorflow::FileSystemRegistry::Factory*") Fn factory);
  public native FileSystem Lookup(@StdString BytePointer scheme);
  public native FileSystem Lookup(@StdString String scheme);
  public native @ByVal Status GetRegisteredFileSystemSchemes(
        StringVector schemes);
}

// Populates the scheme, host, and path from a URI.
//
// Corner cases:
// - If the URI is invalid, scheme and host are set to empty strings and the
//   passed string is assumed to be a path
// - If the URI omits the path (e.g. file://host), then the path is left empty.
@Namespace("tensorflow") public static native void ParseURI(@StringPiece BytePointer uri, @StringPiece BytePointer scheme, @StringPiece BytePointer host,
              @StringPiece BytePointer path);
@Namespace("tensorflow") public static native void ParseURI(@StringPiece String uri, @StringPiece BytePointer scheme, @StringPiece BytePointer host,
              @StringPiece BytePointer path);

// Creates a URI from a scheme, host, and path. If the scheme is empty, we just
// return the path.
@Namespace("tensorflow") public static native @StdString BytePointer CreateURI(@StringPiece BytePointer scheme, @StringPiece BytePointer host, @StringPiece BytePointer path);
@Namespace("tensorflow") public static native @StdString String CreateURI(@StringPiece String scheme, @StringPiece String host, @StringPiece String path);

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_PLATFORM_FILE_SYSTEM_H_


// Parsed from tensorflow/core/platform/file_statistics.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef THIRD_PARTY_TENSORFLOW_CORE_PLATFORM_FILE_STATISTICS_H_
// #define THIRD_PARTY_TENSORFLOW_CORE_PLATFORM_FILE_STATISTICS_H_

// #include "tensorflow/core/platform/types.h"

@Namespace("tensorflow") @NoOffset public static class FileStatistics extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public FileStatistics(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public FileStatistics(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public FileStatistics position(long position) {
        return (FileStatistics)super.position(position);
    }

  // The length of the file or -1 if finding file length is not supported.
  public native @Cast("tensorflow::int64") long length(); public native FileStatistics length(long length);
  // The last modified time in nanoseconds.
  public native @Cast("tensorflow::int64") long mtime_nsec(); public native FileStatistics mtime_nsec(long mtime_nsec);
  // True if the file is a directory, otherwise false.
  public native @Cast("bool") boolean is_directory(); public native FileStatistics is_directory(boolean is_directory);

  public FileStatistics() { super((Pointer)null); allocate(); }
  private native void allocate();
}

  // namespace tensorflow

// #endif  // THIRD_PARTY_TENSORFLOW_CORE_PLATFORM_FILE_STATISTICS_H_


// Parsed from tensorflow/core/platform/env.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_PLATFORM_ENV_H_
// #define TENSORFLOW_CORE_PLATFORM_ENV_H_

// #include <stdint.h>
// #include <memory>
// #include <string>
// #include <unordered_map>
// #include <vector>
// #include "tensorflow/core/lib/core/errors.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/platform/file_system.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/mutex.h"
// #include "tensorflow/core/platform/protobuf.h"
// #include "tensorflow/core/platform/types.h"

/** \brief An interface used by the tensorflow implementation to
 *  access operating system functionality like the filesystem etc.
 * 
 *  Callers may wish to provide a custom Env object to get fine grain
 *  control.
 * 
 *  All Env implementations are safe for concurrent access from
 *  multiple threads without any external synchronization. */
@Namespace("tensorflow") @NoOffset public static class Env extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Env(Pointer p) { super(p); }


  /** \brief Returns a default environment suitable for the current operating
   *  system.
   * 
   *  Sophisticated users may wish to provide their own Env
   *  implementation instead of relying on this default environment.
   * 
   *  The result of Default() belongs to this library and must never be deleted. */
  public static native Env Default();

  /** \brief Returns the FileSystem object to handle operations on the file
   *  specified by 'fname'. The FileSystem object is used as the implementation
   *  for the file system related (non-virtual) functions that follow.
   *  Returned FileSystem object is still owned by the Env object and will */
  // (might) be destroyed when the environment is destroyed.
  public native @ByVal Status GetFileSystemForFile(@StdString BytePointer fname, @Cast("tensorflow::FileSystem**") PointerPointer result);
  public native @ByVal Status GetFileSystemForFile(@StdString BytePointer fname, @ByPtrPtr FileSystem result);
  public native @ByVal Status GetFileSystemForFile(@StdString String fname, @ByPtrPtr FileSystem result);

  /** \brief Returns the file system schemes registered for this Env. */
  public native @ByVal Status GetRegisteredFileSystemSchemes(StringVector schemes);

  // \brief Register a file system for a scheme.
  
  ///
  ///
  public native @ByVal Status RegisterFileSystem(@StdString BytePointer scheme,
                                      @ByVal @Cast("tensorflow::FileSystemRegistry::Factory*") Fn factory);
  public native @ByVal Status RegisterFileSystem(@StdString String scheme,
                                      @ByVal @Cast("tensorflow::FileSystemRegistry::Factory*") Fn factory);

  /** \brief Creates a brand new random access read-only file with the
   *  specified name.
   <p>
   *  On success, stores a pointer to the new file in
   *  *result and returns OK.  On failure stores NULL in *result and
   *  returns non-OK.  If the file does not exist, returns a non-OK
   *  status.
   * 
   *  The returned file may be concurrently accessed by multiple threads.
   * 
   *  The ownership of the returned RandomAccessFile is passed to the caller
   *  and the object should be deleted when is not used. The file object
   *  shouldn't live longer than the Env object. */
  
  ///
  ///
  ///
  public native @ByVal Status NewRandomAccessFile(@StdString BytePointer fname,
                               @UniquePtr RandomAccessFile result);
  public native @ByVal Status NewRandomAccessFile(@StdString String fname,
                               @UniquePtr RandomAccessFile result);

  /** \brief Creates an object that writes to a new file with the specified
   *  name.
   * 
   *  Deletes any existing file with the same name and creates a
   *  new file.  On success, stores a pointer to the new file in
   *  *result and returns OK.  On failure stores NULL in *result and
   *  returns non-OK.
   * 
   *  The returned file will only be accessed by one thread at a time.
   * 
   *  The ownership of the returned WritableFile is passed to the caller
   *  and the object should be deleted when is not used. The file object
   *  shouldn't live longer than the Env object. */
  
  ///
  ///
  ///
  public native @ByVal Status NewWritableFile(@StdString BytePointer fname,
                           @UniquePtr WritableFile result);
  public native @ByVal Status NewWritableFile(@StdString String fname,
                           @UniquePtr WritableFile result);

  /** \brief Creates an object that either appends to an existing file, or
   *  writes to a new file (if the file does not exist to begin with).
   * 
   *  On success, stores a pointer to the new file in *result and
   *  returns OK.  On failure stores NULL in *result and returns
   *  non-OK.
   * 
   *  The returned file will only be accessed by one thread at a time.
   * 
   *  The ownership of the returned WritableFile is passed to the caller
   *  and the object should be deleted when is not used. The file object
   *  shouldn't live longer than the Env object. */
  
  ///
  ///
  ///
  public native @ByVal Status NewAppendableFile(@StdString BytePointer fname,
                             @UniquePtr WritableFile result);
  public native @ByVal Status NewAppendableFile(@StdString String fname,
                             @UniquePtr WritableFile result);

  /** \brief Creates a readonly region of memory with the file context.
   * 
   *  On success, it returns a pointer to read-only memory region
   *  from the content of file fname. The ownership of the region is passed to
   *  the caller. On failure stores nullptr in *result and returns non-OK.
   * 
   *  The returned memory region can be accessed from many threads in parallel.
   * 
   *  The ownership of the returned ReadOnlyMemoryRegion is passed to the caller
   *  and the object should be deleted when is not used. The memory region
   *  object shouldn't live longer than the Env object. */
  public native @ByVal Status NewReadOnlyMemoryRegionFromFile(
        @StdString BytePointer fname, @UniquePtr ReadOnlyMemoryRegion result);
  public native @ByVal Status NewReadOnlyMemoryRegionFromFile(
        @StdString String fname, @UniquePtr ReadOnlyMemoryRegion result);

  /** Returns true iff the named file exists. */
  
  ///
  public native @Cast("bool") boolean FileExists(@StdString BytePointer fname);
  public native @Cast("bool") boolean FileExists(@StdString String fname);

  /** \brief Stores in *result the names of the children of the specified
   *  directory. The names are relative to "dir".
   * 
   *  Original contents of *results are dropped. */
  public native @ByVal Status GetChildren(@StdString BytePointer dir, StringVector result);
  public native @ByVal Status GetChildren(@StdString String dir, StringVector result);

  /** \brief Returns true if the path matches the given pattern. The wildcards
   *  allowed in pattern are described below (GetMatchingPaths). */
  
  ///
  ///
  public native @Cast("bool") boolean MatchPath(@StdString BytePointer path, @StdString BytePointer pattern);
  public native @Cast("bool") boolean MatchPath(@StdString String path, @StdString String pattern);

  /** \brief Given a pattern, stores in *results the set of paths that matches
   *  that pattern. *results is cleared.
   * 
   *  pattern must match all of a name, not just a substring. */
  //
  /** pattern: { term }
  /** term:
  /**   '*': matches any sequence of non-'/' characters
  /**   '?': matches a single non-'/' character
  /**   '[' [ '^' ] { match-list } ']':
  /**        matches any single character (not) on the list
  /**   c: matches character c (c != '*', '?', '\\', '[')
  /**   '\\' c: matches character c
  /** character-range:
  /**   c: matches character c (c != '\\', '-', ']')
  /**   '\\' c: matches character c
  /**   lo '-' hi: matches character c for lo <= c <= hi
  /**
  /** Typical return codes
  /**  * OK - no errors
  /**  * UNIMPLEMENTED - Some underlying functions (like GetChildren) are not
  /**                    implemented
  /** The default implementation uses a combination of GetChildren, MatchPath
  /** and IsDirectory. */
  public native @ByVal Status GetMatchingPaths(@StdString BytePointer pattern,
                                    StringVector results);
  public native @ByVal Status GetMatchingPaths(@StdString String pattern,
                                    StringVector results);

  /** Deletes the named file. */
  public native @ByVal Status DeleteFile(@StdString BytePointer fname);
  public native @ByVal Status DeleteFile(@StdString String fname);

  /** \brief Deletes the specified directory and all subdirectories and files
   *  underneath it. undeleted_files and undeleted_dirs stores the number of
   *  files and directories that weren't deleted (unspecified if the return
   *  status is not OK).
   *  REQUIRES: undeleted_files, undeleted_dirs to be not null.
   *  Typical return codes
   *   * OK - dirname exists and we were able to delete everything underneath.
   *   * NOT_FOUND - dirname doesn't exist
   *   * PERMISSION_DENIED - dirname or some descendant is not writable
   *   * UNIMPLEMENTED - Some underlying functions (like Delete) are not
   *                     implemented */
  public native @ByVal Status DeleteRecursively(@StdString BytePointer dirname, @Cast("tensorflow::int64*") LongPointer undeleted_files,
                             @Cast("tensorflow::int64*") LongPointer undeleted_dirs);
  public native @ByVal Status DeleteRecursively(@StdString String dirname, @Cast("tensorflow::int64*") LongBuffer undeleted_files,
                             @Cast("tensorflow::int64*") LongBuffer undeleted_dirs);
  public native @ByVal Status DeleteRecursively(@StdString BytePointer dirname, @Cast("tensorflow::int64*") long[] undeleted_files,
                             @Cast("tensorflow::int64*") long... undeleted_dirs);
  public native @ByVal Status DeleteRecursively(@StdString String dirname, @Cast("tensorflow::int64*") LongPointer undeleted_files,
                             @Cast("tensorflow::int64*") LongPointer undeleted_dirs);
  public native @ByVal Status DeleteRecursively(@StdString BytePointer dirname, @Cast("tensorflow::int64*") LongBuffer undeleted_files,
                             @Cast("tensorflow::int64*") LongBuffer undeleted_dirs);
  public native @ByVal Status DeleteRecursively(@StdString String dirname, @Cast("tensorflow::int64*") long[] undeleted_files,
                             @Cast("tensorflow::int64*") long... undeleted_dirs);

  /** \brief Creates the specified directory and all the necessary
   *  subdirectories. Typical return codes.
   *   * OK - successfully created the directory and sub directories, even if
   *          they were already created.
   *   * PERMISSION_DENIED - dirname or some subdirectory is not writable. */
  public native @ByVal Status RecursivelyCreateDir(@StdString BytePointer dirname);
  public native @ByVal Status RecursivelyCreateDir(@StdString String dirname);

  /** \brief Creates the specified directory. Typical return codes
   *   * OK - successfully created the directory.
   *   * ALREADY_EXISTS - directory already exists.
   *   * PERMISSION_DENIED - dirname is not writable. */
  public native @ByVal Status CreateDir(@StdString BytePointer dirname);
  public native @ByVal Status CreateDir(@StdString String dirname);

  /** Deletes the specified directory. */
  public native @ByVal Status DeleteDir(@StdString BytePointer dirname);
  public native @ByVal Status DeleteDir(@StdString String dirname);

  /** Obtains statistics for the given path. */
  public native @ByVal Status Stat(@StdString BytePointer fname, FileStatistics stat);
  public native @ByVal Status Stat(@StdString String fname, FileStatistics stat);

  /** \brief Returns whether the given path is a directory or not.
   *  Typical return codes (not guaranteed exhaustive):
   *   * OK - The path exists and is a directory.
   *   * FAILED_PRECONDITION - The path exists and is not a directory.
   *   * NOT_FOUND - The path entry does not exist.
   *   * PERMISSION_DENIED - Insufficient permissions.
   *   * UNIMPLEMENTED - The file factory doesn't support directories. */
  public native @ByVal Status IsDirectory(@StdString BytePointer fname);
  public native @ByVal Status IsDirectory(@StdString String fname);

  /** Stores the size of {@code fname} in {@code *file_size}. */
  public native @ByVal Status GetFileSize(@StdString BytePointer fname, @Cast("tensorflow::uint64*") LongPointer file_size);
  public native @ByVal Status GetFileSize(@StdString String fname, @Cast("tensorflow::uint64*") LongBuffer file_size);
  public native @ByVal Status GetFileSize(@StdString BytePointer fname, @Cast("tensorflow::uint64*") long... file_size);
  public native @ByVal Status GetFileSize(@StdString String fname, @Cast("tensorflow::uint64*") LongPointer file_size);
  public native @ByVal Status GetFileSize(@StdString BytePointer fname, @Cast("tensorflow::uint64*") LongBuffer file_size);
  public native @ByVal Status GetFileSize(@StdString String fname, @Cast("tensorflow::uint64*") long... file_size);

  /** \brief Renames file src to target. If target already exists, it will be
   *  replaced. */
  public native @ByVal Status RenameFile(@StdString BytePointer src, @StdString BytePointer target);
  public native @ByVal Status RenameFile(@StdString String src, @StdString String target);

  // TODO(jeff,sanjay): Add back thread/thread-pool support if needed.
  // TODO(jeff,sanjay): if needed, tighten spec so relative to epoch, or
  // provide a routine to get the absolute time.

  /** \brief Returns the number of micro-seconds since some fixed point in
   *  time. Only useful for computing deltas of time. */
  public native @Cast("tensorflow::uint64") long NowMicros();

  /** \brief Returns the number of seconds since some fixed point in
   *  time. Only useful for computing deltas of time. */
  public native @Cast("tensorflow::uint64") long NowSeconds();

  /** Sleeps/delays the thread for the prescribed number of micro-seconds. */
  
  ///
  public native void SleepForMicroseconds(@Cast("tensorflow::int64") long micros);

  /** \brief Returns a new thread that is running fn() and is identified
   *  (for debugging/performance-analysis) by "name".
   * 
   *  Caller takes ownership of the result and must delete it eventually
   *  (the deletion will block until fn() stops running). */
  public native Thread StartThread(@Const @ByRef ThreadOptions thread_options,
                                @StdString BytePointer name,
                                @ByVal Fn fn);
  public native Thread StartThread(@Const @ByRef ThreadOptions thread_options,
                                @StdString String name,
                                @ByVal Fn fn);

  // \brief Schedules the given closure on a thread-pool.
  //
  // NOTE(mrry): This closure may block.
  public native void SchedClosure(@ByVal Fn closure);

  // \brief Schedules the given closure on a thread-pool after the given number
  // of microseconds.
  //
  // NOTE(mrry): This closure must not block.
  public native void SchedClosureAfter(@Cast("tensorflow::int64") long micros,
                                   @ByVal Fn closure);

  // \brief Load a dynamic library.
  //
  // Pass "library_filename" to a platform-specific mechanism for dynamically
  // loading a library.  The rules for determining the exact location of the
  // library are platform-specific and are not documented here.
  //
  // On success, returns a handle to the library in "*handle" and returns
  // OK from the function.
  // Otherwise returns nullptr in "*handle" and an error status from the
  // function.
  public native @ByVal Status LoadLibrary(@Cast("const char*") BytePointer library_filename, @Cast("void**") PointerPointer handle);
  public native @ByVal Status LoadLibrary(@Cast("const char*") BytePointer library_filename, @Cast("void**") @ByPtrPtr Pointer handle);
  public native @ByVal Status LoadLibrary(String library_filename, @Cast("void**") @ByPtrPtr Pointer handle);

  // \brief Get a pointer to a symbol from a dynamic library.
  //
  // "handle" should be a pointer returned from a previous call to LoadLibrary.
  // On success, store a pointer to the located symbol in "*symbol" and return
  // OK from the function. Otherwise, returns nullptr in "*symbol" and an error
  // status from the function.
  public native @ByVal Status GetSymbolFromLibrary(Pointer handle, @Cast("const char*") BytePointer symbol_name,
                                        @Cast("void**") PointerPointer symbol);
  public native @ByVal Status GetSymbolFromLibrary(Pointer handle, @Cast("const char*") BytePointer symbol_name,
                                        @Cast("void**") @ByPtrPtr Pointer symbol);
  public native @ByVal Status GetSymbolFromLibrary(Pointer handle, String symbol_name,
                                        @Cast("void**") @ByPtrPtr Pointer symbol);
}

/** \brief An implementation of Env that forwards all calls to another Env.
 * 
 *  May be useful to clients who wish to override just part of the
 *  functionality of another Env. */
@Namespace("tensorflow") @NoOffset public static class EnvWrapper extends Env {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public EnvWrapper(Pointer p) { super(p); }

  /** Initializes an EnvWrapper that delegates all calls to *t */
  public EnvWrapper(Env t) { super((Pointer)null); allocate(t); }
  private native void allocate(Env t);

  /** Returns the target to which this Env forwards all calls */
  public native Env target();

  public native @ByVal Status GetFileSystemForFile(@StdString BytePointer fname,
                                @Cast("tensorflow::FileSystem**") PointerPointer result);
  public native @ByVal Status GetFileSystemForFile(@StdString BytePointer fname,
                                @ByPtrPtr FileSystem result);
  public native @ByVal Status GetFileSystemForFile(@StdString String fname,
                                @ByPtrPtr FileSystem result);

  public native @ByVal Status GetRegisteredFileSystemSchemes(StringVector schemes);

  public native @ByVal Status RegisterFileSystem(@StdString BytePointer scheme,
                              @ByVal @Cast("tensorflow::FileSystemRegistry::Factory*") Fn factory);
  public native @ByVal Status RegisterFileSystem(@StdString String scheme,
                              @ByVal @Cast("tensorflow::FileSystemRegistry::Factory*") Fn factory);

  public native @Cast("bool") boolean MatchPath(@StdString BytePointer path, @StdString BytePointer pattern);
  public native @Cast("bool") boolean MatchPath(@StdString String path, @StdString String pattern);

  public native @Cast("tensorflow::uint64") long NowMicros();
  public native void SleepForMicroseconds(@Cast("tensorflow::int64") long micros);
  public native Thread StartThread(@Const @ByRef ThreadOptions thread_options, @StdString BytePointer name,
                        @ByVal Fn fn);
  public native Thread StartThread(@Const @ByRef ThreadOptions thread_options, @StdString String name,
                        @ByVal Fn fn);
  public native void SchedClosure(@ByVal Fn closure);
  public native void SchedClosureAfter(@Cast("tensorflow::int64") long micros, @ByVal Fn closure);
  public native @ByVal Status LoadLibrary(@Cast("const char*") BytePointer library_filename, @Cast("void**") PointerPointer handle);
  public native @ByVal Status LoadLibrary(@Cast("const char*") BytePointer library_filename, @Cast("void**") @ByPtrPtr Pointer handle);
  public native @ByVal Status LoadLibrary(String library_filename, @Cast("void**") @ByPtrPtr Pointer handle);
  public native @ByVal Status GetSymbolFromLibrary(Pointer handle, @Cast("const char*") BytePointer symbol_name,
                                @Cast("void**") PointerPointer symbol);
  public native @ByVal Status GetSymbolFromLibrary(Pointer handle, @Cast("const char*") BytePointer symbol_name,
                                @Cast("void**") @ByPtrPtr Pointer symbol);
  public native @ByVal Status GetSymbolFromLibrary(Pointer handle, String symbol_name,
                                @Cast("void**") @ByPtrPtr Pointer symbol);
}

/** Represents a thread used to run a Tensorflow function. */
@Namespace("tensorflow") public static class Thread extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Thread(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public Thread(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public Thread position(long position) {
        return (Thread)super.position(position);
    }

  public Thread() { super((Pointer)null); allocate(); }
  private native void allocate();

  /** Blocks until the thread of control stops running. */
}

/** \brief Options to configure a Thread.
 * 
 *  Note that the options are all hints, and the
 *  underlying implementation may choose to ignore it. */
@Namespace("tensorflow") public static class ThreadOptions extends Pointer {
    static { Loader.load(); }
    /** Default native constructor. */
    public ThreadOptions() { super((Pointer)null); allocate(); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public ThreadOptions(long size) { super((Pointer)null); allocateArray(size); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ThreadOptions(Pointer p) { super(p); }
    private native void allocate();
    private native void allocateArray(long size);
    @Override public ThreadOptions position(long position) {
        return (ThreadOptions)super.position(position);
    }

  /** Thread stack size to use (in bytes). */
  public native @Cast("size_t") long stack_size(); public native ThreadOptions stack_size(long stack_size);  // 0: use system default value
  /** Guard area size to use near thread stacks to use (in bytes) */
  public native @Cast("size_t") long guard_size(); public native ThreadOptions guard_size(long guard_size);  // 0: use system default value
}

/** A utility routine: reads contents of named file into {@code *data} */
@Namespace("tensorflow") public static native @ByVal Status ReadFileToString(Env env, @StdString BytePointer fname, @StdString @Cast({"char*", "std::string*"}) BytePointer data);
@Namespace("tensorflow") public static native @ByVal Status ReadFileToString(Env env, @StdString String fname, @StdString @Cast({"char*", "std::string*"}) BytePointer data);

/** A utility routine: write contents of {@code data} to file named {@code fname}
 *  (overwriting existing contents, if any). */
@Namespace("tensorflow") public static native @ByVal Status WriteStringToFile(Env env, @StdString BytePointer fname,
                         @StringPiece BytePointer data);
@Namespace("tensorflow") public static native @ByVal Status WriteStringToFile(Env env, @StdString String fname,
                         @StringPiece String data);

/** Write binary representation of "proto" to the named file. */
@Namespace("tensorflow") public static native @ByVal Status WriteBinaryProto(Env env, @StdString BytePointer fname,
                        @Cast("const tensorflow::protobuf::MessageLite*") @ByRef Pointer proto);
@Namespace("tensorflow") public static native @ByVal Status WriteBinaryProto(Env env, @StdString String fname,
                        @Cast("const tensorflow::protobuf::MessageLite*") @ByRef Pointer proto);

/** Reads contents of named file and parse as binary encoded proto data
 *  and store into {@code *proto}. */
@Namespace("tensorflow") public static native @ByVal Status ReadBinaryProto(Env env, @StdString BytePointer fname,
                       @Cast("tensorflow::protobuf::MessageLite*") Pointer proto);
@Namespace("tensorflow") public static native @ByVal Status ReadBinaryProto(Env env, @StdString String fname,
                       @Cast("tensorflow::protobuf::MessageLite*") Pointer proto);

// START_SKIP_DOXYGEN

  // namespace register_file_system

// END_SKIP_DOXYGEN

  // namespace tensorflow

// Register a FileSystem implementation for a scheme. Files with names that have
// "scheme://" prefixes are routed to use this implementation.
// #define REGISTER_FILE_SYSTEM_ENV(env, scheme, factory)
//   REGISTER_FILE_SYSTEM_UNIQ_HELPER(__COUNTER__, env, scheme, factory)
// #define REGISTER_FILE_SYSTEM_UNIQ_HELPER(ctr, env, scheme, factory)
//   REGISTER_FILE_SYSTEM_UNIQ(ctr, env, scheme, factory)
// #define REGISTER_FILE_SYSTEM_UNIQ(ctr, env, scheme, factory)
//   static ::tensorflow::register_file_system::Register<factory>
//       register_ff##ctr TF_ATTRIBUTE_UNUSED =
//           ::tensorflow::register_file_system::Register<factory>(env, scheme)

// #define REGISTER_FILE_SYSTEM(scheme, factory)
//   REGISTER_FILE_SYSTEM_ENV(Env::Default(), scheme, factory);

// #endif  // TENSORFLOW_CORE_PLATFORM_ENV_H_


// Parsed from tensorflow/core/protobuf/config.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/protobuf/config.proto

// #ifndef PROTOBUF_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto__INCLUDED
// #define PROTOBUF_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto__INCLUDED

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3000000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3000000 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>
// #include <google/protobuf/extension_set.h>
// #include <google/protobuf/map.h>
// #include <google/protobuf/map_field_inl.h>
// #include <google/protobuf/generated_enum_reflection.h>
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/cost_graph.pb.h"
// #include "tensorflow/core/framework/graph.pb.h"
// #include "tensorflow/core/framework/step_stats.pb.h"
// @@protoc_insertion_point(includes)

// Internal implementation detail -- do not call these.
@Namespace("tensorflow") public static native void protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto();
@Namespace("tensorflow") public static native void protobuf_AssignDesc_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto();
@Namespace("tensorflow") public static native void protobuf_ShutdownFile_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto();

/** enum tensorflow::OptimizerOptions_Level */
public static final int
  OptimizerOptions_Level_L1 = 0,
  OptimizerOptions_Level_L0 = -1,
  OptimizerOptions_Level_OptimizerOptions_Level_INT_MIN_SENTINEL_DO_NOT_USE_ =kint32min,
  OptimizerOptions_Level_OptimizerOptions_Level_INT_MAX_SENTINEL_DO_NOT_USE_ =kint32max;
@Namespace("tensorflow") public static native @Cast("bool") boolean OptimizerOptions_Level_IsValid(int value);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::OptimizerOptions_Level") int OptimizerOptions_Level_Level_MIN();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::OptimizerOptions_Level") int OptimizerOptions_Level_Level_MAX();
@Namespace("tensorflow") @MemberGetter public static native int OptimizerOptions_Level_Level_ARRAYSIZE();

@Namespace("tensorflow") public static native @Cast("const google::protobuf::EnumDescriptor*") Pointer OptimizerOptions_Level_descriptor();
@Namespace("tensorflow") public static native @StdString BytePointer OptimizerOptions_Level_Name(@Cast("tensorflow::OptimizerOptions_Level") int value);
@Namespace("tensorflow") public static native @Cast("bool") boolean OptimizerOptions_Level_Parse(
    @StdString BytePointer name, @Cast("tensorflow::OptimizerOptions_Level*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean OptimizerOptions_Level_Parse(
    @StdString String name, @Cast("tensorflow::OptimizerOptions_Level*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean OptimizerOptions_Level_Parse(
    @StdString BytePointer name, @Cast("tensorflow::OptimizerOptions_Level*") int... value);
@Namespace("tensorflow") public static native @Cast("bool") boolean OptimizerOptions_Level_Parse(
    @StdString String name, @Cast("tensorflow::OptimizerOptions_Level*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean OptimizerOptions_Level_Parse(
    @StdString BytePointer name, @Cast("tensorflow::OptimizerOptions_Level*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean OptimizerOptions_Level_Parse(
    @StdString String name, @Cast("tensorflow::OptimizerOptions_Level*") int... value);
/** enum tensorflow::RunOptions_TraceLevel */
public static final int
  RunOptions_TraceLevel_NO_TRACE = 0,
  RunOptions_TraceLevel_SOFTWARE_TRACE = 1,
  RunOptions_TraceLevel_HARDWARE_TRACE = 2,
  RunOptions_TraceLevel_FULL_TRACE = 3,
  RunOptions_TraceLevel_RunOptions_TraceLevel_INT_MIN_SENTINEL_DO_NOT_USE_ =kint32min,
  RunOptions_TraceLevel_RunOptions_TraceLevel_INT_MAX_SENTINEL_DO_NOT_USE_ =kint32max;
@Namespace("tensorflow") public static native @Cast("bool") boolean RunOptions_TraceLevel_IsValid(int value);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::RunOptions_TraceLevel") int RunOptions_TraceLevel_TraceLevel_MIN();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::RunOptions_TraceLevel") int RunOptions_TraceLevel_TraceLevel_MAX();
@Namespace("tensorflow") @MemberGetter public static native int RunOptions_TraceLevel_TraceLevel_ARRAYSIZE();

@Namespace("tensorflow") public static native @Cast("const google::protobuf::EnumDescriptor*") Pointer RunOptions_TraceLevel_descriptor();
@Namespace("tensorflow") public static native @StdString BytePointer RunOptions_TraceLevel_Name(@Cast("tensorflow::RunOptions_TraceLevel") int value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RunOptions_TraceLevel_Parse(
    @StdString BytePointer name, @Cast("tensorflow::RunOptions_TraceLevel*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RunOptions_TraceLevel_Parse(
    @StdString String name, @Cast("tensorflow::RunOptions_TraceLevel*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RunOptions_TraceLevel_Parse(
    @StdString BytePointer name, @Cast("tensorflow::RunOptions_TraceLevel*") int... value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RunOptions_TraceLevel_Parse(
    @StdString String name, @Cast("tensorflow::RunOptions_TraceLevel*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RunOptions_TraceLevel_Parse(
    @StdString BytePointer name, @Cast("tensorflow::RunOptions_TraceLevel*") IntBuffer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean RunOptions_TraceLevel_Parse(
    @StdString String name, @Cast("tensorflow::RunOptions_TraceLevel*") int... value);
// ===================================================================

@Namespace("tensorflow") @NoOffset public static class GPUOptions extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public GPUOptions(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public GPUOptions(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public GPUOptions position(long position) {
        return (GPUOptions)super.position(position);
    }

  public GPUOptions() { super((Pointer)null); allocate(); }
  private native void allocate();

  public GPUOptions(@Const @ByRef GPUOptions from) { super((Pointer)null); allocate(from); }
  private native void allocate(@Const @ByRef GPUOptions from);

  public native @ByRef @Name("operator =") GPUOptions put(@Const @ByRef GPUOptions from);

  public native @Cast("google::protobuf::Arena*") Pointer GetArena();
  public native Pointer GetMaybeArenaPointer();
  public static native @Cast("const google::protobuf::Descriptor*") Pointer descriptor();
  public static native @Const @ByRef GPUOptions default_instance();

  public native void UnsafeArenaSwap(GPUOptions other);
  public native void Swap(GPUOptions other);

  // implements Message ----------------------------------------------

  public native GPUOptions New();

  public native GPUOptions New(@Cast("google::protobuf::Arena*") Pointer arena);
  public native void CopyFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void MergeFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void CopyFrom(@Const @ByRef GPUOptions from);
  public native void MergeFrom(@Const @ByRef GPUOptions from);
  public native void Clear();
  public native @Cast("bool") boolean IsInitialized();

  public native int ByteSize();
  public native @Cast("bool") boolean MergePartialFromCodedStream(
        @Cast("google::protobuf::io::CodedInputStream*") Pointer input);
  public native void SerializeWithCachedSizes(
        @Cast("google::protobuf::io::CodedOutputStream*") Pointer output);
  public native @Cast("google::protobuf::uint8*") BytePointer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") byte[] output);
  public native @Cast("google::protobuf::uint8*") BytePointer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") byte[] output);
  public native int GetCachedSize();

  public native @ByVal @Cast("google::protobuf::Metadata*") Pointer GetMetadata();

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional double per_process_gpu_memory_fraction = 1;
  public native void clear_per_process_gpu_memory_fraction();
  @MemberGetter public static native int kPerProcessGpuMemoryFractionFieldNumber();
  public static final int kPerProcessGpuMemoryFractionFieldNumber = kPerProcessGpuMemoryFractionFieldNumber();
  public native double per_process_gpu_memory_fraction();
  public native void set_per_process_gpu_memory_fraction(double value);

  // optional string allocator_type = 2;
  public native void clear_allocator_type();
  @MemberGetter public static native int kAllocatorTypeFieldNumber();
  public static final int kAllocatorTypeFieldNumber = kAllocatorTypeFieldNumber();
  public native @StdString BytePointer allocator_type();
  public native void set_allocator_type(@StdString BytePointer value);
  public native void set_allocator_type(@StdString String value);
  public native void set_allocator_type(@Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void set_allocator_type(String value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_allocator_type();
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer release_allocator_type();
  public native void set_allocated_allocator_type(@StdString @Cast({"char*", "std::string*"}) BytePointer allocator_type);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer unsafe_arena_release_allocator_type();
  public native void unsafe_arena_set_allocated_allocator_type(
        @StdString @Cast({"char*", "std::string*"}) BytePointer allocator_type);

  // optional int64 deferred_deletion_bytes = 3;
  public native void clear_deferred_deletion_bytes();
  @MemberGetter public static native int kDeferredDeletionBytesFieldNumber();
  public static final int kDeferredDeletionBytesFieldNumber = kDeferredDeletionBytesFieldNumber();
  public native @Cast("google::protobuf::int64") long deferred_deletion_bytes();
  public native void set_deferred_deletion_bytes(@Cast("google::protobuf::int64") long value);

  // optional bool allow_growth = 4;
  public native void clear_allow_growth();
  @MemberGetter public static native int kAllowGrowthFieldNumber();
  public static final int kAllowGrowthFieldNumber = kAllowGrowthFieldNumber();
  public native @Cast("bool") boolean allow_growth();
  public native void set_allow_growth(@Cast("bool") boolean value);

  // optional string visible_device_list = 5;
  public native void clear_visible_device_list();
  @MemberGetter public static native int kVisibleDeviceListFieldNumber();
  public static final int kVisibleDeviceListFieldNumber = kVisibleDeviceListFieldNumber();
  public native @StdString BytePointer visible_device_list();
  public native void set_visible_device_list(@StdString BytePointer value);
  public native void set_visible_device_list(@StdString String value);
  public native void set_visible_device_list(@Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void set_visible_device_list(String value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_visible_device_list();
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer release_visible_device_list();
  public native void set_allocated_visible_device_list(@StdString @Cast({"char*", "std::string*"}) BytePointer visible_device_list);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer unsafe_arena_release_visible_device_list();
  public native void unsafe_arena_set_allocated_visible_device_list(
        @StdString @Cast({"char*", "std::string*"}) BytePointer visible_device_list);
}
// -------------------------------------------------------------------

@Namespace("tensorflow") @NoOffset public static class OptimizerOptions extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public OptimizerOptions(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public OptimizerOptions(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public OptimizerOptions position(long position) {
        return (OptimizerOptions)super.position(position);
    }

  public OptimizerOptions() { super((Pointer)null); allocate(); }
  private native void allocate();

  public OptimizerOptions(@Const @ByRef OptimizerOptions from) { super((Pointer)null); allocate(from); }
  private native void allocate(@Const @ByRef OptimizerOptions from);

  public native @ByRef @Name("operator =") OptimizerOptions put(@Const @ByRef OptimizerOptions from);

  public native @Cast("google::protobuf::Arena*") Pointer GetArena();
  public native Pointer GetMaybeArenaPointer();
  public static native @Cast("const google::protobuf::Descriptor*") Pointer descriptor();
  public static native @Const @ByRef OptimizerOptions default_instance();

  public native void UnsafeArenaSwap(OptimizerOptions other);
  public native void Swap(OptimizerOptions other);

  // implements Message ----------------------------------------------

  public native OptimizerOptions New();

  public native OptimizerOptions New(@Cast("google::protobuf::Arena*") Pointer arena);
  public native void CopyFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void MergeFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void CopyFrom(@Const @ByRef OptimizerOptions from);
  public native void MergeFrom(@Const @ByRef OptimizerOptions from);
  public native void Clear();
  public native @Cast("bool") boolean IsInitialized();

  public native int ByteSize();
  public native @Cast("bool") boolean MergePartialFromCodedStream(
        @Cast("google::protobuf::io::CodedInputStream*") Pointer input);
  public native void SerializeWithCachedSizes(
        @Cast("google::protobuf::io::CodedOutputStream*") Pointer output);
  public native @Cast("google::protobuf::uint8*") BytePointer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") byte[] output);
  public native @Cast("google::protobuf::uint8*") BytePointer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") byte[] output);
  public native int GetCachedSize();

  public native @ByVal @Cast("google::protobuf::Metadata*") Pointer GetMetadata();

  // nested types ----------------------------------------------------
  @MemberGetter public static native @Cast("const tensorflow::OptimizerOptions::Level") int L1();
  public static final int L1 = L1();
  @MemberGetter public static native @Cast("const tensorflow::OptimizerOptions::Level") int L0();
  public static final int L0 = L0();
  public static native @Cast("bool") boolean Level_IsValid(int value);
  @MemberGetter public static native @Cast("const tensorflow::OptimizerOptions::Level") int Level_MIN();
  public static final int Level_MIN = Level_MIN();
  @MemberGetter public static native @Cast("const tensorflow::OptimizerOptions::Level") int Level_MAX();
  public static final int Level_MAX = Level_MAX();
  @MemberGetter public static native int Level_ARRAYSIZE();
  public static final int Level_ARRAYSIZE = Level_ARRAYSIZE();
  public static native @Cast("const google::protobuf::EnumDescriptor*") Pointer Level_descriptor();
  public static native @StdString BytePointer Level_Name(@Cast("tensorflow::OptimizerOptions::Level") int value);
  public static native @Cast("bool") boolean Level_Parse(@StdString BytePointer name,
        @Cast("tensorflow::OptimizerOptions::Level*") IntPointer value);
  public static native @Cast("bool") boolean Level_Parse(@StdString String name,
        @Cast("tensorflow::OptimizerOptions::Level*") IntBuffer value);
  public static native @Cast("bool") boolean Level_Parse(@StdString BytePointer name,
        @Cast("tensorflow::OptimizerOptions::Level*") int... value);
  public static native @Cast("bool") boolean Level_Parse(@StdString String name,
        @Cast("tensorflow::OptimizerOptions::Level*") IntPointer value);
  public static native @Cast("bool") boolean Level_Parse(@StdString BytePointer name,
        @Cast("tensorflow::OptimizerOptions::Level*") IntBuffer value);
  public static native @Cast("bool") boolean Level_Parse(@StdString String name,
        @Cast("tensorflow::OptimizerOptions::Level*") int... value);

  // accessors -------------------------------------------------------

  // optional bool do_common_subexpression_elimination = 1;
  public native void clear_do_common_subexpression_elimination();
  @MemberGetter public static native int kDoCommonSubexpressionEliminationFieldNumber();
  public static final int kDoCommonSubexpressionEliminationFieldNumber = kDoCommonSubexpressionEliminationFieldNumber();
  public native @Cast("bool") boolean do_common_subexpression_elimination();
  public native void set_do_common_subexpression_elimination(@Cast("bool") boolean value);

  // optional bool do_constant_folding = 2;
  public native void clear_do_constant_folding();
  @MemberGetter public static native int kDoConstantFoldingFieldNumber();
  public static final int kDoConstantFoldingFieldNumber = kDoConstantFoldingFieldNumber();
  public native @Cast("bool") boolean do_constant_folding();
  public native void set_do_constant_folding(@Cast("bool") boolean value);

  // optional bool do_function_inlining = 4;
  public native void clear_do_function_inlining();
  @MemberGetter public static native int kDoFunctionInliningFieldNumber();
  public static final int kDoFunctionInliningFieldNumber = kDoFunctionInliningFieldNumber();
  public native @Cast("bool") boolean do_function_inlining();
  public native void set_do_function_inlining(@Cast("bool") boolean value);

  // optional .tensorflow.OptimizerOptions.Level opt_level = 3;
  public native void clear_opt_level();
  @MemberGetter public static native int kOptLevelFieldNumber();
  public static final int kOptLevelFieldNumber = kOptLevelFieldNumber();
  public native @Cast("tensorflow::OptimizerOptions_Level") int opt_level();
  public native void set_opt_level(@Cast("tensorflow::OptimizerOptions_Level") int value);
}
// -------------------------------------------------------------------

@Namespace("tensorflow") @NoOffset public static class GraphOptions extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public GraphOptions(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public GraphOptions(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public GraphOptions position(long position) {
        return (GraphOptions)super.position(position);
    }

  public GraphOptions() { super((Pointer)null); allocate(); }
  private native void allocate();

  public GraphOptions(@Const @ByRef GraphOptions from) { super((Pointer)null); allocate(from); }
  private native void allocate(@Const @ByRef GraphOptions from);

  public native @ByRef @Name("operator =") GraphOptions put(@Const @ByRef GraphOptions from);

  public native @Cast("google::protobuf::Arena*") Pointer GetArena();
  public native Pointer GetMaybeArenaPointer();
  public static native @Cast("const google::protobuf::Descriptor*") Pointer descriptor();
  public static native @Const @ByRef GraphOptions default_instance();

  public native void UnsafeArenaSwap(GraphOptions other);
  public native void Swap(GraphOptions other);

  // implements Message ----------------------------------------------

  public native GraphOptions New();

  public native GraphOptions New(@Cast("google::protobuf::Arena*") Pointer arena);
  public native void CopyFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void MergeFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void CopyFrom(@Const @ByRef GraphOptions from);
  public native void MergeFrom(@Const @ByRef GraphOptions from);
  public native void Clear();
  public native @Cast("bool") boolean IsInitialized();

  public native int ByteSize();
  public native @Cast("bool") boolean MergePartialFromCodedStream(
        @Cast("google::protobuf::io::CodedInputStream*") Pointer input);
  public native void SerializeWithCachedSizes(
        @Cast("google::protobuf::io::CodedOutputStream*") Pointer output);
  public native @Cast("google::protobuf::uint8*") BytePointer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") byte[] output);
  public native @Cast("google::protobuf::uint8*") BytePointer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") byte[] output);
  public native int GetCachedSize();

  public native @ByVal @Cast("google::protobuf::Metadata*") Pointer GetMetadata();

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional bool enable_recv_scheduling = 2;
  public native void clear_enable_recv_scheduling();
  @MemberGetter public static native int kEnableRecvSchedulingFieldNumber();
  public static final int kEnableRecvSchedulingFieldNumber = kEnableRecvSchedulingFieldNumber();
  public native @Cast("bool") boolean enable_recv_scheduling();
  public native void set_enable_recv_scheduling(@Cast("bool") boolean value);

  // optional .tensorflow.OptimizerOptions optimizer_options = 3;
  public native @Cast("bool") boolean has_optimizer_options();
  public native void clear_optimizer_options();
  @MemberGetter public static native int kOptimizerOptionsFieldNumber();
  public static final int kOptimizerOptionsFieldNumber = kOptimizerOptionsFieldNumber();
  public native @Const @ByRef OptimizerOptions optimizer_options();
  public native OptimizerOptions mutable_optimizer_options();
  public native OptimizerOptions release_optimizer_options();
  public native void set_allocated_optimizer_options(OptimizerOptions optimizer_options);
  public native OptimizerOptions unsafe_arena_release_optimizer_options();
  public native void unsafe_arena_set_allocated_optimizer_options(
        OptimizerOptions optimizer_options);

  // optional int64 build_cost_model = 4;
  public native void clear_build_cost_model();
  @MemberGetter public static native int kBuildCostModelFieldNumber();
  public static final int kBuildCostModelFieldNumber = kBuildCostModelFieldNumber();
  public native @Cast("google::protobuf::int64") long build_cost_model();
  public native void set_build_cost_model(@Cast("google::protobuf::int64") long value);

  // optional bool infer_shapes = 5;
  public native void clear_infer_shapes();
  @MemberGetter public static native int kInferShapesFieldNumber();
  public static final int kInferShapesFieldNumber = kInferShapesFieldNumber();
  public native @Cast("bool") boolean infer_shapes();
  public native void set_infer_shapes(@Cast("bool") boolean value);

  // optional bool place_pruned_graph = 6;
  public native void clear_place_pruned_graph();
  @MemberGetter public static native int kPlacePrunedGraphFieldNumber();
  public static final int kPlacePrunedGraphFieldNumber = kPlacePrunedGraphFieldNumber();
  public native @Cast("bool") boolean place_pruned_graph();
  public native void set_place_pruned_graph(@Cast("bool") boolean value);

  // optional bool enable_bfloat16_sendrecv = 7;
  public native void clear_enable_bfloat16_sendrecv();
  @MemberGetter public static native int kEnableBfloat16SendrecvFieldNumber();
  public static final int kEnableBfloat16SendrecvFieldNumber = kEnableBfloat16SendrecvFieldNumber();
  public native @Cast("bool") boolean enable_bfloat16_sendrecv();
  public native void set_enable_bfloat16_sendrecv(@Cast("bool") boolean value);

  // optional int32 timeline_step = 8;
  public native void clear_timeline_step();
  @MemberGetter public static native int kTimelineStepFieldNumber();
  public static final int kTimelineStepFieldNumber = kTimelineStepFieldNumber();
  public native @Cast("google::protobuf::int32") int timeline_step();
  public native void set_timeline_step(@Cast("google::protobuf::int32") int value);
}
// -------------------------------------------------------------------

@Namespace("tensorflow") @NoOffset public static class ThreadPoolOptionProto extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ThreadPoolOptionProto(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public ThreadPoolOptionProto(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public ThreadPoolOptionProto position(long position) {
        return (ThreadPoolOptionProto)super.position(position);
    }

  public ThreadPoolOptionProto() { super((Pointer)null); allocate(); }
  private native void allocate();

  public ThreadPoolOptionProto(@Const @ByRef ThreadPoolOptionProto from) { super((Pointer)null); allocate(from); }
  private native void allocate(@Const @ByRef ThreadPoolOptionProto from);

  public native @ByRef @Name("operator =") ThreadPoolOptionProto put(@Const @ByRef ThreadPoolOptionProto from);

  public native @Cast("google::protobuf::Arena*") Pointer GetArena();
  public native Pointer GetMaybeArenaPointer();
  public static native @Cast("const google::protobuf::Descriptor*") Pointer descriptor();
  public static native @Const @ByRef ThreadPoolOptionProto default_instance();

  public native void UnsafeArenaSwap(ThreadPoolOptionProto other);
  public native void Swap(ThreadPoolOptionProto other);

  // implements Message ----------------------------------------------

  public native ThreadPoolOptionProto New();

  public native ThreadPoolOptionProto New(@Cast("google::protobuf::Arena*") Pointer arena);
  public native void CopyFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void MergeFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void CopyFrom(@Const @ByRef ThreadPoolOptionProto from);
  public native void MergeFrom(@Const @ByRef ThreadPoolOptionProto from);
  public native void Clear();
  public native @Cast("bool") boolean IsInitialized();

  public native int ByteSize();
  public native @Cast("bool") boolean MergePartialFromCodedStream(
        @Cast("google::protobuf::io::CodedInputStream*") Pointer input);
  public native void SerializeWithCachedSizes(
        @Cast("google::protobuf::io::CodedOutputStream*") Pointer output);
  public native @Cast("google::protobuf::uint8*") BytePointer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") byte[] output);
  public native @Cast("google::protobuf::uint8*") BytePointer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") byte[] output);
  public native int GetCachedSize();

  public native @ByVal @Cast("google::protobuf::Metadata*") Pointer GetMetadata();

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional int32 num_threads = 1;
  public native void clear_num_threads();
  @MemberGetter public static native int kNumThreadsFieldNumber();
  public static final int kNumThreadsFieldNumber = kNumThreadsFieldNumber();
  public native @Cast("google::protobuf::int32") int num_threads();
  public native void set_num_threads(@Cast("google::protobuf::int32") int value);
}
// -------------------------------------------------------------------

@Namespace("tensorflow") @NoOffset public static class ConfigProto extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ConfigProto(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public ConfigProto(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public ConfigProto position(long position) {
        return (ConfigProto)super.position(position);
    }

  public ConfigProto() { super((Pointer)null); allocate(); }
  private native void allocate();

  public ConfigProto(@Const @ByRef ConfigProto from) { super((Pointer)null); allocate(from); }
  private native void allocate(@Const @ByRef ConfigProto from);

  public native @ByRef @Name("operator =") ConfigProto put(@Const @ByRef ConfigProto from);

  public native @Cast("google::protobuf::Arena*") Pointer GetArena();
  public native Pointer GetMaybeArenaPointer();
  public static native @Cast("const google::protobuf::Descriptor*") Pointer descriptor();
  public static native @Const @ByRef ConfigProto default_instance();

  public native void UnsafeArenaSwap(ConfigProto other);
  public native void Swap(ConfigProto other);

  // implements Message ----------------------------------------------

  public native ConfigProto New();

  public native ConfigProto New(@Cast("google::protobuf::Arena*") Pointer arena);
  public native void CopyFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void MergeFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void CopyFrom(@Const @ByRef ConfigProto from);
  public native void MergeFrom(@Const @ByRef ConfigProto from);
  public native void Clear();
  public native @Cast("bool") boolean IsInitialized();

  public native int ByteSize();
  public native @Cast("bool") boolean MergePartialFromCodedStream(
        @Cast("google::protobuf::io::CodedInputStream*") Pointer input);
  public native void SerializeWithCachedSizes(
        @Cast("google::protobuf::io::CodedOutputStream*") Pointer output);
  public native @Cast("google::protobuf::uint8*") BytePointer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") byte[] output);
  public native @Cast("google::protobuf::uint8*") BytePointer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") byte[] output);
  public native int GetCachedSize();

  public native @ByVal @Cast("google::protobuf::Metadata*") Pointer GetMetadata();

  // nested types ----------------------------------------------------


  // accessors -------------------------------------------------------

  // map<string, int32> device_count = 1;
  public native int device_count_size();
  public native void clear_device_count();
  @MemberGetter public static native int kDeviceCountFieldNumber();
  public static final int kDeviceCountFieldNumber = kDeviceCountFieldNumber();

  // optional int32 intra_op_parallelism_threads = 2;
  public native void clear_intra_op_parallelism_threads();
  @MemberGetter public static native int kIntraOpParallelismThreadsFieldNumber();
  public static final int kIntraOpParallelismThreadsFieldNumber = kIntraOpParallelismThreadsFieldNumber();
  public native @Cast("google::protobuf::int32") int intra_op_parallelism_threads();
  public native void set_intra_op_parallelism_threads(@Cast("google::protobuf::int32") int value);

  // optional int32 inter_op_parallelism_threads = 5;
  public native void clear_inter_op_parallelism_threads();
  @MemberGetter public static native int kInterOpParallelismThreadsFieldNumber();
  public static final int kInterOpParallelismThreadsFieldNumber = kInterOpParallelismThreadsFieldNumber();
  public native @Cast("google::protobuf::int32") int inter_op_parallelism_threads();
  public native void set_inter_op_parallelism_threads(@Cast("google::protobuf::int32") int value);

  // optional bool use_per_session_threads = 9;
  public native void clear_use_per_session_threads();
  @MemberGetter public static native int kUsePerSessionThreadsFieldNumber();
  public static final int kUsePerSessionThreadsFieldNumber = kUsePerSessionThreadsFieldNumber();
  public native @Cast("bool") boolean use_per_session_threads();
  public native void set_use_per_session_threads(@Cast("bool") boolean value);

  // repeated .tensorflow.ThreadPoolOptionProto session_inter_op_thread_pool = 12;
  public native int session_inter_op_thread_pool_size();
  public native void clear_session_inter_op_thread_pool();
  @MemberGetter public static native int kSessionInterOpThreadPoolFieldNumber();
  public static final int kSessionInterOpThreadPoolFieldNumber = kSessionInterOpThreadPoolFieldNumber();
  public native @Const @ByRef ThreadPoolOptionProto session_inter_op_thread_pool(int index);
  public native ThreadPoolOptionProto mutable_session_inter_op_thread_pool(int index);
  public native ThreadPoolOptionProto add_session_inter_op_thread_pool();

  // optional int32 placement_period = 3;
  public native void clear_placement_period();
  @MemberGetter public static native int kPlacementPeriodFieldNumber();
  public static final int kPlacementPeriodFieldNumber = kPlacementPeriodFieldNumber();
  public native @Cast("google::protobuf::int32") int placement_period();
  public native void set_placement_period(@Cast("google::protobuf::int32") int value);

  // repeated string device_filters = 4;
  public native int device_filters_size();
  public native void clear_device_filters();
  @MemberGetter public static native int kDeviceFiltersFieldNumber();
  public static final int kDeviceFiltersFieldNumber = kDeviceFiltersFieldNumber();
  public native @StdString BytePointer device_filters(int index);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_device_filters(int index);
  public native void set_device_filters(int index, @StdString BytePointer value);
  public native void set_device_filters(int index, @StdString String value);
  public native void set_device_filters(int index, @Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void set_device_filters(int index, String value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer add_device_filters();
  public native void add_device_filters(@StdString BytePointer value);
  public native void add_device_filters(@StdString String value);
  public native void add_device_filters(@Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void add_device_filters(String value, @Cast("size_t") long size);

  // optional .tensorflow.GPUOptions gpu_options = 6;
  public native @Cast("bool") boolean has_gpu_options();
  public native void clear_gpu_options();
  @MemberGetter public static native int kGpuOptionsFieldNumber();
  public static final int kGpuOptionsFieldNumber = kGpuOptionsFieldNumber();
  public native @Const @ByRef GPUOptions gpu_options();
  public native GPUOptions mutable_gpu_options();
  public native GPUOptions release_gpu_options();
  public native void set_allocated_gpu_options(GPUOptions gpu_options);
  public native GPUOptions unsafe_arena_release_gpu_options();
  public native void unsafe_arena_set_allocated_gpu_options(
        GPUOptions gpu_options);

  // optional bool allow_soft_placement = 7;
  public native void clear_allow_soft_placement();
  @MemberGetter public static native int kAllowSoftPlacementFieldNumber();
  public static final int kAllowSoftPlacementFieldNumber = kAllowSoftPlacementFieldNumber();
  public native @Cast("bool") boolean allow_soft_placement();
  public native void set_allow_soft_placement(@Cast("bool") boolean value);

  // optional bool log_device_placement = 8;
  public native void clear_log_device_placement();
  @MemberGetter public static native int kLogDevicePlacementFieldNumber();
  public static final int kLogDevicePlacementFieldNumber = kLogDevicePlacementFieldNumber();
  public native @Cast("bool") boolean log_device_placement();
  public native void set_log_device_placement(@Cast("bool") boolean value);

  // optional .tensorflow.GraphOptions graph_options = 10;
  public native @Cast("bool") boolean has_graph_options();
  public native void clear_graph_options();
  @MemberGetter public static native int kGraphOptionsFieldNumber();
  public static final int kGraphOptionsFieldNumber = kGraphOptionsFieldNumber();
  public native @Const @ByRef GraphOptions graph_options();
  public native GraphOptions mutable_graph_options();
  public native GraphOptions release_graph_options();
  public native void set_allocated_graph_options(GraphOptions graph_options);
  public native GraphOptions unsafe_arena_release_graph_options();
  public native void unsafe_arena_set_allocated_graph_options(
        GraphOptions graph_options);

  // optional int64 operation_timeout_in_ms = 11;
  public native void clear_operation_timeout_in_ms();
  @MemberGetter public static native int kOperationTimeoutInMsFieldNumber();
  public static final int kOperationTimeoutInMsFieldNumber = kOperationTimeoutInMsFieldNumber();
  public native @Cast("google::protobuf::int64") long operation_timeout_in_ms();
  public native void set_operation_timeout_in_ms(@Cast("google::protobuf::int64") long value);
}
// -------------------------------------------------------------------

@Namespace("tensorflow") @NoOffset public static class DebugTensorWatch extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public DebugTensorWatch(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public DebugTensorWatch(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public DebugTensorWatch position(long position) {
        return (DebugTensorWatch)super.position(position);
    }

  public DebugTensorWatch() { super((Pointer)null); allocate(); }
  private native void allocate();

  public DebugTensorWatch(@Const @ByRef DebugTensorWatch from) { super((Pointer)null); allocate(from); }
  private native void allocate(@Const @ByRef DebugTensorWatch from);

  public native @ByRef @Name("operator =") DebugTensorWatch put(@Const @ByRef DebugTensorWatch from);

  public native @Cast("google::protobuf::Arena*") Pointer GetArena();
  public native Pointer GetMaybeArenaPointer();
  public static native @Cast("const google::protobuf::Descriptor*") Pointer descriptor();
  public static native @Const @ByRef DebugTensorWatch default_instance();

  public native void UnsafeArenaSwap(DebugTensorWatch other);
  public native void Swap(DebugTensorWatch other);

  // implements Message ----------------------------------------------

  public native DebugTensorWatch New();

  public native DebugTensorWatch New(@Cast("google::protobuf::Arena*") Pointer arena);
  public native void CopyFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void MergeFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void CopyFrom(@Const @ByRef DebugTensorWatch from);
  public native void MergeFrom(@Const @ByRef DebugTensorWatch from);
  public native void Clear();
  public native @Cast("bool") boolean IsInitialized();

  public native int ByteSize();
  public native @Cast("bool") boolean MergePartialFromCodedStream(
        @Cast("google::protobuf::io::CodedInputStream*") Pointer input);
  public native void SerializeWithCachedSizes(
        @Cast("google::protobuf::io::CodedOutputStream*") Pointer output);
  public native @Cast("google::protobuf::uint8*") BytePointer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") byte[] output);
  public native @Cast("google::protobuf::uint8*") BytePointer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") byte[] output);
  public native int GetCachedSize();

  public native @ByVal @Cast("google::protobuf::Metadata*") Pointer GetMetadata();

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional string node_name = 1;
  public native void clear_node_name();
  @MemberGetter public static native int kNodeNameFieldNumber();
  public static final int kNodeNameFieldNumber = kNodeNameFieldNumber();
  public native @StdString BytePointer node_name();
  public native void set_node_name(@StdString BytePointer value);
  public native void set_node_name(@StdString String value);
  public native void set_node_name(@Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void set_node_name(String value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_node_name();
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer release_node_name();
  public native void set_allocated_node_name(@StdString @Cast({"char*", "std::string*"}) BytePointer node_name);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer unsafe_arena_release_node_name();
  public native void unsafe_arena_set_allocated_node_name(
        @StdString @Cast({"char*", "std::string*"}) BytePointer node_name);

  // optional int32 output_slot = 2;
  public native void clear_output_slot();
  @MemberGetter public static native int kOutputSlotFieldNumber();
  public static final int kOutputSlotFieldNumber = kOutputSlotFieldNumber();
  public native @Cast("google::protobuf::int32") int output_slot();
  public native void set_output_slot(@Cast("google::protobuf::int32") int value);

  // repeated string debug_ops = 3;
  public native int debug_ops_size();
  public native void clear_debug_ops();
  @MemberGetter public static native int kDebugOpsFieldNumber();
  public static final int kDebugOpsFieldNumber = kDebugOpsFieldNumber();
  public native @StdString BytePointer debug_ops(int index);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_debug_ops(int index);
  public native void set_debug_ops(int index, @StdString BytePointer value);
  public native void set_debug_ops(int index, @StdString String value);
  public native void set_debug_ops(int index, @Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void set_debug_ops(int index, String value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer add_debug_ops();
  public native void add_debug_ops(@StdString BytePointer value);
  public native void add_debug_ops(@StdString String value);
  public native void add_debug_ops(@Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void add_debug_ops(String value, @Cast("size_t") long size);

  // repeated string debug_urls = 4;
  public native int debug_urls_size();
  public native void clear_debug_urls();
  @MemberGetter public static native int kDebugUrlsFieldNumber();
  public static final int kDebugUrlsFieldNumber = kDebugUrlsFieldNumber();
  public native @StdString BytePointer debug_urls(int index);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_debug_urls(int index);
  public native void set_debug_urls(int index, @StdString BytePointer value);
  public native void set_debug_urls(int index, @StdString String value);
  public native void set_debug_urls(int index, @Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void set_debug_urls(int index, String value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer add_debug_urls();
  public native void add_debug_urls(@StdString BytePointer value);
  public native void add_debug_urls(@StdString String value);
  public native void add_debug_urls(@Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void add_debug_urls(String value, @Cast("size_t") long size);
}
// -------------------------------------------------------------------

@Namespace("tensorflow") @NoOffset public static class RunOptions extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public RunOptions(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public RunOptions(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public RunOptions position(long position) {
        return (RunOptions)super.position(position);
    }

  public RunOptions() { super((Pointer)null); allocate(); }
  private native void allocate();

  public RunOptions(@Const @ByRef RunOptions from) { super((Pointer)null); allocate(from); }
  private native void allocate(@Const @ByRef RunOptions from);

  public native @ByRef @Name("operator =") RunOptions put(@Const @ByRef RunOptions from);

  public native @Cast("google::protobuf::Arena*") Pointer GetArena();
  public native Pointer GetMaybeArenaPointer();
  public static native @Cast("const google::protobuf::Descriptor*") Pointer descriptor();
  public static native @Const @ByRef RunOptions default_instance();

  public native void UnsafeArenaSwap(RunOptions other);
  public native void Swap(RunOptions other);

  // implements Message ----------------------------------------------

  public native RunOptions New();

  public native RunOptions New(@Cast("google::protobuf::Arena*") Pointer arena);
  public native void CopyFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void MergeFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void CopyFrom(@Const @ByRef RunOptions from);
  public native void MergeFrom(@Const @ByRef RunOptions from);
  public native void Clear();
  public native @Cast("bool") boolean IsInitialized();

  public native int ByteSize();
  public native @Cast("bool") boolean MergePartialFromCodedStream(
        @Cast("google::protobuf::io::CodedInputStream*") Pointer input);
  public native void SerializeWithCachedSizes(
        @Cast("google::protobuf::io::CodedOutputStream*") Pointer output);
  public native @Cast("google::protobuf::uint8*") BytePointer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") byte[] output);
  public native @Cast("google::protobuf::uint8*") BytePointer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") byte[] output);
  public native int GetCachedSize();

  public native @ByVal @Cast("google::protobuf::Metadata*") Pointer GetMetadata();

  // nested types ----------------------------------------------------
  @MemberGetter public static native @Cast("const tensorflow::RunOptions::TraceLevel") int NO_TRACE();
  public static final int NO_TRACE = NO_TRACE();
  @MemberGetter public static native @Cast("const tensorflow::RunOptions::TraceLevel") int SOFTWARE_TRACE();
  public static final int SOFTWARE_TRACE = SOFTWARE_TRACE();
  @MemberGetter public static native @Cast("const tensorflow::RunOptions::TraceLevel") int HARDWARE_TRACE();
  public static final int HARDWARE_TRACE = HARDWARE_TRACE();
  @MemberGetter public static native @Cast("const tensorflow::RunOptions::TraceLevel") int FULL_TRACE();
  public static final int FULL_TRACE = FULL_TRACE();
  public static native @Cast("bool") boolean TraceLevel_IsValid(int value);
  @MemberGetter public static native @Cast("const tensorflow::RunOptions::TraceLevel") int TraceLevel_MIN();
  public static final int TraceLevel_MIN = TraceLevel_MIN();
  @MemberGetter public static native @Cast("const tensorflow::RunOptions::TraceLevel") int TraceLevel_MAX();
  public static final int TraceLevel_MAX = TraceLevel_MAX();
  @MemberGetter public static native int TraceLevel_ARRAYSIZE();
  public static final int TraceLevel_ARRAYSIZE = TraceLevel_ARRAYSIZE();
  public static native @Cast("const google::protobuf::EnumDescriptor*") Pointer TraceLevel_descriptor();
  public static native @StdString BytePointer TraceLevel_Name(@Cast("tensorflow::RunOptions::TraceLevel") int value);
  public static native @Cast("bool") boolean TraceLevel_Parse(@StdString BytePointer name,
        @Cast("tensorflow::RunOptions::TraceLevel*") IntPointer value);
  public static native @Cast("bool") boolean TraceLevel_Parse(@StdString String name,
        @Cast("tensorflow::RunOptions::TraceLevel*") IntBuffer value);
  public static native @Cast("bool") boolean TraceLevel_Parse(@StdString BytePointer name,
        @Cast("tensorflow::RunOptions::TraceLevel*") int... value);
  public static native @Cast("bool") boolean TraceLevel_Parse(@StdString String name,
        @Cast("tensorflow::RunOptions::TraceLevel*") IntPointer value);
  public static native @Cast("bool") boolean TraceLevel_Parse(@StdString BytePointer name,
        @Cast("tensorflow::RunOptions::TraceLevel*") IntBuffer value);
  public static native @Cast("bool") boolean TraceLevel_Parse(@StdString String name,
        @Cast("tensorflow::RunOptions::TraceLevel*") int... value);

  // accessors -------------------------------------------------------

  // optional .tensorflow.RunOptions.TraceLevel trace_level = 1;
  public native void clear_trace_level();
  @MemberGetter public static native int kTraceLevelFieldNumber();
  public static final int kTraceLevelFieldNumber = kTraceLevelFieldNumber();
  public native @Cast("tensorflow::RunOptions_TraceLevel") int trace_level();
  public native void set_trace_level(@Cast("tensorflow::RunOptions_TraceLevel") int value);

  // optional int64 timeout_in_ms = 2;
  public native void clear_timeout_in_ms();
  @MemberGetter public static native int kTimeoutInMsFieldNumber();
  public static final int kTimeoutInMsFieldNumber = kTimeoutInMsFieldNumber();
  public native @Cast("google::protobuf::int64") long timeout_in_ms();
  public native void set_timeout_in_ms(@Cast("google::protobuf::int64") long value);

  // optional int32 inter_op_thread_pool = 3;
  public native void clear_inter_op_thread_pool();
  @MemberGetter public static native int kInterOpThreadPoolFieldNumber();
  public static final int kInterOpThreadPoolFieldNumber = kInterOpThreadPoolFieldNumber();
  public native @Cast("google::protobuf::int32") int inter_op_thread_pool();
  public native void set_inter_op_thread_pool(@Cast("google::protobuf::int32") int value);

  // repeated .tensorflow.DebugTensorWatch debug_tensor_watch_opts = 4;
  public native int debug_tensor_watch_opts_size();
  public native void clear_debug_tensor_watch_opts();
  @MemberGetter public static native int kDebugTensorWatchOptsFieldNumber();
  public static final int kDebugTensorWatchOptsFieldNumber = kDebugTensorWatchOptsFieldNumber();
  public native @Const @ByRef DebugTensorWatch debug_tensor_watch_opts(int index);
  public native DebugTensorWatch mutable_debug_tensor_watch_opts(int index);
  public native DebugTensorWatch add_debug_tensor_watch_opts();

  // optional bool output_partition_graphs = 5;
  public native void clear_output_partition_graphs();
  @MemberGetter public static native int kOutputPartitionGraphsFieldNumber();
  public static final int kOutputPartitionGraphsFieldNumber = kOutputPartitionGraphsFieldNumber();
  public native @Cast("bool") boolean output_partition_graphs();
  public native void set_output_partition_graphs(@Cast("bool") boolean value);
}
// -------------------------------------------------------------------

@Namespace("tensorflow") @NoOffset public static class RunMetadata extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public RunMetadata(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public RunMetadata(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public RunMetadata position(long position) {
        return (RunMetadata)super.position(position);
    }

  public RunMetadata() { super((Pointer)null); allocate(); }
  private native void allocate();

  public RunMetadata(@Const @ByRef RunMetadata from) { super((Pointer)null); allocate(from); }
  private native void allocate(@Const @ByRef RunMetadata from);

  public native @ByRef @Name("operator =") RunMetadata put(@Const @ByRef RunMetadata from);

  public native @Cast("google::protobuf::Arena*") Pointer GetArena();
  public native Pointer GetMaybeArenaPointer();
  public static native @Cast("const google::protobuf::Descriptor*") Pointer descriptor();
  public static native @Const @ByRef RunMetadata default_instance();

  public native void UnsafeArenaSwap(RunMetadata other);
  public native void Swap(RunMetadata other);

  // implements Message ----------------------------------------------

  public native RunMetadata New();

  public native RunMetadata New(@Cast("google::protobuf::Arena*") Pointer arena);
  public native void CopyFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void MergeFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void CopyFrom(@Const @ByRef RunMetadata from);
  public native void MergeFrom(@Const @ByRef RunMetadata from);
  public native void Clear();
  public native @Cast("bool") boolean IsInitialized();

  public native int ByteSize();
  public native @Cast("bool") boolean MergePartialFromCodedStream(
        @Cast("google::protobuf::io::CodedInputStream*") Pointer input);
  public native void SerializeWithCachedSizes(
        @Cast("google::protobuf::io::CodedOutputStream*") Pointer output);
  public native @Cast("google::protobuf::uint8*") BytePointer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") byte[] output);
  public native @Cast("google::protobuf::uint8*") BytePointer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") byte[] output);
  public native int GetCachedSize();

  public native @ByVal @Cast("google::protobuf::Metadata*") Pointer GetMetadata();

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .tensorflow.StepStats step_stats = 1;
  public native @Cast("bool") boolean has_step_stats();
  public native void clear_step_stats();
  @MemberGetter public static native int kStepStatsFieldNumber();
  public static final int kStepStatsFieldNumber = kStepStatsFieldNumber();
  public native @Const @ByRef StepStats step_stats();
  public native StepStats mutable_step_stats();
  public native StepStats release_step_stats();
  public native void set_allocated_step_stats(StepStats step_stats);
  public native StepStats unsafe_arena_release_step_stats();
  public native void unsafe_arena_set_allocated_step_stats(
        StepStats step_stats);

  // optional .tensorflow.CostGraphDef cost_graph = 2;
  public native @Cast("bool") boolean has_cost_graph();
  public native void clear_cost_graph();
  @MemberGetter public static native int kCostGraphFieldNumber();
  public static final int kCostGraphFieldNumber = kCostGraphFieldNumber();
  public native @Const @ByRef CostGraphDef cost_graph();
  public native CostGraphDef mutable_cost_graph();
  public native CostGraphDef release_cost_graph();
  public native void set_allocated_cost_graph(CostGraphDef cost_graph);
  public native CostGraphDef unsafe_arena_release_cost_graph();
  public native void unsafe_arena_set_allocated_cost_graph(
        CostGraphDef cost_graph);

  // repeated .tensorflow.GraphDef partition_graphs = 3;
  public native int partition_graphs_size();
  public native void clear_partition_graphs();
  @MemberGetter public static native int kPartitionGraphsFieldNumber();
  public static final int kPartitionGraphsFieldNumber = kPartitionGraphsFieldNumber();
  public native @Const @ByRef GraphDef partition_graphs(int index);
  public native GraphDef mutable_partition_graphs(int index);
  public native GraphDef add_partition_graphs();
}
// ===================================================================


// ===================================================================

// #if !PROTOBUF_INLINE_NOT_IN_HEADERS
// GPUOptions

// optional double per_process_gpu_memory_fraction = 1;




// optional string allocator_type = 2;











// optional int64 deferred_deletion_bytes = 3;




// optional bool allow_growth = 4;




// optional string visible_device_list = 5;











// -------------------------------------------------------------------

// OptimizerOptions

// optional bool do_common_subexpression_elimination = 1;




// optional bool do_constant_folding = 2;




// optional bool do_function_inlining = 4;




// optional .tensorflow.OptimizerOptions.Level opt_level = 3;




// -------------------------------------------------------------------

// GraphOptions

// optional bool enable_recv_scheduling = 2;




// optional .tensorflow.OptimizerOptions optimizer_options = 3;







// optional int64 build_cost_model = 4;




// optional bool infer_shapes = 5;




// optional bool place_pruned_graph = 6;




// optional bool enable_bfloat16_sendrecv = 7;




// optional int32 timeline_step = 8;




// -------------------------------------------------------------------

// ThreadPoolOptionProto

// optional int32 num_threads = 1;




// -------------------------------------------------------------------

// ConfigProto

// map<string, int32> device_count = 1;





// optional int32 intra_op_parallelism_threads = 2;




// optional int32 inter_op_parallelism_threads = 5;




// optional bool use_per_session_threads = 9;




// repeated .tensorflow.ThreadPoolOptionProto session_inter_op_thread_pool = 12;








// optional int32 placement_period = 3;




// repeated string device_filters = 4;














// optional .tensorflow.GPUOptions gpu_options = 6;







// optional bool allow_soft_placement = 7;




// optional bool log_device_placement = 8;




// optional .tensorflow.GraphOptions graph_options = 10;







// optional int64 operation_timeout_in_ms = 11;




// -------------------------------------------------------------------

// DebugTensorWatch

// optional string node_name = 1;











// optional int32 output_slot = 2;




// repeated string debug_ops = 3;














// repeated string debug_urls = 4;














// -------------------------------------------------------------------

// RunOptions

// optional .tensorflow.RunOptions.TraceLevel trace_level = 1;




// optional int64 timeout_in_ms = 2;




// optional int32 inter_op_thread_pool = 3;




// repeated .tensorflow.DebugTensorWatch debug_tensor_watch_opts = 4;








// optional bool output_partition_graphs = 5;




// -------------------------------------------------------------------

// RunMetadata

// optional .tensorflow.StepStats step_stats = 1;







// optional .tensorflow.CostGraphDef cost_graph = 2;







// repeated .tensorflow.GraphDef partition_graphs = 3;








// #endif  // !PROTOBUF_INLINE_NOT_IN_HEADERS
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// #ifndef SWIG
// #endif  // SWIG

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto__INCLUDED


// Parsed from tensorflow/core/framework/cost_graph.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/cost_graph.proto

// #ifndef PROTOBUF_tensorflow_2fcore_2fframework_2fcost_5fgraph_2eproto__INCLUDED
// #define PROTOBUF_tensorflow_2fcore_2fframework_2fcost_5fgraph_2eproto__INCLUDED

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3000000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3000000 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>
// #include <google/protobuf/extension_set.h>
// #include <google/protobuf/unknown_field_set.h>
// @@protoc_insertion_point(includes)

// Internal implementation detail -- do not call these.
@Namespace("tensorflow") public static native void protobuf_AddDesc_tensorflow_2fcore_2fframework_2fcost_5fgraph_2eproto();
@Namespace("tensorflow") public static native void protobuf_AssignDesc_tensorflow_2fcore_2fframework_2fcost_5fgraph_2eproto();
@Namespace("tensorflow") public static native void protobuf_ShutdownFile_tensorflow_2fcore_2fframework_2fcost_5fgraph_2eproto();

// ===================================================================

@Namespace("tensorflow") @NoOffset public static class CostGraphDef_Node_InputInfo extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public CostGraphDef_Node_InputInfo(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public CostGraphDef_Node_InputInfo(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public CostGraphDef_Node_InputInfo position(long position) {
        return (CostGraphDef_Node_InputInfo)super.position(position);
    }

  public CostGraphDef_Node_InputInfo() { super((Pointer)null); allocate(); }
  private native void allocate();

  public CostGraphDef_Node_InputInfo(@Const @ByRef CostGraphDef_Node_InputInfo from) { super((Pointer)null); allocate(from); }
  private native void allocate(@Const @ByRef CostGraphDef_Node_InputInfo from);

  public native @ByRef @Name("operator =") CostGraphDef_Node_InputInfo put(@Const @ByRef CostGraphDef_Node_InputInfo from);

  public native @Cast("google::protobuf::Arena*") Pointer GetArena();
  public native Pointer GetMaybeArenaPointer();
  public static native @Cast("const google::protobuf::Descriptor*") Pointer descriptor();
  public static native @Const @ByRef CostGraphDef_Node_InputInfo default_instance();

  public native void UnsafeArenaSwap(CostGraphDef_Node_InputInfo other);
  public native void Swap(CostGraphDef_Node_InputInfo other);

  // implements Message ----------------------------------------------

  public native CostGraphDef_Node_InputInfo New();

  public native CostGraphDef_Node_InputInfo New(@Cast("google::protobuf::Arena*") Pointer arena);
  public native void CopyFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void MergeFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void CopyFrom(@Const @ByRef CostGraphDef_Node_InputInfo from);
  public native void MergeFrom(@Const @ByRef CostGraphDef_Node_InputInfo from);
  public native void Clear();
  public native @Cast("bool") boolean IsInitialized();

  public native int ByteSize();
  public native @Cast("bool") boolean MergePartialFromCodedStream(
        @Cast("google::protobuf::io::CodedInputStream*") Pointer input);
  public native void SerializeWithCachedSizes(
        @Cast("google::protobuf::io::CodedOutputStream*") Pointer output);
  public native @Cast("google::protobuf::uint8*") BytePointer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") byte[] output);
  public native @Cast("google::protobuf::uint8*") BytePointer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") byte[] output);
  public native int GetCachedSize();

  public native @ByVal @Cast("google::protobuf::Metadata*") Pointer GetMetadata();

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional int32 preceding_node = 1;
  public native void clear_preceding_node();
  @MemberGetter public static native int kPrecedingNodeFieldNumber();
  public static final int kPrecedingNodeFieldNumber = kPrecedingNodeFieldNumber();
  public native @Cast("google::protobuf::int32") int preceding_node();
  public native void set_preceding_node(@Cast("google::protobuf::int32") int value);

  // optional int32 preceding_port = 2;
  public native void clear_preceding_port();
  @MemberGetter public static native int kPrecedingPortFieldNumber();
  public static final int kPrecedingPortFieldNumber = kPrecedingPortFieldNumber();
  public native @Cast("google::protobuf::int32") int preceding_port();
  public native void set_preceding_port(@Cast("google::protobuf::int32") int value);
}
// -------------------------------------------------------------------

@Namespace("tensorflow") @NoOffset public static class CostGraphDef_Node_OutputInfo extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public CostGraphDef_Node_OutputInfo(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public CostGraphDef_Node_OutputInfo(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public CostGraphDef_Node_OutputInfo position(long position) {
        return (CostGraphDef_Node_OutputInfo)super.position(position);
    }

  public CostGraphDef_Node_OutputInfo() { super((Pointer)null); allocate(); }
  private native void allocate();

  public CostGraphDef_Node_OutputInfo(@Const @ByRef CostGraphDef_Node_OutputInfo from) { super((Pointer)null); allocate(from); }
  private native void allocate(@Const @ByRef CostGraphDef_Node_OutputInfo from);

  public native @ByRef @Name("operator =") CostGraphDef_Node_OutputInfo put(@Const @ByRef CostGraphDef_Node_OutputInfo from);

  public native @Cast("google::protobuf::Arena*") Pointer GetArena();
  public native Pointer GetMaybeArenaPointer();
  public static native @Cast("const google::protobuf::Descriptor*") Pointer descriptor();
  public static native @Const @ByRef CostGraphDef_Node_OutputInfo default_instance();

  public native void UnsafeArenaSwap(CostGraphDef_Node_OutputInfo other);
  public native void Swap(CostGraphDef_Node_OutputInfo other);

  // implements Message ----------------------------------------------

  public native CostGraphDef_Node_OutputInfo New();

  public native CostGraphDef_Node_OutputInfo New(@Cast("google::protobuf::Arena*") Pointer arena);
  public native void CopyFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void MergeFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void CopyFrom(@Const @ByRef CostGraphDef_Node_OutputInfo from);
  public native void MergeFrom(@Const @ByRef CostGraphDef_Node_OutputInfo from);
  public native void Clear();
  public native @Cast("bool") boolean IsInitialized();

  public native int ByteSize();
  public native @Cast("bool") boolean MergePartialFromCodedStream(
        @Cast("google::protobuf::io::CodedInputStream*") Pointer input);
  public native void SerializeWithCachedSizes(
        @Cast("google::protobuf::io::CodedOutputStream*") Pointer output);
  public native @Cast("google::protobuf::uint8*") BytePointer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") byte[] output);
  public native @Cast("google::protobuf::uint8*") BytePointer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") byte[] output);
  public native int GetCachedSize();

  public native @ByVal @Cast("google::protobuf::Metadata*") Pointer GetMetadata();

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional int64 size = 1;
  public native void clear_size();
  @MemberGetter public static native int kSizeFieldNumber();
  public static final int kSizeFieldNumber = kSizeFieldNumber();
  public native @Cast("google::protobuf::int64") long size();
  public native void set_size(@Cast("google::protobuf::int64") long value);

  // optional int64 alias_input_port = 2;
  public native void clear_alias_input_port();
  @MemberGetter public static native int kAliasInputPortFieldNumber();
  public static final int kAliasInputPortFieldNumber = kAliasInputPortFieldNumber();
  public native @Cast("google::protobuf::int64") long alias_input_port();
  public native void set_alias_input_port(@Cast("google::protobuf::int64") long value);
}
// -------------------------------------------------------------------

@Namespace("tensorflow") @NoOffset public static class CostGraphDef_Node extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public CostGraphDef_Node(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public CostGraphDef_Node(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public CostGraphDef_Node position(long position) {
        return (CostGraphDef_Node)super.position(position);
    }

  public CostGraphDef_Node() { super((Pointer)null); allocate(); }
  private native void allocate();

  public CostGraphDef_Node(@Const @ByRef CostGraphDef_Node from) { super((Pointer)null); allocate(from); }
  private native void allocate(@Const @ByRef CostGraphDef_Node from);

  public native @ByRef @Name("operator =") CostGraphDef_Node put(@Const @ByRef CostGraphDef_Node from);

  public native @Cast("google::protobuf::Arena*") Pointer GetArena();
  public native Pointer GetMaybeArenaPointer();
  public static native @Cast("const google::protobuf::Descriptor*") Pointer descriptor();
  public static native @Const @ByRef CostGraphDef_Node default_instance();

  public native void UnsafeArenaSwap(CostGraphDef_Node other);
  public native void Swap(CostGraphDef_Node other);

  // implements Message ----------------------------------------------

  public native CostGraphDef_Node New();

  public native CostGraphDef_Node New(@Cast("google::protobuf::Arena*") Pointer arena);
  public native void CopyFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void MergeFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void CopyFrom(@Const @ByRef CostGraphDef_Node from);
  public native void MergeFrom(@Const @ByRef CostGraphDef_Node from);
  public native void Clear();
  public native @Cast("bool") boolean IsInitialized();

  public native int ByteSize();
  public native @Cast("bool") boolean MergePartialFromCodedStream(
        @Cast("google::protobuf::io::CodedInputStream*") Pointer input);
  public native void SerializeWithCachedSizes(
        @Cast("google::protobuf::io::CodedOutputStream*") Pointer output);
  public native @Cast("google::protobuf::uint8*") BytePointer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") byte[] output);
  public native @Cast("google::protobuf::uint8*") BytePointer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") byte[] output);
  public native int GetCachedSize();

  public native @ByVal @Cast("google::protobuf::Metadata*") Pointer GetMetadata();

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional string name = 1;
  public native void clear_name();
  @MemberGetter public static native int kNameFieldNumber();
  public static final int kNameFieldNumber = kNameFieldNumber();
  public native @StdString BytePointer name();
  public native void set_name(@StdString BytePointer value);
  public native void set_name(@StdString String value);
  public native void set_name(@Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void set_name(String value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_name();
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer release_name();
  public native void set_allocated_name(@StdString @Cast({"char*", "std::string*"}) BytePointer name);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer unsafe_arena_release_name();
  public native void unsafe_arena_set_allocated_name(
        @StdString @Cast({"char*", "std::string*"}) BytePointer name);

  // optional string device = 2;
  public native void clear_device();
  @MemberGetter public static native int kDeviceFieldNumber();
  public static final int kDeviceFieldNumber = kDeviceFieldNumber();
  public native @StdString BytePointer device();
  public native void set_device(@StdString BytePointer value);
  public native void set_device(@StdString String value);
  public native void set_device(@Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void set_device(String value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_device();
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer release_device();
  public native void set_allocated_device(@StdString @Cast({"char*", "std::string*"}) BytePointer device);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer unsafe_arena_release_device();
  public native void unsafe_arena_set_allocated_device(
        @StdString @Cast({"char*", "std::string*"}) BytePointer device);

  // optional int32 id = 3;
  public native void clear_id();
  @MemberGetter public static native int kIdFieldNumber();
  public static final int kIdFieldNumber = kIdFieldNumber();
  public native @Cast("google::protobuf::int32") int id();
  public native void set_id(@Cast("google::protobuf::int32") int value);

  // repeated .tensorflow.CostGraphDef.Node.InputInfo input_info = 4;
  public native int input_info_size();
  public native void clear_input_info();
  @MemberGetter public static native int kInputInfoFieldNumber();
  public static final int kInputInfoFieldNumber = kInputInfoFieldNumber();
  public native @Const @ByRef CostGraphDef_Node_InputInfo input_info(int index);
  public native CostGraphDef_Node_InputInfo mutable_input_info(int index);
  public native CostGraphDef_Node_InputInfo add_input_info();

  // repeated .tensorflow.CostGraphDef.Node.OutputInfo output_info = 5;
  public native int output_info_size();
  public native void clear_output_info();
  @MemberGetter public static native int kOutputInfoFieldNumber();
  public static final int kOutputInfoFieldNumber = kOutputInfoFieldNumber();
  public native @Const @ByRef CostGraphDef_Node_OutputInfo output_info(int index);
  public native CostGraphDef_Node_OutputInfo mutable_output_info(int index);
  public native CostGraphDef_Node_OutputInfo add_output_info();

  // optional int64 temporary_memory_size = 6;
  public native void clear_temporary_memory_size();
  @MemberGetter public static native int kTemporaryMemorySizeFieldNumber();
  public static final int kTemporaryMemorySizeFieldNumber = kTemporaryMemorySizeFieldNumber();
  public native @Cast("google::protobuf::int64") long temporary_memory_size();
  public native void set_temporary_memory_size(@Cast("google::protobuf::int64") long value);

  // optional int64 compute_cost = 9;
  public native void clear_compute_cost();
  @MemberGetter public static native int kComputeCostFieldNumber();
  public static final int kComputeCostFieldNumber = kComputeCostFieldNumber();
  public native @Cast("google::protobuf::int64") long compute_cost();
  public native void set_compute_cost(@Cast("google::protobuf::int64") long value);

  // optional bool is_final = 7;
  public native void clear_is_final();
  @MemberGetter public static native int kIsFinalFieldNumber();
  public static final int kIsFinalFieldNumber = kIsFinalFieldNumber();
  public native @Cast("bool") boolean is_final();
  public native void set_is_final(@Cast("bool") boolean value);

  // repeated int32 control_input = 8;
  public native int control_input_size();
  public native void clear_control_input();
  @MemberGetter public static native int kControlInputFieldNumber();
  public static final int kControlInputFieldNumber = kControlInputFieldNumber();
  public native @Cast("google::protobuf::int32") int control_input(int index);
  public native void set_control_input(int index, @Cast("google::protobuf::int32") int value);
  public native void add_control_input(@Cast("google::protobuf::int32") int value);
}
// -------------------------------------------------------------------

@Namespace("tensorflow") @NoOffset public static class CostGraphDef extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public CostGraphDef(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public CostGraphDef(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public CostGraphDef position(long position) {
        return (CostGraphDef)super.position(position);
    }

  public CostGraphDef() { super((Pointer)null); allocate(); }
  private native void allocate();

  public CostGraphDef(@Const @ByRef CostGraphDef from) { super((Pointer)null); allocate(from); }
  private native void allocate(@Const @ByRef CostGraphDef from);

  public native @ByRef @Name("operator =") CostGraphDef put(@Const @ByRef CostGraphDef from);

  public native @Cast("google::protobuf::Arena*") Pointer GetArena();
  public native Pointer GetMaybeArenaPointer();
  public static native @Cast("const google::protobuf::Descriptor*") Pointer descriptor();
  public static native @Const @ByRef CostGraphDef default_instance();

  public native void UnsafeArenaSwap(CostGraphDef other);
  public native void Swap(CostGraphDef other);

  // implements Message ----------------------------------------------

  public native CostGraphDef New();

  public native CostGraphDef New(@Cast("google::protobuf::Arena*") Pointer arena);
  public native void CopyFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void MergeFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void CopyFrom(@Const @ByRef CostGraphDef from);
  public native void MergeFrom(@Const @ByRef CostGraphDef from);
  public native void Clear();
  public native @Cast("bool") boolean IsInitialized();

  public native int ByteSize();
  public native @Cast("bool") boolean MergePartialFromCodedStream(
        @Cast("google::protobuf::io::CodedInputStream*") Pointer input);
  public native void SerializeWithCachedSizes(
        @Cast("google::protobuf::io::CodedOutputStream*") Pointer output);
  public native @Cast("google::protobuf::uint8*") BytePointer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") byte[] output);
  public native @Cast("google::protobuf::uint8*") BytePointer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") byte[] output);
  public native int GetCachedSize();

  public native @ByVal @Cast("google::protobuf::Metadata*") Pointer GetMetadata();

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .tensorflow.CostGraphDef.Node node = 1;
  public native int node_size();
  public native void clear_node();
  @MemberGetter public static native int kNodeFieldNumber();
  public static final int kNodeFieldNumber = kNodeFieldNumber();
  public native @Const @ByRef CostGraphDef_Node node(int index);
  public native CostGraphDef_Node mutable_node(int index);
  public native CostGraphDef_Node add_node();
}
// ===================================================================


// ===================================================================

// #if !PROTOBUF_INLINE_NOT_IN_HEADERS
// CostGraphDef_Node_InputInfo

// optional int32 preceding_node = 1;




// optional int32 preceding_port = 2;




// -------------------------------------------------------------------

// CostGraphDef_Node_OutputInfo

// optional int64 size = 1;




// optional int64 alias_input_port = 2;




// -------------------------------------------------------------------

// CostGraphDef_Node

// optional string name = 1;











// optional string device = 2;











// optional int32 id = 3;




// repeated .tensorflow.CostGraphDef.Node.InputInfo input_info = 4;








// repeated .tensorflow.CostGraphDef.Node.OutputInfo output_info = 5;








// optional int64 temporary_memory_size = 6;




// optional int64 compute_cost = 9;




// optional bool is_final = 7;




// repeated int32 control_input = 8;








// -------------------------------------------------------------------

// CostGraphDef

// repeated .tensorflow.CostGraphDef.Node node = 1;








// #endif  // !PROTOBUF_INLINE_NOT_IN_HEADERS
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_tensorflow_2fcore_2fframework_2fcost_5fgraph_2eproto__INCLUDED


// Parsed from tensorflow/core/framework/step_stats.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/step_stats.proto

// #ifndef PROTOBUF_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto__INCLUDED
// #define PROTOBUF_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto__INCLUDED

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3000000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3000000 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>
// #include <google/protobuf/extension_set.h>
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/allocation_description.pb.h"
// #include "tensorflow/core/framework/tensor_description.pb.h"
// @@protoc_insertion_point(includes)

// Internal implementation detail -- do not call these.
@Namespace("tensorflow") public static native void protobuf_AddDesc_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto();
@Namespace("tensorflow") public static native void protobuf_AssignDesc_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto();
@Namespace("tensorflow") public static native void protobuf_ShutdownFile_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto();

// ===================================================================

@Namespace("tensorflow") @NoOffset public static class AllocatorMemoryUsed extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public AllocatorMemoryUsed(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public AllocatorMemoryUsed(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public AllocatorMemoryUsed position(long position) {
        return (AllocatorMemoryUsed)super.position(position);
    }

  public AllocatorMemoryUsed() { super((Pointer)null); allocate(); }
  private native void allocate();

  public AllocatorMemoryUsed(@Const @ByRef AllocatorMemoryUsed from) { super((Pointer)null); allocate(from); }
  private native void allocate(@Const @ByRef AllocatorMemoryUsed from);

  public native @ByRef @Name("operator =") AllocatorMemoryUsed put(@Const @ByRef AllocatorMemoryUsed from);

  public native @Cast("google::protobuf::Arena*") Pointer GetArena();
  public native Pointer GetMaybeArenaPointer();
  public static native @Cast("const google::protobuf::Descriptor*") Pointer descriptor();
  public static native @Const @ByRef AllocatorMemoryUsed default_instance();

  public native void UnsafeArenaSwap(AllocatorMemoryUsed other);
  public native void Swap(AllocatorMemoryUsed other);

  // implements Message ----------------------------------------------

  public native AllocatorMemoryUsed New();

  public native AllocatorMemoryUsed New(@Cast("google::protobuf::Arena*") Pointer arena);
  public native void CopyFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void MergeFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void CopyFrom(@Const @ByRef AllocatorMemoryUsed from);
  public native void MergeFrom(@Const @ByRef AllocatorMemoryUsed from);
  public native void Clear();
  public native @Cast("bool") boolean IsInitialized();

  public native int ByteSize();
  public native @Cast("bool") boolean MergePartialFromCodedStream(
        @Cast("google::protobuf::io::CodedInputStream*") Pointer input);
  public native void SerializeWithCachedSizes(
        @Cast("google::protobuf::io::CodedOutputStream*") Pointer output);
  public native @Cast("google::protobuf::uint8*") BytePointer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") byte[] output);
  public native @Cast("google::protobuf::uint8*") BytePointer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") byte[] output);
  public native int GetCachedSize();

  public native @ByVal @Cast("google::protobuf::Metadata*") Pointer GetMetadata();

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional string allocator_name = 1;
  public native void clear_allocator_name();
  @MemberGetter public static native int kAllocatorNameFieldNumber();
  public static final int kAllocatorNameFieldNumber = kAllocatorNameFieldNumber();
  public native @StdString BytePointer allocator_name();
  public native void set_allocator_name(@StdString BytePointer value);
  public native void set_allocator_name(@StdString String value);
  public native void set_allocator_name(@Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void set_allocator_name(String value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_allocator_name();
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer release_allocator_name();
  public native void set_allocated_allocator_name(@StdString @Cast({"char*", "std::string*"}) BytePointer allocator_name);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer unsafe_arena_release_allocator_name();
  public native void unsafe_arena_set_allocated_allocator_name(
        @StdString @Cast({"char*", "std::string*"}) BytePointer allocator_name);

  // optional int64 total_bytes = 2;
  public native void clear_total_bytes();
  @MemberGetter public static native int kTotalBytesFieldNumber();
  public static final int kTotalBytesFieldNumber = kTotalBytesFieldNumber();
  public native @Cast("google::protobuf::int64") long total_bytes();
  public native void set_total_bytes(@Cast("google::protobuf::int64") long value);

  // optional int64 peak_bytes = 3;
  public native void clear_peak_bytes();
  @MemberGetter public static native int kPeakBytesFieldNumber();
  public static final int kPeakBytesFieldNumber = kPeakBytesFieldNumber();
  public native @Cast("google::protobuf::int64") long peak_bytes();
  public native void set_peak_bytes(@Cast("google::protobuf::int64") long value);
}
// -------------------------------------------------------------------

@Namespace("tensorflow") @NoOffset public static class NodeOutput extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public NodeOutput(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public NodeOutput(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public NodeOutput position(long position) {
        return (NodeOutput)super.position(position);
    }

  public NodeOutput() { super((Pointer)null); allocate(); }
  private native void allocate();

  public NodeOutput(@Const @ByRef NodeOutput from) { super((Pointer)null); allocate(from); }
  private native void allocate(@Const @ByRef NodeOutput from);

  public native @ByRef @Name("operator =") NodeOutput put(@Const @ByRef NodeOutput from);

  public native @Cast("google::protobuf::Arena*") Pointer GetArena();
  public native Pointer GetMaybeArenaPointer();
  public static native @Cast("const google::protobuf::Descriptor*") Pointer descriptor();
  public static native @Const @ByRef NodeOutput default_instance();

  public native void UnsafeArenaSwap(NodeOutput other);
  public native void Swap(NodeOutput other);

  // implements Message ----------------------------------------------

  public native NodeOutput New();

  public native NodeOutput New(@Cast("google::protobuf::Arena*") Pointer arena);
  public native void CopyFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void MergeFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void CopyFrom(@Const @ByRef NodeOutput from);
  public native void MergeFrom(@Const @ByRef NodeOutput from);
  public native void Clear();
  public native @Cast("bool") boolean IsInitialized();

  public native int ByteSize();
  public native @Cast("bool") boolean MergePartialFromCodedStream(
        @Cast("google::protobuf::io::CodedInputStream*") Pointer input);
  public native void SerializeWithCachedSizes(
        @Cast("google::protobuf::io::CodedOutputStream*") Pointer output);
  public native @Cast("google::protobuf::uint8*") BytePointer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") byte[] output);
  public native @Cast("google::protobuf::uint8*") BytePointer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") byte[] output);
  public native int GetCachedSize();

  public native @ByVal @Cast("google::protobuf::Metadata*") Pointer GetMetadata();

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional int32 slot = 1;
  public native void clear_slot();
  @MemberGetter public static native int kSlotFieldNumber();
  public static final int kSlotFieldNumber = kSlotFieldNumber();
  public native @Cast("google::protobuf::int32") int slot();
  public native void set_slot(@Cast("google::protobuf::int32") int value);

  // optional .tensorflow.TensorDescription tensor_description = 3;
  public native @Cast("bool") boolean has_tensor_description();
  public native void clear_tensor_description();
  @MemberGetter public static native int kTensorDescriptionFieldNumber();
  public static final int kTensorDescriptionFieldNumber = kTensorDescriptionFieldNumber();
  public native @Const @ByRef TensorDescription tensor_description();
  public native TensorDescription mutable_tensor_description();
  public native TensorDescription release_tensor_description();
  public native void set_allocated_tensor_description(TensorDescription tensor_description);
  public native TensorDescription unsafe_arena_release_tensor_description();
  public native void unsafe_arena_set_allocated_tensor_description(
        TensorDescription tensor_description);
}
// -------------------------------------------------------------------

@Namespace("tensorflow") @NoOffset public static class NodeExecStats extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public NodeExecStats(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public NodeExecStats(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public NodeExecStats position(long position) {
        return (NodeExecStats)super.position(position);
    }

  public NodeExecStats() { super((Pointer)null); allocate(); }
  private native void allocate();

  public NodeExecStats(@Const @ByRef NodeExecStats from) { super((Pointer)null); allocate(from); }
  private native void allocate(@Const @ByRef NodeExecStats from);

  public native @ByRef @Name("operator =") NodeExecStats put(@Const @ByRef NodeExecStats from);

  public native @Cast("google::protobuf::Arena*") Pointer GetArena();
  public native Pointer GetMaybeArenaPointer();
  public static native @Cast("const google::protobuf::Descriptor*") Pointer descriptor();
  public static native @Const @ByRef NodeExecStats default_instance();

  public native void UnsafeArenaSwap(NodeExecStats other);
  public native void Swap(NodeExecStats other);

  // implements Message ----------------------------------------------

  public native NodeExecStats New();

  public native NodeExecStats New(@Cast("google::protobuf::Arena*") Pointer arena);
  public native void CopyFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void MergeFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void CopyFrom(@Const @ByRef NodeExecStats from);
  public native void MergeFrom(@Const @ByRef NodeExecStats from);
  public native void Clear();
  public native @Cast("bool") boolean IsInitialized();

  public native int ByteSize();
  public native @Cast("bool") boolean MergePartialFromCodedStream(
        @Cast("google::protobuf::io::CodedInputStream*") Pointer input);
  public native void SerializeWithCachedSizes(
        @Cast("google::protobuf::io::CodedOutputStream*") Pointer output);
  public native @Cast("google::protobuf::uint8*") BytePointer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") byte[] output);
  public native @Cast("google::protobuf::uint8*") BytePointer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") byte[] output);
  public native int GetCachedSize();

  public native @ByVal @Cast("google::protobuf::Metadata*") Pointer GetMetadata();

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional string node_name = 1;
  public native void clear_node_name();
  @MemberGetter public static native int kNodeNameFieldNumber();
  public static final int kNodeNameFieldNumber = kNodeNameFieldNumber();
  public native @StdString BytePointer node_name();
  public native void set_node_name(@StdString BytePointer value);
  public native void set_node_name(@StdString String value);
  public native void set_node_name(@Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void set_node_name(String value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_node_name();
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer release_node_name();
  public native void set_allocated_node_name(@StdString @Cast({"char*", "std::string*"}) BytePointer node_name);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer unsafe_arena_release_node_name();
  public native void unsafe_arena_set_allocated_node_name(
        @StdString @Cast({"char*", "std::string*"}) BytePointer node_name);

  // optional int64 all_start_micros = 2;
  public native void clear_all_start_micros();
  @MemberGetter public static native int kAllStartMicrosFieldNumber();
  public static final int kAllStartMicrosFieldNumber = kAllStartMicrosFieldNumber();
  public native @Cast("google::protobuf::int64") long all_start_micros();
  public native void set_all_start_micros(@Cast("google::protobuf::int64") long value);

  // optional int64 op_start_rel_micros = 3;
  public native void clear_op_start_rel_micros();
  @MemberGetter public static native int kOpStartRelMicrosFieldNumber();
  public static final int kOpStartRelMicrosFieldNumber = kOpStartRelMicrosFieldNumber();
  public native @Cast("google::protobuf::int64") long op_start_rel_micros();
  public native void set_op_start_rel_micros(@Cast("google::protobuf::int64") long value);

  // optional int64 op_end_rel_micros = 4;
  public native void clear_op_end_rel_micros();
  @MemberGetter public static native int kOpEndRelMicrosFieldNumber();
  public static final int kOpEndRelMicrosFieldNumber = kOpEndRelMicrosFieldNumber();
  public native @Cast("google::protobuf::int64") long op_end_rel_micros();
  public native void set_op_end_rel_micros(@Cast("google::protobuf::int64") long value);

  // optional int64 all_end_rel_micros = 5;
  public native void clear_all_end_rel_micros();
  @MemberGetter public static native int kAllEndRelMicrosFieldNumber();
  public static final int kAllEndRelMicrosFieldNumber = kAllEndRelMicrosFieldNumber();
  public native @Cast("google::protobuf::int64") long all_end_rel_micros();
  public native void set_all_end_rel_micros(@Cast("google::protobuf::int64") long value);

  // repeated .tensorflow.AllocatorMemoryUsed memory = 6;
  public native int memory_size();
  public native void clear_memory();
  @MemberGetter public static native int kMemoryFieldNumber();
  public static final int kMemoryFieldNumber = kMemoryFieldNumber();
  public native @Const @ByRef AllocatorMemoryUsed memory(int index);
  public native AllocatorMemoryUsed mutable_memory(int index);
  public native AllocatorMemoryUsed add_memory();

  // repeated .tensorflow.NodeOutput output = 7;
  public native int output_size();
  public native void clear_output();
  @MemberGetter public static native int kOutputFieldNumber();
  public static final int kOutputFieldNumber = kOutputFieldNumber();
  public native @Const @ByRef NodeOutput output(int index);
  public native NodeOutput mutable_output(int index);
  public native NodeOutput add_output();

  // optional string timeline_label = 8;
  public native void clear_timeline_label();
  @MemberGetter public static native int kTimelineLabelFieldNumber();
  public static final int kTimelineLabelFieldNumber = kTimelineLabelFieldNumber();
  public native @StdString BytePointer timeline_label();
  public native void set_timeline_label(@StdString BytePointer value);
  public native void set_timeline_label(@StdString String value);
  public native void set_timeline_label(@Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void set_timeline_label(String value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_timeline_label();
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer release_timeline_label();
  public native void set_allocated_timeline_label(@StdString @Cast({"char*", "std::string*"}) BytePointer timeline_label);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer unsafe_arena_release_timeline_label();
  public native void unsafe_arena_set_allocated_timeline_label(
        @StdString @Cast({"char*", "std::string*"}) BytePointer timeline_label);

  // optional int64 scheduled_micros = 9;
  public native void clear_scheduled_micros();
  @MemberGetter public static native int kScheduledMicrosFieldNumber();
  public static final int kScheduledMicrosFieldNumber = kScheduledMicrosFieldNumber();
  public native @Cast("google::protobuf::int64") long scheduled_micros();
  public native void set_scheduled_micros(@Cast("google::protobuf::int64") long value);

  // optional uint32 thread_id = 10;
  public native void clear_thread_id();
  @MemberGetter public static native int kThreadIdFieldNumber();
  public static final int kThreadIdFieldNumber = kThreadIdFieldNumber();
  public native @Cast("google::protobuf::uint32") int thread_id();
  public native void set_thread_id(@Cast("google::protobuf::uint32") int value);

  // repeated .tensorflow.AllocationDescription referenced_tensor = 11;
  public native int referenced_tensor_size();
  public native void clear_referenced_tensor();
  @MemberGetter public static native int kReferencedTensorFieldNumber();
  public static final int kReferencedTensorFieldNumber = kReferencedTensorFieldNumber();
  public native @Const @ByRef AllocationDescription referenced_tensor(int index);
  public native AllocationDescription mutable_referenced_tensor(int index);
  public native AllocationDescription add_referenced_tensor();
}
// -------------------------------------------------------------------

@Namespace("tensorflow") @NoOffset public static class DeviceStepStats extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public DeviceStepStats(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public DeviceStepStats(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public DeviceStepStats position(long position) {
        return (DeviceStepStats)super.position(position);
    }

  public DeviceStepStats() { super((Pointer)null); allocate(); }
  private native void allocate();

  public DeviceStepStats(@Const @ByRef DeviceStepStats from) { super((Pointer)null); allocate(from); }
  private native void allocate(@Const @ByRef DeviceStepStats from);

  public native @ByRef @Name("operator =") DeviceStepStats put(@Const @ByRef DeviceStepStats from);

  public native @Cast("google::protobuf::Arena*") Pointer GetArena();
  public native Pointer GetMaybeArenaPointer();
  public static native @Cast("const google::protobuf::Descriptor*") Pointer descriptor();
  public static native @Const @ByRef DeviceStepStats default_instance();

  public native void UnsafeArenaSwap(DeviceStepStats other);
  public native void Swap(DeviceStepStats other);

  // implements Message ----------------------------------------------

  public native DeviceStepStats New();

  public native DeviceStepStats New(@Cast("google::protobuf::Arena*") Pointer arena);
  public native void CopyFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void MergeFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void CopyFrom(@Const @ByRef DeviceStepStats from);
  public native void MergeFrom(@Const @ByRef DeviceStepStats from);
  public native void Clear();
  public native @Cast("bool") boolean IsInitialized();

  public native int ByteSize();
  public native @Cast("bool") boolean MergePartialFromCodedStream(
        @Cast("google::protobuf::io::CodedInputStream*") Pointer input);
  public native void SerializeWithCachedSizes(
        @Cast("google::protobuf::io::CodedOutputStream*") Pointer output);
  public native @Cast("google::protobuf::uint8*") BytePointer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") byte[] output);
  public native @Cast("google::protobuf::uint8*") BytePointer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") byte[] output);
  public native int GetCachedSize();

  public native @ByVal @Cast("google::protobuf::Metadata*") Pointer GetMetadata();

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional string device = 1;
  public native void clear_device();
  @MemberGetter public static native int kDeviceFieldNumber();
  public static final int kDeviceFieldNumber = kDeviceFieldNumber();
  public native @StdString BytePointer device();
  public native void set_device(@StdString BytePointer value);
  public native void set_device(@StdString String value);
  public native void set_device(@Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void set_device(String value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_device();
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer release_device();
  public native void set_allocated_device(@StdString @Cast({"char*", "std::string*"}) BytePointer device);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer unsafe_arena_release_device();
  public native void unsafe_arena_set_allocated_device(
        @StdString @Cast({"char*", "std::string*"}) BytePointer device);

  // repeated .tensorflow.NodeExecStats node_stats = 2;
  public native int node_stats_size();
  public native void clear_node_stats();
  @MemberGetter public static native int kNodeStatsFieldNumber();
  public static final int kNodeStatsFieldNumber = kNodeStatsFieldNumber();
  public native @Const @ByRef NodeExecStats node_stats(int index);
  public native NodeExecStats mutable_node_stats(int index);
  public native NodeExecStats add_node_stats();
}
// -------------------------------------------------------------------

@Namespace("tensorflow") @NoOffset public static class StepStats extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public StepStats(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public StepStats(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public StepStats position(long position) {
        return (StepStats)super.position(position);
    }

  public StepStats() { super((Pointer)null); allocate(); }
  private native void allocate();

  public StepStats(@Const @ByRef StepStats from) { super((Pointer)null); allocate(from); }
  private native void allocate(@Const @ByRef StepStats from);

  public native @ByRef @Name("operator =") StepStats put(@Const @ByRef StepStats from);

  public native @Cast("google::protobuf::Arena*") Pointer GetArena();
  public native Pointer GetMaybeArenaPointer();
  public static native @Cast("const google::protobuf::Descriptor*") Pointer descriptor();
  public static native @Const @ByRef StepStats default_instance();

  public native void UnsafeArenaSwap(StepStats other);
  public native void Swap(StepStats other);

  // implements Message ----------------------------------------------

  public native StepStats New();

  public native StepStats New(@Cast("google::protobuf::Arena*") Pointer arena);
  public native void CopyFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void MergeFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void CopyFrom(@Const @ByRef StepStats from);
  public native void MergeFrom(@Const @ByRef StepStats from);
  public native void Clear();
  public native @Cast("bool") boolean IsInitialized();

  public native int ByteSize();
  public native @Cast("bool") boolean MergePartialFromCodedStream(
        @Cast("google::protobuf::io::CodedInputStream*") Pointer input);
  public native void SerializeWithCachedSizes(
        @Cast("google::protobuf::io::CodedOutputStream*") Pointer output);
  public native @Cast("google::protobuf::uint8*") BytePointer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") byte[] output);
  public native @Cast("google::protobuf::uint8*") BytePointer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") byte[] output);
  public native int GetCachedSize();

  public native @ByVal @Cast("google::protobuf::Metadata*") Pointer GetMetadata();

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .tensorflow.DeviceStepStats dev_stats = 1;
  public native int dev_stats_size();
  public native void clear_dev_stats();
  @MemberGetter public static native int kDevStatsFieldNumber();
  public static final int kDevStatsFieldNumber = kDevStatsFieldNumber();
  public native @Const @ByRef DeviceStepStats dev_stats(int index);
  public native DeviceStepStats mutable_dev_stats(int index);
  public native DeviceStepStats add_dev_stats();
}
// ===================================================================


// ===================================================================

// #if !PROTOBUF_INLINE_NOT_IN_HEADERS
// AllocatorMemoryUsed

// optional string allocator_name = 1;











// optional int64 total_bytes = 2;




// optional int64 peak_bytes = 3;




// -------------------------------------------------------------------

// NodeOutput

// optional int32 slot = 1;




// optional .tensorflow.TensorDescription tensor_description = 3;







// -------------------------------------------------------------------

// NodeExecStats

// optional string node_name = 1;











// optional int64 all_start_micros = 2;




// optional int64 op_start_rel_micros = 3;




// optional int64 op_end_rel_micros = 4;




// optional int64 all_end_rel_micros = 5;




// repeated .tensorflow.AllocatorMemoryUsed memory = 6;








// repeated .tensorflow.NodeOutput output = 7;








// optional string timeline_label = 8;











// optional int64 scheduled_micros = 9;




// optional uint32 thread_id = 10;




// repeated .tensorflow.AllocationDescription referenced_tensor = 11;








// -------------------------------------------------------------------

// DeviceStepStats

// optional string device = 1;











// repeated .tensorflow.NodeExecStats node_stats = 2;








// -------------------------------------------------------------------

// StepStats

// repeated .tensorflow.DeviceStepStats dev_stats = 1;








// #endif  // !PROTOBUF_INLINE_NOT_IN_HEADERS
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto__INCLUDED


// Parsed from tensorflow/core/framework/versions.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/versions.proto

// #ifndef PROTOBUF_tensorflow_2fcore_2fframework_2fversions_2eproto__INCLUDED
// #define PROTOBUF_tensorflow_2fcore_2fframework_2fversions_2eproto__INCLUDED

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3000000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3000000 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>
// #include <google/protobuf/extension_set.h>
// #include <google/protobuf/unknown_field_set.h>
// @@protoc_insertion_point(includes)

// Internal implementation detail -- do not call these.
@Namespace("tensorflow") public static native void protobuf_AddDesc_tensorflow_2fcore_2fframework_2fversions_2eproto();
@Namespace("tensorflow") public static native void protobuf_AssignDesc_tensorflow_2fcore_2fframework_2fversions_2eproto();
@Namespace("tensorflow") public static native void protobuf_ShutdownFile_tensorflow_2fcore_2fframework_2fversions_2eproto();

// ===================================================================

@Namespace("tensorflow") @NoOffset public static class VersionDef extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public VersionDef(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public VersionDef(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public VersionDef position(long position) {
        return (VersionDef)super.position(position);
    }

  public VersionDef() { super((Pointer)null); allocate(); }
  private native void allocate();

  public VersionDef(@Const @ByRef VersionDef from) { super((Pointer)null); allocate(from); }
  private native void allocate(@Const @ByRef VersionDef from);

  public native @ByRef @Name("operator =") VersionDef put(@Const @ByRef VersionDef from);

  public native @Cast("google::protobuf::Arena*") Pointer GetArena();
  public native Pointer GetMaybeArenaPointer();
  public static native @Cast("const google::protobuf::Descriptor*") Pointer descriptor();
  public static native @Const @ByRef VersionDef default_instance();

  public native void UnsafeArenaSwap(VersionDef other);
  public native void Swap(VersionDef other);

  // implements Message ----------------------------------------------

  public native VersionDef New();

  public native VersionDef New(@Cast("google::protobuf::Arena*") Pointer arena);
  public native void CopyFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void MergeFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void CopyFrom(@Const @ByRef VersionDef from);
  public native void MergeFrom(@Const @ByRef VersionDef from);
  public native void Clear();
  public native @Cast("bool") boolean IsInitialized();

  public native int ByteSize();
  public native @Cast("bool") boolean MergePartialFromCodedStream(
        @Cast("google::protobuf::io::CodedInputStream*") Pointer input);
  public native void SerializeWithCachedSizes(
        @Cast("google::protobuf::io::CodedOutputStream*") Pointer output);
  public native @Cast("google::protobuf::uint8*") BytePointer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") byte[] output);
  public native @Cast("google::protobuf::uint8*") BytePointer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") byte[] output);
  public native int GetCachedSize();

  public native @ByVal @Cast("google::protobuf::Metadata*") Pointer GetMetadata();

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional int32 producer = 1;
  public native void clear_producer();
  @MemberGetter public static native int kProducerFieldNumber();
  public static final int kProducerFieldNumber = kProducerFieldNumber();
  public native @Cast("google::protobuf::int32") int producer();
  public native void set_producer(@Cast("google::protobuf::int32") int value);

  // optional int32 min_consumer = 2;
  public native void clear_min_consumer();
  @MemberGetter public static native int kMinConsumerFieldNumber();
  public static final int kMinConsumerFieldNumber = kMinConsumerFieldNumber();
  public native @Cast("google::protobuf::int32") int min_consumer();
  public native void set_min_consumer(@Cast("google::protobuf::int32") int value);

  // repeated int32 bad_consumers = 3;
  public native int bad_consumers_size();
  public native void clear_bad_consumers();
  @MemberGetter public static native int kBadConsumersFieldNumber();
  public static final int kBadConsumersFieldNumber = kBadConsumersFieldNumber();
  public native @Cast("google::protobuf::int32") int bad_consumers(int index);
  public native void set_bad_consumers(int index, @Cast("google::protobuf::int32") int value);
  public native void add_bad_consumers(@Cast("google::protobuf::int32") int value);
}
// ===================================================================


// ===================================================================

// #if !PROTOBUF_INLINE_NOT_IN_HEADERS
// VersionDef

// optional int32 producer = 1;




// optional int32 min_consumer = 2;




// repeated int32 bad_consumers = 3;








// #endif  // !PROTOBUF_INLINE_NOT_IN_HEADERS

// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_tensorflow_2fcore_2fframework_2fversions_2eproto__INCLUDED


// Parsed from tensorflow/core/public/session_options.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_PUBLIC_SESSION_OPTIONS_H_
// #define TENSORFLOW_PUBLIC_SESSION_OPTIONS_H_

// #include <string>
// #include "tensorflow/core/platform/types.h"
// #include "tensorflow/core/protobuf/config.pb.h"

/** Configuration information for a Session. */
@Namespace("tensorflow") @NoOffset public static class SessionOptions extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SessionOptions(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public SessionOptions(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public SessionOptions position(long position) {
        return (SessionOptions)super.position(position);
    }

  /** The environment to use. */
  
  ///
  ///
  ///
  ///
  ///
  public native Env env(); public native SessionOptions env(Env env);

  /** \brief The TensorFlow runtime to connect to.
   * 
   *  If 'target' is empty or unspecified, the local TensorFlow runtime
   *  implementation will be used.  Otherwise, the TensorFlow engine
   *  defined by 'target' will be used to perform all computations.
   * 
   *  "target" can be either a single entry or a comma separated list
   *  of entries. Each entry is a resolvable address of the
   *  following format:
   *    local
   *    ip:port
   *    host:port
   *    ... other system-specific formats to identify tasks and jobs ...
   * 
   *  NOTE: at the moment 'local' maps to an in-process service-based
   *  runtime.
   * 
   *  Upon creation, a single session affines itself to one of the
   *  remote processes, with possible load balancing choices when the
   *  "target" resolves to a list of possible processes.
   * 
   *  If the session disconnects from the remote process during its
   *  lifetime, session calls may fail immediately. */
  public native @StdString BytePointer target(); public native SessionOptions target(BytePointer target);

  /** Configuration options. */
  public native @ByRef ConfigProto config(); public native SessionOptions config(ConfigProto config);

  public SessionOptions() { super((Pointer)null); allocate(); }
  private native void allocate();
}

  // end namespace tensorflow

// #endif  // TENSORFLOW_PUBLIC_SESSION_OPTIONS_H_


// Parsed from tensorflow/core/lib/core/threadpool.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_LIB_CORE_THREADPOOL_H_
// #define TENSORFLOW_LIB_CORE_THREADPOOL_H_

// #include <functional>
// #include <memory>
// #include "tensorflow/core/platform/env.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/types.h"

@Namespace("tensorflow::thread") @NoOffset public static class ThreadPool extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ThreadPool(Pointer p) { super(p); }

  // Construct a pool that contains "num_threads" threads with specified "name".
  // env->StartThread() is used to create individual threads.
  //
  // REQUIRES: num_threads > 0
  public ThreadPool(Env env, @StdString BytePointer name, int num_threads) { super((Pointer)null); allocate(env, name, num_threads); }
  private native void allocate(Env env, @StdString BytePointer name, int num_threads);
  public ThreadPool(Env env, @StdString String name, int num_threads) { super((Pointer)null); allocate(env, name, num_threads); }
  private native void allocate(Env env, @StdString String name, int num_threads);

  // Construct a pool that contains "num_threads" threads with specified "name".
  // env->StartThread() is used to create individual threads.
  //
  // REQUIRES: num_threads > 0
  public ThreadPool(Env env, @Const @ByRef ThreadOptions thread_options, @StdString BytePointer name,
               int num_threads) { super((Pointer)null); allocate(env, thread_options, name, num_threads); }
  private native void allocate(Env env, @Const @ByRef ThreadOptions thread_options, @StdString BytePointer name,
               int num_threads);
  public ThreadPool(Env env, @Const @ByRef ThreadOptions thread_options, @StdString String name,
               int num_threads) { super((Pointer)null); allocate(env, thread_options, name, num_threads); }
  private native void allocate(Env env, @Const @ByRef ThreadOptions thread_options, @StdString String name,
               int num_threads);

  // Wait until all scheduled work has finished and then destroy the
  // set of threads.

  // Schedule fn() for execution in the pool of threads.
  public native void Schedule(@ByVal Fn fn);

  // ParallelFor shards the "total" unit of work assuming each unit of work
  // having roughly "cost_per_unit" cost, in cycles. Each unit of work is
  // indexed 0, 1, ..., total - 1. Each shard contains 1 or more units of work
  // and the total cost of each shard is roughly the same.
  //
  // "cost_per_unit" is an estimate of the number of CPU cycles (or nanoseconds
  // if not CPU-bound) to complete a unit of work. Overestimating creates too
  // many shards and CPU time will be dominated by per-shard overhead, such as
  // Context creation. Underestimating may not fully make use of the specified
  // parallelism.
  public native void ParallelFor(@Cast("tensorflow::int64") long total, @Cast("tensorflow::int64") long cost_per_unit,
                     @ByVal ForFn fn);

  // Returns the number of threads in the pool.
  public native int NumThreads();

  // Returns current thread id between 0 and NumThreads() - 1, if called from a
  // thread in the pool. Returns -1 otherwise.
  public native int CurrentThreadId();

  @Opaque public static class Impl extends Pointer {
      /** Empty constructor. Calls {@code super((Pointer)null)}. */
      public Impl() { super((Pointer)null); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Impl(Pointer p) { super(p); }
  }
}

  // namespace thread
  // namespace tensorflow

// #endif  // TENSORFLOW_LIB_CORE_THREADPOOL_H_


// Parsed from tensorflow/core/framework/allocation_description.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/allocation_description.proto

// #ifndef PROTOBUF_tensorflow_2fcore_2fframework_2fallocation_5fdescription_2eproto__INCLUDED
// #define PROTOBUF_tensorflow_2fcore_2fframework_2fallocation_5fdescription_2eproto__INCLUDED

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3000000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3000000 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>
// #include <google/protobuf/extension_set.h>
// #include <google/protobuf/unknown_field_set.h>
// @@protoc_insertion_point(includes)

// Internal implementation detail -- do not call these.
@Namespace("tensorflow") public static native void protobuf_AddDesc_tensorflow_2fcore_2fframework_2fallocation_5fdescription_2eproto();
@Namespace("tensorflow") public static native void protobuf_AssignDesc_tensorflow_2fcore_2fframework_2fallocation_5fdescription_2eproto();
@Namespace("tensorflow") public static native void protobuf_ShutdownFile_tensorflow_2fcore_2fframework_2fallocation_5fdescription_2eproto();

// ===================================================================

@Namespace("tensorflow") @NoOffset public static class AllocationDescription extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public AllocationDescription(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public AllocationDescription(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public AllocationDescription position(long position) {
        return (AllocationDescription)super.position(position);
    }

  public AllocationDescription() { super((Pointer)null); allocate(); }
  private native void allocate();

  public AllocationDescription(@Const @ByRef AllocationDescription from) { super((Pointer)null); allocate(from); }
  private native void allocate(@Const @ByRef AllocationDescription from);

  public native @ByRef @Name("operator =") AllocationDescription put(@Const @ByRef AllocationDescription from);

  public native @Cast("google::protobuf::Arena*") Pointer GetArena();
  public native Pointer GetMaybeArenaPointer();
  public static native @Cast("const google::protobuf::Descriptor*") Pointer descriptor();
  public static native @Const @ByRef AllocationDescription default_instance();

  public native void UnsafeArenaSwap(AllocationDescription other);
  public native void Swap(AllocationDescription other);

  // implements Message ----------------------------------------------

  public native AllocationDescription New();

  public native AllocationDescription New(@Cast("google::protobuf::Arena*") Pointer arena);
  public native void CopyFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void MergeFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void CopyFrom(@Const @ByRef AllocationDescription from);
  public native void MergeFrom(@Const @ByRef AllocationDescription from);
  public native void Clear();
  public native @Cast("bool") boolean IsInitialized();

  public native int ByteSize();
  public native @Cast("bool") boolean MergePartialFromCodedStream(
        @Cast("google::protobuf::io::CodedInputStream*") Pointer input);
  public native void SerializeWithCachedSizes(
        @Cast("google::protobuf::io::CodedOutputStream*") Pointer output);
  public native @Cast("google::protobuf::uint8*") BytePointer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") byte[] output);
  public native @Cast("google::protobuf::uint8*") BytePointer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") byte[] output);
  public native int GetCachedSize();

  public native @ByVal @Cast("google::protobuf::Metadata*") Pointer GetMetadata();

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional int64 requested_bytes = 1;
  public native void clear_requested_bytes();
  @MemberGetter public static native int kRequestedBytesFieldNumber();
  public static final int kRequestedBytesFieldNumber = kRequestedBytesFieldNumber();
  public native @Cast("google::protobuf::int64") long requested_bytes();
  public native void set_requested_bytes(@Cast("google::protobuf::int64") long value);

  // optional int64 allocated_bytes = 2;
  public native void clear_allocated_bytes();
  @MemberGetter public static native int kAllocatedBytesFieldNumber();
  public static final int kAllocatedBytesFieldNumber = kAllocatedBytesFieldNumber();
  public native @Cast("google::protobuf::int64") long allocated_bytes();
  public native void set_allocated_bytes(@Cast("google::protobuf::int64") long value);

  // optional string allocator_name = 3;
  public native void clear_allocator_name();
  @MemberGetter public static native int kAllocatorNameFieldNumber();
  public static final int kAllocatorNameFieldNumber = kAllocatorNameFieldNumber();
  public native @StdString BytePointer allocator_name();
  public native void set_allocator_name(@StdString BytePointer value);
  public native void set_allocator_name(@StdString String value);
  public native void set_allocator_name(@Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void set_allocator_name(String value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_allocator_name();
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer release_allocator_name();
  public native void set_allocated_allocator_name(@StdString @Cast({"char*", "std::string*"}) BytePointer allocator_name);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer unsafe_arena_release_allocator_name();
  public native void unsafe_arena_set_allocated_allocator_name(
        @StdString @Cast({"char*", "std::string*"}) BytePointer allocator_name);

  // optional int64 allocation_id = 4;
  public native void clear_allocation_id();
  @MemberGetter public static native int kAllocationIdFieldNumber();
  public static final int kAllocationIdFieldNumber = kAllocationIdFieldNumber();
  public native @Cast("google::protobuf::int64") long allocation_id();
  public native void set_allocation_id(@Cast("google::protobuf::int64") long value);

  // optional bool has_single_reference = 5;
  public native void clear_has_single_reference();
  @MemberGetter public static native int kHasSingleReferenceFieldNumber();
  public static final int kHasSingleReferenceFieldNumber = kHasSingleReferenceFieldNumber();
  public native @Cast("bool") boolean has_single_reference();
  public native void set_has_single_reference(@Cast("bool") boolean value);

  // optional uint64 ptr = 6;
  public native void clear_ptr();
  @MemberGetter public static native int kPtrFieldNumber();
  public static final int kPtrFieldNumber = kPtrFieldNumber();
  public native @Cast("google::protobuf::uint64") long ptr();
  public native void set_ptr(@Cast("google::protobuf::uint64") long value);
}
// ===================================================================


// ===================================================================

// #if !PROTOBUF_INLINE_NOT_IN_HEADERS
// AllocationDescription

// optional int64 requested_bytes = 1;




// optional int64 allocated_bytes = 2;




// optional string allocator_name = 3;











// optional int64 allocation_id = 4;




// optional bool has_single_reference = 5;




// optional uint64 ptr = 6;




// #endif  // !PROTOBUF_INLINE_NOT_IN_HEADERS

// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_tensorflow_2fcore_2fframework_2fallocation_5fdescription_2eproto__INCLUDED


// Parsed from tensorflow/core/framework/allocator.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_FRAMEWORK_ALLOCATOR_H_
// #define TENSORFLOW_FRAMEWORK_ALLOCATOR_H_

// #include <stdlib.h>
// #include <unistd.h>

// #include <limits>

// #include "tensorflow/core/framework/numeric_types.h"
// #include "tensorflow/core/framework/type_traits.h"
// #include "tensorflow/core/platform/logging.h"
// #include "tensorflow/core/platform/types.h"

// Attributes for a single allocation call. Different calls to the same
// allocator could potentially have different allocation attributes.
@Namespace("tensorflow") public static class AllocationAttributes extends Pointer {
    static { Loader.load(); }
    /** Default native constructor. */
    public AllocationAttributes() { super((Pointer)null); allocate(); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public AllocationAttributes(long size) { super((Pointer)null); allocateArray(size); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public AllocationAttributes(Pointer p) { super(p); }
    private native void allocate();
    private native void allocateArray(long size);
    @Override public AllocationAttributes position(long position) {
        return (AllocationAttributes)super.position(position);
    }

  // If the first attempt to allocate the memory fails, the allocation
  // should return immediately without retrying.
  // An example use case is optional scratch spaces where a failure
  // has only performance impact.
  public native @Cast("bool") boolean no_retry_on_failure(); public native AllocationAttributes no_retry_on_failure(boolean no_retry_on_failure);
  // If a Tensor is allocated without the following set to true, then
  // it is logged as an unknown allocation. During execution Tensors
  // should be allocated through the OpKernelContext which records
  // which Op is performing the allocation, and sets this flag to
  // true.
  public native @Cast("bool") boolean allocation_will_be_logged(); public native AllocationAttributes allocation_will_be_logged(boolean allocation_will_be_logged);
}

// Runtime statistics collected by an allocator.
@Namespace("tensorflow") @NoOffset public static class AllocatorStats extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public AllocatorStats(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public AllocatorStats(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public AllocatorStats position(long position) {
        return (AllocatorStats)super.position(position);
    }

  public native @Cast("tensorflow::int64") long num_allocs(); public native AllocatorStats num_allocs(long num_allocs);        // Number of allocations.
  public native @Cast("tensorflow::int64") long bytes_in_use(); public native AllocatorStats bytes_in_use(long bytes_in_use);      // Number of bytes in use.
  public native @Cast("tensorflow::int64") long max_bytes_in_use(); public native AllocatorStats max_bytes_in_use(long max_bytes_in_use);  // The maximum bytes in use.
  public native @Cast("tensorflow::int64") long max_alloc_size(); public native AllocatorStats max_alloc_size(long max_alloc_size);    // The max single allocation seen.

  // The upper limit what the allocator can allocate, if such a limit
  // is known. Certain allocator may return 0 to indicate the limit is
  // unknown.
  public native @Cast("tensorflow::int64") long bytes_limit(); public native AllocatorStats bytes_limit(long bytes_limit);

  public AllocatorStats() { super((Pointer)null); allocate(); }
  private native void allocate();

  public native void Clear();
  public native @StdString BytePointer DebugString();
}

// Allocator is an abstract interface for allocating and deallocating
// device memory.
@Namespace("tensorflow") public static class Allocator extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Allocator(Pointer p) { super(p); }

  // Align to 32 byte boundary.
  @MemberGetter public static native @Cast("const size_t") long kAllocatorAlignment();
  public static final long kAllocatorAlignment = kAllocatorAlignment();

  // Return a string identifying this allocator
  public native @StdString BytePointer Name();

  // Return an uninitialized block of memory that is "num_bytes" bytes
  // in size.  The returned pointer is guaranteed to be aligned to a
  // multiple of "alignment" bytes.
  // REQUIRES: "alignment" is a power of 2.
  public native Pointer AllocateRaw(@Cast("size_t") long alignment, @Cast("size_t") long num_bytes);

  // Return an uninitialized block of memory that is "num_bytes" bytes
  // in size with specified allocation attributes.  The returned pointer is
  // guaranteed to be aligned to a multiple of "alignment" bytes.
  // REQUIRES: "alignment" is a power of 2.
  public native Pointer AllocateRaw(@Cast("size_t") long alignment, @Cast("size_t") long num_bytes,
                              @Const @ByRef AllocationAttributes allocation_attr);

  // Deallocate a block of memory pointer to by "ptr"
  // REQUIRES: "ptr" was previously returned by a call to AllocateRaw
  public native void DeallocateRaw(Pointer ptr);

  // Convenience functions to do typed allocation.  C++ constructors
  // and destructors are invoked for complex types if necessary,
  // depending on the concrete Allocator implementation. May return
  // NULL if the tensor has too many elements to represent in a single
  // allocation.

  // Returns true if this allocator tracks the sizes of allocations.
  // RequestedSize and AllocatedSize must be overridden if
  // TracksAllocationSizes is overridden to return true.
  public native @Cast("bool") boolean TracksAllocationSizes();

  // Returns true if this allocator requires tensors with 0 elements
  // to allocate buffers. This is false for most allocators, but may
  // be used by special-case allocators that want to track tensor
  // usage.
  public native @Cast("bool") boolean ShouldAllocateEmptyTensors();

  // Returns the user-requested size of the data allocated at
  // 'ptr'.  Note that the actual buffer allocated might be larger
  // than requested, but this function returns the size requested by
  // the user.
  //
  // REQUIRES: TracksAllocationSizes() is true.
  //
  // REQUIRES: 'ptr!=nullptr' and points to a buffer previously
  // allocated by this allocator.
  public native @Cast("size_t") long RequestedSize(Pointer ptr);

  // Returns the allocated size of the buffer at 'ptr' if known,
  // otherwise returns RequestedSize(ptr). AllocatedSize(ptr) is
  // guaranteed to be >= RequestedSize(ptr).
  //
  // REQUIRES: TracksAllocationSizes() is true.
  //
  // REQUIRES: 'ptr!=nullptr' and points to a buffer previously
  // allocated by this allocator.
  public native @Cast("size_t") long AllocatedSize(Pointer ptr);

  // Returns either 0 or an identifier assigned to the buffer at 'ptr'
  // when the buffer was returned by AllocateRaw. If non-zero, the
  // identifier differs from every other ID assigned by this
  // allocator.
  //
  // REQUIRES: TracksAllocationSizes() is true.
  //
  // REQUIRES: 'ptr!=nullptr' and points to a buffer previously
  // allocated by this allocator.
  public native @Cast("tensorflow::int64") long AllocationId(Pointer ptr);

  // Returns the allocated size of the buffer at 'ptr' if known,
  // otherwise returns 0. This method can be called when
  // TracksAllocationSizes() is false, but can be extremely slow.
  //
  // REQUIRES: 'ptr!=nullptr' and points to a buffer previously
  // allocated by this allocator.
  public native @Cast("size_t") long AllocatedSizeSlow(Pointer ptr);

  // is_simple<T>::value if T[] can be safely constructed and destructed
  // without running T() and ~T().  We do not use std::is_trivial<T>
  // directly because std::complex<float> and std::complex<double> are
  // not trival, but their arrays can be constructed and destructed
  // without running their default ctors and dtors.

  // Fills in 'stats' with statistics collected by this allocator.
  public native void GetStats(AllocatorStats stats);
}

// Allocator-specific constructors and destructors are used for
// strings




// A tensorflow Op may need access to different kinds of memory that
// are not simply a function of the device to which the Op has been
// assigned.  For example, an Op executing on a GPU may still need
// to allocate CPU RAM for some purpose.  Internal to the tensorflow
// runtime we may choose to allocate CPU ram from special regions
// that have been prepared for higher performance in some use
// contexts, e.g. doing DMA with particular devices.  For these
// reasons, the Device interface does not expose just one memory
// Allocator, but instead provides an accessor that takes a
// specification of the desired memory attributes in order to select
// an Allocator.
//
// Example use:
//  // Allocator for ordinary device memory:
//  Allocator* a = allocator(AllocatorAttributes());
// ...
//  // Allocator for CPU RAM, regardless of where Op is executing:
//  AllocatorAttributes attr;
//  attr.set_on_host(true);
//  Allocator* a = allocator(attr);
@Namespace("tensorflow") public static class AllocatorAttributes extends Pointer {
    static { Loader.load(); }
    /** Default native constructor. */
    public AllocatorAttributes() { super((Pointer)null); allocate(); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public AllocatorAttributes(long size) { super((Pointer)null); allocateArray(size); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public AllocatorAttributes(Pointer p) { super(p); }
    private native void allocate();
    private native void allocateArray(long size);
    @Override public AllocatorAttributes position(long position) {
        return (AllocatorAttributes)super.position(position);
    }

  public native void set_on_host(@Cast("bool") boolean v);
  public native @Cast("bool") boolean on_host();
  public native void set_nic_compatible(@Cast("bool") boolean v);
  public native @Cast("bool") boolean nic_compatible();
  public native void set_gpu_compatible(@Cast("bool") boolean v);
  public native @Cast("bool") boolean gpu_compatible();
  public native void set_track_sizes(@Cast("bool") boolean v);
  public native @Cast("bool") boolean track_sizes();
  public native void Merge(@ByVal AllocatorAttributes other);

  // NOTE: The upper 8 bits of the value are reserved for
  // device-specific uses.  Implementors of a device can interpret these
  // upper 8 bits in device-specific ways, and ops implemented for those
  // devices are responsible for setting those 8 bits appropriately.
  public native int value(); public native AllocatorAttributes value(int value);
}

// Returns a trivial implementation of Allocator which uses the system
// default malloc. The returned allocator is a process singleton.
@Namespace("tensorflow") public static native Allocator cpu_allocator();

// If 'enable' is true, the process-wide cpu allocator collects
// AllocatorStats. By default, it's disabled.
@Namespace("tensorflow") public static native void EnableCPUAllocatorStats(@Cast("bool") boolean enable);

// If 'enable' is true, the process-wide cpu allocator collects full
// statistics. By default, it's disabled.
@Namespace("tensorflow") public static native void EnableCPUAllocatorFullStats(@Cast("bool") boolean enable);

// Abstract interface of an object that does the underlying suballoc/free of
// memory for a higher-level allocator.
@Namespace("tensorflow") public static class SubAllocator extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SubAllocator(Pointer p) { super(p); }

  public native Pointer Alloc(@Cast("size_t") long alignment, @Cast("size_t") long num_bytes);
  public native void Free(Pointer ptr, @Cast("size_t") long num_bytes);
}

  // namespace tensorflow

// #endif  // TENSORFLOW_FRAMEWORK_ALLOCATOR_H_


// Parsed from tensorflow/core/framework/tensor_shape.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/tensor_shape.proto

// #ifndef PROTOBUF_tensorflow_2fcore_2fframework_2ftensor_5fshape_2eproto__INCLUDED
// #define PROTOBUF_tensorflow_2fcore_2fframework_2ftensor_5fshape_2eproto__INCLUDED

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3000000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3000000 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>
// #include <google/protobuf/extension_set.h>
// #include <google/protobuf/unknown_field_set.h>
// @@protoc_insertion_point(includes)

// Internal implementation detail -- do not call these.
@Namespace("tensorflow") public static native void protobuf_AddDesc_tensorflow_2fcore_2fframework_2ftensor_5fshape_2eproto();
@Namespace("tensorflow") public static native void protobuf_AssignDesc_tensorflow_2fcore_2fframework_2ftensor_5fshape_2eproto();
@Namespace("tensorflow") public static native void protobuf_ShutdownFile_tensorflow_2fcore_2fframework_2ftensor_5fshape_2eproto();

// ===================================================================

@Namespace("tensorflow") @NoOffset public static class TensorShapeProto_Dim extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TensorShapeProto_Dim(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public TensorShapeProto_Dim(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public TensorShapeProto_Dim position(long position) {
        return (TensorShapeProto_Dim)super.position(position);
    }

  public TensorShapeProto_Dim() { super((Pointer)null); allocate(); }
  private native void allocate();

  public TensorShapeProto_Dim(@Const @ByRef TensorShapeProto_Dim from) { super((Pointer)null); allocate(from); }
  private native void allocate(@Const @ByRef TensorShapeProto_Dim from);

  public native @ByRef @Name("operator =") TensorShapeProto_Dim put(@Const @ByRef TensorShapeProto_Dim from);

  public native @Cast("google::protobuf::Arena*") Pointer GetArena();
  public native Pointer GetMaybeArenaPointer();
  public static native @Cast("const google::protobuf::Descriptor*") Pointer descriptor();
  public static native @Const @ByRef TensorShapeProto_Dim default_instance();

  public native void UnsafeArenaSwap(TensorShapeProto_Dim other);
  public native void Swap(TensorShapeProto_Dim other);

  // implements Message ----------------------------------------------

  public native TensorShapeProto_Dim New();

  public native TensorShapeProto_Dim New(@Cast("google::protobuf::Arena*") Pointer arena);
  public native void CopyFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void MergeFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void CopyFrom(@Const @ByRef TensorShapeProto_Dim from);
  public native void MergeFrom(@Const @ByRef TensorShapeProto_Dim from);
  public native void Clear();
  public native @Cast("bool") boolean IsInitialized();

  public native int ByteSize();
  public native @Cast("bool") boolean MergePartialFromCodedStream(
        @Cast("google::protobuf::io::CodedInputStream*") Pointer input);
  public native void SerializeWithCachedSizes(
        @Cast("google::protobuf::io::CodedOutputStream*") Pointer output);
  public native @Cast("google::protobuf::uint8*") BytePointer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") byte[] output);
  public native @Cast("google::protobuf::uint8*") BytePointer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") byte[] output);
  public native int GetCachedSize();

  public native @ByVal @Cast("google::protobuf::Metadata*") Pointer GetMetadata();

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional int64 size = 1;
  public native void clear_size();
  @MemberGetter public static native int kSizeFieldNumber();
  public static final int kSizeFieldNumber = kSizeFieldNumber();
  public native @Cast("google::protobuf::int64") long size();
  public native void set_size(@Cast("google::protobuf::int64") long value);

  // optional string name = 2;
  public native void clear_name();
  @MemberGetter public static native int kNameFieldNumber();
  public static final int kNameFieldNumber = kNameFieldNumber();
  public native @StdString BytePointer name();
  public native void set_name(@StdString BytePointer value);
  public native void set_name(@StdString String value);
  public native void set_name(@Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void set_name(String value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_name();
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer release_name();
  public native void set_allocated_name(@StdString @Cast({"char*", "std::string*"}) BytePointer name);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer unsafe_arena_release_name();
  public native void unsafe_arena_set_allocated_name(
        @StdString @Cast({"char*", "std::string*"}) BytePointer name);
}
// -------------------------------------------------------------------

@Namespace("tensorflow") @NoOffset public static class TensorShapeProto extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TensorShapeProto(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public TensorShapeProto(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public TensorShapeProto position(long position) {
        return (TensorShapeProto)super.position(position);
    }

  public TensorShapeProto() { super((Pointer)null); allocate(); }
  private native void allocate();

  public TensorShapeProto(@Const @ByRef TensorShapeProto from) { super((Pointer)null); allocate(from); }
  private native void allocate(@Const @ByRef TensorShapeProto from);

  public native @ByRef @Name("operator =") TensorShapeProto put(@Const @ByRef TensorShapeProto from);

  public native @Cast("google::protobuf::Arena*") Pointer GetArena();
  public native Pointer GetMaybeArenaPointer();
  public static native @Cast("const google::protobuf::Descriptor*") Pointer descriptor();
  public static native @Const @ByRef TensorShapeProto default_instance();

  public native void UnsafeArenaSwap(TensorShapeProto other);
  public native void Swap(TensorShapeProto other);

  // implements Message ----------------------------------------------

  public native TensorShapeProto New();

  public native TensorShapeProto New(@Cast("google::protobuf::Arena*") Pointer arena);
  public native void CopyFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void MergeFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void CopyFrom(@Const @ByRef TensorShapeProto from);
  public native void MergeFrom(@Const @ByRef TensorShapeProto from);
  public native void Clear();
  public native @Cast("bool") boolean IsInitialized();

  public native int ByteSize();
  public native @Cast("bool") boolean MergePartialFromCodedStream(
        @Cast("google::protobuf::io::CodedInputStream*") Pointer input);
  public native void SerializeWithCachedSizes(
        @Cast("google::protobuf::io::CodedOutputStream*") Pointer output);
  public native @Cast("google::protobuf::uint8*") BytePointer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") byte[] output);
  public native @Cast("google::protobuf::uint8*") BytePointer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") byte[] output);
  public native int GetCachedSize();

  public native @ByVal @Cast("google::protobuf::Metadata*") Pointer GetMetadata();

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .tensorflow.TensorShapeProto.Dim dim = 2;
  public native int dim_size();
  public native void clear_dim();
  @MemberGetter public static native int kDimFieldNumber();
  public static final int kDimFieldNumber = kDimFieldNumber();
  public native @Const @ByRef TensorShapeProto_Dim dim(int index);
  public native TensorShapeProto_Dim mutable_dim(int index);
  public native TensorShapeProto_Dim add_dim();

  // optional bool unknown_rank = 3;
  public native void clear_unknown_rank();
  @MemberGetter public static native int kUnknownRankFieldNumber();
  public static final int kUnknownRankFieldNumber = kUnknownRankFieldNumber();
  public native @Cast("bool") boolean unknown_rank();
  public native void set_unknown_rank(@Cast("bool") boolean value);
}
// ===================================================================


// ===================================================================

// #if !PROTOBUF_INLINE_NOT_IN_HEADERS
// TensorShapeProto_Dim

// optional int64 size = 1;




// optional string name = 2;











// -------------------------------------------------------------------

// TensorShapeProto

// repeated .tensorflow.TensorShapeProto.Dim dim = 2;








// optional bool unknown_rank = 3;




// #endif  // !PROTOBUF_INLINE_NOT_IN_HEADERS
// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_tensorflow_2fcore_2fframework_2ftensor_5fshape_2eproto__INCLUDED


// Parsed from tensorflow/core/framework/types.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/types.proto

// #ifndef PROTOBUF_tensorflow_2fcore_2fframework_2ftypes_2eproto__INCLUDED
// #define PROTOBUF_tensorflow_2fcore_2fframework_2ftypes_2eproto__INCLUDED

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3000000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3000000 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/repeated_field.h>
// #include <google/protobuf/extension_set.h>
// #include <google/protobuf/generated_enum_reflection.h>
// @@protoc_insertion_point(includes)

// Internal implementation detail -- do not call these.
@Namespace("tensorflow") public static native void protobuf_AddDesc_tensorflow_2fcore_2fframework_2ftypes_2eproto();
@Namespace("tensorflow") public static native void protobuf_AssignDesc_tensorflow_2fcore_2fframework_2ftypes_2eproto();
@Namespace("tensorflow") public static native void protobuf_ShutdownFile_tensorflow_2fcore_2fframework_2ftypes_2eproto();


/** enum tensorflow::DataType */
public static final int
  DT_INVALID = 0,
  DT_FLOAT = 1,
  DT_DOUBLE = 2,
  DT_INT32 = 3,
  DT_UINT8 = 4,
  DT_INT16 = 5,
  DT_INT8 = 6,
  DT_STRING = 7,
  DT_COMPLEX64 = 8,
  DT_INT64 = 9,
  DT_BOOL = 10,
  DT_QINT8 = 11,
  DT_QUINT8 = 12,
  DT_QINT32 = 13,
  DT_BFLOAT16 = 14,
  DT_QINT16 = 15,
  DT_QUINT16 = 16,
  DT_UINT16 = 17,
  DT_COMPLEX128 = 18,
  DT_HALF = 19,
  DT_FLOAT_REF = 101,
  DT_DOUBLE_REF = 102,
  DT_INT32_REF = 103,
  DT_UINT8_REF = 104,
  DT_INT16_REF = 105,
  DT_INT8_REF = 106,
  DT_STRING_REF = 107,
  DT_COMPLEX64_REF = 108,
  DT_INT64_REF = 109,
  DT_BOOL_REF = 110,
  DT_QINT8_REF = 111,
  DT_QUINT8_REF = 112,
  DT_QINT32_REF = 113,
  DT_BFLOAT16_REF = 114,
  DT_QINT16_REF = 115,
  DT_QUINT16_REF = 116,
  DT_UINT16_REF = 117,
  DT_COMPLEX128_REF = 118,
  DT_HALF_REF = 119,
  DataType_INT_MIN_SENTINEL_DO_NOT_USE_ =kint32min,
  DataType_INT_MAX_SENTINEL_DO_NOT_USE_ =kint32max;
@Namespace("tensorflow") public static native @Cast("bool") boolean DataType_IsValid(int value);
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::DataType") int DataType_MIN();
@Namespace("tensorflow") @MemberGetter public static native @Cast("const tensorflow::DataType") int DataType_MAX();
@Namespace("tensorflow") @MemberGetter public static native int DataType_ARRAYSIZE();

@Namespace("tensorflow") public static native @Cast("const google::protobuf::EnumDescriptor*") Pointer DataType_descriptor();
@Namespace("tensorflow") public static native @StdString BytePointer DataType_Name(@Cast("tensorflow::DataType") int value);
@Namespace("tensorflow") public static native @Cast("bool") boolean DataType_Parse(
    @StdString BytePointer name, @Cast("tensorflow::DataType*") IntPointer value);
@Namespace("tensorflow") public static native @Cast("bool") boolean DataType_Parse(
    @StdString String name, @Cast("tensorflow::DataType*") IntPointer value);
// ===================================================================


// ===================================================================


// ===================================================================

// #if !PROTOBUF_INLINE_NOT_IN_HEADERS
// #endif  // !PROTOBUF_INLINE_NOT_IN_HEADERS

// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// #ifndef SWIG
// #endif  // SWIG

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_tensorflow_2fcore_2fframework_2ftypes_2eproto__INCLUDED


// Parsed from tensorflow/core/framework/tensor.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/tensor.proto

// #ifndef PROTOBUF_tensorflow_2fcore_2fframework_2ftensor_2eproto__INCLUDED
// #define PROTOBUF_tensorflow_2fcore_2fframework_2ftensor_2eproto__INCLUDED

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3000000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3000000 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>
// #include <google/protobuf/extension_set.h>
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/tensor_shape.pb.h"
// #include "tensorflow/core/framework/types.pb.h"
// @@protoc_insertion_point(includes)

// Internal implementation detail -- do not call these.
@Namespace("tensorflow") public static native void protobuf_AddDesc_tensorflow_2fcore_2fframework_2ftensor_2eproto();
@Namespace("tensorflow") public static native void protobuf_AssignDesc_tensorflow_2fcore_2fframework_2ftensor_2eproto();
@Namespace("tensorflow") public static native void protobuf_ShutdownFile_tensorflow_2fcore_2fframework_2ftensor_2eproto();

// ===================================================================

@Namespace("tensorflow") @NoOffset public static class TensorProto extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TensorProto(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public TensorProto(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public TensorProto position(long position) {
        return (TensorProto)super.position(position);
    }

  public TensorProto() { super((Pointer)null); allocate(); }
  private native void allocate();

  public TensorProto(@Const @ByRef TensorProto from) { super((Pointer)null); allocate(from); }
  private native void allocate(@Const @ByRef TensorProto from);

  public native @ByRef @Name("operator =") TensorProto put(@Const @ByRef TensorProto from);

  public native @Cast("google::protobuf::Arena*") Pointer GetArena();
  public native Pointer GetMaybeArenaPointer();
  public static native @Cast("const google::protobuf::Descriptor*") Pointer descriptor();
  public static native @Const @ByRef TensorProto default_instance();

  public native void UnsafeArenaSwap(TensorProto other);
  public native void Swap(TensorProto other);

  // implements Message ----------------------------------------------

  public native TensorProto New();

  public native TensorProto New(@Cast("google::protobuf::Arena*") Pointer arena);
  public native void CopyFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void MergeFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void CopyFrom(@Const @ByRef TensorProto from);
  public native void MergeFrom(@Const @ByRef TensorProto from);
  public native void Clear();
  public native @Cast("bool") boolean IsInitialized();

  public native int ByteSize();
  public native @Cast("bool") boolean MergePartialFromCodedStream(
        @Cast("google::protobuf::io::CodedInputStream*") Pointer input);
  public native void SerializeWithCachedSizes(
        @Cast("google::protobuf::io::CodedOutputStream*") Pointer output);
  public native @Cast("google::protobuf::uint8*") BytePointer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") byte[] output);
  public native @Cast("google::protobuf::uint8*") BytePointer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") byte[] output);
  public native int GetCachedSize();

  public native @ByVal @Cast("google::protobuf::Metadata*") Pointer GetMetadata();

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .tensorflow.DataType dtype = 1;
  public native void clear_dtype();
  @MemberGetter public static native int kDtypeFieldNumber();
  public static final int kDtypeFieldNumber = kDtypeFieldNumber();
  public native @Cast("tensorflow::DataType") int dtype();
  public native void set_dtype(@Cast("tensorflow::DataType") int value);

  // optional .tensorflow.TensorShapeProto tensor_shape = 2;
  public native @Cast("bool") boolean has_tensor_shape();
  public native void clear_tensor_shape();
  @MemberGetter public static native int kTensorShapeFieldNumber();
  public static final int kTensorShapeFieldNumber = kTensorShapeFieldNumber();
  public native @Const @ByRef TensorShapeProto tensor_shape();
  public native TensorShapeProto mutable_tensor_shape();
  public native TensorShapeProto release_tensor_shape();
  public native void set_allocated_tensor_shape(TensorShapeProto tensor_shape);
  public native TensorShapeProto unsafe_arena_release_tensor_shape();
  public native void unsafe_arena_set_allocated_tensor_shape(
        TensorShapeProto tensor_shape);

  // optional int32 version_number = 3;
  public native void clear_version_number();
  @MemberGetter public static native int kVersionNumberFieldNumber();
  public static final int kVersionNumberFieldNumber = kVersionNumberFieldNumber();
  public native @Cast("google::protobuf::int32") int version_number();
  public native void set_version_number(@Cast("google::protobuf::int32") int value);

  // optional bytes tensor_content = 4;
  public native void clear_tensor_content();
  @MemberGetter public static native int kTensorContentFieldNumber();
  public static final int kTensorContentFieldNumber = kTensorContentFieldNumber();
  public native @StdString BytePointer tensor_content();
  public native void set_tensor_content(@StdString BytePointer value);
  public native void set_tensor_content(@StdString String value);
  public native void set_tensor_content(@Const Pointer value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_tensor_content();
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer release_tensor_content();
  public native void set_allocated_tensor_content(@StdString @Cast({"char*", "std::string*"}) BytePointer tensor_content);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer unsafe_arena_release_tensor_content();
  public native void unsafe_arena_set_allocated_tensor_content(
        @StdString @Cast({"char*", "std::string*"}) BytePointer tensor_content);

  // repeated int32 half_val = 13 [packed = true];
  public native int half_val_size();
  public native void clear_half_val();
  @MemberGetter public static native int kHalfValFieldNumber();
  public static final int kHalfValFieldNumber = kHalfValFieldNumber();
  public native @Cast("google::protobuf::int32") int half_val(int index);
  public native void set_half_val(int index, @Cast("google::protobuf::int32") int value);
  public native void add_half_val(@Cast("google::protobuf::int32") int value);

  // repeated float float_val = 5 [packed = true];
  public native int float_val_size();
  public native void clear_float_val();
  @MemberGetter public static native int kFloatValFieldNumber();
  public static final int kFloatValFieldNumber = kFloatValFieldNumber();
  public native float float_val(int index);
  public native void set_float_val(int index, float value);
  public native void add_float_val(float value);

  // repeated double double_val = 6 [packed = true];
  public native int double_val_size();
  public native void clear_double_val();
  @MemberGetter public static native int kDoubleValFieldNumber();
  public static final int kDoubleValFieldNumber = kDoubleValFieldNumber();
  public native double double_val(int index);
  public native void set_double_val(int index, double value);
  public native void add_double_val(double value);

  // repeated int32 int_val = 7 [packed = true];
  public native int int_val_size();
  public native void clear_int_val();
  @MemberGetter public static native int kIntValFieldNumber();
  public static final int kIntValFieldNumber = kIntValFieldNumber();
  public native @Cast("google::protobuf::int32") int int_val(int index);
  public native void set_int_val(int index, @Cast("google::protobuf::int32") int value);
  public native void add_int_val(@Cast("google::protobuf::int32") int value);

  // repeated bytes string_val = 8;
  public native int string_val_size();
  public native void clear_string_val();
  @MemberGetter public static native int kStringValFieldNumber();
  public static final int kStringValFieldNumber = kStringValFieldNumber();
  public native @StdString BytePointer string_val(int index);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_string_val(int index);
  public native void set_string_val(int index, @StdString BytePointer value);
  public native void set_string_val(int index, @StdString String value);
  public native void set_string_val(int index, @Const Pointer value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer add_string_val();
  public native void add_string_val(@StdString BytePointer value);
  public native void add_string_val(@StdString String value);
  public native void add_string_val(@Const Pointer value, @Cast("size_t") long size);

  // repeated float scomplex_val = 9 [packed = true];
  public native int scomplex_val_size();
  public native void clear_scomplex_val();
  @MemberGetter public static native int kScomplexValFieldNumber();
  public static final int kScomplexValFieldNumber = kScomplexValFieldNumber();
  public native float scomplex_val(int index);
  public native void set_scomplex_val(int index, float value);
  public native void add_scomplex_val(float value);

  // repeated int64 int64_val = 10 [packed = true];
  public native int int64_val_size();
  public native void clear_int64_val();
  @MemberGetter public static native int kInt64ValFieldNumber();
  public static final int kInt64ValFieldNumber = kInt64ValFieldNumber();
  public native @Cast("google::protobuf::int64") long int64_val(int index);
  public native void set_int64_val(int index, @Cast("google::protobuf::int64") long value);
  public native void add_int64_val(@Cast("google::protobuf::int64") long value);

  // repeated bool bool_val = 11 [packed = true];
  public native int bool_val_size();
  public native void clear_bool_val();
  @MemberGetter public static native int kBoolValFieldNumber();
  public static final int kBoolValFieldNumber = kBoolValFieldNumber();
  public native @Cast("bool") boolean bool_val(int index);
  public native void set_bool_val(int index, @Cast("bool") boolean value);
  public native void add_bool_val(@Cast("bool") boolean value);

  // repeated double dcomplex_val = 12 [packed = true];
  public native int dcomplex_val_size();
  public native void clear_dcomplex_val();
  @MemberGetter public static native int kDcomplexValFieldNumber();
  public static final int kDcomplexValFieldNumber = kDcomplexValFieldNumber();
  public native double dcomplex_val(int index);
  public native void set_dcomplex_val(int index, double value);
  public native void add_dcomplex_val(double value);
}
// ===================================================================


// ===================================================================

// #if !PROTOBUF_INLINE_NOT_IN_HEADERS
// TensorProto

// optional .tensorflow.DataType dtype = 1;




// optional .tensorflow.TensorShapeProto tensor_shape = 2;







// optional int32 version_number = 3;




// optional bytes tensor_content = 4;











// repeated int32 half_val = 13 [packed = true];








// repeated float float_val = 5 [packed = true];








// repeated double double_val = 6 [packed = true];








// repeated int32 int_val = 7 [packed = true];








// repeated bytes string_val = 8;














// repeated float scomplex_val = 9 [packed = true];








// repeated int64 int64_val = 10 [packed = true];








// repeated bool bool_val = 11 [packed = true];








// repeated double dcomplex_val = 12 [packed = true];








// #endif  // !PROTOBUF_INLINE_NOT_IN_HEADERS

// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_tensorflow_2fcore_2fframework_2ftensor_2eproto__INCLUDED


// Parsed from tensorflow/core/framework/tensor_description.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/tensor_description.proto

// #ifndef PROTOBUF_tensorflow_2fcore_2fframework_2ftensor_5fdescription_2eproto__INCLUDED
// #define PROTOBUF_tensorflow_2fcore_2fframework_2ftensor_5fdescription_2eproto__INCLUDED

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3000000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3000000 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>
// #include <google/protobuf/extension_set.h>
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/types.pb.h"
// #include "tensorflow/core/framework/tensor_shape.pb.h"
// #include "tensorflow/core/framework/allocation_description.pb.h"
// @@protoc_insertion_point(includes)

// Internal implementation detail -- do not call these.
@Namespace("tensorflow") public static native void protobuf_AddDesc_tensorflow_2fcore_2fframework_2ftensor_5fdescription_2eproto();
@Namespace("tensorflow") public static native void protobuf_AssignDesc_tensorflow_2fcore_2fframework_2ftensor_5fdescription_2eproto();
@Namespace("tensorflow") public static native void protobuf_ShutdownFile_tensorflow_2fcore_2fframework_2ftensor_5fdescription_2eproto();

// ===================================================================

@Namespace("tensorflow") @NoOffset public static class TensorDescription extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TensorDescription(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public TensorDescription(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public TensorDescription position(long position) {
        return (TensorDescription)super.position(position);
    }

  public TensorDescription() { super((Pointer)null); allocate(); }
  private native void allocate();

  public TensorDescription(@Const @ByRef TensorDescription from) { super((Pointer)null); allocate(from); }
  private native void allocate(@Const @ByRef TensorDescription from);

  public native @ByRef @Name("operator =") TensorDescription put(@Const @ByRef TensorDescription from);

  public native @Cast("google::protobuf::Arena*") Pointer GetArena();
  public native Pointer GetMaybeArenaPointer();
  public static native @Cast("const google::protobuf::Descriptor*") Pointer descriptor();
  public static native @Const @ByRef TensorDescription default_instance();

  public native void UnsafeArenaSwap(TensorDescription other);
  public native void Swap(TensorDescription other);

  // implements Message ----------------------------------------------

  public native TensorDescription New();

  public native TensorDescription New(@Cast("google::protobuf::Arena*") Pointer arena);
  public native void CopyFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void MergeFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void CopyFrom(@Const @ByRef TensorDescription from);
  public native void MergeFrom(@Const @ByRef TensorDescription from);
  public native void Clear();
  public native @Cast("bool") boolean IsInitialized();

  public native int ByteSize();
  public native @Cast("bool") boolean MergePartialFromCodedStream(
        @Cast("google::protobuf::io::CodedInputStream*") Pointer input);
  public native void SerializeWithCachedSizes(
        @Cast("google::protobuf::io::CodedOutputStream*") Pointer output);
  public native @Cast("google::protobuf::uint8*") BytePointer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") byte[] output);
  public native @Cast("google::protobuf::uint8*") BytePointer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") byte[] output);
  public native int GetCachedSize();

  public native @ByVal @Cast("google::protobuf::Metadata*") Pointer GetMetadata();

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .tensorflow.DataType dtype = 1;
  public native void clear_dtype();
  @MemberGetter public static native int kDtypeFieldNumber();
  public static final int kDtypeFieldNumber = kDtypeFieldNumber();
  public native @Cast("tensorflow::DataType") int dtype();
  public native void set_dtype(@Cast("tensorflow::DataType") int value);

  // optional .tensorflow.TensorShapeProto shape = 2;
  public native @Cast("bool") boolean has_shape();
  public native void clear_shape();
  @MemberGetter public static native int kShapeFieldNumber();
  public static final int kShapeFieldNumber = kShapeFieldNumber();
  public native @Const @ByRef TensorShapeProto shape();
  public native TensorShapeProto mutable_shape();
  public native TensorShapeProto release_shape();
  public native void set_allocated_shape(TensorShapeProto shape);
  public native TensorShapeProto unsafe_arena_release_shape();
  public native void unsafe_arena_set_allocated_shape(
        TensorShapeProto shape);

  // optional .tensorflow.AllocationDescription allocation_description = 4;
  public native @Cast("bool") boolean has_allocation_description();
  public native void clear_allocation_description();
  @MemberGetter public static native int kAllocationDescriptionFieldNumber();
  public static final int kAllocationDescriptionFieldNumber = kAllocationDescriptionFieldNumber();
  public native @Const @ByRef AllocationDescription allocation_description();
  public native AllocationDescription mutable_allocation_description();
  public native AllocationDescription release_allocation_description();
  public native void set_allocated_allocation_description(AllocationDescription allocation_description);
  public native AllocationDescription unsafe_arena_release_allocation_description();
  public native void unsafe_arena_set_allocated_allocation_description(
        AllocationDescription allocation_description);
}
// ===================================================================


// ===================================================================

// #if !PROTOBUF_INLINE_NOT_IN_HEADERS
// TensorDescription

// optional .tensorflow.DataType dtype = 1;




// optional .tensorflow.TensorShapeProto shape = 2;







// optional .tensorflow.AllocationDescription allocation_description = 4;







// #endif  // !PROTOBUF_INLINE_NOT_IN_HEADERS

// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_tensorflow_2fcore_2fframework_2ftensor_5fdescription_2eproto__INCLUDED


// Parsed from tensorflow/core/framework/tensor_types.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_FRAMEWORK_TENSOR_TYPES_H_
// #define TENSORFLOW_FRAMEWORK_TENSOR_TYPES_H_

// #include "third_party/eigen3/unsupported/Eigen/CXX11/Tensor"

// Helper to define Tensor types given that the scalar is of type T.

  // namespace tensorflow
// #endif  // TENSORFLOW_FRAMEWORK_TENSOR_TYPES_H_


// Parsed from tensorflow/core/framework/tensor_shape.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_TENSOR_SHAPE_H_
// #define TENSORFLOW_CORE_FRAMEWORK_TENSOR_SHAPE_H_

// #include <string>

// #include "third_party/eigen3/unsupported/Eigen/CXX11/Tensor"
// #include "tensorflow/core/framework/tensor_shape.pb.h"
// #include "tensorflow/core/framework/types.pb.h"
// #include "tensorflow/core/lib/core/errors.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// #include "tensorflow/core/lib/gtl/inlined_vector.h"
// #include "tensorflow/core/lib/strings/strcat.h"
// #include "tensorflow/core/platform/logging.h"

// START_SKIP_DOXYGEN  // Declared below
// END_SKIP_DOXYGEN

/** Represents the shape of a Tensor.
 * 
 *  A tensor's shape is denoted by its number of dimensions and a size for each
 *  dimension.  For example, a Tensor represented by a 3 x 4 matrix would have
 *  a shape of 2-D, [3,4].
 * 
 *  If you know the exact shape of your Tensor when you create the TensorShape
 *  object, you can specify it then, or you can create a TensorShape with
 *  zero dimensions and one element, and call AddDim() to add dimensions later. */
@Namespace("tensorflow") @NoOffset public static class TensorShape extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TensorShape(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public TensorShape(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public TensorShape position(long position) {
        return (TensorShape)super.position(position);
    }

  /** \brief Construct a {@code TensorShape} from the provided sizes.
   *  REQUIRES: {@code dim_sizes[i] >= 0} */
  public TensorShape(@Cast("tensorflow::int64*") @ArraySlice LongPointer dim_sizes) { super((Pointer)null); allocate(dim_sizes); }
  private native void allocate(@Cast("tensorflow::int64*") @ArraySlice LongPointer dim_sizes);
  public TensorShape(@Cast("tensorflow::int64*") @ArraySlice LongBuffer dim_sizes) { super((Pointer)null); allocate(dim_sizes); }
  private native void allocate(@Cast("tensorflow::int64*") @ArraySlice LongBuffer dim_sizes);
  public TensorShape(@Cast("tensorflow::int64*") @ArraySlice long... dim_sizes) { super((Pointer)null); allocate(dim_sizes); }
  private native void allocate(@Cast("tensorflow::int64*") @ArraySlice long... dim_sizes);

  /** REQUIRES: {@code IsValid(proto)} */
  public TensorShape(@Const @ByRef TensorShapeProto proto) { super((Pointer)null); allocate(proto); }
  private native void allocate(@Const @ByRef TensorShapeProto proto);

  /** Create a tensor shape with no dimensions and one element, which you can
   *  then call {@code AddDim()} on. */
  public TensorShape() { super((Pointer)null); allocate(); }
  private native void allocate();

  /** Copy the specified shape */
  public TensorShape(@Const @ByRef TensorShape b) { super((Pointer)null); allocate(b); }
  private native void allocate(@Const @ByRef TensorShape b);
  public native @Name("operator =") void put(@Const @ByRef TensorShape b);

  /** Move the specified shape.  After moving, <b> is safe for destruction and */
  // can be reassigned into, but its dimensions and number of elements can be
  // nonsensical (e.g., negative dimension sizes, or number of elements not
  // properly recomputed).

  /** Returns {@code true} iff {@code proto} is a valid tensor shape. */
  public static native @Cast("bool") boolean IsValid(@Const @ByRef TensorShapeProto proto);

  /** Returns {@code OK} iff {@code proto} is a valid tensor shape, and a descriptive error
   *  status otherwise. */
  public static native @ByVal Status IsValidShape(@Const @ByRef TensorShapeProto proto);

  /** Clear a tensor shape */
  public native void Clear();

  /** \brief Add a dimension to the end ("inner-most").
   *  REQUIRES: {@code size >= 0} */
  public native void AddDim(@Cast("tensorflow::int64") long size);

  /** Appends all the dimensions from {@code shape}. */
  public native void AppendShape(@Const @ByRef TensorShape shape);

  // Maximum number of dimensions in a tensor.
  public static native int MaxDimensions();

  /** \brief Insert a dimension somewhere in the {@code TensorShape}.
   *  REQUIRES: {@code 0 <= d <= dims()}
   *  REQUIRES: {@code size >= 0} */
  public native void InsertDim(int d, @Cast("tensorflow::int64") long size);

  /** \brief Modifies the size of the dimension {@code d} to be {@code size}
   *  REQUIRES: {@code 0 <= d < dims()}
   *  REQUIRES: {@code size >= 0} */
  public native void set_dim(int d, @Cast("tensorflow::int64") long size);

  /** \brief Removes dimension {@code d} from the {@code TensorShape}.
   *  REQUIRES: {@code 0 <= d < dims()} */
  public native void RemoveDim(int d);

  /** Return the number of dimensions in the tensor. */
  public native int dims();

  /** \brief Returns the number of elements in dimension {@code d}.
   *  REQUIRES: {@code 0 <= d < dims()} */
  // TODO(touts): Rename to `dimension()` to match
  // `Eigen::Tensor::dimension()`?
  public native @Cast("tensorflow::int64") long dim_size(int d);

  /** Returns sizes of all dimensions. */
  
  ///
  public native @ByVal LongVector dim_sizes();

  /** \brief Returns the number of elements in the tensor.
   * 
   *  We use {@code int64} and not {@code size_t} to be compatible with {@code Eigen::Tensor}
   *  which uses {@code ptrdiff_t}. */
  public native @Cast("tensorflow::int64") long num_elements();

  /** Returns true if {@code *this} and {@code b} have the same sizes. Ignores
   *  dimension names. */
  public native @Cast("bool") boolean IsSameSize(@Const @ByRef TensorShape b);
  public native @Cast("bool") @Name("operator ==") boolean equals(@Const @ByRef TensorShape b);
  public native @Cast("bool") @Name("operator !=") boolean notEquals(@Const @ByRef TensorShape b);

  /** Fill {@code *proto} from {@code *this}. */
  public native void AsProto(TensorShapeProto proto);

  /** Fill {@code *dsizes} from {@code *this}. */

  /** Same as {@code AsEigenDSizes()} but allows for {@code NDIMS > dims()} -- in
   *  which case we pad the rest of the sizes with 1. */

  /** For iterating through the dimensions. */
  public native @ByVal TensorShapeIter begin();
  public native @ByVal TensorShapeIter end();

  /** For error messages. */
  public native @StdString BytePointer DebugString();

  /** Same as {@code TensorShape(proto).DebugString()} but doesn't crash for
   *  invalid protos. */
  public static native @StdString BytePointer DebugString(@Const @ByRef TensorShapeProto proto);

  public native void DumpRep();
}

/** Represents the value of one dimension in a TensorShape. */
@Namespace("tensorflow") @NoOffset public static class TensorShapeDim extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TensorShapeDim(Pointer p) { super(p); }

  public TensorShapeDim(@Cast("tensorflow::int64") long s) { super((Pointer)null); allocate(s); }
  private native void allocate(@Cast("tensorflow::int64") long s);
  public native @Cast("tensorflow::int64") long size(); public native TensorShapeDim size(long size);
}

// START_SKIP_DOXYGEN
@Namespace("tensorflow") @NoOffset public static class TensorShapeIter extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TensorShapeIter(Pointer p) { super(p); }

  public TensorShapeIter(@Const TensorShape shape, int d) { super((Pointer)null); allocate(shape, d); }
  private native void allocate(@Const TensorShape shape, int d);
  public native @Cast("bool") @Name("operator ==") boolean equals(@Const @ByRef TensorShapeIter rhs);
  public native @Cast("bool") @Name("operator !=") boolean notEquals(@Const @ByRef TensorShapeIter rhs);
  public native @Name("operator ++") void increment();
  public native @ByVal @Name("operator *") TensorShapeDim multiply();
}
// END_SKIP_DOXYGEN

/** \brief Static helper routines for {@code TensorShape}. Includes a few common
 *  predicates on a tensor shape. */
@Namespace("tensorflow") public static class TensorShapeUtils extends Pointer {
    static { Loader.load(); }
    /** Default native constructor. */
    public TensorShapeUtils() { super((Pointer)null); allocate(); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public TensorShapeUtils(long size) { super((Pointer)null); allocateArray(size); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TensorShapeUtils(Pointer p) { super(p); }
    private native void allocate();
    private native void allocateArray(long size);
    @Override public TensorShapeUtils position(long position) {
        return (TensorShapeUtils)super.position(position);
    }

  public static native @Cast("bool") boolean IsScalar(@Const @ByRef TensorShape shape);

  public static native @Cast("bool") boolean IsVector(@Const @ByRef TensorShape shape);

  public static native @Cast("bool") boolean IsVectorOrHigher(@Const @ByRef TensorShape shape);

  public static native @Cast("bool") boolean IsMatrix(@Const @ByRef TensorShape shape);

  public static native @Cast("bool") boolean IsSquareMatrix(@Const @ByRef TensorShape shape);

  public static native @Cast("bool") boolean IsMatrixOrHigher(@Const @ByRef TensorShape shape);

  /** \brief Returns a {@code TensorShape} whose dimensions are
   *  {@code dims[0]}, {@code dims[1]}, ..., {@code dims[n-1]}. */
  public static native @ByVal Status MakeShape(@Const IntPointer dims, @Cast("tensorflow::int64") long n, TensorShape out);
  public static native @ByVal Status MakeShape(@Const IntBuffer dims, @Cast("tensorflow::int64") long n, TensorShape out);
  public static native @ByVal Status MakeShape(@Const int[] dims, @Cast("tensorflow::int64") long n, TensorShape out);
  public static native @ByVal Status MakeShape(@Cast("const tensorflow::int64*") LongPointer dims, @Cast("tensorflow::int64") long n, TensorShape out);
  public static native @ByVal Status MakeShape(@Cast("const tensorflow::int64*") LongBuffer dims, @Cast("tensorflow::int64") long n, TensorShape out);
  public static native @ByVal Status MakeShape(@Cast("const tensorflow::int64*") long[] dims, @Cast("tensorflow::int64") long n, TensorShape out);
  public static native @ByVal Status MakeShape(@ArraySlice IntPointer shape, TensorShape out);
  public static native @ByVal Status MakeShape(@ArraySlice IntBuffer shape, TensorShape out);
  public static native @ByVal Status MakeShape(@ArraySlice int[] shape, TensorShape out);
  public static native @ByVal Status MakeShape(@Cast("tensorflow::int64*") @ArraySlice LongPointer shape, TensorShape out);
  public static native @ByVal Status MakeShape(@Cast("tensorflow::int64*") @ArraySlice LongBuffer shape, TensorShape out);
  public static native @ByVal Status MakeShape(@Cast("tensorflow::int64*") @ArraySlice long[] shape, TensorShape out);

  public static native @StdString BytePointer ShapeListString(@Cast("const tensorflow::gtl::ArraySlice<tensorflow::TensorShape>*") @ByRef TensorShapeVector shapes);

  public static native @Cast("bool") boolean StartsWith(@Const @ByRef TensorShape shape0, @Const @ByRef TensorShape shape1);
}

// ----------------------------------------------------------------------------
// Template method implementation details below
// ----------------------------------------------------------------------------





// ----------------------------------------------------------------------------
// Inlining of some performance critical routines
// ----------------------------------------------------------------------------











  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_TENSOR_SHAPE_H_


// Parsed from tensorflow/core/framework/tensor_util.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_FRAMEWORK_TENSOR_UTIL_H_
// #define TENSORFLOW_FRAMEWORK_TENSOR_UTIL_H_

// #include "tensorflow/core/framework/tensor.h"

// #include <vector>

// DeepCopy returns a tensor whose contents are a deep copy of the
// contents of 'other'.  This function is intended only for
// convenience, not speed.
//
// REQUIRES: 'other' must point to data stored in CPU memory.
// REQUIRES: 'other' must be a Tensor of a copy-able type if
//           'other' is not appropriately memory-aligned.
@Namespace("tensorflow::tensor") public static native @ByVal Tensor DeepCopy(@Const @ByRef Tensor other);

// Concatenates 'tensors' into a single tensor, along their 0th dimension.
//
// REQUIRES: All members of 'tensors' must have the same data type parameter.
// REQUIRES: Each member of 'tensors' must have at least one dimension.
// REQUIRES: Each member of 'tensors' must point to data stored in CPU memory.
// REQUIRES: Each member of 'tensors' must be a Tensor of a copy-able type if it
//           is not appropriately memory-aligned.
@Namespace("tensorflow::tensor") public static native @ByVal Tensor Concat(@Const @ByRef TensorVector tensors);

// Splits 'tensor' into 'sizes.size()' individual tensors, along the 0th
// dimension. The ith output tensor has 0th-dimension size 'sizes[i]'.
//
// REQUIRES: 'tensor' must have at least one dimension.
// REQUIRES: 'tensor.dim_size(0)' must equal the sum of the elements of 'sizes'.
// REQUIRES: 'tensor' must point to data stored in CPU memory.
// REQUIRES: 'tensor' must be a Tensor of a copy-able type if it is not
//           appropriately memory-aligned.
//
// Split() and Concat() are inverse operations.
@Namespace("tensorflow::tensor") public static native @ByVal TensorVector Split(@Const @ByRef Tensor tensor,
                          @Cast("tensorflow::int64*") @ArraySlice LongPointer sizes);
@Namespace("tensorflow::tensor") public static native @ByVal TensorVector Split(@Const @ByRef Tensor tensor,
                          @Cast("tensorflow::int64*") @ArraySlice LongBuffer sizes);
@Namespace("tensorflow::tensor") public static native @ByVal TensorVector Split(@Const @ByRef Tensor tensor,
                          @Cast("tensorflow::int64*") @ArraySlice long... sizes);

  // namespace tensor
  // namespace tensorflow

// #endif  // TENSORFLOW_FRAMEWORK_TENSOR_UTIL_H_


// Parsed from tensorflow/core/framework/tensor_reference.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_FRAMEWORK_TENSOR_REFERENCE_H_
// #define TENSORFLOW_FRAMEWORK_TENSOR_REFERENCE_H_

// #include "tensorflow/core/framework/allocation_description.pb.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/lib/gtl/inlined_vector.h"

// An opaque class that holds a reference to an underlying TensorBuffer.
// Unlike Tensor, it does not have any shape or type information, so
// it is cheaper to construct/move, but the only thing you can really do
// with it is Unref it, which releases one of the references to the underlying
// TensorBuffer.
// IMPORTANT: If you do not call Unref(), you will likely leak tensor memory.
@Namespace("tensorflow") @NoOffset public static class TensorReference extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TensorReference(Pointer p) { super(p); }

  // Take the reference of the root buffer so the size will be more accurate
  public TensorReference(@Const @ByRef Tensor tensor) { super((Pointer)null); allocate(tensor); }
  private native void allocate(@Const @ByRef Tensor tensor);

  public native void Unref();

  // Return an estimate of the total bytes being kept alive by this reference.
  public native @Cast("size_t") long TotalBytes();

  public native void FillDescription(AllocationDescription description);

  // Convenience function for de-duplicating tensor references.
  public native @Cast("bool") boolean SharesBufferWith(@Const @ByRef TensorReference t);

  // Convenience function for de-duplicating tensor references.
  public native @Cast("bool") boolean SharesBufferWith(@Const @ByRef Tensor t);

  // Convenience function for de-duplicating tensor references.
  public native @Cast("size_t") long BufferHash();

  // A constructor used only for tests
  public TensorReference(TensorBuffer test_buffer) { super((Pointer)null); allocate(test_buffer); }
  private native void allocate(TensorBuffer test_buffer);
}

  // namespace tensorflow

// #endif  // TENSORFLOW_FRAMEWORK_TENSOR_REFERENCE_H_


// Parsed from tensorflow/core/framework/tensor.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_TENSOR_H_
// #define TENSORFLOW_CORE_FRAMEWORK_TENSOR_H_

// #include "third_party/eigen3/unsupported/Eigen/CXX11/Tensor"
// #include "tensorflow/core/framework/allocation_description.pb.h"
// #include "tensorflow/core/framework/allocator.h"
// #include "tensorflow/core/framework/tensor.pb.h"
// #include "tensorflow/core/framework/tensor_description.pb.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/tensor_types.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/framework/types.pb.h"
// #include "tensorflow/core/lib/core/refcount.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/lib/gtl/inlined_vector.h"
// #include "tensorflow/core/platform/logging.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/types.h"  // Forward declaration.
@Namespace("tensorflow") @Opaque public static class TensorCApi extends Pointer {
    /** Empty constructor. Calls {@code super((Pointer)null)}. */
    public TensorCApi() { super((Pointer)null); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TensorCApi(Pointer p) { super(p); }
}

/** Represents an n-dimensional array of values. */
@Namespace("tensorflow") @NoOffset public static class Tensor extends AbstractTensor {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Tensor(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public Tensor(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public Tensor position(long position) {
        return (Tensor)super.position(position);
    }

  /** \brief Creates a 1-dimensional, 0-element float tensor.
   * 
   *  The returned Tensor is not a scalar (shape {}), but is instead
   *  an empty one-dimensional Tensor (shape {0}, NumElements() ==
   *  0). Since it has no elements, it does not need to be assigned a
   *  value and is initialized by default (IsInitialized() is
   *  true). If this is undesirable, consider creating a one-element
   *  scalar which does require initialization:
   * 
   *  <pre>{@code c++
   * 
   *      Tensor(DT_FLOAT, TensorShape({}))
   * 
   *  }</pre> */
  
  ///
  public Tensor() { super((Pointer)null); allocate(); }
  private native void allocate();

  /** \brief Creates a Tensor of the given {@code type} and {@code shape}.  If
   *  LogMemory::IsEnabled() the allocation is logged as coming from
   *  an unknown kernel and step. Calling the Tensor constructor
   *  directly from within an Op is deprecated: use the
   *  OpKernelConstruction/OpKernelContext allocate_* methods to
   *  allocate a new tensor, which record the kernel and step.
   * 
   *  The underlying buffer is allocated using a {@code CPUAllocator}. */
  
  ///
  public Tensor(@Cast("tensorflow::DataType") int type, @Const @ByRef TensorShape shape) { super((Pointer)null); allocate(type, shape); }
  private native void allocate(@Cast("tensorflow::DataType") int type, @Const @ByRef TensorShape shape);

  /** \brief Creates a tensor with the input {@code type} and {@code shape}, using
   *  the allocator {@code a} to allocate the underlying buffer. If
   *  LogMemory::IsEnabled() the allocation is logged as coming from
   *  an unknown kernel and step. Calling the Tensor constructor
   *  directly from within an Op is deprecated: use the
   *  OpKernelConstruction/OpKernelContext allocate_* methods to
   *  allocate a new tensor, which record the kernel and step.
   * 
   *  {@code a} must outlive the lifetime of this Tensor. */
  
  ///
  public Tensor(Allocator a, @Cast("tensorflow::DataType") int type, @Const @ByRef TensorShape shape) { super((Pointer)null); allocate(a, type, shape); }
  private native void allocate(Allocator a, @Cast("tensorflow::DataType") int type, @Const @ByRef TensorShape shape);

  /** \brief Creates a tensor with the input {@code type} and {@code shape}, using
   *  the allocator {@code a} and the specified "allocation_attr" to
   *  allocate the underlying buffer. If the kernel and step are known
   *  allocation_attr.allocation_will_be_logged should be set to true
   *  and LogMemory::RecordTensorAllocation should be called after the
   *  tensor is constructed. Calling the Tensor constructor directly
   *  from within an Op is deprecated: use the
   *  OpKernelConstruction/OpKernelContext allocate_* methods to
   *  allocate a new tensor, which record the kernel and step.
   * 
   *  {@code a} must outlive the lifetime of this Tensor. */
  
  ///
  public Tensor(Allocator a, @Cast("tensorflow::DataType") int type, @Const @ByRef TensorShape shape,
           @Const @ByRef AllocationAttributes allocation_attr) { super((Pointer)null); allocate(a, type, shape, allocation_attr); }
  private native void allocate(Allocator a, @Cast("tensorflow::DataType") int type, @Const @ByRef TensorShape shape,
           @Const @ByRef AllocationAttributes allocation_attr);

  /** \brief Creates an empty Tensor of the given data type.
   * 
   *  Like Tensor(), returns a 1-dimensional, 0-element Tensor with
   *  IsInitialized() returning True. See the Tensor() documentation
   *  for details. */
  public Tensor(@Cast("tensorflow::DataType") int type) { super((Pointer)null); allocate(type); }
  private native void allocate(@Cast("tensorflow::DataType") int type);

  public Tensor(@Const @ByRef Tensor other) { super((Pointer)null); allocate(other); }
  private native void allocate(@Const @ByRef Tensor other);  /** Copy constructor. */

  // Move constructor.  After this call, <other> is safely destructible and can
  // be assigned to, but other calls on it (e.g. shape manipulation) are not
  // valid.

  /** Returns the data type. */
  public native @Cast("tensorflow::DataType") int dtype();

  /** Returns the shape of the tensor. */
  
  ///
  public native @Const @ByRef TensorShape shape();

  /** \brief Convenience accessor for the tensor shape.
   * 
   *  For all shape accessors, see comments for relevant methods of
   *  {@code TensorShape} in {@code tensor_shape.h}. */
  public native int dims();

  /** Convenience accessor for the tensor shape. */
  public native @Cast("tensorflow::int64") long dim_size(int d);

  /** Convenience accessor for the tensor shape. */
  public native @Cast("tensorflow::int64") long NumElements();

  public native @Cast("bool") boolean IsSameSize(@Const @ByRef Tensor b);

  // True iff the two tensors use the same underlying refcounted storage
  
  ///
  public native @Cast("bool") boolean SharesBufferWith(@Const @ByRef Tensor b);

  /** \brief If necessary, has this Tensor been initialized?
   * 
   *  Zero-element Tensors are always considered initialized, even if they
   *  have never been assigned to and do not have any memory allocated. */
  public native @Cast("bool") boolean IsInitialized();

  /** Returns the estimated memory usage of this tensor. */
  public native @Cast("size_t") long TotalBytes();

  /** Returns true iff this tensor is aligned. */
  public native @Cast("bool") boolean IsAligned();

  /** Assign operator. This tensor shares other's underlying storage. */
  public native @ByRef @Name("operator =") Tensor put(@Const @ByRef Tensor other);

  /** Move operator.  See move constructor for details. */

  /** \brief Copy the other tensor into this tensor and reshape it.
   * 
   *  This tensor shares other's underlying storage. Returns {@code true}
   *  iff {@code other.shape()} has the same number of elements of the given
   *  {@code shape}. */
  
  ///
  ///
  public native @Cast("bool") boolean CopyFrom(@Const @ByRef Tensor other,
                  @Const @ByRef TensorShape shape);

  /** \brief Slice this tensor along the 1st dimension.
   <p>
   *  I.e., the returned tensor satisfies
   *      returned[i, ...] == this[dim0_start + i, ...].
   *  The returned tensor shares the underlying tensor buffer with this
   *  tensor.
   * 
   *  NOTE: The returned tensor may not satisfies the same alignment
   *  requirement as this tensor depending on the shape. The caller
   *  must check the returned tensor's alignment before calling certain
   *  methods that have alignment requirement (e.g., {@code flat()}, {@code tensor()}).
   * 
   *  REQUIRES: {@code dims()} >= 1
   *  REQUIRES: {@code 0 <= dim0_start <= dim0_limit <= dim_size(0)} */
  public native @ByVal Tensor Slice(@Cast("tensorflow::int64") long dim0_start, @Cast("tensorflow::int64") long dim0_limit);

  /** \brief Parse {@code other} and construct the tensor.
   <p>
   *  Returns {@code true} iff the parsing succeeds. If the parsing fails,
   *  the state of {@code *this} is unchanged. */
  public native @Cast("bool") boolean FromProto(@Const @ByRef TensorProto other);
  
  ///
  public native @Cast("bool") boolean FromProto(Allocator a, @Const @ByRef TensorProto other);

  /** \brief Fills in {@code proto} with {@code *this} tensor's content.
   * 
   *  {@code AsProtoField()} fills in the repeated field for {@code proto.dtype()}, while
   *  {@code AsProtoTensorContent()} encodes the content in {@code proto.tensor_content()}
   *  in a compact form. */
  public native void AsProtoField(TensorProto proto);
  
  ///
  ///
  ///
  ///
  ///
  public native void AsProtoTensorContent(TensorProto proto);

  /** \brief Return the tensor data as an {@code Eigen::Tensor} with the type and
   *  sizes of this {@code Tensor}.
   * 
   *  Use these methods when you know the data type and the number of
   *  dimensions of the Tensor and you want an {@code Eigen::Tensor}
   *  automatically sized to the {@code Tensor} sizes. The implementation check
   *  fails if either type or sizes mismatch.
   * 
   *  Example:
   * 
   *  <pre>{@code c++
   * 
   *      typedef float T;
   *      Tensor my_mat(...built with Shape{rows: 3, cols: 5}...);
   *      auto mat = my_mat.matrix<T>();    // 2D Eigen::Tensor, 3 x 5.
   *      auto mat = my_mat.tensor<T, 2>(); // 2D Eigen::Tensor, 3 x 5.
   *      auto vec = my_mat.vec<T>();       // CHECK fails as my_mat is 2D.
   *      auto vec = my_mat.tensor<T, 3>(); // CHECK fails as my_mat is 2D.
   *      auto mat = my_mat.matrix<int32>();// CHECK fails as type mismatch.
   * 
   *  }</pre> */

  /** \brief Return the tensor data to an {@code Eigen::Tensor} with the
   *  same size but a bitwise cast to the specified dtype {@code T}.
   * 
   *  Using a bitcast is useful for move and copy operations.
   *  NOTE: this is the same as {@code tensor()} except a bitcast is allowed. */

  /** \brief Return the tensor data as an {@code Eigen::Tensor} of the data type and a
   *  specified shape.
   * 
   *  These methods allow you to access the data with the dimensions
   *  and sizes of your choice.  You do not need to know the number of
   *  dimensions of the Tensor to call them.  However, they {@code CHECK} that
   *  the type matches and the dimensions requested creates an
   *  {@code Eigen::Tensor} with the same number of elements as the tensor.
   * 
   *  Example:
   * 
   *  <pre>{@code c++
   * 
   *      typedef float T;
   *      Tensor my_ten(...built with Shape{planes: 4, rows: 3, cols: 5}...);
   *      // 1D Eigen::Tensor, size 60:
   *      auto flat = my_ten.flat<T>();
   *      // 2D Eigen::Tensor 12 x 5:
   *      auto inner = my_ten.flat_inner_dims<T>();
   *      // 2D Eigen::Tensor 4 x 15:
   *      auto outer = my_ten.shaped<T, 2>({4, 15});
   *      // CHECK fails, bad num elements:
   *      auto outer = my_ten.shaped<T, 2>({4, 8});
   *      // 3D Eigen::Tensor 6 x 5 x 2:
   *      auto weird = my_ten.shaped<T, 3>({6, 5, 2});
   *      // CHECK fails, type mismatch:
   *      auto bad   = my_ten.flat<int32>();
   * 
   *  }</pre> */

  /** Returns the data as an Eigen::Tensor with NDIMS dimensions, collapsing all
   *  Tensor dimensions but the last NDIMS-1 into the first dimension of the
   *  result. If NDIMS > dims() then leading dimensions of size 1 will be
   *  added to make the output rank NDIMS. */

  /** Returns the data as an Eigen::Tensor with NDIMS dimensions, collapsing all
   *  Tensor dimensions but the first NDIMS-1 into the last dimension of the
   *  result. If NDIMS > dims() then trailing dimensions of size 1 will be
   *  added to make the output rank NDIMS. */

  /** \brief Return the tensor data to an {@code Eigen::Tensor} with the new
   *  shape specified in {@code new_sizes} and cast to a new dtype {@code T}.
   * 
   *  Using a bitcast is useful for move and copy operations.
   *  The allowed bitcast is the only difference from {@code shaped()}. */

  /** \brief Return the Tensor data as a {@code TensorMap} of fixed size 1:
   *  {@code TensorMap<TensorFixedSize<T, 1>>}.
   <p>
   *  Using {@code scalar()} allows the compiler to perform optimizations as
   *  the size of the tensor is known at compile time. */

  /** Const versions of all the methods above. */

  /** \brief Return the tensor data to an {@code Eigen::Tensor} with the
   *  same size but a bitwise cast to the specified dtype {@code T}.
   * 
   *  Using a bitcast is useful for move and copy operations.
   *  NOTE: this is the same as {@code tensor()} except a bitcast is allowed. */

  /** \brief Return the tensor data to an {@code Eigen::Tensor} with the new
   *  shape specified in {@code new_sizes} and cast to a new dtype {@code T}.
   * 
   *  Using a bitcast is useful for move and copy operations.
   *  The allowed bitcast is the only difference from {@code shaped()}. */

  /** Render the first {@code max_entries} values in {@code *this} into a string. */
  public native @StdString BytePointer SummarizeValue(@Cast("tensorflow::int64") long max_entries);

  /** A human-readable summary of the tensor suitable for debugging. */
  public native @StdString BytePointer DebugString();

  /** Fill in the {@code TensorDescription} proto with metadata about the
   *  tensor that is useful for monitoring and debugging. */
  
  ///
  ///
  ///
  public native void FillDescription(TensorDescription description);

  /** \brief Returns a {@code StringPiece} mapping the current tensor's buffer.
   * 
   *  The returned {@code StringPiece} may point to memory location on devices
   *  that the CPU cannot address directly.
   * 
   *  NOTE: The underlying tensor buffer is refcounted, so the lifetime
   *  of the contents mapped by the {@code StringPiece} matches the lifetime of
   *  the buffer; callers should arrange to make sure the buffer does
   *  not get destroyed while the {@code StringPiece} is still used.
   * 
   *  REQUIRES: {@code DataTypeCanUseMemcpy(dtype())}. */
  
  ///
  public native @StringPiece BytePointer tensor_data();

  /** Copy the other tensor into this tensor and reshape it and reinterpret the
   *  buffer's datatype.
   * 
   *  This tensor shares other's underlying storage. */
  public native void UnsafeCopyFromInternal(@Const @ByRef Tensor arg0, @Cast("tensorflow::DataType") int dtype,
                                @Const @ByRef TensorShape arg2);
}

// Implementation details

// START_SKIP_DOXYGEN

// Interface to access the raw ref-counted data buffer.
@Namespace("tensorflow") public static class TensorBuffer extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TensorBuffer(Pointer p) { super(p); }


  // data() points to a memory region of size() bytes.
  public native Pointer data();
  public native @Cast("size_t") long size();

  // If this TensorBuffer is sub-buffer of another TensorBuffer,
  // returns that TensorBuffer. Otherwise, returns this.
  public native TensorBuffer root_buffer();

  // Fill metadata about the allocation into the proto.
  public native void FillAllocationDescription(
        AllocationDescription proto);
}













































// END_SKIP_DOXYGEN

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_TENSOR_H_


// Parsed from tensorflow/core/framework/attr_value.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/attr_value.proto

// #ifndef PROTOBUF_tensorflow_2fcore_2fframework_2fattr_5fvalue_2eproto__INCLUDED
// #define PROTOBUF_tensorflow_2fcore_2fframework_2fattr_5fvalue_2eproto__INCLUDED

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3000000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3000000 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>
// #include <google/protobuf/extension_set.h>
// #include <google/protobuf/map.h>
// #include <google/protobuf/map_field_inl.h>
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/tensor.pb.h"
// #include "tensorflow/core/framework/tensor_shape.pb.h"
// #include "tensorflow/core/framework/types.pb.h"
// @@protoc_insertion_point(includes)

// Internal implementation detail -- do not call these.
@Namespace("tensorflow") public static native void protobuf_AddDesc_tensorflow_2fcore_2fframework_2fattr_5fvalue_2eproto();
@Namespace("tensorflow") public static native void protobuf_AssignDesc_tensorflow_2fcore_2fframework_2fattr_5fvalue_2eproto();
@Namespace("tensorflow") public static native void protobuf_ShutdownFile_tensorflow_2fcore_2fframework_2fattr_5fvalue_2eproto();

// ===================================================================

@Namespace("tensorflow") @NoOffset public static class AttrValue_ListValue extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public AttrValue_ListValue(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public AttrValue_ListValue(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public AttrValue_ListValue position(long position) {
        return (AttrValue_ListValue)super.position(position);
    }

  public AttrValue_ListValue() { super((Pointer)null); allocate(); }
  private native void allocate();

  public AttrValue_ListValue(@Const @ByRef AttrValue_ListValue from) { super((Pointer)null); allocate(from); }
  private native void allocate(@Const @ByRef AttrValue_ListValue from);

  public native @ByRef @Name("operator =") AttrValue_ListValue put(@Const @ByRef AttrValue_ListValue from);

  public native @Cast("google::protobuf::Arena*") Pointer GetArena();
  public native Pointer GetMaybeArenaPointer();
  public static native @Cast("const google::protobuf::Descriptor*") Pointer descriptor();
  public static native @Const @ByRef AttrValue_ListValue default_instance();

  public native void UnsafeArenaSwap(AttrValue_ListValue other);
  public native void Swap(AttrValue_ListValue other);

  // implements Message ----------------------------------------------

  public native AttrValue_ListValue New();

  public native AttrValue_ListValue New(@Cast("google::protobuf::Arena*") Pointer arena);
  public native void CopyFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void MergeFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void CopyFrom(@Const @ByRef AttrValue_ListValue from);
  public native void MergeFrom(@Const @ByRef AttrValue_ListValue from);
  public native void Clear();
  public native @Cast("bool") boolean IsInitialized();

  public native int ByteSize();
  public native @Cast("bool") boolean MergePartialFromCodedStream(
        @Cast("google::protobuf::io::CodedInputStream*") Pointer input);
  public native void SerializeWithCachedSizes(
        @Cast("google::protobuf::io::CodedOutputStream*") Pointer output);
  public native @Cast("google::protobuf::uint8*") BytePointer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") byte[] output);
  public native @Cast("google::protobuf::uint8*") BytePointer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") byte[] output);
  public native int GetCachedSize();

  public native @ByVal @Cast("google::protobuf::Metadata*") Pointer GetMetadata();

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated bytes s = 2;
  public native int s_size();
  public native void clear_s();
  @MemberGetter public static native int kSFieldNumber();
  public static final int kSFieldNumber = kSFieldNumber();
  public native @StdString BytePointer s(int index);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_s(int index);
  public native void set_s(int index, @StdString BytePointer value);
  public native void set_s(int index, @StdString String value);
  public native void set_s(int index, @Const Pointer value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer add_s();
  public native void add_s(@StdString BytePointer value);
  public native void add_s(@StdString String value);
  public native void add_s(@Const Pointer value, @Cast("size_t") long size);

  // repeated int64 i = 3 [packed = true];
  public native int i_size();
  public native void clear_i();
  @MemberGetter public static native int kIFieldNumber();
  public static final int kIFieldNumber = kIFieldNumber();
  public native @Cast("google::protobuf::int64") long i(int index);
  public native void set_i(int index, @Cast("google::protobuf::int64") long value);
  public native void add_i(@Cast("google::protobuf::int64") long value);

  // repeated float f = 4 [packed = true];
  public native int f_size();
  public native void clear_f();
  @MemberGetter public static native int kFFieldNumber();
  public static final int kFFieldNumber = kFFieldNumber();
  public native float f(int index);
  public native void set_f(int index, float value);
  public native void add_f(float value);

  // repeated bool b = 5 [packed = true];
  public native int b_size();
  public native void clear_b();
  @MemberGetter public static native int kBFieldNumber();
  public static final int kBFieldNumber = kBFieldNumber();
  public native @Cast("bool") boolean b(int index);
  public native void set_b(int index, @Cast("bool") boolean value);
  public native void add_b(@Cast("bool") boolean value);

  // repeated .tensorflow.DataType type = 6 [packed = true];
  public native int type_size();
  public native void clear_type();
  @MemberGetter public static native int kTypeFieldNumber();
  public static final int kTypeFieldNumber = kTypeFieldNumber();
  public native @Cast("tensorflow::DataType") int type(int index);
  public native void set_type(int index, @Cast("tensorflow::DataType") int value);
  public native void add_type(@Cast("tensorflow::DataType") int value);

  // repeated .tensorflow.TensorShapeProto shape = 7;
  public native int shape_size();
  public native void clear_shape();
  @MemberGetter public static native int kShapeFieldNumber();
  public static final int kShapeFieldNumber = kShapeFieldNumber();
  public native @Const @ByRef TensorShapeProto shape(int index);
  public native TensorShapeProto mutable_shape(int index);
  public native TensorShapeProto add_shape();

  // repeated .tensorflow.TensorProto tensor = 8;
  public native int tensor_size();
  public native void clear_tensor();
  @MemberGetter public static native int kTensorFieldNumber();
  public static final int kTensorFieldNumber = kTensorFieldNumber();
  public native @Const @ByRef TensorProto tensor(int index);
  public native TensorProto mutable_tensor(int index);
  public native TensorProto add_tensor();
}
// -------------------------------------------------------------------

@Namespace("tensorflow") @NoOffset public static class AttrValue extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public AttrValue(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public AttrValue(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public AttrValue position(long position) {
        return (AttrValue)super.position(position);
    }

  public AttrValue() { super((Pointer)null); allocate(); }
  private native void allocate();

  public AttrValue(@Const @ByRef AttrValue from) { super((Pointer)null); allocate(from); }
  private native void allocate(@Const @ByRef AttrValue from);

  public native @ByRef @Name("operator =") AttrValue put(@Const @ByRef AttrValue from);

  public native @Cast("google::protobuf::Arena*") Pointer GetArena();
  public native Pointer GetMaybeArenaPointer();
  public static native @Cast("const google::protobuf::Descriptor*") Pointer descriptor();
  public static native @Const @ByRef AttrValue default_instance();

  /** enum tensorflow::AttrValue::ValueCase */
  public static final int
    kS = 2,
    kI = 3,
    kF = 4,
    kB = 5,
    kType = 6,
    kShape = 7,
    kTensor = 8,
    kList = 1,
    kFunc = 10,
    kPlaceholder = 9,
    VALUE_NOT_SET = 0;

  public native void UnsafeArenaSwap(AttrValue other);
  public native void Swap(AttrValue other);

  // implements Message ----------------------------------------------

  public native AttrValue New();

  public native AttrValue New(@Cast("google::protobuf::Arena*") Pointer arena);
  public native void CopyFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void MergeFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void CopyFrom(@Const @ByRef AttrValue from);
  public native void MergeFrom(@Const @ByRef AttrValue from);
  public native void Clear();
  public native @Cast("bool") boolean IsInitialized();

  public native int ByteSize();
  public native @Cast("bool") boolean MergePartialFromCodedStream(
        @Cast("google::protobuf::io::CodedInputStream*") Pointer input);
  public native void SerializeWithCachedSizes(
        @Cast("google::protobuf::io::CodedOutputStream*") Pointer output);
  public native @Cast("google::protobuf::uint8*") BytePointer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") byte[] output);
  public native @Cast("google::protobuf::uint8*") BytePointer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") byte[] output);
  public native int GetCachedSize();

  public native @ByVal @Cast("google::protobuf::Metadata*") Pointer GetMetadata();

  // nested types ----------------------------------------------------
  public native void clear_s();
  @MemberGetter public static native int kSFieldNumber();
  public static final int kSFieldNumber = kSFieldNumber();
  public native @StdString BytePointer s();
  public native void set_s(@StdString BytePointer value);
  public native void set_s(@StdString String value);
  public native void set_s(@Const Pointer value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_s();
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer release_s();
  public native void set_allocated_s(@StdString @Cast({"char*", "std::string*"}) BytePointer s);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer unsafe_arena_release_s();
  public native void unsafe_arena_set_allocated_s(
        @StdString @Cast({"char*", "std::string*"}) BytePointer s);
  public native void clear_i();
  @MemberGetter public static native int kIFieldNumber();
  public static final int kIFieldNumber = kIFieldNumber();
  public native @Cast("google::protobuf::int64") long i();
  public native void set_i(@Cast("google::protobuf::int64") long value);
  public native void clear_f();
  @MemberGetter public static native int kFFieldNumber();
  public static final int kFFieldNumber = kFFieldNumber();
  public native float f();
  public native void set_f(float value);
  public native void clear_b();
  @MemberGetter public static native int kBFieldNumber();
  public static final int kBFieldNumber = kBFieldNumber();
  public native @Cast("bool") boolean b();
  public native void set_b(@Cast("bool") boolean value);
  public native void clear_type();
  @MemberGetter public static native int kTypeFieldNumber();
  public static final int kTypeFieldNumber = kTypeFieldNumber();
  public native @Cast("tensorflow::DataType") int type();
  public native void set_type(@Cast("tensorflow::DataType") int value);

  // optional .tensorflow.TensorShapeProto shape = 7;
  public native @Cast("bool") boolean has_shape();
  public native void clear_shape();
  @MemberGetter public static native int kShapeFieldNumber();
  public static final int kShapeFieldNumber = kShapeFieldNumber();
  public native @Const @ByRef TensorShapeProto shape();
  public native TensorShapeProto mutable_shape();
  public native TensorShapeProto release_shape();
  public native void set_allocated_shape(TensorShapeProto shape);
  public native TensorShapeProto unsafe_arena_release_shape();
  public native void unsafe_arena_set_allocated_shape(
        TensorShapeProto shape);

  // optional .tensorflow.TensorProto tensor = 8;
  public native @Cast("bool") boolean has_tensor();
  public native void clear_tensor();
  @MemberGetter public static native int kTensorFieldNumber();
  public static final int kTensorFieldNumber = kTensorFieldNumber();
  public native @Const @ByRef TensorProto tensor();
  public native TensorProto mutable_tensor();
  public native TensorProto release_tensor();
  public native void set_allocated_tensor(TensorProto tensor);
  public native TensorProto unsafe_arena_release_tensor();
  public native void unsafe_arena_set_allocated_tensor(
        TensorProto tensor);

  // optional .tensorflow.AttrValue.ListValue list = 1;
  public native @Cast("bool") boolean has_list();
  public native void clear_list();
  @MemberGetter public static native int kListFieldNumber();
  public static final int kListFieldNumber = kListFieldNumber();
  public native @Const @ByRef AttrValue_ListValue list();
  public native AttrValue_ListValue mutable_list();
  public native AttrValue_ListValue release_list();
  public native void set_allocated_list(AttrValue_ListValue list);
  public native AttrValue_ListValue unsafe_arena_release_list();
  public native void unsafe_arena_set_allocated_list(
        AttrValue_ListValue list);

  // optional .tensorflow.NameAttrList func = 10;
  public native @Cast("bool") boolean has_func();
  public native void clear_func();
  @MemberGetter public static native int kFuncFieldNumber();
  public static final int kFuncFieldNumber = kFuncFieldNumber();
  public native @Const @ByRef NameAttrList func();
  public native NameAttrList mutable_func();
  public native NameAttrList release_func();
  public native void set_allocated_func(NameAttrList func);
  public native NameAttrList unsafe_arena_release_func();
  public native void unsafe_arena_set_allocated_func(
        NameAttrList func);
  public native void clear_placeholder();
  @MemberGetter public static native int kPlaceholderFieldNumber();
  public static final int kPlaceholderFieldNumber = kPlaceholderFieldNumber();
  public native @StdString BytePointer placeholder();
  public native void set_placeholder(@StdString BytePointer value);
  public native void set_placeholder(@StdString String value);
  public native void set_placeholder(@Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void set_placeholder(String value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_placeholder();
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer release_placeholder();
  public native void set_allocated_placeholder(@StdString @Cast({"char*", "std::string*"}) BytePointer placeholder);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer unsafe_arena_release_placeholder();
  public native void unsafe_arena_set_allocated_placeholder(
        @StdString @Cast({"char*", "std::string*"}) BytePointer placeholder);

  public native @Cast("tensorflow::AttrValue::ValueCase") int value_case();
}
// -------------------------------------------------------------------

@Namespace("tensorflow") @NoOffset public static class NameAttrList extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public NameAttrList(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public NameAttrList(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public NameAttrList position(long position) {
        return (NameAttrList)super.position(position);
    }

  public NameAttrList() { super((Pointer)null); allocate(); }
  private native void allocate();

  public NameAttrList(@Const @ByRef NameAttrList from) { super((Pointer)null); allocate(from); }
  private native void allocate(@Const @ByRef NameAttrList from);

  public native @ByRef @Name("operator =") NameAttrList put(@Const @ByRef NameAttrList from);

  public native @Cast("google::protobuf::Arena*") Pointer GetArena();
  public native Pointer GetMaybeArenaPointer();
  public static native @Cast("const google::protobuf::Descriptor*") Pointer descriptor();
  public static native @Const @ByRef NameAttrList default_instance();

  public native void UnsafeArenaSwap(NameAttrList other);
  public native void Swap(NameAttrList other);

  // implements Message ----------------------------------------------

  public native NameAttrList New();

  public native NameAttrList New(@Cast("google::protobuf::Arena*") Pointer arena);
  public native void CopyFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void MergeFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void CopyFrom(@Const @ByRef NameAttrList from);
  public native void MergeFrom(@Const @ByRef NameAttrList from);
  public native void Clear();
  public native @Cast("bool") boolean IsInitialized();

  public native int ByteSize();
  public native @Cast("bool") boolean MergePartialFromCodedStream(
        @Cast("google::protobuf::io::CodedInputStream*") Pointer input);
  public native void SerializeWithCachedSizes(
        @Cast("google::protobuf::io::CodedOutputStream*") Pointer output);
  public native @Cast("google::protobuf::uint8*") BytePointer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") byte[] output);
  public native @Cast("google::protobuf::uint8*") BytePointer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") byte[] output);
  public native int GetCachedSize();

  public native @ByVal @Cast("google::protobuf::Metadata*") Pointer GetMetadata();

  // nested types ----------------------------------------------------


  // accessors -------------------------------------------------------

  // optional string name = 1;
  public native void clear_name();
  @MemberGetter public static native int kNameFieldNumber();
  public static final int kNameFieldNumber = kNameFieldNumber();
  public native @StdString BytePointer name();
  public native void set_name(@StdString BytePointer value);
  public native void set_name(@StdString String value);
  public native void set_name(@Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void set_name(String value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_name();
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer release_name();
  public native void set_allocated_name(@StdString @Cast({"char*", "std::string*"}) BytePointer name);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer unsafe_arena_release_name();
  public native void unsafe_arena_set_allocated_name(
        @StdString @Cast({"char*", "std::string*"}) BytePointer name);

  // map<string, .tensorflow.AttrValue> attr = 2;
  public native int attr_size();
  public native void clear_attr();
  @MemberGetter public static native int kAttrFieldNumber();
  public static final int kAttrFieldNumber = kAttrFieldNumber();
  public native @Const @ByRef StringAttrValueMap attr();
  public native StringAttrValueMap mutable_attr();
}
// ===================================================================


// ===================================================================

// #if !PROTOBUF_INLINE_NOT_IN_HEADERS
// AttrValue_ListValue

// repeated bytes s = 2;














// repeated int64 i = 3 [packed = true];








// repeated float f = 4 [packed = true];








// repeated bool b = 5 [packed = true];








// repeated .tensorflow.DataType type = 6 [packed = true];








// repeated .tensorflow.TensorShapeProto shape = 7;








// repeated .tensorflow.TensorProto tensor = 8;








// -------------------------------------------------------------------

// AttrValue

// optional bytes s = 2;













// optional int64 i = 3;






// optional float f = 4;






// optional bool b = 5;






// optional .tensorflow.DataType type = 6;






// optional .tensorflow.TensorShapeProto shape = 7;










// optional .tensorflow.TensorProto tensor = 8;










// optional .tensorflow.AttrValue.ListValue list = 1;










// optional .tensorflow.NameAttrList func = 10;










// optional string placeholder = 9;
















// -------------------------------------------------------------------

// NameAttrList

// optional string name = 1;











// map<string, .tensorflow.AttrValue> attr = 2;





// #endif  // !PROTOBUF_INLINE_NOT_IN_HEADERS
// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_tensorflow_2fcore_2fframework_2fattr_5fvalue_2eproto__INCLUDED


// Parsed from tensorflow/core/framework/node_def.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/node_def.proto

// #ifndef PROTOBUF_tensorflow_2fcore_2fframework_2fnode_5fdef_2eproto__INCLUDED
// #define PROTOBUF_tensorflow_2fcore_2fframework_2fnode_5fdef_2eproto__INCLUDED

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3000000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3000000 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>
// #include <google/protobuf/extension_set.h>
// #include <google/protobuf/map.h>
// #include <google/protobuf/map_field_inl.h>
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/attr_value.pb.h"
// @@protoc_insertion_point(includes)

// Internal implementation detail -- do not call these.
@Namespace("tensorflow") public static native void protobuf_AddDesc_tensorflow_2fcore_2fframework_2fnode_5fdef_2eproto();
@Namespace("tensorflow") public static native void protobuf_AssignDesc_tensorflow_2fcore_2fframework_2fnode_5fdef_2eproto();
@Namespace("tensorflow") public static native void protobuf_ShutdownFile_tensorflow_2fcore_2fframework_2fnode_5fdef_2eproto();

// ===================================================================

@Namespace("tensorflow") @NoOffset public static class NodeDef extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public NodeDef(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public NodeDef(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public NodeDef position(long position) {
        return (NodeDef)super.position(position);
    }

  public NodeDef() { super((Pointer)null); allocate(); }
  private native void allocate();

  public NodeDef(@Const @ByRef NodeDef from) { super((Pointer)null); allocate(from); }
  private native void allocate(@Const @ByRef NodeDef from);

  public native @ByRef @Name("operator =") NodeDef put(@Const @ByRef NodeDef from);

  public native @Cast("google::protobuf::Arena*") Pointer GetArena();
  public native Pointer GetMaybeArenaPointer();
  public static native @Cast("const google::protobuf::Descriptor*") Pointer descriptor();
  public static native @Const @ByRef NodeDef default_instance();

  public native void UnsafeArenaSwap(NodeDef other);
  public native void Swap(NodeDef other);

  // implements Message ----------------------------------------------

  public native NodeDef New();

  public native NodeDef New(@Cast("google::protobuf::Arena*") Pointer arena);
  public native void CopyFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void MergeFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void CopyFrom(@Const @ByRef NodeDef from);
  public native void MergeFrom(@Const @ByRef NodeDef from);
  public native void Clear();
  public native @Cast("bool") boolean IsInitialized();

  public native int ByteSize();
  public native @Cast("bool") boolean MergePartialFromCodedStream(
        @Cast("google::protobuf::io::CodedInputStream*") Pointer input);
  public native void SerializeWithCachedSizes(
        @Cast("google::protobuf::io::CodedOutputStream*") Pointer output);
  public native @Cast("google::protobuf::uint8*") BytePointer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") byte[] output);
  public native @Cast("google::protobuf::uint8*") BytePointer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") byte[] output);
  public native int GetCachedSize();

  public native @ByVal @Cast("google::protobuf::Metadata*") Pointer GetMetadata();

  // nested types ----------------------------------------------------


  // accessors -------------------------------------------------------

  // optional string name = 1;
  public native void clear_name();
  @MemberGetter public static native int kNameFieldNumber();
  public static final int kNameFieldNumber = kNameFieldNumber();
  public native @StdString BytePointer name();
  public native void set_name(@StdString BytePointer value);
  public native void set_name(@StdString String value);
  public native void set_name(@Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void set_name(String value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_name();
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer release_name();
  public native void set_allocated_name(@StdString @Cast({"char*", "std::string*"}) BytePointer name);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer unsafe_arena_release_name();
  public native void unsafe_arena_set_allocated_name(
        @StdString @Cast({"char*", "std::string*"}) BytePointer name);

  // optional string op = 2;
  public native void clear_op();
  @MemberGetter public static native int kOpFieldNumber();
  public static final int kOpFieldNumber = kOpFieldNumber();
  public native @StdString BytePointer op();
  public native void set_op(@StdString BytePointer value);
  public native void set_op(@StdString String value);
  public native void set_op(@Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void set_op(String value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_op();
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer release_op();
  public native void set_allocated_op(@StdString @Cast({"char*", "std::string*"}) BytePointer op);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer unsafe_arena_release_op();
  public native void unsafe_arena_set_allocated_op(
        @StdString @Cast({"char*", "std::string*"}) BytePointer op);

  // repeated string input = 3;
  public native int input_size();
  public native void clear_input();
  @MemberGetter public static native int kInputFieldNumber();
  public static final int kInputFieldNumber = kInputFieldNumber();
  public native @StdString BytePointer input(int index);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_input(int index);
  public native void set_input(int index, @StdString BytePointer value);
  public native void set_input(int index, @StdString String value);
  public native void set_input(int index, @Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void set_input(int index, String value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer add_input();
  public native void add_input(@StdString BytePointer value);
  public native void add_input(@StdString String value);
  public native void add_input(@Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void add_input(String value, @Cast("size_t") long size);

  // optional string device = 4;
  public native void clear_device();
  @MemberGetter public static native int kDeviceFieldNumber();
  public static final int kDeviceFieldNumber = kDeviceFieldNumber();
  public native @StdString BytePointer device();
  public native void set_device(@StdString BytePointer value);
  public native void set_device(@StdString String value);
  public native void set_device(@Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void set_device(String value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_device();
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer release_device();
  public native void set_allocated_device(@StdString @Cast({"char*", "std::string*"}) BytePointer device);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer unsafe_arena_release_device();
  public native void unsafe_arena_set_allocated_device(
        @StdString @Cast({"char*", "std::string*"}) BytePointer device);

  // map<string, .tensorflow.AttrValue> attr = 5;
  public native int attr_size();
  public native void clear_attr();
  @MemberGetter public static native int kAttrFieldNumber();
  public static final int kAttrFieldNumber = kAttrFieldNumber();
  public native @Const @ByRef StringAttrValueMap attr();
  public native StringAttrValueMap mutable_attr();
}
// ===================================================================


// ===================================================================

// #if !PROTOBUF_INLINE_NOT_IN_HEADERS
// NodeDef

// optional string name = 1;











// optional string op = 2;











// repeated string input = 3;














// optional string device = 4;











// map<string, .tensorflow.AttrValue> attr = 5;





// #endif  // !PROTOBUF_INLINE_NOT_IN_HEADERS

// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_tensorflow_2fcore_2fframework_2fnode_5fdef_2eproto__INCLUDED


// Parsed from tensorflow/core/framework/op_def.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/op_def.proto

// #ifndef PROTOBUF_tensorflow_2fcore_2fframework_2fop_5fdef_2eproto__INCLUDED
// #define PROTOBUF_tensorflow_2fcore_2fframework_2fop_5fdef_2eproto__INCLUDED

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3000000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3000000 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>
// #include <google/protobuf/extension_set.h>
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/attr_value.pb.h"
// #include "tensorflow/core/framework/types.pb.h"
// @@protoc_insertion_point(includes)

// Internal implementation detail -- do not call these.
@Namespace("tensorflow") public static native void protobuf_AddDesc_tensorflow_2fcore_2fframework_2fop_5fdef_2eproto();
@Namespace("tensorflow") public static native void protobuf_AssignDesc_tensorflow_2fcore_2fframework_2fop_5fdef_2eproto();
@Namespace("tensorflow") public static native void protobuf_ShutdownFile_tensorflow_2fcore_2fframework_2fop_5fdef_2eproto();

// ===================================================================

@Namespace("tensorflow") @NoOffset public static class OpDef_ArgDef extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public OpDef_ArgDef(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public OpDef_ArgDef(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public OpDef_ArgDef position(long position) {
        return (OpDef_ArgDef)super.position(position);
    }

  public OpDef_ArgDef() { super((Pointer)null); allocate(); }
  private native void allocate();

  public OpDef_ArgDef(@Const @ByRef OpDef_ArgDef from) { super((Pointer)null); allocate(from); }
  private native void allocate(@Const @ByRef OpDef_ArgDef from);

  public native @ByRef @Name("operator =") OpDef_ArgDef put(@Const @ByRef OpDef_ArgDef from);

  public native @Cast("google::protobuf::Arena*") Pointer GetArena();
  public native Pointer GetMaybeArenaPointer();
  public static native @Cast("const google::protobuf::Descriptor*") Pointer descriptor();
  public static native @Const @ByRef OpDef_ArgDef default_instance();

  public native void UnsafeArenaSwap(OpDef_ArgDef other);
  public native void Swap(OpDef_ArgDef other);

  // implements Message ----------------------------------------------

  public native OpDef_ArgDef New();

  public native OpDef_ArgDef New(@Cast("google::protobuf::Arena*") Pointer arena);
  public native void CopyFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void MergeFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void CopyFrom(@Const @ByRef OpDef_ArgDef from);
  public native void MergeFrom(@Const @ByRef OpDef_ArgDef from);
  public native void Clear();
  public native @Cast("bool") boolean IsInitialized();

  public native int ByteSize();
  public native @Cast("bool") boolean MergePartialFromCodedStream(
        @Cast("google::protobuf::io::CodedInputStream*") Pointer input);
  public native void SerializeWithCachedSizes(
        @Cast("google::protobuf::io::CodedOutputStream*") Pointer output);
  public native @Cast("google::protobuf::uint8*") BytePointer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") byte[] output);
  public native @Cast("google::protobuf::uint8*") BytePointer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") byte[] output);
  public native int GetCachedSize();

  public native @ByVal @Cast("google::protobuf::Metadata*") Pointer GetMetadata();

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional string name = 1;
  public native void clear_name();
  @MemberGetter public static native int kNameFieldNumber();
  public static final int kNameFieldNumber = kNameFieldNumber();
  public native @StdString BytePointer name();
  public native void set_name(@StdString BytePointer value);
  public native void set_name(@StdString String value);
  public native void set_name(@Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void set_name(String value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_name();
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer release_name();
  public native void set_allocated_name(@StdString @Cast({"char*", "std::string*"}) BytePointer name);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer unsafe_arena_release_name();
  public native void unsafe_arena_set_allocated_name(
        @StdString @Cast({"char*", "std::string*"}) BytePointer name);

  // optional string description = 2;
  public native void clear_description();
  @MemberGetter public static native int kDescriptionFieldNumber();
  public static final int kDescriptionFieldNumber = kDescriptionFieldNumber();
  public native @StdString BytePointer description();
  public native void set_description(@StdString BytePointer value);
  public native void set_description(@StdString String value);
  public native void set_description(@Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void set_description(String value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_description();
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer release_description();
  public native void set_allocated_description(@StdString @Cast({"char*", "std::string*"}) BytePointer description);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer unsafe_arena_release_description();
  public native void unsafe_arena_set_allocated_description(
        @StdString @Cast({"char*", "std::string*"}) BytePointer description);

  // optional .tensorflow.DataType type = 3;
  public native void clear_type();
  @MemberGetter public static native int kTypeFieldNumber();
  public static final int kTypeFieldNumber = kTypeFieldNumber();
  public native @Cast("tensorflow::DataType") int type();
  public native void set_type(@Cast("tensorflow::DataType") int value);

  // optional string type_attr = 4;
  public native void clear_type_attr();
  @MemberGetter public static native int kTypeAttrFieldNumber();
  public static final int kTypeAttrFieldNumber = kTypeAttrFieldNumber();
  public native @StdString BytePointer type_attr();
  public native void set_type_attr(@StdString BytePointer value);
  public native void set_type_attr(@StdString String value);
  public native void set_type_attr(@Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void set_type_attr(String value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_type_attr();
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer release_type_attr();
  public native void set_allocated_type_attr(@StdString @Cast({"char*", "std::string*"}) BytePointer type_attr);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer unsafe_arena_release_type_attr();
  public native void unsafe_arena_set_allocated_type_attr(
        @StdString @Cast({"char*", "std::string*"}) BytePointer type_attr);

  // optional string number_attr = 5;
  public native void clear_number_attr();
  @MemberGetter public static native int kNumberAttrFieldNumber();
  public static final int kNumberAttrFieldNumber = kNumberAttrFieldNumber();
  public native @StdString BytePointer number_attr();
  public native void set_number_attr(@StdString BytePointer value);
  public native void set_number_attr(@StdString String value);
  public native void set_number_attr(@Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void set_number_attr(String value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_number_attr();
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer release_number_attr();
  public native void set_allocated_number_attr(@StdString @Cast({"char*", "std::string*"}) BytePointer number_attr);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer unsafe_arena_release_number_attr();
  public native void unsafe_arena_set_allocated_number_attr(
        @StdString @Cast({"char*", "std::string*"}) BytePointer number_attr);

  // optional string type_list_attr = 6;
  public native void clear_type_list_attr();
  @MemberGetter public static native int kTypeListAttrFieldNumber();
  public static final int kTypeListAttrFieldNumber = kTypeListAttrFieldNumber();
  public native @StdString BytePointer type_list_attr();
  public native void set_type_list_attr(@StdString BytePointer value);
  public native void set_type_list_attr(@StdString String value);
  public native void set_type_list_attr(@Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void set_type_list_attr(String value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_type_list_attr();
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer release_type_list_attr();
  public native void set_allocated_type_list_attr(@StdString @Cast({"char*", "std::string*"}) BytePointer type_list_attr);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer unsafe_arena_release_type_list_attr();
  public native void unsafe_arena_set_allocated_type_list_attr(
        @StdString @Cast({"char*", "std::string*"}) BytePointer type_list_attr);

  // optional bool is_ref = 16;
  public native void clear_is_ref();
  @MemberGetter public static native int kIsRefFieldNumber();
  public static final int kIsRefFieldNumber = kIsRefFieldNumber();
  public native @Cast("bool") boolean is_ref();
  public native void set_is_ref(@Cast("bool") boolean value);
}
// -------------------------------------------------------------------

@Namespace("tensorflow") @NoOffset public static class OpDef_AttrDef extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public OpDef_AttrDef(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public OpDef_AttrDef(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public OpDef_AttrDef position(long position) {
        return (OpDef_AttrDef)super.position(position);
    }

  public OpDef_AttrDef() { super((Pointer)null); allocate(); }
  private native void allocate();

  public OpDef_AttrDef(@Const @ByRef OpDef_AttrDef from) { super((Pointer)null); allocate(from); }
  private native void allocate(@Const @ByRef OpDef_AttrDef from);

  public native @ByRef @Name("operator =") OpDef_AttrDef put(@Const @ByRef OpDef_AttrDef from);

  public native @Cast("google::protobuf::Arena*") Pointer GetArena();
  public native Pointer GetMaybeArenaPointer();
  public static native @Cast("const google::protobuf::Descriptor*") Pointer descriptor();
  public static native @Const @ByRef OpDef_AttrDef default_instance();

  public native void UnsafeArenaSwap(OpDef_AttrDef other);
  public native void Swap(OpDef_AttrDef other);

  // implements Message ----------------------------------------------

  public native OpDef_AttrDef New();

  public native OpDef_AttrDef New(@Cast("google::protobuf::Arena*") Pointer arena);
  public native void CopyFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void MergeFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void CopyFrom(@Const @ByRef OpDef_AttrDef from);
  public native void MergeFrom(@Const @ByRef OpDef_AttrDef from);
  public native void Clear();
  public native @Cast("bool") boolean IsInitialized();

  public native int ByteSize();
  public native @Cast("bool") boolean MergePartialFromCodedStream(
        @Cast("google::protobuf::io::CodedInputStream*") Pointer input);
  public native void SerializeWithCachedSizes(
        @Cast("google::protobuf::io::CodedOutputStream*") Pointer output);
  public native @Cast("google::protobuf::uint8*") BytePointer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") byte[] output);
  public native @Cast("google::protobuf::uint8*") BytePointer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") byte[] output);
  public native int GetCachedSize();

  public native @ByVal @Cast("google::protobuf::Metadata*") Pointer GetMetadata();

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional string name = 1;
  public native void clear_name();
  @MemberGetter public static native int kNameFieldNumber();
  public static final int kNameFieldNumber = kNameFieldNumber();
  public native @StdString BytePointer name();
  public native void set_name(@StdString BytePointer value);
  public native void set_name(@StdString String value);
  public native void set_name(@Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void set_name(String value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_name();
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer release_name();
  public native void set_allocated_name(@StdString @Cast({"char*", "std::string*"}) BytePointer name);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer unsafe_arena_release_name();
  public native void unsafe_arena_set_allocated_name(
        @StdString @Cast({"char*", "std::string*"}) BytePointer name);

  // optional string type = 2;
  public native void clear_type();
  @MemberGetter public static native int kTypeFieldNumber();
  public static final int kTypeFieldNumber = kTypeFieldNumber();
  public native @StdString BytePointer type();
  public native void set_type(@StdString BytePointer value);
  public native void set_type(@StdString String value);
  public native void set_type(@Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void set_type(String value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_type();
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer release_type();
  public native void set_allocated_type(@StdString @Cast({"char*", "std::string*"}) BytePointer type);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer unsafe_arena_release_type();
  public native void unsafe_arena_set_allocated_type(
        @StdString @Cast({"char*", "std::string*"}) BytePointer type);

  // optional .tensorflow.AttrValue default_value = 3;
  public native @Cast("bool") boolean has_default_value();
  public native void clear_default_value();
  @MemberGetter public static native int kDefaultValueFieldNumber();
  public static final int kDefaultValueFieldNumber = kDefaultValueFieldNumber();
  public native @Const @ByRef AttrValue default_value();
  public native AttrValue mutable_default_value();
  public native AttrValue release_default_value();
  public native void set_allocated_default_value(AttrValue default_value);
  public native AttrValue unsafe_arena_release_default_value();
  public native void unsafe_arena_set_allocated_default_value(
        AttrValue default_value);

  // optional string description = 4;
  public native void clear_description();
  @MemberGetter public static native int kDescriptionFieldNumber();
  public static final int kDescriptionFieldNumber = kDescriptionFieldNumber();
  public native @StdString BytePointer description();
  public native void set_description(@StdString BytePointer value);
  public native void set_description(@StdString String value);
  public native void set_description(@Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void set_description(String value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_description();
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer release_description();
  public native void set_allocated_description(@StdString @Cast({"char*", "std::string*"}) BytePointer description);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer unsafe_arena_release_description();
  public native void unsafe_arena_set_allocated_description(
        @StdString @Cast({"char*", "std::string*"}) BytePointer description);

  // optional bool has_minimum = 5;
  public native void clear_has_minimum();
  @MemberGetter public static native int kHasMinimumFieldNumber();
  public static final int kHasMinimumFieldNumber = kHasMinimumFieldNumber();
  public native @Cast("bool") boolean has_minimum();
  public native void set_has_minimum(@Cast("bool") boolean value);

  // optional int64 minimum = 6;
  public native void clear_minimum();
  @MemberGetter public static native int kMinimumFieldNumber();
  public static final int kMinimumFieldNumber = kMinimumFieldNumber();
  public native @Cast("google::protobuf::int64") long minimum();
  public native void set_minimum(@Cast("google::protobuf::int64") long value);

  // optional .tensorflow.AttrValue allowed_values = 7;
  public native @Cast("bool") boolean has_allowed_values();
  public native void clear_allowed_values();
  @MemberGetter public static native int kAllowedValuesFieldNumber();
  public static final int kAllowedValuesFieldNumber = kAllowedValuesFieldNumber();
  public native @Const @ByRef AttrValue allowed_values();
  public native AttrValue mutable_allowed_values();
  public native AttrValue release_allowed_values();
  public native void set_allocated_allowed_values(AttrValue allowed_values);
  public native AttrValue unsafe_arena_release_allowed_values();
  public native void unsafe_arena_set_allocated_allowed_values(
        AttrValue allowed_values);
}
// -------------------------------------------------------------------

@Namespace("tensorflow") @NoOffset public static class OpDef extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public OpDef(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public OpDef(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public OpDef position(long position) {
        return (OpDef)super.position(position);
    }

  public OpDef() { super((Pointer)null); allocate(); }
  private native void allocate();

  public OpDef(@Const @ByRef OpDef from) { super((Pointer)null); allocate(from); }
  private native void allocate(@Const @ByRef OpDef from);

  public native @ByRef @Name("operator =") OpDef put(@Const @ByRef OpDef from);

  public native @Cast("google::protobuf::Arena*") Pointer GetArena();
  public native Pointer GetMaybeArenaPointer();
  public static native @Cast("const google::protobuf::Descriptor*") Pointer descriptor();
  public static native @Const @ByRef OpDef default_instance();

  public native void UnsafeArenaSwap(OpDef other);
  public native void Swap(OpDef other);

  // implements Message ----------------------------------------------

  public native OpDef New();

  public native OpDef New(@Cast("google::protobuf::Arena*") Pointer arena);
  public native void CopyFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void MergeFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void CopyFrom(@Const @ByRef OpDef from);
  public native void MergeFrom(@Const @ByRef OpDef from);
  public native void Clear();
  public native @Cast("bool") boolean IsInitialized();

  public native int ByteSize();
  public native @Cast("bool") boolean MergePartialFromCodedStream(
        @Cast("google::protobuf::io::CodedInputStream*") Pointer input);
  public native void SerializeWithCachedSizes(
        @Cast("google::protobuf::io::CodedOutputStream*") Pointer output);
  public native @Cast("google::protobuf::uint8*") BytePointer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") byte[] output);
  public native @Cast("google::protobuf::uint8*") BytePointer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") byte[] output);
  public native int GetCachedSize();

  public native @ByVal @Cast("google::protobuf::Metadata*") Pointer GetMetadata();

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional string name = 1;
  public native void clear_name();
  @MemberGetter public static native int kNameFieldNumber();
  public static final int kNameFieldNumber = kNameFieldNumber();
  public native @StdString BytePointer name();
  public native void set_name(@StdString BytePointer value);
  public native void set_name(@StdString String value);
  public native void set_name(@Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void set_name(String value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_name();
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer release_name();
  public native void set_allocated_name(@StdString @Cast({"char*", "std::string*"}) BytePointer name);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer unsafe_arena_release_name();
  public native void unsafe_arena_set_allocated_name(
        @StdString @Cast({"char*", "std::string*"}) BytePointer name);

  // repeated .tensorflow.OpDef.ArgDef input_arg = 2;
  public native int input_arg_size();
  public native void clear_input_arg();
  @MemberGetter public static native int kInputArgFieldNumber();
  public static final int kInputArgFieldNumber = kInputArgFieldNumber();
  public native @Const @ByRef OpDef_ArgDef input_arg(int index);
  public native OpDef_ArgDef mutable_input_arg(int index);
  public native OpDef_ArgDef add_input_arg();

  // repeated .tensorflow.OpDef.ArgDef output_arg = 3;
  public native int output_arg_size();
  public native void clear_output_arg();
  @MemberGetter public static native int kOutputArgFieldNumber();
  public static final int kOutputArgFieldNumber = kOutputArgFieldNumber();
  public native @Const @ByRef OpDef_ArgDef output_arg(int index);
  public native OpDef_ArgDef mutable_output_arg(int index);
  public native OpDef_ArgDef add_output_arg();

  // repeated .tensorflow.OpDef.AttrDef attr = 4;
  public native int attr_size();
  public native void clear_attr();
  @MemberGetter public static native int kAttrFieldNumber();
  public static final int kAttrFieldNumber = kAttrFieldNumber();
  public native @Const @ByRef OpDef_AttrDef attr(int index);
  public native OpDef_AttrDef mutable_attr(int index);
  public native OpDef_AttrDef add_attr();

  // optional .tensorflow.OpDeprecation deprecation = 8;
  public native @Cast("bool") boolean has_deprecation();
  public native void clear_deprecation();
  @MemberGetter public static native int kDeprecationFieldNumber();
  public static final int kDeprecationFieldNumber = kDeprecationFieldNumber();
  public native @Const @ByRef OpDeprecation deprecation();
  public native OpDeprecation mutable_deprecation();
  public native OpDeprecation release_deprecation();
  public native void set_allocated_deprecation(OpDeprecation deprecation);
  public native OpDeprecation unsafe_arena_release_deprecation();
  public native void unsafe_arena_set_allocated_deprecation(
        OpDeprecation deprecation);

  // optional string summary = 5;
  public native void clear_summary();
  @MemberGetter public static native int kSummaryFieldNumber();
  public static final int kSummaryFieldNumber = kSummaryFieldNumber();
  public native @StdString BytePointer summary();
  public native void set_summary(@StdString BytePointer value);
  public native void set_summary(@StdString String value);
  public native void set_summary(@Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void set_summary(String value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_summary();
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer release_summary();
  public native void set_allocated_summary(@StdString @Cast({"char*", "std::string*"}) BytePointer summary);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer unsafe_arena_release_summary();
  public native void unsafe_arena_set_allocated_summary(
        @StdString @Cast({"char*", "std::string*"}) BytePointer summary);

  // optional string description = 6;
  public native void clear_description();
  @MemberGetter public static native int kDescriptionFieldNumber();
  public static final int kDescriptionFieldNumber = kDescriptionFieldNumber();
  public native @StdString BytePointer description();
  public native void set_description(@StdString BytePointer value);
  public native void set_description(@StdString String value);
  public native void set_description(@Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void set_description(String value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_description();
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer release_description();
  public native void set_allocated_description(@StdString @Cast({"char*", "std::string*"}) BytePointer description);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer unsafe_arena_release_description();
  public native void unsafe_arena_set_allocated_description(
        @StdString @Cast({"char*", "std::string*"}) BytePointer description);

  // optional bool is_commutative = 18;
  public native void clear_is_commutative();
  @MemberGetter public static native int kIsCommutativeFieldNumber();
  public static final int kIsCommutativeFieldNumber = kIsCommutativeFieldNumber();
  public native @Cast("bool") boolean is_commutative();
  public native void set_is_commutative(@Cast("bool") boolean value);

  // optional bool is_aggregate = 16;
  public native void clear_is_aggregate();
  @MemberGetter public static native int kIsAggregateFieldNumber();
  public static final int kIsAggregateFieldNumber = kIsAggregateFieldNumber();
  public native @Cast("bool") boolean is_aggregate();
  public native void set_is_aggregate(@Cast("bool") boolean value);

  // optional bool is_stateful = 17;
  public native void clear_is_stateful();
  @MemberGetter public static native int kIsStatefulFieldNumber();
  public static final int kIsStatefulFieldNumber = kIsStatefulFieldNumber();
  public native @Cast("bool") boolean is_stateful();
  public native void set_is_stateful(@Cast("bool") boolean value);

  // optional bool allows_uninitialized_input = 19;
  public native void clear_allows_uninitialized_input();
  @MemberGetter public static native int kAllowsUninitializedInputFieldNumber();
  public static final int kAllowsUninitializedInputFieldNumber = kAllowsUninitializedInputFieldNumber();
  public native @Cast("bool") boolean allows_uninitialized_input();
  public native void set_allows_uninitialized_input(@Cast("bool") boolean value);
}
// -------------------------------------------------------------------

@Namespace("tensorflow") @NoOffset public static class OpDeprecation extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public OpDeprecation(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public OpDeprecation(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public OpDeprecation position(long position) {
        return (OpDeprecation)super.position(position);
    }

  public OpDeprecation() { super((Pointer)null); allocate(); }
  private native void allocate();

  public OpDeprecation(@Const @ByRef OpDeprecation from) { super((Pointer)null); allocate(from); }
  private native void allocate(@Const @ByRef OpDeprecation from);

  public native @ByRef @Name("operator =") OpDeprecation put(@Const @ByRef OpDeprecation from);

  public native @Cast("google::protobuf::Arena*") Pointer GetArena();
  public native Pointer GetMaybeArenaPointer();
  public static native @Cast("const google::protobuf::Descriptor*") Pointer descriptor();
  public static native @Const @ByRef OpDeprecation default_instance();

  public native void UnsafeArenaSwap(OpDeprecation other);
  public native void Swap(OpDeprecation other);

  // implements Message ----------------------------------------------

  public native OpDeprecation New();

  public native OpDeprecation New(@Cast("google::protobuf::Arena*") Pointer arena);
  public native void CopyFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void MergeFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void CopyFrom(@Const @ByRef OpDeprecation from);
  public native void MergeFrom(@Const @ByRef OpDeprecation from);
  public native void Clear();
  public native @Cast("bool") boolean IsInitialized();

  public native int ByteSize();
  public native @Cast("bool") boolean MergePartialFromCodedStream(
        @Cast("google::protobuf::io::CodedInputStream*") Pointer input);
  public native void SerializeWithCachedSizes(
        @Cast("google::protobuf::io::CodedOutputStream*") Pointer output);
  public native @Cast("google::protobuf::uint8*") BytePointer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") byte[] output);
  public native @Cast("google::protobuf::uint8*") BytePointer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") byte[] output);
  public native int GetCachedSize();

  public native @ByVal @Cast("google::protobuf::Metadata*") Pointer GetMetadata();

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional int32 version = 1;
  public native void clear_version();
  @MemberGetter public static native int kVersionFieldNumber();
  public static final int kVersionFieldNumber = kVersionFieldNumber();
  public native @Cast("google::protobuf::int32") int version();
  public native void set_version(@Cast("google::protobuf::int32") int value);

  // optional string explanation = 2;
  public native void clear_explanation();
  @MemberGetter public static native int kExplanationFieldNumber();
  public static final int kExplanationFieldNumber = kExplanationFieldNumber();
  public native @StdString BytePointer explanation();
  public native void set_explanation(@StdString BytePointer value);
  public native void set_explanation(@StdString String value);
  public native void set_explanation(@Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void set_explanation(String value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_explanation();
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer release_explanation();
  public native void set_allocated_explanation(@StdString @Cast({"char*", "std::string*"}) BytePointer explanation);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer unsafe_arena_release_explanation();
  public native void unsafe_arena_set_allocated_explanation(
        @StdString @Cast({"char*", "std::string*"}) BytePointer explanation);
}
// -------------------------------------------------------------------

@Namespace("tensorflow") @NoOffset public static class OpList extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public OpList(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public OpList(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public OpList position(long position) {
        return (OpList)super.position(position);
    }

  public OpList() { super((Pointer)null); allocate(); }
  private native void allocate();

  public OpList(@Const @ByRef OpList from) { super((Pointer)null); allocate(from); }
  private native void allocate(@Const @ByRef OpList from);

  public native @ByRef @Name("operator =") OpList put(@Const @ByRef OpList from);

  public native @Cast("google::protobuf::Arena*") Pointer GetArena();
  public native Pointer GetMaybeArenaPointer();
  public static native @Cast("const google::protobuf::Descriptor*") Pointer descriptor();
  public static native @Const @ByRef OpList default_instance();

  public native void UnsafeArenaSwap(OpList other);
  public native void Swap(OpList other);

  // implements Message ----------------------------------------------

  public native OpList New();

  public native OpList New(@Cast("google::protobuf::Arena*") Pointer arena);
  public native void CopyFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void MergeFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void CopyFrom(@Const @ByRef OpList from);
  public native void MergeFrom(@Const @ByRef OpList from);
  public native void Clear();
  public native @Cast("bool") boolean IsInitialized();

  public native int ByteSize();
  public native @Cast("bool") boolean MergePartialFromCodedStream(
        @Cast("google::protobuf::io::CodedInputStream*") Pointer input);
  public native void SerializeWithCachedSizes(
        @Cast("google::protobuf::io::CodedOutputStream*") Pointer output);
  public native @Cast("google::protobuf::uint8*") BytePointer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") byte[] output);
  public native @Cast("google::protobuf::uint8*") BytePointer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") byte[] output);
  public native int GetCachedSize();

  public native @ByVal @Cast("google::protobuf::Metadata*") Pointer GetMetadata();

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .tensorflow.OpDef op = 1;
  public native int op_size();
  public native void clear_op();
  @MemberGetter public static native int kOpFieldNumber();
  public static final int kOpFieldNumber = kOpFieldNumber();
  public native @Const @ByRef OpDef op(int index);
  public native OpDef mutable_op(int index);
  public native OpDef add_op();
}
// ===================================================================


// ===================================================================

// #if !PROTOBUF_INLINE_NOT_IN_HEADERS
// OpDef_ArgDef

// optional string name = 1;











// optional string description = 2;











// optional .tensorflow.DataType type = 3;




// optional string type_attr = 4;











// optional string number_attr = 5;











// optional string type_list_attr = 6;











// optional bool is_ref = 16;




// -------------------------------------------------------------------

// OpDef_AttrDef

// optional string name = 1;











// optional string type = 2;











// optional .tensorflow.AttrValue default_value = 3;







// optional string description = 4;











// optional bool has_minimum = 5;




// optional int64 minimum = 6;




// optional .tensorflow.AttrValue allowed_values = 7;







// -------------------------------------------------------------------

// OpDef

// optional string name = 1;











// repeated .tensorflow.OpDef.ArgDef input_arg = 2;








// repeated .tensorflow.OpDef.ArgDef output_arg = 3;








// repeated .tensorflow.OpDef.AttrDef attr = 4;








// optional .tensorflow.OpDeprecation deprecation = 8;







// optional string summary = 5;











// optional string description = 6;











// optional bool is_commutative = 18;




// optional bool is_aggregate = 16;




// optional bool is_stateful = 17;




// optional bool allows_uninitialized_input = 19;




// -------------------------------------------------------------------

// OpDeprecation

// optional int32 version = 1;




// optional string explanation = 2;











// -------------------------------------------------------------------

// OpList

// repeated .tensorflow.OpDef op = 1;








// #endif  // !PROTOBUF_INLINE_NOT_IN_HEADERS
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_tensorflow_2fcore_2fframework_2fop_5fdef_2eproto__INCLUDED


// Parsed from tensorflow/core/framework/function.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/function.proto

// #ifndef PROTOBUF_tensorflow_2fcore_2fframework_2ffunction_2eproto__INCLUDED
// #define PROTOBUF_tensorflow_2fcore_2fframework_2ffunction_2eproto__INCLUDED

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3000000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3000000 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>
// #include <google/protobuf/extension_set.h>
// #include <google/protobuf/map.h>
// #include <google/protobuf/map_field_inl.h>
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/attr_value.pb.h"
// #include "tensorflow/core/framework/node_def.pb.h"
// #include "tensorflow/core/framework/op_def.pb.h"
// @@protoc_insertion_point(includes)

// Internal implementation detail -- do not call these.
@Namespace("tensorflow") public static native void protobuf_AddDesc_tensorflow_2fcore_2fframework_2ffunction_2eproto();
@Namespace("tensorflow") public static native void protobuf_AssignDesc_tensorflow_2fcore_2fframework_2ffunction_2eproto();
@Namespace("tensorflow") public static native void protobuf_ShutdownFile_tensorflow_2fcore_2fframework_2ffunction_2eproto();

// ===================================================================

@Namespace("tensorflow") @NoOffset public static class FunctionDefLibrary extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public FunctionDefLibrary(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public FunctionDefLibrary(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public FunctionDefLibrary position(long position) {
        return (FunctionDefLibrary)super.position(position);
    }

  public FunctionDefLibrary() { super((Pointer)null); allocate(); }
  private native void allocate();

  public FunctionDefLibrary(@Const @ByRef FunctionDefLibrary from) { super((Pointer)null); allocate(from); }
  private native void allocate(@Const @ByRef FunctionDefLibrary from);

  public native @ByRef @Name("operator =") FunctionDefLibrary put(@Const @ByRef FunctionDefLibrary from);

  public native @Cast("google::protobuf::Arena*") Pointer GetArena();
  public native Pointer GetMaybeArenaPointer();
  public static native @Cast("const google::protobuf::Descriptor*") Pointer descriptor();
  public static native @Const @ByRef FunctionDefLibrary default_instance();

  public native void UnsafeArenaSwap(FunctionDefLibrary other);
  public native void Swap(FunctionDefLibrary other);

  // implements Message ----------------------------------------------

  public native FunctionDefLibrary New();

  public native FunctionDefLibrary New(@Cast("google::protobuf::Arena*") Pointer arena);
  public native void CopyFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void MergeFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void CopyFrom(@Const @ByRef FunctionDefLibrary from);
  public native void MergeFrom(@Const @ByRef FunctionDefLibrary from);
  public native void Clear();
  public native @Cast("bool") boolean IsInitialized();

  public native int ByteSize();
  public native @Cast("bool") boolean MergePartialFromCodedStream(
        @Cast("google::protobuf::io::CodedInputStream*") Pointer input);
  public native void SerializeWithCachedSizes(
        @Cast("google::protobuf::io::CodedOutputStream*") Pointer output);
  public native @Cast("google::protobuf::uint8*") BytePointer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") byte[] output);
  public native @Cast("google::protobuf::uint8*") BytePointer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") byte[] output);
  public native int GetCachedSize();

  public native @ByVal @Cast("google::protobuf::Metadata*") Pointer GetMetadata();

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .tensorflow.FunctionDef function = 1;
  public native int function_size();
  public native void clear_function();
  @MemberGetter public static native int kFunctionFieldNumber();
  public static final int kFunctionFieldNumber = kFunctionFieldNumber();
  public native @Const @ByRef FunctionDef function(int index);
  public native FunctionDef mutable_function(int index);
  public native FunctionDef add_function();

  // repeated .tensorflow.GradientDef gradient = 2;
  public native int gradient_size();
  public native void clear_gradient();
  @MemberGetter public static native int kGradientFieldNumber();
  public static final int kGradientFieldNumber = kGradientFieldNumber();
  public native @Const @ByRef GradientDef gradient(int index);
  public native GradientDef mutable_gradient(int index);
  public native GradientDef add_gradient();
}
// -------------------------------------------------------------------

@Namespace("tensorflow") @NoOffset public static class FunctionDef_Node extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public FunctionDef_Node(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public FunctionDef_Node(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public FunctionDef_Node position(long position) {
        return (FunctionDef_Node)super.position(position);
    }

  public FunctionDef_Node() { super((Pointer)null); allocate(); }
  private native void allocate();

  public FunctionDef_Node(@Const @ByRef FunctionDef_Node from) { super((Pointer)null); allocate(from); }
  private native void allocate(@Const @ByRef FunctionDef_Node from);

  public native @ByRef @Name("operator =") FunctionDef_Node put(@Const @ByRef FunctionDef_Node from);

  public native @Cast("google::protobuf::Arena*") Pointer GetArena();
  public native Pointer GetMaybeArenaPointer();
  public static native @Cast("const google::protobuf::Descriptor*") Pointer descriptor();
  public static native @Const @ByRef FunctionDef_Node default_instance();

  public native void UnsafeArenaSwap(FunctionDef_Node other);
  public native void Swap(FunctionDef_Node other);

  // implements Message ----------------------------------------------

  public native FunctionDef_Node New();

  public native FunctionDef_Node New(@Cast("google::protobuf::Arena*") Pointer arena);
  public native void CopyFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void MergeFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void CopyFrom(@Const @ByRef FunctionDef_Node from);
  public native void MergeFrom(@Const @ByRef FunctionDef_Node from);
  public native void Clear();
  public native @Cast("bool") boolean IsInitialized();

  public native int ByteSize();
  public native @Cast("bool") boolean MergePartialFromCodedStream(
        @Cast("google::protobuf::io::CodedInputStream*") Pointer input);
  public native void SerializeWithCachedSizes(
        @Cast("google::protobuf::io::CodedOutputStream*") Pointer output);
  public native @Cast("google::protobuf::uint8*") BytePointer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") byte[] output);
  public native @Cast("google::protobuf::uint8*") BytePointer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") byte[] output);
  public native int GetCachedSize();

  public native @ByVal @Cast("google::protobuf::Metadata*") Pointer GetMetadata();

  // nested types ----------------------------------------------------


  // accessors -------------------------------------------------------

  // repeated string ret = 1;
  public native int ret_size();
  public native void clear_ret();
  @MemberGetter public static native int kRetFieldNumber();
  public static final int kRetFieldNumber = kRetFieldNumber();
  public native @StdString BytePointer ret(int index);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_ret(int index);
  public native void set_ret(int index, @StdString BytePointer value);
  public native void set_ret(int index, @StdString String value);
  public native void set_ret(int index, @Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void set_ret(int index, String value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer add_ret();
  public native void add_ret(@StdString BytePointer value);
  public native void add_ret(@StdString String value);
  public native void add_ret(@Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void add_ret(String value, @Cast("size_t") long size);

  // optional string op = 2;
  public native void clear_op();
  @MemberGetter public static native int kOpFieldNumber();
  public static final int kOpFieldNumber = kOpFieldNumber();
  public native @StdString BytePointer op();
  public native void set_op(@StdString BytePointer value);
  public native void set_op(@StdString String value);
  public native void set_op(@Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void set_op(String value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_op();
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer release_op();
  public native void set_allocated_op(@StdString @Cast({"char*", "std::string*"}) BytePointer op);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer unsafe_arena_release_op();
  public native void unsafe_arena_set_allocated_op(
        @StdString @Cast({"char*", "std::string*"}) BytePointer op);

  // repeated string arg = 3;
  public native int arg_size();
  public native void clear_arg();
  @MemberGetter public static native int kArgFieldNumber();
  public static final int kArgFieldNumber = kArgFieldNumber();
  public native @StdString BytePointer arg(int index);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_arg(int index);
  public native void set_arg(int index, @StdString BytePointer value);
  public native void set_arg(int index, @StdString String value);
  public native void set_arg(int index, @Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void set_arg(int index, String value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer add_arg();
  public native void add_arg(@StdString BytePointer value);
  public native void add_arg(@StdString String value);
  public native void add_arg(@Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void add_arg(String value, @Cast("size_t") long size);

  // repeated string dep = 4;
  public native int dep_size();
  public native void clear_dep();
  @MemberGetter public static native int kDepFieldNumber();
  public static final int kDepFieldNumber = kDepFieldNumber();
  public native @StdString BytePointer dep(int index);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_dep(int index);
  public native void set_dep(int index, @StdString BytePointer value);
  public native void set_dep(int index, @StdString String value);
  public native void set_dep(int index, @Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void set_dep(int index, String value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer add_dep();
  public native void add_dep(@StdString BytePointer value);
  public native void add_dep(@StdString String value);
  public native void add_dep(@Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void add_dep(String value, @Cast("size_t") long size);

  // map<string, .tensorflow.AttrValue> attr = 5;
  public native int attr_size();
  public native void clear_attr();
  @MemberGetter public static native int kAttrFieldNumber();
  public static final int kAttrFieldNumber = kAttrFieldNumber();
  public native @Const @ByRef StringAttrValueMap attr();
  public native StringAttrValueMap mutable_attr();
}
// -------------------------------------------------------------------

@Namespace("tensorflow") @NoOffset public static class FunctionDef extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public FunctionDef(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public FunctionDef(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public FunctionDef position(long position) {
        return (FunctionDef)super.position(position);
    }

  public FunctionDef() { super((Pointer)null); allocate(); }
  private native void allocate();

  public FunctionDef(@Const @ByRef FunctionDef from) { super((Pointer)null); allocate(from); }
  private native void allocate(@Const @ByRef FunctionDef from);

  public native @ByRef @Name("operator =") FunctionDef put(@Const @ByRef FunctionDef from);

  public native @Cast("google::protobuf::Arena*") Pointer GetArena();
  public native Pointer GetMaybeArenaPointer();
  public static native @Cast("const google::protobuf::Descriptor*") Pointer descriptor();
  public static native @Const @ByRef FunctionDef default_instance();

  public native void UnsafeArenaSwap(FunctionDef other);
  public native void Swap(FunctionDef other);

  // implements Message ----------------------------------------------

  public native FunctionDef New();

  public native FunctionDef New(@Cast("google::protobuf::Arena*") Pointer arena);
  public native void CopyFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void MergeFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void CopyFrom(@Const @ByRef FunctionDef from);
  public native void MergeFrom(@Const @ByRef FunctionDef from);
  public native void Clear();
  public native @Cast("bool") boolean IsInitialized();

  public native int ByteSize();
  public native @Cast("bool") boolean MergePartialFromCodedStream(
        @Cast("google::protobuf::io::CodedInputStream*") Pointer input);
  public native void SerializeWithCachedSizes(
        @Cast("google::protobuf::io::CodedOutputStream*") Pointer output);
  public native @Cast("google::protobuf::uint8*") BytePointer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") byte[] output);
  public native @Cast("google::protobuf::uint8*") BytePointer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") byte[] output);
  public native int GetCachedSize();

  public native @ByVal @Cast("google::protobuf::Metadata*") Pointer GetMetadata();

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .tensorflow.OpDef signature = 1;
  public native @Cast("bool") boolean has_signature();
  public native void clear_signature();
  @MemberGetter public static native int kSignatureFieldNumber();
  public static final int kSignatureFieldNumber = kSignatureFieldNumber();
  public native @Const @ByRef OpDef signature();
  public native OpDef mutable_signature();
  public native OpDef release_signature();
  public native void set_allocated_signature(OpDef signature);
  public native OpDef unsafe_arena_release_signature();
  public native void unsafe_arena_set_allocated_signature(
        OpDef signature);

  // repeated .tensorflow.FunctionDef.Node node = 2;
  public native int node_size();
  public native void clear_node();
  @MemberGetter public static native int kNodeFieldNumber();
  public static final int kNodeFieldNumber = kNodeFieldNumber();
  public native @Const @ByRef FunctionDef_Node node(int index);
  public native FunctionDef_Node mutable_node(int index);
  public native FunctionDef_Node add_node();

  // repeated .tensorflow.NodeDef node_def = 3;
  public native int node_def_size();
  public native void clear_node_def();
  @MemberGetter public static native int kNodeDefFieldNumber();
  public static final int kNodeDefFieldNumber = kNodeDefFieldNumber();
  public native @Const @ByRef NodeDef node_def(int index);
  public native NodeDef mutable_node_def(int index);
  public native NodeDef add_node_def();

  // map<string, string> ret = 4;
  public native int ret_size();
  public native void clear_ret();
  @MemberGetter public static native int kRetFieldNumber();
  public static final int kRetFieldNumber = kRetFieldNumber();
}
// -------------------------------------------------------------------

@Namespace("tensorflow") @NoOffset public static class GradientDef extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public GradientDef(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public GradientDef(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public GradientDef position(long position) {
        return (GradientDef)super.position(position);
    }

  public GradientDef() { super((Pointer)null); allocate(); }
  private native void allocate();

  public GradientDef(@Const @ByRef GradientDef from) { super((Pointer)null); allocate(from); }
  private native void allocate(@Const @ByRef GradientDef from);

  public native @ByRef @Name("operator =") GradientDef put(@Const @ByRef GradientDef from);

  public native @Cast("google::protobuf::Arena*") Pointer GetArena();
  public native Pointer GetMaybeArenaPointer();
  public static native @Cast("const google::protobuf::Descriptor*") Pointer descriptor();
  public static native @Const @ByRef GradientDef default_instance();

  public native void UnsafeArenaSwap(GradientDef other);
  public native void Swap(GradientDef other);

  // implements Message ----------------------------------------------

  public native GradientDef New();

  public native GradientDef New(@Cast("google::protobuf::Arena*") Pointer arena);
  public native void CopyFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void MergeFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void CopyFrom(@Const @ByRef GradientDef from);
  public native void MergeFrom(@Const @ByRef GradientDef from);
  public native void Clear();
  public native @Cast("bool") boolean IsInitialized();

  public native int ByteSize();
  public native @Cast("bool") boolean MergePartialFromCodedStream(
        @Cast("google::protobuf::io::CodedInputStream*") Pointer input);
  public native void SerializeWithCachedSizes(
        @Cast("google::protobuf::io::CodedOutputStream*") Pointer output);
  public native @Cast("google::protobuf::uint8*") BytePointer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") byte[] output);
  public native @Cast("google::protobuf::uint8*") BytePointer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") byte[] output);
  public native int GetCachedSize();

  public native @ByVal @Cast("google::protobuf::Metadata*") Pointer GetMetadata();

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional string function_name = 1;
  public native void clear_function_name();
  @MemberGetter public static native int kFunctionNameFieldNumber();
  public static final int kFunctionNameFieldNumber = kFunctionNameFieldNumber();
  public native @StdString BytePointer function_name();
  public native void set_function_name(@StdString BytePointer value);
  public native void set_function_name(@StdString String value);
  public native void set_function_name(@Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void set_function_name(String value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_function_name();
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer release_function_name();
  public native void set_allocated_function_name(@StdString @Cast({"char*", "std::string*"}) BytePointer function_name);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer unsafe_arena_release_function_name();
  public native void unsafe_arena_set_allocated_function_name(
        @StdString @Cast({"char*", "std::string*"}) BytePointer function_name);

  // optional string gradient_func = 2;
  public native void clear_gradient_func();
  @MemberGetter public static native int kGradientFuncFieldNumber();
  public static final int kGradientFuncFieldNumber = kGradientFuncFieldNumber();
  public native @StdString BytePointer gradient_func();
  public native void set_gradient_func(@StdString BytePointer value);
  public native void set_gradient_func(@StdString String value);
  public native void set_gradient_func(@Cast("const char*") BytePointer value, @Cast("size_t") long size);
  public native void set_gradient_func(String value, @Cast("size_t") long size);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer mutable_gradient_func();
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer release_gradient_func();
  public native void set_allocated_gradient_func(@StdString @Cast({"char*", "std::string*"}) BytePointer gradient_func);
  public native @StdString @Cast({"char*", "std::string*"}) BytePointer unsafe_arena_release_gradient_func();
  public native void unsafe_arena_set_allocated_gradient_func(
        @StdString @Cast({"char*", "std::string*"}) BytePointer gradient_func);
}
// ===================================================================


// ===================================================================

// #if !PROTOBUF_INLINE_NOT_IN_HEADERS
// FunctionDefLibrary

// repeated .tensorflow.FunctionDef function = 1;








// repeated .tensorflow.GradientDef gradient = 2;








// -------------------------------------------------------------------

// FunctionDef_Node

// repeated string ret = 1;














// optional string op = 2;











// repeated string arg = 3;














// repeated string dep = 4;














// map<string, .tensorflow.AttrValue> attr = 5;





// -------------------------------------------------------------------

// FunctionDef

// optional .tensorflow.OpDef signature = 1;







// repeated .tensorflow.FunctionDef.Node node = 2;








// repeated .tensorflow.NodeDef node_def = 3;








// map<string, string> ret = 4;





// -------------------------------------------------------------------

// GradientDef

// optional string function_name = 1;











// optional string gradient_func = 2;











// #endif  // !PROTOBUF_INLINE_NOT_IN_HEADERS
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_tensorflow_2fcore_2fframework_2ffunction_2eproto__INCLUDED


// Parsed from tensorflow/core/framework/graph.pb.h

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/graph.proto

// #ifndef PROTOBUF_tensorflow_2fcore_2fframework_2fgraph_2eproto__INCLUDED
// #define PROTOBUF_tensorflow_2fcore_2fframework_2fgraph_2eproto__INCLUDED

// #include <string>

// #include <google/protobuf/stubs/common.h>

// #if GOOGLE_PROTOBUF_VERSION < 3000000
// #error This file was generated by a newer version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please update
// #error your headers.
// #endif
// #if 3000000 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
// #error This file was generated by an older version of protoc which is
// #error incompatible with your Protocol Buffer headers.  Please
// #error regenerate this file with a newer version of protoc.
// #endif

// #include <google/protobuf/arena.h>
// #include <google/protobuf/arenastring.h>
// #include <google/protobuf/generated_message_util.h>
// #include <google/protobuf/metadata.h>
// #include <google/protobuf/message.h>
// #include <google/protobuf/repeated_field.h>
// #include <google/protobuf/extension_set.h>
// #include <google/protobuf/unknown_field_set.h>
// #include "tensorflow/core/framework/node_def.pb.h"
// #include "tensorflow/core/framework/function.pb.h"
// #include "tensorflow/core/framework/versions.pb.h"
// @@protoc_insertion_point(includes)

// Internal implementation detail -- do not call these.
@Namespace("tensorflow") public static native void protobuf_AddDesc_tensorflow_2fcore_2fframework_2fgraph_2eproto();
@Namespace("tensorflow") public static native void protobuf_AssignDesc_tensorflow_2fcore_2fframework_2fgraph_2eproto();
@Namespace("tensorflow") public static native void protobuf_ShutdownFile_tensorflow_2fcore_2fframework_2fgraph_2eproto();

// ===================================================================

@Namespace("tensorflow") @NoOffset public static class GraphDef extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public GraphDef(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public GraphDef(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public GraphDef position(long position) {
        return (GraphDef)super.position(position);
    }

  public GraphDef() { super((Pointer)null); allocate(); }
  private native void allocate();

  public GraphDef(@Const @ByRef GraphDef from) { super((Pointer)null); allocate(from); }
  private native void allocate(@Const @ByRef GraphDef from);

  public native @ByRef @Name("operator =") GraphDef put(@Const @ByRef GraphDef from);

  public native @Cast("google::protobuf::Arena*") Pointer GetArena();
  public native Pointer GetMaybeArenaPointer();
  public static native @Cast("const google::protobuf::Descriptor*") Pointer descriptor();
  public static native @Const @ByRef GraphDef default_instance();

  public native void UnsafeArenaSwap(GraphDef other);
  public native void Swap(GraphDef other);

  // implements Message ----------------------------------------------

  public native GraphDef New();

  public native GraphDef New(@Cast("google::protobuf::Arena*") Pointer arena);
  public native void CopyFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void MergeFrom(@Cast("const google::protobuf::Message*") @ByRef Pointer from);
  public native void CopyFrom(@Const @ByRef GraphDef from);
  public native void MergeFrom(@Const @ByRef GraphDef from);
  public native void Clear();
  public native @Cast("bool") boolean IsInitialized();

  public native int ByteSize();
  public native @Cast("bool") boolean MergePartialFromCodedStream(
        @Cast("google::protobuf::io::CodedInputStream*") Pointer input);
  public native void SerializeWithCachedSizes(
        @Cast("google::protobuf::io::CodedOutputStream*") Pointer output);
  public native @Cast("google::protobuf::uint8*") BytePointer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] InternalSerializeWithCachedSizesToArray(
        @Cast("bool") boolean deterministic, @Cast("google::protobuf::uint8*") byte[] output);
  public native @Cast("google::protobuf::uint8*") BytePointer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") BytePointer output);
  public native @Cast("google::protobuf::uint8*") ByteBuffer SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") ByteBuffer output);
  public native @Cast("google::protobuf::uint8*") byte[] SerializeWithCachedSizesToArray(@Cast("google::protobuf::uint8*") byte[] output);
  public native int GetCachedSize();

  public native @ByVal @Cast("google::protobuf::Metadata*") Pointer GetMetadata();

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .tensorflow.NodeDef node = 1;
  public native int node_size();
  public native void clear_node();
  @MemberGetter public static native int kNodeFieldNumber();
  public static final int kNodeFieldNumber = kNodeFieldNumber();
  public native @Const @ByRef NodeDef node(int index);
  public native NodeDef mutable_node(int index);
  public native NodeDef add_node();

  // optional .tensorflow.VersionDef versions = 4;
  public native @Cast("bool") boolean has_versions();
  public native void clear_versions();
  @MemberGetter public static native int kVersionsFieldNumber();
  public static final int kVersionsFieldNumber = kVersionsFieldNumber();
  public native @Const @ByRef VersionDef versions();
  public native VersionDef mutable_versions();
  public native VersionDef release_versions();
  public native void set_allocated_versions(VersionDef versions);
  public native VersionDef unsafe_arena_release_versions();
  public native void unsafe_arena_set_allocated_versions(
        VersionDef versions);

  // optional int32 version = 3 [deprecated = true];
  public native void clear_version();
  @MemberGetter public static native int kVersionFieldNumber();
  public static final int kVersionFieldNumber = kVersionFieldNumber();
  public native @Cast("google::protobuf::int32") int version();
  public native void set_version(@Cast("google::protobuf::int32") int value);

  // optional .tensorflow.FunctionDefLibrary library = 2;
  public native @Cast("bool") boolean has_library();
  public native void clear_library();
  @MemberGetter public static native int kLibraryFieldNumber();
  public static final int kLibraryFieldNumber = kLibraryFieldNumber();
  public native @Const @ByRef FunctionDefLibrary library();
  public native FunctionDefLibrary mutable_library();
  public native FunctionDefLibrary release_library();
  public native void set_allocated_library(FunctionDefLibrary library);
  public native FunctionDefLibrary unsafe_arena_release_library();
  public native void unsafe_arena_set_allocated_library(
        FunctionDefLibrary library);
}
// ===================================================================


// ===================================================================

// #if !PROTOBUF_INLINE_NOT_IN_HEADERS
// GraphDef

// repeated .tensorflow.NodeDef node = 1;








// optional .tensorflow.VersionDef versions = 4;







// optional int32 version = 3 [deprecated = true];




// optional .tensorflow.FunctionDefLibrary library = 2;







// #endif  // !PROTOBUF_INLINE_NOT_IN_HEADERS

// @@protoc_insertion_point(namespace_scope)

  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

// #endif  // PROTOBUF_tensorflow_2fcore_2fframework_2fgraph_2eproto__INCLUDED


// Parsed from tensorflow/core/framework/shape_inference.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
// #ifndef THIRD_PARTY_TENSORFLOW_CORE_FRAMEWORK_SHAPE_INFERENCE_H_
// #define THIRD_PARTY_TENSORFLOW_CORE_FRAMEWORK_SHAPE_INFERENCE_H_

// #include <vector>

// #include "tensorflow/core/framework/graph.pb.h"
// #include "tensorflow/core/framework/node_def_util.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/lib/core/errors.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/gtl/inlined_vector.h"
// #include "tensorflow/core/platform/macros.h"

// Dimension values are accessed through InferenceContext.
@Namespace("tensorflow::shape_inference") @NoOffset public static class Dimension extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Dimension(Pointer p) { super(p); }

}

@Namespace("tensorflow::shape_inference") @NoOffset public static class DimensionHandle extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public DimensionHandle(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public DimensionHandle(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public DimensionHandle position(long position) {
        return (DimensionHandle)super.position(position);
    }

  public DimensionHandle() { super((Pointer)null); allocate(); }
  private native void allocate();
}

// Shape rank and dimensions are accessed through InferenceContext.
@Namespace("tensorflow::shape_inference") @NoOffset public static class Shape extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Shape(Pointer p) { super(p); }

}

@Namespace("tensorflow::shape_inference") @NoOffset public static class ShapeHandle extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ShapeHandle(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public ShapeHandle(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public ShapeHandle position(long position) {
        return (ShapeHandle)super.position(position);
    }

  public ShapeHandle() { super((Pointer)null); allocate(); }
  private native void allocate();
}

// Struct used to allow functions to take DimensionHandle or a dimension value.
// Not meant to be constructed directly.
@Namespace("tensorflow::shape_inference") @NoOffset public static class DimensionOrConstant extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public DimensionOrConstant(Pointer p) { super(p); }

  // Intentionally not explicit.
  public DimensionOrConstant(@ByVal DimensionHandle dim) { super((Pointer)null); allocate(dim); }
  private native void allocate(@ByVal DimensionHandle dim);

  // val must be non-negative or InferenceContext::kUnknownDim.
  public DimensionOrConstant(@Cast("tensorflow::int64") long val) { super((Pointer)null); allocate(val); }
  private native void allocate(@Cast("tensorflow::int64") long val);

  // dim takes precedence. If dim != nullptr, val is ignored.
  public native @ByRef DimensionHandle dim(); public native DimensionOrConstant dim(DimensionHandle dim);
  public native @Cast("tensorflow::int64") long val(); public native DimensionOrConstant val(long val);
}

// Note: This is experimental support for op shape inference in C++.  Shape
// inference functions are not ready to be implemented yet.
//
// An InferenceContext is created by the framework and passed to a shape
// inference function.  The shape inference function calls functions on the
// context, and should call set_output() to set the shape on all outputs.
//
// All Shape* and Dimension* returned by functions of InferenceContext are owned
// by the InferenceContext.
@Namespace("tensorflow::shape_inference") @NoOffset public static class InferenceContext extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public InferenceContext(Pointer p) { super(p); }

  @MemberGetter public static native @Cast("const tensorflow::int64") long kUnknownDim();
  public static final long kUnknownDim = kUnknownDim();
  @MemberGetter public static native int kUnknownRank();
  public static final int kUnknownRank = kUnknownRank();

  // <input_tensors> is NULL-padded to be the same size as <input_shapes>.
  //
  // REQUIRES: <node_def> is not NULL, and must outlive the InferenceContext.
  //
  // TODO(vrv): Remove 'input_shapes_string' once we can move the
  // creation of Shapes from strings out of this class (or hide it).
  public InferenceContext(@Const NodeDef node_def, @Const @ByRef OpDef op_def,
                     @Const @ByRef StringVector input_shapes_string,
                     @StdVector ShapeHandle input_shapes,
                     @Const @ByRef ConstTensorPtrVector input_tensors) { super((Pointer)null); allocate(node_def, op_def, input_shapes_string, input_shapes, input_tensors); }
  private native void allocate(@Const NodeDef node_def, @Const @ByRef OpDef op_def,
                     @Const @ByRef StringVector input_shapes_string,
                     @StdVector ShapeHandle input_shapes,
                     @Const @ByRef ConstTensorPtrVector input_tensors);

  // <input_tensors> is NULL-padded to be the same size as <input_shapes>.
  //
  // REQUIRES: <node_def> is not NULL, and must outlive the InferenceContext.
  //
  // TODO(cwhipkey): Remove 'input_shapes_string' once we can move the creation
  // of Shapes from strings out of this class (or hide it).
  public InferenceContext(@Const NodeDef node_def, @Const @ByRef OpDef op_def,
                     @Const @ByRef StringVector input_shapes_string,
                     @StdVector TensorShapeProto input_shapes,
                     @Const @ByRef ConstTensorPtrVector input_tensors) { super((Pointer)null); allocate(node_def, op_def, input_shapes_string, input_shapes, input_tensors); }
  private native void allocate(@Const NodeDef node_def, @Const @ByRef OpDef op_def,
                     @Const @ByRef StringVector input_shapes_string,
                     @StdVector TensorShapeProto input_shapes,
                     @Const @ByRef ConstTensorPtrVector input_tensors);

  // This is a temporary constructor used for initial testing.
  //
  // TODO(cwhipkey): remove this temporary constructor.
  //
  // Each input shape describes the input shape as follows:
  // * "?" : the shape's rank and dimensions are unknown
  // * "[1,?,3]" : the shape's rank is known, and dimensions can be known or
  //               unknown (? for unknown #1 - multiple dimensions can be
  //               labeled with the same unknown number, and are deduplicated to
  //               the same Dimension*.
  //
  // <input_tensors> is NULL-padded to be the same size as <input_shapes>.
  //
  // REQUIRES: <node_def> is not NULL, and must outlive the InferenceContext.
  public InferenceContext(@Const NodeDef node_def, @Const @ByRef OpDef op_def,
                     @Const @ByRef StringVector input_shapes,
                     @Const @ByRef ConstTensorPtrVector input_tensors) { super((Pointer)null); allocate(node_def, op_def, input_shapes, input_tensors); }
  private native void allocate(@Const NodeDef node_def, @Const @ByRef OpDef op_def,
                     @Const @ByRef StringVector input_shapes,
                     @Const @ByRef ConstTensorPtrVector input_tensors);

  public native @ByVal ShapeHandle input(int idx);
  public native int num_inputs();

  // Returns the input tensor at index <idx>, or nullptr if the input tensor is
  // not available at the time of shape inference.
  public native @Const Tensor input_tensor(int idx);

  // Returns true iff input_tensor(idx) was called by the shape function.
  public native @Cast("bool") boolean requested_input_tensor(int idx);

  public native void set_input_tensors(@Const @ByRef ConstTensorPtrVector input_tensors);

  public native void set_output(int idx, @ByVal ShapeHandle shape);
  public native int num_outputs();
  public native @ByVal ShapeHandle output(int idx);

  // idx can be negative for an offset from end of dimensions.
  // idx must be in the range [-1 * s.rank, s.rank).
  public native @ByVal DimensionHandle Dim(@ByVal ShapeHandle s, int idx);
  public native int Rank(@ByVal ShapeHandle s);
  public native @Cast("bool") boolean RankKnown(@ByVal ShapeHandle s);
  public native @Cast("tensorflow::int64") long Value(@ByVal DimensionOrConstant d);
  public native @Cast("bool") boolean ValueKnown(@ByVal DimensionOrConstant d);

  // Returns true if the rank and all dimensions of the Shape are known.
  public native @Cast("bool") boolean FullyDefined(@ByVal ShapeHandle s);

  // Returns the total number of elements, or an unknown dimension for an
  // incomplete shape.
  public native @ByVal DimensionHandle NumElements(@ByVal ShapeHandle s);

  public native @StdString BytePointer DebugString(@ByVal ShapeHandle s);
  public native @StdString BytePointer DebugString(@ByVal DimensionHandle d);

  // If <shape> has rank <rank>, or its rank is unknown, return OK and return
  // the shape with asserted rank in <*out>. Otherwise return an error.
  //
  // Note that <*out> may be set to <shape>.
  public native @ByVal Status WithRank(@ByVal ShapeHandle shape, int rank,
                    ShapeHandle out);
  public native @ByVal Status WithRankAtLeast(@ByVal ShapeHandle shape, int rank,
                           ShapeHandle out);
  public native @ByVal Status WithRankAtMost(@ByVal ShapeHandle shape, int rank,
                          ShapeHandle out);

  // If <dim> has value <value>, or its value is unknown, returns OK and returns
  // the dimension with asserted value in <*out>. Otherwise returns an error.
  //
  // Note that <*out> may be set to <dim>.
  public native @ByVal Status WithValue(@ByVal DimensionHandle dim, @Cast("tensorflow::int64") long value,
                     DimensionHandle out);

  // Merges <in0> and <in1> and returns the merged shape in <*out>. If <in0> and
  // <in1> are incompatible in rank, or in the value of any dimension, returns
  // an error.
  //
  // Note that <*out> may be set to <in0> or <in1>.
  public native @ByVal Status Merge(@ByVal ShapeHandle in0, @ByVal ShapeHandle in1,
                 ShapeHandle out);

  // Asserts that <s>'s rank >= <prefix>'s rank, and the first
  // <prefix.rank> dimensions of <s> are compatible with the dimensions of
  // <prefix>.
  // Returns the merged results in <*s_out> and <*prefix_out>.
  public native @ByVal Status MergePrefix(@ByVal ShapeHandle s, @ByVal ShapeHandle prefix, ShapeHandle s_out,
                       ShapeHandle prefix_out);

  // Merges <d0> and <d1> and returns the merged dimension in <*out>. If <d0>
  // and <d1> have incompatible values, returns an error.
  //
  // Note that <*out> may be set to <d0> or <d1>.
  public native @ByVal Status Merge(@ByVal DimensionHandle d0, @ByVal DimensionHandle d1,
                 DimensionHandle out);

  // Returns in <*out> a sub-shape of <s> with dimensions [start:].
  // <start> can be negative to index from the end of the shape. If <start> >
  // rank of <s>, then an empty subshape is returned.
  public native @ByVal Status Subshape(@ByVal ShapeHandle s, @Cast("tensorflow::int64") long start,
                    ShapeHandle out);

  // Returns in <*out> a sub-shape of <s>, with dimensions [start:end].
  // <start> and <end> can be negative, to index from the end of the shape.
  // <start> and <end> are set to the rank of <s> if > rank of <s>.
  public native @ByVal Status Subshape(@ByVal ShapeHandle s, @Cast("tensorflow::int64") long start, @Cast("tensorflow::int64") long end,
                    ShapeHandle out);

  // Returns in <*out> the result of appending the dimensions of <s2> to those
  // of <s1>.
  public native @ByVal Status Concatenate(@ByVal ShapeHandle s1, @ByVal ShapeHandle s2,
                       ShapeHandle out);

  // Returns in <out> the shape from replacing <s.dim[dim_index]> with
  // <new_dim>.
  public native @ByVal Status ReplaceDim(@ByVal ShapeHandle s, int dim_index, @ByVal DimensionHandle new_dim,
                      ShapeHandle out);

  // Returns a new shape with the given dims. The returned value is owned by
  // this context.
  public native @ByVal ShapeHandle MakeShape(@StdVector DimensionHandle dims);

  // Returns a new unknown shape.
  public native @ByVal ShapeHandle UnknownShape();

  // Returns a shape with specified rank but unknown dims.
  public native @ByVal ShapeHandle UnknownShapeOfRank(int rank);

  // Returns a new shape of zero dimensions.
  public native @ByVal ShapeHandle Scalar();

  // Returns a new shape of one dimension.
  public native @ByVal ShapeHandle Vector(@ByVal DimensionOrConstant dim);

  // Returns a new shape of two dimensions.
  public native @ByVal ShapeHandle Matrix(@ByVal DimensionOrConstant dim1, @ByVal DimensionOrConstant dim2);

  // Returns in <out> a new shape whose dimension sizes come from input tensor
  // <input_idx>. The tensor must be a 1-dimensional int32 or int64 tensor.  If
  // the input tensor is NULL, then an unknown shape is returned.
  public native @ByVal Status MakeShapeFromShapeTensor(int input_idx, ShapeHandle out);

  // Returns in <out> a new shape corresponding to <proto>.
  public native @ByVal Status MakeShapeFromShapeProto(@Const @ByRef TensorShapeProto proto,
                                   ShapeHandle out);

  // Returns a new dimension of the given size.  The returned value is owned by
  // this context.
  public native @ByVal DimensionHandle MakeDim(@ByVal DimensionOrConstant d);
  public native @ByVal DimensionHandle UnknownDim();

  // Returns a new dimension whose value is given by a scalar input tensor.
  // The input tensor must be in host memory, since it is dereferenced to get
  // the value.
  public native @ByVal Status MakeDimForScalarInput(int idx, DimensionHandle out);

  // Look up the attr for the NodeDef being evaluated with name attr_name and
  // set *value to its value.  If no attr with attr_name is found in def(), or
  // the attr does not have a matching type, a non-ok status will be returned.

  // Returns in <out> the result of dividing <dividend> by <divisor>.
  // Returns an error if <divisor>  is not positive or if <evenly_divisible>
  // and <divisor> does not evenly divide <dividend>.
  public native @ByVal Status Divide(@ByVal DimensionHandle dividend, @Cast("tensorflow::int64") long divisor, @Cast("bool") boolean evenly_divisible,
                  DimensionHandle out);

  // Returns in <out> the sum of <first> and <second>.
  public native @ByVal Status Add(@ByVal DimensionHandle first, @ByVal DimensionOrConstant second,
               DimensionHandle out);

  // Returns in <out> the dimension that is <first> minus <second>.
  public native @ByVal Status Subtract(@ByVal DimensionHandle first, @ByVal DimensionOrConstant second,
                    DimensionHandle out);

  // Returns in <out> the product of <first> and <second>.
  public native @ByVal Status Multiply(@ByVal DimensionHandle first, @ByVal DimensionOrConstant second,
                    DimensionHandle out);

  // Returns in <out> the minimum of <first> and <second>. If either <first> or
  // <second> is zero the results is zero. Otherwise, if either <first> or
  // <second> is unknown the results is unknown.
  public native @ByVal Status Min(@ByVal DimensionHandle first, @ByVal DimensionOrConstant second,
               DimensionHandle out);

  // Returns in <out> the maximum of <first> and <second>. If either <first> or
  // <second> is unknown the results is unknown.
  public native @ByVal Status Max(@ByVal DimensionHandle first, @ByVal DimensionOrConstant second,
               DimensionHandle out);

  public native @ByVal Status construction_status();

  // Validates the 3 component tensors of a sparse tensor have the proper
  // shapes. This mimics SparseTensor.__init__ in python/framework/ops.py.
  public native @ByVal Status ValidateSparseTensor(@ByVal ShapeHandle indices_shape,
                                @ByVal ShapeHandle values_shape,
                                @ByVal ShapeHandle shape_shape);
}

// -----------------------------------------------------------------------------
// Template and inline method implementations, please ignore













  // namespace shape_inference
  // namespace tensorflow

// #endif  // THIRD_PARTY_TENSORFLOW_CORE_FRAMEWORK_SHAPE_INFERENCE_H_


// Parsed from tensorflow/core/framework/partial_tensor_shape.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_CORE_FRAMEWORK_PARTIAL_TENSOR_SHAPE_H_
// #define TENSORFLOW_CORE_FRAMEWORK_PARTIAL_TENSOR_SHAPE_H_

// #include <string>

// #include "third_party/eigen3/unsupported/Eigen/CXX11/Tensor"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/tensor_shape.pb.h"
// #include "tensorflow/core/lib/core/errors.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// #include "tensorflow/core/lib/gtl/inlined_vector.h"
// #include "tensorflow/core/lib/strings/strcat.h"
// #include "tensorflow/core/platform/logging.h"

@Namespace("tensorflow") @Opaque public static class PartialTensorShapeIter extends Pointer {
    /** Empty constructor. Calls {@code super((Pointer)null)}. */
    public PartialTensorShapeIter() { super((Pointer)null); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public PartialTensorShapeIter(Pointer p) { super(p); }
}  // Declared below

/** Manages the partially known dimensions of a Tensor and their sizes. */
@Namespace("tensorflow") @NoOffset public static class PartialTensorShape extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public PartialTensorShape(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public PartialTensorShape(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public PartialTensorShape position(long position) {
        return (PartialTensorShape)super.position(position);
    }

  /** \brief Construct an unknown {@code PartialTensorShape}. */
  public PartialTensorShape() { super((Pointer)null); allocate(); }
  private native void allocate();

  /** \brief Construct a {@code PartialTensorShape} from the provided sizes.
   *  REQUIRES: {@code dim_sizes[i] >= 0} */
  public PartialTensorShape(@Cast("tensorflow::int64*") @ArraySlice LongPointer dim_sizes) { super((Pointer)null); allocate(dim_sizes); }
  private native void allocate(@Cast("tensorflow::int64*") @ArraySlice LongPointer dim_sizes);
  public PartialTensorShape(@Cast("tensorflow::int64*") @ArraySlice LongBuffer dim_sizes) { super((Pointer)null); allocate(dim_sizes); }
  private native void allocate(@Cast("tensorflow::int64*") @ArraySlice LongBuffer dim_sizes);
  public PartialTensorShape(@Cast("tensorflow::int64*") @ArraySlice long... dim_sizes) { super((Pointer)null); allocate(dim_sizes); }
  private native void allocate(@Cast("tensorflow::int64*") @ArraySlice long... dim_sizes);

  /** REQUIRES: {@code IsValid(proto)} */
  public PartialTensorShape(@Const @ByRef TensorShapeProto proto) { super((Pointer)null); allocate(proto); }
  private native void allocate(@Const @ByRef TensorShapeProto proto);

  /** Returns {@code true} iff {@code proto} is a valid partial tensor shape. */
  public static native @Cast("bool") boolean IsValid(@Const @ByRef TensorShapeProto proto);

  /** Returns {@code OK} iff {@code proto} is a valid tensor shape, and a descriptive error
   *  status otherwise. */
  public static native @ByVal Status IsValidShape(@Const @ByRef TensorShapeProto proto);

  /** Add a dimension to the end ("inner-most"), returns a new
   *  PartialTensorShape.
   *  REQUIRES: {@code size >= -1}, where -1 means unknown */
  public native @ByVal PartialTensorShape Concatenate(@Cast("tensorflow::int64") long size);

  /** Appends all the dimensions from {@code shape}.  Returns a new
   *  PartialTensorShape. */
  public native @ByVal PartialTensorShape Concatenate(@Const @ByRef PartialTensorShape shape);

  /** Merges all the dimensions from {@code shape}.  Returns
   *  {@code InvalidArgument} error if either {@code shape} has a different rank
   *  or if any of the dimensions are incompatible. */
  public native @ByVal Status MergeWith(@Const @ByRef PartialTensorShape shape,
                     PartialTensorShape result);

  /** Return the number of dimensions in the tensor. If the number of
   *  dimensions is unknown, return -1. */
  public native int dims();

  /** Return true iff the rank and all of the dimensions are well defined */
  public native @Cast("bool") boolean IsFullyDefined();

  /** Return true iff the ranks match, and if the
   *  dimensions all either match or one is unknown. */
  public native @Cast("bool") boolean IsCompatibleWith(@Const @ByRef PartialTensorShape shape);

  /** Return true iff the dimensions of {@code shape} are compatible with
   *  {@code *this}. */
  public native @Cast("bool") boolean IsCompatibleWith(@Const @ByRef TensorShape shape);

  /** \brief Returns the number of elements in dimension {@code d}.
   *  REQUIRES: {@code 0 <= d < dims()} */
  public native @Cast("tensorflow::int64") long dim_size(int d);

  /** Returns sizes of all dimensions. */
  public native @Cast("tensorflow::int64*") @ArraySlice LongPointer dim_sizes();

  /** Fill {@code *proto} from {@code *this}. */
  public native void AsProto(TensorShapeProto proto);

  // Fill `*tensor_shape` from `*this`.
  // If `*this` is not fully defined, returns false and
  // `*tensor_shape` is left in an intermediate state.  Otherwise
  // returns true.
  public native @Cast("bool") boolean AsTensorShape(TensorShape tensor_shape);

  /** For error messages. */
  public native @StdString BytePointer DebugString();
  public static native @StdString BytePointer DebugString(@Const @ByRef TensorShapeProto proto);

  /** \brief Returns a {@code PartialTensorShape} whose dimensions are
   *  {@code dims[0]}, {@code dims[1]}, ..., {@code dims[n-1]}.  Values of -1 are
   *  considered "unknown". */
  public static native @ByVal Status MakePartialShape(@Const IntPointer dims, int n,
                                   PartialTensorShape out);
  public static native @ByVal Status MakePartialShape(@Const IntBuffer dims, int n,
                                   PartialTensorShape out);
  public static native @ByVal Status MakePartialShape(@Const int[] dims, int n,
                                   PartialTensorShape out);
  public static native @ByVal Status MakePartialShape(@Cast("const tensorflow::int64*") LongPointer dims, int n,
                                   PartialTensorShape out);
  public static native @ByVal Status MakePartialShape(@Cast("const tensorflow::int64*") LongBuffer dims, int n,
                                   PartialTensorShape out);
  public static native @ByVal Status MakePartialShape(@Cast("const tensorflow::int64*") long[] dims, int n,
                                   PartialTensorShape out);
}

/** \brief Static helper routines for {@code PartialTensorShape}. Includes a few
 *  common predicates on a partially known tensor shape. */
@Namespace("tensorflow") public static class PartialTensorShapeUtils extends Pointer {
    static { Loader.load(); }
    /** Default native constructor. */
    public PartialTensorShapeUtils() { super((Pointer)null); allocate(); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public PartialTensorShapeUtils(long size) { super((Pointer)null); allocateArray(size); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public PartialTensorShapeUtils(Pointer p) { super(p); }
    private native void allocate();
    private native void allocateArray(long size);
    @Override public PartialTensorShapeUtils position(long position) {
        return (PartialTensorShapeUtils)super.position(position);
    }

  public static native @StdString BytePointer PartialShapeListString(
        @ArraySlice PartialTensorShape shapes);

  public static native @Cast("bool") boolean AreCompatible(@ArraySlice PartialTensorShape shapes0,
                              @ArraySlice PartialTensorShape shapes1);
}

  // namespace tensorflow

// #endif  // TENSORFLOW_CORE_FRAMEWORK_PARTIAL_TENSOR_SHAPE_H_


// Parsed from tensorflow/core/public/session.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_PUBLIC_SESSION_H_
// #define TENSORFLOW_PUBLIC_SESSION_H_

// #include <string>
// #include <vector>

// #include "tensorflow/core/framework/graph.pb.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/platform/env.h"
// #include "tensorflow/core/protobuf/config.pb.h"
// #include "tensorflow/core/public/session_options.h"

/** \brief A Session instance lets a caller drive a TensorFlow graph
 *  computation.
 * 
 *  When a Session is created with a given target, a new Session object
 *  is bound to the universe of resources specified by that target.
 *  Those resources are available to this session to perform
 *  computation described in the GraphDef.  After extending the session
 *  with a graph, the caller uses the Run() API to perform the
 *  computation and potentially fetch outputs as Tensors.
 * 
 *  Example:
 * 
 *  <pre>{@code c++
 * 
 *      tensorflow::GraphDef graph;
 *      // ... Create or load graph into "graph".
 * 
 *      // This example uses the default options which connects
 *      // to a local runtime.
 *      tensorflow::SessionOptions options;
 *      std::unique_ptr<tensorflow::Session>
 *      session(tensorflow::NewSession(options));
 * 
 *      // Create the session with this graph.
 *      tensorflow::Status s = session->Create(graph);
 *      if (!s.ok()) { ... }
 * 
 *      // Run the graph and fetch the first output of the "output"
 *      // operation, and also run to but do not return anything
 *      // for the "update_state" operation.
 *      std::vector<tensorflow::Tensor> outputs;
 *      s = session->Run({}, {"output:0"}, {"update_state"}, &outputs);
 *      if (!s.ok()) { ... }
 * 
 *      // Map the output as a flattened float tensor, and do something
 *      // with it.
 *      auto output_tensor = outputs[0].flat<float>();
 *      if (output_tensor(0) > 0.5) { ... }
 * 
 *      // Close the session to release the resources associated with
 *      // this session.
 *      session->Close();
 * 
 *  }</pre>
 * 
 *  A Session allows concurrent calls to Run(), though a Session must
 *  be created / extended by a single thread.
 * 
 *  Only one thread must call Close(), and Close() must only be called
 *  after all other calls to Run() have returned. */
@Namespace("tensorflow") public static class Session extends AbstractSession {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Session(Pointer p) { super(p); }

  
  ///
  /** Calls {@link tensorflow#NewSession(SessionOptions)} and registers a deallocator. */
  public Session(SessionOptions options) { super(options); }

  /** \brief Create the graph to be used for the session.
   * 
   *  Returns an error if this session has already been created with a
   *  graph. To re-use the session with a different graph, the caller
   *  must Close() the session first. */
  
  ///
  public native @ByVal Status Create(@Const @ByRef GraphDef graph);

  /** \brief Adds operations to the graph that is already registered with the
   *  Session.
   * 
   *  The names of new operations in "graph" must not exist in the
   *  graph that is already registered. */
  
  ///
  ///
  ///
  ///
  ///
  public native @ByVal Status Extend(@Const @ByRef GraphDef graph);

  /** \brief Runs the graph with the provided input tensors and fills
   *  {@code outputs} for the endpoints specified in {@code output_tensor_names}.
   *  Runs to but does not return Tensors for the nodes in
   *  {@code target_node_names}.
   * 
   *  The order of tensors in {@code outputs} will match the order provided
   *  by {@code output_tensor_names}.
   * 
   *  If {@code Run} returns {@code OK()}, then {@code outputs->size()} will be equal to
   *  {@code output_tensor_names.size()}.  If {@code Run} does not return {@code OK()}, the
   *  state of {@code outputs} is undefined.
   * 
   *  REQUIRES: The name of each Tensor of the input or output must
   *  match a "Tensor endpoint" in the {@code GraphDef} passed to {@code Create()}.
   * 
   *  REQUIRES: At least one of {@code output_tensor_names} and
   *  {@code target_node_names} must be non-empty.
   * 
   *  REQUIRES: outputs is not nullptr if {@code output_tensor_names} is non-empty. */
  public native @ByVal Status Run(@Const @ByRef StringTensorPairVector inputs,
                       @Const @ByRef StringVector output_tensor_names,
                       @Const @ByRef StringVector target_node_names,
                       TensorVector outputs);

  /** \brief Implementations which support {@code RunOptions}. */
  //
  /** NOTE: This API is still experimental and may change. */
  public native @ByVal Status Create(@Const @ByRef RunOptions run_options, @Const @ByRef GraphDef graph);
  public native @ByVal Status Extend(@Const @ByRef RunOptions run_options, @Const @ByRef GraphDef graph);
  public native @ByVal Status Close(@Const @ByRef RunOptions run_options);

  /** \brief Like {@code Run}, but allows users to pass in a {@code RunOptions} proto and
   *  to retrieve non-Tensor metadata output via a {@code RunMetadata} proto for this
   *  step.  {@code run_metadata} may be nullptr, in which case any metadata output is
   *  discarded.
   *  NOTE: This API is still experimental and may change. */
  public native @ByVal Status Run(@Const @ByRef RunOptions run_options,
                       @Const @ByRef StringTensorPairVector inputs,
                       @Const @ByRef StringVector output_tensor_names,
                       @Const @ByRef StringVector target_node_names,
                       TensorVector outputs, RunMetadata run_metadata);

  /** \brief Sets up a graph for partial execution. All future feeds and
   *  fetches are specified by {@code input_names} and {@code output_names}. Returns
   *  {@code handle} that can be used to perform a sequence of partial feeds and
   *  fetches.
   *  NOTE: This API is still experimental and may change. */
  public native @ByVal Status PRunSetup(@Const @ByRef StringVector input_names,
                             @Const @ByRef StringVector output_names,
                             @Const @ByRef StringVector target_nodes,
                             @StdString @Cast({"char*", "std::string*"}) BytePointer handle);

  /** \brief Continues the pending execution specified by {@code handle} with the
   *  provided input tensors and fills {@code outputs} for the endpoints specified
   *  in {@code output_names}.
   *  NOTE: This API is still experimental and may change. */
  
  ///
  public native @ByVal Status PRun(@StdString BytePointer handle,
                        @Const @ByRef StringTensorPairVector inputs,
                        @Const @ByRef StringVector output_names,
                        TensorVector outputs);
  public native @ByVal Status PRun(@StdString String handle,
                        @Const @ByRef StringTensorPairVector inputs,
                        @Const @ByRef StringVector output_names,
                        TensorVector outputs);

  /** \brief Closes this session.
   * 
   *  Closing a session releases the resources used by this session
   *  on the TensorFlow runtime (specified during session creation by
   *  the {@code SessionOptions::target} field). */
  public native @ByVal Status Close();
}

/** \brief Create a new session with the given options.
 * 
 *  If session creation succeeds, the new {@code Session} will be stored in
 *  {@code *out_session}, the caller will take ownership of the returned
 *  {@code *out_session}, and this function will return {@code OK()}. Otherwise, this
 *  function will return an error status. */

///
///
@Namespace("tensorflow") public static native @ByVal Status NewSession(@Const @ByRef SessionOptions options, @Cast("tensorflow::Session**") PointerPointer out_session);
@Namespace("tensorflow") public static native @ByVal Status NewSession(@Const @ByRef SessionOptions options, @ByPtrPtr Session out_session);

/** \brief Resets resource containers associated with a target.
 * 
 *  {@code containers} is a vector of string representation of resource container
 *  names. When a resource container is reset, the resources held by the
 *  container will be released. In particular, all Variables in the container
 *  will become undefined.
 * 
 *  If Reset succeeds, this function will return {@code OK()}. Otherwise, this
 *  function will return an error status. */

///
///
@Namespace("tensorflow") public static native @ByVal Status Reset(@Const @ByRef SessionOptions options,
             @Const @ByRef StringVector containers);

/** \brief Create a new session with the given options.
 * 
 *  If a new {@code Session} object could not be created, this function will
 *  return nullptr.
 * 
 *  *Strongly prefer* the version of NewSession that returns Status,
 *  which contains more helpful error information. */
@Namespace("tensorflow") public static native Session NewSession(@Const @ByRef SessionOptions options);

  // end namespace tensorflow

// #endif  // TENSORFLOW_PUBLIC_SESSION_H_


// Parsed from tensorflow/c/c_api.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_C_C_API_H_
// #define TENSORFLOW_C_C_API_H_

// #include <stddef.h>
// #include <stdint.h>

// --------------------------------------------------------------------------
// C API for TensorFlow.
//
// The API leans towards simplicity and uniformity instead of convenience
// since most usage will be by language specific wrappers.
//
// Conventions:
// * We use the prefix TF_ for everything in the API.
// * Objects are always passed around as pointers to opaque structs
//   and these structs are allocated/deallocated via the API.
// * TF_Status holds error information.  It is an object type
//   and therefore is passed around as a pointer to an opaque
//   struct as mentioned above.
// * Every call that has a TF_Status* argument clears it on success
//   and fills it with error info on failure.
// * unsigned char is used for booleans (instead of the 'bool' type).
//   In C++ bool is a keyword while in C99 bool is a macro defined
//   in stdbool.h. It is possible for the two to be inconsistent.
//   For example, neither the C99 nor the C++11 standard force a byte
//   size on the bool type, so the macro defined in stdbool.h could
//   be inconsistent with the bool keyword in C++. Thus, the use
//   of stdbool.h is avoided and unsigned char is used instead.
//
// Questions left to address:
// * Might at some point need a way for callers to provide their own Env.
// * Maybe add TF_TensorShape that encapsulates dimension info.
//
// Design decisions made:
// * Backing store for tensor memory has an associated deallocation
//   function.  This deallocation function will point to client code
//   for tensors populated by the client.  So the client can do things
//   like shadowing a numpy array.
// * We do not provide TF_OK since it is not strictly necessary and we
//   are not optimizing for convenience.
// * We make assumption that one session has one graph.  This should be
//   fine since we have the ability to run sub-graphs.
// * We could allow NULL for some arguments (e.g., NULL options arg).
//   However since convenience is not a primary goal, we don't do this.
// * Devices are not in this API.  Instead, they are created/used internally
//   and the API just provides high level controls over the number of
//   devices of each type.

// #ifdef __cplusplus
// #endif

// --------------------------------------------------------------------------
// TF_DataType holds the type for a scalar value.  E.g., one slot in a tensor.
// The enum values here are identical to corresponding values in types.proto.
/** enum TF_DataType */
public static final int
  TF_FLOAT = 1,
  TF_DOUBLE = 2,
  TF_INT32 = 3,  // Int32 tensors are always in 'host' memory.
  TF_UINT8 = 4,
  TF_INT16 = 5,
  TF_INT8 = 6,
  TF_STRING = 7,
  TF_COMPLEX64 = 8,  // Single-precision complex
  TF_COMPLEX = 8,    // Old identifier kept for API backwards compatibility
  TF_INT64 = 9,
  TF_BOOL = 10,
  TF_QINT8 = 11,     // Quantized int8
  TF_QUINT8 = 12,    // Quantized uint8
  TF_QINT32 = 13,    // Quantized int32
  TF_BFLOAT16 = 14,  // Float32 truncated to 16 bits.  Only for cast ops.
  TF_QINT16 = 15,    // Quantized int16
  TF_QUINT16 = 16,   // Quantized uint16
  TF_UINT16 = 17,
  TF_COMPLEX128 = 18,  // Double-precision complex
  TF_HALF = 19;

// --------------------------------------------------------------------------
// TF_Code holds an error code.  The enum values here are identical to
// corresponding values in error_codes.proto.
/** enum TF_Code */
public static final int
  TF_OK = 0,
  TF_CANCELLED = 1,
  TF_UNKNOWN = 2,
  TF_INVALID_ARGUMENT = 3,
  TF_DEADLINE_EXCEEDED = 4,
  TF_NOT_FOUND = 5,
  TF_ALREADY_EXISTS = 6,
  TF_PERMISSION_DENIED = 7,
  TF_UNAUTHENTICATED = 16,
  TF_RESOURCE_EXHAUSTED = 8,
  TF_FAILED_PRECONDITION = 9,
  TF_ABORTED = 10,
  TF_OUT_OF_RANGE = 11,
  TF_UNIMPLEMENTED = 12,
  TF_INTERNAL = 13,
  TF_UNAVAILABLE = 14,
  TF_DATA_LOSS = 15;

// --------------------------------------------------------------------------
// TF_Status holds error information.  It either has an OK code, or
// else an error code with an associated error message.
@Opaque public static class TF_Status extends Pointer {
    /** Empty constructor. Calls {@code super((Pointer)null)}. */
    public TF_Status() { super((Pointer)null); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TF_Status(Pointer p) { super(p); }
}

// Return a new status object.
public static native TF_Status TF_NewStatus();

// Delete a previously created status object.
public static native void TF_DeleteStatus(TF_Status arg0);

// Record <code, msg> in *s.  Any previous information is lost.
// A common use is to clear a status: TF_SetStatus(s, TF_OK, "");
public static native void TF_SetStatus(TF_Status s, @Cast("TF_Code") int code, @Cast("const char*") BytePointer msg);
public static native void TF_SetStatus(TF_Status s, @Cast("TF_Code") int code, String msg);

// Return the code record in *s.
public static native @Cast("TF_Code") int TF_GetCode(@Const TF_Status s);

// Return a pointer to the (null-terminated) error message in *s.  The
// return value points to memory that is only usable until the next
// mutation to *s.  Always returns an empty string if TF_GetCode(s) is
// TF_OK.
public static native @Cast("const char*") BytePointer TF_Message(@Const TF_Status s);

// --------------------------------------------------------------------------
// TF_Buffer holds a pointer to a block of data and its associated length.
// Typically, the data consists of a serialized protocol buffer, but other data
// may also be held in a buffer.
//
// By default, TF_Buffer itself does not do any memory management of the
// pointed-to block.  If need be, users of this struct should specify how to
// deallocate the block by setting the `data_deallocator` function pointer.
public static class TF_Buffer extends Pointer {
    static { Loader.load(); }
    /** Default native constructor. */
    public TF_Buffer() { super((Pointer)null); allocate(); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public TF_Buffer(long size) { super((Pointer)null); allocateArray(size); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TF_Buffer(Pointer p) { super(p); }
    private native void allocate();
    private native void allocateArray(long size);
    @Override public TF_Buffer position(long position) {
        return (TF_Buffer)super.position(position);
    }

  @MemberGetter public native @Const Pointer data();
  public native @Cast("size_t") long length(); public native TF_Buffer length(long length);
  public static class Data_deallocator_Pointer_long extends FunctionPointer {
      static { Loader.load(); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public    Data_deallocator_Pointer_long(Pointer p) { super(p); }
      protected Data_deallocator_Pointer_long() { allocate(); }
      private native void allocate();
      public native void call(Pointer data, @Cast("size_t") long length);
  }
  public native Data_deallocator_Pointer_long data_deallocator(); public native TF_Buffer data_deallocator(Data_deallocator_Pointer_long data_deallocator);
}

// Makes a copy of the input and sets an appropriate deallocator.  Useful for
// passing in read-only, input protobufs.
public static native TF_Buffer TF_NewBufferFromString(@Const Pointer proto, @Cast("size_t") long proto_len);

// Useful for passing *out* a protobuf.
public static native TF_Buffer TF_NewBuffer();

public static native void TF_DeleteBuffer(TF_Buffer arg0);

public static native @ByVal TF_Buffer TF_GetBuffer(TF_Buffer buffer);

// --------------------------------------------------------------------------
// TF_Tensor holds a multi-dimensional array of elements of a single data type.
// For all types other than TF_STRING, the data buffer stores elements
// in row major order.  E.g. if data is treated as a vector of TF_DataType:
//
//   element 0:   index (0, ..., 0)
//   element 1:   index (0, ..., 1)
//   ...
//
// The format for TF_STRING tensors is:
//   start_offset: array[uint64]
//   data:         byte[...]
//
//   String length is encoded (varint?) starting at data[start_offset[i]]
//   String contents follow immediately after string length.

@Opaque public static class TF_Tensor extends Pointer {
    /** Empty constructor. Calls {@code super((Pointer)null)}. */
    public TF_Tensor() { super((Pointer)null); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TF_Tensor(Pointer p) { super(p); }
}

// Return a new tensor that holds the bytes data[0,len-1].
//
// The data will be deallocated by a subsequent call to TF_DeleteTensor via:
//      (*deallocator)(data, len, deallocator_arg)
// Clients must provide a custom deallocator function so they can pass in
// memory managed by something like numpy.
public static class Deallocator_Pointer_long_Pointer extends FunctionPointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public    Deallocator_Pointer_long_Pointer(Pointer p) { super(p); }
    protected Deallocator_Pointer_long_Pointer() { allocate(); }
    private native void allocate();
    public native void call(Pointer data, @Cast("size_t") long len,
                                                   Pointer arg);
}
public static native TF_Tensor TF_NewTensor(@Cast("TF_DataType") int arg0, @Cast("const int64_t*") LongPointer dims, int num_dims,
                               Pointer data, @Cast("size_t") long len,
                               Deallocator_Pointer_long_Pointer deallocator,
                               Pointer deallocator_arg);
public static native TF_Tensor TF_NewTensor(@Cast("TF_DataType") int arg0, @Cast("const int64_t*") LongBuffer dims, int num_dims,
                               Pointer data, @Cast("size_t") long len,
                               Deallocator_Pointer_long_Pointer deallocator,
                               Pointer deallocator_arg);
public static native TF_Tensor TF_NewTensor(@Cast("TF_DataType") int arg0, @Cast("const int64_t*") long[] dims, int num_dims,
                               Pointer data, @Cast("size_t") long len,
                               Deallocator_Pointer_long_Pointer deallocator,
                               Pointer deallocator_arg);

// Allocate and return a new Tensor.
//
// This function is an alternative to TF_NewTensor and should be used when
// memory is allocated to pass the Tensor to the C API. The allocated memory
// satisfies TensorFlow's memory alignment preferences and should be preferred
// over calling malloc and free.
//
// The caller must set the Tensor values by writing them to the pointer returned
// by TF_TensorData with length TF_TensorByteSize.
public static native TF_Tensor TF_AllocateTensor(@Cast("TF_DataType") int arg0, @Cast("const int64_t*") LongPointer dims,
                                    int num_dims, @Cast("size_t") long len);
public static native TF_Tensor TF_AllocateTensor(@Cast("TF_DataType") int arg0, @Cast("const int64_t*") LongBuffer dims,
                                    int num_dims, @Cast("size_t") long len);
public static native TF_Tensor TF_AllocateTensor(@Cast("TF_DataType") int arg0, @Cast("const int64_t*") long[] dims,
                                    int num_dims, @Cast("size_t") long len);

// Destroy a tensor.
public static native void TF_DeleteTensor(TF_Tensor arg0);

// Return the type of a tensor element.
public static native @Cast("TF_DataType") int TF_TensorType(@Const TF_Tensor arg0);

// Return the number of dimensions that the tensor has.
public static native int TF_NumDims(@Const TF_Tensor arg0);

// Return the length of the tensor in the "dim_index" dimension.
// REQUIRES: 0 <= dim_index < TF_NumDims(tensor)
public static native @Cast("int64_t") long TF_Dim(@Const TF_Tensor tensor, int dim_index);

// Return the size of the underlying data in bytes.
public static native @Cast("size_t") long TF_TensorByteSize(@Const TF_Tensor arg0);

// Return a pointer to the underlying data buffer.
public static native Pointer TF_TensorData(@Const TF_Tensor arg0);

// --------------------------------------------------------------------------
// TF_SessionOptions holds options that can be passed during session creation.
@Opaque public static class TF_SessionOptions extends Pointer {
    /** Empty constructor. Calls {@code super((Pointer)null)}. */
    public TF_SessionOptions() { super((Pointer)null); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TF_SessionOptions(Pointer p) { super(p); }
}

// Return a new options object.
public static native TF_SessionOptions TF_NewSessionOptions();

// Set the target in TF_SessionOptions.options.
// target can be empty, a single entry, or a comma separated list of entries.
// Each entry is in one of the following formats :
// "local"
// ip:port
// host:port
public static native void TF_SetTarget(TF_SessionOptions options, @Cast("const char*") BytePointer target);
public static native void TF_SetTarget(TF_SessionOptions options, String target);

// Set the config in TF_SessionOptions.options.
// config should be a serialized tensorflow.ConfigProto proto.
// If config was not parsed successfully as a ConfigProto, record the
// error information in *status.
public static native void TF_SetConfig(TF_SessionOptions options, @Const Pointer proto,
                         @Cast("size_t") long proto_len, TF_Status status);

// Destroy an options object.
public static native void TF_DeleteSessionOptions(TF_SessionOptions arg0);

// TODO(jeff,sanjay):
// - export functions to set Config fields

// --------------------------------------------------------------------------
// The new graph construction API, still under development.

// Represents a computation graph.  Graphs may be shared between sessions.
// Graphs are thread-safe when used as directed below.
@Opaque public static class TF_Graph extends Pointer {
    /** Empty constructor. Calls {@code super((Pointer)null)}. */
    public TF_Graph() { super((Pointer)null); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TF_Graph(Pointer p) { super(p); }
}

// Return a new graph object.
public static native TF_Graph TF_NewGraph();

// Destroy an options object.  Graph will be deleted once no more
// TFSessionWithGraph's are referencing it.
public static native void TF_DeleteGraph(TF_Graph arg0);

// Operation being built. The underlying graph must outlive this.
@Opaque public static class TF_OperationDescription extends Pointer {
    /** Empty constructor. Calls {@code super((Pointer)null)}. */
    public TF_OperationDescription() { super((Pointer)null); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TF_OperationDescription(Pointer p) { super(p); }
}

// Operation that has been added to the graph. Valid until the graph is
// deleted -- in particular adding a new operation to the graph does not
// invalidate old TF_Operation* pointers.
@Opaque public static class TF_Operation extends Pointer {
    /** Empty constructor. Calls {@code super((Pointer)null)}. */
    public TF_Operation() { super((Pointer)null); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TF_Operation(Pointer p) { super(p); }
}

// Represents a specific input or output of an operation, e.g. to
// specify the specific output to pass as an input to a new op.
public static class TF_Port extends Pointer {
    static { Loader.load(); }
    /** Default native constructor. */
    public TF_Port() { super((Pointer)null); allocate(); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public TF_Port(long size) { super((Pointer)null); allocateArray(size); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TF_Port(Pointer p) { super(p); }
    private native void allocate();
    private native void allocateArray(long size);
    @Override public TF_Port position(long position) {
        return (TF_Port)super.position(position);
    }

  public native TF_Operation oper(); public native TF_Port oper(TF_Operation oper);
  public native int index(); public native TF_Port index(int index);  // Specifies the index of the input or output within oper.
}

// Sets the shape of the Tensor referenced by `port` in `graph` to
// the shape described by `dims` and `num_dims`.
//
// If the number of dimensions is unknown, `num_dims` must be
// set to -1 and dims can be null. If a dimension is unknown,
// the corresponding entry in the `dims` array must be -1.
//
// This does not overwrite the existing shape associated with `port`,
// but merges the input shape with the existing shape.  For example,
// setting a shape of [-1, 2] with an existing shape [2, -1] would set
// a final shape of [2, 2] based on shape merging semantics.
//
// Returns an error into `status` if:
//   * `port` is not in `graph`.
//   * An invalid shape is being set (e.g., the shape being set
//     is incompatible with the existing shape).
public static native void TF_GraphSetTensorShape(TF_Graph graph, @ByVal TF_Port port,
                                   @Cast("const int64_t*") LongPointer dims, int num_dims,
                                   TF_Status status);
public static native void TF_GraphSetTensorShape(TF_Graph graph, @ByVal TF_Port port,
                                   @Cast("const int64_t*") LongBuffer dims, int num_dims,
                                   TF_Status status);
public static native void TF_GraphSetTensorShape(TF_Graph graph, @ByVal TF_Port port,
                                   @Cast("const int64_t*") long[] dims, int num_dims,
                                   TF_Status status);

// Returns the number of dimensions of the Tensor referenced by `port`
// in `graph`.
//
// If the number of dimensions in the shape is unknown, returns -1.
//
// Returns an error into `status` if:
//   * `port` is not in `graph`.
public static native int TF_GraphGetTensorNumDims(TF_Graph graph, @ByVal TF_Port port,
                                    TF_Status status);

// Returns the shape of the Tensor referenced by `port` in `graph`
// into `dims`. `dims` must be an array large enough to hold `num_dims`
// entries (e.g., the return value of TF_GraphGetTensorNumDims).
//
// If the number of dimensions in the shape is unknown or the shape is
// a scalar, `dims` will remain untouched. Otherwise, each element of
// `dims` will be set corresponding to the size of the dimension. An
// unknown dimension is represented by `-1`.
//
// Returns an error into `status` if:
//   * `port` is not in `graph`.
//   * `num_dims` does not match the actual number of dimensions.
public static native void TF_GraphGetTensorShape(TF_Graph graph, @ByVal TF_Port port, @Cast("int64_t*") LongPointer dims,
                                   int num_dims, TF_Status status);
public static native void TF_GraphGetTensorShape(TF_Graph graph, @ByVal TF_Port port, @Cast("int64_t*") LongBuffer dims,
                                   int num_dims, TF_Status status);
public static native void TF_GraphGetTensorShape(TF_Graph graph, @ByVal TF_Port port, @Cast("int64_t*") long[] dims,
                                   int num_dims, TF_Status status);

// Operation will only be added to *graph when TF_FinishOperation() is
// called (assuming TF_FinishOperation() does not return an error).
// *graph must not be deleted until after TF_FinishOperation() is
// called.
public static native TF_OperationDescription TF_NewOperation(TF_Graph graph,
                                                @Cast("const char*") BytePointer op_type,
                                                @Cast("const char*") BytePointer oper_name);
public static native TF_OperationDescription TF_NewOperation(TF_Graph graph,
                                                String op_type,
                                                String oper_name);

// Specify the device for `desc`.  Defaults to empty, meaning unconstrained.
public static native void TF_SetDevice(TF_OperationDescription desc, @Cast("const char*") BytePointer device);
public static native void TF_SetDevice(TF_OperationDescription desc, String device);

// The calls to TF_AddInput and TF_AddInputList must match (in number,
// order, and type) the op declaration.  For example, the "Concat" op
// has registration:
//   REGISTER_OP("Concat")
//       .Input("concat_dim: int32")
//       .Input("values: N * T")
//       .Output("output: T")
//       .Attr("N: int >= 2")
//       .Attr("T: type");
// that defines two inputs, "concat_dim" and "values" (in that order).
// You must use TF_AddInput() for the first input (since it takes a
// single tensor), and TF_AddInputList() for the second input (since
// it takes a list, even if you were to pass a list with a single
// tensor), as in:
//   TF_OperationDescription* desc = TF_NewOperation(graph, "Concat", "c");
//   TF_Port concat_dim_input = {...};
//   TF_AddInput(desc, concat_dim_input);
//   TF_Port values_inputs[5] = {{...}, ..., {...}};
//   TF_AddInputList(desc, values_inputs, 5);

// For inputs that take a single tensor.
public static native void TF_AddInput(TF_OperationDescription desc, @ByVal TF_Port input);

// For inputs that take a list of tensors.
// inputs must point to TF_Port[num_inputs].
public static native void TF_AddInputList(TF_OperationDescription desc,
                            @Const TF_Port inputs, int num_inputs);

// Call once per control input to `desc`.
public static native void TF_AddControlInput(TF_OperationDescription desc,
                               TF_Operation input);

// Request that `desc` be co-located on the device where `op`
// is placed.
//
// Use of this is discouraged since the implementation of device placement is
// subject to change. Primarily intended for internal libraries
public static native void TF_ColocateWith(TF_OperationDescription desc, TF_Operation op);

// Call some TF_SetAttr*() function for every attr that is not
// inferred from an input and doesn't have a default value you wish to
// keep.

// `value` must point to a string of length `length` bytes.
public static native void TF_SetAttrString(TF_OperationDescription desc,
                             @Cast("const char*") BytePointer attr_name, @Const Pointer value,
                             int length);
public static native void TF_SetAttrString(TF_OperationDescription desc,
                             String attr_name, @Const Pointer value,
                             int length);
// `values` and `lengths` both must have lengths `num_values`.
// `values[i]` must point to a string of length `lengths[i]` bytes.
public static native void TF_SetAttrStringList(TF_OperationDescription desc,
                                 @Cast("const char*") BytePointer attr_name,
                                 @Cast("const void*const*") PointerPointer values, @Const IntPointer lengths,
                                 int num_values);
public static native void TF_SetAttrStringList(TF_OperationDescription desc,
                                 @Cast("const char*") BytePointer attr_name,
                                 @Cast("const void*const*") @ByPtrPtr Pointer values, @Const IntPointer lengths,
                                 int num_values);
public static native void TF_SetAttrStringList(TF_OperationDescription desc,
                                 String attr_name,
                                 @Cast("const void*const*") @ByPtrPtr Pointer values, @Const IntBuffer lengths,
                                 int num_values);
public static native void TF_SetAttrStringList(TF_OperationDescription desc,
                                 @Cast("const char*") BytePointer attr_name,
                                 @Cast("const void*const*") @ByPtrPtr Pointer values, @Const int[] lengths,
                                 int num_values);
public static native void TF_SetAttrStringList(TF_OperationDescription desc,
                                 String attr_name,
                                 @Cast("const void*const*") @ByPtrPtr Pointer values, @Const IntPointer lengths,
                                 int num_values);
public static native void TF_SetAttrStringList(TF_OperationDescription desc,
                                 @Cast("const char*") BytePointer attr_name,
                                 @Cast("const void*const*") @ByPtrPtr Pointer values, @Const IntBuffer lengths,
                                 int num_values);
public static native void TF_SetAttrStringList(TF_OperationDescription desc,
                                 String attr_name,
                                 @Cast("const void*const*") @ByPtrPtr Pointer values, @Const int[] lengths,
                                 int num_values);
public static native void TF_SetAttrInt(TF_OperationDescription desc, @Cast("const char*") BytePointer attr_name,
                          @Cast("int64_t") long value);
public static native void TF_SetAttrInt(TF_OperationDescription desc, String attr_name,
                          @Cast("int64_t") long value);
public static native void TF_SetAttrIntList(TF_OperationDescription desc,
                              @Cast("const char*") BytePointer attr_name, @Cast("const int64_t*") LongPointer values,
                              int num_values);
public static native void TF_SetAttrIntList(TF_OperationDescription desc,
                              String attr_name, @Cast("const int64_t*") LongBuffer values,
                              int num_values);
public static native void TF_SetAttrIntList(TF_OperationDescription desc,
                              @Cast("const char*") BytePointer attr_name, @Cast("const int64_t*") long[] values,
                              int num_values);
public static native void TF_SetAttrIntList(TF_OperationDescription desc,
                              String attr_name, @Cast("const int64_t*") LongPointer values,
                              int num_values);
public static native void TF_SetAttrIntList(TF_OperationDescription desc,
                              @Cast("const char*") BytePointer attr_name, @Cast("const int64_t*") LongBuffer values,
                              int num_values);
public static native void TF_SetAttrIntList(TF_OperationDescription desc,
                              String attr_name, @Cast("const int64_t*") long[] values,
                              int num_values);
public static native void TF_SetAttrFloat(TF_OperationDescription desc,
                            @Cast("const char*") BytePointer attr_name, float value);
public static native void TF_SetAttrFloat(TF_OperationDescription desc,
                            String attr_name, float value);
public static native void TF_SetAttrFloatList(TF_OperationDescription desc,
                                @Cast("const char*") BytePointer attr_name, @Const FloatPointer values,
                                int num_values);
public static native void TF_SetAttrFloatList(TF_OperationDescription desc,
                                String attr_name, @Const FloatBuffer values,
                                int num_values);
public static native void TF_SetAttrFloatList(TF_OperationDescription desc,
                                @Cast("const char*") BytePointer attr_name, @Const float[] values,
                                int num_values);
public static native void TF_SetAttrFloatList(TF_OperationDescription desc,
                                String attr_name, @Const FloatPointer values,
                                int num_values);
public static native void TF_SetAttrFloatList(TF_OperationDescription desc,
                                @Cast("const char*") BytePointer attr_name, @Const FloatBuffer values,
                                int num_values);
public static native void TF_SetAttrFloatList(TF_OperationDescription desc,
                                String attr_name, @Const float[] values,
                                int num_values);
public static native void TF_SetAttrBool(TF_OperationDescription desc, @Cast("const char*") BytePointer attr_name,
                           @Cast("unsigned char") byte value);
public static native void TF_SetAttrBool(TF_OperationDescription desc, String attr_name,
                           @Cast("unsigned char") byte value);
public static native void TF_SetAttrBoolList(TF_OperationDescription desc,
                               @Cast("const char*") BytePointer attr_name,
                               @Cast("const unsigned char*") BytePointer values, int num_values);
public static native void TF_SetAttrBoolList(TF_OperationDescription desc,
                               String attr_name,
                               @Cast("const unsigned char*") ByteBuffer values, int num_values);
public static native void TF_SetAttrBoolList(TF_OperationDescription desc,
                               @Cast("const char*") BytePointer attr_name,
                               @Cast("const unsigned char*") byte[] values, int num_values);
public static native void TF_SetAttrBoolList(TF_OperationDescription desc,
                               String attr_name,
                               @Cast("const unsigned char*") BytePointer values, int num_values);
public static native void TF_SetAttrBoolList(TF_OperationDescription desc,
                               @Cast("const char*") BytePointer attr_name,
                               @Cast("const unsigned char*") ByteBuffer values, int num_values);
public static native void TF_SetAttrBoolList(TF_OperationDescription desc,
                               String attr_name,
                               @Cast("const unsigned char*") byte[] values, int num_values);
public static native void TF_SetAttrType(TF_OperationDescription desc, @Cast("const char*") BytePointer attr_name,
                           @Cast("TF_DataType") int value);
public static native void TF_SetAttrType(TF_OperationDescription desc, String attr_name,
                           @Cast("TF_DataType") int value);
public static native void TF_SetAttrTypeList(TF_OperationDescription desc,
                               @Cast("const char*") BytePointer attr_name, @Cast("const TF_DataType*") IntPointer values,
                               int num_values);
public static native void TF_SetAttrTypeList(TF_OperationDescription desc,
                               String attr_name, @Cast("const TF_DataType*") IntBuffer values,
                               int num_values);
public static native void TF_SetAttrTypeList(TF_OperationDescription desc,
                               @Cast("const char*") BytePointer attr_name, @Cast("const TF_DataType*") int[] values,
                               int num_values);
public static native void TF_SetAttrTypeList(TF_OperationDescription desc,
                               String attr_name, @Cast("const TF_DataType*") IntPointer values,
                               int num_values);
public static native void TF_SetAttrTypeList(TF_OperationDescription desc,
                               @Cast("const char*") BytePointer attr_name, @Cast("const TF_DataType*") IntBuffer values,
                               int num_values);
public static native void TF_SetAttrTypeList(TF_OperationDescription desc,
                               String attr_name, @Cast("const TF_DataType*") int[] values,
                               int num_values);

// Set `num_dims` to -1 to represent "unknown rank".  Otherwise,
// `dims` points to an array of length `num_dims`.  `dims[i]` must be
// >= -1, with -1 meaning "unknown dimension".
public static native void TF_SetAttrShape(TF_OperationDescription desc,
                            @Cast("const char*") BytePointer attr_name, @Cast("const int64_t*") LongPointer dims,
                            int num_dims);
public static native void TF_SetAttrShape(TF_OperationDescription desc,
                            String attr_name, @Cast("const int64_t*") LongBuffer dims,
                            int num_dims);
public static native void TF_SetAttrShape(TF_OperationDescription desc,
                            @Cast("const char*") BytePointer attr_name, @Cast("const int64_t*") long[] dims,
                            int num_dims);
public static native void TF_SetAttrShape(TF_OperationDescription desc,
                            String attr_name, @Cast("const int64_t*") LongPointer dims,
                            int num_dims);
public static native void TF_SetAttrShape(TF_OperationDescription desc,
                            @Cast("const char*") BytePointer attr_name, @Cast("const int64_t*") LongBuffer dims,
                            int num_dims);
public static native void TF_SetAttrShape(TF_OperationDescription desc,
                            String attr_name, @Cast("const int64_t*") long[] dims,
                            int num_dims);
// `dims` and `num_dims` must point to arrays of length `num_shapes`.
// Set `num_dims[i]` to -1 to represent "unknown rank".  Otherwise,
// `dims[i]` points to an array of length `num_dims[i]`.  `dims[i][j]`
// must be >= -1, with -1 meaning "unknown dimension".
public static native void TF_SetAttrShapeList(TF_OperationDescription desc,
                                @Cast("const char*") BytePointer attr_name,
                                @Cast("const int64_t*const*") PointerPointer dims, @Const IntPointer num_dims,
                                int num_shapes);
public static native void TF_SetAttrShapeList(TF_OperationDescription desc,
                                @Cast("const char*") BytePointer attr_name,
                                @Cast("const int64_t*const*") @ByPtrPtr LongPointer dims, @Const IntPointer num_dims,
                                int num_shapes);
public static native void TF_SetAttrShapeList(TF_OperationDescription desc,
                                String attr_name,
                                @Cast("const int64_t*const*") @ByPtrPtr LongBuffer dims, @Const IntBuffer num_dims,
                                int num_shapes);
public static native void TF_SetAttrShapeList(TF_OperationDescription desc,
                                @Cast("const char*") BytePointer attr_name,
                                @Cast("const int64_t*const*") @ByPtrPtr long[] dims, @Const int[] num_dims,
                                int num_shapes);
public static native void TF_SetAttrShapeList(TF_OperationDescription desc,
                                String attr_name,
                                @Cast("const int64_t*const*") @ByPtrPtr LongPointer dims, @Const IntPointer num_dims,
                                int num_shapes);
public static native void TF_SetAttrShapeList(TF_OperationDescription desc,
                                @Cast("const char*") BytePointer attr_name,
                                @Cast("const int64_t*const*") @ByPtrPtr LongBuffer dims, @Const IntBuffer num_dims,
                                int num_shapes);
public static native void TF_SetAttrShapeList(TF_OperationDescription desc,
                                String attr_name,
                                @Cast("const int64_t*const*") @ByPtrPtr long[] dims, @Const int[] num_dims,
                                int num_shapes);
// `proto` must point to an array of `proto_len` bytes representing a
// binary-serialized TensorShapeProto.
public static native void TF_SetAttrTensorShapeProto(TF_OperationDescription desc,
                                       @Cast("const char*") BytePointer attr_name, @Const Pointer proto,
                                       int proto_len, TF_Status status);
public static native void TF_SetAttrTensorShapeProto(TF_OperationDescription desc,
                                       String attr_name, @Const Pointer proto,
                                       int proto_len, TF_Status status);
// `protos` and `proto_lens` must point to arrays of length `num_shapes`.
// `protos[i]` must point to an array of `proto_lens[i]` bytes
// representing a binary-serialized TensorShapeProto.
public static native void TF_SetAttrTensorShapeProtoList(TF_OperationDescription desc,
                                           @Cast("const char*") BytePointer attr_name,
                                           @Cast("const void*const*") PointerPointer protos,
                                           @Const IntPointer proto_lens,
                                           int num_shapes, TF_Status status);
public static native void TF_SetAttrTensorShapeProtoList(TF_OperationDescription desc,
                                           @Cast("const char*") BytePointer attr_name,
                                           @Cast("const void*const*") @ByPtrPtr Pointer protos,
                                           @Const IntPointer proto_lens,
                                           int num_shapes, TF_Status status);
public static native void TF_SetAttrTensorShapeProtoList(TF_OperationDescription desc,
                                           String attr_name,
                                           @Cast("const void*const*") @ByPtrPtr Pointer protos,
                                           @Const IntBuffer proto_lens,
                                           int num_shapes, TF_Status status);
public static native void TF_SetAttrTensorShapeProtoList(TF_OperationDescription desc,
                                           @Cast("const char*") BytePointer attr_name,
                                           @Cast("const void*const*") @ByPtrPtr Pointer protos,
                                           @Const int[] proto_lens,
                                           int num_shapes, TF_Status status);
public static native void TF_SetAttrTensorShapeProtoList(TF_OperationDescription desc,
                                           String attr_name,
                                           @Cast("const void*const*") @ByPtrPtr Pointer protos,
                                           @Const IntPointer proto_lens,
                                           int num_shapes, TF_Status status);
public static native void TF_SetAttrTensorShapeProtoList(TF_OperationDescription desc,
                                           @Cast("const char*") BytePointer attr_name,
                                           @Cast("const void*const*") @ByPtrPtr Pointer protos,
                                           @Const IntBuffer proto_lens,
                                           int num_shapes, TF_Status status);
public static native void TF_SetAttrTensorShapeProtoList(TF_OperationDescription desc,
                                           String attr_name,
                                           @Cast("const void*const*") @ByPtrPtr Pointer protos,
                                           @Const int[] proto_lens,
                                           int num_shapes, TF_Status status);

// This functions takes ownership of *value (the
// implementation will eventually call TF_DeleteTensor).
public static native void TF_SetAttrTensor(TF_OperationDescription desc,
                             @Cast("const char*") BytePointer attr_name, TF_Tensor value,
                             TF_Status status);
public static native void TF_SetAttrTensor(TF_OperationDescription desc,
                             String attr_name, TF_Tensor value,
                             TF_Status status);
// This functions takes ownership of values[0]..values[num_values-1] (the
// implementation will eventually call TF_DeleteTensor on each).
public static native void TF_SetAttrTensorList(TF_OperationDescription desc,
                                 @Cast("const char*") BytePointer attr_name,
                                 @Cast("TF_Tensor*const*") PointerPointer values, int num_values,
                                 TF_Status status);
public static native void TF_SetAttrTensorList(TF_OperationDescription desc,
                                 @Cast("const char*") BytePointer attr_name,
                                 @ByPtrPtr TF_Tensor values, int num_values,
                                 TF_Status status);
public static native void TF_SetAttrTensorList(TF_OperationDescription desc,
                                 String attr_name,
                                 @ByPtrPtr TF_Tensor values, int num_values,
                                 TF_Status status);

// `proto` should point to a sequence of bytes of length `proto_len`
// representing a binary serialization of an AttrValue protocol
// buffer.
public static native void TF_SetAttrValueProto(TF_OperationDescription desc,
                                 @Cast("const char*") BytePointer attr_name, @Const Pointer proto,
                                 @Cast("size_t") long proto_len, TF_Status status);
public static native void TF_SetAttrValueProto(TF_OperationDescription desc,
                                 String attr_name, @Const Pointer proto,
                                 @Cast("size_t") long proto_len, TF_Status status);

// If this function succeeds:
//   * *status is set to an OK value,
//   * a TF_Operation is added to the graph,
//   * a non-null value pointing to the added operation is returned --
//     this value is valid until the underlying graph is deleted.
// Otherwise:
//   * *status is set to a non-OK value,
//   * the graph is not modified,
//   * a null value is returned.
// In either case, it deletes `desc`.
public static native TF_Operation TF_FinishOperation(TF_OperationDescription desc,
                                        TF_Status status);

// TF_Operation functions.  Operations are immutable once created, so
// these are all query functions.

public static native @Cast("const char*") BytePointer TF_OperationName(TF_Operation oper);
public static native @Cast("const char*") BytePointer TF_OperationOpType(TF_Operation oper);
public static native @Cast("const char*") BytePointer TF_OperationDevice(TF_Operation oper);

public static native int TF_OperationNumOutputs(TF_Operation oper);
public static native @Cast("TF_DataType") int TF_OperationOutputType(@ByVal TF_Port oper_out);
public static native int TF_OperationOutputListLength(TF_Operation oper,
                                        @Cast("const char*") BytePointer arg_name,
                                        TF_Status status);
public static native int TF_OperationOutputListLength(TF_Operation oper,
                                        String arg_name,
                                        TF_Status status);

public static native int TF_OperationNumInputs(TF_Operation oper);
public static native @Cast("TF_DataType") int TF_OperationInputType(@ByVal TF_Port oper_in);
public static native int TF_OperationInputListLength(TF_Operation oper, @Cast("const char*") BytePointer arg_name,
                                       TF_Status status);
public static native int TF_OperationInputListLength(TF_Operation oper, String arg_name,
                                       TF_Status status);

// In this code:
//   TF_Port producer = TF_OperationInput(consumer);
// There is an edge from producer.oper's output (given by
// producer.index) to consumer.oper's input (given by consumer.index).
public static native @ByVal TF_Port TF_OperationInput(@ByVal TF_Port oper_in);

// Get the number of current consumers of a specific output of an
// operation.  Note that this number can change when new operations
// are added to the graph.
public static native int TF_OperationOutputNumConsumers(@ByVal TF_Port oper_out);

// Get list of all current consumers of a specific output of an
// operation.  `consumers` must point to an array of length at least
// `max_consumers` (ideally set to
// TF_OperationOutputNumConsumers(oper_out)).  Beware that a concurrent
// modification of the graph can increase the number of consumers of
// an operation.  Returns the number of output consumers (should match
// TF_OperationOutputNumConsumers(oper_out)).
public static native int TF_OperationOutputConsumers(@ByVal TF_Port oper_out, TF_Port consumers,
                                       int max_consumers);

// Get the number of control inputs to an operation.
public static native int TF_OperationNumControlInputs(TF_Operation oper);

// Get list of all control inputs to an operation.  `control_inputs` must
// point to an array of length `max_control_inputs` (ideally set to
// TF_OperationNumControlInputs(oper)).  Returns the number of control
// inputs (should match TF_OperationNumControlInputs(oper)).
public static native int TF_OperationGetControlInputs(TF_Operation oper,
                                        @Cast("TF_Operation**") PointerPointer control_inputs,
                                        int max_control_inputs);
public static native int TF_OperationGetControlInputs(TF_Operation oper,
                                        @ByPtrPtr TF_Operation control_inputs,
                                        int max_control_inputs);

// Get the number of operations that have `*oper` as a control input.
// Note that this number can change when new operations are added to
// the graph.
public static native int TF_OperationNumControlOutputs(TF_Operation oper);

// Get the list of operations that have `*oper` as a control input.
// `control_outputs` must point to an array of length at least
// `max_control_outputs` (ideally set to
// TF_OperationNumControlOutputs(oper)). Beware that a concurrent
// modification of the graph can increase the number of control
// outputs.  Returns the number of control outputs (should match
// TF_OperationNumControlOutputs(oper)).
public static native int TF_OperationGetControlOutputs(TF_Operation oper,
                                         @Cast("TF_Operation**") PointerPointer control_outputs,
                                         int max_control_outputs);
public static native int TF_OperationGetControlOutputs(TF_Operation oper,
                                         @ByPtrPtr TF_Operation control_outputs,
                                         int max_control_outputs);

// TF_Attr_Type describes the type of the value of an attribute on an operation.
/** enum TF_Attr_Type */
public static final int
  TF_ATTR_STRING = 0,
  TF_ATTR_INT = 1,
  TF_ATTR_FLOAT = 2,
  TF_ATTR_BOOL = 3,
  TF_ATTR_TYPE = 4,
  TF_ATTR_SHAPE = 5,
  TF_ATTR_TENSOR = 6,
  TF_ATTR_PLACEHOLDER = 7,
  TF_ATTR_FUNC = 8;

// TF_Attr_Metadata describes the value of an attribute on an operation.
public static class TF_Attr_Metadata extends Pointer {
    static { Loader.load(); }
    /** Default native constructor. */
    public TF_Attr_Metadata() { super((Pointer)null); allocate(); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public TF_Attr_Metadata(long size) { super((Pointer)null); allocateArray(size); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TF_Attr_Metadata(Pointer p) { super(p); }
    private native void allocate();
    private native void allocateArray(long size);
    @Override public TF_Attr_Metadata position(long position) {
        return (TF_Attr_Metadata)super.position(position);
    }

  // A boolean: 1 if the attribute value is a list, 0 otherwise.
  public native @Cast("unsigned char") byte is_list(); public native TF_Attr_Metadata is_list(byte is_list);

  // Length of the list if is_list is true. Undefined otherwise.
  public native @Cast("int64_t") long list_size(); public native TF_Attr_Metadata list_size(long list_size);

  // Type of elements of the list if is_list != 0.
  // Type of the single value stored in the attribute if is_list == 0.
  public native @Cast("TF_Attr_Type") int type(); public native TF_Attr_Metadata type(int type);

  // Total size the attribute value.
  // The units of total_size depend on is_list and type.
  // (1) If type == TF_ATTR_STRING and is_list == 0
  //     then total_size is the byte size of the string
  //     valued attribute.
  // (2) If type == TF_ATTR_STRING and is_list == 1
  //     then total_size is the cumulative byte size
  //     of all the strings in the list.
  // (3) If type == TF_ATTR_SHAPE and is_list == 0
  //     then total_size is the number of dimensions
  //     of the shape valued attribute, or -1
  //     if its rank is unknown.
  // (4) If type == TF_ATTR_SHAPE and is_list == 1
  //     then total_size is the cumulative number
  //     of dimensions of all shapes in the list.
  // (5) Otherwise, total_size is undefined.
  public native @Cast("int64_t") long total_size(); public native TF_Attr_Metadata total_size(long total_size);
}

// Returns metadata about the value of the attribute `attr_name` of `oper`.
public static native @ByVal TF_Attr_Metadata TF_OperationGetAttrMetadata(TF_Operation oper,
                                             @Cast("const char*") BytePointer attr_name,
                                             TF_Status status);
public static native @ByVal TF_Attr_Metadata TF_OperationGetAttrMetadata(TF_Operation oper,
                                             String attr_name,
                                             TF_Status status);

// Fills in `value` with the value of the attribute `attr_name`.  `value` must
// point to an array of length at least `max_length` (ideally set to
// TF_Attr_Metadata.total_size from TF_OperationGetAttrMetadata(oper,
// attr_name)).
public static native void TF_OperationGetAttrString(TF_Operation oper, @Cast("const char*") BytePointer attr_name,
                                      Pointer value, int max_length,
                                      TF_Status status);
public static native void TF_OperationGetAttrString(TF_Operation oper, String attr_name,
                                      Pointer value, int max_length,
                                      TF_Status status);

// Get the list of strings in the value of the attribute `attr_name`.  Fills in
// `values` and `lengths`, both of which must point to an array of length at
// least `max_values`.
//
// The elements of values will point to addresses in `storage` which must be at
// least `storage_size` bytes large.  Ideally, max_values would be set to
// TF_Attr_Metadata.list_size and `storage` would be at least
// TF_Attr_Metadata.total_size, obtained from TF_OperationGetAttrMetadata(oper,
// attr_name).
//
// Fails if storage_size is too small to hold the requested number of strings.
public static native void TF_OperationGetAttrStringList(TF_Operation oper,
                                          @Cast("const char*") BytePointer attr_name, @Cast("void**") PointerPointer values,
                                          IntPointer lengths, int max_values,
                                          Pointer storage, @Cast("size_t") long storage_size,
                                          TF_Status status);
public static native void TF_OperationGetAttrStringList(TF_Operation oper,
                                          @Cast("const char*") BytePointer attr_name, @Cast("void**") @ByPtrPtr Pointer values,
                                          IntPointer lengths, int max_values,
                                          Pointer storage, @Cast("size_t") long storage_size,
                                          TF_Status status);
public static native void TF_OperationGetAttrStringList(TF_Operation oper,
                                          String attr_name, @Cast("void**") @ByPtrPtr Pointer values,
                                          IntBuffer lengths, int max_values,
                                          Pointer storage, @Cast("size_t") long storage_size,
                                          TF_Status status);
public static native void TF_OperationGetAttrStringList(TF_Operation oper,
                                          @Cast("const char*") BytePointer attr_name, @Cast("void**") @ByPtrPtr Pointer values,
                                          int[] lengths, int max_values,
                                          Pointer storage, @Cast("size_t") long storage_size,
                                          TF_Status status);
public static native void TF_OperationGetAttrStringList(TF_Operation oper,
                                          String attr_name, @Cast("void**") @ByPtrPtr Pointer values,
                                          IntPointer lengths, int max_values,
                                          Pointer storage, @Cast("size_t") long storage_size,
                                          TF_Status status);
public static native void TF_OperationGetAttrStringList(TF_Operation oper,
                                          @Cast("const char*") BytePointer attr_name, @Cast("void**") @ByPtrPtr Pointer values,
                                          IntBuffer lengths, int max_values,
                                          Pointer storage, @Cast("size_t") long storage_size,
                                          TF_Status status);
public static native void TF_OperationGetAttrStringList(TF_Operation oper,
                                          String attr_name, @Cast("void**") @ByPtrPtr Pointer values,
                                          int[] lengths, int max_values,
                                          Pointer storage, @Cast("size_t") long storage_size,
                                          TF_Status status);

public static native void TF_OperationGetAttrInt(TF_Operation oper, @Cast("const char*") BytePointer attr_name,
                                   @Cast("int64_t*") LongPointer value, TF_Status status);
public static native void TF_OperationGetAttrInt(TF_Operation oper, String attr_name,
                                   @Cast("int64_t*") LongBuffer value, TF_Status status);
public static native void TF_OperationGetAttrInt(TF_Operation oper, @Cast("const char*") BytePointer attr_name,
                                   @Cast("int64_t*") long[] value, TF_Status status);
public static native void TF_OperationGetAttrInt(TF_Operation oper, String attr_name,
                                   @Cast("int64_t*") LongPointer value, TF_Status status);
public static native void TF_OperationGetAttrInt(TF_Operation oper, @Cast("const char*") BytePointer attr_name,
                                   @Cast("int64_t*") LongBuffer value, TF_Status status);
public static native void TF_OperationGetAttrInt(TF_Operation oper, String attr_name,
                                   @Cast("int64_t*") long[] value, TF_Status status);

// Fills in `values` with the value of the attribute `attr_name` of `oper`.
// `values` must point to an array of length at least `max_values` (ideally set
// TF_Attr_Metadata.list_size from TF_OperationGetAttrMetadata(oper,
// attr_name)).
public static native void TF_OperationGetAttrIntList(TF_Operation oper,
                                       @Cast("const char*") BytePointer attr_name, @Cast("int64_t*") LongPointer values,
                                       int max_values, TF_Status status);
public static native void TF_OperationGetAttrIntList(TF_Operation oper,
                                       String attr_name, @Cast("int64_t*") LongBuffer values,
                                       int max_values, TF_Status status);
public static native void TF_OperationGetAttrIntList(TF_Operation oper,
                                       @Cast("const char*") BytePointer attr_name, @Cast("int64_t*") long[] values,
                                       int max_values, TF_Status status);
public static native void TF_OperationGetAttrIntList(TF_Operation oper,
                                       String attr_name, @Cast("int64_t*") LongPointer values,
                                       int max_values, TF_Status status);
public static native void TF_OperationGetAttrIntList(TF_Operation oper,
                                       @Cast("const char*") BytePointer attr_name, @Cast("int64_t*") LongBuffer values,
                                       int max_values, TF_Status status);
public static native void TF_OperationGetAttrIntList(TF_Operation oper,
                                       String attr_name, @Cast("int64_t*") long[] values,
                                       int max_values, TF_Status status);

public static native void TF_OperationGetAttrFloat(TF_Operation oper, @Cast("const char*") BytePointer attr_name,
                                     FloatPointer value, TF_Status status);
public static native void TF_OperationGetAttrFloat(TF_Operation oper, String attr_name,
                                     FloatBuffer value, TF_Status status);
public static native void TF_OperationGetAttrFloat(TF_Operation oper, @Cast("const char*") BytePointer attr_name,
                                     float[] value, TF_Status status);
public static native void TF_OperationGetAttrFloat(TF_Operation oper, String attr_name,
                                     FloatPointer value, TF_Status status);
public static native void TF_OperationGetAttrFloat(TF_Operation oper, @Cast("const char*") BytePointer attr_name,
                                     FloatBuffer value, TF_Status status);
public static native void TF_OperationGetAttrFloat(TF_Operation oper, String attr_name,
                                     float[] value, TF_Status status);

// Fills in `values` with the value of the attribute `attr_name` of `oper`.
// `values` must point to an array of length at least `max_values` (ideally set
// to TF_Attr_Metadata.list_size from TF_OperationGetAttrMetadata(oper,
// attr_name)).
public static native void TF_OperationGetAttrFloatList(TF_Operation oper,
                                         @Cast("const char*") BytePointer attr_name, FloatPointer values,
                                         int max_values, TF_Status status);
public static native void TF_OperationGetAttrFloatList(TF_Operation oper,
                                         String attr_name, FloatBuffer values,
                                         int max_values, TF_Status status);
public static native void TF_OperationGetAttrFloatList(TF_Operation oper,
                                         @Cast("const char*") BytePointer attr_name, float[] values,
                                         int max_values, TF_Status status);
public static native void TF_OperationGetAttrFloatList(TF_Operation oper,
                                         String attr_name, FloatPointer values,
                                         int max_values, TF_Status status);
public static native void TF_OperationGetAttrFloatList(TF_Operation oper,
                                         @Cast("const char*") BytePointer attr_name, FloatBuffer values,
                                         int max_values, TF_Status status);
public static native void TF_OperationGetAttrFloatList(TF_Operation oper,
                                         String attr_name, float[] values,
                                         int max_values, TF_Status status);

public static native void TF_OperationGetAttrBool(TF_Operation oper, @Cast("const char*") BytePointer attr_name,
                                    @Cast("unsigned char*") BytePointer value, TF_Status status);
public static native void TF_OperationGetAttrBool(TF_Operation oper, String attr_name,
                                    @Cast("unsigned char*") ByteBuffer value, TF_Status status);
public static native void TF_OperationGetAttrBool(TF_Operation oper, @Cast("const char*") BytePointer attr_name,
                                    @Cast("unsigned char*") byte[] value, TF_Status status);
public static native void TF_OperationGetAttrBool(TF_Operation oper, String attr_name,
                                    @Cast("unsigned char*") BytePointer value, TF_Status status);
public static native void TF_OperationGetAttrBool(TF_Operation oper, @Cast("const char*") BytePointer attr_name,
                                    @Cast("unsigned char*") ByteBuffer value, TF_Status status);
public static native void TF_OperationGetAttrBool(TF_Operation oper, String attr_name,
                                    @Cast("unsigned char*") byte[] value, TF_Status status);

// Fills in `values` with the value of the attribute `attr_name` of `oper`.
// `values` must point to an array of length at least `max_values` (ideally set
// to TF_Attr_Metadata.list_size from TF_OperationGetAttrMetadata(oper,
// attr_name)).
public static native void TF_OperationGetAttrBoolList(TF_Operation oper,
                                        @Cast("const char*") BytePointer attr_name,
                                        @Cast("unsigned char*") BytePointer values, int max_values,
                                        TF_Status status);
public static native void TF_OperationGetAttrBoolList(TF_Operation oper,
                                        String attr_name,
                                        @Cast("unsigned char*") ByteBuffer values, int max_values,
                                        TF_Status status);
public static native void TF_OperationGetAttrBoolList(TF_Operation oper,
                                        @Cast("const char*") BytePointer attr_name,
                                        @Cast("unsigned char*") byte[] values, int max_values,
                                        TF_Status status);
public static native void TF_OperationGetAttrBoolList(TF_Operation oper,
                                        String attr_name,
                                        @Cast("unsigned char*") BytePointer values, int max_values,
                                        TF_Status status);
public static native void TF_OperationGetAttrBoolList(TF_Operation oper,
                                        @Cast("const char*") BytePointer attr_name,
                                        @Cast("unsigned char*") ByteBuffer values, int max_values,
                                        TF_Status status);
public static native void TF_OperationGetAttrBoolList(TF_Operation oper,
                                        String attr_name,
                                        @Cast("unsigned char*") byte[] values, int max_values,
                                        TF_Status status);

public static native void TF_OperationGetAttrType(TF_Operation oper, @Cast("const char*") BytePointer attr_name,
                                    @Cast("TF_DataType*") IntPointer value, TF_Status status);
public static native void TF_OperationGetAttrType(TF_Operation oper, String attr_name,
                                    @Cast("TF_DataType*") IntBuffer value, TF_Status status);
public static native void TF_OperationGetAttrType(TF_Operation oper, @Cast("const char*") BytePointer attr_name,
                                    @Cast("TF_DataType*") int[] value, TF_Status status);
public static native void TF_OperationGetAttrType(TF_Operation oper, String attr_name,
                                    @Cast("TF_DataType*") IntPointer value, TF_Status status);
public static native void TF_OperationGetAttrType(TF_Operation oper, @Cast("const char*") BytePointer attr_name,
                                    @Cast("TF_DataType*") IntBuffer value, TF_Status status);
public static native void TF_OperationGetAttrType(TF_Operation oper, String attr_name,
                                    @Cast("TF_DataType*") int[] value, TF_Status status);

// Fills in `values` with the value of the attribute `attr_name` of `oper`.
// `values` must point to an array of length at least `max_values` (ideally set
// to TF_Attr_Metadata.list_size from TF_OperationGetAttrMetadata(oper,
// attr_name)).
public static native void TF_OperationGetAttrTypeList(TF_Operation oper,
                                        @Cast("const char*") BytePointer attr_name,
                                        @Cast("TF_DataType*") IntPointer values, int max_values,
                                        TF_Status status);
public static native void TF_OperationGetAttrTypeList(TF_Operation oper,
                                        String attr_name,
                                        @Cast("TF_DataType*") IntBuffer values, int max_values,
                                        TF_Status status);
public static native void TF_OperationGetAttrTypeList(TF_Operation oper,
                                        @Cast("const char*") BytePointer attr_name,
                                        @Cast("TF_DataType*") int[] values, int max_values,
                                        TF_Status status);
public static native void TF_OperationGetAttrTypeList(TF_Operation oper,
                                        String attr_name,
                                        @Cast("TF_DataType*") IntPointer values, int max_values,
                                        TF_Status status);
public static native void TF_OperationGetAttrTypeList(TF_Operation oper,
                                        @Cast("const char*") BytePointer attr_name,
                                        @Cast("TF_DataType*") IntBuffer values, int max_values,
                                        TF_Status status);
public static native void TF_OperationGetAttrTypeList(TF_Operation oper,
                                        String attr_name,
                                        @Cast("TF_DataType*") int[] values, int max_values,
                                        TF_Status status);

// Fills in `value` with the value of the attribute `attr_name` of `oper`.
// `values` must point to an array of length at least `num_dims` (ideally set to
// TF_Attr_Meta.size from TF_OperationGetAttrMetadata(oper, attr_name)).
public static native void TF_OperationGetAttrShape(TF_Operation oper, @Cast("const char*") BytePointer attr_name,
                                     @Cast("int64_t*") LongPointer value, int num_dims,
                                     TF_Status status);
public static native void TF_OperationGetAttrShape(TF_Operation oper, String attr_name,
                                     @Cast("int64_t*") LongBuffer value, int num_dims,
                                     TF_Status status);
public static native void TF_OperationGetAttrShape(TF_Operation oper, @Cast("const char*") BytePointer attr_name,
                                     @Cast("int64_t*") long[] value, int num_dims,
                                     TF_Status status);
public static native void TF_OperationGetAttrShape(TF_Operation oper, String attr_name,
                                     @Cast("int64_t*") LongPointer value, int num_dims,
                                     TF_Status status);
public static native void TF_OperationGetAttrShape(TF_Operation oper, @Cast("const char*") BytePointer attr_name,
                                     @Cast("int64_t*") LongBuffer value, int num_dims,
                                     TF_Status status);
public static native void TF_OperationGetAttrShape(TF_Operation oper, String attr_name,
                                     @Cast("int64_t*") long[] value, int num_dims,
                                     TF_Status status);

// Fills in `dims` with the list of shapes in the attribute `attr_name` of
// `oper` and `num_dims` with the corresponding number of dimensions. On return,
// for every i where `num_dims[i]` > 0, `dims[i]` will be an array of
// `num_dims[i]` elements. A value of -1 for `num_dims[i]` indicates that the
// i-th shape in the list is unknown.
//
// The elements of `dims` will point to addresses in `storage` which must be
// large enough to hold at least `storage_size` int64_ts.  Ideally, `num_shapes`
// would be set to TF_Attr_Metadata.list_size and `storage_size` would be set to
// TF_Attr_Metadata.total_size from TF_OperationGetAttrMetadata(oper,
// attr_name).
//
// Fails if storage_size is insufficient to hold the requested shapes.
public static native void TF_OperationGetAttrShapeList(TF_Operation oper,
                                         @Cast("const char*") BytePointer attr_name, @Cast("int64_t**") PointerPointer dims,
                                         IntPointer num_dims, int num_shapes,
                                         @Cast("int64_t*") LongPointer storage, int storage_size,
                                         TF_Status status);
public static native void TF_OperationGetAttrShapeList(TF_Operation oper,
                                         @Cast("const char*") BytePointer attr_name, @Cast("int64_t**") @ByPtrPtr LongPointer dims,
                                         IntPointer num_dims, int num_shapes,
                                         @Cast("int64_t*") LongPointer storage, int storage_size,
                                         TF_Status status);
public static native void TF_OperationGetAttrShapeList(TF_Operation oper,
                                         String attr_name, @Cast("int64_t**") @ByPtrPtr LongBuffer dims,
                                         IntBuffer num_dims, int num_shapes,
                                         @Cast("int64_t*") LongBuffer storage, int storage_size,
                                         TF_Status status);
public static native void TF_OperationGetAttrShapeList(TF_Operation oper,
                                         @Cast("const char*") BytePointer attr_name, @Cast("int64_t**") @ByPtrPtr long[] dims,
                                         int[] num_dims, int num_shapes,
                                         @Cast("int64_t*") long[] storage, int storage_size,
                                         TF_Status status);
public static native void TF_OperationGetAttrShapeList(TF_Operation oper,
                                         String attr_name, @Cast("int64_t**") @ByPtrPtr LongPointer dims,
                                         IntPointer num_dims, int num_shapes,
                                         @Cast("int64_t*") LongPointer storage, int storage_size,
                                         TF_Status status);
public static native void TF_OperationGetAttrShapeList(TF_Operation oper,
                                         @Cast("const char*") BytePointer attr_name, @Cast("int64_t**") @ByPtrPtr LongBuffer dims,
                                         IntBuffer num_dims, int num_shapes,
                                         @Cast("int64_t*") LongBuffer storage, int storage_size,
                                         TF_Status status);
public static native void TF_OperationGetAttrShapeList(TF_Operation oper,
                                         String attr_name, @Cast("int64_t**") @ByPtrPtr long[] dims,
                                         int[] num_dims, int num_shapes,
                                         @Cast("int64_t*") long[] storage, int storage_size,
                                         TF_Status status);

// Sets `value` to the binary-serialized TensorShapeProto of the value of
// `attr_name` attribute of `oper`'.
public static native void TF_OperationGetAttrTensorShapeProto(TF_Operation oper,
                                                @Cast("const char*") BytePointer attr_name,
                                                TF_Buffer value,
                                                TF_Status status);
public static native void TF_OperationGetAttrTensorShapeProto(TF_Operation oper,
                                                String attr_name,
                                                TF_Buffer value,
                                                TF_Status status);

// Fills in `values` with binary-serialized TensorShapeProto values of the
// attribute `attr_name` of `oper`. `values` must point to an array of length at
// least `num_values` (ideally set to TF_Attr_Metadata.list_size from
// TF_OperationGetAttrMetadata(oper, attr_name)).
public static native void TF_OperationGetAttrTensorShapeProtoList(TF_Operation oper,
                                                    @Cast("const char*") BytePointer attr_name,
                                                    @Cast("TF_Buffer**") PointerPointer values,
                                                    int max_values,
                                                    TF_Status status);
public static native void TF_OperationGetAttrTensorShapeProtoList(TF_Operation oper,
                                                    @Cast("const char*") BytePointer attr_name,
                                                    @ByPtrPtr TF_Buffer values,
                                                    int max_values,
                                                    TF_Status status);
public static native void TF_OperationGetAttrTensorShapeProtoList(TF_Operation oper,
                                                    String attr_name,
                                                    @ByPtrPtr TF_Buffer values,
                                                    int max_values,
                                                    TF_Status status);

// Gets the TF_Tensor valued attribute of `attr_name` of `oper`.
//
// Allocates a new TF_Tensor which the caller is expected to take
// ownership of (and can deallocate using TF_DeleteTensor).
public static native void TF_OperationGetAttrTensor(TF_Operation oper, @Cast("const char*") BytePointer attr_name,
                                      @Cast("TF_Tensor**") PointerPointer value, TF_Status status);
public static native void TF_OperationGetAttrTensor(TF_Operation oper, @Cast("const char*") BytePointer attr_name,
                                      @ByPtrPtr TF_Tensor value, TF_Status status);
public static native void TF_OperationGetAttrTensor(TF_Operation oper, String attr_name,
                                      @ByPtrPtr TF_Tensor value, TF_Status status);

// Fills in `values` with the TF_Tensor values of the attribute `attr_name` of
// `oper`. `values` must point to an array of TF_Tensor* of length at least
// `max_values` (ideally set to TF_Attr_Metadata.list_size from
// TF_OperationGetAttrMetadata(oper, attr_name)).
//
// The caller takes ownership of all the non-null TF_Tensor* entries in `values`
// (which can be deleted using TF_DeleteTensor(values[i])).
public static native void TF_OperationGetAttrTensorList(TF_Operation oper,
                                          @Cast("const char*") BytePointer attr_name,
                                          @Cast("TF_Tensor**") PointerPointer values, int max_values,
                                          TF_Status status);
public static native void TF_OperationGetAttrTensorList(TF_Operation oper,
                                          @Cast("const char*") BytePointer attr_name,
                                          @ByPtrPtr TF_Tensor values, int max_values,
                                          TF_Status status);
public static native void TF_OperationGetAttrTensorList(TF_Operation oper,
                                          String attr_name,
                                          @ByPtrPtr TF_Tensor values, int max_values,
                                          TF_Status status);

// Sets `output_attr_value` to the binary-serialized AttrValue proto
// representation of the value of the `attr_name` attr of `oper`.
public static native void TF_OperationGetAttrValueProto(TF_Operation oper,
                                          @Cast("const char*") BytePointer attr_name,
                                          TF_Buffer output_attr_value,
                                          TF_Status status);
public static native void TF_OperationGetAttrValueProto(TF_Operation oper,
                                          String attr_name,
                                          TF_Buffer output_attr_value,
                                          TF_Status status);

// Returns the operation in the graph with `oper_name`. Returns nullptr if
// no operation found.
public static native TF_Operation TF_GraphOperationByName(TF_Graph graph,
                                             @Cast("const char*") BytePointer oper_name);
public static native TF_Operation TF_GraphOperationByName(TF_Graph graph,
                                             String oper_name);

// Iterate through the operations of a graph.  To use:
// size_t pos = 0;
// TF_Operation* oper;
// while ((oper = TF_GraphNextOperation(graph, &pos)) != nullptr) {
//   DoSomethingWithOperation(oper);
// }
public static native TF_Operation TF_GraphNextOperation(TF_Graph graph, @Cast("size_t*") SizeTPointer pos);

// Write out a serialized representation of `graph` (as a GraphDef protocol
// message) to `output_graph_def`.
//
// May fail on very large graphs in the future.
public static native void TF_GraphToGraphDef(TF_Graph graph, TF_Buffer output_graph_def,
                               TF_Status status);

// TF_ImportGraphDefOptions holds options that can be passed to
// TF_GraphImportGraphDef.
@Opaque public static class TF_ImportGraphDefOptions extends Pointer {
    /** Empty constructor. Calls {@code super((Pointer)null)}. */
    public TF_ImportGraphDefOptions() { super((Pointer)null); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TF_ImportGraphDefOptions(Pointer p) { super(p); }
}

public static native TF_ImportGraphDefOptions TF_NewImportGraphDefOptions();
public static native void TF_DeleteImportGraphDefOptions(TF_ImportGraphDefOptions opts);

// Set the prefix to be prepended to the names of nodes in `graph_def` that will
// be imported into `graph`.
public static native void TF_ImportGraphDefOptionsSetPrefix(TF_ImportGraphDefOptions opts,
                                              @Cast("const char*") BytePointer prefix);
public static native void TF_ImportGraphDefOptionsSetPrefix(TF_ImportGraphDefOptions opts,
                                              String prefix);

// Import the graph serialized in `graph_def` into `graph`.
public static native void TF_GraphImportGraphDef(TF_Graph graph, @Const TF_Buffer graph_def,
                                   @Const TF_ImportGraphDefOptions options,
                                   TF_Status status);

// Note: The following function may fail on very large protos in the future.

public static native void TF_OperationToNodeDef(TF_Operation oper,
                                  TF_Buffer output_node_def,
                                  TF_Status status);

// TODO(andydavis): Function to add gradients to a graph.

// TODO(josh11b): Register OpDef, available to all operations added
// to this graph.

// The following two may both benefit from a subgraph-definition API
// that re-uses most of the graph-definition API.
// TODO(andydavis): Add functions to a graph.
// TODO(yuanbyu): Add while loop to graph.

// --------------------------------------------------------------------------
// The new session API that uses TF_Graph*.  The intent is this will
// replace the TF_ExtendGraph() API.

// TODO(josh11b): Rename this TF_Session once we delete the old API.
@Opaque public static class TF_SessionWithGraph extends Pointer {
    /** Empty constructor. Calls {@code super((Pointer)null)}. */
    public TF_SessionWithGraph() { super((Pointer)null); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TF_SessionWithGraph(Pointer p) { super(p); }
}

// Return a new execution session with the associated graph, or NULL
// on error.  *graph must be a valid graph (not deleted or nullptr).
// This function will prevent the graph from being deleted until
// TF_DeleteSessionWithGraph() is called.  Does not take ownership of opts.
// TODO(josh11b): Rename this TF_NewSession() once we delete the old API.
public static native TF_SessionWithGraph TF_NewSessionWithGraph(
    TF_Graph graph, @Const TF_SessionOptions opts, TF_Status status);

// Close a session. This contacts any other processes associated with this
// session, if applicable. This may not be called after
// TF_DeleteSessionWithGraph().
// TODO(josh11b): Rename this TF_CloseSession() once we delete the old API.
public static native void TF_CloseSessionWithGraph(TF_SessionWithGraph arg0, TF_Status status);

// Destroy a session object.  Even if error information is recorded in
// *status, this call discards all local resources associated with the
// session.  The session may not be used during or after this call
// (and the session drops its reference to the corresponding graph).
// TODO(josh11b): Rename this TF_DeleteSession() once we delete the old API.
public static native void TF_DeleteSessionWithGraph(TF_SessionWithGraph arg0, TF_Status status);

// See TF_Run() below.
public static native void TF_SessionRun(TF_SessionWithGraph session,
                          @Const TF_Buffer run_options,
                          @Const TF_Port inputs, @Cast("TF_Tensor*const*") PointerPointer input_values,
                          int ninputs,
                          @Const TF_Port outputs, @Cast("TF_Tensor**") PointerPointer output_values,
                          int noutputs,
                          @Cast("const TF_Operation*const*") PointerPointer target_opers, int ntargets,
                          TF_Buffer run_metadata,
                          TF_Status arg11);
public static native void TF_SessionRun(TF_SessionWithGraph session,
                          @Const TF_Buffer run_options,
                          @Const TF_Port inputs, @ByPtrPtr TF_Tensor input_values,
                          int ninputs,
                          @Const TF_Port outputs, @ByPtrPtr TF_Tensor output_values,
                          int noutputs,
                          @Const @ByPtrPtr TF_Operation target_opers, int ntargets,
                          TF_Buffer run_metadata,
                          TF_Status arg11);

// See TF_PRunSetup() below.
public static native void TF_SessionPRunSetup(TF_SessionWithGraph arg0,
                                @Const TF_Port inputs, int ninputs,
                                @Const TF_Port outputs, int noutputs,
                                @Cast("const TF_Operation*const*") PointerPointer target_opers,
                                int ntargets,
                                @Cast("const char**") PointerPointer handle,
                                TF_Status arg8);
public static native void TF_SessionPRunSetup(TF_SessionWithGraph arg0,
                                @Const TF_Port inputs, int ninputs,
                                @Const TF_Port outputs, int noutputs,
                                @Const @ByPtrPtr TF_Operation target_opers,
                                int ntargets,
                                @Cast("const char**") @ByPtrPtr BytePointer handle,
                                TF_Status arg8);
public static native void TF_SessionPRunSetup(TF_SessionWithGraph arg0,
                                @Const TF_Port inputs, int ninputs,
                                @Const TF_Port outputs, int noutputs,
                                @Const @ByPtrPtr TF_Operation target_opers,
                                int ntargets,
                                @Cast("const char**") @ByPtrPtr ByteBuffer handle,
                                TF_Status arg8);
public static native void TF_SessionPRunSetup(TF_SessionWithGraph arg0,
                                @Const TF_Port inputs, int ninputs,
                                @Const TF_Port outputs, int noutputs,
                                @Const @ByPtrPtr TF_Operation target_opers,
                                int ntargets,
                                @Cast("const char**") @ByPtrPtr byte[] handle,
                                TF_Status arg8);

// See TF_PRun() below.
public static native void TF_SessionPRun(TF_SessionWithGraph arg0, @Cast("const char*") BytePointer handle,
                           @Const TF_Port inputs,
                           @Cast("TF_Tensor*const*") PointerPointer input_values, int ninputs,
                           @Const TF_Port outputs, @Cast("TF_Tensor**") PointerPointer output_values,
                           int noutputs,
                           @Cast("const TF_Operation*const*") PointerPointer target_opers,
                           int ntargets,
                           TF_Status arg10);
public static native void TF_SessionPRun(TF_SessionWithGraph arg0, @Cast("const char*") BytePointer handle,
                           @Const TF_Port inputs,
                           @ByPtrPtr TF_Tensor input_values, int ninputs,
                           @Const TF_Port outputs, @ByPtrPtr TF_Tensor output_values,
                           int noutputs,
                           @Const @ByPtrPtr TF_Operation target_opers,
                           int ntargets,
                           TF_Status arg10);
public static native void TF_SessionPRun(TF_SessionWithGraph arg0, String handle,
                           @Const TF_Port inputs,
                           @ByPtrPtr TF_Tensor input_values, int ninputs,
                           @Const TF_Port outputs, @ByPtrPtr TF_Tensor output_values,
                           int noutputs,
                           @Const @ByPtrPtr TF_Operation target_opers,
                           int ntargets,
                           TF_Status arg10);

// --------------------------------------------------------------------------
// The deprecated session API.  Please switch to the above instead of
// TF_ExtendGraph().  TF_Session manages a single graph and execution.

@Opaque public static class TF_Session extends Pointer {
    /** Empty constructor. Calls {@code super((Pointer)null)}. */
    public TF_Session() { super((Pointer)null); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TF_Session(Pointer p) { super(p); }
}

// Return a new execution session, or NULL on error.
public static native TF_Session TF_NewSession(@Const TF_SessionOptions arg0, TF_Status status);

// Close a session.
public static native void TF_CloseSession(TF_Session arg0, TF_Status status);

// Destroy a session.  Even if error information is recorded in *status,
// this call discards all resources associated with the session.
public static native void TF_DeleteSession(TF_Session arg0, TF_Status status);

// Closes all existing sessions connected to the `target` specified in the
// `SessionOptions`, and frees shared resources in `containers` on `target'.
// If no containers are provided, all containers are cleared.
public static native void TF_Reset(@Const TF_SessionOptions opt, @Cast("const char**") PointerPointer containers,
                     int ncontainers, TF_Status status);
public static native void TF_Reset(@Const TF_SessionOptions opt, @Cast("const char**") @ByPtrPtr BytePointer containers,
                     int ncontainers, TF_Status status);
public static native void TF_Reset(@Const TF_SessionOptions opt, @Cast("const char**") @ByPtrPtr ByteBuffer containers,
                     int ncontainers, TF_Status status);
public static native void TF_Reset(@Const TF_SessionOptions opt, @Cast("const char**") @ByPtrPtr byte[] containers,
                     int ncontainers, TF_Status status);

// Treat the bytes proto[0,proto_len-1] as a serialized GraphDef and
// add the nodes in that GraphDef to the graph for the session.
public static native void TF_ExtendGraph(TF_Session arg0, @Const Pointer proto, @Cast("size_t") long proto_len,
                           TF_Status arg3);

// Run the graph associated with the session starting with the
// supplied inputs (inputs[0,ninputs-1]).  Regardless of success or
// failure, inputs[] become the property of the implementation (the
// implementation will eventually call TF_DeleteTensor on each input).
//
// Any NULL and non-NULL value combinations for (`run_options`,
// `run_metadata`) are valid.
//
//    - `run_options` may be NULL, in which case it will be ignored; or
//      non-NULL, in which case it must point to a `TF_Buffer` containing the
//      serialized representation of a `RunOptions` protocol buffer.
//    - `run_metadata` may be NULL, in which case it will be ignored; or
//      non-NULL, in which case it must point to an empty, freshly allocated
//      `TF_Buffer` that may be updated to contain the serialized representation
//      of a `RunMetadata` protocol buffer.
//
// The caller retains the ownership of `run_options` and/or `run_metadata` (when
// not NULL) and should manually call TF_DeleteBuffer on them.
//
// On success, the tensors corresponding to output_names[0,noutputs-1]
// are placed in outputs[], and these outputs[] become the property
// of the caller (the caller must eventually call TF_DeleteTensor on
// them).
//
// On failure, outputs[] contains NULLs.
public static native void TF_Run(TF_Session arg0,
                   @Const TF_Buffer run_options,
                   @Cast("const char**") PointerPointer input_names, @Cast("TF_Tensor**") PointerPointer inputs, int ninputs,
                   @Cast("const char**") PointerPointer output_names, @Cast("TF_Tensor**") PointerPointer outputs, int noutputs,
                   @Cast("const char**") PointerPointer target_oper_names, int ntargets,
                   TF_Buffer run_metadata,
                   TF_Status arg11);
public static native void TF_Run(TF_Session arg0,
                   @Const TF_Buffer run_options,
                   @Cast("const char**") @ByPtrPtr BytePointer input_names, @ByPtrPtr TF_Tensor inputs, int ninputs,
                   @Cast("const char**") @ByPtrPtr BytePointer output_names, @ByPtrPtr TF_Tensor outputs, int noutputs,
                   @Cast("const char**") @ByPtrPtr BytePointer target_oper_names, int ntargets,
                   TF_Buffer run_metadata,
                   TF_Status arg11);
public static native void TF_Run(TF_Session arg0,
                   @Const TF_Buffer run_options,
                   @Cast("const char**") @ByPtrPtr ByteBuffer input_names, @ByPtrPtr TF_Tensor inputs, int ninputs,
                   @Cast("const char**") @ByPtrPtr ByteBuffer output_names, @ByPtrPtr TF_Tensor outputs, int noutputs,
                   @Cast("const char**") @ByPtrPtr ByteBuffer target_oper_names, int ntargets,
                   TF_Buffer run_metadata,
                   TF_Status arg11);
public static native void TF_Run(TF_Session arg0,
                   @Const TF_Buffer run_options,
                   @Cast("const char**") @ByPtrPtr byte[] input_names, @ByPtrPtr TF_Tensor inputs, int ninputs,
                   @Cast("const char**") @ByPtrPtr byte[] output_names, @ByPtrPtr TF_Tensor outputs, int noutputs,
                   @Cast("const char**") @ByPtrPtr byte[] target_oper_names, int ntargets,
                   TF_Buffer run_metadata,
                   TF_Status arg11);

// Set up the graph with the intended feeds and fetches for a sequence
// of partial run calls.
//
// On success, returns a handle that is used for subsequent PRun calls.
//
// On failure, out_status contains a tensorflow::Status with an error
// message.
// NOTE: This is EXPERIMENTAL and subject to change.
public static native void TF_PRunSetup(TF_Session arg0,
                         @Cast("const char**") PointerPointer input_names, int ninputs,
                         @Cast("const char**") PointerPointer output_names, int noutputs,
                         @Cast("const char**") PointerPointer target_oper_names, int ntargets,
                         @Cast("const char**") PointerPointer handle,
                         TF_Status arg8);
public static native void TF_PRunSetup(TF_Session arg0,
                         @Cast("const char**") @ByPtrPtr BytePointer input_names, int ninputs,
                         @Cast("const char**") @ByPtrPtr BytePointer output_names, int noutputs,
                         @Cast("const char**") @ByPtrPtr BytePointer target_oper_names, int ntargets,
                         @Cast("const char**") @ByPtrPtr BytePointer handle,
                         TF_Status arg8);
public static native void TF_PRunSetup(TF_Session arg0,
                         @Cast("const char**") @ByPtrPtr ByteBuffer input_names, int ninputs,
                         @Cast("const char**") @ByPtrPtr ByteBuffer output_names, int noutputs,
                         @Cast("const char**") @ByPtrPtr ByteBuffer target_oper_names, int ntargets,
                         @Cast("const char**") @ByPtrPtr ByteBuffer handle,
                         TF_Status arg8);
public static native void TF_PRunSetup(TF_Session arg0,
                         @Cast("const char**") @ByPtrPtr byte[] input_names, int ninputs,
                         @Cast("const char**") @ByPtrPtr byte[] output_names, int noutputs,
                         @Cast("const char**") @ByPtrPtr byte[] target_oper_names, int ntargets,
                         @Cast("const char**") @ByPtrPtr byte[] handle,
                         TF_Status arg8);

// Continue to run the graph with additional feeds and fetches. The
// execution state is uniquely identified by the handle.
// NOTE: This is EXPERIMENTAL and subject to change.
public static native void TF_PRun(TF_Session arg0, @Cast("const char*") BytePointer handle,
                    @Cast("const char**") PointerPointer input_names, @Cast("TF_Tensor**") PointerPointer inputs, int ninputs,
                    @Cast("const char**") PointerPointer output_names, @Cast("TF_Tensor**") PointerPointer outputs,
                    int noutputs,
                    @Cast("const char**") PointerPointer target_oper_names, int ntargets,
                    TF_Status arg10);
public static native void TF_PRun(TF_Session arg0, @Cast("const char*") BytePointer handle,
                    @Cast("const char**") @ByPtrPtr BytePointer input_names, @ByPtrPtr TF_Tensor inputs, int ninputs,
                    @Cast("const char**") @ByPtrPtr BytePointer output_names, @ByPtrPtr TF_Tensor outputs,
                    int noutputs,
                    @Cast("const char**") @ByPtrPtr BytePointer target_oper_names, int ntargets,
                    TF_Status arg10);
public static native void TF_PRun(TF_Session arg0, String handle,
                    @Cast("const char**") @ByPtrPtr ByteBuffer input_names, @ByPtrPtr TF_Tensor inputs, int ninputs,
                    @Cast("const char**") @ByPtrPtr ByteBuffer output_names, @ByPtrPtr TF_Tensor outputs,
                    int noutputs,
                    @Cast("const char**") @ByPtrPtr ByteBuffer target_oper_names, int ntargets,
                    TF_Status arg10);
public static native void TF_PRun(TF_Session arg0, @Cast("const char*") BytePointer handle,
                    @Cast("const char**") @ByPtrPtr byte[] input_names, @ByPtrPtr TF_Tensor inputs, int ninputs,
                    @Cast("const char**") @ByPtrPtr byte[] output_names, @ByPtrPtr TF_Tensor outputs,
                    int noutputs,
                    @Cast("const char**") @ByPtrPtr byte[] target_oper_names, int ntargets,
                    TF_Status arg10);
public static native void TF_PRun(TF_Session arg0, String handle,
                    @Cast("const char**") @ByPtrPtr BytePointer input_names, @ByPtrPtr TF_Tensor inputs, int ninputs,
                    @Cast("const char**") @ByPtrPtr BytePointer output_names, @ByPtrPtr TF_Tensor outputs,
                    int noutputs,
                    @Cast("const char**") @ByPtrPtr BytePointer target_oper_names, int ntargets,
                    TF_Status arg10);
public static native void TF_PRun(TF_Session arg0, @Cast("const char*") BytePointer handle,
                    @Cast("const char**") @ByPtrPtr ByteBuffer input_names, @ByPtrPtr TF_Tensor inputs, int ninputs,
                    @Cast("const char**") @ByPtrPtr ByteBuffer output_names, @ByPtrPtr TF_Tensor outputs,
                    int noutputs,
                    @Cast("const char**") @ByPtrPtr ByteBuffer target_oper_names, int ntargets,
                    TF_Status arg10);
public static native void TF_PRun(TF_Session arg0, String handle,
                    @Cast("const char**") @ByPtrPtr byte[] input_names, @ByPtrPtr TF_Tensor inputs, int ninputs,
                    @Cast("const char**") @ByPtrPtr byte[] output_names, @ByPtrPtr TF_Tensor outputs,
                    int noutputs,
                    @Cast("const char**") @ByPtrPtr byte[] target_oper_names, int ntargets,
                    TF_Status arg10);

// --------------------------------------------------------------------------
// Load plugins containing custom ops and kernels

// TF_Library holds information about dynamically loaded TensorFlow plugins.
@Opaque public static class TF_Library extends Pointer {
    /** Empty constructor. Calls {@code super((Pointer)null)}. */
    public TF_Library() { super((Pointer)null); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TF_Library(Pointer p) { super(p); }
}

// Load the library specified by library_filename and register the ops and
// kernels present in that library.
//
// Pass "library_filename" to a platform-specific mechanism for dynamically
// loading a library. The rules for determining the exact location of the
// library are platform-specific and are not documented here.
// Expects the symbols "RegisterOps", "RegisterKernels", and "GetOpList", to be
// defined in the library.
//
// On success, place OK in status and return the newly created library handle.
// The caller owns the library handle.
//
// On failure, place an error status in status and return NULL.
public static native TF_Library TF_LoadLibrary(@Cast("const char*") BytePointer library_filename,
                                  TF_Status status);
public static native TF_Library TF_LoadLibrary(String library_filename,
                                  TF_Status status);

// Get the OpList of OpDefs defined in the library pointed by lib_handle.
//
// Returns a TF_Buffer. The memory pointed to by the result is owned by
// lib_handle. The data in the buffer will be the serialized OpList proto for
// ops defined in the library.
public static native @ByVal TF_Buffer TF_GetOpList(TF_Library lib_handle);

// Frees the memory associated with the library handle.
// Does NOT unload the library.
public static native void TF_DeleteLibraryHandle(TF_Library lib_handle);

// Get the OpList of all OpDefs defined in this address space.
// Returns a TF_Buffer, ownership of which is transferred to the caller
// (and can be freed using TF_DeleteBuffer).
//
// The data in the buffer will be the serialized OpList proto for ops registered
// in this address space.
public static native TF_Buffer TF_GetAllOpList();

// #ifdef __cplusplus /* end extern "C" */
// #endif

// #endif  // TENSORFLOW_C_C_API_H_


// Parsed from tensorflow/core/framework/op_def_builder.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// Class and associated machinery for specifying an Op's OpDef and shape
// inference function for Op registration.

// #ifndef TENSORFLOW_FRAMEWORK_OP_DEF_BUILDER_H_
// #define TENSORFLOW_FRAMEWORK_OP_DEF_BUILDER_H_

// #include <string>
// #include <vector>
// #include "tensorflow/core/framework/op_def.pb.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/platform/macros.h"


@Namespace("tensorflow") @NoOffset public static class OpRegistrationData extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public OpRegistrationData(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public OpRegistrationData(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public OpRegistrationData position(long position) {
        return (OpRegistrationData)super.position(position);
    }

  public OpRegistrationData() { super((Pointer)null); allocate(); }
  private native void allocate();
  public OpRegistrationData(@Const @ByRef OpDef def) { super((Pointer)null); allocate(def); }
  private native void allocate(@Const @ByRef OpDef def);

  public native @ByRef OpDef op_def(); public native OpRegistrationData op_def(OpDef op_def);
  @MemberSetter public native OpRegistrationData shape_inference_fn(@ByVal ShapeInferenceFn shape_inference_fn);
}

// Builder class passed to the REGISTER_OP() macro.
@Namespace("tensorflow") @NoOffset public static class OpDefBuilder extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public OpDefBuilder(Pointer p) { super(p); }

  // Constructs an OpDef with just the name field set.
  public OpDefBuilder(@StringPiece BytePointer op_name) { super((Pointer)null); allocate(op_name); }
  private native void allocate(@StringPiece BytePointer op_name);
  public OpDefBuilder(@StringPiece String op_name) { super((Pointer)null); allocate(op_name); }
  private native void allocate(@StringPiece String op_name);

  // Adds an attr to this OpDefBuilder (and returns *this). The spec has
  // format "<name>:<type>" or "<name>:<type>=<default>"
  // where <name> matches regexp [a-zA-Z][a-zA-Z0-9_]*
  // (by convention only using capital letters for attrs that can be inferred)
  // <type> can be:
  //   "string", "int", "float", "bool", "type", "shape", or "tensor"
  //   "numbertype", "realnumbertype", "quantizedtype", "{int32,int64}"
  //       (meaning "type" with a restriction on valid values)
  //   "{\"foo\", \"bar\n baz\"}", or "{'foo', 'bar\n baz'}"
  //       (meaning "string" with a restriction on valid values)
  //   "list(string)", ..., "list(tensor)", "list(numbertype)", ...
  //       (meaning lists of the above types)
  //   "int >= 2" (meaning "int" with a restriction on valid values)
  //   "list(string) >= 2", "list(int) >= 2"
  //       (meaning "list(string)" / "list(int)" with length at least 2)
  // <default>, if included, should use the Proto text format
  // of <type>.  For lists use [a, b, c] format.
  //
  // Note that any attr specifying the length of an input or output will
  // get a default minimum of 1 unless the >= # syntax is used.
  //
  // TODO(josh11b): Perhaps support restrictions and defaults as optional
  // extra arguments to Attr() instead of encoding them in the spec string.
  // TODO(josh11b): Would like to have better dtype handling for tensor attrs:
  // * Ability to say the type of an input/output matches the type of
  //   the tensor.
  // * Ability to restrict the type of the tensor like the existing
  //   restrictions for type attrs.
  // Perhaps by linking the type of the tensor to a type attr?
  public native @ByRef OpDefBuilder Attr(@StringPiece BytePointer spec);
  public native @ByRef OpDefBuilder Attr(@StringPiece String spec);

  // Adds an input or output to this OpDefBuilder (and returns *this).
  // The spec has form "<name>:<type-expr>" or "<name>:Ref(<type-expr>)"
  // where <name> matches regexp [a-z][a-z0-9_]* and <type-expr> can be:
  // * For a single tensor: <type>
  // * For a sequence of tensors with the same type: <number>*<type>
  // * For a sequence of tensors with different types: <type-list>
  // Where:
  //   <type> is either one of "float", "int32", "string", ...
  //                 or the name of an attr (see above) with type "type".
  //   <number> is the name of an attr with type "int".
  //   <type-list> is the name of an attr with type "list(type)".
  // TODO(josh11b): Indicate Ref() via an optional argument instead of
  // in the spec?
  // TODO(josh11b): SparseInput() and SparseOutput() matching the Python
  // handling?
  public native @ByRef OpDefBuilder Input(@StringPiece BytePointer spec);
  public native @ByRef OpDefBuilder Input(@StringPiece String spec);
  public native @ByRef OpDefBuilder Output(@StringPiece BytePointer spec);
  public native @ByRef OpDefBuilder Output(@StringPiece String spec);

  // Turns on the indicated boolean flag in this OpDefBuilder (and
  // returns *this).
  public native @ByRef OpDefBuilder SetIsCommutative();
  public native @ByRef OpDefBuilder SetIsAggregate();
  public native @ByRef OpDefBuilder SetIsStateful();
  public native @ByRef OpDefBuilder SetAllowsUninitializedInput();

  // Deprecate the op at a certain GraphDef version.
  public native @ByRef OpDefBuilder Deprecated(int version, @StringPiece BytePointer explanation);
  public native @ByRef OpDefBuilder Deprecated(int version, @StringPiece String explanation);

  // Adds docs to this OpDefBuilder (and returns *this).
  // Docs have the format:
  //   <1-line summary>
  //   <rest of the description>
  //   <name>: <description of name>
  //   <name>: <description of name>
  //     <if long, indent the description on subsequent lines>
  // Where <name> is the name of an attr, input, or output.  Please
  // wrap docs at 72 columns so that it may be indented in the
  // generated output.  For tensor inputs or outputs (not attrs), you
  // may start the description with an "=" (like name:= <description>)
  // to suppress the automatically-generated type documentation in
  // generated output.
// #ifndef TF_LEAN_BINARY
  public native @ByRef OpDefBuilder Doc(@StringPiece BytePointer text);
  public native @ByRef OpDefBuilder Doc(@StringPiece String text);
// #else
// #endif

  public static class Fn_InferenceContext extends FunctionPointer {
      static { Loader.load(); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public    Fn_InferenceContext(Pointer p) { super(p); }
      protected Fn_InferenceContext() { allocate(); }
      private native void allocate();
      public native @ByVal Status call(InferenceContext arg0);
  }
  public native @ByRef OpDefBuilder SetShapeFn(Fn_InferenceContext fn);

  // Sets op_reg_data->op_def to the requested OpDef and
  // op_reg_data->shape_inference_fn to the requested shape inference function,
  // or returns an error.
  // Must be called after all of the above methods.
  //
  // Note that OpDefBuilder only reports parsing errors.  You should also
  // call ValidateOpDef() to detect other problems.
  public native @ByVal Status Finalize(OpRegistrationData op_reg_data);
}

  // namespace tensorflow

// #endif  // TENSORFLOW_FRAMEWORK_OP_DEF_BUILDER_H_


// Parsed from tensorflow/core/framework/op_def_util.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// TODO(josh11b): Probably not needed for OpKernel authors, so doesn't
// need to be as publicly accessible as other files in framework/.

// #ifndef TENSORFLOW_FRAMEWORK_OP_DEF_UTIL_H_
// #define TENSORFLOW_FRAMEWORK_OP_DEF_UTIL_H_

// #include <string>
// #include "tensorflow/core/framework/op_def.pb.h"
// #include "tensorflow/core/lib/core/status.h"

// Performs a consistency check across the fields of the op_def.
@Namespace("tensorflow") public static native @ByVal Status ValidateOpDef(@Const @ByRef OpDef op_def);

// Check if an op is deprecated at the given GraphDef version.  If the op is
// deprecated at a future version, a warning will be logged.
@Namespace("tensorflow") public static native @ByVal Status CheckOpDeprecation(@Const @ByRef OpDef op_def, int graph_def_version);

// Validates that attr_value satisfies the type and constraints from attr.
// REQUIRES: attr has already been validated.
@Namespace("tensorflow") public static native @ByVal Status ValidateAttrValue(@Const @ByRef AttrValue attr_value,
                         @Cast("const tensorflow::OpDef::AttrDef*") @ByRef OpDef_AttrDef attr);

// The following search through op_def for an attr with the indicated name.
// Returns nullptr if no such attr is found.
@Namespace("tensorflow") public static native @Cast("const tensorflow::OpDef::AttrDef*") OpDef_AttrDef FindAttr(@StringPiece BytePointer name, @Const @ByRef OpDef op_def);
@Namespace("tensorflow") public static native @Cast("const tensorflow::OpDef::AttrDef*") OpDef_AttrDef FindAttr(@StringPiece String name, @Const @ByRef OpDef op_def);
@Namespace("tensorflow") public static native @Cast("tensorflow::OpDef::AttrDef*") OpDef_AttrDef FindAttrMutable(@StringPiece BytePointer name, OpDef op_def);
@Namespace("tensorflow") public static native @Cast("tensorflow::OpDef::AttrDef*") OpDef_AttrDef FindAttrMutable(@StringPiece String name, OpDef op_def);

// Produce a human-readable version of an op_def that is more concise
// than a text-format proto.  Excludes descriptions.
@Namespace("tensorflow") public static native @StdString BytePointer SummarizeOpDef(@Const @ByRef OpDef op_def);

// Returns an error if new_op is not backwards-compatible with (more
// accepting than) old_op.
// REQUIRES: old_op and new_op must pass validation.
@Namespace("tensorflow") public static native @ByVal Status OpDefCompatible(@Const @ByRef OpDef old_op, @Const @ByRef OpDef new_op);

// Returns an error if any attr in penultimate_op that is not in old_op
// has a different default value in new_op.  In general it is not safe
// to change the default for an attr that has been added to an op.
@Namespace("tensorflow") public static native @ByVal Status OpDefAddedDefaultsUnchanged(@Const @ByRef OpDef old_op,
                                   @Const @ByRef OpDef penultimate_op,
                                   @Const @ByRef OpDef new_op);

// Remove all docs from *op_def / *op_list.
@Namespace("tensorflow") public static native void RemoveDescriptionsFromOpDef(OpDef op_def);
@Namespace("tensorflow") public static native void RemoveDescriptionsFromOpList(OpList op_list);

// Remove docs from *op_def but leave explanations of deprecations.
@Namespace("tensorflow") public static native void RemoveNonDeprecationDescriptionsFromOpDef(OpDef op_def);

  // namespace tensorflow

// #endif  // TENSORFLOW_FRAMEWORK_OP_DEF_UTIL_H_


// Parsed from tensorflow/core/framework/op.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_FRAMEWORK_OP_H_
// #define TENSORFLOW_FRAMEWORK_OP_H_

// #include <functional>
// #include <unordered_map>

// #include <vector>
// #include "tensorflow/core/framework/op_def.pb.h"
// #include "tensorflow/core/framework/op_def_builder.h"
// #include "tensorflow/core/framework/op_def_util.h"
// #include "tensorflow/core/framework/selective_registration.h"
// #include "tensorflow/core/lib/core/errors.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/strings/str_util.h"
// #include "tensorflow/core/lib/strings/strcat.h"
// #include "tensorflow/core/platform/logging.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/mutex.h"
// #include "tensorflow/core/platform/thread_annotations.h"
// #include "tensorflow/core/platform/types.h"

// Users that want to look up an OpDef by type name should take an
// OpRegistryInterface.  Functions accepting a
// (const) OpRegistryInterface* may call LookUp() from multiple threads.
@Namespace("tensorflow") public static class OpRegistryInterface extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public OpRegistryInterface(Pointer p) { super(p); }


  // Returns an error status and sets *op_reg_data to nullptr if no OpDef is
  // registered under that name, otherwise returns the registered OpDef.
  // Caller must not delete the returned pointer.
  public native @ByVal Status LookUp(@StdString BytePointer op_type_name,
                          @Cast("const tensorflow::OpRegistrationData**") PointerPointer op_reg_data);
  public native @ByVal Status LookUp(@StdString BytePointer op_type_name,
                          @Const @ByPtrPtr OpRegistrationData op_reg_data);
  public native @ByVal Status LookUp(@StdString String op_type_name,
                          @Const @ByPtrPtr OpRegistrationData op_reg_data);

  // Shorthand for calling LookUp to get the OpDef.
  public native @ByVal Status LookUpOpDef(@StdString BytePointer op_type_name, @Cast("const tensorflow::OpDef**") PointerPointer op_def);
  public native @ByVal Status LookUpOpDef(@StdString BytePointer op_type_name, @Const @ByPtrPtr OpDef op_def);
  public native @ByVal Status LookUpOpDef(@StdString String op_type_name, @Const @ByPtrPtr OpDef op_def);
}

// The standard implementation of OpRegistryInterface, along with a
// global singleton used for registering ops via the REGISTER
// macros below.  Thread-safe.
//
// Example registration:
//   OpRegistry::Global()->Register(
//     [](OpRegistrationData* op_reg_data)->Status {
//       // Populate *op_reg_data here.
//       return Status::OK();
//   });
@Namespace("tensorflow") @NoOffset public static class OpRegistry extends OpRegistryInterface {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public OpRegistry(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public OpRegistry(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public OpRegistry position(long position) {
        return (OpRegistry)super.position(position);
    }


  public OpRegistry() { super((Pointer)null); allocate(); }
  private native void allocate();

  public native void Register(@ByVal @Cast("tensorflow::OpRegistry::OpRegistrationDataFactory*") Fn op_data_factory);

  public native @ByVal Status LookUp(@StdString BytePointer op_type_name,
                  @Cast("const tensorflow::OpRegistrationData**") PointerPointer op_reg_data);
  public native @ByVal Status LookUp(@StdString BytePointer op_type_name,
                  @Const @ByPtrPtr OpRegistrationData op_reg_data);
  public native @ByVal Status LookUp(@StdString String op_type_name,
                  @Const @ByPtrPtr OpRegistrationData op_reg_data);

  // Fills *ops with all registered OpDefs (except those with names
  // starting with '_' if include_internal == false).
  public native void Export(@Cast("bool") boolean include_internal, OpList ops);

  // Returns ASCII-format OpList for all registered OpDefs (except
  // those with names starting with '_' if include_internal == false).
  public native @StdString BytePointer DebugString(@Cast("bool") boolean include_internal);

  // A singleton available at startup.
  public static native OpRegistry Global();

  // Get all registered ops.
  public native void GetRegisteredOps(@StdVector OpDef op_defs);

  // Watcher, a function object.
  // The watcher, if set by SetWatcher(), is called every time an op is
  // registered via the Register function. The watcher is passed the Status
  // obtained from building and adding the OpDef to the registry, and the OpDef
  // itself if it was successfully built. A watcher returns a Status which is in
  // turn returned as the final registration status.

  // An OpRegistry object has only one watcher. This interface is not thread
  // safe, as different clients are free to set the watcher any time.
  // Clients are expected to atomically perform the following sequence of
  // operations :
  // SetWatcher(a_watcher);
  // Register some ops;
  // op_registry->ProcessRegistrations();
  // SetWatcher(nullptr);
  // Returns a non-OK status if a non-null watcher is over-written by another
  // non-null watcher.
  public native @ByVal Status SetWatcher(@Cast("const tensorflow::OpRegistry::Watcher*") @ByRef Fn watcher);

  // Process the current list of deferred registrations. Note that calls to
  // Export, LookUp and DebugString would also implicitly process the deferred
  // registrations. Returns the status of the first failed op registration or
  // Status::OK() otherwise.
  public native @ByVal Status ProcessRegistrations();

  // Defer the registrations until a later call to a function that processes
  // deferred registrations are made. Normally, registrations that happen after
  // calls to Export, LookUp, ProcessRegistrations and DebugString are processed
  // immediately. Call this to defer future registrations.
  public native void DeferRegistrations();

  // Clear the registrations that have been deferred.
  public native void ClearDeferredRegistrations();
}

// An adapter to allow an OpList to be used as an OpRegistryInterface.
//
// Note that shape inference functions are not passed in to OpListOpRegistry, so
// it will return an unusable shape inference function for every op it supports;
// therefore, it should only be used in contexts where this is okay.
@Namespace("tensorflow") @NoOffset public static class OpListOpRegistry extends OpRegistryInterface {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public OpListOpRegistry(Pointer p) { super(p); }

  // Does not take ownership of op_list, *op_list must outlive *this.
  public OpListOpRegistry(@Const OpList op_list) { super((Pointer)null); allocate(op_list); }
  private native void allocate(@Const OpList op_list);
  public native @ByVal Status LookUp(@StdString BytePointer op_type_name,
                  @Cast("const tensorflow::OpRegistrationData**") PointerPointer op_reg_data);
  public native @ByVal Status LookUp(@StdString BytePointer op_type_name,
                  @Const @ByPtrPtr OpRegistrationData op_reg_data);
  public native @ByVal Status LookUp(@StdString String op_type_name,
                  @Const @ByPtrPtr OpRegistrationData op_reg_data);
}

// Treats 'registry_ptr' as a pointer to OpRegistry, and calls
// registry_ptr->Register(op_def) for each op_def that has been registered with
// the current library's global op registry (obtained by calling
// OpRegistry::Global().
@Namespace("tensorflow") public static native void RegisterOps(Pointer registry_ptr);

// Support for defining the OpDef (specifying the semantics of the Op and how
// it should be created) and registering it in the OpRegistry::Global()
// registry.  Usage:
//
// REGISTER_OP("my_op_name")
//     .Attr("<name>:<type>")
//     .Attr("<name>:<type>=<default>")
//     .Input("<name>:<type-expr>")
//     .Input("<name>:Ref(<type-expr>)")
//     .Output("<name>:<type-expr>")
//     .Doc(R"(
// <1-line summary>
// <rest of the description (potentially many lines)>
// <name-of-attr-input-or-output>: <description of name>
// <name-of-attr-input-or-output>: <description of name;
//   if long, indent the description on subsequent lines>
// )");
//
// Note: .Doc() should be last.
// For details, see the OpDefBuilder class in op_def_builder.h.

// OpDefBuilderWrapper is a templated class that is used in the REGISTER_OP
// calls. This allows the result of REGISTER_OP to be used in chaining, as in
// REGISTER_OP(a).Attr("...").Input("...");, while still allowing selective
// registration to turn the entire call-chain into a no-op.

// Template specialization that forwards all calls to the contained builder.
@Name("tensorflow::register_op::OpDefBuilderWrapper<true>") @NoOffset public static class TrueOpDefBuilderWrapper extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TrueOpDefBuilderWrapper(Pointer p) { super(p); }

  public TrueOpDefBuilderWrapper(@Cast("const char*") BytePointer name) { super((Pointer)null); allocate(name); }
  private native void allocate(@Cast("const char*") BytePointer name);
  public TrueOpDefBuilderWrapper(String name) { super((Pointer)null); allocate(name); }
  private native void allocate(String name);
  public native @ByRef TrueOpDefBuilderWrapper Attr(@StringPiece BytePointer spec);
  public native @ByRef TrueOpDefBuilderWrapper Attr(@StringPiece String spec);
  public native @ByRef TrueOpDefBuilderWrapper Input(@StringPiece BytePointer spec);
  public native @ByRef TrueOpDefBuilderWrapper Input(@StringPiece String spec);
  public native @ByRef TrueOpDefBuilderWrapper Output(@StringPiece BytePointer spec);
  public native @ByRef TrueOpDefBuilderWrapper Output(@StringPiece String spec);
  public native @ByRef TrueOpDefBuilderWrapper SetIsCommutative();
  public native @ByRef TrueOpDefBuilderWrapper SetIsAggregate();
  public native @ByRef TrueOpDefBuilderWrapper SetIsStateful();
  public native @ByRef TrueOpDefBuilderWrapper SetAllowsUninitializedInput();
  public native @ByRef TrueOpDefBuilderWrapper Deprecated(int version, @StringPiece BytePointer explanation);
  public native @ByRef TrueOpDefBuilderWrapper Deprecated(int version, @StringPiece String explanation);
  public native @ByRef TrueOpDefBuilderWrapper Doc(@StringPiece BytePointer text);
  public native @ByRef TrueOpDefBuilderWrapper Doc(@StringPiece String text);
  public static class Fn_InferenceContext extends FunctionPointer {
      static { Loader.load(); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public    Fn_InferenceContext(Pointer p) { super(p); }
      protected Fn_InferenceContext() { allocate(); }
      private native void allocate();
      public native @ByVal Status call(InferenceContext arg0);
  }
  public native @ByRef TrueOpDefBuilderWrapper SetShapeFn(
        Fn_InferenceContext fn);
  public native @Const @ByRef OpDefBuilder builder();
}

// Template specialization that turns all calls into no-ops.
@Name("tensorflow::register_op::OpDefBuilderWrapper<false>") public static class FalseOpDefBuilderWrapper extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public FalseOpDefBuilderWrapper(Pointer p) { super(p); }

  public FalseOpDefBuilderWrapper(@Cast("const char*") BytePointer name) { super((Pointer)null); allocate(name); }
  private native void allocate(@Cast("const char*") BytePointer name);
  public FalseOpDefBuilderWrapper(String name) { super((Pointer)null); allocate(name); }
  private native void allocate(String name);
  public native @ByRef FalseOpDefBuilderWrapper Attr(@StringPiece BytePointer spec);
  public native @ByRef FalseOpDefBuilderWrapper Attr(@StringPiece String spec);
  public native @ByRef FalseOpDefBuilderWrapper Input(@StringPiece BytePointer spec);
  public native @ByRef FalseOpDefBuilderWrapper Input(@StringPiece String spec);
  public native @ByRef FalseOpDefBuilderWrapper Output(@StringPiece BytePointer spec);
  public native @ByRef FalseOpDefBuilderWrapper Output(@StringPiece String spec);
  public native @ByRef FalseOpDefBuilderWrapper SetIsCommutative();
  public native @ByRef FalseOpDefBuilderWrapper SetIsAggregate();
  public native @ByRef FalseOpDefBuilderWrapper SetIsStateful();
  public native @ByRef FalseOpDefBuilderWrapper SetAllowsUninitializedInput();
  public native @ByRef FalseOpDefBuilderWrapper Deprecated(int arg0, @StringPiece BytePointer arg1);
  public native @ByRef FalseOpDefBuilderWrapper Deprecated(int arg0, @StringPiece String arg1);
  public native @ByRef FalseOpDefBuilderWrapper Doc(@StringPiece BytePointer text);
  public native @ByRef FalseOpDefBuilderWrapper Doc(@StringPiece String text);
  public static class Fn_InferenceContext extends FunctionPointer {
      static { Loader.load(); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public    Fn_InferenceContext(Pointer p) { super(p); }
      protected Fn_InferenceContext() { allocate(); }
      private native void allocate();
      public native @ByVal Status call(InferenceContext arg0);
  }
  public native @ByRef FalseOpDefBuilderWrapper SetShapeFn(
        Fn_InferenceContext fn);
}

@Namespace("tensorflow::register_op") public static class OpDefBuilderReceiver extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public OpDefBuilderReceiver(Pointer p) { super(p); }

  // To call OpRegistry::Global()->Register(...), used by the
  // REGISTER_OP macro below.
  // Note: These are implicitly converting constructors.
  public OpDefBuilderReceiver(
        @Const @ByRef TrueOpDefBuilderWrapper wrapper) { super((Pointer)null); allocate(wrapper); }
  private native void allocate(
        @Const @ByRef TrueOpDefBuilderWrapper wrapper);  // NOLINT(runtime/explicit)
  public OpDefBuilderReceiver(@Const @ByRef FalseOpDefBuilderWrapper arg0) { super((Pointer)null); allocate(arg0); }
  private native void allocate(@Const @ByRef FalseOpDefBuilderWrapper arg0);  // NOLINT(runtime/explicit)
}
  // namespace register_op

// #define REGISTER_OP(name) REGISTER_OP_UNIQ_HELPER(__COUNTER__, name)
// #define REGISTER_OP_UNIQ_HELPER(ctr, name) REGISTER_OP_UNIQ(ctr, name)
// #define REGISTER_OP_UNIQ(ctr, name)
//   static ::tensorflow::register_op::OpDefBuilderReceiver register_op##ctr
//       TF_ATTRIBUTE_UNUSED =
//           ::tensorflow::register_op::OpDefBuilderWrapper<SHOULD_REGISTER_OP(
//               name)>(name)

  // namespace tensorflow

// #endif  // TENSORFLOW_FRAMEWORK_OP_H_


// Parsed from tensorflow/core/framework/types.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_FRAMEWORK_TYPES_H_
// #define TENSORFLOW_FRAMEWORK_TYPES_H_

// #include <map>
// #include <set>
// #include <string>

// #include "third_party/eigen3/unsupported/Eigen/CXX11/Tensor"
// Disable clang-format to prevent 'FixedPoint' header from being included
// before 'Tensor' header on which it depends.
// clang-format off
// #include "third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint"
// clang-format on
// #include "tensorflow/core/framework/bfloat16.h"
// #include "tensorflow/core/framework/numeric_types.h"
// #include "tensorflow/core/framework/types.pb.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// #include "tensorflow/core/lib/gtl/inlined_vector.h"
// #include "tensorflow/core/platform/logging.h"
// #include "tensorflow/core/platform/types.h"

// MemoryType is used to describe whether input or output Tensors of
// an OpKernel should reside in "Host memory" (e.g., CPU memory) or
// "Device" Memory (CPU memory for CPU devices, GPU memory for GPU
// devices).
/** enum tensorflow::MemoryType */
public static final int
  DEVICE_MEMORY = 0,
  HOST_MEMORY = 1;

// A DeviceType is just a string, but we wrap it up in a class to give
// some type checking as we're passing these around
@Namespace("tensorflow") @NoOffset public static class DeviceType extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public DeviceType(Pointer p) { super(p); }

  public DeviceType(@Cast("const char*") BytePointer type) { super((Pointer)null); allocate(type); }
  private native void allocate(@Cast("const char*") BytePointer type);
  public DeviceType(String type) { super((Pointer)null); allocate(type); }
  private native void allocate(String type);

  public native @Cast("const char*") BytePointer type();

  public native @Cast("bool") @Name("operator <") boolean lessThan(@Const @ByRef DeviceType other);
  public native @Cast("bool") @Name("operator ==") boolean equals(@Const @ByRef DeviceType other);
  public native @Cast("bool") @Name("operator !=") boolean notEquals(@Const @ByRef DeviceType other);
}
@Namespace("tensorflow") public static native @Cast("std::ostream*") @ByRef @Name("operator <<") Pointer shiftLeft(@Cast("std::ostream*") @ByRef Pointer os, @Const @ByRef DeviceType d);

// Convenient constants that can be passed to a DeviceType constructor
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer DEVICE_CPU();  // "CPU"
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer DEVICE_GPU();  // "GPU"

// Convert the enums to strings for errors:
@Namespace("tensorflow") public static native @StdString BytePointer DataTypeString(@Cast("tensorflow::DataType") int dtype);
@Namespace("tensorflow") public static native @StdString BytePointer DeviceTypeString(@ByVal DeviceType device_type);
@Namespace("tensorflow") public static native @StdString BytePointer DataTypeSliceString(@ByVal @Cast("const tensorflow::DataTypeSlice*") DataTypeVector dtypes);
@Namespace("tensorflow") public static native @StdString BytePointer DataTypeVectorString(@Const @ByRef DataTypeVector dtypes);

// If "sp" names a valid type, store it in "*dt" and return true.  Otherwise,
// return false.
@Namespace("tensorflow") public static native @Cast("bool") boolean DataTypeFromString(@StringPiece BytePointer sp, @Cast("tensorflow::DataType*") IntPointer dt);
@Namespace("tensorflow") public static native @Cast("bool") boolean DataTypeFromString(@StringPiece String sp, @Cast("tensorflow::DataType*") IntPointer dt);

// DT_FLOAT + kDataTypeRefOffset == DT_FLOAT_REF, etc.
/** enum tensorflow:: */
public static final int kDataTypeRefOffset = 100;
@Namespace("tensorflow") public static native @Cast("bool") boolean IsRefType(@Cast("tensorflow::DataType") int dtype);
@Namespace("tensorflow") public static native @Cast("tensorflow::DataType") int MakeRefType(@Cast("tensorflow::DataType") int dtype);
@Namespace("tensorflow") public static native @Cast("tensorflow::DataType") int RemoveRefType(@Cast("tensorflow::DataType") int dtype);
@Namespace("tensorflow") public static native @Cast("tensorflow::DataType") int BaseType(@Cast("tensorflow::DataType") int dtype);

// Returns true if the actual type is the same as or ref of the expected type.
@Namespace("tensorflow") public static native @Cast("bool") boolean TypesCompatible(@Cast("tensorflow::DataType") int expected, @Cast("tensorflow::DataType") int actual);

// Does not include _ref types.
@Namespace("tensorflow") public static native @ByVal DataTypeVector AllTypes();

// Return the list of all numeric types.
// NOTE: On Android, we only include the float and int32 types for now.
@Namespace("tensorflow") public static native @ByVal DataTypeVector RealNumberTypes();  // Types that support '<' and '>'.
@Namespace("tensorflow") public static native @ByVal DataTypeVector NumberTypes();      // Includes complex and quantized types.

@Namespace("tensorflow") public static native @ByVal DataTypeVector QuantizedTypes();
@Namespace("tensorflow") public static native @ByVal DataTypeVector RealAndQuantizedTypes();  // Types that support '<' and
                                         // '>', including quantized
                                         // types

// Validates type T for whether it is a supported DataType.

// DataTypeToEnum<T>::v() and DataTypeToEnum<T>::value are the DataType
// constants for T, e.g. DataTypeToEnum<float>::v() is DT_FLOAT.  // Specializations below

// EnumToDataType<VALUE>::Type is the type for DataType constant VALUE, e.g.
// EnumToDataType<DT_FLOAT>::Type is float.  // Specializations below

// Template specialization for both DataTypeToEnum and EnumToDataType.
// #define MATCH_TYPE_AND_ENUM(TYPE, ENUM)
//   template <>
//   struct DataTypeToEnum<TYPE> {
//     static DataType v() { return ENUM; }
//     static DataType ref() { return MakeRefType(ENUM); }
//     static constexpr DataType value = ENUM;
//   };
//   template <>
//   struct IsValidDataType<TYPE> {
//     static constexpr bool value = true;
//   };
//   template <>
//   struct EnumToDataType<ENUM> {
//     typedef TYPE Type;
//   }

// We use Eigen's QInt implementations for our quantized int types.

@Name("tensorflow::DataTypeToEnum<float>") public static class DataTypeToEnum extends Pointer {
    static { Loader.load(); }
    /** Default native constructor. */
    public DataTypeToEnum() { super((Pointer)null); allocate(); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public DataTypeToEnum(long size) { super((Pointer)null); allocateArray(size); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public DataTypeToEnum(Pointer p) { super(p); }
    private native void allocate();
    private native void allocateArray(long size);
    @Override public DataTypeToEnum position(long position) {
        return (DataTypeToEnum)super.position(position);
    }

    public static native @Cast("tensorflow::DataType") int v();
    public static native @Cast("tensorflow::DataType") int ref();
    @MemberGetter public static native @Cast("const tensorflow::DataType") int value();
    public static final int value = value();
  }
  @Name("tensorflow::IsValidDataType<float>") public static class IsValidDataType extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public IsValidDataType() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public IsValidDataType(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public IsValidDataType(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public IsValidDataType position(long position) {
          return (IsValidDataType)super.position(position);
      }
  
    @MemberGetter public static native @Cast("const bool") boolean value();
    public static final boolean value = value();
  }
  @Name("tensorflow::EnumToDataType<tensorflow::DT_FLOAT>") public static class EnumToDataType extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public EnumToDataType() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public EnumToDataType(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public EnumToDataType(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public EnumToDataType position(long position) {
          return (EnumToDataType)super.position(position);
      }
  
  }

// #undef MATCH_TYPE_AND_ENUM

@Namespace("tensorflow") public static native @Cast("bool") boolean DataTypeCanUseMemcpy(@Cast("tensorflow::DataType") int dt);

@Namespace("tensorflow") public static native @Cast("bool") boolean DataTypeIsQuantized(@Cast("tensorflow::DataType") int dt);

// Is the dtype nonquantized integral?
@Namespace("tensorflow") public static native @Cast("bool") boolean DataTypeIsInteger(@Cast("tensorflow::DataType") int dt);

// Returns a 0 on failure
@Namespace("tensorflow") public static native int DataTypeSize(@Cast("tensorflow::DataType") int dt);

  // namespace tensorflow

// #endif  // TENSORFLOW_FRAMEWORK_TYPES_H_


// Parsed from tensorflow/core/graph/edgeset.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_GRAPH_EDGESET_H_
// #define TENSORFLOW_GRAPH_EDGESET_H_

// #include <stddef.h>
// #include <set>
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/types.h"

// #include "tensorflow/core/platform/logging.h"

// An unordered set of edges.  Uses very little memory for small sets.
// Unlike std::set, EdgeSet does NOT allow mutations during iteration.
@Namespace("tensorflow") @NoOffset public static class EdgeSet extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public EdgeSet(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public EdgeSet(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public EdgeSet position(long position) {
        return (EdgeSet)super.position(position);
    }

  public EdgeSet() { super((Pointer)null); allocate(); }
  private native void allocate();

  @Name("const_iterator") @Opaque public static class EdgeSetIterator extends Pointer {
      /** Empty constructor. Calls {@code super((Pointer)null)}. */
      public EdgeSetIterator() { super((Pointer)null); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public EdgeSetIterator(Pointer p) { super(p); }
  }

  public native @Cast("bool") boolean empty();
  public native @Cast("tensorflow::EdgeSet::size_type") long size();
  public native void clear();
  public native @ByVal EdgeSetBoolPair insert(@Cast("tensorflow::EdgeSet::value_type") Edge value);
  public native @Cast("tensorflow::EdgeSet::size_type") long erase(@Cast("tensorflow::EdgeSet::key_type") Edge key);

  // Caller is not allowed to mutate the EdgeSet while iterating.
  public native @ByVal EdgeSetIterator begin();
  public native @ByVal EdgeSetIterator end();
}

@Name("tensorflow::EdgeSet::const_iterator") @NoOffset public static class EdgeSetIterator extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public EdgeSetIterator(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public EdgeSetIterator(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public EdgeSetIterator position(long position) {
        return (EdgeSetIterator)super.position(position);
    }


  public EdgeSetIterator() { super((Pointer)null); allocate(); }
  private native void allocate();

  public native @ByRef @Name("operator ++") EdgeSetIterator increment();
  public native @ByVal @Name("operator ++") EdgeSetIterator increment(int arg0);
  public native @Cast("const tensorflow::EdgeSet::value_type*") @Name("operator ->") PointerPointer access();
  public native @Cast("tensorflow::EdgeSet::value_type") @Name("operator *") Edge multiply();
  public native @Cast("bool") @Name("operator ==") boolean equals(@Const @ByRef EdgeSetIterator other);
  public native @Cast("bool") @Name("operator !=") boolean notEquals(@Const @ByRef EdgeSetIterator other);
}



















// gcc's set and multiset always use const_iterator since it will otherwise
// allow modification of keys.


// gcc's set and multiset always use const_iterator since it will otherwise
// allow modification of keys.




  // namespace tensorflow

// #endif  // TENSORFLOW_GRAPH_EDGESET_H_


// Parsed from tensorflow/core/lib/gtl/iterator_range.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// This provides a very simple, boring adaptor for a begin and end iterator
// into a range type. This should be used to build range views that work well
// with range based for loops and range based constructors.
//
// Note that code here follows more standards-based coding conventions as it
// is mirroring proposed interfaces for standardization.
//
// Converted from chandlerc@'s code to Google style by joshl@.

// #ifndef TENSORFLOW_LIB_GTL_ITERATOR_RANGE_H_
// #define TENSORFLOW_LIB_GTL_ITERATOR_RANGE_H_

// #include <utility>

// A range adaptor for a pair of iterators.
//
// This just wraps two iterators into a range-compatible interface. Nothing
// fancy at all.
@Name("tensorflow::gtl::iterator_range<tensorflow::NeighborIter>") @NoOffset public static class NeighborIterRange extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public NeighborIterRange(Pointer p) { super(p); }

  
  public NeighborIterRange(@ByVal NeighborIter begin_iterator, @ByVal NeighborIter end_iterator) { super((Pointer)null); allocate(begin_iterator, end_iterator); }
  private native void allocate(@ByVal NeighborIter begin_iterator, @ByVal NeighborIter end_iterator);

  public native @ByVal NeighborIter begin();
  public native @ByVal NeighborIter end();
}
@Name("tensorflow::gtl::iterator_range<tensorflow::NodeIter>") @NoOffset public static class NodeIterRange extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public NodeIterRange(Pointer p) { super(p); }

  
  public NodeIterRange(@ByVal NodeIter begin_iterator, @ByVal NodeIter end_iterator) { super((Pointer)null); allocate(begin_iterator, end_iterator); }
  private native void allocate(@ByVal NodeIter begin_iterator, @ByVal NodeIter end_iterator);

  public native @ByVal NodeIter begin();
  public native @ByVal NodeIter end();
}

// Convenience function for iterating over sub-ranges.
//
// This provides a bit of syntactic sugar to make using sub-ranges
// in for loops a bit easier. Analogous to std::make_pair().

  // namespace gtl
  // namespace tensorflow

// #endif  // TENSORFLOW_LIB_GTL_ITERATOR_RANGE_H_


// Parsed from tensorflow/core/graph/graph.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// A Graph describes a set of computations that are to be
// performed, as well as the dependencies between those
// computations. The basic model is a DAG (directed acyclic graph) with
// * internal nodes representing computational operations to be performed;
// * edges represent dependencies, indicating the target may only be
//   executed once the source has completed; and
// * predefined "source" (start) and "sink" (finish) nodes -- the source
//   should be the only node that doesn't depend on anything, and the sink
//   should be the only node that nothing depends on.
//
// Note: Node ids are intended to be relatively dense in the
// 0..max_id range, but there may be gaps since ids won't be reused.
//
// Note: Some dependencies between operations are due to one operation
// consuming the output of another. In fact operations can produce
// multiple outputs and consume multiple inputs, and some
// optimizations will care about which specific outputs are connected
// to which specific inputs.  We therefore represent data dependency
// between output O of layer A and input I of layer B using
// "input index" and "output index" labels per edge.

// #ifndef TENSORFLOW_GRAPH_GRAPH_H_
// #define TENSORFLOW_GRAPH_GRAPH_H_

// #include <functional>
// #include <string>
// #include <vector>
// #include "tensorflow/core/framework/graph.pb.h"
// #include "tensorflow/core/framework/op.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/framework/versions.pb.h"
// #include "tensorflow/core/graph/edgeset.h"
// #include "tensorflow/core/lib/core/arena.h"
// #include "tensorflow/core/lib/core/refcount.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/gtl/iterator_range.h"
// #include "tensorflow/core/platform/logging.h"
// #include "tensorflow/core/platform/macros.h"
// #include "tensorflow/core/platform/types.h"
@Namespace("tensorflow") @Opaque public static class EdgeSetTest extends Pointer {
    /** Empty constructor. Calls {@code super((Pointer)null)}. */
    public EdgeSetTest() { super((Pointer)null); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public EdgeSetTest(Pointer p) { super(p); }
}  // Declared below      // Declared below

@Namespace("tensorflow") @NoOffset public static class Node extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Node(Pointer p) { super(p); }

  public native @StdString BytePointer DebugString();
  public native int id();
  public native int cost_id();
  public native @StdString BytePointer name();
  public native @StdString BytePointer type_string();
  public native @Const @ByRef NodeDef def();
  public native @Const @ByRef OpDef op_def();

  // input and output types
  public native int num_inputs();
  public native @Cast("tensorflow::DataType") int input_type(int i);
  public native @Const @ByRef DataTypeVector input_types();

  public native int num_outputs();
  public native @Cast("tensorflow::DataType") int output_type(int o);
  public native @Const @ByRef DataTypeVector output_types();

  // This gives the device the runtime has assigned this node to.  If
  // you want the device the user requested, use def().device() instead.
  // TODO(josh11b): Validate that the assigned_device, if not empty:
  // fully specifies a device, and satisfies def().device().
  // TODO(josh11b): Move device_name outside of Node into a NodeId->DeviceName
  // map.
  public native @StdString BytePointer assigned_device_name();
  public native void set_assigned_device_name(@StdString BytePointer device_name);
  public native void set_assigned_device_name(@StdString String device_name);

  // Get the neighboring nodes via edges either in or out of this node.
  public native @ByVal NeighborIterRange in_nodes();
  public native @ByVal NeighborIterRange out_nodes();
  public native @Const @ByRef EdgeSet in_edges();
  public native @Const @ByRef EdgeSet out_edges();

  // Node type helpers.
  public native @Cast("bool") boolean IsSource();
  public native @Cast("bool") boolean IsSink();
  // Anything other than the special Source & Sink nodes.
  public native @Cast("bool") boolean IsOp();

  // Node class helpers
  public native @Cast("bool") boolean IsSwitch();
  public native @Cast("bool") boolean IsMerge();
  public native @Cast("bool") boolean IsEnter();
  public native @Cast("bool") boolean IsExit();
  public native @Cast("bool") boolean IsNextIteration();
  public native @Cast("bool") boolean IsLoopCond();
  public native @Cast("bool") boolean IsControlTrigger();
  public native @Cast("bool") boolean IsSend();
  public native @Cast("bool") boolean IsRecv();
  public native @Cast("bool") boolean IsConstant();
  public native @Cast("bool") boolean IsVariable();
  public native @Cast("bool") boolean IsIdentity();
  public native @Cast("bool") boolean IsGetSessionHandle();
  public native @Cast("bool") boolean IsGetSessionTensor();
  public native @Cast("bool") boolean IsDeleteSessionTensor();
  public native @Cast("bool") boolean IsControlFlow();
  public native @Cast("bool") boolean IsHostSend();
  public native @Cast("bool") boolean IsHostRecv();

  public native void ClearAttr(@StdString BytePointer name);
  public native void ClearAttr(@StdString String name);

  // Returns into '*e' the edge connecting to the 'idx' input of this Node.
  public native @ByVal Status input_edge(int idx, @Cast("const tensorflow::Edge**") PointerPointer e);
  public native @ByVal Status input_edge(int idx, @Const @ByPtrPtr Edge e);

  // Returns into '*n' the node that has an output connected to the
  // 'idx' input of this Node.
  public native @ByVal Status input_node(int idx, @Cast("const tensorflow::Node**") PointerPointer n);
  public native @ByVal Status input_node(int idx, @Const @ByPtrPtr Node n);
}

@Namespace("tensorflow") @NoOffset public static class Edge extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Edge(Pointer p) { super(p); }

  public native Node src();
  public native Node dst();
  public native int id();

  // Return the number of the source output that produces the data
  // carried by this edge.  The special value kControlSlot is used
  // for control dependencies.
  public native int src_output();

  // Return the number of the destination input that consumes the data
  // carried by this edge.  The special value kControlSlot is used
  // for control dependencies.
  public native int dst_input();

  // Return true iff this is an edge that indicates a control-flow
  // (as opposed to a data-flow) dependency.
  public native @Cast("bool") boolean IsControlEdge();
}

// Thread compatible but not thread safe.
@Namespace("tensorflow") @NoOffset public static class Graph extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Graph(Pointer p) { super(p); }

  // Constructs a graph with a single SOURCE (always id kSourceId) and a
  // single SINK (always id kSinkId) node, and an edge from SOURCE->SINK.
  //
  // The graph can hold ops found in registry.
  public Graph(@Const OpRegistryInterface registry) { super((Pointer)null); allocate(registry); }
  private native void allocate(@Const OpRegistryInterface registry);

  @MemberGetter public static native int kControlSlot();
  public static final int kControlSlot = kControlSlot();

  // The GraphDef version range of this graph (see graph.proto).
  public native @Const @ByRef VersionDef versions();
  public native void set_versions(@Const @ByRef VersionDef versions);

  // Adds a new node to this graph, and returns it. Infers the Op and
  // input/output types for the node. *this owns the returned instance.
  // Returns nullptr and sets *status on error.
  public native Node AddNode(@Const @ByRef NodeDef node_def, Status status);

  // Copies *node, which may belong to another graph, to a new node,
  // which is returned.  Does not copy any edges.  *this owns the
  // returned instance.
  public native Node CopyNode(Node node);

  // Remove a node from this graph, including all edges from or to it.
  // *node should not be accessed after calling this function.
  // REQUIRES: node->IsOp()
  public native void RemoveNode(Node node);

  // Add an edge that connects the xth output of "source" to the yth input
  // of "dest".
  public native @Const Edge AddEdge(Node source, int x, Node dest, int y);

  // Add a control-edge (no data flows along this edge) that
  // connects "source" to "dest".
  public native @Const Edge AddControlEdge(Node source, Node dest);

  // Removes edge from the graph.
  // REQUIRES: The edge must exist.
  public native void RemoveEdge(@Const Edge edge);

  // The number of live nodes in the graph.
  //
  // Because nodes can be removed from the graph, num_nodes() is often
  // smaller than num_node_ids(). If one needs to create an array of
  // nodes indexed by node ids, num_node_ids() should be used as the
  // array's size.
  public native int num_nodes();

  // The number of live edges in the graph.
  //
  // Because edges can be removed from the graph, num_edges() is often
  // smaller than num_edge_ids(). If one needs to create an array of
  // edges indexed by edge ids, num_edge_ids() should be used as the
  // array's size.
  public native int num_edges();

  // Serialize the nodes starting at `from_node_id` to a GraphDef.
  public native void ToGraphDefSubRange(GraphDef graph_def, int from_node_id);

  // Serialize to a GraphDef.
  public native void ToGraphDef(GraphDef graph_def);

  // Generate new node name with the specified prefix that is unique
  // across this graph.
  public native @StdString BytePointer NewName(@StringPiece BytePointer prefix);
  public native @StdString String NewName(@StringPiece String prefix);

  // Access to the list of all nodes.  Example usage:
  //   for (Node* node : graph.nodes()) { ... }
  public native @ByVal NodeIterRange nodes();

  // Returns one more than the maximum id assigned to any node.
  public native int num_node_ids();

  // Returns the node associated with an id, or nullptr if no node
  // with that id (the node with that id was removed and the id has
  // not yet been re-used). *this owns the returned instance.
  // REQUIRES: 0 <= id < num_node_ids().
  public native Node FindNodeId(int id);

  // Returns one more than the maximum id assigned to any edge.
  public native int num_edge_ids();

  // Returns the Edge associated with an id, or nullptr if no edge
  // with that id (the node with that id was removed and the id has
  // not yet been re-used). *this owns the returned instance.
  // REQUIRES: 0 <= id < num_node_ids().
  public native @Const Edge FindEdgeId(int id);

  // Access to the set of all edges.  Example usage:
  //   for (const Edge* e : graph.edges()) { ... }
  public native @Const @ByRef EdgeSet edges();

  // The pre-defined nodes.
  /** enum tensorflow::Graph:: */
  public static final int kSourceId = 0, kSinkId = 1;
  public native Node source_node();
  public native Node sink_node();

  public native @Const OpRegistryInterface op_registry();
}

// TODO(josh11b): We may want to support keeping an index on various
// node/edge attributes in a graph, particularly node names.

// Helper routines

@Namespace("tensorflow") public static native @Cast("bool") boolean IsSwitch(@Const Node node);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsMerge(@Const Node node);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsEnter(@Const Node node);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsExit(@Const Node node);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsNextIteration(@Const Node n);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsLoopCond(@Const Node node);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsControlTrigger(@Const Node n);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsSend(@Const Node node);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsRecv(@Const Node node);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsHostSend(@Const Node node);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsHostRecv(@Const Node node);

// True for Nodes that mediate the transfer of values between processes.
@Namespace("tensorflow") public static native @Cast("bool") boolean IsTransferNode(@Const Node n);

@Namespace("tensorflow") public static native @Cast("bool") boolean IsConstant(@Const Node node);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsVariable(@Const Node node);
@Namespace("tensorflow") public static native @Cast("bool") boolean IsIdentity(@Const Node node);

// Returns true iff 'n' is a control flow node.
@Namespace("tensorflow") public static native @Cast("bool") boolean IsControlFlow(@Const Node n);

@Namespace("tensorflow") public static native @Cast("bool") boolean IsHostMemoryPreserving(@Const Node node);

// Iterator for stepping through the nodes of a graph.
@Namespace("tensorflow") @NoOffset public static class NodeIter extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public NodeIter(Pointer p) { super(p); }

  public NodeIter(@Const Graph graph, int id) { super((Pointer)null); allocate(graph, id); }
  private native void allocate(@Const Graph graph, int id);
  public native @Cast("bool") @Name("operator ==") boolean equals(@Const @ByRef NodeIter rhs);
  public native @Cast("bool") @Name("operator !=") boolean notEquals(@Const @ByRef NodeIter rhs);
  public native @Name("operator ++") void increment();
  public native @Name("operator *") Node multiply();
  public native @Name("operator ->") Node access();
}

// Iterator for stepping through the neighbors of a node.
@Namespace("tensorflow") @NoOffset public static class NeighborIter extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public NeighborIter(Pointer p) { super(p); }

  public NeighborIter(@ByVal EdgeSetIterator iter, @Cast("bool") boolean incoming) { super((Pointer)null); allocate(iter, incoming); }
  private native void allocate(@ByVal EdgeSetIterator iter, @Cast("bool") boolean incoming);
  public native @Cast("bool") @Name("operator ==") boolean equals(@Const @ByRef NeighborIter rhs);
  public native @Cast("bool") @Name("operator !=") boolean notEquals(@Const @ByRef NeighborIter rhs);
  public native @Name("operator ++") void increment();
  public native @Name("operator *") Node multiply();
  public native @Name("operator ->") Node access();
}

// IMPLEMENTATION DETAILS, PLEASE IGNORE



























  // namespace tensorflow

// #endif  // TENSORFLOW_GRAPH_GRAPH_H_


// Parsed from tensorflow/core/framework/node_def_builder.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_FRAMEWORK_NODE_DEF_BUILDER_H_
// #define TENSORFLOW_FRAMEWORK_NODE_DEF_BUILDER_H_

// #include <functional>
// #include <vector>
// #include "tensorflow/core/framework/attr_value_util.h"
// #include "tensorflow/core/framework/graph.pb.h"
// #include "tensorflow/core/framework/node_def_util.h"
// #include "tensorflow/core/framework/op.h"
// #include "tensorflow/core/framework/op_def.pb.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"
// #include "tensorflow/core/lib/strings/strcat.h"

// This is a helper for creating a NodeDef.  Automatically sets attrs
// that can be inferred from the inputs, and uses default values
// (where they exist) for unspecified attrs.  Example usage:
//
//  NodeDef node_def;
//  Status status = NodeDefBuilder(node_name, op_name)
//                           .Input(...)
//                           .Attr(...)
//                           .Finalize(&node_def);
//  if (!status.ok()) return status;
//  // Use node_def here.
@Namespace("tensorflow") @NoOffset public static class NodeDefBuilder extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public NodeDefBuilder(Pointer p) { super(p); }

  // To specify an output to be consumed by one of the Input() methods below.
  @NoOffset public static class NodeOut extends Pointer {
      static { Loader.load(); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public NodeOut(Pointer p) { super(p); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public NodeOut(long size) { super((Pointer)null); allocateArray(size); }
      private native void allocateArray(long size);
      @Override public NodeOut position(long position) {
          return (NodeOut)super.position(position);
      }
  
    public NodeOut(@StringPiece BytePointer n, int i, @Cast("tensorflow::DataType") int dt) { super((Pointer)null); allocate(n, i, dt); }
    private native void allocate(@StringPiece BytePointer n, int i, @Cast("tensorflow::DataType") int dt);
    public NodeOut(@StringPiece String n, int i, @Cast("tensorflow::DataType") int dt) { super((Pointer)null); allocate(n, i, dt); }
    private native void allocate(@StringPiece String n, int i, @Cast("tensorflow::DataType") int dt);
    public NodeOut() { super((Pointer)null); allocate(); }
    private native void allocate();  // uninitialized, call Reset() before use.
    public native void Reset(@StringPiece BytePointer n, int i, @Cast("tensorflow::DataType") int dt);
    public native void Reset(@StringPiece String n, int i, @Cast("tensorflow::DataType") int dt);
    public native @StdString BytePointer node(); public native NodeOut node(BytePointer node);
    public native int index(); public native NodeOut index(int index);
    public native @Cast("tensorflow::DataType") int data_type(); public native NodeOut data_type(int data_type);
  }

  // Specify the name and the Op (either via an OpDef or the name of
  // the Op plus a registry) for the NodeDef.  Other fields are
  // specified by calling the methods below.
  // REQUIRES: The OpDef must satisfy ValidateOpDef().
  public NodeDefBuilder(@StringPiece BytePointer name, @StringPiece BytePointer op_name,
                   @Const OpRegistryInterface op_registry/*=tensorflow::OpRegistry::Global()*/) { super((Pointer)null); allocate(name, op_name, op_registry); }
  private native void allocate(@StringPiece BytePointer name, @StringPiece BytePointer op_name,
                   @Const OpRegistryInterface op_registry/*=tensorflow::OpRegistry::Global()*/);
  public NodeDefBuilder(@StringPiece BytePointer name, @StringPiece BytePointer op_name) { super((Pointer)null); allocate(name, op_name); }
  private native void allocate(@StringPiece BytePointer name, @StringPiece BytePointer op_name);
  public NodeDefBuilder(@StringPiece String name, @StringPiece String op_name,
                   @Const OpRegistryInterface op_registry/*=tensorflow::OpRegistry::Global()*/) { super((Pointer)null); allocate(name, op_name, op_registry); }
  private native void allocate(@StringPiece String name, @StringPiece String op_name,
                   @Const OpRegistryInterface op_registry/*=tensorflow::OpRegistry::Global()*/);
  public NodeDefBuilder(@StringPiece String name, @StringPiece String op_name) { super((Pointer)null); allocate(name, op_name); }
  private native void allocate(@StringPiece String name, @StringPiece String op_name);
  // REQUIRES: in addition, *op_def must outlive *this.
  public NodeDefBuilder(@StringPiece BytePointer name, @Const OpDef op_def) { super((Pointer)null); allocate(name, op_def); }
  private native void allocate(@StringPiece BytePointer name, @Const OpDef op_def);
  public NodeDefBuilder(@StringPiece String name, @Const OpDef op_def) { super((Pointer)null); allocate(name, op_def); }
  private native void allocate(@StringPiece String name, @Const OpDef op_def);

  // You must call one Input() function per input_arg in the Op,
  // *and in the same order as the input_args appear in the OpDef.*

  // For inputs that take a single tensor.
  public native @ByRef NodeDefBuilder Input(@StringPiece BytePointer src_node, int src_index, @Cast("tensorflow::DataType") int dt);
  public native @ByRef NodeDefBuilder Input(@StringPiece String src_node, int src_index, @Cast("tensorflow::DataType") int dt);
  public native @ByRef NodeDefBuilder Input(@Const @ByRef NodeOut src);

  // For inputs that take a list of tensors.

  // To create inputs in tests, see fake_input.h.
  public native @ByRef NodeDefBuilder Input(@ByVal @Cast("tensorflow::FakeInputFunctor*") Fn fake_input);

  // Specify that this node must only run after src_node.
  public native @ByRef NodeDefBuilder ControlInput(@StringPiece BytePointer src_node);
  public native @ByRef NodeDefBuilder ControlInput(@StringPiece String src_node);

  // Constrains what devices this node may be scheduled on.
  public native @ByRef NodeDefBuilder Device(@StringPiece BytePointer device_spec);
  public native @ByRef NodeDefBuilder Device(@StringPiece String device_spec);

  // Sets the attr, if not already set.  If already set with a different
  // value, an error will be returned from Finalize().
  // Note: overload needed to allow {...} expressions for value.

  // Finish building the NodeDef, returning any errors or setting
  // *node_def if none.
  // WARNING: Not all problems are detected!  The resulting NodeDef may
  // not be valid!  Call ValidateNodeDef() from node_def_utils to be sure.
  public native @ByVal Status Finalize(NodeDef node_def);

  // Accessors for the values set in the constructor.
  public native @StdString BytePointer node_name();
  public native @Const @ByRef OpDef op_def();
}

// IMPLEMENTATION -------------------------------------------------------------



  // namespace tensorflow

// #endif  // TENSORFLOW_FRAMEWORK_NODE_DEF_BUILDER_H_


// Parsed from tensorflow/core/framework/node_def_util.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_FRAMEWORK_NODE_DEF_UTIL_H_
// #define TENSORFLOW_FRAMEWORK_NODE_DEF_UTIL_H_

// #include <string>
// #include <unordered_map>
// #include <vector>

// #include "tensorflow/core/framework/attr_value_util.h"
// #include "tensorflow/core/framework/node_def.pb.h"
// #include "tensorflow/core/framework/op_def.pb.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/platform/protobuf.h"

// Name of the attribute used to encode node colocation constraints.
//
// Nodes can be co-located on the same device. Desire for explicit co-location
// is described by list(string) attribute containing the name of colocation
// groups.
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer kColocationAttrName();

// String prefix applied to the operation name for colocation constraints.
@Namespace("tensorflow") @MemberGetter public static native @Cast("const char*") BytePointer kColocationGroupPrefix();

// Produce a human-readable version of a NodeDef that is more concise
// than a text-format proto.
@Namespace("tensorflow") public static native @StdString BytePointer SummarizeNodeDef(@Const @ByRef NodeDef node_def);

// Adds an attr with name <name> and value <value> to *node_def.
// The type of the attr is based on the type of value.

// Version to workaround C++'s "perfect" forwarding not being able to
// forward {...} initialization.

@Namespace("tensorflow") @NoOffset public static class AttrSlice extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public AttrSlice(Pointer p) { super(p); }

  public AttrSlice(@Const @ByRef NodeDef node_def) { super((Pointer)null); allocate(node_def); }
  private native void allocate(@Const @ByRef NodeDef node_def);  // NOLINT(runtime/explicit)

  public AttrSlice(@Cast("const tensorflow::AttrValueMap*") StringAttrValueMap a) { super((Pointer)null); allocate(a); }
  private native void allocate(@Cast("const tensorflow::AttrValueMap*") StringAttrValueMap a);

  // Returns the attr with attr_name if found.  Otherwise, returns
  // nullptr.
  public native @Const AttrValue Find(@StringPiece BytePointer attr_name);
  public native @Const AttrValue Find(@StringPiece String attr_name);

  // Returns the attr_value for attr_name if found. Otherwise, returns a
  // NotFound status.
  public native @ByVal Status Find(@StringPiece BytePointer attr_name, @Cast("const tensorflow::AttrValue**") PointerPointer attr_value);
  public native @ByVal Status Find(@StringPiece BytePointer attr_name, @Const @ByPtrPtr AttrValue attr_value);
  public native @ByVal Status Find(@StringPiece String attr_name, @Const @ByPtrPtr AttrValue attr_value);
}

// Look up the attr with name attr_name and set *value to its value.  If no
// attr with attr_name is found in node_def, or the attr does not have
// a matching type, a non-ok status will be returned.
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   @StdString @Cast({"char*", "std::string*"}) BytePointer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   @StdString @Cast({"char*", "std::string*"}) BytePointer value);  // type: "string"
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   @Cast("tensorflow::int64*") LongPointer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   @Cast("tensorflow::int64*") LongBuffer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   @Cast("tensorflow::int64*") long... value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   @Cast("tensorflow::int64*") LongPointer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   @Cast("tensorflow::int64*") LongBuffer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   @Cast("tensorflow::int64*") long... value);  // type: "int"
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   IntPointer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   IntBuffer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   int... value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   IntPointer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   IntBuffer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   int... value);  // type: "int"
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   FloatPointer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   FloatBuffer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   float... value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   FloatPointer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   FloatBuffer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   float... value);  // type: "float"
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   @Cast("bool*") BoolPointer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   @Cast("bool*") boolean... value);  // type: "bool"  // type: "type"
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   TensorShapeProto value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   TensorShapeProto value);  // type: "shape"
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   TensorShape value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   TensorShape value);  // type: "shape"
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   PartialTensorShape value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   PartialTensorShape value);  // type: "shape"
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   Tensor value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   Tensor value);  // type: "tensor"
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   StringVector value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   StringVector value);  // type "list(string)"  // type "list(int)"  // type "list(int)"  // type "list(float)"  // type "list(bool)"  // type "list(type)"
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   DataTypeVector value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   DataTypeVector value);  // type "list(type)"  // type "list(shape)"
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   TensorShapeVector value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   TensorShapeVector value);  // type "list(shape)"  // type "list(shape)"
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   TensorVector value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   TensorVector value);  // type: "list(tensor)"

// This version avoids copying the TensorProto.
// REQUIRES: Must not use *value beyond the lifetime of node_def.
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   @Cast("const tensorflow::TensorProto**") PointerPointer value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   @Const @ByPtrPtr TensorProto value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   @Const @ByPtrPtr TensorProto value);  // type: "tensor"

// This version avoids copying the NameAttrList.
// REQUIRES: Must not use *value beyond the lifetime of node_def.
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece BytePointer attr_name,
                   @Const @ByPtrPtr NameAttrList value);
@Namespace("tensorflow") public static native @ByVal Status GetNodeAttr(@Const @ByRef AttrSlice attrs, @StringPiece String attr_name,
                   @Const @ByPtrPtr NameAttrList value);  // type: "func"

// Computes the input and output types for a specific node.
// REQUIRES: ValidateOpDef(op_def).ok()
@Namespace("tensorflow") public static native @ByVal Status InOutTypesForNode(@Const @ByRef NodeDef node_def, @Const @ByRef OpDef op_def,
                         DataTypeVector inputs, DataTypeVector outputs);

// Validates that the NodeDef:
// * Defines all expected attrs from the OpDef.
// * All attrs satisfies constraints from the OpDef.
// * Has a signature matching SignatureForNode().
// etc.
@Namespace("tensorflow") public static native @ByVal Status ValidateNodeDef(@Const @ByRef NodeDef node_def, @Const @ByRef OpDef op_def);

// Computes the mapping from input/output argument name to the
// corresponding input/output index range.  For example,
// input "foo" corresponds to input indices
//   [ (*inputs)["foo"].first, (*inputs)["foo"].second ).
@Namespace("tensorflow") public static native @ByVal Status NameRangesForNode(@Const @ByRef NodeDef node_def, @Const @ByRef OpDef op_def,
                         NameRangeMap inputs, NameRangeMap outputs);

// Adds default values to *node_def for unspecified attrs from op_def.
@Namespace("tensorflow") public static native void AddDefaultsToNodeDef(@Const @ByRef OpDef op_def, NodeDef node_def);

// Validates the syntax of a NodeDef provided externally.
//
// The following is an EBNF-style syntax for NodeDef objects. Note that
// Node objects are actually specified as tensorflow::NodeDef protocol buffers,
// which contain many other fields that are not (currently) validated.
//
// Node         = NodeName, Inputs
// Inputs       = ( DataInput * ), ( ControlInput * )
// DataInput    = NodeName, ( ":", [1-9], [0-9] * ) ?
// ControlInput = "^", NodeName
// NodeName     = [A-Za-z0-9.], [A-Za-z0-9_./] *
@Namespace("tensorflow") public static native @ByVal Status ValidateExternalNodeDefSyntax(@Const @ByRef NodeDef node_def);

// Returns "status" with kernel's NodeDef attached as additional text
// in the error message.
@Namespace("tensorflow") public static native @ByVal Status AttachDef(@Const @ByRef Status status, @Const @ByRef NodeDef node_def);

  // namespace tensorflow

// #endif  // TENSORFLOW_FRAMEWORK_NODE_DEF_UTIL_H_


// Parsed from tensorflow/core/framework/selective_registration.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_FRAMEWORK_SELECTIVE_REGISTRATION_H_
// #define TENSORFLOW_FRAMEWORK_SELECTIVE_REGISTRATION_H_

// #include <string.h>

// #ifdef SELECTIVE_REGISTRATION

// Experimental selective registration support to reduce binary size.
//
// To use selective registration, when building:
// 1. define SELECTIVE_REGISTRATION, e.g. in gcc by passing
//    -DSELECTIVE_REGISTRATION to compilation.
// 2. Provide ops_to_register.h. This file is not included in the repo and must
//    be placed by the user or a tool where the compiler can find it.  It must
//    define the constants and functions used in the macros below. The
//    functions should be defined as valid constexpr functions, so that they are
//    evaluated at compile time: this is needed to make symbols referenced by
//    un-registered objects unused, and therefore allow the linker to strip them
//    out.
// #include "ops_to_register.h"

// Op kernel classes for which ShouldRegisterOpKernel returns false will not be
// registered.
// #define SHOULD_REGISTER_OP_KERNEL(clz)
//   (strstr(kNecessaryOpKernelClasses, "," clz ",") != nullptr)

// Ops for which ShouldRegisterOp returns false will not be registered.
// #define SHOULD_REGISTER_OP(op) ShouldRegisterOp(op)

// If kRequiresSymbolicGradients is false, then no gradient ops are registered.
// #define SHOULD_REGISTER_OP_GRADIENT kRequiresSymbolicGradients

// #else
// #define SHOULD_REGISTER_OP_KERNEL(filename) true
// #define SHOULD_REGISTER_OP(op) true
// #define SHOULD_REGISTER_OP_GRADIENT true
// #endif

// #endif  // TENSORFLOW_FRAMEWORK_SELECTIVE_REGISTRATION_H_


// Parsed from tensorflow/core/graph/node_builder.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_GRAPH_NODE_BUILDER_H_
// #define TENSORFLOW_GRAPH_NODE_BUILDER_H_

// #include <vector>
// #include "tensorflow/core/framework/node_def_builder.h"
// #include "tensorflow/core/framework/op.h"
// #include "tensorflow/core/framework/op_def.pb.h"
// #include "tensorflow/core/graph/graph.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"

// This is a helper for creating a Node and adding it to a Graph.
// Internally, it uses a NodeDefBuilder to automatically set attrs
// that can be inferred from the inputs, and use default values
// (where they exist) for unspecified attrs.  Example usage:
//
//  Node* node;
//  Status status = NodeBuilder(node_name, op_name)
//                           .Input(...)
//                           .Attr(...)
//                           .Finalize(&graph, &node);
//  if (!status.ok()) return status;
//  // Use node here.
@Namespace("tensorflow") @NoOffset public static class NodeBuilder extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public NodeBuilder(Pointer p) { super(p); }

  // For specifying the output of a Node to provide to one of the Input()
  // functions below.  It supports both regular inputs (where you are
  // connecting to an existing Node*), and inputs from outside the graph
  // (or haven't been added to the graph yet, like back edges, where
  // you don't have a Node*). Both types can be mixed, e.g. in an
  // ArraySlice.
  @NoOffset public static class NodeOut extends Pointer {
      static { Loader.load(); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public NodeOut(Pointer p) { super(p); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public NodeOut(long size) { super((Pointer)null); allocateArray(size); }
      private native void allocateArray(long size);
      @Override public NodeOut position(long position) {
          return (NodeOut)super.position(position);
      }
  
    // For referencing an existing Node.
    public NodeOut(Node n, int i/*=0*/) { super((Pointer)null); allocate(n, i); }
    private native void allocate(Node n, int i/*=0*/);
    public NodeOut(Node n) { super((Pointer)null); allocate(n); }
    private native void allocate(Node n);

    // For referencing Nodes not in the graph being built. It is
    // useful when preparing a graph for ExtendSession or creating a
    // back edge to a node that hasn't been added to the graph yet,
    // but will be.
    public NodeOut(@StringPiece BytePointer name, int i, @Cast("tensorflow::DataType") int t) { super((Pointer)null); allocate(name, i, t); }
    private native void allocate(@StringPiece BytePointer name, int i, @Cast("tensorflow::DataType") int t);
    public NodeOut(@StringPiece String name, int i, @Cast("tensorflow::DataType") int t) { super((Pointer)null); allocate(name, i, t); }
    private native void allocate(@StringPiece String name, int i, @Cast("tensorflow::DataType") int t);

    // Default constructor for std::vector<NodeOut>.
    public NodeOut() { super((Pointer)null); allocate(); }
    private native void allocate();

    public native Node node(); public native NodeOut node(Node node);
    // error is set to true if:
    // * the NodeOut was default constructed and never overwritten,
    // * a nullptr Node* was passed to the NodeOut constructor, or
    // * an out-of-range index was passed to the NodeOut constructor.
    public native @Cast("bool") boolean error(); public native NodeOut error(boolean error);
    public native @StdString BytePointer name(); public native NodeOut name(BytePointer name);
    public native int index(); public native NodeOut index(int index);
    public native @Cast("tensorflow::DataType") int dt(); public native NodeOut dt(int dt);
  }

  // Specify the name and the Op (either via an OpDef or the name of
  // the Op plus a registry) for the Node.  Other fields are
  // specified by calling the methods below.
  // REQUIRES: The OpDef must satisfy ValidateOpDef().
  public NodeBuilder(@StringPiece BytePointer name, @StringPiece BytePointer op_name,
                @Const OpRegistryInterface op_registry/*=tensorflow::OpRegistry::Global()*/) { super((Pointer)null); allocate(name, op_name, op_registry); }
  private native void allocate(@StringPiece BytePointer name, @StringPiece BytePointer op_name,
                @Const OpRegistryInterface op_registry/*=tensorflow::OpRegistry::Global()*/);
  public NodeBuilder(@StringPiece BytePointer name, @StringPiece BytePointer op_name) { super((Pointer)null); allocate(name, op_name); }
  private native void allocate(@StringPiece BytePointer name, @StringPiece BytePointer op_name);
  public NodeBuilder(@StringPiece String name, @StringPiece String op_name,
                @Const OpRegistryInterface op_registry/*=tensorflow::OpRegistry::Global()*/) { super((Pointer)null); allocate(name, op_name, op_registry); }
  private native void allocate(@StringPiece String name, @StringPiece String op_name,
                @Const OpRegistryInterface op_registry/*=tensorflow::OpRegistry::Global()*/);
  public NodeBuilder(@StringPiece String name, @StringPiece String op_name) { super((Pointer)null); allocate(name, op_name); }
  private native void allocate(@StringPiece String name, @StringPiece String op_name);
  public NodeBuilder(@StringPiece BytePointer name, @Const OpDef op_def) { super((Pointer)null); allocate(name, op_def); }
  private native void allocate(@StringPiece BytePointer name, @Const OpDef op_def);
  public NodeBuilder(@StringPiece String name, @Const OpDef op_def) { super((Pointer)null); allocate(name, op_def); }
  private native void allocate(@StringPiece String name, @Const OpDef op_def);

  // Create a NodeBuilder from an existing NodeDefBuilder.
  public NodeBuilder(@Const @ByRef NodeDefBuilder def_builder) { super((Pointer)null); allocate(def_builder); }
  private native void allocate(@Const @ByRef NodeDefBuilder def_builder);

  // You must call one Input() function per input_arg in the Op,
  // *and in the same order as the input_args appear in the OpDef.*

  // For inputs that take a single tensor.
  public native @ByRef NodeBuilder Input(Node src_node, int src_index/*=0*/);
  public native @ByRef NodeBuilder Input(Node src_node);
  public native @ByRef NodeBuilder Input(@ByVal NodeOut src);

  // For inputs that take a list of tensors.

  // Require that this node run after src_node(s).
  public native @ByRef NodeBuilder ControlInput(Node src_node);
  public native @ByRef NodeBuilder ControlInputs(@ByVal NodeVector src_nodes);

  // Sets the "requested device spec" in the NodeDef (not the
  // "assigned device" in the Node).
  public native @ByRef NodeBuilder Device(@StringPiece BytePointer device_spec);
  public native @ByRef NodeBuilder Device(@StringPiece String device_spec);

  // Set the value of an attr.  attr_name must match the name of one of
  // attrs defined by the Op, and value must have the corresponding type
  // (see SetAttrValue() in ../framework/attr_value_util.h for legal
  // types for value).  Note that attrs will be set automatically if
  // they can be determined by the inputs.

  // Validates the described node and adds it to *graph, adding edges
  // for all (non-back) inputs.  If created_node is not nullptr,
  // *created_node will be set to the new node (or nullptr on error).
  public native @ByVal Status Finalize(Graph graph, @Cast("tensorflow::Node**") PointerPointer created_node);
  public native @ByVal Status Finalize(Graph graph, @ByPtrPtr Node created_node);

  // Accessors for the values set in the constructor.
  public native @StdString BytePointer node_name();
  public native @Const @ByRef OpDef op_def();
}

// IMPLEMENTATION -------------------------------------------------------------





  // namespace tensorflow

// #endif  // TENSORFLOW_GRAPH_NODE_BUILDER_H_


// Parsed from tensorflow/core/graph/graph_def_builder.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_GRAPH_GRAPH_DEF_BUILDER_H_
// #define TENSORFLOW_GRAPH_GRAPH_DEF_BUILDER_H_

// #include <vector>
// #include "tensorflow/core/framework/graph.pb.h"
// #include "tensorflow/core/framework/op.h"
// #include "tensorflow/core/graph/graph.h"
// #include "tensorflow/core/graph/node_builder.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/core/stringpiece.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"

// Given a function like:
//   namespace ops {
//   Node* Identity(NodeOut input, const GraphDefBuilder::Options& opts) {
//     if (opts.HaveError()) return nullptr;
//     static const string kOpName = "Identity";
//     NodeBuilder node_builder(opts.GetNameForOp(kOpName), kOpName,
//                              opts.op_registry());
//     node_builder.Input(input);
//     return opts.FinalizeBuilder(&node_builder);
//   }
//   }  // namespace ops
//
//   // Or, alternatively:
//   namespace ops {
//   Node* Identity(NodeOut input, const GraphDefBuilder::Options& opts) {
//     static const string kOpName = "Identity";
//     return UnaryOp(kOpName, input, opts);
//   }
//   }  // namespace ops
//
// You call it like:
//   GraphDefBuilder b;
//   using namespace ::tensorflow::ops;  // NOLINT(build/namespaces)
//   Node* na = Const(7, b.opts());
//   // Note: WithName() returns a copy, opts is unchanged.
//   Node* nb = Const(5, b.opts().WithName("control-input"));
//   Node* nc = Identity(na, b.opts().WithControlInput(nb));
//   GraphDef graph_def;
//   Status status = b.ToGraphDef(&graph_def);
//   if (!status.ok()) { /* Handle error */ }
//
// In tests you can skip the status handling via:
//   GraphDefBuilder b(GraphDefBuilder::kFailImmediately);
//   ...
//   b.ToGraphDef(&graph_def);

@Namespace("tensorflow") @NoOffset public static class GraphDefBuilder extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public GraphDefBuilder(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public GraphDefBuilder(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public GraphDefBuilder position(long position) {
        return (GraphDefBuilder)super.position(position);
    }

  // Options for adding a Node to a Graph.
  @NoOffset public static class Options extends Pointer {
      static { Loader.load(); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Options(Pointer p) { super(p); }
  
    // Sets the Graph (that Nodes will be added to) and the status.  The
    // status may be set to nullptr, in which case errors cause CHECK
    // failures.  The graph and status must outlive *this.
    public Options(Graph graph, Status status) { super((Pointer)null); allocate(graph, status); }
    private native void allocate(Graph graph, Status status);

    // Methods for setting options.  These are const methods: they
    // return a copy of *this with the option set.
    public native @ByVal Options WithName(@StringPiece BytePointer name);
    public native @ByVal Options WithName(@StringPiece String name);
    public native @ByVal Options WithDevice(@StringPiece BytePointer device);
    public native @ByVal Options WithDevice(@StringPiece String device);
    public native @ByVal Options WithControlInput(Node control_input);
    public native @ByVal Options WithControlInputs(@ByVal NodeVector control_inputs);

    // Override the default value for an optional attr.
    public native @ByVal Options WithAttr(@StringPiece BytePointer attr_name, int value);
    public native @ByVal Options WithAttr(@StringPiece String attr_name, int value);
    public native @ByVal Options WithAttr(@StringPiece BytePointer attr_name, @ArraySlice IntPointer value);
    public native @ByVal Options WithAttr(@StringPiece String attr_name, @ArraySlice IntBuffer value);
    public native @ByVal Options WithAttr(@StringPiece BytePointer attr_name, @ArraySlice int... value);
    public native @ByVal Options WithAttr(@StringPiece String attr_name, @ArraySlice IntPointer value);
    public native @ByVal Options WithAttr(@StringPiece BytePointer attr_name, @ArraySlice IntBuffer value);
    public native @ByVal Options WithAttr(@StringPiece String attr_name, @ArraySlice int... value);
    public native @ByVal Options WithAttr(@StringPiece BytePointer attr_name, @Cast("long long") long value);
    public native @ByVal Options WithAttr(@StringPiece String attr_name, @Cast("long long") long value);
    public native @ByVal Options WithAttr(@StringPiece BytePointer attr_name, @Cast("long long*") @ArraySlice LongPointer value);
    public native @ByVal Options WithAttr(@StringPiece String attr_name, @Cast("long long*") @ArraySlice LongBuffer value);
    public native @ByVal Options WithAttr(@StringPiece BytePointer attr_name, @Cast("long long*") @ArraySlice long... value);
    public native @ByVal Options WithAttr(@StringPiece String attr_name, @Cast("long long*") @ArraySlice LongPointer value);
    public native @ByVal Options WithAttr(@StringPiece BytePointer attr_name, @Cast("long long*") @ArraySlice LongBuffer value);
    public native @ByVal Options WithAttr(@StringPiece String attr_name, @Cast("long long*") @ArraySlice long... value);
    public native @ByVal Options WithAttr(@StringPiece BytePointer attr_name, float value);
    public native @ByVal Options WithAttr(@StringPiece String attr_name, float value);
    public native @ByVal Options WithAttr(@StringPiece BytePointer attr_name, @ArraySlice FloatPointer value);
    public native @ByVal Options WithAttr(@StringPiece String attr_name, @ArraySlice FloatBuffer value);
    public native @ByVal Options WithAttr(@StringPiece BytePointer attr_name, @ArraySlice float... value);
    public native @ByVal Options WithAttr(@StringPiece String attr_name, @ArraySlice FloatPointer value);
    public native @ByVal Options WithAttr(@StringPiece BytePointer attr_name, @ArraySlice FloatBuffer value);
    public native @ByVal Options WithAttr(@StringPiece String attr_name, @ArraySlice float... value);
    public native @ByVal Options WithAttr(@StringPiece BytePointer attr_name, double value);
    public native @ByVal Options WithAttr(@StringPiece String attr_name, double value);
    public native @ByVal Options WithAttr(@StringPiece BytePointer attr_name, @ArraySlice DoublePointer value);
    public native @ByVal Options WithAttr(@StringPiece String attr_name, @ArraySlice DoubleBuffer value);
    public native @ByVal Options WithAttr(@StringPiece BytePointer attr_name, @ArraySlice double... value);
    public native @ByVal Options WithAttr(@StringPiece String attr_name, @ArraySlice DoublePointer value);
    public native @ByVal Options WithAttr(@StringPiece BytePointer attr_name, @ArraySlice DoubleBuffer value);
    public native @ByVal Options WithAttr(@StringPiece String attr_name, @ArraySlice double... value);
    public native @ByVal Options WithAttr(@StringPiece BytePointer attr_name, @Cast("bool") boolean value);
    public native @ByVal Options WithAttr(@StringPiece String attr_name, @Cast("bool") boolean value);
    public native @ByVal Options WithAttr(@StringPiece BytePointer attr_name, @Cast("bool*") @ArraySlice BoolPointer value);
    public native @ByVal Options WithAttr(@StringPiece String attr_name, @Cast("bool*") @ArraySlice boolean... value);
    public native @ByVal Options WithAttr(@StringPiece BytePointer attr_name, @StdString BytePointer value);
    public native @ByVal Options WithAttr(@StringPiece String attr_name, @StdString String value);
    public native @ByVal Options WithAttr(@StringPiece BytePointer attr_name, @ByVal @Cast("tensorflow::gtl::ArraySlice<std::string>*") StringVector value);
    public native @ByVal Options WithAttr(@StringPiece String attr_name, @ByVal @Cast("tensorflow::gtl::ArraySlice<std::string>*") StringVector value);
    public native @ByVal Options WithAttr(@StringPiece BytePointer attr_name, @ByVal Tensor value);
    public native @ByVal Options WithAttr(@StringPiece String attr_name, @ByVal Tensor value);
    public native @ByVal Options WithAttr(@StringPiece BytePointer attr_name, @ByVal TensorVector value);
    public native @ByVal Options WithAttr(@StringPiece String attr_name, @ByVal TensorVector value);
    public native @ByVal Options WithAttr(@StringPiece BytePointer attr_name, @ByVal TensorProto value);
    public native @ByVal Options WithAttr(@StringPiece String attr_name, @ByVal TensorProto value);
    public native @ByVal Options WithAttr(@StringPiece BytePointer attr_name, @ByVal TensorProtoVector value);
    public native @ByVal Options WithAttr(@StringPiece String attr_name, @ByVal TensorProtoVector value);
    public native @ByVal Options WithAttr(@StringPiece BytePointer attr_name, @ByVal TensorShape value);
    public native @ByVal Options WithAttr(@StringPiece String attr_name, @ByVal TensorShape value);
    public native @ByVal Options WithAttr(@StringPiece BytePointer attr_name, @ByVal @Cast("tensorflow::gtl::ArraySlice<tensorflow::TensorShape>*") TensorShapeVector value);
    public native @ByVal Options WithAttr(@StringPiece String attr_name, @ByVal @Cast("tensorflow::gtl::ArraySlice<tensorflow::TensorShape>*") TensorShapeVector value);
    public native @ByVal Options WithAttr(@StringPiece BytePointer attr_name, @ByVal NameAttrList value);
    public native @ByVal Options WithAttr(@StringPiece String attr_name, @ByVal NameAttrList value);
    // Note: overload needed to allow {...} expressions for value.

    // Methods for using options from a function that creates a Node.

    // Returns true if the status associated with *this has an error.
    // Use this to skip processing that may depend on prior results.
    public native @Cast("bool") boolean HaveError();

    // Given the Op type name, return a name for a node of that type.
    // Uses the value set in WithName() if that has been called.  Otherwise,
    // returns a name built out of the Op type name.
    public native @StdString BytePointer GetNameForOp(@StringPiece BytePointer op);
    public native @StdString String GetNameForOp(@StringPiece String op);

    // Sets the device, adds control inputs, adds attrs, and calls Finalize().
    // If Finalize returns an error, it is saved and this function returns
    // nullptr.
    public native Node FinalizeBuilder(NodeBuilder builder);

    // Updates the associated status, if any, or calls TF_CHECK_OK if none.
    public native void UpdateStatus(@Const @ByRef Status status);

    // Accessor
    public native @Const OpRegistryInterface op_registry();
  }

  // Start building a new graph.
  public GraphDefBuilder(
        @Const OpRegistryInterface op_registry/*=tensorflow::OpRegistry::Global()*/) { super((Pointer)null); allocate(op_registry); }
  private native void allocate(
        @Const OpRegistryInterface op_registry/*=tensorflow::OpRegistry::Global()*/);
  public GraphDefBuilder() { super((Pointer)null); allocate(); }
  private native void allocate();

  // For use in tests, where you want to fail immediately on error instead
  // of checking the status at the end.
  /** enum tensorflow::GraphDefBuilder::TestFailImmediatelyType */
  public static final int kFailImmediately = 0;
  public GraphDefBuilder(
        @Cast("tensorflow::GraphDefBuilder::TestFailImmediatelyType") int arg0,
        @Const OpRegistryInterface op_registry/*=tensorflow::OpRegistry::Global()*/) { super((Pointer)null); allocate(arg0, op_registry); }
  private native void allocate(
        @Cast("tensorflow::GraphDefBuilder::TestFailImmediatelyType") int arg0,
        @Const OpRegistryInterface op_registry/*=tensorflow::OpRegistry::Global()*/);
  public GraphDefBuilder(
        @Cast("tensorflow::GraphDefBuilder::TestFailImmediatelyType") int arg0) { super((Pointer)null); allocate(arg0); }
  private native void allocate(
        @Cast("tensorflow::GraphDefBuilder::TestFailImmediatelyType") int arg0);

  // Gets the Options with the associated Graph and Status.
  public native @Const @ByRef Options opts();

  // Once all the nodes have been added, call this to get whether it was
  // successful, and if so fill *graph_def.
  public native @ByVal Status ToGraphDef(GraphDef graph_def);

  // Like ToGraphDef(), but converts to a Graph (using the default
  // GraphConstructorOptions).
  // TODO(josh11b): Make this faster; right now it converts
  // Graph->GraphDef->Graph.  This cleans up the graph (e.g. adds
  // edges from the source and to the sink node, resolves back edges
  // by name), and makes sure the resulting graph is valid.
  public native @ByVal Status ToGraph(Graph graph);
}

// A NodeOut may either be a regular input or back input.  Regular
// inputs are specified via either a Node* or a Node* and an output
// index.  Back inputs are specified by a node name, output index, and
// output type.

// For adding an Op with no inputs to a GraphDefBuilder.
@Namespace("tensorflow::ops") public static native Node SourceOp(@StdString BytePointer op_name, @Const @ByRef GraphDefBuilder.Options opts);
@Namespace("tensorflow::ops") public static native Node SourceOp(@StdString String op_name, @Const @ByRef GraphDefBuilder.Options opts);

// For adding an Op with one input to a GraphDefBuilder.
@Namespace("tensorflow::ops") public static native Node UnaryOp(@StdString BytePointer op_name, @ByVal NodeBuilder.NodeOut input,
              @Const @ByRef GraphDefBuilder.Options opts);
@Namespace("tensorflow::ops") public static native Node UnaryOp(@StdString String op_name, Node input,
              @Const @ByRef GraphDefBuilder.Options opts);

// For adding an Op with two inputs to a GraphDefBuilder.
@Namespace("tensorflow::ops") public static native Node BinaryOp(@StdString BytePointer op_name, @ByVal NodeBuilder.NodeOut a, @ByVal NodeBuilder.NodeOut b,
               @Const @ByRef GraphDefBuilder.Options opts);
@Namespace("tensorflow::ops") public static native Node BinaryOp(@StdString String op_name, Node a, Node b,
               @Const @ByRef GraphDefBuilder.Options opts);

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_GRAPH_GRAPH_DEF_BUILDER_H_


// Parsed from tensorflow/core/graph/default_device.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_GRAPH_DEFAULT_DEVICE_H_
// #define TENSORFLOW_GRAPH_DEFAULT_DEVICE_H_

// #include <string>

// #include "tensorflow/core/framework/graph.pb.h"

// Sets the default device for all nodes in graph_def to "device",
// only if not already set.
@Namespace("tensorflow::graph") public static native void SetDefaultDevice(@StdString BytePointer device, GraphDef graph_def);
@Namespace("tensorflow::graph") public static native void SetDefaultDevice(@StdString String device, GraphDef graph_def);

  // namespace graph
  // namespace tensorflow

// #endif  // TENSORFLOW_GRAPH_DEFAULT_DEVICE_H_


// Parsed from tensorflow/core/graph/graph_constructor.h

/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef TENSORFLOW_GRAPH_GRAPH_CONSTRUCTOR_H_
// #define TENSORFLOW_GRAPH_GRAPH_CONSTRUCTOR_H_

// #include "tensorflow/core/framework/graph.pb.h"
// #include "tensorflow/core/graph/graph.h"
// #include "tensorflow/core/lib/core/status.h"
@Namespace("tensorflow") @Opaque public static class ShapeRefiner extends Pointer {
    /** Empty constructor. Calls {@code super((Pointer)null)}. */
    public ShapeRefiner() { super((Pointer)null); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ShapeRefiner(Pointer p) { super(p); }
}

// Options specific to constant folding optimizations.
//
// TODO(ashankar,vrv): This should move to where constant folding is done.
@Namespace("tensorflow") public static class ConstantFoldingOptions extends Pointer {
    static { Loader.load(); }
    /** Default native constructor. */
    public ConstantFoldingOptions() { super((Pointer)null); allocate(); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public ConstantFoldingOptions(long size) { super((Pointer)null); allocateArray(size); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ConstantFoldingOptions(Pointer p) { super(p); }
    private native void allocate();
    private native void allocateArray(long size);
    @Override public ConstantFoldingOptions position(long position) {
        return (ConstantFoldingOptions)super.position(position);
    }

  // If "consider" is not a nullptr, then only constant fold a node "n" if
  // consider(n) returns true.
  @MemberSetter public native ConstantFoldingOptions consider(@ByVal ConsiderFunction consider);
}

// Construct a Graph *g out of a GraphDef gdef. Returns non-OK on
// error, in which case *g is left in an incomplete state.
//
// *g is expected to be an empty graph (with no more than a source and sink
// nodes) when provided to ConvertGraphDefToGraph. To enhance an existing Graph,
// see ImportGraphDef.
@Namespace("tensorflow") @NoOffset public static class GraphConstructorOptions extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public GraphConstructorOptions(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public GraphConstructorOptions(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public GraphConstructorOptions position(long position) {
        return (GraphConstructorOptions)super.position(position);
    }

  public GraphConstructorOptions() { super((Pointer)null); allocate(); }
  private native void allocate();

  // If true, allows internal ops in the GraphDef.
  public native @Cast("bool") boolean allow_internal_ops(); public native GraphConstructorOptions allow_internal_ops(boolean allow_internal_ops);

  // If true, the graph def is expected to have fully specified
  // devices for all nodes. A node in the resulting graph "g" has the
  // device name set accordingly.
  //
  // TODO(zhifengc): if possible, consider removing this option.
  public native @Cast("bool") boolean expect_device_spec(); public native GraphConstructorOptions expect_device_spec(boolean expect_device_spec);
}
@Namespace("tensorflow") public static native @ByVal Status ConvertGraphDefToGraph(@Const @ByRef GraphConstructorOptions opts,
                                     @Const @ByRef GraphDef gdef, Graph g);

// Add the graph in GraphDef gdef into an existing Graph *g.
//
// On error, returns non-OK and leaves *g unmodified.
//
// "shape_refiner" can be null. It should be non-null if the caller
// intends to add additonal nodes to the graph after the import. This
// allows the caller to validate shapes of those nodes (since
// ShapeRefiner::AddNode must be called in topological order).
//
// TODO(ashankar): Push this mechanism and get rid of Session::Extend()
// as a means of enhancing an existing Graph.
@Namespace("tensorflow") @NoOffset public static class ImportGraphDefOptions extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ImportGraphDefOptions(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public ImportGraphDefOptions(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public ImportGraphDefOptions position(long position) {
        return (ImportGraphDefOptions)super.position(position);
    }

  public ImportGraphDefOptions() { super((Pointer)null); allocate(); }
  private native void allocate();

  // Name prefix to use for nodes imported from the GraphDef.  For example, if
  // prefix="animals" and GraphDef contains a node "bunny" then the node will be
  // named "animals/bunny" in *g.
  public native @StdString BytePointer prefix(); public native ImportGraphDefOptions prefix(BytePointer prefix);

  // TODO(ashankar): Enable node rebinding (in Python's import_graph_def
  // this is achieved by providing an input_map).
  //
  // TODO(ashankar): Enable handling of GraphDefs produced by newer binaries
  // with ops that are not defined in the binary calling ImportGraphDef.
  // Similar to the producer_op_list argument to import_graph_def in the
  // python API.
}
@Namespace("tensorflow") public static native @ByVal Status ImportGraphDef(@Const @ByRef ImportGraphDefOptions opts,
                             @Const @ByRef GraphDef gdef, Graph g,
                             ShapeRefiner refiner);

// Make a copy of "src" into "*dest".
//
// REQUIRES: "*dest" is a freshly allocated graph without any nodes or edges
// other than the implicit Source/Sink nodes.
@Namespace("tensorflow") public static native void CopyGraph(@Const @ByRef Graph src, Graph dest);

  // namespace tensorflow

// #endif  // TENSORFLOW_GRAPH_GRAPH_CONSTRUCTOR_H_


// Parsed from tensorflow/cc/framework/scope.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef THIRD_PARTY_TENSORFLOW_CC_FRAMEWORK_SCOPE_H_
// #define THIRD_PARTY_TENSORFLOW_CC_FRAMEWORK_SCOPE_H_

// #include <memory>
// #include <string>
// #include <unordered_map>
// #include <unordered_set>
// #include <vector>

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/core/common_runtime/shape_refiner.h"
// #include "tensorflow/core/lib/core/status.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"

// A `Scope` object represents a set of related TensorFlow ops that have the
// same properties such as a common name prefix.
// A Scope object is a container for TensorFlow Op properties. Op constructors
// get a Scope object as a mandatory first argument and the constructed op
// acquires the properties in the object.
//
// A simple example:
//
// using namespace ops;
// Scope root = Scope::NewRootScope();
// auto c1 = Const(root, {{1, 1}});
// auto m = MatMul(root, c1, {{41}, {1}});
// GraphDef gdef;
// Status s = root.ToGraphDef(&gdef);
// if (!s.ok()) { /* Handle error */ }
//
// Scope hierarchy:
// The Scope class provides various With<> functions that create a new scope.
// The new scope typically has one property changed while other properties are
// inherited from the parent scope.
// NewSubScope(name) method appends `name` to the prefix of names for ops
// created within the scope, and WithOpName() changes the suffix which
// otherwise defaults to the type of the op.
//
// Name examples:
// Scope root = Scope::NewRootScope();
// Scope linear = root.NewSubScope("linear");
// /* W will be named "linear/W" */
// auto W = Variable(linear.WithOpName("W"),
//                   {2, 2}, DT_FLOAT);
// /* b will be named "linear/b" */
// auto b = Variable(linear.WithOpName("b"),
//                   {2}, DT_FLOAT);
// auto x = Const(linear, {...});  // name: "linear/Const"
// auto m = MatMul(linear, x, W);  // name: "linear/MatMul"
// auto r = BiasAdd(linear, m, b); // name: "linear/BiasAdd"
//
// Scope lifetime:
// A new scope is created by calling Scope::NewRootScope. This creates some
// resources that are shared by all the child scopes that inherit from this
// scope, directly or transitively. For instance, a new scope creates a new
// Graph object to which operations are added when the new scope or its children
// are used by an Op constructor. The new scope also has a Status object which
// will be used to indicate errors by Op-constructor functions called on any
// child scope. The Op-constructor functions have to check the scope's status by
// calling the ok() method before proceeding to construct the op.
//
// Thread safety:
// A `Scope` object is NOT thread-safe. Threads cannot concurrently call
// op-constructor functions on the same `Scope` object.
@Namespace("tensorflow") @NoOffset public static class Scope extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Scope(Pointer p) { super(p); }

  // The following functions are for users making graphs. They return brand new
  // scopes, or scopes derived from an existing scope object.

  // Return a new scope.
  // This creates a new graph and all operations constructed in this graph
  // should use the returned object as the "root" scope.
  public static native @ByVal Scope NewRootScope();

  // Return a new scope. Ops created with this scope will have
  // <name>/<child_scope_name> as the prefix. The actual name will be unique
  // in the current scope. All other properties are inherited from the current
  // scope. If child_scope_name is empty, the '/' is elided.
  public native @ByVal Scope NewSubScope(@StdString BytePointer child_scope_name);
  public native @ByVal Scope NewSubScope(@StdString String child_scope_name);

  // Return a new scope. All ops created within the returned scope will have
  // names of the form <name>/<op_name>[_<suffix].
  public native @ByVal Scope WithOpName(@StdString BytePointer op_name);
  public native @ByVal Scope WithOpName(@StdString String op_name);

  // Return a new scope. All ops created within the returned scope will have as
  // control dependencies the union of operations in the control_deps vector and
  // the control dependencies of the current scope.
  public native @ByVal Scope WithControlDependencies(
        @ArraySlice Operation control_deps);
  // Same as above, but convenient to add control dependency on the operation
  // producing the control_dep output.
  public native @ByVal Scope WithControlDependencies(@Const @ByRef Output control_dep);

  // Return a new scope. All ops created within the returned scope will have no
  // control dependencies on other operations.
  public native @ByVal Scope WithNoControlDependencies();

  // Return a new scope. All ops created within the returned scope will have the
  // device field set to 'device'.
  public native @ByVal Scope WithDevice(@StdString BytePointer device);
  public native @ByVal Scope WithDevice(@StdString String device);

  // Return a new scope. All ops created within the returned scope will be
  // co-located on the device where op is placed.
  // NOTE: This function is intended to be use internal libraries only for
  // controlling placement of ops on to devices. Public use is not encouraged
  // because the implementation of device placement is subject to change.
  public native @ByVal Scope ColocateWith(@Const @ByRef Operation op);
  // Convenience function for above.
  public native @ByVal Scope ColocateWith(@Const @ByRef Output out);
  // Clear all colocation constraints.
  public native @ByVal Scope ClearColocation();

  // Return a new scope. The op-constructor functions taking the returned scope
  // as the scope argument will exit as soon as an error is detected, instead of
  // setting the status on the scope.
  public native @ByVal Scope ExitOnError();

  // Return a new scope. All ops created with the new scope will have
  // kernel_label as the value for their '_kernel' attribute;
  public native @ByVal Scope WithKernelLabel(@StdString BytePointer kernel_label);
  public native @ByVal Scope WithKernelLabel(@StdString String kernel_label);

  // The following functions are for scope object consumers.

  // Return a unique name, using default_name if an op name has not been
  // specified.
  public native @StdString BytePointer GetUniqueNameForOp(@StdString BytePointer default_name);
  public native @StdString String GetUniqueNameForOp(@StdString String default_name);

  // Update the status on this scope.
  // Note: The status object is shared between all children of this scope.
  // If the resulting status is not Status::OK() and exit_on_error_ is set on
  // this scope, this function exits by calling LOG(FATAL).
  public native void UpdateStatus(@Const @ByVal Status s);

  // Update the builder with properties accumulated in this scope.
  public native void UpdateBuilder(NodeBuilder builder);

  public native @Cast("bool") boolean ok();

  public native Graph graph();

  public native ShapeRefiner refiner();

  public native @SharedPtr Graph graph_as_shared_ptr();

  public native @ByVal Status status();

  // If status() is Status::OK(), convert the Graph object stored in this scope
  // to a GraphDef proto and return Status::OK(). Otherwise, return the error
  // status as is without performing GraphDef conversion.
  public native @ByVal Status ToGraphDef(GraphDef gdef);

  // If status() is Status::OK(), construct a Graph object using the default
  // GraphConstructorOptions, and return Status::OK if graph construction was
  // successful. Otherwise, return the error status.
  // TODO(josh11b, keveman): Make this faster; right now it converts
  // Graph->GraphDef->Graph.  This cleans up the graph (e.g. adds
  // edges from the source and to the sink node, resolves back edges
  // by name), and makes sure the resulting graph is valid.
  public native @ByVal Status ToGraph(Graph g);

  public native @StdVector Operation control_deps();
}

// A helper struct to hold the scopes that would be used by a function
// constructing a composite op.

  // namespace tensorflow

// #endif  // THIRD_PARTY_TENSORFLOW_CC_FRAMEWORK_SCOPE_H_


// Parsed from tensorflow/cc/framework/ops.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef THIRD_PARTY_TENSORFLOW_CC_FRAMEWORK_OPS_H_
// #define THIRD_PARTY_TENSORFLOW_CC_FRAMEWORK_OPS_H_

// #include <type_traits>

// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor.pb.h"
// #include "tensorflow/core/graph/graph.h"
// #include "tensorflow/core/lib/hash/hash.h"
// #include "tensorflow/core/lib/strings/strcat.h"

// Represents a node in the computation graph.
@Namespace("tensorflow::ops") @NoOffset public static class Operation extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Operation(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public Operation(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public Operation position(long position) {
        return (Operation)super.position(position);
    }

  public Operation() { super((Pointer)null); allocate(); }
  private native void allocate();
  public Operation(Node n) { super((Pointer)null); allocate(n); }
  private native void allocate(Node n);

  public native int num_inputs();
  public native @Cast("tensorflow::DataType") int input_type(int o);
  public native @ByVal Output input(int i);

  public native int num_outputs();
  public native @Cast("tensorflow::DataType") int output_type(int o);
  public native @ByVal Output output(int i);

  public native Node node();

  public native @Cast("tensorflow::uint64") long hash(@Cast("tensorflow::int64") long index);

  public native @Cast("bool") @Name("operator ==") boolean equals(@Const @ByRef Operation other);
}

// Represents a tensor value produced by an Operation.
@Namespace("tensorflow::ops") @NoOffset public static class Output extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Output(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public Output(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public Output position(long position) {
        return (Output)super.position(position);
    }

  public Output() { super((Pointer)null); allocate(); }
  private native void allocate();
  public Output(Node n) { super((Pointer)null); allocate(n); }
  private native void allocate(Node n);
  public Output(Node n, @Cast("tensorflow::int64") long index) { super((Pointer)null); allocate(n, index); }
  private native void allocate(Node n, @Cast("tensorflow::int64") long index);
  public Output(@Const @ByRef Operation op, @Cast("tensorflow::int64") long index) { super((Pointer)null); allocate(op, index); }
  private native void allocate(@Const @ByRef Operation op, @Cast("tensorflow::int64") long index);

  public native @ByVal Operation op();
  public native Node node();
  public native @Cast("tensorflow::int64") long index();
  public native @Cast("tensorflow::DataType") int type();
  public native @StdString BytePointer name();
  public native @Cast("bool") @Name("operator ==") boolean equals(@Const @ByRef Output other);

  public native @Cast("tensorflow::uint64") long hash();
}

@Namespace("tensorflow::ops") public static class OutputHash extends Pointer {
    static { Loader.load(); }
    /** Default native constructor. */
    public OutputHash() { super((Pointer)null); allocate(); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public OutputHash(long size) { super((Pointer)null); allocateArray(size); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public OutputHash(Pointer p) { super(p); }
    private native void allocate();
    private native void allocateArray(long size);
    @Override public OutputHash position(long position) {
        return (OutputHash)super.position(position);
    }

  public native @Cast("std::size_t") @Name("operator ()") long apply(@Const @ByRef Output output);
}

// Represents a tensor value that can be used as an operand to an Operation.
@Namespace("tensorflow::ops") @NoOffset public static class Input extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Input(Pointer p) { super(p); }

  // Initializer enables constructing an Input object from various kinds of C++
  // constants such as simple primitive constants and nested initializer lists
  // representing a multi-dimensional array. Initializer constructors are all
  // templates, so the aforementioned kinds of C++ constants can be used to
  // construct an Initializer. Intializer stores the value it got constructed
  // with in a Tensor object.
  @NoOffset public static class Initializer extends Pointer {
      static { Loader.load(); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Initializer(Pointer p) { super(p); }
  
    // Construct from a scalar value of an arithmetic type or a type that can be
    // converted to a string (eg. a string literal).

    public Initializer(@Const @ByRef Tensor t) { super((Pointer)null); allocate(t); }
    private native void allocate(@Const @ByRef Tensor t);  // NOLINT(runtime/explicit)

    // Construct from a scalar value and an explicit shape

    // Construct from a initializer list of scalars (a one-dimensional tensor).

    // Construct from a initializer list of scalars and an explicit shape.

    // Construct a multi-dimensional tensor from a nested initializer list. Note
    // that C++ syntax allows nesting of arbitrarily typed intializer lists, so
    // such invalid initializers cannot be disallowed at compile time. This
    // function performs checks to make sure that the nested initializer list is
    // indeed a valid multi-dimensional tensor.

    public native @ByVal TensorProto AsTensorProto();

    public native @ByRef Status status(); public native Initializer status(Status status);
    public native @ByRef Tensor tensor(); public native Initializer tensor(Tensor tensor);
  }

  // All of Input's constructors are implicit. Input can be implicitly
  // constructed from the following objects :
  // * Output: This is so that the output of an Operation can be directly used
  //   as the input to a op wrapper, which takes Inputs.
  // * A scalar, or a multi-dimensional tensor specified as a recursive
  //   initializer list. This enables directly passing constants as
  //   inputs to op wrappers.
  public Input(@Const @ByRef Output o) { super((Pointer)null); allocate(o); }
  private native void allocate(@Const @ByRef Output o);  // NOLINT(runtime/explicit)

  public Input(@Const @ByRef Input.Initializer init) { super((Pointer)null); allocate(init); }
  private native void allocate(@Const @ByRef Input.Initializer init);
  public Input(@ByRef Tensor init) { super((Pointer)null); allocate(init); }
  private native void allocate(@ByRef Tensor init);
  public Input(byte init) { super((Pointer)null); allocate(init); }
  private native void allocate(byte init);
  public Input(short init) { super((Pointer)null); allocate(init); }
  private native void allocate(short init);
  public Input(int init) { super((Pointer)null); allocate(init); }
  private native void allocate(int init);
  public Input(long init) { super((Pointer)null); allocate(init); }
  private native void allocate(long init);
  public Input(float init) { super((Pointer)null); allocate(init); }
  private native void allocate(float init);
  public Input(double init) { super((Pointer)null); allocate(init); }
  private native void allocate(double init);
  public Input(boolean init) { super((Pointer)null); allocate(init); }
  private native void allocate(boolean init);
  public Input(@StdString String init) { super((Pointer)null); allocate(init); }
  private native void allocate(@StdString String init);
  public Input(@StdString BytePointer init) { super((Pointer)null); allocate(init); }
  private native void allocate(@StdString BytePointer init);

  // Constructor specifying a node name, index and datatype. This should only be
  // used for specifying a backward edge, needed by control flow.
  public Input(@StdString BytePointer name, int i, @Cast("tensorflow::DataType") int dt) { super((Pointer)null); allocate(name, i, dt); }
  private native void allocate(@StdString BytePointer name, int i, @Cast("tensorflow::DataType") int dt);
  public Input(@StdString String name, int i, @Cast("tensorflow::DataType") int dt) { super((Pointer)null); allocate(name, i, dt); }
  private native void allocate(@StdString String name, int i, @Cast("tensorflow::DataType") int dt);

  public native Node node();
  public native @StdString BytePointer node_name();
  public native int index();
  public native @Cast("tensorflow::DataType") int data_type();
  public native @ByVal Status status();
  public native @Const @ByRef Tensor tensor();
}

// A type for representing the output of ops that produce more than one output,
// or a list of tensors.

// A type for representing the input to ops that require a list of tensors.
@Namespace("tensorflow::ops") @NoOffset public static class InputList extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public InputList(Pointer p) { super(p); }

  // Implicitly convert a list of outputs to a list of inputs. This is useful to
  // write code such as tf.Concat(tf.Split(x, 4)).
  public InputList(@Cast("const tensorflow::ops::OutputList*") @ByRef StringVector out) { super((Pointer)null); allocate(out); }
  private native void allocate(@Cast("const tensorflow::ops::OutputList*") @ByRef StringVector out);

  public InputList(@ArraySlice Input inputs) { super((Pointer)null); allocate(inputs); }
  private native void allocate(@ArraySlice Input inputs);
}

  // namespace ops
  // namespace tensorflow

// #endif  // THIRD_PARTY_TENSORFLOW_CC_FRAMEWORK_OPS_H_


// Parsed from tensorflow/cc/framework/cc_op_gen.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef THIRD_PARTY_TENSORFLOW_CC_FRAMEWORK_CC_OP_GEN_H_
// #define THIRD_PARTY_TENSORFLOW_CC_FRAMEWORK_CC_OP_GEN_H_

// #include "tensorflow/core/framework/op_def.pb.h"

// Result is written to files dot_h and dot_cc.
@Namespace("tensorflow") public static native void WriteCCOps(@Const @ByRef OpList ops, @StdString BytePointer dot_h_fname,
                @StdString BytePointer dot_cc_fname);
@Namespace("tensorflow") public static native void WriteCCOps(@Const @ByRef OpList ops, @StdString String dot_h_fname,
                @StdString String dot_cc_fname);

  // namespace tensorflow

// #endif  // THIRD_PARTY_TENSORFLOW_CC_FRAMEWORK_CC_OP_GEN_H_


// Parsed from tensorflow/cc/ops/standard_ops.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef THIRD_PARTY_TENSORFLOW_CC_OPS_STANDARD_OPS_H_
// #define THIRD_PARTY_TENSORFLOW_CC_OPS_STANDARD_OPS_H_

// #include "tensorflow/cc/ops/array_ops.h"
// #include "tensorflow/cc/ops/candidate_sampling_ops.h"
// #include "tensorflow/cc/ops/const_op.h"
// #include "tensorflow/cc/ops/control_flow_ops.h"
// #include "tensorflow/cc/ops/data_flow_ops.h"
// #include "tensorflow/cc/ops/image_ops.h"
// #include "tensorflow/cc/ops/io_ops.h"
// #include "tensorflow/cc/ops/linalg_ops.h"
// #include "tensorflow/cc/ops/logging_ops.h"
// #include "tensorflow/cc/ops/math_ops.h"
// #include "tensorflow/cc/ops/nn_ops.h"
// #include "tensorflow/cc/ops/no_op.h"
// #include "tensorflow/cc/ops/parsing_ops.h"
// #include "tensorflow/cc/ops/random_ops.h"
// #include "tensorflow/cc/ops/sparse_ops.h"
// #include "tensorflow/cc/ops/state_ops.h"
// #include "tensorflow/cc/ops/string_ops.h"
// #include "tensorflow/cc/ops/training_ops.h"
// #include "tensorflow/cc/ops/user_ops.h"

// #endif  // THIRD_PARTY_TENSORFLOW_CC_OPS_STANDARD_OPS_H_


// Parsed from tensorflow/cc/ops/const_op.h

/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// #ifndef THIRD_PARTY_TENSORFLOW_CC_OPS_CONST_OP_H_
// #define THIRD_PARTY_TENSORFLOW_CC_OPS_CONST_OP_H_

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/graph/node_builder.h"

@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, @Const @ByRef Input.Initializer val);
@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, @ByRef Tensor val);
@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, byte val);
@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, short val);
@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, int val);
@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, long val);
@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, float val);
@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, double val);
@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, boolean val);
@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, @StdString String val);
@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, @StdString BytePointer val);

@Namespace("tensorflow::ops") public static native @ByVal NodeBuilder.NodeOut AsNodeOut(@Const @ByRef Scope scope, @Const @ByRef Input inp);

@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, @Cast("const unsigned char") byte v, @Const @ByVal TensorShape shape);

@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, short v, @Const @ByVal TensorShape shape);

@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, int v, @Const @ByVal TensorShape shape);

@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, @Cast("const long long") long v, @Const @ByVal TensorShape shape);

@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, float v, @Const @ByVal TensorShape shape);

@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, double v, @Const @ByVal TensorShape shape);

@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, @Cast("const bool") boolean v, @Const @ByVal TensorShape shape);

@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, @StdString BytePointer v, @Const @ByVal TensorShape shape);
@Namespace("tensorflow::ops") public static native @ByVal Output Const(@Const @ByRef Scope scope, @StdString String v, @Const @ByVal TensorShape shape);

@Namespace("tensorflow::ops") public static native @ByVal NodeOutVector AsNodeOutList(@Const @ByRef Scope scope,
                                                @Const @ByRef InputList inp);

  // namespace ops
  // namespace tensorflow

// #endif  // THIRD_PARTY_TENSORFLOW_CC_OPS_CONST_OP_H_


// Parsed from tensorflow/cc/ops/array_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_ARRAY_OPS_H_
// #define TENSORFLOW_CC_OPS_ARRAY_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"

// TODO: add doc.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class BatchMatrixBandPart extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public BatchMatrixBandPart(Pointer p) { super(p); }

  public BatchMatrixBandPart(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input num_lower,
                      @ByVal Input num_upper) { super((Pointer)null); allocate(scope, input, num_lower, num_upper); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input num_lower,
                      @ByVal Input num_upper);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output band(); public native BatchMatrixBandPart band(Output band);
}

// TODO: add doc.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class BatchMatrixDiag extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public BatchMatrixDiag(Pointer p) { super(p); }

  public BatchMatrixDiag(@Const @ByRef Scope scope, @ByVal Input diagonal) { super((Pointer)null); allocate(scope, diagonal); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input diagonal);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native BatchMatrixDiag output(Output output);
}

// TODO: add doc.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class BatchMatrixDiagPart extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public BatchMatrixDiagPart(Pointer p) { super(p); }

  public BatchMatrixDiagPart(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output diagonal(); public native BatchMatrixDiagPart diagonal(Output diagonal);
}

// TODO: add doc.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class BatchMatrixSetDiag extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public BatchMatrixSetDiag(Pointer p) { super(p); }

  public BatchMatrixSetDiag(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input diagonal) { super((Pointer)null); allocate(scope, input, diagonal); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input diagonal);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native BatchMatrixSetDiag output(Output output);
}

// BatchToSpace for 4-D tensors of type T.
//
// This is a legacy version of the more general BatchToSpaceND.
//
// Rearranges (permutes) data from batch into blocks of spatial data, followed by
// cropping. This is the reverse transformation of SpaceToBatch. More specifically,
// this op outputs a copy of the input tensor where values from the `batch`
// dimension are moved in spatial blocks to the `height` and `width` dimensions,
// followed by cropping along the `height` and `width` dimensions.
//
// Arguments:
// * scope: A Scope object
// * input: 4-D tensor with shape
// `[batch*block_size*block_size, height_pad/block_size, width_pad/block_size,
//   depth]`. Note that the batch size of the input tensor must be divisible by
// `block_size * block_size`.
// * crops: 2-D tensor of non-negative integers with shape `[2, 2]`. It specifies
// how many elements to crop from the intermediate result across the spatial
// dimensions as follows:
//
//     crops = [[crop_top, crop_bottom], [crop_left, crop_right]]
@Namespace("tensorflow::ops") @NoOffset public static class BatchToSpace extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public BatchToSpace(Pointer p) { super(p); }

  public BatchToSpace(@Const @ByRef Scope scope, @ByVal Input input,
               @ByVal Input crops, @Cast("tensorflow::int64") long block_size) { super((Pointer)null); allocate(scope, input, crops, block_size); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
               @ByVal Input crops, @Cast("tensorflow::int64") long block_size);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native BatchToSpace output(Output output);
}

// BatchToSpace for N-D tensors of type T.
//
// This operation reshapes the "batch" dimension 0 into `M + 1` dimensions of shape
// `block_shape + [batch]`, interleaves these blocks back into the grid defined by
// the spatial dimensions `[1, ..., M]`, to obtain a result with the same rank as
// the input.  The spatial dimensions of this intermediate result are then
// optionally cropped according to `crops` to produce the output.  This is the
// reverse of SpaceToBatch.  See below for a precise description.
//
// Arguments:
// * scope: A Scope object
// * input: N-D with shape `input_shape = [batch] + spatial_shape + remaining_shape`,
// where spatial_shape has M dimensions.
// * block_shape: 1-D with shape `[M]`, all values must be >= 1.
// * crops: 2-D with shape `[M, 2]`, all values must be >= 0.
//   `crops[i] = [crop_start, crop_end]` specifies the amount to crop from input
//   dimension `i + 1`, which corresponds to spatial dimension `i`.  It is
//   required that
//   `crop_start[i] + crop_end[i] <= block_shape[i] * input_shape[i + 1]`.
//
// This operation is equivalent to the following steps:
//
// 1. Reshape `input` to `reshaped` of shape:
//      [block_shape[0], ..., block_shape[M-1],
//       batch / prod(block_shape),
//       input_shape[1], ..., input_shape[N-1]]
//
// 2. Permute dimensions of `reshaped` to produce `permuted` of shape
//      [batch / prod(block_shape),
//
//       input_shape[1], block_shape[0],
//       ...,
//       input_shape[M], block_shape[M-1],
//
//       input_shape[M+1], ..., input_shape[N-1]]
//
// 3. Reshape `permuted` to produce `reshaped_permuted` of shape
//      [batch / prod(block_shape),
//
//       input_shape[1] * block_shape[0],
//       ...,
//       input_shape[M] * block_shape[M-1],
//
//       input_shape[M+1],
//       ...,
//       input_shape[N-1]]
//
// 4. Crop the start and end of dimensions `[1, ..., M]` of
//    `reshaped_permuted` according to `crops` to produce the output of shape:
//      [batch / prod(block_shape),
//
//       input_shape[1] * block_shape[0] - crops[0,0] - crops[0,1],
//       ...,
//       input_shape[M] * block_shape[M-1] - crops[M-1,0] - crops[M-1,1],
//
//       input_shape[M+1], ..., input_shape[N-1]]
//
// Some examples:
//
// (1) For the following input of shape `[4, 1, 1, 1]`, `block_shape = [2, 2]`, and
//     `crops = [[0, 0], [0, 0]]`:
//
// ```prettyprint
// [[[[1]]], [[[2]]], [[[3]]], [[[4]]]]
// ```
//
// The output tensor has shape `[1, 2, 2, 1]` and value:
//
// ```prettyprint
// x = [[[[1], [2]], [[3], [4]]]]
// ```
//
// (2) For the following input of shape `[4, 1, 1, 3]`, `block_shape = [2, 2]`, and
//     `crops = [[0, 0], [0, 0]]`:
//
// ```prettyprint
// [[[1, 2, 3]], [[4, 5, 6]], [[7, 8, 9]], [[10, 11, 12]]]
// ```
//
// The output tensor has shape `[1, 2, 2, 3]` and value:
//
// ```prettyprint
// x = [[[[1, 2, 3], [4, 5, 6]],
//       [[7, 8, 9], [10, 11, 12]]]]
// ```
//
// (3) For the following input of shape `[4, 2, 2, 1]`, `block_shape = [2, 2]`, and
//     `crops = [[0, 0], [0, 0]]`:
//
// ```prettyprint
// x = [[[[1], [3]], [[5], [7]]],
//      [[[2], [4]], [[10], [12]]],
//      [[[5], [7]], [[13], [15]]],
//      [[[6], [8]], [[14], [16]]]]
// ```
//
// The output tensor has shape `[1, 4, 4, 1]` and value:
//
// ```prettyprint
// x = [[[1],   [2],  [3],  [4]],
//      [[5],   [6],  [7],  [8]],
//      [[9],  [10], [11],  [12]],
//      [[13], [14], [15],  [16]]]
// ```
//
// (4) For the following input of shape `[8, 1, 3, 1]`, `block_shape = [2, 2]`, and
//     `crops = [[0, 0], [2, 0]]`:
//
// ```prettyprint
// x = [[[[0], [1], [3]]], [[[0], [9], [11]]],
//      [[[0], [2], [4]]], [[[0], [10], [12]]],
//      [[[0], [5], [7]]], [[[0], [13], [15]]],
//      [[[0], [6], [8]]], [[[0], [14], [16]]]]
// ```
//
// The output tensor has shape `[2, 2, 4, 1]` and value:
//
// ```prettyprint
// x = [[[[1],   [2],  [3],  [4]],
//       [[5],   [6],  [7],  [8]]],
//      [[[9],  [10], [11],  [12]],
//       [[13], [14], [15],  [16]]]]
// ```
@Namespace("tensorflow::ops") @NoOffset public static class BatchToSpaceND extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public BatchToSpaceND(Pointer p) { super(p); }

  public BatchToSpaceND(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input block_shape,
                 @ByVal Input crops) { super((Pointer)null); allocate(scope, input, block_shape, crops); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input block_shape,
                 @ByVal Input crops);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native BatchToSpaceND output(Output output);
}

// Bitcasts a tensor from one type to another without copying data.
//
// Given a tensor `input`, this operation returns a tensor that has the same buffer
// data as `input` with datatype `type`.
//
// If the input datatype `T` is larger than the output datatype `type` then the
// shape changes from [...] to [..., sizeof(`T`)/sizeof(`type`)].
//
// If `T` is smaller than `type`, the operator requires that the rightmost
// dimension be equal to sizeof(`type`)/sizeof(`T`). The shape then goes from
// [..., sizeof(`type`)/sizeof(`T`)] to [...].
//
// *NOTE*: Bitcast is implemented as a low-level cast, so machines with different
// endian orderings will give different results.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Bitcast extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Bitcast(Pointer p) { super(p); }

  public Bitcast(@Const @ByRef Scope scope, @ByVal Input input,
          @Cast("tensorflow::DataType") int type) { super((Pointer)null); allocate(scope, input, type); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
          @Cast("tensorflow::DataType") int type);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native Bitcast output(Output output);
}

// Return the reduction indices for computing gradients of s0 op s1 with broadcast.
//
// This is typically used by gradient computations for a broadcasting operation.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class BroadcastGradientArgs extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public BroadcastGradientArgs(Pointer p) { super(p); }

  public BroadcastGradientArgs(@Const @ByRef Scope scope,
                        @ByVal Input s0, @ByVal Input s1) { super((Pointer)null); allocate(scope, s0, s1); }
  private native void allocate(@Const @ByRef Scope scope,
                        @ByVal Input s0, @ByVal Input s1);

  public native @ByRef Output r0(); public native BroadcastGradientArgs r0(Output r0);
  public native @ByRef Output r1(); public native BroadcastGradientArgs r1(Output r1);
}

// Checks a tensor for NaN and Inf values.
//
// When run, reports an `InvalidArgument` error if `tensor` has any values
// that are not a number (NaN) or infinity (Inf). Otherwise, passes `tensor` as-is.
//
// Arguments:
// * scope: A Scope object
// * message:
//     Prefix of the error message.
@Namespace("tensorflow::ops") @NoOffset public static class CheckNumerics extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public CheckNumerics(Pointer p) { super(p); }

  public CheckNumerics(@Const @ByRef Scope scope, @ByVal Input tensor, @StringPiece BytePointer message) { super((Pointer)null); allocate(scope, tensor, message); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input tensor, @StringPiece BytePointer message);
  public CheckNumerics(@Const @ByRef Scope scope, @ByVal Input tensor, @StringPiece String message) { super((Pointer)null); allocate(scope, tensor, message); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input tensor, @StringPiece String message);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native CheckNumerics output(Output output);
}

// Concatenates tensors along one dimension.
//
// Arguments:
// * scope: A Scope object
// * concat_dim: 0-D.  The dimension along which to concatenate.  Must be in the
// range [0, rank(values)).
// * values: The `N` Tensors to concatenate. Their ranks and types must match,
// and their sizes must match in all dimensions except `concat_dim`.
@Namespace("tensorflow::ops") @NoOffset public static class Concat extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Concat(Pointer p) { super(p); }

  public Concat(@Const @ByRef Scope scope, @ByVal Input concat_dim,
         @ByVal InputList values) { super((Pointer)null); allocate(scope, concat_dim, values); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input concat_dim,
         @ByVal InputList values);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native Concat output(Output output);
}

// Computes offsets of concat inputs within its output.
//
// For example:
//
// ```prettyprint
// # 'x' is [2, 2, 7]
// # 'y' is [2, 3, 7]
// # 'z' is [2, 5, 7]
// concat_offset(2, [x, y, z]) => [0, 0, 0], [0, 2, 0], [0, 5, 0]
// ```
//
// Arguments:
// * scope: A Scope object
// * concat_dim: The dimension along which to concatenate.
// * shape: The `N` int32 vectors representing shape of tensors being concatenated.
@Namespace("tensorflow::ops") @NoOffset public static class ConcatOffset extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ConcatOffset(Pointer p) { super(p); }

  public ConcatOffset(@Const @ByRef Scope scope, @ByVal Input concat_dim, @ByVal InputList shape) { super((Pointer)null); allocate(scope, concat_dim, shape); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input concat_dim, @ByVal InputList shape);
  public native @ByVal @Name("operator []") Output get(@Cast("size_t") long index);


  public native @ByRef @Cast("tensorflow::ops::OutputList*") StringVector offset(); public native ConcatOffset offset(StringVector offset);
}

// Copy Op.
//
// Performs CPU-to-CPU or GPU-to-GPU deep-copying of tensor, depending on the
// device on which the tensor is allocated.
//
// Unlike the CopyHost Op, this op does not have HostMemory constraint on its
// input or output.
//
// Arguments:
// * scope: A Scope object
// * input: Input tensor.
@Namespace("tensorflow::ops") @NoOffset public static class Copy extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Copy(Pointer p) { super(p); }

  // Optional attribute setters for Copy :
  //
  // TensorName(StringPiece): Defaults to ""
  //     The name of the input tensor.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs TensorName(@StringPiece BytePointer x);
    public native @ByVal Attrs TensorName(@StringPiece String x);

    public native @StringPiece BytePointer tensor_name_(); public native Attrs tensor_name_(BytePointer tensor_name_);
  }
  public Copy(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public Copy(@Const @ByRef Scope scope, @ByVal Input input, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs TensorName(@StringPiece BytePointer x);
  public static native @ByVal Attrs TensorName(@StringPiece String x);

  public native @ByRef Output output(); public native Copy output(Output output);
}

// Copy Host Op.
//
// Performs CPU-to-CPU deep-copying of tensor.
//
// Unlike the Copy Op, this op has HostMemory constraint on its input or output.
//
// Arguments:
// * scope: A Scope object
// * input: Input tensor.
@Namespace("tensorflow::ops") @NoOffset public static class CopyHost extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public CopyHost(Pointer p) { super(p); }

  // Optional attribute setters for CopyHost :
  //
  // TensorName(StringPiece): Defaults to ""
  //     The name of the input tensor.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs TensorName(@StringPiece BytePointer x);
    public native @ByVal Attrs TensorName(@StringPiece String x);

    public native @StringPiece BytePointer tensor_name_(); public native Attrs tensor_name_(BytePointer tensor_name_);
  }
  public CopyHost(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public CopyHost(@Const @ByRef Scope scope, @ByVal Input input,
           @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
           @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs TensorName(@StringPiece BytePointer x);
  public static native @ByVal Attrs TensorName(@StringPiece String x);

  public native @ByRef Output output(); public native CopyHost output(Output output);
}

// Debug Identity Op.
//
// Provides an identity mapping of the non-Ref type input tensor for debugging.
//
// Arguments:
// * scope: A Scope object
// * input: Input tensor, non-Reference type.
@Namespace("tensorflow::ops") @NoOffset public static class DebugIdentity extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public DebugIdentity(Pointer p) { super(p); }

  // Optional attribute setters for DebugIdentity :
  //
  // TensorName(StringPiece): Defaults to ""
  //     Name of the input tensor.
  // DebugUrls(const gtl::ArraySlice<string>&): Defaults to []
  //     List of URLs to debug targets, e.g.,
  // file:///foo/tfdbg_dump, grpc:://localhost:11011
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs TensorName(@StringPiece BytePointer x);
    public native @ByVal Attrs TensorName(@StringPiece String x);

    public native @ByVal Attrs DebugUrls(@Cast("const tensorflow::gtl::ArraySlice<std::string>*") @ByRef StringVector x);

    public native @StringPiece BytePointer tensor_name_(); public native Attrs tensor_name_(BytePointer tensor_name_);
    public native @ByRef @Cast("tensorflow::gtl::ArraySlice<std::string>*") StringVector debug_urls_(); public native Attrs debug_urls_(StringVector debug_urls_);
  }
  public DebugIdentity(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public DebugIdentity(@Const @ByRef Scope scope, @ByVal Input input,
                @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
                @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs TensorName(@StringPiece BytePointer x);
  public static native @ByVal Attrs TensorName(@StringPiece String x);
  public static native @ByVal Attrs DebugUrls(@Cast("const tensorflow::gtl::ArraySlice<std::string>*") @ByRef StringVector x);

  public native @ByRef Output output(); public native DebugIdentity output(Output output);
}

// Debug NaN Value Counter Op
//
// Counts number of NaNs in the input tensor, for debugging.
//
// Arguments:
// * scope: A Scope object
// * input: Input tensor, non-Reference type.
@Namespace("tensorflow::ops") @NoOffset public static class DebugNanCount extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public DebugNanCount(Pointer p) { super(p); }

  // Optional attribute setters for DebugNanCount :
  //
  // TensorName(StringPiece): Defaults to ""
  //     Name of the input tensor.
  // DebugUrls(const gtl::ArraySlice<string>&): Defaults to []
  //     List of URLs to debug targets, e.g.,
  // file:///foo/tfdbg_dump, grpc:://localhost:11011
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs TensorName(@StringPiece BytePointer x);
    public native @ByVal Attrs TensorName(@StringPiece String x);

    public native @ByVal Attrs DebugUrls(@Cast("const tensorflow::gtl::ArraySlice<std::string>*") @ByRef StringVector x);

    public native @StringPiece BytePointer tensor_name_(); public native Attrs tensor_name_(BytePointer tensor_name_);
    public native @ByRef @Cast("tensorflow::gtl::ArraySlice<std::string>*") StringVector debug_urls_(); public native Attrs debug_urls_(StringVector debug_urls_);
  }
  public DebugNanCount(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public DebugNanCount(@Const @ByRef Scope scope, @ByVal Input input,
                @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
                @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs TensorName(@StringPiece BytePointer x);
  public static native @ByVal Attrs TensorName(@StringPiece String x);
  public static native @ByVal Attrs DebugUrls(@Cast("const tensorflow::gtl::ArraySlice<std::string>*") @ByRef StringVector x);

  public native @ByRef Output output(); public native DebugNanCount output(Output output);
}

// DepthToSpace for tensors of type T.
//
// Rearranges data from depth into blocks of spatial data.
// This is the reverse transformation of SpaceToDepth. More specifically,
// this op outputs a copy of the input tensor where values from the `depth`
// dimension are moved in spatial blocks to the `height` and `width` dimensions.
// The attr `block_size` indicates the input block size and how the data is moved.
//
//   * Chunks of data of size `block_size * block_size` from depth are rearranged
//     into non-overlapping blocks of size `block_size x block_size`
//   * The width the output tensor is `input_depth * block_size`, whereas the
//     height is `input_height * block_size`.
//   * The depth of the input tensor must be divisible by
//     `block_size * block_size`.
//
// That is, assuming the input is in the shape:
// `[batch, height, width, depth]`,
// the shape of the output will be:
// `[batch, height*block_size, width*block_size, depth/(block_size*block_size)]`
//
// This operation requires that the input tensor be of rank 4, and that
// `block_size` be >=1 and that `block_size * block_size` be a divisor of the
// input depth.
//
// This operation is useful for resizing the activations between convolutions
// (but keeping all data), e.g. instead of pooling. It is also useful for training
// purely convolutional models.
//
// For example, given this input of shape `[1, 1, 1, 4]`, and a block size of 2:
//
// ```prettyprint
// x = [[[[1, 2, 3, 4]]]]
//
// ```
//
// This operation will output a tensor of shape `[1, 2, 2, 1]`:
//
// ```prettyprint
//    [[[[1], [2]],
//      [[3], [4]]]]
// ```
//
// Here, the input has a batch of 1 and each batch element has shape `[1, 1, 4]`,
// the corresponding output will have 2x2 elements and will have a depth of
// 1 channel (1 = `4 / (block_size * block_size)`).
// The output element shape is `[2, 2, 1]`.
//
// For an input tensor with larger depth, here of shape `[1, 1, 1, 12]`, e.g.
//
// ```prettyprint
// x = [[[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]]]]
// ```
//
// This operation, for block size of 2, will return the following tensor of shape
// `[1, 2, 2, 3]`
//
// ```prettyprint
//    [[[[1, 2, 3], [4, 5, 6]],
//      [[7, 8, 9], [10, 11, 12]]]]
//
// ```
//
// Similarly, for the following input of shape `[1 2 2 4]`, and a block size of 2:
//
// ```prettyprint
// x =  [[[[1, 2, 3, 4],
//        [5, 6, 7, 8]],
//       [[9, 10, 11, 12],
//        [13, 14, 15, 16]]]]
// ```
//
// the operator will return the following tensor of shape `[1 4 4 1]`:
//
// ```prettyprint
// x = [[ [1],   [2],  [5],  [6]],
//      [ [3],   [4],  [7],  [8]],
//      [ [9],  [10], [13],  [14]],
//      [ [11], [12], [15],  [16]]]
//
// ```
//
// Arguments:
// * scope: A Scope object
// * block_size:
//     The size of the spatial block, same as in Space2Depth.
@Namespace("tensorflow::ops") @NoOffset public static class DepthToSpace extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public DepthToSpace(Pointer p) { super(p); }

  public DepthToSpace(@Const @ByRef Scope scope, @ByVal Input input,
               @Cast("tensorflow::int64") long block_size) { super((Pointer)null); allocate(scope, input, block_size); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
               @Cast("tensorflow::int64") long block_size);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native DepthToSpace output(Output output);
}

// Returns a diagonal tensor with a given diagonal values.
//
// Given a `diagonal`, this operation returns a tensor with the `diagonal` and
// everything else padded with zeros. The diagonal is computed as follows:
//
// Assume `diagonal` has dimensions [D1,..., Dk], then the output is a tensor of
// rank 2k with dimensions [D1,..., Dk, D1,..., Dk] where:
//
// `output[i1,..., ik, i1,..., ik] = diagonal[i1, ..., ik]` and 0 everywhere else.
//
// For example:
//
// ```prettyprint
// # 'diagonal' is [1, 2, 3, 4]
// tf.diag(diagonal) ==> [[1, 0, 0, 0]
//                        [0, 2, 0, 0]
//                        [0, 0, 3, 0]
//                        [0, 0, 0, 4]]
// ```
//
// Arguments:
// * scope: A Scope object
// * diagonal: Rank k tensor where k is at most 3.
@Namespace("tensorflow::ops") @NoOffset public static class Diag extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Diag(Pointer p) { super(p); }

  public Diag(@Const @ByRef Scope scope, @ByVal Input diagonal) { super((Pointer)null); allocate(scope, diagonal); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input diagonal);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native Diag output(Output output);
}

// Returns the diagonal part of the tensor.
//
// This operation returns a tensor with the `diagonal` part
// of the `input`. The `diagonal` part is computed as follows:
//
// Assume `input` has dimensions `[D1,..., Dk, D1,..., Dk]`, then the output is a
// tensor of rank `k` with dimensions `[D1,..., Dk]` where:
//
// `diagonal[i1,..., ik] = input[i1, ..., ik, i1,..., ik]`.
//
// For example:
//
// ```prettyprint
// # 'input' is [[1, 0, 0, 0]
//               [0, 2, 0, 0]
//               [0, 0, 3, 0]
//               [0, 0, 0, 4]]
//
// tf.diag_part(input) ==> [1, 2, 3, 4]
// ```
//
// Arguments:
// * scope: A Scope object
// * input: Rank k tensor where k is 2, 4, or 6.
@Namespace("tensorflow::ops") @NoOffset public static class DiagPart extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public DiagPart(Pointer p) { super(p); }

  public DiagPart(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output diagonal(); public native DiagPart diagonal(Output diagonal);
}

// Computes the (possibly normalized) Levenshtein Edit Distance.
//
// The inputs are variable-length sequences provided by SparseTensors
//   (hypothesis_indices, hypothesis_values, hypothesis_shape)
// and
//   (truth_indices, truth_values, truth_shape).
//
// The inputs are:
//
// Arguments:
// * scope: A Scope object
// * hypothesis_indices: The indices of the hypothesis list SparseTensor.
// This is an N x R int64 matrix.
// * hypothesis_values: The values of the hypothesis list SparseTensor.
// This is an N-length vector.
// * hypothesis_shape: The shape of the hypothesis list SparseTensor.
// This is an R-length vector.
// * truth_indices: The indices of the truth list SparseTensor.
// This is an M x R int64 matrix.
// * truth_values: The values of the truth list SparseTensor.
// This is an M-length vector.
// * truth_shape: truth indices, vector.
@Namespace("tensorflow::ops") @NoOffset public static class EditDistance extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public EditDistance(Pointer p) { super(p); }

  // Optional attribute setters for EditDistance :
  //
  // Normalize(bool): Defaults to true
  //     boolean (if true, edit distances are normalized by length of truth).
  //
  // The output is:
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Normalize(@Cast("bool") boolean x);

    public native @Cast("bool") boolean normalize_(); public native Attrs normalize_(boolean normalize_);
  }
  public EditDistance(@Const @ByRef Scope scope, @ByVal Input hypothesis_indices, @ByVal Input hypothesis_values,
               @ByVal Input hypothesis_shape,
               @ByVal Input truth_indices, @ByVal Input truth_values, @ByVal Input truth_shape) { super((Pointer)null); allocate(scope, hypothesis_indices, hypothesis_values, hypothesis_shape, truth_indices, truth_values, truth_shape); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input hypothesis_indices, @ByVal Input hypothesis_values,
               @ByVal Input hypothesis_shape,
               @ByVal Input truth_indices, @ByVal Input truth_values, @ByVal Input truth_shape);
  public EditDistance(@Const @ByRef Scope scope, @ByVal Input hypothesis_indices, @ByVal Input hypothesis_values,
               @ByVal Input hypothesis_shape,
               @ByVal Input truth_indices, @ByVal Input truth_values, @ByVal Input truth_shape, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, hypothesis_indices, hypothesis_values, hypothesis_shape, truth_indices, truth_values, truth_shape, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input hypothesis_indices, @ByVal Input hypothesis_values,
               @ByVal Input hypothesis_shape,
               @ByVal Input truth_indices, @ByVal Input truth_values, @ByVal Input truth_shape, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Normalize(@Cast("bool") boolean x);

  public native @ByRef Output output(); public native EditDistance output(Output output);
}

// Inserts a dimension of 1 into a tensor's shape.
//
// Given a tensor `input`, this operation inserts a dimension of 1 at the
// dimension index `dim` of `input`'s shape. The dimension index `dim` starts at
// zero; if you specify a negative number for `dim` it is counted backward from
// the end.
//
// This operation is useful if you want to add a batch dimension to a single
// element. For example, if you have a single image of shape `[height, width,
// channels]`, you can make it a batch of 1 image with `expand_dims(image, 0)`,
// which will make the shape `[1, height, width, channels]`.
//
// Other examples:
//
// ```prettyprint
// # 't' is a tensor of shape [2]
// shape(expand_dims(t, 0)) ==> [1, 2]
// shape(expand_dims(t, 1)) ==> [2, 1]
// shape(expand_dims(t, -1)) ==> [2, 1]
//
// # 't2' is a tensor of shape [2, 3, 5]
// shape(expand_dims(t2, 0)) ==> [1, 2, 3, 5]
// shape(expand_dims(t2, 2)) ==> [2, 3, 1, 5]
// shape(expand_dims(t2, 3)) ==> [2, 3, 5, 1]
// ```
//
// This operation requires that:
//
// `-1-input.dims() <= dim <= input.dims()`
//
// This operation is related to `squeeze()`, which removes dimensions of
// size 1.
//
// Arguments:
// * scope: A Scope object
// * dim: 0-D (scalar). Specifies the dimension index at which to
// expand the shape of `input`.
@Namespace("tensorflow::ops") @NoOffset public static class ExpandDims extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ExpandDims(Pointer p) { super(p); }

  public ExpandDims(@Const @ByRef Scope scope, @ByVal Input input,
             @ByVal Input dim) { super((Pointer)null); allocate(scope, input, dim); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
             @ByVal Input dim);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native ExpandDims output(Output output);
}

// Extract `patches` from `images` and put them in the "depth" output dimension.
//
// Arguments:
// * scope: A Scope object
// * images: 4-D Tensor with shape `[batch, in_rows, in_cols, depth]`.
// * ksizes:
//     The size of the sliding window for each dimension of `images`.
// * strides:
//     1-D of length 4. How far the centers of two consecutive patches are in
// the images. Must be: `[1, stride_rows, stride_cols, 1]`.
// * rates:
//     1-D of length 4. Must be: `[1, rate_rows, rate_cols, 1]`. This is the
// input stride, specifying how far two consecutive patch samples are in the
// input. Equivalent to extracting patches with
// `patch_sizes_eff = patch_sizes + (patch_sizes - 1) * (rates - 1), followed by
// subsampling them spatially by a factor of `rates`.
// * padding:
//     The type of padding algorithm to use.
//
// We specify the size-related attributes as:
//
//       ksizes = [1, ksize_rows, ksize_cols, 1]
//       strides = [1, strides_rows, strides_cols, 1]
//       rates = [1, rates_rows, rates_cols, 1]
@Namespace("tensorflow::ops") @NoOffset public static class ExtractImagePatches extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ExtractImagePatches(Pointer p) { super(p); }

  public ExtractImagePatches(@Const @ByRef Scope scope, @ByVal Input images, @ArraySlice IntPointer ksizes, @ArraySlice IntPointer strides, @ArraySlice IntPointer rates, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, images, ksizes, strides, rates, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input images, @ArraySlice IntPointer ksizes, @ArraySlice IntPointer strides, @ArraySlice IntPointer rates, @StringPiece BytePointer padding);
  public ExtractImagePatches(@Const @ByRef Scope scope, @ByVal Input images, @ArraySlice IntBuffer ksizes, @ArraySlice IntBuffer strides, @ArraySlice IntBuffer rates, @StringPiece String padding) { super((Pointer)null); allocate(scope, images, ksizes, strides, rates, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input images, @ArraySlice IntBuffer ksizes, @ArraySlice IntBuffer strides, @ArraySlice IntBuffer rates, @StringPiece String padding);
  public ExtractImagePatches(@Const @ByRef Scope scope, @ByVal Input images, @ArraySlice int[] ksizes, @ArraySlice int[] strides, @ArraySlice int[] rates, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, images, ksizes, strides, rates, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input images, @ArraySlice int[] ksizes, @ArraySlice int[] strides, @ArraySlice int[] rates, @StringPiece BytePointer padding);
  public ExtractImagePatches(@Const @ByRef Scope scope, @ByVal Input images, @ArraySlice IntPointer ksizes, @ArraySlice IntPointer strides, @ArraySlice IntPointer rates, @StringPiece String padding) { super((Pointer)null); allocate(scope, images, ksizes, strides, rates, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input images, @ArraySlice IntPointer ksizes, @ArraySlice IntPointer strides, @ArraySlice IntPointer rates, @StringPiece String padding);
  public ExtractImagePatches(@Const @ByRef Scope scope, @ByVal Input images, @ArraySlice IntBuffer ksizes, @ArraySlice IntBuffer strides, @ArraySlice IntBuffer rates, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, images, ksizes, strides, rates, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input images, @ArraySlice IntBuffer ksizes, @ArraySlice IntBuffer strides, @ArraySlice IntBuffer rates, @StringPiece BytePointer padding);
  public ExtractImagePatches(@Const @ByRef Scope scope, @ByVal Input images, @ArraySlice int[] ksizes, @ArraySlice int[] strides, @ArraySlice int[] rates, @StringPiece String padding) { super((Pointer)null); allocate(scope, images, ksizes, strides, rates, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input images, @ArraySlice int[] ksizes, @ArraySlice int[] strides, @ArraySlice int[] rates, @StringPiece String padding);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output patches(); public native ExtractImagePatches patches(Output patches);
}

// Creates a tensor filled with a scalar value.
//
// This operation creates a tensor of shape `dims` and fills it with `value`.
//
// For example:
//
// ```prettyprint
// # Output tensor has shape [2, 3].
// fill([2, 3], 9) ==> [[9, 9, 9]
//                      [9, 9, 9]]
// ```
//
// Arguments:
// * scope: A Scope object
// * dims: 1-D. Represents the shape of the output tensor.
// * value: 0-D (scalar). Value to fill the returned tensor.
@Namespace("tensorflow::ops") @NoOffset public static class Fill extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Fill(Pointer p) { super(p); }

  public Fill(@Const @ByRef Scope scope, @ByVal Input dims,
       @ByVal Input value) { super((Pointer)null); allocate(scope, dims, value); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input dims,
       @ByVal Input value);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native Fill output(Output output);
}

// Gather slices from `params` according to `indices`.
//
// `indices` must be an integer tensor of any dimension (usually 0-D or 1-D).
// Produces an output tensor with shape `indices.shape + params.shape[1:]` where:
//
//     # Scalar indices
//     output[:, ..., :] = params[indices, :, ... :]
//
//     # Vector indices
//     output[i, :, ..., :] = params[indices[i], :, ... :]
//
//     # Higher rank indices
//     output[i, ..., j, :, ... :] = params[indices[i, ..., j], :, ..., :]
//
// If `indices` is a permutation and `len(indices) == params.shape[0]` then
// this operation will permute `params` accordingly.
//
// <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
// <img style="width:100%" src="../../images/Gather.png" alt>
// </div>
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Gather extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Gather(Pointer p) { super(p); }

  // Optional attribute setters for Gather :
  //
  // ValidateIndices(bool): Defaults to true
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs ValidateIndices(@Cast("bool") boolean x);

    public native @Cast("bool") boolean validate_indices_(); public native Attrs validate_indices_(boolean validate_indices_);
  }
  public Gather(@Const @ByRef Scope scope, @ByVal Input params,
         @ByVal Input indices) { super((Pointer)null); allocate(scope, params, indices); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input params,
         @ByVal Input indices);
  public Gather(@Const @ByRef Scope scope, @ByVal Input params,
         @ByVal Input indices, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, params, indices, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input params,
         @ByVal Input indices, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs ValidateIndices(@Cast("bool") boolean x);

  public native @ByRef Output output(); public native Gather output(Output output);
}

// Gather values or slices from `params` according to `indices`.
//
// `params` is a Tensor of rank `R` and `indices` is a Tensor of rank `M`.
//
// `indices` must be integer tensor, containing indices into `params`.
// It must be shape `[d_0, ..., d_N, R]` where `0 < R <= M`.
//
// The innermost dimension of `indices` (with length `R`) corresponds to
// indices into elements (if `R = M`) or slices (if `R < M`) along the `N`th
// dimension of `params`.
//
// Produces an output tensor with shape
//
//     [d_0, ..., d_{n-1}, params.shape[R], ..., params.shape[M-1]].
//
// Some examples below.
//
// Simple indexing into a matrix:
//
//     indices = [[0, 0], [1, 1]]
//     params = [['a', 'b'], ['c', 'd']]
//     output = ['a', 'd']
//
// Slice indexing into a matrix:
//
//     indices = [[1], [0]]
//     params = [['a', 'b'], ['c', 'd']]
//     output = [['c', 'd'], ['a', 'b']]
//
// Indexing into a 3-tensor:
//
//     indices = [[1]]
//     params = [[['a0', 'b0'], ['c0', 'd0']],
//               [['a1', 'b1'], ['c1', 'd1']]]
//     output = [[['a1', 'b1'], ['c1', 'd1']]]
//
//
//     indices = [[0, 1], [1, 0]]
//     params = [[['a0', 'b0'], ['c0', 'd0']],
//               [['a1', 'b1'], ['c1', 'd1']]]
//     output = [['c0', 'd0'], ['a1', 'b1']]
//
//
//     indices = [[0, 0, 1], [1, 0, 1]]
//     params = [[['a0', 'b0'], ['c0', 'd0']],
//               [['a1', 'b1'], ['c1', 'd1']]]
//     output = ['b0', 'b1']
//
// Batched indexing into a matrix:
//
//     indices = [[[0, 0]], [[0, 1]]]
//     params = [['a', 'b'], ['c', 'd']]
//     output = [['a'], ['b']]
//
// Batched slice indexing into a matrix:
//
//     indices = [[[1]], [[0]]]
//     params = [['a', 'b'], ['c', 'd']]
//     output = [[['c', 'd']], [['a', 'b']]]
//
// Batched indexing into a 3-tensor:
//
//     indices = [[[1]], [[0]]]
//     params = [[['a0', 'b0'], ['c0', 'd0']],
//               [['a1', 'b1'], ['c1', 'd1']]]
//     output = [[[['a1', 'b1'], ['c1', 'd1']]],
//               [[['a0', 'b0'], ['c0', 'd0']]]]
//
//
//     indices = [[[0, 1], [1, 0]], [[0, 0], [1, 1]]]
//     params = [[['a0', 'b0'], ['c0', 'd0']],
//               [['a1', 'b1'], ['c1', 'd1']]]
//     output = [[['c0', 'd0'], ['a1', 'b1']],
//               [['a0', 'b0'], ['c1', 'd1']]]
//
//
//     indices = [[[0, 0, 1], [1, 0, 1]], [[0, 1, 1], [1, 1, 0]]]
//     params = [[['a0', 'b0'], ['c0', 'd0']],
//               [['a1', 'b1'], ['c1', 'd1']]]
//     output = [['b0', 'b1'], ['d0', 'c1']]
//
// Arguments:
// * scope: A Scope object
// * params: `M-D`.  The tensor from which to gather values.
// * indices: `(N+1)-D`.  Index tensor having shape `[d_0, ..., d_N, R]`.
@Namespace("tensorflow::ops") @NoOffset public static class GatherNd extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public GatherNd(Pointer p) { super(p); }

  public GatherNd(@Const @ByRef Scope scope, @ByVal Input params,
           @ByVal Input indices) { super((Pointer)null); allocate(scope, params, indices); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input params,
           @ByVal Input indices);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native GatherNd output(Output output);
}

// Return a tensor with the same shape and contents as the input tensor or value.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Identity extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Identity(Pointer p) { super(p); }

  public Identity(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native Identity output(Output output);
}

// Returns immutable tensor from memory region.
//
// The current implementation memmaps the tensor from a file.
//
// Arguments:
// * scope: A Scope object
// * dtype:
//     Type of the returned tensor.
// * shape:
//     Shape of the returned tensor.
// * memory_region_name:
//     Name of readonly memory region used by the tensor, see
// NewReadOnlyMemoryRegionFromFile in tensorflow::Env.
@Namespace("tensorflow::ops") @NoOffset public static class ImmutableConst extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ImmutableConst(Pointer p) { super(p); }

  public ImmutableConst(@Const @ByRef Scope scope, @Cast("tensorflow::DataType") int dtype, @ByVal TensorShape shape, @StringPiece BytePointer memory_region_name) { super((Pointer)null); allocate(scope, dtype, shape, memory_region_name); }
  private native void allocate(@Const @ByRef Scope scope, @Cast("tensorflow::DataType") int dtype, @ByVal TensorShape shape, @StringPiece BytePointer memory_region_name);
  public ImmutableConst(@Const @ByRef Scope scope, @Cast("tensorflow::DataType") int dtype, @ByVal TensorShape shape, @StringPiece String memory_region_name) { super((Pointer)null); allocate(scope, dtype, shape, memory_region_name); }
  private native void allocate(@Const @ByRef Scope scope, @Cast("tensorflow::DataType") int dtype, @ByVal TensorShape shape, @StringPiece String memory_region_name);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output tensor(); public native ImmutableConst tensor(Output tensor);
}

// Computes the inverse permutation of a tensor.
//
// This operation computes the inverse of an index permutation. It takes a 1-D
// integer tensor `x`, which represents the indices of a zero-based array, and
// swaps each value with its index position. In other words, for an output tensor
// `y` and an input tensor `x`, this operation computes the following:
//
// `y[x[i]] = i for i in [0, 1, ..., len(x) - 1]`
//
// The values must include 0. There can be no duplicate values or negative values.
//
// For example:
//
// ```prettyprint
// # tensor `x` is [3, 4, 0, 2, 1]
// invert_permutation(x) ==> [2, 4, 3, 0, 1]
// ```
//
// Arguments:
// * scope: A Scope object
// * x: 1-D.
@Namespace("tensorflow::ops") @NoOffset public static class InvertPermutation extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public InvertPermutation(Pointer p) { super(p); }

  public InvertPermutation(@Const @ByRef Scope scope, @ByVal Input x) { super((Pointer)null); allocate(scope, x); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output y(); public native InvertPermutation y(Output y);
}

// Computes the difference between two lists of numbers or strings.
//
// Given a list `x` and a list `y`, this operation returns a list `out` that
// represents all values that are in `x` but not in `y`. The returned list `out`
// is sorted in the same order that the numbers appear in `x` (duplicates are
// preserved). This operation also returns a list `idx` that represents the
// position of each `out` element in `x`. In other words:
//
// `out[i] = x[idx[i]] for i in [0, 1, ..., len(out) - 1]`
//
// For example, given this input:
//
// ```prettyprint
// x = [1, 2, 3, 4, 5, 6]
// y = [1, 3, 5]
// ```
//
// This operation would return:
//
// ```prettyprint
// out ==> [2, 4, 6]
// idx ==> [1, 3, 5]
// ```
//
// Arguments:
// * scope: A Scope object
// * x: 1-D. Values to keep.
// * y: 1-D. Values to remove.
@Namespace("tensorflow::ops") @NoOffset public static class ListDiff extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ListDiff(Pointer p) { super(p); }

  // Optional attribute setters for ListDiff :
  //
  // OutIdx(DataType): Defaults to DT_INT32
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs OutIdx(@Cast("tensorflow::DataType") int x);

    public native @Cast("tensorflow::DataType") int out_idx_(); public native Attrs out_idx_(int out_idx_);
  }
  public ListDiff(@Const @ByRef Scope scope, @ByVal Input x,
           @ByVal Input y) { super((Pointer)null); allocate(scope, x, y); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x,
           @ByVal Input y);
  public ListDiff(@Const @ByRef Scope scope, @ByVal Input x,
           @ByVal Input y, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, x, y, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x,
           @ByVal Input y, @Const @ByRef Attrs attrs);

  public static native @ByVal Attrs OutIdx(@Cast("tensorflow::DataType") int x);

  public native @ByRef Output out(); public native ListDiff out(Output out);
  public native @ByRef Output idx(); public native ListDiff idx(Output idx);
}

// Copy a tensor setting everything outside a central band in each innermost matrix
//
// to zero.
//
// The `band` part is computed as follows:
// Assume `input` has `k` dimensions `[I, J, K, ..., M, N]`, then the output is a
// tensor with the same shape where
//
// `band[i, j, k, ..., m, n] = in_band(m, n) * input[i, j, k, ..., m, n]`.
//
// The indicator function 'in_band(m, n)` is one if
// `(num_lower < 0 || (m-n) <= num_lower)) &&
// (num_upper < 0 || (n-m) <= num_upper)`, and zero otherwise.
//
// For example:
//
// ```prettyprint
// # if 'input' is [[ 0,  1,  2, 3]
//                  [-1,  0,  1, 2]
//                  [-2, -1,  0, 1]
//                  [-3, -2, -1, 0]],
//
// tf.matrix_band_part(input, 1, -1) ==> [[ 0,  1,  2, 3]
//                                              [-1,  0,  1, 2]
//                                              [ 0, -1,  0, 1]
//                                              [ 0,  0, -1, 0]],
//
// tf.matrix_band_part(input, 2, 1) ==> [[ 0,  1,  0, 0]
//                                             [-1,  0,  1, 0]
//                                             [-2, -1,  0, 1]
//                                             [ 0, -2, -1, 0]]
// ```
//
// Useful special cases:
//
// ```prettyprint
//  tf.matrix_band_part(input, 0, -1) ==> Upper triangular part.
//  tf.matrix_band_part(input, -1, 0) ==> Lower triangular part.
//  tf.matrix_band_part(input, 0, 0) ==> Diagonal.
// ```
//
// Arguments:
// * scope: A Scope object
// * input: Rank `k` tensor.
// * num_lower: 0-D tensor. Number of subdiagonals to keep. If negative, keep entire
// lower triangle.
// * num_upper: 0-D tensor. Number of superdiagonals to keep. If negative, keep
// entire upper triangle.
@Namespace("tensorflow::ops") @NoOffset public static class MatrixBandPart extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public MatrixBandPart(Pointer p) { super(p); }

  public MatrixBandPart(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input num_lower,
                 @ByVal Input num_upper) { super((Pointer)null); allocate(scope, input, num_lower, num_upper); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input num_lower,
                 @ByVal Input num_upper);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output band(); public native MatrixBandPart band(Output band);
}

// Returns a batched diagonal tensor with a given batched diagonal values.
//
// Given a `diagonal`, this operation returns a tensor with the `diagonal` and
// everything else padded with zeros. The diagonal is computed as follows:
//
// Assume `diagonal` has `k` dimensions `[I, J, K, ..., N]`, then the output is a
// tensor of rank `k+1` with dimensions [I, J, K, ..., N, N]` where:
//
// `output[i, j, k, ..., m, n] = 1{m=n} * diagonal[i, j, k, ..., n]`.
//
// For example:
//
// ```prettyprint
// # 'diagonal' is [[1, 2, 3, 4], [5, 6, 7, 8]]
//
// and diagonal.shape = (2, 4)
//
// tf.matrix_diag(diagonal) ==> [[[1, 0, 0, 0]
//                                      [0, 2, 0, 0]
//                                      [0, 0, 3, 0]
//                                      [0, 0, 0, 4]],
//                                     [[5, 0, 0, 0]
//                                      [0, 6, 0, 0]
//                                      [0, 0, 7, 0]
//                                      [0, 0, 0, 8]]]
//
// which has shape (2, 4, 4)
// ```
//
// Arguments:
// * scope: A Scope object
// * diagonal: Rank `k`, where `k >= 1`.
@Namespace("tensorflow::ops") @NoOffset public static class MatrixDiag extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public MatrixDiag(Pointer p) { super(p); }

  public MatrixDiag(@Const @ByRef Scope scope, @ByVal Input diagonal) { super((Pointer)null); allocate(scope, diagonal); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input diagonal);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native MatrixDiag output(Output output);
}

// Returns the batched diagonal part of a batched tensor.
//
// This operation returns a tensor with the `diagonal` part
// of the batched `input`. The `diagonal` part is computed as follows:
//
// Assume `input` has `k` dimensions `[I, J, K, ..., N, N]`, then the output is a
// tensor of rank `k - 1` with dimensions `[I, J, K, ..., N]` where:
//
// `diagonal[i, j, k, ..., n] = input[i, j, k, ..., n, n]`.
//
// The input must be at least a matrix.
//
// For example:
//
// ```prettyprint
// # 'input' is [[[1, 0, 0, 0]
//                [0, 2, 0, 0]
//                [0, 0, 3, 0]
//                [0, 0, 0, 4]],
//               [[5, 0, 0, 0]
//                [0, 6, 0, 0]
//                [0, 0, 7, 0]
//                [0, 0, 0, 8]]]
//
// and input.shape = (2, 4, 4)
//
// tf.matrix_diag_part(input) ==> [[1, 2, 3, 4], [5, 6, 7, 8]]
//
// which has shape (2, 4)
// ```
//
// Arguments:
// * scope: A Scope object
// * input: Rank `k` tensor where `k >= 2` and the last two dimensions are equal.
@Namespace("tensorflow::ops") @NoOffset public static class MatrixDiagPart extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public MatrixDiagPart(Pointer p) { super(p); }

  public MatrixDiagPart(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output diagonal(); public native MatrixDiagPart diagonal(Output diagonal);
}

// Returns a batched matrix tensor with new batched diagonal values.
//
// Given `input` and `diagonal`, this operation returns a tensor with the
// same shape and values as `input`, except for the diagonals of the innermost
// matrices.  These will be overwritten by the values in `diagonal`.
// The batched matrices must be square.
//
// The output is computed as follows:
//
// Assume `input` has `k+1` dimensions `[I, J, K, ..., N, N]` and `diagonal` has
// `k` dimensions `[I, J, K, ..., N]`.  Then the output is a
// tensor of rank `k+1` with dimensions [I, J, K, ..., N, N]` where:
//
//   * `output[i, j, k, ..., m, n] = diagonal[i, j, k, ..., n]` for `m == n`.
//   * `output[i, j, k, ..., m, n] = input[i, j, k, ..., m, n]` for `m != n`.
//
// Arguments:
// * scope: A Scope object
// * input: Rank `k+1`, where `k >= 1`.
// * diagonal: Rank `k`, where `k >= 1`.
@Namespace("tensorflow::ops") @NoOffset public static class MatrixSetDiag extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public MatrixSetDiag(Pointer p) { super(p); }

  public MatrixSetDiag(@Const @ByRef Scope scope, @ByVal Input input,
                @ByVal Input diagonal) { super((Pointer)null); allocate(scope, input, diagonal); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
                @ByVal Input diagonal);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native MatrixSetDiag output(Output output);
}

// Pads a tensor with mirrored values.
//
// This operation pads a `input` with mirrored values according to the `paddings`
// you specify. `paddings` is an integer tensor with shape `[n, 2]`, where n is
// the rank of `input`. For each dimension D of `input`, `paddings[D, 0]` indicates
// how many values to add before the contents of `input` in that dimension, and
// `paddings[D, 1]` indicates how many values to add after the contents of `input`
// in that dimension. Both `paddings[D, 0]` and `paddings[D, 1]` must be no greater
// than `input.dim_size(D)` (or `input.dim_size(D) - 1`) if `copy_border` is true
// (if false, respectively).
//
// The padded size of each dimension D of the output is:
//
// `paddings(D, 0) + input.dim_size(D) + paddings(D, 1)`
//
// For example:
//
// ```prettyprint
// # 't' is [[1, 2, 3], [4, 5, 6]].
// # 'paddings' is [[1, 1]], [2, 2]].
// # 'mode' is SYMMETRIC.
// # rank of 't' is 2.
// pad(t, paddings) ==> [[2, 1, 1, 2, 3, 3, 2]
//                       [2, 1, 1, 2, 3, 3, 2]
//                       [5, 4, 4, 5, 6, 6, 5]
//                       [5, 4, 4, 5, 6, 6, 5]]
// ```
//
// Arguments:
// * scope: A Scope object
// * input: The input tensor to be padded.
// * paddings: A two-column matrix specifying the padding sizes. The number of
// rows must be the same as the rank of `input`.
// * mode:
//     Either `REFLECT` or `SYMMETRIC`. In reflect mode the padded regions
// do not include the borders, while in symmetric mode the padded regions
// do include the borders. For example, if `input` is `[1, 2, 3]` and `paddings`
// is `[0, 2]`, then the output is `[1, 2, 3, 2, 1]` in reflect mode, and
// it is `[1, 2, 3, 3, 2]` in symmetric mode.
@Namespace("tensorflow::ops") @NoOffset public static class MirrorPad extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public MirrorPad(Pointer p) { super(p); }

  public MirrorPad(@Const @ByRef Scope scope, @ByVal Input input,
            @ByVal Input paddings, @StringPiece BytePointer mode) { super((Pointer)null); allocate(scope, input, paddings, mode); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
            @ByVal Input paddings, @StringPiece BytePointer mode);
  public MirrorPad(@Const @ByRef Scope scope, @ByVal Input input,
            @ByVal Input paddings, @StringPiece String mode) { super((Pointer)null); allocate(scope, input, paddings, mode); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
            @ByVal Input paddings, @StringPiece String mode);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native MirrorPad output(Output output);
}

// Gradient op for `MirrorPad` op. This op folds a mirror-padded tensor.
//
// This operation folds the padded areas of `input` by `MirrorPad` according to the
// `paddings` you specify. `paddings` must be the same as `paddings` argument
// given to the corresponding `MirrorPad` op.
//
// The folded size of each dimension D of the output is:
//
// `input.dim_size(D) - paddings(D, 0) - paddings(D, 1)`
//
// For example:
//
// ```prettyprint
// # 't' is [[1, 2, 3], [4, 5, 6], [7, 8, 9]].
// # 'paddings' is [[0, 1]], [0, 1]].
// # 'mode' is SYMMETRIC.
// # rank of 't' is 2.
// pad(t, paddings) ==> [[ 1,  5]
//                       [11, 28]]
// ```
//
// Arguments:
// * scope: A Scope object
// * input: The input tensor to be folded.
// * paddings: A two-column matrix specifying the padding sizes. The number of
// rows must be the same as the rank of `input`.
// * mode:
//     The mode used in the `MirrorPad` op.
@Namespace("tensorflow::ops") @NoOffset public static class MirrorPadGrad extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public MirrorPadGrad(Pointer p) { super(p); }

  public MirrorPadGrad(@Const @ByRef Scope scope, @ByVal Input input,
                @ByVal Input paddings, @StringPiece BytePointer mode) { super((Pointer)null); allocate(scope, input, paddings, mode); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
                @ByVal Input paddings, @StringPiece BytePointer mode);
  public MirrorPadGrad(@Const @ByRef Scope scope, @ByVal Input input,
                @ByVal Input paddings, @StringPiece String mode) { super((Pointer)null); allocate(scope, input, paddings, mode); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
                @ByVal Input paddings, @StringPiece String mode);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native MirrorPadGrad output(Output output);
}

// Returns a one-hot tensor.
//
// The locations represented by indices in `indices` take value `on_value`,
// while all other locations take value `off_value`.
//
// If the input `indices` is rank `N`, the output will have rank `N+1`,
// The new axis is created at dimension `axis` (default: the new axis is
// appended at the end).
//
// If `indices` is a scalar the output shape will be a vector of length `depth`.
//
// If `indices` is a vector of length `features`, the output shape will be:
// ```
//   features x depth if axis == -1
//   depth x features if axis == 0
// ```
//
// If `indices` is a matrix (batch) with shape `[batch, features]`,
// the output shape will be:
// ```
//   batch x features x depth if axis == -1
//   batch x depth x features if axis == 1
//   depth x batch x features if axis == 0
// ```
//
//
// Examples
// =========
//
// Suppose that
//
// ```
//   indices = [0, 2, -1, 1]
//   depth = 3
//   on_value = 5.0
//   off_value = 0.0
//   axis = -1
// ```
//
// Then output is `[4 x 3]`:
//
//     ```output =
//       [5.0 0.0 0.0]  // one_hot(0)
//       [0.0 0.0 5.0]  // one_hot(2)
//       [0.0 0.0 0.0]  // one_hot(-1)
//       [0.0 5.0 0.0]  // one_hot(1)
//     ```
//
// Suppose that
//
// ```
//   indices = [0, 2, -1, 1]
//   depth = 3
//   on_value = 0.0
//   off_value = 3.0
//   axis = 0
// ```
//
// Then output is `[3 x 4]`:
//
//     ```output =
//       [0.0 3.0 3.0 3.0]
//       [3.0 3.0 3.0 0.0]
//       [3.0 3.0 3.0 3.0]
//       [3.0 0.0 3.0 3.0]
//     //  ^                one_hot(0)
//     //      ^            one_hot(2)
//     //          ^        one_hot(-1)
//     //              ^    one_hot(1)
//     ```
// Suppose that
//
// ```
//   indices = [[0, 2], [1, -1]]
//   depth = 3
//   on_value = 1.0
//   off_value = 0.0
//   axis = -1
// ```
//
// Then output is `[2 x 2 x 3]`:
//
//     ```output =
//       [
//         [1.0, 0.0, 0.0]  // one_hot(0)
//         [0.0, 0.0, 1.0]  // one_hot(2)
//       ][
//         [0.0, 1.0, 0.0]  // one_hot(1)
//         [0.0, 0.0, 0.0]  // one_hot(-1)
//       ]```
//
// Arguments:
// * scope: A Scope object
// * indices: A tensor of indices.
// * depth: A scalar defining the depth of the one hot dimension.
// * on_value: A scalar defining the value to fill in output when `indices[j] = i`.
// * off_value: A scalar defining the value to fill in output when `indices[j] != i`.
@Namespace("tensorflow::ops") @NoOffset public static class OneHot extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public OneHot(Pointer p) { super(p); }

  // Optional attribute setters for OneHot :
  //
  // Axis(int64): Defaults to -1
  //     The axis to fill (default: -1, a new inner-most axis).
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Axis(@Cast("tensorflow::int64") long x);

    public native @Cast("tensorflow::int64") long axis_(); public native Attrs axis_(long axis_);
  }
  public OneHot(@Const @ByRef Scope scope, @ByVal Input indices,
         @ByVal Input depth, @ByVal Input on_value,
         @ByVal Input off_value) { super((Pointer)null); allocate(scope, indices, depth, on_value, off_value); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input indices,
         @ByVal Input depth, @ByVal Input on_value,
         @ByVal Input off_value);
  public OneHot(@Const @ByRef Scope scope, @ByVal Input indices,
         @ByVal Input depth, @ByVal Input on_value,
         @ByVal Input off_value, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, indices, depth, on_value, off_value, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input indices,
         @ByVal Input depth, @ByVal Input on_value,
         @ByVal Input off_value, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Axis(@Cast("tensorflow::int64") long x);

  public native @ByRef Output output(); public native OneHot output(Output output);
}

// Packs a list of `N` rank-`R` tensors into one rank-`(R+1)` tensor.
//
// Packs the `N` tensors in `values` into a tensor with rank one higher than each
// tensor in `values`, by packing them along the `axis` dimension.
// Given a list of tensors of shape `(A, B, C)`;
//
// if `axis == 0` then the `output` tensor will have the shape `(N, A, B, C)`.
// if `axis == 1` then the `output` tensor will have the shape `(A, N, B, C)`.
// Etc.
//
// For example:
//
// ```prettyprint
// # 'x' is [1, 4]
// # 'y' is [2, 5]
// # 'z' is [3, 6]
// pack([x, y, z]) => [[1, 4], [2, 5], [3, 6]]  # Pack along first dim.
// pack([x, y, z], axis=1) => [[1, 2, 3], [4, 5, 6]]
// ```
//
// This is the opposite of `unpack`.
//
// Arguments:
// * scope: A Scope object
// * values: Must be of same shape and type.
@Namespace("tensorflow::ops") @NoOffset public static class Pack extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Pack(Pointer p) { super(p); }

  // Optional attribute setters for Pack :
  //
  // Axis(int64): Defaults to 0
  //     Dimension along which to pack.  Negative values wrap around, so the
  // valid range is `[-(R+1), R+1)`.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Axis(@Cast("tensorflow::int64") long x);

    public native @Cast("tensorflow::int64") long axis_(); public native Attrs axis_(long axis_);
  }
  public Pack(@Const @ByRef Scope scope, @ByVal InputList values) { super((Pointer)null); allocate(scope, values); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal InputList values);
  public Pack(@Const @ByRef Scope scope, @ByVal InputList values,
       @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, values, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal InputList values,
       @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Axis(@Cast("tensorflow::int64") long x);

  public native @ByRef Output output(); public native Pack output(Output output);
}

// Pads a tensor with zeros.
//
// This operation pads a `input` with zeros according to the `paddings` you
// specify. `paddings` is an integer tensor with shape `[Dn, 2]`, where n is the
// rank of `input`. For each dimension D of `input`, `paddings[D, 0]` indicates
// how many zeros to add before the contents of `input` in that dimension, and
// `paddings[D, 1]` indicates how many zeros to add after the contents of `input`
// in that dimension.
//
// The padded size of each dimension D of the output is:
//
// `paddings(D, 0) + input.dim_size(D) + paddings(D, 1)`
//
// For example:
//
// ```prettyprint
// # 't' is [[1, 1], [2, 2]]
// # 'paddings' is [[1, 1], [2, 2]]
// # rank of 't' is 2
// pad(t, paddings) ==> [[0, 0, 0, 0, 0, 0]
//                       [0, 0, 1, 1, 0, 0]
//                       [0, 0, 2, 2, 0, 0]
//                       [0, 0, 0, 0, 0, 0]]
// ```
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Pad extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Pad(Pointer p) { super(p); }

  public Pad(@Const @ByRef Scope scope, @ByVal Input input,
      @ByVal Input paddings) { super((Pointer)null); allocate(scope, input, paddings); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
      @ByVal Input paddings);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native Pad output(Output output);
}

// A placeholder op for a value that will be fed into the computation.
//
// N.B. This operation will fail with an error if it is executed. It is
// intended as a way to represent a value that will always be fed, and to
// provide attrs that enable the fed value to be checked at runtime.
//
// Arguments:
// * scope: A Scope object
// * dtype:
//     The type of elements in the tensor.
@Namespace("tensorflow::ops") @NoOffset public static class Placeholder extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Placeholder(Pointer p) { super(p); }

  // Optional attribute setters for Placeholder :
  //
  // Shape(TensorShape): Defaults to []
  //     (Optional) The shape of the tensor. If the shape has 0 dimensions, the
  // shape is unconstrained.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Shape(@ByVal TensorShape x);

    public native @ByRef TensorShape shape_(); public native Attrs shape_(TensorShape shape_);
  }
  public Placeholder(@Const @ByRef Scope scope, @Cast("tensorflow::DataType") int dtype) { super((Pointer)null); allocate(scope, dtype); }
  private native void allocate(@Const @ByRef Scope scope, @Cast("tensorflow::DataType") int dtype);
  public Placeholder(@Const @ByRef Scope scope, @Cast("tensorflow::DataType") int dtype, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, dtype, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @Cast("tensorflow::DataType") int dtype, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Shape(@ByVal TensorShape x);

  public native @ByRef Output output(); public native Placeholder output(Output output);
}

// A placeholder op that passes though `input` when its output is not fed.
//
// Arguments:
// * scope: A Scope object
// * input: The default value to produce when `output` is not fed.
// * shape:
//     The (possibly partial) shape of the tensor.
@Namespace("tensorflow::ops") @NoOffset public static class PlaceholderWithDefault extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public PlaceholderWithDefault(Pointer p) { super(p); }

  public PlaceholderWithDefault(@Const @ByRef Scope scope,
                         @ByVal Input input, @ByVal TensorShape shape) { super((Pointer)null); allocate(scope, input, shape); }
  private native void allocate(@Const @ByRef Scope scope,
                         @ByVal Input input, @ByVal TensorShape shape);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native PlaceholderWithDefault output(Output output);
}

// Quantizes then dequantizes a tensor.
//
// This op simulates the precision loss from the quantized forward pass by:
// 1. Quantizing the tensor to fixed point numbers, which should match the target
//    quantization method when it is used in inference.
// 2. Dequantizing it back to floating point numbers for the following ops, most
//    likely matmul.
//
// There are different ways to quantize. This version does not use the full range
// of the output type, choosing to elide the lowest possible value for symmetry
// (e.g., output range is -127 to 127, not -128 to 127 for signed 8 bit
// quantization), so that 0.0 maps to 0.
//
// To perform this op, we first find the range of values in our tensor. The range
// we use is always centered on 0, so we find m such that
//
// 1. m = max(abs(input_min), abs(input_max)) if range_given is true,
// 2. m = max(max(abs(min_elem(input)), abs(max_elem(input))) otherwise.
//
// Our input tensor range is then [-m, m].
//
// Next, we choose our fixed-point quantization buckets, [min_fixed, max_fixed].
// If signed_input is true, this is
//
//   [min_fixed, max_fixed ] =
//       [-(1 << (num_bits - 1) - 1), (1 << (num_bits - 1)) - 1].
//
// Otherwise, if signed_input is false, the fixed-point range is
//
//   [min_fixed, max_fixed] = [0, (1 << num_bits) - 1].
//
// From this we compute our scaling factor, s:
//
//   s = (max_fixed - min_fixed) / (2 * m).
//
// Now we can quantize and dequantize the elements of our tensor.  An element e
// is transformed into e':
//
//   e' = (e * s).round_to_nearest() / s.
//
// Note that we have a different number of buckets in the signed vs. unsigned
// cases.  For example, if num_bits == 8, we get 254 buckets in the signed case
// vs. 255 in the unsigned case.
//
// For example, suppose num_bits = 8 and m = 1.  Then
//
//   [min_fixed, max_fixed] = [-127, 127], and
//   s = (127 + 127) / 2 = 127.
//
// Given the vector {-1, -0.5, 0, 0.3}, this is quantized to
// {-127, -63, 0, 38}, and dequantized to {-1, -63.0/127, 0, 38.0/127}.
//
// Arguments:
// * scope: A Scope object
// * input: Tensor to quantize and then dequantize.
@Namespace("tensorflow::ops") @NoOffset public static class QuantizeAndDequantize extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public QuantizeAndDequantize(Pointer p) { super(p); }

  // Optional attribute setters for QuantizeAndDequantize :
  //
  // SignedInput(bool): Defaults to true
  //     If the quantization is signed or unsigned.
  // NumBits(int64): Defaults to 8
  //     The bitwidth of the quantization.
  // RangeGiven(bool): Defaults to false
  //     If the range is given or should be computed from the tensor.
  // InputMin(float): Defaults to 0
  //     If range is given, this is the min of the range.
  // InputMax(float): Defaults to 0
  //     If range is given, this is the max of the range.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs SignedInput(@Cast("bool") boolean x);

    public native @ByVal Attrs NumBits(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs RangeGiven(@Cast("bool") boolean x);

    public native @ByVal Attrs InputMin(float x);

    public native @ByVal Attrs InputMax(float x);

    public native @Cast("bool") boolean signed_input_(); public native Attrs signed_input_(boolean signed_input_);
    public native @Cast("tensorflow::int64") long num_bits_(); public native Attrs num_bits_(long num_bits_);
    public native @Cast("bool") boolean range_given_(); public native Attrs range_given_(boolean range_given_);
    public native float input_min_(); public native Attrs input_min_(float input_min_);
    public native float input_max_(); public native Attrs input_max_(float input_max_);
  }
  public QuantizeAndDequantize(@Const @ByRef Scope scope,
                        @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope,
                        @ByVal Input input);
  public QuantizeAndDequantize(@Const @ByRef Scope scope,
                        @ByVal Input input, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, attrs); }
  private native void allocate(@Const @ByRef Scope scope,
                        @ByVal Input input, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs SignedInput(@Cast("bool") boolean x);
  public static native @ByVal Attrs NumBits(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs RangeGiven(@Cast("bool") boolean x);
  public static native @ByVal Attrs InputMin(float x);
  public static native @ByVal Attrs InputMax(float x);

  public native @ByRef Output output(); public native QuantizeAndDequantize output(Output output);
}

// Returns the rank of a tensor.
//
// This operation returns an integer representing the rank of `input`.
//
// For example:
//
// ```prettyprint
// # 't' is [[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]]
// # shape of tensor 't' is [2, 2, 3]
// rank(t) ==> 3
// ```
//
// **Note**: The rank of a tensor is not the same as the rank of a matrix. The rank
// of a tensor is the number of indices required to uniquely select each element
// of the tensor. Rank is also known as "order", "degree", or "ndims."
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Rank extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Rank(Pointer p) { super(p); }

  public Rank(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native Rank output(Output output);
}

// Return the same ref tensor as the input ref tensor.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class RefIdentity extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public RefIdentity(Pointer p) { super(p); }

  public RefIdentity(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native RefIdentity output(Output output);
}

// Reshapes a tensor.
//
// Given `tensor`, this operation returns a tensor that has the same values
// as `tensor` with shape `shape`.
//
// If one component of `shape` is the special value -1, the size of that dimension
// is computed so that the total size remains constant.  In particular, a `shape`
// of `[-1]` flattens into 1-D.  At most one component of `shape` can be -1.
//
// If `shape` is 1-D or higher, then the operation returns a tensor with shape
// `shape` filled with the values of `tensor`. In this case, the number of elements
// implied by `shape` must be the same as the number of elements in `tensor`.
//
// For example:
//
// ```prettyprint
// # tensor 't' is [1, 2, 3, 4, 5, 6, 7, 8, 9]
// # tensor 't' has shape [9]
// reshape(t, [3, 3]) ==> [[1, 2, 3],
//                         [4, 5, 6],
//                         [7, 8, 9]]
//
// # tensor 't' is [[[1, 1], [2, 2]],
// #                [[3, 3], [4, 4]]]
// # tensor 't' has shape [2, 2, 2]
// reshape(t, [2, 4]) ==> [[1, 1, 2, 2],
//                         [3, 3, 4, 4]]
//
// # tensor 't' is [[[1, 1, 1],
// #                 [2, 2, 2]],
// #                [[3, 3, 3],
// #                 [4, 4, 4]],
// #                [[5, 5, 5],
// #                 [6, 6, 6]]]
// # tensor 't' has shape [3, 2, 3]
// # pass '[-1]' to flatten 't'
// reshape(t, [-1]) ==> [1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6]
//
// # -1 can also be used to infer the shape
//
// # -1 is inferred to be 9:
// reshape(t, [2, -1]) ==> [[1, 1, 1, 2, 2, 2, 3, 3, 3],
//                          [4, 4, 4, 5, 5, 5, 6, 6, 6]]
// # -1 is inferred to be 2:
// reshape(t, [-1, 9]) ==> [[1, 1, 1, 2, 2, 2, 3, 3, 3],
//                          [4, 4, 4, 5, 5, 5, 6, 6, 6]]
// # -1 is inferred to be 3:
// reshape(t, [ 2, -1, 3]) ==> [[[1, 1, 1],
//                               [2, 2, 2],
//                               [3, 3, 3]],
//                              [[4, 4, 4],
//                               [5, 5, 5],
//                               [6, 6, 6]]]
//
// # tensor 't' is [7]
// # shape `[]` reshapes to a scalar
// reshape(t, []) ==> 7
// ```
//
// Arguments:
// * scope: A Scope object
// * shape: Defines the shape of the output tensor.
@Namespace("tensorflow::ops") @NoOffset public static class Reshape extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Reshape(Pointer p) { super(p); }

  public Reshape(@Const @ByRef Scope scope, @ByVal Input tensor,
          @ByVal Input shape) { super((Pointer)null); allocate(scope, tensor, shape); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input tensor,
          @ByVal Input shape);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native Reshape output(Output output);
}

// Reverses specific dimensions of a tensor.
//
// Given a `tensor`, and a `bool` tensor `dims` representing the dimensions
// of `tensor`, this operation reverses each dimension i of `tensor` where
// `dims[i]` is `True`.
//
// `tensor` can have up to 8 dimensions. The number of dimensions
// of `tensor` must equal the number of elements in `dims`. In other words:
//
// `rank(tensor) = size(dims)`
//
// For example:
//
// ```prettyprint
// # tensor 't' is [[[[ 0,  1,  2,  3],
// #                  [ 4,  5,  6,  7],
// #                  [ 8,  9, 10, 11]],
// #                 [[12, 13, 14, 15],
// #                  [16, 17, 18, 19],
// #                  [20, 21, 22, 23]]]]
// # tensor 't' shape is [1, 2, 3, 4]
//
// # 'dims' is [False, False, False, True]
// reverse(t, dims) ==> [[[[ 3,  2,  1,  0],
//                         [ 7,  6,  5,  4],
//                         [ 11, 10, 9, 8]],
//                        [[15, 14, 13, 12],
//                         [19, 18, 17, 16],
//                         [23, 22, 21, 20]]]]
//
// # 'dims' is [False, True, False, False]
// reverse(t, dims) ==> [[[[12, 13, 14, 15],
//                         [16, 17, 18, 19],
//                         [20, 21, 22, 23]
//                        [[ 0,  1,  2,  3],
//                         [ 4,  5,  6,  7],
//                         [ 8,  9, 10, 11]]]]
//
// # 'dims' is [False, False, True, False]
// reverse(t, dims) ==> [[[[8, 9, 10, 11],
//                         [4, 5, 6, 7],
//                         [0, 1, 2, 3]]
//                        [[20, 21, 22, 23],
//                         [16, 17, 18, 19],
//                         [12, 13, 14, 15]]]]
// ```
//
// Arguments:
// * scope: A Scope object
// * tensor: Up to 8-D.
// * dims: 1-D. The dimensions to reverse.
@Namespace("tensorflow::ops") @NoOffset public static class Reverse extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Reverse(Pointer p) { super(p); }

  public Reverse(@Const @ByRef Scope scope, @ByVal Input tensor,
          @ByVal Input dims) { super((Pointer)null); allocate(scope, tensor, dims); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input tensor,
          @ByVal Input dims);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native Reverse output(Output output);
}

// Reverses variable length slices.
//
// This op first slices `input` along the dimension `batch_dim`, and for each
// slice `i`, reverses the first `seq_lengths[i]` elements along
// the dimension `seq_dim`.
//
// The elements of `seq_lengths` must obey `seq_lengths[i] < input.dims[seq_dim]`,
// and `seq_lengths` must be a vector of length `input.dims[batch_dim]`.
//
// The output slice `i` along dimension `batch_dim` is then given by input
// slice `i`, with the first `seq_lengths[i]` slices along dimension
// `seq_dim` reversed.
//
// For example:
//
// ```prettyprint
// # Given this:
// batch_dim = 0
// seq_dim = 1
// input.dims = (4, 8, ...)
// seq_lengths = [7, 2, 3, 5]
//
// # then slices of input are reversed on seq_dim, but only up to seq_lengths:
// output[0, 0:7, :, ...] = input[0, 7:0:-1, :, ...]
// output[1, 0:2, :, ...] = input[1, 2:0:-1, :, ...]
// output[2, 0:3, :, ...] = input[2, 3:0:-1, :, ...]
// output[3, 0:5, :, ...] = input[3, 5:0:-1, :, ...]
//
// # while entries past seq_lens are copied through:
// output[0, 7:, :, ...] = input[0, 7:, :, ...]
// output[1, 2:, :, ...] = input[1, 2:, :, ...]
// output[2, 3:, :, ...] = input[2, 3:, :, ...]
// output[3, 2:, :, ...] = input[3, 2:, :, ...]
// ```
//
// In contrast, if:
//
// ```prettyprint
// # Given this:
// batch_dim = 2
// seq_dim = 0
// input.dims = (8, ?, 4, ...)
// seq_lengths = [7, 2, 3, 5]
//
// # then slices of input are reversed on seq_dim, but only up to seq_lengths:
// output[0:7, :, 0, :, ...] = input[7:0:-1, :, 0, :, ...]
// output[0:2, :, 1, :, ...] = input[2:0:-1, :, 1, :, ...]
// output[0:3, :, 2, :, ...] = input[3:0:-1, :, 2, :, ...]
// output[0:5, :, 3, :, ...] = input[5:0:-1, :, 3, :, ...]
//
// # while entries past seq_lens are copied through:
// output[7:, :, 0, :, ...] = input[7:, :, 0, :, ...]
// output[2:, :, 1, :, ...] = input[2:, :, 1, :, ...]
// output[3:, :, 2, :, ...] = input[3:, :, 2, :, ...]
// output[2:, :, 3, :, ...] = input[2:, :, 3, :, ...]
// ```
//
// Arguments:
// * scope: A Scope object
// * input: The input to reverse.
// * seq_lengths: 1-D with length `input.dims(batch_dim)` and
// `max(seq_lengths) < input.dims(seq_dim)`
// * seq_dim:
//     The dimension which is partially reversed.
@Namespace("tensorflow::ops") @NoOffset public static class ReverseSequence extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ReverseSequence(Pointer p) { super(p); }

  // Optional attribute setters for ReverseSequence :
  //
  // BatchDim(int64): Defaults to 0
  //     The dimension along which reversal is performed.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs BatchDim(@Cast("tensorflow::int64") long x);

    public native @Cast("tensorflow::int64") long batch_dim_(); public native Attrs batch_dim_(long batch_dim_);
  }
  public ReverseSequence(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input seq_lengths, @Cast("tensorflow::int64") long seq_dim) { super((Pointer)null); allocate(scope, input, seq_lengths, seq_dim); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input seq_lengths, @Cast("tensorflow::int64") long seq_dim);
  public ReverseSequence(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input seq_lengths, @Cast("tensorflow::int64") long seq_dim,
                  @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, seq_lengths, seq_dim, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input seq_lengths, @Cast("tensorflow::int64") long seq_dim,
                  @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs BatchDim(@Cast("tensorflow::int64") long x);

  public native @ByRef Output output(); public native ReverseSequence output(Output output);
}

// Returns the shape of a tensor.
//
// This operation returns a 1-D integer tensor representing the shape of `input`.
//
// For example:
//
// ```prettyprint
// # 't' is [[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]]
// shape(t) ==> [2, 2, 3]
// ```
//
// Arguments:
// * scope: A Scope object

// Returns shape of tensors.
//
// This operation returns N 1-D integer tensors representing shape of `input[i]s`.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class ShapeN extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ShapeN(Pointer p) { super(p); }

  // Optional attribute setters for ShapeN :
  //
  // OutType(DataType): Defaults to DT_INT32
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs OutType(@Cast("tensorflow::DataType") int x);

    public native @Cast("tensorflow::DataType") int out_type_(); public native Attrs out_type_(int out_type_);
  }
  public ShapeN(@Const @ByRef Scope scope, @ByVal InputList input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal InputList input);
  public ShapeN(@Const @ByRef Scope scope, @ByVal InputList input,
         @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal InputList input,
         @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator []") Output get(@Cast("size_t") long index);


  public static native @ByVal Attrs OutType(@Cast("tensorflow::DataType") int x);

  public native @ByRef @Cast("tensorflow::ops::OutputList*") StringVector output(); public native ShapeN output(StringVector output);
}

// Returns the size of a tensor.
//
// This operation returns an integer representing the number of elements in
// `input`.
//
// For example:
//
// ```prettyprint
// # 't' is [[[1, 1,, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]]]
// size(t) ==> 12
// ```
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Size extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Size(Pointer p) { super(p); }

  // Optional attribute setters for Size :
  //
  // OutType(DataType): Defaults to DT_INT32
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs OutType(@Cast("tensorflow::DataType") int x);

    public native @Cast("tensorflow::DataType") int out_type_(); public native Attrs out_type_(int out_type_);
  }
  public Size(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public Size(@Const @ByRef Scope scope, @ByVal Input input, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs OutType(@Cast("tensorflow::DataType") int x);

  public native @ByRef Output output(); public native Size output(Output output);
}

// Return a slice from 'input'.
//
// The output tensor is a tensor with dimensions described by 'size'
// whose values are extracted from 'input' starting at the offsets in
// 'begin'.
//
// *Requirements*:
//   0 <= begin[i] <= begin[i] + size[i] <= Di  for i in [0, n)
//
// Arguments:
// * scope: A Scope object
// * begin: begin[i] specifies the offset into the 'i'th dimension of
// 'input' to slice from.
// * size: size[i] specifies the number of elements of the 'i'th dimension
// of 'input' to slice. If size[i] is -1, all remaining elements in dimension
// i are included in the slice (i.e. this is equivalent to setting
// size[i] = input.dim_size(i) - begin[i]).
@Namespace("tensorflow::ops") @NoOffset public static class Slice extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Slice(Pointer p) { super(p); }

  public Slice(@Const @ByRef Scope scope, @ByVal Input input,
        @ByVal Input begin, @ByVal Input size) { super((Pointer)null); allocate(scope, input, begin, size); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
        @ByVal Input begin, @ByVal Input size);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native Slice output(Output output);
}

// SpaceToBatch for 4-D tensors of type T.
//
// This is a legacy version of the more general SpaceToBatchND.
//
// Zero-pads and then rearranges (permutes) blocks of spatial data into batch.
// More specifically, this op outputs a copy of the input tensor where values from
// the `height` and `width` dimensions are moved to the `batch` dimension. After
// the zero-padding, both `height` and `width` of the input must be divisible by the
// block size.
//
// Arguments:
// * scope: A Scope object
// * input: 4-D with shape `[batch, height, width, depth]`.
// * paddings: 2-D tensor of non-negative integers with shape `[2, 2]`. It specifies
//   the padding of the input with zeros across the spatial dimensions as follows:
//
//       paddings = [[pad_top, pad_bottom], [pad_left, pad_right]]
//
//   The effective spatial dimensions of the zero-padded input tensor will be:
//
//       height_pad = pad_top + height + pad_bottom
//       width_pad = pad_left + width + pad_right
//
// The attr `block_size` must be greater than one. It indicates the block size.
//
//   * Non-overlapping blocks of size `block_size x block size` in the height and
//     width dimensions are rearranged into the batch dimension at each location.
//   * The batch of the output tensor is `batch * block_size * block_size`.
//   * Both height_pad and width_pad must be divisible by block_size.
//
// The shape of the output will be:
//
//     [batch*block_size*block_size, height_pad/block_size, width_pad/block_size,
//      depth]
//
// Some examples:
//
// (1) For the following input of shape `[1, 2, 2, 1]` and block_size of 2:
//
// ```prettyprint
// x = [[[[1], [2]], [[3], [4]]]]
// ```
//
// The output tensor has shape `[4, 1, 1, 1]` and value:
//
// ```prettyprint
// [[[[1]]], [[[2]]], [[[3]]], [[[4]]]]
// ```
//
// (2) For the following input of shape `[1, 2, 2, 3]` and block_size of 2:
//
// ```prettyprint
// x = [[[[1, 2, 3], [4, 5, 6]],
//       [[7, 8, 9], [10, 11, 12]]]]
// ```
//
// The output tensor has shape `[4, 1, 1, 3]` and value:
//
// ```prettyprint
// [[[1, 2, 3]], [[4, 5, 6]], [[7, 8, 9]], [[10, 11, 12]]]
// ```
//
// (3) For the following input of shape `[1, 4, 4, 1]` and block_size of 2:
//
// ```prettyprint
// x = [[[[1],   [2],  [3],  [4]],
//       [[5],   [6],  [7],  [8]],
//       [[9],  [10], [11],  [12]],
//       [[13], [14], [15],  [16]]]]
// ```
//
// The output tensor has shape `[4, 2, 2, 1]` and value:
//
// ```prettyprint
// x = [[[[1], [3]], [[5], [7]]],
//      [[[2], [4]], [[10], [12]]],
//      [[[5], [7]], [[13], [15]]],
//      [[[6], [8]], [[14], [16]]]]
// ```
//
// (4) For the following input of shape `[2, 2, 4, 1]` and block_size of 2:
//
// ```prettyprint
// x = [[[[1],   [2],  [3],  [4]],
//       [[5],   [6],  [7],  [8]]],
//      [[[9],  [10], [11],  [12]],
//       [[13], [14], [15],  [16]]]]
// ```
//
// The output tensor has shape `[8, 1, 2, 1]` and value:
//
// ```prettyprint
// x = [[[[1], [3]]], [[[9], [11]]], [[[2], [4]]], [[[10], [12]]],
//      [[[5], [7]]], [[[13], [15]]], [[[6], [8]]], [[[14], [16]]]]
// ```
//
// Among others, this operation is useful for reducing atrous convolution into
// regular convolution.
@Namespace("tensorflow::ops") @NoOffset public static class SpaceToBatch extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SpaceToBatch(Pointer p) { super(p); }

  public SpaceToBatch(@Const @ByRef Scope scope, @ByVal Input input,
               @ByVal Input paddings, @Cast("tensorflow::int64") long block_size) { super((Pointer)null); allocate(scope, input, paddings, block_size); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
               @ByVal Input paddings, @Cast("tensorflow::int64") long block_size);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native SpaceToBatch output(Output output);
}

// SpaceToBatch for N-D tensors of type T.
//
// This operation divides "spatial" dimensions `[1, ..., M]` of the input into a
// grid of blocks of shape `block_shape`, and interleaves these blocks with the
// "batch" dimension (0) such that in the output, the spatial dimensions
// `[1, ..., M]` correspond to the position within the grid, and the batch
// dimension combines both the position within a spatial block and the original
// batch position.  Prior to division into blocks, the spatial dimensions of the
// input are optionally zero padded according to `paddings`.  See below for a
// precise description.
//
// Arguments:
// * scope: A Scope object
// * input: N-D with shape `input_shape = [batch] + spatial_shape + remaining_shape`,
// where spatial_shape has `M` dimensions.
// * block_shape: 1-D with shape `[M]`, all values must be >= 1.
// * paddings: 2-D with shape `[M, 2]`, all values must be >= 0.
//   `paddings[i] = [pad_start, pad_end]` specifies the padding for input dimension
//   `i + 1`, which corresponds to spatial dimension `i`.  It is required that
//   `block_shape[i]` divides `input_shape[i + 1] + pad_start + pad_end`.
//
// This operation is equivalent to the following steps:
//
// 1. Zero-pad the start and end of dimensions `[1, ..., M]` of the
//    input according to `paddings` to produce `padded` of shape `padded_shape`.
//
// 2. Reshape `padded` to `reshaped_padded` of shape:
//      [batch] +
//      [padded_shape[1] / block_shape[0],
//        block_shape[0],
//       ...,
//       padded_shape[M] / block_shape[M-1],
//       block_shape[M-1]] +
//      remaining_shape
//
// 3. Permute dimensions of `reshaped_padded` to produce
//    `permuted_reshaped_padded` of shape:
//      block_shape +
//      [batch] +
//      [padded_shape[1] / block_shape[0],
//       ...,
//       padded_shape[M] / block_shape[M-1]] +
//      remaining_shape
//
// 4. Reshape `permuted_reshaped_padded` to flatten `block_shape` into the batch
//    dimension, producing an output tensor of shape:
//      [batch * prod(block_shape)] +
//      [padded_shape[1] / block_shape[0],
//       ...,
//       padded_shape[M] / block_shape[M-1]] +
//      remaining_shape
//
// Some examples:
//
// (1) For the following input of shape `[1, 2, 2, 1]`, `block_shape = [2, 2]`, and
//     `paddings = [[0, 0], [0, 0]]`:
//
// ```prettyprint
// x = [[[[1], [2]], [[3], [4]]]]
// ```
//
// The output tensor has shape `[4, 1, 1, 1]` and value:
//
// ```prettyprint
// [[[[1]]], [[[2]]], [[[3]]], [[[4]]]]
// ```
//
// (2) For the following input of shape `[1, 2, 2, 3]`, `block_shape = [2, 2]`, and
//     `paddings = [[0, 0], [0, 0]]`:
//
// ```prettyprint
// x = [[[[1, 2, 3], [4, 5, 6]],
//       [[7, 8, 9], [10, 11, 12]]]]
// ```
//
// The output tensor has shape `[4, 1, 1, 3]` and value:
//
// ```prettyprint
// [[[1, 2, 3]], [[4, 5, 6]], [[7, 8, 9]], [[10, 11, 12]]]
// ```
//
// (3) For the following input of shape `[1, 4, 4, 1]`, `block_shape = [2, 2]`, and
//     `paddings = [[0, 0], [0, 0]]`:
//
// ```prettyprint
// x = [[[[1],   [2],  [3],  [4]],
//       [[5],   [6],  [7],  [8]],
//       [[9],  [10], [11],  [12]],
//       [[13], [14], [15],  [16]]]]
// ```
//
// The output tensor has shape `[4, 2, 2, 1]` and value:
//
// ```prettyprint
// x = [[[[1], [3]], [[5], [7]]],
//      [[[2], [4]], [[10], [12]]],
//      [[[5], [7]], [[13], [15]]],
//      [[[6], [8]], [[14], [16]]]]
// ```
//
// (4) For the following input of shape `[2, 2, 4, 1]`, block_shape = `[2, 2]`, and
//     paddings = `[[0, 0], [2, 0]]`:
//
// ```prettyprint
// x = [[[[1],   [2],  [3],  [4]],
//       [[5],   [6],  [7],  [8]]],
//      [[[9],  [10], [11],  [12]],
//       [[13], [14], [15],  [16]]]]
// ```
//
// The output tensor has shape `[8, 1, 3, 1]` and value:
//
// ```prettyprint
// x = [[[[0], [1], [3]]], [[[0], [9], [11]]],
//      [[[0], [2], [4]]], [[[0], [10], [12]]],
//      [[[0], [5], [7]]], [[[0], [13], [15]]],
//      [[[0], [6], [8]]], [[[0], [14], [16]]]]
// ```
//
// Among others, this operation is useful for reducing atrous convolution into
// regular convolution.
@Namespace("tensorflow::ops") @NoOffset public static class SpaceToBatchND extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SpaceToBatchND(Pointer p) { super(p); }

  public SpaceToBatchND(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input block_shape,
                 @ByVal Input paddings) { super((Pointer)null); allocate(scope, input, block_shape, paddings); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input block_shape,
                 @ByVal Input paddings);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native SpaceToBatchND output(Output output);
}

// SpaceToDepth for tensors of type T.
//
// Rearranges blocks of spatial data, into depth. More specifically,
// this op outputs a copy of the input tensor where values from the `height`
// and `width` dimensions are moved to the `depth` dimension.
// The attr `block_size` indicates the input block size and how the data is moved.
//
//   * Non-overlapping blocks of size `block_size x block size` are rearranged
//     into depth at each location.
//   * The depth of the output tensor is `input_depth * block_size * block_size`.
//   * The input tensor's height and width must be divisible by block_size.
//
// That is, assuming the input is in the shape:
// `[batch, height, width, depth]`,
// the shape of the output will be:
// `[batch, height/block_size, width/block_size, depth*block_size*block_size]`
//
// This operation requires that the input tensor be of rank 4, and that
// `block_size` be >=1 and a divisor of both the input `height` and `width`.
//
// This operation is useful for resizing the activations between convolutions
// (but keeping all data), e.g. instead of pooling. It is also useful for training
// purely convolutional models.
//
// For example, given this input of shape `[1, 2, 2, 1]`, and block_size of 2:
//
// ```prettyprint
// x = [[[[1], [2]],
//       [[3], [4]]]]
// ```
//
// This operation will output a tensor of shape `[1, 1, 1, 4]`:
//
// ```prettyprint
// [[[[1, 2, 3, 4]]]]
// ```
//
// Here, the input has a batch of 1 and each batch element has shape `[2, 2, 1]`,
// the corresponding output will have a single element (i.e. width and height are
// both 1) and will have a depth of 4 channels (1 * block_size * block_size).
// The output element shape is `[1, 1, 4]`.
//
// For an input tensor with larger depth, here of shape `[1, 2, 2, 3]`, e.g.
//
// ```prettyprint
// x = [[[[1, 2, 3], [4, 5, 6]],
//       [[7, 8, 9], [10, 11, 12]]]]
// ```
//
// This operation, for block_size of 2, will return the following tensor of shape
// `[1, 1, 1, 12]`
//
// ```prettyprint
// [[[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]]]]
// ```
//
// Similarly, for the following input of shape `[1 4 4 1]`, and a block size of 2:
//
// ```prettyprint
// x = [[[[1],   [2],  [5],  [6]],
//       [[3],   [4],  [7],  [8]],
//       [[9],  [10], [13],  [14]],
//       [[11], [12], [15],  [16]]]]
// ```
//
// the operator will return the following tensor of shape `[1 2 2 4]`:
//
// ```prettyprint
// x = [[[[1, 2, 3, 4],
//        [5, 6, 7, 8]],
//       [[9, 10, 11, 12],
//        [13, 14, 15, 16]]]]
// ```
//
// Arguments:
// * scope: A Scope object
// * block_size:
//     The size of the spatial block.
@Namespace("tensorflow::ops") @NoOffset public static class SpaceToDepth extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SpaceToDepth(Pointer p) { super(p); }

  public SpaceToDepth(@Const @ByRef Scope scope, @ByVal Input input,
               @Cast("tensorflow::int64") long block_size) { super((Pointer)null); allocate(scope, input, block_size); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
               @Cast("tensorflow::int64") long block_size);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native SpaceToDepth output(Output output);
}

// Splits a tensor into `num_split` tensors along one dimension.
//
// Arguments:
// * scope: A Scope object
// * split_dim: 0-D.  The dimension along which to split.  Must be in the range
// `[0, rank(value))`.
// * value: The tensor to split.
// * num_split:
//     The number of ways to split.  Must evenly divide
// `value.shape[split_dim]`.
@Namespace("tensorflow::ops") @NoOffset public static class Split extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Split(Pointer p) { super(p); }

  public Split(@Const @ByRef Scope scope, @ByVal Input split_dim,
        @ByVal Input value, @Cast("tensorflow::int64") long num_split) { super((Pointer)null); allocate(scope, split_dim, value, num_split); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input split_dim,
        @ByVal Input value, @Cast("tensorflow::int64") long num_split);
  public native @ByVal @Name("operator []") Output get(@Cast("size_t") long index);


  public native @ByRef @Cast("tensorflow::ops::OutputList*") StringVector output(); public native Split output(StringVector output);
}

// Removes dimensions of size 1 from the shape of a tensor.
//
// Given a tensor `input`, this operation returns a tensor of the same type with
// all dimensions of size 1 removed. If you don't want to remove all size 1
// dimensions, you can remove specific size 1 dimensions by specifying
// `squeeze_dims`.
//
// For example:
//
// ```prettyprint
// # 't' is a tensor of shape [1, 2, 1, 3, 1, 1]
// shape(squeeze(t)) ==> [2, 3]
// ```
//
// Or, to remove specific size 1 dimensions:
//
// ```prettyprint
// # 't' is a tensor of shape [1, 2, 1, 3, 1, 1]
// shape(squeeze(t, [2, 4])) ==> [1, 2, 3, 1]
// ```
//
// Arguments:
// * scope: A Scope object
// * input: The `input` to squeeze.
@Namespace("tensorflow::ops") @NoOffset public static class Squeeze extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Squeeze(Pointer p) { super(p); }

  // Optional attribute setters for Squeeze :
  //
  // SqueezeDims(const gtl::ArraySlice<int>&): Defaults to []
  //     If specified, only squeezes the dimensions listed. The dimension
  // index starts at 0. It is an error to squeeze a dimension that is not 1.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs SqueezeDims(@ArraySlice IntPointer x);
    public native @ByVal Attrs SqueezeDims(@ArraySlice IntBuffer x);
    public native @ByVal Attrs SqueezeDims(@ArraySlice int... x);

    public native @ArraySlice IntPointer squeeze_dims_(); public native Attrs squeeze_dims_(IntPointer squeeze_dims_);
  }
  public Squeeze(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public Squeeze(@Const @ByRef Scope scope, @ByVal Input input, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs SqueezeDims(@ArraySlice IntPointer x);
  public static native @ByVal Attrs SqueezeDims(@ArraySlice IntBuffer x);
  public static native @ByVal Attrs SqueezeDims(@ArraySlice int... x);

  public native @ByRef Output output(); public native Squeeze output(Output output);
}

// Stops gradient computation.
//
// When executed in a graph, this op outputs its input tensor as-is.
//
// When building ops to compute gradients, this op prevents the contribution of
// its inputs to be taken into account.  Normally, the gradient generator adds ops
// to a graph to compute the derivatives of a specified 'loss' by recursively
// finding out inputs that contributed to its computation.  If you insert this op
// in the graph it inputs are masked from the gradient generator.  They are not
// taken into account for computing gradients.
//
// This is useful any time you want to compute a value with TensorFlow but need
// to pretend that the value was a constant. Some examples include:
//
// *  The *EM* algorithm where the *M-step* should not involve backpropagation
//    through the output of the *E-step*.
// *  Contrastive divergence training of Boltzmann machines where, when
//    differentiating the energy function, the training must not backpropagate
//    through the graph that generated the samples from the model.
// *  Adversarial training, where no backprop should happen through the adversarial
//    example generation process.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class StopGradient extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public StopGradient(Pointer p) { super(p); }

  public StopGradient(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native StopGradient output(Output output);
}

// Return a strided slice from `input`.
//
// The output tensor is a tensor with dimensions implied by `begin`,
// `end`, and `strides`, whose values are extracted from `begin`.
//
// Specifically, the result tensor at index `(i[0], i[1], ..., i[n-1])`
// will obtain the value `input[begin[0] + i[0] * stride[0], ..., `
//                             `begin[n-1] + i[n-1] * stride[n-1])]`.
//
// *Requirements*:
//   `0 != strides[i] for i in [0, n)`
//
// Arguments:
// * scope: A Scope object
// * begin: `begin[i]` specifies the offset into the `i`th dimension of
// `input` to slice from.
// * end: `end[i]` specifies the first offset into the `i`th dimension of
// `input` that will not be extracted. Out or range values are
// clamped to `[0,dim[i]) if slice[i] > 0` or `[-1,dim[i]-1]`
// `if slice[i] < 0`
// * strides: `strides[i]` specifies the increment in the `i`th dimension
// after extracting a given element. Negative indices will reverse
// the original order. Out or range values are
// clamped to `[0,dim[i]) if slice[i]>0` or `[-1,dim[i]-1] if slice[i] < 0`
@Namespace("tensorflow::ops") @NoOffset public static class StridedSlice extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public StridedSlice(Pointer p) { super(p); }

  // Optional attribute setters for StridedSlice :
  //
  // BeginMask(int64): Defaults to 0
  //     a bitmask where a bit i being 1 means to ignore the begin
  // value and instead use the largest interval possible. At runtime
  // begin[i] will be replaced with `[0, n-1) if `stride[i] > 0` or
  // `[-1, n-1]` if `stride[i] < 0`
  // EndMask(int64): Defaults to 0
  //     analogous to `begin_mask`
  // EllipsisMask(int64): Defaults to 0
  //     a bitmask where bit `i` being 1 means the `i`th
  // position is actually an ellipsis. One bit at most can be 1.
  // NewAxisMask(int64): Defaults to 0
  //     a bitmask where bit `i` being 1 means the `i`th
  // position creates a dimension in the tensor of length 1. Thus
  // the total number of elements remain unchanged but the shape
  // gets a 1 in the appropriate position.
  // ShrinkAxisMask(int64): Defaults to 0
  //     a bitmask where bit `i` implies that the `i`th
  // position should shrink the dimensionality. begin and end
  // must imply a slice of size 1 in the dimension. For example in
  // python one might do `foo[:,3,:]` which would result in
  // `shrink_axis_mask` being 2.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs BeginMask(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs EndMask(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs EllipsisMask(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs NewAxisMask(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs ShrinkAxisMask(@Cast("tensorflow::int64") long x);

    public native @Cast("tensorflow::int64") long begin_mask_(); public native Attrs begin_mask_(long begin_mask_);
    public native @Cast("tensorflow::int64") long end_mask_(); public native Attrs end_mask_(long end_mask_);
    public native @Cast("tensorflow::int64") long ellipsis_mask_(); public native Attrs ellipsis_mask_(long ellipsis_mask_);
    public native @Cast("tensorflow::int64") long new_axis_mask_(); public native Attrs new_axis_mask_(long new_axis_mask_);
    public native @Cast("tensorflow::int64") long shrink_axis_mask_(); public native Attrs shrink_axis_mask_(long shrink_axis_mask_);
  }
  public StridedSlice(@Const @ByRef Scope scope, @ByVal Input input,
               @ByVal Input begin, @ByVal Input end,
               @ByVal Input strides) { super((Pointer)null); allocate(scope, input, begin, end, strides); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
               @ByVal Input begin, @ByVal Input end,
               @ByVal Input strides);
  public StridedSlice(@Const @ByRef Scope scope, @ByVal Input input,
               @ByVal Input begin, @ByVal Input end,
               @ByVal Input strides, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, begin, end, strides, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
               @ByVal Input begin, @ByVal Input end,
               @ByVal Input strides, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs BeginMask(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs EndMask(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs EllipsisMask(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs NewAxisMask(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs ShrinkAxisMask(@Cast("tensorflow::int64") long x);

  public native @ByRef Output output(); public native StridedSlice output(Output output);
}

// Assign `value` to the sliced l-value reference of `ref`.
//
// The values of `value` are assigned to the positions in the variable
// `ref` that are selected by the slice parameters. The slice parameters
// `begin, `end`, `strides`, etc. work exactly as in `StridedSlice`.
//
// NOTE this op currently does not support broadcasting and so `value`'s
// shape must be exactly the shape produced by the slice of `ref`.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class StridedSliceAssign extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public StridedSliceAssign(Pointer p) { super(p); }

  // Optional attribute setters for StridedSliceAssign :
  //
  // BeginMask(int64): Defaults to 0
  // EndMask(int64): Defaults to 0
  // EllipsisMask(int64): Defaults to 0
  // NewAxisMask(int64): Defaults to 0
  // ShrinkAxisMask(int64): Defaults to 0
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs BeginMask(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs EndMask(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs EllipsisMask(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs NewAxisMask(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs ShrinkAxisMask(@Cast("tensorflow::int64") long x);

    public native @Cast("tensorflow::int64") long begin_mask_(); public native Attrs begin_mask_(long begin_mask_);
    public native @Cast("tensorflow::int64") long end_mask_(); public native Attrs end_mask_(long end_mask_);
    public native @Cast("tensorflow::int64") long ellipsis_mask_(); public native Attrs ellipsis_mask_(long ellipsis_mask_);
    public native @Cast("tensorflow::int64") long new_axis_mask_(); public native Attrs new_axis_mask_(long new_axis_mask_);
    public native @Cast("tensorflow::int64") long shrink_axis_mask_(); public native Attrs shrink_axis_mask_(long shrink_axis_mask_);
  }
  public StridedSliceAssign(@Const @ByRef Scope scope, @ByVal Input ref, @ByVal Input begin,
                     @ByVal Input end, @ByVal Input strides, @ByVal Input value) { super((Pointer)null); allocate(scope, ref, begin, end, strides, value); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input ref, @ByVal Input begin,
                     @ByVal Input end, @ByVal Input strides, @ByVal Input value);
  public StridedSliceAssign(@Const @ByRef Scope scope, @ByVal Input ref, @ByVal Input begin,
                     @ByVal Input end, @ByVal Input strides, @ByVal Input value, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, ref, begin, end, strides, value, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input ref, @ByVal Input begin,
                     @ByVal Input end, @ByVal Input strides, @ByVal Input value, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs BeginMask(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs EndMask(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs EllipsisMask(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs NewAxisMask(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs ShrinkAxisMask(@Cast("tensorflow::int64") long x);

  public native @ByRef Output output_ref(); public native StridedSliceAssign output_ref(Output output_ref);
}

// Returns the gradient of `StridedSlice`.
//
// Since `StridedSlice` cuts out pieces of its `input` which is size
// `shape`, its gradient will have the same shape (which is passed here
// as `shape`). The gradient will be zero in any element that the slice
// does not select.
//
// Arguments are the same as StridedSliceGrad with the exception that
// `dy` is the input gradient to be propagated and `shape` is the
// shape of `StridedSlice`'s `input`.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class StridedSliceGrad extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public StridedSliceGrad(Pointer p) { super(p); }

  // Optional attribute setters for StridedSliceGrad :
  //
  // BeginMask(int64): Defaults to 0
  // EndMask(int64): Defaults to 0
  // EllipsisMask(int64): Defaults to 0
  // NewAxisMask(int64): Defaults to 0
  // ShrinkAxisMask(int64): Defaults to 0
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs BeginMask(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs EndMask(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs EllipsisMask(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs NewAxisMask(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs ShrinkAxisMask(@Cast("tensorflow::int64") long x);

    public native @Cast("tensorflow::int64") long begin_mask_(); public native Attrs begin_mask_(long begin_mask_);
    public native @Cast("tensorflow::int64") long end_mask_(); public native Attrs end_mask_(long end_mask_);
    public native @Cast("tensorflow::int64") long ellipsis_mask_(); public native Attrs ellipsis_mask_(long ellipsis_mask_);
    public native @Cast("tensorflow::int64") long new_axis_mask_(); public native Attrs new_axis_mask_(long new_axis_mask_);
    public native @Cast("tensorflow::int64") long shrink_axis_mask_(); public native Attrs shrink_axis_mask_(long shrink_axis_mask_);
  }
  public StridedSliceGrad(@Const @ByRef Scope scope, @ByVal Input shape, @ByVal Input begin,
                   @ByVal Input end, @ByVal Input strides, @ByVal Input dy) { super((Pointer)null); allocate(scope, shape, begin, end, strides, dy); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input shape, @ByVal Input begin,
                   @ByVal Input end, @ByVal Input strides, @ByVal Input dy);
  public StridedSliceGrad(@Const @ByRef Scope scope, @ByVal Input shape, @ByVal Input begin,
                   @ByVal Input end, @ByVal Input strides, @ByVal Input dy, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, shape, begin, end, strides, dy, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input shape, @ByVal Input begin,
                   @ByVal Input end, @ByVal Input strides, @ByVal Input dy, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs BeginMask(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs EndMask(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs EllipsisMask(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs NewAxisMask(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs ShrinkAxisMask(@Cast("tensorflow::int64") long x);

  public native @ByRef Output output(); public native StridedSliceGrad output(Output output);
}

// Constructs a tensor by tiling a given tensor.
//
// This operation creates a new tensor by replicating `input` `multiples` times.
// The output tensor's i'th dimension has `input.dims(i) * multiples[i]` elements,
// and the values of `input` are replicated `multiples[i]` times along the 'i'th
// dimension. For example, tiling `[a b c d]` by `[2]` produces
// `[a b c d a b c d]`.
//
// Arguments:
// * scope: A Scope object
// * input: 1-D or higher.
// * multiples: 1-D. Length must be the same as the number of dimensions in `input`
@Namespace("tensorflow::ops") @NoOffset public static class Tile extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Tile(Pointer p) { super(p); }

  public Tile(@Const @ByRef Scope scope, @ByVal Input input,
       @ByVal Input multiples) { super((Pointer)null); allocate(scope, input, multiples); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
       @ByVal Input multiples);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native Tile output(Output output);
}

// Returns the gradient of `Tile`.
//
// DEPRECATED at GraphDef version 3:
// TileGrad has been replaced with reduce_sum.
//
// Since `Tile` takes an input and repeats the input `multiples` times
// along each dimension, `TileGrad` takes in `multiples` and aggregates
// each repeated tile of `input` into `output`.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class TileGrad extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TileGrad(Pointer p) { super(p); }

  public TileGrad(@Const @ByRef Scope scope, @ByVal Input input,
           @ByVal Input multiples) { super((Pointer)null); allocate(scope, input, multiples); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
           @ByVal Input multiples);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native TileGrad output(Output output);
}

// Shuffle dimensions of x according to a permutation.
//
// The output `y` has the same rank as `x`. The shapes of `x` and `y` satisfy:
//   `y.shape[i] == x.shape[perm[i]] for i in [0, 1, ..., rank(x) - 1]`
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Transpose extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Transpose(Pointer p) { super(p); }

  public Transpose(@Const @ByRef Scope scope, @ByVal Input x,
            @ByVal Input perm) { super((Pointer)null); allocate(scope, x, perm); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x,
            @ByVal Input perm);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output y(); public native Transpose y(Output y);
}

// Finds unique elements in a 1-D tensor.
//
// This operation returns a tensor `y` containing all of the unique elements of `x`
// sorted in the same order that they occur in `x`. This operation also returns a
// tensor `idx` the same size as `x` that contains the index of each value of `x`
// in the unique output `y`. In other words:
//
// `y[idx[i]] = x[i] for i in [0, 1,...,rank(x) - 1]`
//
// For example:
//
// ```prettyprint
// # tensor 'x' is [1, 1, 2, 4, 4, 4, 7, 8, 8]
// y, idx = unique(x)
// y ==> [1, 2, 4, 7, 8]
// idx ==> [0, 0, 1, 2, 2, 2, 3, 4, 4]
// ```
//
// Arguments:
// * scope: A Scope object
// * x: 1-D.
@Namespace("tensorflow::ops") @NoOffset public static class Unique extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Unique(Pointer p) { super(p); }

  // Optional attribute setters for Unique :
  //
  // OutIdx(DataType): Defaults to DT_INT32
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs OutIdx(@Cast("tensorflow::DataType") int x);

    public native @Cast("tensorflow::DataType") int out_idx_(); public native Attrs out_idx_(int out_idx_);
  }
  public Unique(@Const @ByRef Scope scope, @ByVal Input x) { super((Pointer)null); allocate(scope, x); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x);
  public Unique(@Const @ByRef Scope scope, @ByVal Input x, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, x, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x, @Const @ByRef Attrs attrs);

  public static native @ByVal Attrs OutIdx(@Cast("tensorflow::DataType") int x);

  public native @ByRef Output y(); public native Unique y(Output y);
  public native @ByRef Output idx(); public native Unique idx(Output idx);
}

// Finds unique elements in a 1-D tensor.
//
// This operation returns a tensor `y` containing all of the unique elements of `x`
// sorted in the same order that they occur in `x`. This operation also returns a
// tensor `idx` the same size as `x` that contains the index of each value of `x`
// in the unique output `y`. Finally, it returns a third tensor `count` that
// contains the count of each element of `y` in `x`. In other words:
//
// `y[idx[i]] = x[i] for i in [0, 1,...,rank(x) - 1]`
//
// For example:
//
// ```prettyprint
// # tensor 'x' is [1, 1, 2, 4, 4, 4, 7, 8, 8]
// y, idx, count = unique_with_counts(x)
// y ==> [1, 2, 4, 7, 8]
// idx ==> [0, 0, 1, 2, 2, 2, 3, 4, 4]
// count ==> [2, 1, 3, 1, 2]
// ```
//
// Arguments:
// * scope: A Scope object
// * x: 1-D.
@Namespace("tensorflow::ops") @NoOffset public static class UniqueWithCounts extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public UniqueWithCounts(Pointer p) { super(p); }

  // Optional attribute setters for UniqueWithCounts :
  //
  // OutIdx(DataType): Defaults to DT_INT32
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs OutIdx(@Cast("tensorflow::DataType") int x);

    public native @Cast("tensorflow::DataType") int out_idx_(); public native Attrs out_idx_(int out_idx_);
  }
  public UniqueWithCounts(@Const @ByRef Scope scope, @ByVal Input x) { super((Pointer)null); allocate(scope, x); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x);
  public UniqueWithCounts(@Const @ByRef Scope scope, @ByVal Input x,
                   @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, x, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x,
                   @Const @ByRef Attrs attrs);

  public static native @ByVal Attrs OutIdx(@Cast("tensorflow::DataType") int x);

  public native @ByRef Output y(); public native UniqueWithCounts y(Output y);
  public native @ByRef Output idx(); public native UniqueWithCounts idx(Output idx);
  public native @ByRef Output count(); public native UniqueWithCounts count(Output count);
}

// Unpacks a given dimension of a rank-`R` tensor into `num` rank-`(R-1)` tensors.
//
// Unpacks `num` tensors from `value` by chipping it along the `axis` dimension.
// For example, given a tensor of shape `(A, B, C, D)`;
//
// If `axis == 0` then the i'th tensor in `output` is the slice `value[i, :, :, :]`
//   and each tensor in `output` will have shape `(B, C, D)`. (Note that the
//   dimension unpacked along is gone, unlike `split`).
//
// If `axis == 1` then the i'th tensor in `output` is the slice `value[:, i, :, :]`
//   and each tensor in `output` will have shape `(A, C, D)`.
// Etc.
//
// This is the opposite of `pack`.
//
// Arguments:
// * scope: A Scope object
// * value: 1-D or higher, with `axis` dimension size equal to `num`.
@Namespace("tensorflow::ops") @NoOffset public static class Unpack extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Unpack(Pointer p) { super(p); }

  // Optional attribute setters for Unpack :
  //
  // Axis(int64): Defaults to 0
  //     Dimension along which to unpack.  Negative values wrap around, so the
  // valid range is `[-R, R)`.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Axis(@Cast("tensorflow::int64") long x);

    public native @Cast("tensorflow::int64") long axis_(); public native Attrs axis_(long axis_);
  }
  public Unpack(@Const @ByRef Scope scope, @ByVal Input value, @Cast("tensorflow::int64") long num) { super((Pointer)null); allocate(scope, value, num); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input value, @Cast("tensorflow::int64") long num);
  public Unpack(@Const @ByRef Scope scope, @ByVal Input value, @Cast("tensorflow::int64") long num, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, value, num, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input value, @Cast("tensorflow::int64") long num, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator []") Output get(@Cast("size_t") long index);


  public static native @ByVal Attrs Axis(@Cast("tensorflow::int64") long x);

  public native @ByRef @Cast("tensorflow::ops::OutputList*") StringVector output(); public native Unpack output(StringVector output);
}

// Returns locations of true values in a boolean tensor.
//
// This operation returns the coordinates of true elements in `input`. The
// coordinates are returned in a 2-D tensor where the first dimension (rows)
// represents the number of true elements, and the second dimension (columns)
// represents the coordinates of the true elements. Keep in mind, the shape of
// the output tensor can vary depending on how many true values there are in
// `input`. Indices are output in row-major order.
//
// For example:
//
// ```prettyprint
// # 'input' tensor is [[True, False]
// #                    [True, False]]
// # 'input' has two true values, so output has two coordinates.
// # 'input' has rank of 2, so coordinates have two indices.
// where(input) ==> [[0, 0],
//                   [1, 0]]
//
// # `input` tensor is [[[True, False]
// #                     [True, False]]
// #                    [[False, True]
// #                     [False, True]]
// #                    [[False, False]
// #                     [False, True]]]
// # 'input' has 5 true values, so output has 5 coordinates.
// # 'input' has rank of 3, so coordinates have three indices.
// where(input) ==> [[0, 0, 0],
//                   [0, 1, 0],
//                   [1, 0, 1],
//                   [1, 1, 1],
//                   [2, 1, 1]]
// ```
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Where extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Where(Pointer p) { super(p); }

  public Where(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output index(); public native Where index(Output index);
}

// Returns a tensor of zeros with the same shape and type as x.
//
// Arguments:
// * scope: A Scope object
// * x: a tensor of type T.
@Namespace("tensorflow::ops") @NoOffset public static class ZerosLike extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ZerosLike(Pointer p) { super(p); }

  public ZerosLike(@Const @ByRef Scope scope, @ByVal Input x) { super((Pointer)null); allocate(scope, x); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output y(); public native ZerosLike y(Output y);
}

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_ARRAY_OPS_H_


// Parsed from tensorflow/cc/ops/candidate_sampling_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_CANDIDATE_SAMPLING_OPS_H_
// #define TENSORFLOW_CC_OPS_CANDIDATE_SAMPLING_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"

// Generates labels for candidate sampling with a learned unigram distribution.
//
// See explanations of candidate sampling and the data formats at
// go/candidate-sampling.
//
// For each batch, this op picks a single set of sampled candidate labels.
//
// The advantages of sampling candidates per-batch are simplicity and the
// possibility of efficient dense matrix multiplication. The disadvantage is that
// the sampled candidates must be chosen independently of the context and of the
// true labels.
//
// Arguments:
// * scope: A Scope object
// * true_classes: A batch_size * num_true matrix, in which each row contains the
// IDs of the num_true target_classes in the corresponding original label.
// * num_true:
//     Number of true labels per context.
// * num_sampled:
//     Number of candidates to produce per batch.
// * unique:
//     If unique is true, we sample with rejection, so that all sampled
// candidates in a batch are unique. This requires some approximation to
// estimate the post-rejection sampling probabilities.
@Namespace("tensorflow::ops") @NoOffset public static class AllCandidateSampler extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public AllCandidateSampler(Pointer p) { super(p); }

  // Optional attribute setters for AllCandidateSampler :
  //
  // Seed(int64): Defaults to 0
  //     If either seed or seed2 are set to be non-zero, the random number
  // generator is seeded by the given seed.  Otherwise, it is seeded by a
  // random seed.
  // Seed2(int64): Defaults to 0
  //     An second seed to avoid seed collision.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);

    public native @Cast("tensorflow::int64") long seed_(); public native Attrs seed_(long seed_);
    public native @Cast("tensorflow::int64") long seed2_(); public native Attrs seed2_(long seed2_);
  }
  public AllCandidateSampler(@Const @ByRef Scope scope, @ByVal Input true_classes, @Cast("tensorflow::int64") long num_true, @Cast("tensorflow::int64") long num_sampled, @Cast("bool") boolean unique) { super((Pointer)null); allocate(scope, true_classes, num_true, num_sampled, unique); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input true_classes, @Cast("tensorflow::int64") long num_true, @Cast("tensorflow::int64") long num_sampled, @Cast("bool") boolean unique);
  public AllCandidateSampler(@Const @ByRef Scope scope, @ByVal Input true_classes, @Cast("tensorflow::int64") long num_true, @Cast("tensorflow::int64") long num_sampled, @Cast("bool") boolean unique, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, true_classes, num_true, num_sampled, unique, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input true_classes, @Cast("tensorflow::int64") long num_true, @Cast("tensorflow::int64") long num_sampled, @Cast("bool") boolean unique, @Const @ByRef Attrs attrs);

  public static native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);

  public native @ByRef Output sampled_candidates(); public native AllCandidateSampler sampled_candidates(Output sampled_candidates);
  public native @ByRef Output true_expected_count(); public native AllCandidateSampler true_expected_count(Output true_expected_count);
  public native @ByRef Output sampled_expected_count(); public native AllCandidateSampler sampled_expected_count(Output sampled_expected_count);
}

// Computes the ids of the positions in sampled_candidates that match true_labels.
//
// When doing log-odds NCE, the result of this op should be passed through a
// SparseToDense op, then added to the logits of the sampled candidates. This has
// the effect of 'removing' the sampled labels that match the true labels by
// making the classifier sure that they are sampled labels.
//
// Arguments:
// * scope: A Scope object
// * true_classes: The true_classes output of UnpackSparseLabels.
// * sampled_candidates: The sampled_candidates output of CandidateSampler.
// * num_true:
//     Number of true labels per context.
@Namespace("tensorflow::ops") @NoOffset public static class ComputeAccidentalHits extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ComputeAccidentalHits(Pointer p) { super(p); }

  // Optional attribute setters for ComputeAccidentalHits :
  //
  // Seed(int64): Defaults to 0
  //     If either seed or seed2 are set to be non-zero, the random number
  // generator is seeded by the given seed.  Otherwise, it is seeded by a
  // random seed.
  // Seed2(int64): Defaults to 0
  //     An second seed to avoid seed collision.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);

    public native @Cast("tensorflow::int64") long seed_(); public native Attrs seed_(long seed_);
    public native @Cast("tensorflow::int64") long seed2_(); public native Attrs seed2_(long seed2_);
  }
  public ComputeAccidentalHits(@Const @ByRef Scope scope,
                        @ByVal Input true_classes,
                        @ByVal Input sampled_candidates, @Cast("tensorflow::int64") long num_true) { super((Pointer)null); allocate(scope, true_classes, sampled_candidates, num_true); }
  private native void allocate(@Const @ByRef Scope scope,
                        @ByVal Input true_classes,
                        @ByVal Input sampled_candidates, @Cast("tensorflow::int64") long num_true);
  public ComputeAccidentalHits(@Const @ByRef Scope scope,
                        @ByVal Input true_classes,
                        @ByVal Input sampled_candidates, @Cast("tensorflow::int64") long num_true, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, true_classes, sampled_candidates, num_true, attrs); }
  private native void allocate(@Const @ByRef Scope scope,
                        @ByVal Input true_classes,
                        @ByVal Input sampled_candidates, @Cast("tensorflow::int64") long num_true, @Const @ByRef Attrs attrs);

  public static native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);

  public native @ByRef Output indices(); public native ComputeAccidentalHits indices(Output indices);
  public native @ByRef Output ids(); public native ComputeAccidentalHits ids(Output ids);
  public native @ByRef Output weights(); public native ComputeAccidentalHits weights(Output weights);
}

// Generates labels for candidate sampling with a learned unigram distribution.
//
// A unigram sampler could use a fixed unigram distribution read from a
// file or passed in as an in-memory array instead of building up the distribution
// from data on the fly. There is also an option to skew the distribution by
// applying a distortion power to the weights.
//
// The vocabulary file should be in CSV-like format, with the last field
// being the weight associated with the word.
//
// For each batch, this op picks a single set of sampled candidate labels.
//
// The advantages of sampling candidates per-batch are simplicity and the
// possibility of efficient dense matrix multiplication. The disadvantage is that
// the sampled candidates must be chosen independently of the context and of the
// true labels.
//
// Arguments:
// * scope: A Scope object
// * true_classes: A batch_size * num_true matrix, in which each row contains the
// IDs of the num_true target_classes in the corresponding original label.
// * num_true:
//     Number of true labels per context.
// * num_sampled:
//     Number of candidates to randomly sample per batch.
// * unique:
//     If unique is true, we sample with rejection, so that all sampled
// candidates in a batch are unique. This requires some approximation to
// estimate the post-rejection sampling probabilities.
// * range_max:
//     The sampler will sample integers from the interval [0, range_max).
@Namespace("tensorflow::ops") @NoOffset public static class FixedUnigramCandidateSampler extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public FixedUnigramCandidateSampler(Pointer p) { super(p); }

  // Optional attribute setters for FixedUnigramCandidateSampler :
  //
  // VocabFile(StringPiece): Defaults to ""
  //     Each valid line in this file (which should have a CSV-like format)
  // corresponds to a valid word ID. IDs are in sequential order, starting from
  // num_reserved_ids. The last entry in each line is expected to be a value
  // corresponding to the count or relative probability. Exactly one of vocab_file
  // and unigrams needs to be passed to this op.
  // Distortion(float): Defaults to 1
  //     The distortion is used to skew the unigram probability distribution.
  // Each weight is first raised to the distortion's power before adding to the
  // internal unigram distribution. As a result, distortion = 1.0 gives regular
  // unigram sampling (as defined by the vocab file), and distortion = 0.0 gives
  // a uniform distribution.
  // NumReservedIds(int64): Defaults to 0
  //     Optionally some reserved IDs can be added in the range [0,
  // ..., num_reserved_ids) by the users. One use case is that a special unknown
  // word token is used as ID 0. These IDs will have a sampling probability of 0.
  // NumShards(int64): Defaults to 1
  //     A sampler can be used to sample from a subset of the original range
  // in order to speed up the whole computation through parallelism. This parameter
  // (together with 'shard') indicates the number of partitions that are being
  // used in the overall computation.
  // Shard(int64): Defaults to 0
  //     A sampler can be used to sample from a subset of the original range
  // in order to speed up the whole computation through parallelism. This parameter
  // (together with 'num_shards') indicates the particular partition number of a
  // sampler op, when partitioning is being used.
  // Unigrams(const gtl::ArraySlice<float>&): Defaults to []
  //     A list of unigram counts or probabilities, one per ID in sequential
  // order. Exactly one of vocab_file and unigrams should be passed to this op.
  // Seed(int64): Defaults to 0
  //     If either seed or seed2 are set to be non-zero, the random number
  // generator is seeded by the given seed.  Otherwise, it is seeded by a
  // random seed.
  // Seed2(int64): Defaults to 0
  //     An second seed to avoid seed collision.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs VocabFile(@StringPiece BytePointer x);
    public native @ByVal Attrs VocabFile(@StringPiece String x);

    public native @ByVal Attrs Distortion(float x);

    public native @ByVal Attrs NumReservedIds(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs NumShards(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs Shard(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs Unigrams(@ArraySlice FloatPointer x);
    public native @ByVal Attrs Unigrams(@ArraySlice FloatBuffer x);
    public native @ByVal Attrs Unigrams(@ArraySlice float... x);

    public native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);

    public native @StringPiece BytePointer vocab_file_(); public native Attrs vocab_file_(BytePointer vocab_file_);
    public native float distortion_(); public native Attrs distortion_(float distortion_);
    public native @Cast("tensorflow::int64") long num_reserved_ids_(); public native Attrs num_reserved_ids_(long num_reserved_ids_);
    public native @Cast("tensorflow::int64") long num_shards_(); public native Attrs num_shards_(long num_shards_);
    public native @Cast("tensorflow::int64") long shard_(); public native Attrs shard_(long shard_);
    public native @ArraySlice FloatPointer unigrams_(); public native Attrs unigrams_(FloatPointer unigrams_);
    public native @Cast("tensorflow::int64") long seed_(); public native Attrs seed_(long seed_);
    public native @Cast("tensorflow::int64") long seed2_(); public native Attrs seed2_(long seed2_);
  }
  public FixedUnigramCandidateSampler(@Const @ByRef Scope scope,
                               @ByVal Input true_classes, @Cast("tensorflow::int64") long num_true, @Cast("tensorflow::int64") long num_sampled, @Cast("bool") boolean unique, @Cast("tensorflow::int64") long range_max) { super((Pointer)null); allocate(scope, true_classes, num_true, num_sampled, unique, range_max); }
  private native void allocate(@Const @ByRef Scope scope,
                               @ByVal Input true_classes, @Cast("tensorflow::int64") long num_true, @Cast("tensorflow::int64") long num_sampled, @Cast("bool") boolean unique, @Cast("tensorflow::int64") long range_max);
  public FixedUnigramCandidateSampler(@Const @ByRef Scope scope,
                               @ByVal Input true_classes, @Cast("tensorflow::int64") long num_true, @Cast("tensorflow::int64") long num_sampled, @Cast("bool") boolean unique, @Cast("tensorflow::int64") long range_max, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, true_classes, num_true, num_sampled, unique, range_max, attrs); }
  private native void allocate(@Const @ByRef Scope scope,
                               @ByVal Input true_classes, @Cast("tensorflow::int64") long num_true, @Cast("tensorflow::int64") long num_sampled, @Cast("bool") boolean unique, @Cast("tensorflow::int64") long range_max, @Const @ByRef Attrs attrs);

  public static native @ByVal Attrs VocabFile(@StringPiece BytePointer x);
  public static native @ByVal Attrs VocabFile(@StringPiece String x);
  public static native @ByVal Attrs Distortion(float x);
  public static native @ByVal Attrs NumReservedIds(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs NumShards(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs Shard(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs Unigrams(@ArraySlice FloatPointer x);
  public static native @ByVal Attrs Unigrams(@ArraySlice FloatBuffer x);
  public static native @ByVal Attrs Unigrams(@ArraySlice float... x);
  public static native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);

  public native @ByRef Output sampled_candidates(); public native FixedUnigramCandidateSampler sampled_candidates(Output sampled_candidates);
  public native @ByRef Output true_expected_count(); public native FixedUnigramCandidateSampler true_expected_count(Output true_expected_count);
  public native @ByRef Output sampled_expected_count(); public native FixedUnigramCandidateSampler sampled_expected_count(Output sampled_expected_count);
}

// Generates labels for candidate sampling with a learned unigram distribution.
//
// See explanations of candidate sampling and the data formats at
// go/candidate-sampling.
//
// For each batch, this op picks a single set of sampled candidate labels.
//
// The advantages of sampling candidates per-batch are simplicity and the
// possibility of efficient dense matrix multiplication. The disadvantage is that
// the sampled candidates must be chosen independently of the context and of the
// true labels.
//
// Arguments:
// * scope: A Scope object
// * true_classes: A batch_size * num_true matrix, in which each row contains the
// IDs of the num_true target_classes in the corresponding original label.
// * num_true:
//     Number of true labels per context.
// * num_sampled:
//     Number of candidates to randomly sample per batch.
// * unique:
//     If unique is true, we sample with rejection, so that all sampled
// candidates in a batch are unique. This requires some approximation to
// estimate the post-rejection sampling probabilities.
// * range_max:
//     The sampler will sample integers from the interval [0, range_max).
@Namespace("tensorflow::ops") @NoOffset public static class LearnedUnigramCandidateSampler extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public LearnedUnigramCandidateSampler(Pointer p) { super(p); }

  // Optional attribute setters for LearnedUnigramCandidateSampler :
  //
  // Seed(int64): Defaults to 0
  //     If either seed or seed2 are set to be non-zero, the random number
  // generator is seeded by the given seed.  Otherwise, it is seeded by a
  // random seed.
  // Seed2(int64): Defaults to 0
  //     An second seed to avoid seed collision.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);

    public native @Cast("tensorflow::int64") long seed_(); public native Attrs seed_(long seed_);
    public native @Cast("tensorflow::int64") long seed2_(); public native Attrs seed2_(long seed2_);
  }
  public LearnedUnigramCandidateSampler(@Const @ByRef Scope scope,
                                 @ByVal Input true_classes, @Cast("tensorflow::int64") long num_true, @Cast("tensorflow::int64") long num_sampled, @Cast("bool") boolean unique, @Cast("tensorflow::int64") long range_max) { super((Pointer)null); allocate(scope, true_classes, num_true, num_sampled, unique, range_max); }
  private native void allocate(@Const @ByRef Scope scope,
                                 @ByVal Input true_classes, @Cast("tensorflow::int64") long num_true, @Cast("tensorflow::int64") long num_sampled, @Cast("bool") boolean unique, @Cast("tensorflow::int64") long range_max);
  public LearnedUnigramCandidateSampler(@Const @ByRef Scope scope,
                                 @ByVal Input true_classes, @Cast("tensorflow::int64") long num_true, @Cast("tensorflow::int64") long num_sampled, @Cast("bool") boolean unique, @Cast("tensorflow::int64") long range_max, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, true_classes, num_true, num_sampled, unique, range_max, attrs); }
  private native void allocate(@Const @ByRef Scope scope,
                                 @ByVal Input true_classes, @Cast("tensorflow::int64") long num_true, @Cast("tensorflow::int64") long num_sampled, @Cast("bool") boolean unique, @Cast("tensorflow::int64") long range_max, @Const @ByRef Attrs attrs);

  public static native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);

  public native @ByRef Output sampled_candidates(); public native LearnedUnigramCandidateSampler sampled_candidates(Output sampled_candidates);
  public native @ByRef Output true_expected_count(); public native LearnedUnigramCandidateSampler true_expected_count(Output true_expected_count);
  public native @ByRef Output sampled_expected_count(); public native LearnedUnigramCandidateSampler sampled_expected_count(Output sampled_expected_count);
}

// Generates labels for candidate sampling with a log-uniform distribution.
//
// See explanations of candidate sampling and the data formats at
// go/candidate-sampling.
//
// For each batch, this op picks a single set of sampled candidate labels.
//
// The advantages of sampling candidates per-batch are simplicity and the
// possibility of efficient dense matrix multiplication. The disadvantage is that
// the sampled candidates must be chosen independently of the context and of the
// true labels.
//
// Arguments:
// * scope: A Scope object
// * true_classes: A batch_size * num_true matrix, in which each row contains the
// IDs of the num_true target_classes in the corresponding original label.
// * num_true:
//     Number of true labels per context.
// * num_sampled:
//     Number of candidates to randomly sample per batch.
// * unique:
//     If unique is true, we sample with rejection, so that all sampled
// candidates in a batch are unique. This requires some approximation to
// estimate the post-rejection sampling probabilities.
// * range_max:
//     The sampler will sample integers from the interval [0, range_max).
@Namespace("tensorflow::ops") @NoOffset public static class LogUniformCandidateSampler extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public LogUniformCandidateSampler(Pointer p) { super(p); }

  // Optional attribute setters for LogUniformCandidateSampler :
  //
  // Seed(int64): Defaults to 0
  //     If either seed or seed2 are set to be non-zero, the random number
  // generator is seeded by the given seed.  Otherwise, it is seeded by a
  // random seed.
  // Seed2(int64): Defaults to 0
  //     An second seed to avoid seed collision.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);

    public native @Cast("tensorflow::int64") long seed_(); public native Attrs seed_(long seed_);
    public native @Cast("tensorflow::int64") long seed2_(); public native Attrs seed2_(long seed2_);
  }
  public LogUniformCandidateSampler(@Const @ByRef Scope scope,
                             @ByVal Input true_classes, @Cast("tensorflow::int64") long num_true, @Cast("tensorflow::int64") long num_sampled, @Cast("bool") boolean unique, @Cast("tensorflow::int64") long range_max) { super((Pointer)null); allocate(scope, true_classes, num_true, num_sampled, unique, range_max); }
  private native void allocate(@Const @ByRef Scope scope,
                             @ByVal Input true_classes, @Cast("tensorflow::int64") long num_true, @Cast("tensorflow::int64") long num_sampled, @Cast("bool") boolean unique, @Cast("tensorflow::int64") long range_max);
  public LogUniformCandidateSampler(@Const @ByRef Scope scope,
                             @ByVal Input true_classes, @Cast("tensorflow::int64") long num_true, @Cast("tensorflow::int64") long num_sampled, @Cast("bool") boolean unique, @Cast("tensorflow::int64") long range_max, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, true_classes, num_true, num_sampled, unique, range_max, attrs); }
  private native void allocate(@Const @ByRef Scope scope,
                             @ByVal Input true_classes, @Cast("tensorflow::int64") long num_true, @Cast("tensorflow::int64") long num_sampled, @Cast("bool") boolean unique, @Cast("tensorflow::int64") long range_max, @Const @ByRef Attrs attrs);

  public static native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);

  public native @ByRef Output sampled_candidates(); public native LogUniformCandidateSampler sampled_candidates(Output sampled_candidates);
  public native @ByRef Output true_expected_count(); public native LogUniformCandidateSampler true_expected_count(Output true_expected_count);
  public native @ByRef Output sampled_expected_count(); public native LogUniformCandidateSampler sampled_expected_count(Output sampled_expected_count);
}

// Generates labels for candidate sampling with a learned unigram distribution.
//
// See explanations of candidate sampling and the data formats at
// go/candidate-sampling.
//
// For each batch, this op picks a single set of sampled candidate labels.
//
// The advantages of sampling candidates per-batch are simplicity and the
// possibility of efficient dense matrix multiplication. The disadvantage is that
// the sampled candidates must be chosen independently of the context and of the
// true labels.
//
// Arguments:
// * scope: A Scope object
// * true_classes: A batch_size * num_true matrix, in which each row contains the
// IDs of the num_true target_classes in the corresponding original label.
// * num_true:
//     Number of true labels per context.
// * num_sampled:
//     Number of candidates to randomly sample per batch.
// * unique:
//     If unique is true, we sample with rejection, so that all sampled
// candidates in a batch are unique. This requires some approximation to
// estimate the post-rejection sampling probabilities.
// * range_max:
//     The sampler will sample integers from the interval [0, range_max).
@Namespace("tensorflow::ops") @NoOffset public static class ThreadUnsafeUnigramCandidateSampler extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ThreadUnsafeUnigramCandidateSampler(Pointer p) { super(p); }

  // Optional attribute setters for ThreadUnsafeUnigramCandidateSampler :
  //
  // Seed(int64): Defaults to 0
  //     If either seed or seed2 are set to be non-zero, the random number
  // generator is seeded by the given seed.  Otherwise, it is seeded by a
  // random seed.
  // Seed2(int64): Defaults to 0
  //     An second seed to avoid seed collision.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);

    public native @Cast("tensorflow::int64") long seed_(); public native Attrs seed_(long seed_);
    public native @Cast("tensorflow::int64") long seed2_(); public native Attrs seed2_(long seed2_);
  }
  public ThreadUnsafeUnigramCandidateSampler(@Const @ByRef Scope scope,
                                      @ByVal Input true_classes,
                                      @Cast("tensorflow::int64") long num_true, @Cast("tensorflow::int64") long num_sampled, @Cast("bool") boolean unique, @Cast("tensorflow::int64") long range_max) { super((Pointer)null); allocate(scope, true_classes, num_true, num_sampled, unique, range_max); }
  private native void allocate(@Const @ByRef Scope scope,
                                      @ByVal Input true_classes,
                                      @Cast("tensorflow::int64") long num_true, @Cast("tensorflow::int64") long num_sampled, @Cast("bool") boolean unique, @Cast("tensorflow::int64") long range_max);
  public ThreadUnsafeUnigramCandidateSampler(@Const @ByRef Scope scope,
                                      @ByVal Input true_classes,
                                      @Cast("tensorflow::int64") long num_true, @Cast("tensorflow::int64") long num_sampled, @Cast("bool") boolean unique, @Cast("tensorflow::int64") long range_max, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, true_classes, num_true, num_sampled, unique, range_max, attrs); }
  private native void allocate(@Const @ByRef Scope scope,
                                      @ByVal Input true_classes,
                                      @Cast("tensorflow::int64") long num_true, @Cast("tensorflow::int64") long num_sampled, @Cast("bool") boolean unique, @Cast("tensorflow::int64") long range_max, @Const @ByRef Attrs attrs);

  public static native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);

  public native @ByRef Output sampled_candidates(); public native ThreadUnsafeUnigramCandidateSampler sampled_candidates(Output sampled_candidates);
  public native @ByRef Output true_expected_count(); public native ThreadUnsafeUnigramCandidateSampler true_expected_count(Output true_expected_count);
  public native @ByRef Output sampled_expected_count(); public native ThreadUnsafeUnigramCandidateSampler sampled_expected_count(Output sampled_expected_count);
}

// Generates labels for candidate sampling with a uniform distribution.
//
// See explanations of candidate sampling and the data formats at
// go/candidate-sampling.
//
// For each batch, this op picks a single set of sampled candidate labels.
//
// The advantages of sampling candidates per-batch are simplicity and the
// possibility of efficient dense matrix multiplication. The disadvantage is that
// the sampled candidates must be chosen independently of the context and of the
// true labels.
//
// Arguments:
// * scope: A Scope object
// * true_classes: A batch_size * num_true matrix, in which each row contains the
// IDs of the num_true target_classes in the corresponding original label.
// * num_true:
//     Number of true labels per context.
// * num_sampled:
//     Number of candidates to randomly sample per batch.
// * unique:
//     If unique is true, we sample with rejection, so that all sampled
// candidates in a batch are unique. This requires some approximation to
// estimate the post-rejection sampling probabilities.
// * range_max:
//     The sampler will sample integers from the interval [0, range_max).
@Namespace("tensorflow::ops") @NoOffset public static class UniformCandidateSampler extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public UniformCandidateSampler(Pointer p) { super(p); }

  // Optional attribute setters for UniformCandidateSampler :
  //
  // Seed(int64): Defaults to 0
  //     If either seed or seed2 are set to be non-zero, the random number
  // generator is seeded by the given seed.  Otherwise, it is seeded by a
  // random seed.
  // Seed2(int64): Defaults to 0
  //     An second seed to avoid seed collision.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);

    public native @Cast("tensorflow::int64") long seed_(); public native Attrs seed_(long seed_);
    public native @Cast("tensorflow::int64") long seed2_(); public native Attrs seed2_(long seed2_);
  }
  public UniformCandidateSampler(@Const @ByRef Scope scope,
                          @ByVal Input true_classes, @Cast("tensorflow::int64") long num_true,
                          @Cast("tensorflow::int64") long num_sampled, @Cast("bool") boolean unique, @Cast("tensorflow::int64") long range_max) { super((Pointer)null); allocate(scope, true_classes, num_true, num_sampled, unique, range_max); }
  private native void allocate(@Const @ByRef Scope scope,
                          @ByVal Input true_classes, @Cast("tensorflow::int64") long num_true,
                          @Cast("tensorflow::int64") long num_sampled, @Cast("bool") boolean unique, @Cast("tensorflow::int64") long range_max);
  public UniformCandidateSampler(@Const @ByRef Scope scope,
                          @ByVal Input true_classes, @Cast("tensorflow::int64") long num_true,
                          @Cast("tensorflow::int64") long num_sampled, @Cast("bool") boolean unique, @Cast("tensorflow::int64") long range_max, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, true_classes, num_true, num_sampled, unique, range_max, attrs); }
  private native void allocate(@Const @ByRef Scope scope,
                          @ByVal Input true_classes, @Cast("tensorflow::int64") long num_true,
                          @Cast("tensorflow::int64") long num_sampled, @Cast("bool") boolean unique, @Cast("tensorflow::int64") long range_max, @Const @ByRef Attrs attrs);

  public static native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);

  public native @ByRef Output sampled_candidates(); public native UniformCandidateSampler sampled_candidates(Output sampled_candidates);
  public native @ByRef Output true_expected_count(); public native UniformCandidateSampler true_expected_count(Output true_expected_count);
  public native @ByRef Output sampled_expected_count(); public native UniformCandidateSampler sampled_expected_count(Output sampled_expected_count);
}

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_CANDIDATE_SAMPLING_OPS_H_


// Parsed from tensorflow/cc/ops/control_flow_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_CONTROL_FLOW_OPS_H_
// #define TENSORFLOW_CC_OPS_CONTROL_FLOW_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"

// Raise a exception to abort the process when called.
//
// Returns nothing but an exception.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Abort extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Abort(Pointer p) { super(p); }

  // Optional attribute setters for Abort :
  //
  // ErrorMsg(StringPiece): Defaults to ""
  //     A string which is the message associated with the exception.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs ErrorMsg(@StringPiece BytePointer x);
    public native @ByVal Attrs ErrorMsg(@StringPiece String x);

    public native @StringPiece BytePointer error_msg_(); public native Attrs error_msg_(BytePointer error_msg_);
  }
  public Abort(@Const @ByRef Scope scope) { super((Pointer)null); allocate(scope); }
  private native void allocate(@Const @ByRef Scope scope);
  public Abort(@Const @ByRef Scope scope, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Operation") Operation asOperation();

  public static native @ByVal Attrs ErrorMsg(@StringPiece BytePointer x);
  public static native @ByVal Attrs ErrorMsg(@StringPiece String x);

  public native @ByRef Operation operation(); public native Abort operation(Operation operation);
}

// Does nothing. Serves as a control trigger for scheduling.
//
// Only useful as a placeholder for control edges.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class ControlTrigger extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ControlTrigger(Pointer p) { super(p); }

  public ControlTrigger(@Const @ByRef Scope scope) { super((Pointer)null); allocate(scope); }
  private native void allocate(@Const @ByRef Scope scope);
  public native @ByVal @Name("operator tensorflow::ops::Operation") Operation asOperation();

  public native @ByRef Operation operation(); public native ControlTrigger operation(Operation operation);
}

// Creates or finds a child frame, and makes `data` available to the child frame.
//
// This op is used together with `Exit` to create loops in the graph.
// The unique `frame_name` is used by the `Executor` to identify frames. If
// `is_constant` is true, `output` is a constant in the child frame; otherwise
// it may be changed in the child frame. At most `parallel_iterations` iterations
// are run in parallel in the child frame.
//
// Arguments:
// * scope: A Scope object
// * data: The tensor to be made available to the child frame.
// * frame_name:
//     The name of the child frame.
@Namespace("tensorflow::ops") @NoOffset public static class Enter extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Enter(Pointer p) { super(p); }

  // Optional attribute setters for Enter :
  //
  // IsConstant(bool): Defaults to false
  //     If true, the output is constant within the child frame.
  // ParallelIterations(int64): Defaults to 10
  //     The number of iterations allowed to run in parallel.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs IsConstant(@Cast("bool") boolean x);

    public native @ByVal Attrs ParallelIterations(@Cast("tensorflow::int64") long x);

    public native @Cast("bool") boolean is_constant_(); public native Attrs is_constant_(boolean is_constant_);
    public native @Cast("tensorflow::int64") long parallel_iterations_(); public native Attrs parallel_iterations_(long parallel_iterations_);
  }
  public Enter(@Const @ByRef Scope scope, @ByVal Input data,
        @StringPiece BytePointer frame_name) { super((Pointer)null); allocate(scope, data, frame_name); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input data,
        @StringPiece BytePointer frame_name);
  public Enter(@Const @ByRef Scope scope, @ByVal Input data,
        @StringPiece String frame_name) { super((Pointer)null); allocate(scope, data, frame_name); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input data,
        @StringPiece String frame_name);
  public Enter(@Const @ByRef Scope scope, @ByVal Input data,
        @StringPiece BytePointer frame_name, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, data, frame_name, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input data,
        @StringPiece BytePointer frame_name, @Const @ByRef Attrs attrs);
  public Enter(@Const @ByRef Scope scope, @ByVal Input data,
        @StringPiece String frame_name, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, data, frame_name, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input data,
        @StringPiece String frame_name, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs IsConstant(@Cast("bool") boolean x);
  public static native @ByVal Attrs ParallelIterations(@Cast("tensorflow::int64") long x);

  public native @ByRef Output output(); public native Enter output(Output output);
}

// Exits the current frame to its parent frame.
//
// Exit makes its input `data` available to the parent frame.
//
// Arguments:
// * scope: A Scope object
// * data: The tensor to be made available to the parent frame.
@Namespace("tensorflow::ops") @NoOffset public static class Exit extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Exit(Pointer p) { super(p); }

  public Exit(@Const @ByRef Scope scope, @ByVal Input data) { super((Pointer)null); allocate(scope, data); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input data);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native Exit output(Output output);
}

// Forwards the input to the output.
//
// This operator represents the loop termination condition used by the
// "pivot" switches of a loop.
//
// Arguments:
// * scope: A Scope object
// * input: A boolean scalar, representing the branch predicate of the Switch op.
@Namespace("tensorflow::ops") @NoOffset public static class LoopCond extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public LoopCond(Pointer p) { super(p); }

  public LoopCond(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native LoopCond output(Output output);
}

// Forwards the value of an available tensor from `inputs` to `output`.
//
// `Merge` waits for at least one of the tensors in `inputs` to become available.
// It is usually combined with `Switch` to implement branching.
//
// `Merge` forwards the first tensor for become available to `output`, and sets
// `value_index` to its index in `inputs`.
//
// Arguments:
// * scope: A Scope object
// * inputs: The input tensors, exactly one of which will become available.
@Namespace("tensorflow::ops") @NoOffset public static class Merge extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Merge(Pointer p) { super(p); }

  public Merge(@Const @ByRef Scope scope, @ByVal InputList inputs) { super((Pointer)null); allocate(scope, inputs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal InputList inputs);

  public native @ByRef Output output(); public native Merge output(Output output);
  public native @ByRef Output value_index(); public native Merge value_index(Output value_index);
}

// Makes its input available to the next iteration.
//
// Arguments:
// * scope: A Scope object
// * data: The tensor to be made available to the next iteration.
@Namespace("tensorflow::ops") @NoOffset public static class NextIteration extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public NextIteration(Pointer p) { super(p); }

  public NextIteration(@Const @ByRef Scope scope, @ByVal Input data) { super((Pointer)null); allocate(scope, data); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input data);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native NextIteration output(Output output);
}

// Creates or finds a child frame, and makes `data` available to the child frame.
//
// The unique `frame_name` is used by the `Executor` to identify frames. If
// `is_constant` is true, `output` is a constant in the child frame; otherwise
// it may be changed in the child frame. At most `parallel_iterations` iterations
// are run in parallel in the child frame.
//
// Arguments:
// * scope: A Scope object
// * data: The tensor to be made available to the child frame.
// * frame_name:
//     The name of the child frame.
@Namespace("tensorflow::ops") @NoOffset public static class RefEnter extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public RefEnter(Pointer p) { super(p); }

  // Optional attribute setters for RefEnter :
  //
  // IsConstant(bool): Defaults to false
  //     If true, the output is constant within the child frame.
  // ParallelIterations(int64): Defaults to 10
  //     The number of iterations allowed to run in parallel.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs IsConstant(@Cast("bool") boolean x);

    public native @ByVal Attrs ParallelIterations(@Cast("tensorflow::int64") long x);

    public native @Cast("bool") boolean is_constant_(); public native Attrs is_constant_(boolean is_constant_);
    public native @Cast("tensorflow::int64") long parallel_iterations_(); public native Attrs parallel_iterations_(long parallel_iterations_);
  }
  public RefEnter(@Const @ByRef Scope scope, @ByVal Input data,
           @StringPiece BytePointer frame_name) { super((Pointer)null); allocate(scope, data, frame_name); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input data,
           @StringPiece BytePointer frame_name);
  public RefEnter(@Const @ByRef Scope scope, @ByVal Input data,
           @StringPiece String frame_name) { super((Pointer)null); allocate(scope, data, frame_name); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input data,
           @StringPiece String frame_name);
  public RefEnter(@Const @ByRef Scope scope, @ByVal Input data,
           @StringPiece BytePointer frame_name, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, data, frame_name, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input data,
           @StringPiece BytePointer frame_name, @Const @ByRef Attrs attrs);
  public RefEnter(@Const @ByRef Scope scope, @ByVal Input data,
           @StringPiece String frame_name, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, data, frame_name, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input data,
           @StringPiece String frame_name, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs IsConstant(@Cast("bool") boolean x);
  public static native @ByVal Attrs ParallelIterations(@Cast("tensorflow::int64") long x);

  public native @ByRef Output output(); public native RefEnter output(Output output);
}

// Exits the current frame to its parent frame.
//
// Exit makes its input `data` available to the parent frame.
//
// Arguments:
// * scope: A Scope object
// * data: The tensor to be made available to the parent frame.
@Namespace("tensorflow::ops") @NoOffset public static class RefExit extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public RefExit(Pointer p) { super(p); }

  public RefExit(@Const @ByRef Scope scope, @ByVal Input data) { super((Pointer)null); allocate(scope, data); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input data);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native RefExit output(Output output);
}

// Forwards the value of an available tensor from `inputs` to `output`.
//
// `Merge` waits for at least one of the tensors in `inputs` to become available.
// It is usually combined with `Switch` to implement branching.
//
// `Merge` forwards the first tensor for become available to `output`, and sets
// `value_index` to its index in `inputs`.
//
// Arguments:
// * scope: A Scope object
// * inputs: The input tensors, exactly one of which will become available.
@Namespace("tensorflow::ops") @NoOffset public static class RefMerge extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public RefMerge(Pointer p) { super(p); }

  public RefMerge(@Const @ByRef Scope scope, @ByVal InputList inputs) { super((Pointer)null); allocate(scope, inputs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal InputList inputs);

  public native @ByRef Output output(); public native RefMerge output(Output output);
  public native @ByRef Output value_index(); public native RefMerge value_index(Output value_index);
}

// Makes its input available to the next iteration.
//
// Arguments:
// * scope: A Scope object
// * data: The tensor to be made available to the next iteration.
@Namespace("tensorflow::ops") @NoOffset public static class RefNextIteration extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public RefNextIteration(Pointer p) { super(p); }

  public RefNextIteration(@Const @ByRef Scope scope, @ByVal Input data) { super((Pointer)null); allocate(scope, data); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input data);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native RefNextIteration output(Output output);
}

// Forwards the `index`th element of `inputs` to `output`.
//
// Arguments:
// * scope: A Scope object
// * index: A scalar that determines the input that gets selected.
// * inputs: A list of ref tensors, one of which will be forwarded to `output`.
@Namespace("tensorflow::ops") @NoOffset public static class RefSelect extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public RefSelect(Pointer p) { super(p); }

  public RefSelect(@Const @ByRef Scope scope, @ByVal Input index,
            @ByVal InputList inputs) { super((Pointer)null); allocate(scope, index, inputs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input index,
            @ByVal InputList inputs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native RefSelect output(Output output);
}

// Forwards the ref tensor `data` to the output port determined by `pred`.
//
// If `pred` is true, the `data` input is forwarded to `output_true`. Otherwise,
// the data goes to `output_false`.
//
// See also `Switch` and `Merge`.
//
// Arguments:
// * scope: A Scope object
// * data: The ref tensor to be forwarded to the appropriate output.
// * pred: A scalar that specifies which output port will receive data.
@Namespace("tensorflow::ops") @NoOffset public static class RefSwitch extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public RefSwitch(Pointer p) { super(p); }

  public RefSwitch(@Const @ByRef Scope scope, @ByVal Input data,
            @ByVal Input pred) { super((Pointer)null); allocate(scope, data, pred); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input data,
            @ByVal Input pred);

  public native @ByRef Output output_false(); public native RefSwitch output_false(Output output_false);
  public native @ByRef Output output_true(); public native RefSwitch output_true(Output output_true);
}

// Forwards `data` to the output port determined by `pred`.
//
// If `pred` is true, the `data` input is forwarded to `output_true`. Otherwise,
// the data goes to `output_false`.
//
// See also `RefSwitch` and `Merge`.
//
// Arguments:
// * scope: A Scope object
// * data: The tensor to be forwarded to the appropriate output.
// * pred: A scalar that specifies which output port will receive data.
@Namespace("tensorflow::ops") @NoOffset public static class Switch extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Switch(Pointer p) { super(p); }

  public Switch(@Const @ByRef Scope scope, @ByVal Input data,
         @ByVal Input pred) { super((Pointer)null); allocate(scope, data, pred); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input data,
         @ByVal Input pred);

  public native @ByRef Output output_false(); public native Switch output_false(Output output_false);
  public native @ByRef Output output_true(); public native Switch output_true(Output output_true);
}

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_CONTROL_FLOW_OPS_H_


// Parsed from tensorflow/cc/ops/data_flow_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_DATA_FLOW_OPS_H_
// #define TENSORFLOW_CC_OPS_DATA_FLOW_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"

// Defines a barrier that persists across different graph executions.
//
// A barrier represents a key-value map, where each key is a string, and
// each value is a tuple of tensors.
//
// At runtime, the barrier contains 'complete' and 'incomplete'
// elements. A complete element has defined tensors for all components of
// its value tuple, and may be accessed using BarrierTakeMany. An
// incomplete element has some undefined components in its value tuple,
// and may be updated using BarrierInsertMany.
//
// Arguments:
// * scope: A Scope object
// * component_types:
//     The type of each component in a value.
@Namespace("tensorflow::ops") @NoOffset public static class Barrier extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Barrier(Pointer p) { super(p); }

  // Optional attribute setters for Barrier :
  //
  // Shapes(const gtl::ArraySlice<TensorShape>&): Defaults to []
  //     The shape of each component in a value. Each shape must be 1 in the
  // first dimension. The length of this attr must be the same as the length of
  // component_types.
  // Capacity(int64): Defaults to -1
  //     The capacity of the barrier.  The default capacity is MAX_INT32,
  // which is the largest capacity of the underlying queue.
  // Container(StringPiece): Defaults to ""
  //     If non-empty, this barrier is placed in the given container.
  // Otherwise, a default container is used.
  // SharedName(StringPiece): Defaults to ""
  //     If non-empty, this barrier will be shared under the given name
  // across multiple sessions.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Shapes(@Cast("const tensorflow::gtl::ArraySlice<tensorflow::TensorShape>*") @ByRef TensorShapeVector x);

    public native @ByVal Attrs Capacity(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs Container(@StringPiece BytePointer x);
    public native @ByVal Attrs Container(@StringPiece String x);

    public native @ByVal Attrs SharedName(@StringPiece BytePointer x);
    public native @ByVal Attrs SharedName(@StringPiece String x);

    public native @ByRef @Cast("tensorflow::gtl::ArraySlice<tensorflow::TensorShape>*") TensorShapeVector shapes_(); public native Attrs shapes_(TensorShapeVector shapes_);
    public native @Cast("tensorflow::int64") long capacity_(); public native Attrs capacity_(long capacity_);
    public native @StringPiece BytePointer container_(); public native Attrs container_(BytePointer container_);
    public native @StringPiece BytePointer shared_name_(); public native Attrs shared_name_(BytePointer shared_name_);
  }
  public Barrier(@Const @ByRef Scope scope, @Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector component_types) { super((Pointer)null); allocate(scope, component_types); }
  private native void allocate(@Const @ByRef Scope scope, @Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector component_types);
  public Barrier(@Const @ByRef Scope scope, @Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector component_types,
          @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, component_types, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector component_types,
          @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Shapes(@Cast("const tensorflow::gtl::ArraySlice<tensorflow::TensorShape>*") @ByRef TensorShapeVector x);
  public static native @ByVal Attrs Capacity(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs Container(@StringPiece BytePointer x);
  public static native @ByVal Attrs Container(@StringPiece String x);
  public static native @ByVal Attrs SharedName(@StringPiece BytePointer x);
  public static native @ByVal Attrs SharedName(@StringPiece String x);

  public native @ByRef Output handle(); public native Barrier handle(Output handle);
}

// Closes the given barrier.
//
// This operation signals that no more new elements will be inserted in the
// given barrier. Subsequent InsertMany that try to introduce a new key will fail.
// Subsequent InsertMany operations that just add missing components to already
// existing elements will continue to succeed. Subsequent TakeMany operations will
// continue to succeed if sufficient completed elements remain in the barrier.
// Subsequent TakeMany operations that would block will fail immediately.
//
// Arguments:
// * scope: A Scope object
// * handle: The handle to a barrier.
@Namespace("tensorflow::ops") @NoOffset public static class BarrierClose extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public BarrierClose(Pointer p) { super(p); }

  // Optional attribute setters for BarrierClose :
  //
  // CancelPendingEnqueues(bool): Defaults to false
  //     If true, all pending enqueue requests that are
  // blocked on the barrier's queue will be cancelled. InsertMany will fail, even
  // if no new key is introduced.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs CancelPendingEnqueues(@Cast("bool") boolean x);

    public native @Cast("bool") boolean cancel_pending_enqueues_(); public native Attrs cancel_pending_enqueues_(boolean cancel_pending_enqueues_);
  }
  public BarrierClose(@Const @ByRef Scope scope, @ByVal Input handle) { super((Pointer)null); allocate(scope, handle); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle);
  public BarrierClose(@Const @ByRef Scope scope, @ByVal Input handle,
               @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, handle, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle,
               @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Operation") Operation asOperation();

  public static native @ByVal Attrs CancelPendingEnqueues(@Cast("bool") boolean x);

  public native @ByRef Operation operation(); public native BarrierClose operation(Operation operation);
}

// Computes the number of incomplete elements in the given barrier.
//
// Arguments:
// * scope: A Scope object
// * handle: The handle to a barrier.
@Namespace("tensorflow::ops") @NoOffset public static class BarrierIncompleteSize extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public BarrierIncompleteSize(Pointer p) { super(p); }

  public BarrierIncompleteSize(@Const @ByRef Scope scope,
                        @ByVal Input handle) { super((Pointer)null); allocate(scope, handle); }
  private native void allocate(@Const @ByRef Scope scope,
                        @ByVal Input handle);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output size(); public native BarrierIncompleteSize size(Output size);
}

// For each key, assigns the respective value to the specified component.
//
// If a key is not found in the barrier, this operation will create a new
// incomplete element. If a key is found in the barrier, and the element
// already has a value at component_index, this operation will fail with
// INVALID_ARGUMENT, and leave the barrier in an undefined state.
//
// Arguments:
// * scope: A Scope object
// * handle: The handle to a barrier.
// * keys: A one-dimensional tensor of keys, with length n.
// * values: An any-dimensional tensor of values, which are associated with the
// respective keys. The 0th dimension must have length n.
// * component_index:
//     The component of the barrier elements that is being assigned.
@Namespace("tensorflow::ops") @NoOffset public static class BarrierInsertMany extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public BarrierInsertMany(Pointer p) { super(p); }

  public BarrierInsertMany(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input keys,
                    @ByVal Input values, @Cast("tensorflow::int64") long component_index) { super((Pointer)null); allocate(scope, handle, keys, values, component_index); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input keys,
                    @ByVal Input values, @Cast("tensorflow::int64") long component_index);
  public native @ByVal @Name("operator tensorflow::ops::Operation") Operation asOperation();

  public native @ByRef Operation operation(); public native BarrierInsertMany operation(Operation operation);
}

// Computes the number of complete elements in the given barrier.
//
// Arguments:
// * scope: A Scope object
// * handle: The handle to a barrier.
@Namespace("tensorflow::ops") @NoOffset public static class BarrierReadySize extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public BarrierReadySize(Pointer p) { super(p); }

  public BarrierReadySize(@Const @ByRef Scope scope, @ByVal Input handle) { super((Pointer)null); allocate(scope, handle); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output size(); public native BarrierReadySize size(Output size);
}

// Takes the given number of completed elements from a barrier.
//
// This operation concatenates completed-element component tensors along
// the 0th dimension to make a single component tensor.
//
// Elements come out of the barrier when they are complete, and in the order
// in which they were placed into the barrier.  The indices output provides
// information about the batch in which each element was originally inserted
// into the barrier.
//
// Arguments:
// * scope: A Scope object
// * handle: The handle to a barrier.
// * num_elements: A single-element tensor containing the number of elements to
// take.
// * component_types:
//     The type of each component in a value.
@Namespace("tensorflow::ops") @NoOffset public static class BarrierTakeMany extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public BarrierTakeMany(Pointer p) { super(p); }

  // Optional attribute setters for BarrierTakeMany :
  //
  // AllowSmallBatch(bool): Defaults to false
  //     Allow to return less than num_elements items if barrier is
  // already closed.
  // WaitForIncomplete(bool): Defaults to false
  // TimeoutMs(int64): Defaults to -1
  //     If the queue is empty, this operation will block for up to
  // timeout_ms milliseconds.
  // Note: This option is not supported yet.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs AllowSmallBatch(@Cast("bool") boolean x);

    public native @ByVal Attrs WaitForIncomplete(@Cast("bool") boolean x);

    public native @ByVal Attrs TimeoutMs(@Cast("tensorflow::int64") long x);

    public native @Cast("bool") boolean allow_small_batch_(); public native Attrs allow_small_batch_(boolean allow_small_batch_);
    public native @Cast("bool") boolean wait_for_incomplete_(); public native Attrs wait_for_incomplete_(boolean wait_for_incomplete_);
    public native @Cast("tensorflow::int64") long timeout_ms_(); public native Attrs timeout_ms_(long timeout_ms_);
  }
  public BarrierTakeMany(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input num_elements, @Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector component_types) { super((Pointer)null); allocate(scope, handle, num_elements, component_types); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input num_elements, @Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector component_types);
  public BarrierTakeMany(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input num_elements, @Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector component_types, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, handle, num_elements, component_types, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input num_elements, @Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector component_types, @Const @ByRef Attrs attrs);

  public static native @ByVal Attrs AllowSmallBatch(@Cast("bool") boolean x);
  public static native @ByVal Attrs WaitForIncomplete(@Cast("bool") boolean x);
  public static native @ByVal Attrs TimeoutMs(@Cast("tensorflow::int64") long x);

  public native @ByRef Output indices(); public native BarrierTakeMany indices(Output indices);
  public native @ByRef Output keys(); public native BarrierTakeMany keys(Output keys);
  public native @ByRef @Cast("tensorflow::ops::OutputList*") StringVector values(); public native BarrierTakeMany values(StringVector values);
}

// Delete the tensor specified by its handle in the session.
//
// Arguments:
// * scope: A Scope object
// * handle: The handle for a tensor stored in the session state.
@Namespace("tensorflow::ops") @NoOffset public static class DeleteSessionTensor extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public DeleteSessionTensor(Pointer p) { super(p); }

  public DeleteSessionTensor(@Const @ByRef Scope scope, @ByVal Input handle) { super((Pointer)null); allocate(scope, handle); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle);
  public native @ByVal @Name("operator tensorflow::ops::Operation") Operation asOperation();

  public native @ByRef Operation operation(); public native DeleteSessionTensor operation(Operation operation);
}

// Partitions `data` into `num_partitions` tensors using indices from `partitions`.
//
// For each index tuple `js` of size `partitions.ndim`, the slice `data[js, ...]`
// becomes part of `outputs[partitions[js]]`.  The slices with `partitions[js] = i`
// are placed in `outputs[i]` in lexicographic order of `js`, and the first
// dimension of `outputs[i]` is the number of entries in `partitions` equal to `i`.
// In detail,
//
//     outputs[i].shape = [sum(partitions == i)] + data.shape[partitions.ndim:]
//
//     outputs[i] = pack([data[js, ...] for js if partitions[js] == i])
//
// `data.shape` must start with `partitions.shape`.
//
// For example:
//
//     # Scalar partitions
//     partitions = 1
//     num_partitions = 2
//     data = [10, 20]
//     outputs[0] = []  # Empty with shape [0, 2]
//     outputs[1] = [[10, 20]]
//
//     # Vector partitions
//     partitions = [0, 0, 1, 1, 0]
//     num_partitions = 2
//     data = [10, 20, 30, 40, 50]
//     outputs[0] = [10, 20, 50]
//     outputs[1] = [30, 40]
//
// <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
// <img style="width:100%" src="../../images/DynamicPartition.png" alt>
// </div>
//
// Arguments:
// * scope: A Scope object
// * partitions: Any shape.  Indices in the range `[0, num_partitions)`.
// * num_partitions:
//     The number of partitions to output.
@Namespace("tensorflow::ops") @NoOffset public static class DynamicPartition extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public DynamicPartition(Pointer p) { super(p); }

  public DynamicPartition(@Const @ByRef Scope scope, @ByVal Input data, @ByVal Input partitions, @Cast("tensorflow::int64") long num_partitions) { super((Pointer)null); allocate(scope, data, partitions, num_partitions); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input data, @ByVal Input partitions, @Cast("tensorflow::int64") long num_partitions);
  public native @ByVal @Name("operator []") Output get(@Cast("size_t") long index);


  public native @ByRef @Cast("tensorflow::ops::OutputList*") StringVector outputs(); public native DynamicPartition outputs(StringVector outputs);
}

// Interleave the values from the `data` tensors into a single tensor.
//
// Builds a merged tensor such that
//
//     merged[indices[m][i, ..., j], ...] = data[m][i, ..., j, ...]
//
// For example, if each `indices[m]` is scalar or vector, we have
//
//     # Scalar indices
//     merged[indices[m], ...] = data[m][...]
//
//     # Vector indices
//     merged[indices[m][i], ...] = data[m][i, ...]
//
// Each `data[i].shape` must start with the corresponding `indices[i].shape`,
// and the rest of `data[i].shape` must be constant w.r.t. `i`.  That is, we
// must have `data[i].shape = indices[i].shape + constant`.  In terms of this
// `constant`, the output shape is
//
//     merged.shape = [max(indices)] + constant
//
// Values are merged in order, so if an index appears in both `indices[m][i]` and
// `indices[n][j]` for `(m,i) < (n,j)` the slice `data[n][j]` will appear in the
// merged result.
//
// For example:
//
//     indices[0] = 6
//     indices[1] = [4, 1]
//     indices[2] = [[5, 2], [0, 3]]
//     data[0] = [61, 62]
//     data[1] = [[41, 42], [11, 12]]
//     data[2] = [[[51, 52], [21, 22]], [[1, 2], [31, 32]]]
//     merged = [[1, 2], [11, 12], [21, 22], [31, 32], [41, 42],
//               [51, 52], [61, 62]]
//
// <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
// <img style="width:100%" src="../../images/DynamicStitch.png" alt>
// </div>
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class DynamicStitch extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public DynamicStitch(Pointer p) { super(p); }

  public DynamicStitch(@Const @ByRef Scope scope, @ByVal InputList indices, @ByVal InputList data) { super((Pointer)null); allocate(scope, indices, data); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal InputList indices, @ByVal InputList data);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output merged(); public native DynamicStitch merged(Output merged);
}

// A queue that produces elements in first-in first-out order.
//
// Arguments:
// * scope: A Scope object
// * component_types:
//     The type of each component in a value.
@Namespace("tensorflow::ops") @NoOffset public static class FIFOQueue extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public FIFOQueue(Pointer p) { super(p); }

  // Optional attribute setters for FIFOQueue :
  //
  // Shapes(const gtl::ArraySlice<TensorShape>&): Defaults to []
  //     The shape of each component in a value. The length of this attr must
  // be either 0 or the same as the length of component_types. If the length of
  // this attr is 0, the shapes of queue elements are not constrained, and
  // only one element may be dequeued at a time.
  // Capacity(int64): Defaults to -1
  //     The upper bound on the number of elements in this queue.
  // Negative numbers mean no limit.
  // Container(StringPiece): Defaults to ""
  //     If non-empty, this queue is placed in the given container.
  // Otherwise, a default container is used.
  // SharedName(StringPiece): Defaults to ""
  //     If non-empty, this queue will be shared under the given name
  // across multiple sessions.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Shapes(@Cast("const tensorflow::gtl::ArraySlice<tensorflow::TensorShape>*") @ByRef TensorShapeVector x);

    public native @ByVal Attrs Capacity(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs Container(@StringPiece BytePointer x);
    public native @ByVal Attrs Container(@StringPiece String x);

    public native @ByVal Attrs SharedName(@StringPiece BytePointer x);
    public native @ByVal Attrs SharedName(@StringPiece String x);

    public native @ByRef @Cast("tensorflow::gtl::ArraySlice<tensorflow::TensorShape>*") TensorShapeVector shapes_(); public native Attrs shapes_(TensorShapeVector shapes_);
    public native @Cast("tensorflow::int64") long capacity_(); public native Attrs capacity_(long capacity_);
    public native @StringPiece BytePointer container_(); public native Attrs container_(BytePointer container_);
    public native @StringPiece BytePointer shared_name_(); public native Attrs shared_name_(BytePointer shared_name_);
  }
  public FIFOQueue(@Const @ByRef Scope scope, @Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector component_types) { super((Pointer)null); allocate(scope, component_types); }
  private native void allocate(@Const @ByRef Scope scope, @Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector component_types);
  public FIFOQueue(@Const @ByRef Scope scope, @Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector component_types, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, component_types, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector component_types, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Shapes(@Cast("const tensorflow::gtl::ArraySlice<tensorflow::TensorShape>*") @ByRef TensorShapeVector x);
  public static native @ByVal Attrs Capacity(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs Container(@StringPiece BytePointer x);
  public static native @ByVal Attrs Container(@StringPiece String x);
  public static native @ByVal Attrs SharedName(@StringPiece BytePointer x);
  public static native @ByVal Attrs SharedName(@StringPiece String x);

  public native @ByRef Output handle(); public native FIFOQueue handle(Output handle);
}

// Store the input tensor in the state of the current session.
//
// Arguments:
// * scope: A Scope object
// * value: The tensor to be stored.
@Namespace("tensorflow::ops") @NoOffset public static class GetSessionHandle extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public GetSessionHandle(Pointer p) { super(p); }

  public GetSessionHandle(@Const @ByRef Scope scope, @ByVal Input value) { super((Pointer)null); allocate(scope, value); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input value);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output handle(); public native GetSessionHandle handle(Output handle);
}

// Get the value of the tensor specified by its handle.
//
// Arguments:
// * scope: A Scope object
// * handle: The handle for a tensor stored in the session state.
// * dtype:
//     The type of the output value.
@Namespace("tensorflow::ops") @NoOffset public static class GetSessionTensor extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public GetSessionTensor(Pointer p) { super(p); }

  public GetSessionTensor(@Const @ByRef Scope scope, @ByVal Input handle, @Cast("tensorflow::DataType") int dtype) { super((Pointer)null); allocate(scope, handle, dtype); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle, @Cast("tensorflow::DataType") int dtype);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output value(); public native GetSessionTensor value(Output value);
}

// Creates a non-initialized hash table.
//
// This op creates a hash table, specifying the type of its keys and values.
// Before using the table you will have to initialize it.  After initialization the
// table will be immutable.
//
// Arguments:
// * scope: A Scope object
// * key_dtype:
//     Type of the table keys.
// * value_dtype:
//     Type of the table values.
@Namespace("tensorflow::ops") @NoOffset public static class HashTable extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public HashTable(Pointer p) { super(p); }

  // Optional attribute setters for HashTable :
  //
  // Container(StringPiece): Defaults to ""
  //     If non-empty, this table is placed in the given container.
  // Otherwise, a default container is used.
  // SharedName(StringPiece): Defaults to ""
  //     If non-empty, this table is shared under the given name across
  // multiple sessions.
  // UseNodeNameSharing(bool): Defaults to false
  //     If true and shared_name is empty, the table is shared
  // using the node name.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Container(@StringPiece BytePointer x);
    public native @ByVal Attrs Container(@StringPiece String x);

    public native @ByVal Attrs SharedName(@StringPiece BytePointer x);
    public native @ByVal Attrs SharedName(@StringPiece String x);

    public native @ByVal Attrs UseNodeNameSharing(@Cast("bool") boolean x);

    public native @StringPiece BytePointer container_(); public native Attrs container_(BytePointer container_);
    public native @StringPiece BytePointer shared_name_(); public native Attrs shared_name_(BytePointer shared_name_);
    public native @Cast("bool") boolean use_node_name_sharing_(); public native Attrs use_node_name_sharing_(boolean use_node_name_sharing_);
  }
  public HashTable(@Const @ByRef Scope scope, @Cast("tensorflow::DataType") int key_dtype, @Cast("tensorflow::DataType") int value_dtype) { super((Pointer)null); allocate(scope, key_dtype, value_dtype); }
  private native void allocate(@Const @ByRef Scope scope, @Cast("tensorflow::DataType") int key_dtype, @Cast("tensorflow::DataType") int value_dtype);
  public HashTable(@Const @ByRef Scope scope, @Cast("tensorflow::DataType") int key_dtype, @Cast("tensorflow::DataType") int value_dtype, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, key_dtype, value_dtype, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @Cast("tensorflow::DataType") int key_dtype, @Cast("tensorflow::DataType") int value_dtype, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Container(@StringPiece BytePointer x);
  public static native @ByVal Attrs Container(@StringPiece String x);
  public static native @ByVal Attrs SharedName(@StringPiece BytePointer x);
  public static native @ByVal Attrs SharedName(@StringPiece String x);
  public static native @ByVal Attrs UseNodeNameSharing(@Cast("bool") boolean x);

  public native @ByRef Output table_handle(); public native HashTable table_handle(Output table_handle);
}

// Table initializer that takes two tensors for keys and values respectively.
//
// Arguments:
// * scope: A Scope object
// * table_handle: Handle to a table which will be initialized.
// * keys: Keys of type Tkey.
// * values: Values of type Tval.
@Namespace("tensorflow::ops") @NoOffset public static class InitializeTable extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public InitializeTable(Pointer p) { super(p); }

  public InitializeTable(@Const @ByRef Scope scope, @ByVal Input table_handle, @ByVal Input keys,
                  @ByVal Input values) { super((Pointer)null); allocate(scope, table_handle, keys, values); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input table_handle, @ByVal Input keys,
                  @ByVal Input values);
  public native @ByVal @Name("operator tensorflow::ops::Operation") Operation asOperation();

  public native @ByRef Operation operation(); public native InitializeTable operation(Operation operation);
}

// Initializes a table from a text file.
//
// It inserts one key-value pair into the table for each line of the file.
// The key and value is extracted from the whole line content, elements from the
// split line based on `delimiter` or the line number (starting from zero).
// Where to extract the key and value from a line is specified by `key_index` and
// `value_index`.
//
// - A value of -1 means use the line number(starting from zero), expects `int64`.
// - A value of -2 means use the whole line content, expects `string`.
// - A value >= 0 means use the index (starting at zero) of the split line based
//   on `delimiter`.
//
// Arguments:
// * scope: A Scope object
// * table_handle: Handle to a table which will be initialized.
// * filename: Filename of a vocabulary text file.
// * key_index:
//     Column index in a line to get the table `key` values from.
// * value_index:
//     Column index that represents information of a line to get the table
// `value` values from.
@Namespace("tensorflow::ops") @NoOffset public static class InitializeTableFromTextFile extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public InitializeTableFromTextFile(Pointer p) { super(p); }

  // Optional attribute setters for InitializeTableFromTextFile :
  //
  // VocabSize(int64): Defaults to -1
  //     Number of elements of the file, use -1 if unknown.
  // Delimiter(StringPiece): Defaults to "\t"
  //     Delimiter to separate fields in a line.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs VocabSize(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs Delimiter(@StringPiece BytePointer x);
    public native @ByVal Attrs Delimiter(@StringPiece String x);

    public native @Cast("tensorflow::int64") long vocab_size_(); public native Attrs vocab_size_(long vocab_size_);
    public native @StringPiece BytePointer delimiter_(); public native Attrs delimiter_(BytePointer delimiter_);
  }
  public InitializeTableFromTextFile(@Const @ByRef Scope scope,
                              @ByVal Input table_handle,
                              @ByVal Input filename, @Cast("tensorflow::int64") long key_index,
                              @Cast("tensorflow::int64") long value_index) { super((Pointer)null); allocate(scope, table_handle, filename, key_index, value_index); }
  private native void allocate(@Const @ByRef Scope scope,
                              @ByVal Input table_handle,
                              @ByVal Input filename, @Cast("tensorflow::int64") long key_index,
                              @Cast("tensorflow::int64") long value_index);
  public InitializeTableFromTextFile(@Const @ByRef Scope scope,
                              @ByVal Input table_handle,
                              @ByVal Input filename, @Cast("tensorflow::int64") long key_index,
                              @Cast("tensorflow::int64") long value_index, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, table_handle, filename, key_index, value_index, attrs); }
  private native void allocate(@Const @ByRef Scope scope,
                              @ByVal Input table_handle,
                              @ByVal Input filename, @Cast("tensorflow::int64") long key_index,
                              @Cast("tensorflow::int64") long value_index, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Operation") Operation asOperation();

  public static native @ByVal Attrs VocabSize(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs Delimiter(@StringPiece BytePointer x);
  public static native @ByVal Attrs Delimiter(@StringPiece String x);

  public native @ByRef Operation operation(); public native InitializeTableFromTextFile operation(Operation operation);
}

// Outputs all keys and values in the table.
//
// Arguments:
// * scope: A Scope object
// * table_handle: Handle to the table.
@Namespace("tensorflow::ops") @NoOffset public static class LookupTableExport extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public LookupTableExport(Pointer p) { super(p); }

  public LookupTableExport(@Const @ByRef Scope scope, @ByVal Input table_handle, @Cast("tensorflow::DataType") int Tkeys, @Cast("tensorflow::DataType") int Tvalues) { super((Pointer)null); allocate(scope, table_handle, Tkeys, Tvalues); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input table_handle, @Cast("tensorflow::DataType") int Tkeys, @Cast("tensorflow::DataType") int Tvalues);

  public native @ByRef Output keys(); public native LookupTableExport keys(Output keys);
  public native @ByRef Output values(); public native LookupTableExport values(Output values);
}

// Looks up keys in a table, outputs the corresponding values.
//
// The tensor `keys` must of the same type as the keys of the table.
// The output `values` is of the type of the table values.
//
// The scalar `default_value` is the value output for keys not present in the
// table. It must also be of the same type as the table values.
//
// Arguments:
// * scope: A Scope object
// * table_handle: Handle to the table.
// * keys: Any shape.  Keys to look up.
@Namespace("tensorflow::ops") @NoOffset public static class LookupTableFind extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public LookupTableFind(Pointer p) { super(p); }

  public LookupTableFind(@Const @ByRef Scope scope, @ByVal Input table_handle, @ByVal Input keys,
                  @ByVal Input default_value) { super((Pointer)null); allocate(scope, table_handle, keys, default_value); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input table_handle, @ByVal Input keys,
                  @ByVal Input default_value);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output values(); public native LookupTableFind values(Output values);
}

// Replaces the contents of the table with the specified keys and values.
//
// The tensor `keys` must be of the same type as the keys of the table.
// The tensor `values` must be of the type of the table values.
//
// Arguments:
// * scope: A Scope object
// * table_handle: Handle to the table.
// * keys: Any shape.  Keys to look up.
// * values: Values to associate with keys.
@Namespace("tensorflow::ops") @NoOffset public static class LookupTableImport extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public LookupTableImport(Pointer p) { super(p); }

  public LookupTableImport(@Const @ByRef Scope scope, @ByVal Input table_handle, @ByVal Input keys,
                    @ByVal Input values) { super((Pointer)null); allocate(scope, table_handle, keys, values); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input table_handle, @ByVal Input keys,
                    @ByVal Input values);
  public native @ByVal @Name("operator tensorflow::ops::Operation") Operation asOperation();

  public native @ByRef Operation operation(); public native LookupTableImport operation(Operation operation);
}

// Updates the table to associates keys with values.
//
// The tensor `keys` must be of the same type as the keys of the table.
// The tensor `values` must be of the type of the table values.
//
// Arguments:
// * scope: A Scope object
// * table_handle: Handle to the table.
// * keys: Any shape.  Keys to look up.
// * values: Values to associate with keys.
@Namespace("tensorflow::ops") @NoOffset public static class LookupTableInsert extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public LookupTableInsert(Pointer p) { super(p); }

  public LookupTableInsert(@Const @ByRef Scope scope, @ByVal Input table_handle, @ByVal Input keys,
                    @ByVal Input values) { super((Pointer)null); allocate(scope, table_handle, keys, values); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input table_handle, @ByVal Input keys,
                    @ByVal Input values);
  public native @ByVal @Name("operator tensorflow::ops::Operation") Operation asOperation();

  public native @ByRef Operation operation(); public native LookupTableInsert operation(Operation operation);
}

// Computes the number of elements in the given table.
//
// Arguments:
// * scope: A Scope object
// * table_handle: Handle to the table.
@Namespace("tensorflow::ops") @NoOffset public static class LookupTableSize extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public LookupTableSize(Pointer p) { super(p); }

  public LookupTableSize(@Const @ByRef Scope scope, @ByVal Input table_handle) { super((Pointer)null); allocate(scope, table_handle); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input table_handle);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output size(); public native LookupTableSize size(Output size);
}

// Creates an empty hash table.
//
// This op creates a mutable hash table, specifying the type of its keys and
// values. Each value must be a scalar. Data can be inserted into the table using
// the insert operations. It does not support the initialization operation.
//
// Arguments:
// * scope: A Scope object
// * key_dtype:
//     Type of the table keys.
// * value_dtype:
//     Type of the table values.
@Namespace("tensorflow::ops") @NoOffset public static class MutableHashTable extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public MutableHashTable(Pointer p) { super(p); }

  // Optional attribute setters for MutableHashTable :
  //
  // Container(StringPiece): Defaults to ""
  //     If non-empty, this table is placed in the given container.
  // Otherwise, a default container is used.
  // SharedName(StringPiece): Defaults to ""
  //     If non-empty, this table is shared under the given name across
  // multiple sessions.
  // UseNodeNameSharing(bool): Defaults to false
  //     If true and shared_name is empty, the table is shared
  // using the node name.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Container(@StringPiece BytePointer x);
    public native @ByVal Attrs Container(@StringPiece String x);

    public native @ByVal Attrs SharedName(@StringPiece BytePointer x);
    public native @ByVal Attrs SharedName(@StringPiece String x);

    public native @ByVal Attrs UseNodeNameSharing(@Cast("bool") boolean x);

    public native @StringPiece BytePointer container_(); public native Attrs container_(BytePointer container_);
    public native @StringPiece BytePointer shared_name_(); public native Attrs shared_name_(BytePointer shared_name_);
    public native @Cast("bool") boolean use_node_name_sharing_(); public native Attrs use_node_name_sharing_(boolean use_node_name_sharing_);
  }
  public MutableHashTable(@Const @ByRef Scope scope, @Cast("tensorflow::DataType") int key_dtype, @Cast("tensorflow::DataType") int value_dtype) { super((Pointer)null); allocate(scope, key_dtype, value_dtype); }
  private native void allocate(@Const @ByRef Scope scope, @Cast("tensorflow::DataType") int key_dtype, @Cast("tensorflow::DataType") int value_dtype);
  public MutableHashTable(@Const @ByRef Scope scope, @Cast("tensorflow::DataType") int key_dtype, @Cast("tensorflow::DataType") int value_dtype, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, key_dtype, value_dtype, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @Cast("tensorflow::DataType") int key_dtype, @Cast("tensorflow::DataType") int value_dtype, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Container(@StringPiece BytePointer x);
  public static native @ByVal Attrs Container(@StringPiece String x);
  public static native @ByVal Attrs SharedName(@StringPiece BytePointer x);
  public static native @ByVal Attrs SharedName(@StringPiece String x);
  public static native @ByVal Attrs UseNodeNameSharing(@Cast("bool") boolean x);

  public native @ByRef Output table_handle(); public native MutableHashTable table_handle(Output table_handle);
}

// Creates an empty hash table.
//
// This op creates a mutable hash table, specifying the type of its keys and
// values. Each value must be a vector. Data can be inserted into the table using
// the insert operations. It does not support the initialization operation.
//
// Arguments:
// * scope: A Scope object
// * key_dtype:
//     Type of the table keys.
// * value_dtype:
//     Type of the table values.
@Namespace("tensorflow::ops") @NoOffset public static class MutableHashTableOfTensors extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public MutableHashTableOfTensors(Pointer p) { super(p); }

  // Optional attribute setters for MutableHashTableOfTensors :
  //
  // Container(StringPiece): Defaults to ""
  //     If non-empty, this table is placed in the given container.
  // Otherwise, a default container is used.
  // SharedName(StringPiece): Defaults to ""
  //     If non-empty, this table is shared under the given name across
  // multiple sessions.
  // UseNodeNameSharing(bool): Defaults to false
  // ValueShape(TensorShape): Defaults to []
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Container(@StringPiece BytePointer x);
    public native @ByVal Attrs Container(@StringPiece String x);

    public native @ByVal Attrs SharedName(@StringPiece BytePointer x);
    public native @ByVal Attrs SharedName(@StringPiece String x);

    public native @ByVal Attrs UseNodeNameSharing(@Cast("bool") boolean x);

    public native @ByVal Attrs ValueShape(@ByVal TensorShape x);

    public native @StringPiece BytePointer container_(); public native Attrs container_(BytePointer container_);
    public native @StringPiece BytePointer shared_name_(); public native Attrs shared_name_(BytePointer shared_name_);
    public native @Cast("bool") boolean use_node_name_sharing_(); public native Attrs use_node_name_sharing_(boolean use_node_name_sharing_);
    public native @ByRef TensorShape value_shape_(); public native Attrs value_shape_(TensorShape value_shape_);
  }
  public MutableHashTableOfTensors(@Const @ByRef Scope scope, @Cast("tensorflow::DataType") int key_dtype,
                            @Cast("tensorflow::DataType") int value_dtype) { super((Pointer)null); allocate(scope, key_dtype, value_dtype); }
  private native void allocate(@Const @ByRef Scope scope, @Cast("tensorflow::DataType") int key_dtype,
                            @Cast("tensorflow::DataType") int value_dtype);
  public MutableHashTableOfTensors(@Const @ByRef Scope scope, @Cast("tensorflow::DataType") int key_dtype,
                            @Cast("tensorflow::DataType") int value_dtype, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, key_dtype, value_dtype, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @Cast("tensorflow::DataType") int key_dtype,
                            @Cast("tensorflow::DataType") int value_dtype, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Container(@StringPiece BytePointer x);
  public static native @ByVal Attrs Container(@StringPiece String x);
  public static native @ByVal Attrs SharedName(@StringPiece BytePointer x);
  public static native @ByVal Attrs SharedName(@StringPiece String x);
  public static native @ByVal Attrs UseNodeNameSharing(@Cast("bool") boolean x);
  public static native @ByVal Attrs ValueShape(@ByVal TensorShape x);

  public native @ByRef Output table_handle(); public native MutableHashTableOfTensors table_handle(Output table_handle);
}

// A queue that produces elements in first-in first-out order.
//
// Variable-size shapes are allowed by setting the corresponding shape dimensions
// to 0 in the shape attr.  In this case DequeueMany will pad up to the maximum
// size of any given element in the minibatch.  See below for details.
//
// Arguments:
// * scope: A Scope object
// * component_types:
//     The type of each component in a value.
@Namespace("tensorflow::ops") @NoOffset public static class PaddingFIFOQueue extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public PaddingFIFOQueue(Pointer p) { super(p); }

  // Optional attribute setters for PaddingFIFOQueue :
  //
  // Shapes(const gtl::ArraySlice<TensorShape>&): Defaults to []
  //     The shape of each component in a value. The length of this attr must
  // be either 0 or the same as the length of component_types.
  // Shapes of fixed rank but variable size are allowed by setting
  // any shape dimension to -1.  In this case, the inputs' shape may vary along
  // the given dimension, and DequeueMany will pad the given dimension with
  // zeros up to the maximum shape of all elements in the given batch.
  // If the length of this attr is 0, different queue elements may have
  // different ranks and shapes, but only one element may be dequeued at a time.
  // Capacity(int64): Defaults to -1
  //     The upper bound on the number of elements in this queue.
  // Negative numbers mean no limit.
  // Container(StringPiece): Defaults to ""
  //     If non-empty, this queue is placed in the given container.
  // Otherwise, a default container is used.
  // SharedName(StringPiece): Defaults to ""
  //     If non-empty, this queue will be shared under the given name
  // across multiple sessions.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Shapes(@Cast("const tensorflow::gtl::ArraySlice<tensorflow::TensorShape>*") @ByRef TensorShapeVector x);

    public native @ByVal Attrs Capacity(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs Container(@StringPiece BytePointer x);
    public native @ByVal Attrs Container(@StringPiece String x);

    public native @ByVal Attrs SharedName(@StringPiece BytePointer x);
    public native @ByVal Attrs SharedName(@StringPiece String x);

    public native @ByRef @Cast("tensorflow::gtl::ArraySlice<tensorflow::TensorShape>*") TensorShapeVector shapes_(); public native Attrs shapes_(TensorShapeVector shapes_);
    public native @Cast("tensorflow::int64") long capacity_(); public native Attrs capacity_(long capacity_);
    public native @StringPiece BytePointer container_(); public native Attrs container_(BytePointer container_);
    public native @StringPiece BytePointer shared_name_(); public native Attrs shared_name_(BytePointer shared_name_);
  }
  public PaddingFIFOQueue(@Const @ByRef Scope scope, @Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector component_types) { super((Pointer)null); allocate(scope, component_types); }
  private native void allocate(@Const @ByRef Scope scope, @Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector component_types);
  public PaddingFIFOQueue(@Const @ByRef Scope scope, @Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector component_types, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, component_types, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector component_types, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Shapes(@Cast("const tensorflow::gtl::ArraySlice<tensorflow::TensorShape>*") @ByRef TensorShapeVector x);
  public static native @ByVal Attrs Capacity(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs Container(@StringPiece BytePointer x);
  public static native @ByVal Attrs Container(@StringPiece String x);
  public static native @ByVal Attrs SharedName(@StringPiece BytePointer x);
  public static native @ByVal Attrs SharedName(@StringPiece String x);

  public native @ByRef Output handle(); public native PaddingFIFOQueue handle(Output handle);
}

// A queue that produces elements sorted by the first component value.
//
// Note that the PriorityQueue requires the first component of any element
// to be a scalar int64, in addition to the other elements declared by
// component_types.  Therefore calls to Enqueue and EnqueueMany (resp. Dequeue
// and DequeueMany) on a PriorityQueue will all require (resp. output) one extra
// entry in their input (resp. output) lists.
//
// Arguments:
// * scope: A Scope object
// * shapes:
//     The shape of each component in a value. The length of this attr must
// be either 0 or the same as the length of component_types. If the length of
// this attr is 0, the shapes of queue elements are not constrained, and
// only one element may be dequeued at a time.
@Namespace("tensorflow::ops") @NoOffset public static class PriorityQueue extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public PriorityQueue(Pointer p) { super(p); }

  // Optional attribute setters for PriorityQueue :
  //
  // ComponentTypes(const DataTypeSlice&): Defaults to []
  //     The type of each component in a value.
  // Capacity(int64): Defaults to -1
  //     The upper bound on the number of elements in this queue.
  // Negative numbers mean no limit.
  // Container(StringPiece): Defaults to ""
  //     If non-empty, this queue is placed in the given container.
  // Otherwise, a default container is used.
  // SharedName(StringPiece): Defaults to ""
  //     If non-empty, this queue will be shared under the given name
  // across multiple sessions.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs ComponentTypes(@Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector x);

    public native @ByVal Attrs Capacity(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs Container(@StringPiece BytePointer x);
    public native @ByVal Attrs Container(@StringPiece String x);

    public native @ByVal Attrs SharedName(@StringPiece BytePointer x);
    public native @ByVal Attrs SharedName(@StringPiece String x);

    public native @ByRef @Cast("tensorflow::DataTypeSlice*") DataTypeVector component_types_(); public native Attrs component_types_(DataTypeVector component_types_);
    public native @Cast("tensorflow::int64") long capacity_(); public native Attrs capacity_(long capacity_);
    public native @StringPiece BytePointer container_(); public native Attrs container_(BytePointer container_);
    public native @StringPiece BytePointer shared_name_(); public native Attrs shared_name_(BytePointer shared_name_);
  }
  public PriorityQueue(@Const @ByRef Scope scope, @Cast("const tensorflow::gtl::ArraySlice<tensorflow::TensorShape>*") @ByRef TensorShapeVector shapes) { super((Pointer)null); allocate(scope, shapes); }
  private native void allocate(@Const @ByRef Scope scope, @Cast("const tensorflow::gtl::ArraySlice<tensorflow::TensorShape>*") @ByRef TensorShapeVector shapes);
  public PriorityQueue(@Const @ByRef Scope scope, @Cast("const tensorflow::gtl::ArraySlice<tensorflow::TensorShape>*") @ByRef TensorShapeVector shapes, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, shapes, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @Cast("const tensorflow::gtl::ArraySlice<tensorflow::TensorShape>*") @ByRef TensorShapeVector shapes, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs ComponentTypes(@Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector x);
  public static native @ByVal Attrs Capacity(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs Container(@StringPiece BytePointer x);
  public static native @ByVal Attrs Container(@StringPiece String x);
  public static native @ByVal Attrs SharedName(@StringPiece BytePointer x);
  public static native @ByVal Attrs SharedName(@StringPiece String x);

  public native @ByRef Output handle(); public native PriorityQueue handle(Output handle);
}

// Closes the given queue.
//
// This operation signals that no more elements will be enqueued in the
// given queue. Subsequent Enqueue(Many) operations will fail.
// Subsequent Dequeue(Many) operations will continue to succeed if
// sufficient elements remain in the queue. Subsequent Dequeue(Many)
// operations that would block will fail immediately.
//
// Arguments:
// * scope: A Scope object
// * handle: The handle to a queue.
@Namespace("tensorflow::ops") @NoOffset public static class QueueClose extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public QueueClose(Pointer p) { super(p); }

  // Optional attribute setters for QueueClose :
  //
  // CancelPendingEnqueues(bool): Defaults to false
  //     If true, all pending enqueue requests that are
  // blocked on the given queue will be cancelled.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs CancelPendingEnqueues(@Cast("bool") boolean x);

    public native @Cast("bool") boolean cancel_pending_enqueues_(); public native Attrs cancel_pending_enqueues_(boolean cancel_pending_enqueues_);
  }
  public QueueClose(@Const @ByRef Scope scope, @ByVal Input handle) { super((Pointer)null); allocate(scope, handle); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle);
  public QueueClose(@Const @ByRef Scope scope, @ByVal Input handle,
             @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, handle, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle,
             @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Operation") Operation asOperation();

  public static native @ByVal Attrs CancelPendingEnqueues(@Cast("bool") boolean x);

  public native @ByRef Operation operation(); public native QueueClose operation(Operation operation);
}

// Dequeues a tuple of one or more tensors from the given queue.
//
// This operation has k outputs, where k is the number of components
// in the tuples stored in the given queue, and output i is the ith
// component of the dequeued tuple.
//
// N.B. If the queue is empty, this operation will block until an element
// has been dequeued (or 'timeout_ms' elapses, if specified).
//
// Arguments:
// * scope: A Scope object
// * handle: The handle to a queue.
// * component_types:
//     The type of each component in a tuple.
@Namespace("tensorflow::ops") @NoOffset public static class QueueDequeue extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public QueueDequeue(Pointer p) { super(p); }

  // Optional attribute setters for QueueDequeue :
  //
  // TimeoutMs(int64): Defaults to -1
  //     If the queue is empty, this operation will block for up to
  // timeout_ms milliseconds.
  // Note: This option is not supported yet.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs TimeoutMs(@Cast("tensorflow::int64") long x);

    public native @Cast("tensorflow::int64") long timeout_ms_(); public native Attrs timeout_ms_(long timeout_ms_);
  }
  public QueueDequeue(@Const @ByRef Scope scope, @ByVal Input handle,
               @Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector component_types) { super((Pointer)null); allocate(scope, handle, component_types); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle,
               @Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector component_types);
  public QueueDequeue(@Const @ByRef Scope scope, @ByVal Input handle,
               @Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector component_types, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, handle, component_types, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle,
               @Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector component_types, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator []") Output get(@Cast("size_t") long index);


  public static native @ByVal Attrs TimeoutMs(@Cast("tensorflow::int64") long x);

  public native @ByRef @Cast("tensorflow::ops::OutputList*") StringVector components(); public native QueueDequeue components(StringVector components);
}

// Dequeues n tuples of one or more tensors from the given queue.
//
// If the queue is closed and there are fewer than n elements, then an
// OutOfRange error is returned.
//
// This operation concatenates queue-element component tensors along the
// 0th dimension to make a single component tensor.  All of the components
// in the dequeued tuple will have size n in the 0th dimension.
//
// This operation has k outputs, where k is the number of components in
// the tuples stored in the given queue, and output i is the ith
// component of the dequeued tuple.
//
// N.B. If the queue is empty, this operation will block until n elements
// have been dequeued (or 'timeout_ms' elapses, if specified).
//
// Arguments:
// * scope: A Scope object
// * handle: The handle to a queue.
// * n: The number of tuples to dequeue.
// * component_types:
//     The type of each component in a tuple.
@Namespace("tensorflow::ops") @NoOffset public static class QueueDequeueMany extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public QueueDequeueMany(Pointer p) { super(p); }

  // Optional attribute setters for QueueDequeueMany :
  //
  // TimeoutMs(int64): Defaults to -1
  //     If the queue has fewer than n elements, this operation
  // will block for up to timeout_ms milliseconds.
  // Note: This option is not supported yet.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs TimeoutMs(@Cast("tensorflow::int64") long x);

    public native @Cast("tensorflow::int64") long timeout_ms_(); public native Attrs timeout_ms_(long timeout_ms_);
  }
  public QueueDequeueMany(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input n, @Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector component_types) { super((Pointer)null); allocate(scope, handle, n, component_types); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input n, @Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector component_types);
  public QueueDequeueMany(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input n, @Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector component_types, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, handle, n, component_types, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input n, @Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector component_types, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator []") Output get(@Cast("size_t") long index);


  public static native @ByVal Attrs TimeoutMs(@Cast("tensorflow::int64") long x);

  public native @ByRef @Cast("tensorflow::ops::OutputList*") StringVector components(); public native QueueDequeueMany components(StringVector components);
}

// Dequeues n tuples of one or more tensors from the given queue.
//
// This operation is not supported by all queues.  If a queue does not support
// DequeueUpTo, then an Unimplemented error is returned.
//
// If the queue is closed and there are more than 0 but less than n elements
// remaining, then instead of returning an OutOfRange error like
// QueueDequeueMany, less than `n` elements are returned immediately.  If the queue
// is closed and there are 0 elements left in the queue, then an OutOfRange
// error is returned just like in QueueDequeueMany.  Otherwise the behavior
// is identical to QueueDequeueMany:
//
// This operation concatenates queue-element component tensors along the
// 0th dimension to make a single component tensor.  All of the components
// in the dequeued tuple will have size n in the 0th dimension.
//
// This operation has k outputs, where k is the number of components in
// the tuples stored in the given queue, and output i is the ith
// component of the dequeued tuple.
//
// Arguments:
// * scope: A Scope object
// * handle: The handle to a queue.
// * n: The number of tuples to dequeue.
// * component_types:
//     The type of each component in a tuple.
@Namespace("tensorflow::ops") @NoOffset public static class QueueDequeueUpTo extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public QueueDequeueUpTo(Pointer p) { super(p); }

  // Optional attribute setters for QueueDequeueUpTo :
  //
  // TimeoutMs(int64): Defaults to -1
  //     If the queue has fewer than n elements, this operation
  // will block for up to timeout_ms milliseconds.
  // Note: This option is not supported yet.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs TimeoutMs(@Cast("tensorflow::int64") long x);

    public native @Cast("tensorflow::int64") long timeout_ms_(); public native Attrs timeout_ms_(long timeout_ms_);
  }
  public QueueDequeueUpTo(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input n, @Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector component_types) { super((Pointer)null); allocate(scope, handle, n, component_types); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input n, @Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector component_types);
  public QueueDequeueUpTo(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input n, @Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector component_types, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, handle, n, component_types, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input n, @Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector component_types, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator []") Output get(@Cast("size_t") long index);


  public static native @ByVal Attrs TimeoutMs(@Cast("tensorflow::int64") long x);

  public native @ByRef @Cast("tensorflow::ops::OutputList*") StringVector components(); public native QueueDequeueUpTo components(StringVector components);
}

// Enqueues a tuple of one or more tensors in the given queue.
//
// The components input has k elements, which correspond to the components of
// tuples stored in the given queue.
//
// N.B. If the queue is full, this operation will block until the given
// element has been enqueued (or 'timeout_ms' elapses, if specified).
//
// Arguments:
// * scope: A Scope object
// * handle: The handle to a queue.
// * components: One or more tensors from which the enqueued tensors should be taken.
@Namespace("tensorflow::ops") @NoOffset public static class QueueEnqueue extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public QueueEnqueue(Pointer p) { super(p); }

  // Optional attribute setters for QueueEnqueue :
  //
  // TimeoutMs(int64): Defaults to -1
  //     If the queue is full, this operation will block for up to
  // timeout_ms milliseconds.
  // Note: This option is not supported yet.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs TimeoutMs(@Cast("tensorflow::int64") long x);

    public native @Cast("tensorflow::int64") long timeout_ms_(); public native Attrs timeout_ms_(long timeout_ms_);
  }
  public QueueEnqueue(@Const @ByRef Scope scope, @ByVal Input handle,
               @ByVal InputList components) { super((Pointer)null); allocate(scope, handle, components); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle,
               @ByVal InputList components);
  public QueueEnqueue(@Const @ByRef Scope scope, @ByVal Input handle,
               @ByVal InputList components, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, handle, components, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle,
               @ByVal InputList components, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Operation") Operation asOperation();

  public static native @ByVal Attrs TimeoutMs(@Cast("tensorflow::int64") long x);

  public native @ByRef Operation operation(); public native QueueEnqueue operation(Operation operation);
}

// Enqueues zero or more tuples of one or more tensors in the given queue.
//
// This operation slices each component tensor along the 0th dimension to
// make multiple queue elements. All of the tuple components must have the
// same size in the 0th dimension.
//
// The components input has k elements, which correspond to the components of
// tuples stored in the given queue.
//
// N.B. If the queue is full, this operation will block until the given
// elements have been enqueued (or 'timeout_ms' elapses, if specified).
//
// Arguments:
// * scope: A Scope object
// * handle: The handle to a queue.
// * components: One or more tensors from which the enqueued tensors should
// be taken.
@Namespace("tensorflow::ops") @NoOffset public static class QueueEnqueueMany extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public QueueEnqueueMany(Pointer p) { super(p); }

  // Optional attribute setters for QueueEnqueueMany :
  //
  // TimeoutMs(int64): Defaults to -1
  //     If the queue is too full, this operation will block for up
  // to timeout_ms milliseconds.
  // Note: This option is not supported yet.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs TimeoutMs(@Cast("tensorflow::int64") long x);

    public native @Cast("tensorflow::int64") long timeout_ms_(); public native Attrs timeout_ms_(long timeout_ms_);
  }
  public QueueEnqueueMany(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal InputList components) { super((Pointer)null); allocate(scope, handle, components); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal InputList components);
  public QueueEnqueueMany(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal InputList components, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, handle, components, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal InputList components, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Operation") Operation asOperation();

  public static native @ByVal Attrs TimeoutMs(@Cast("tensorflow::int64") long x);

  public native @ByRef Operation operation(); public native QueueEnqueueMany operation(Operation operation);
}

// Computes the number of elements in the given queue.
//
// Arguments:
// * scope: A Scope object
// * handle: The handle to a queue.
@Namespace("tensorflow::ops") @NoOffset public static class QueueSize extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public QueueSize(Pointer p) { super(p); }

  public QueueSize(@Const @ByRef Scope scope, @ByVal Input handle) { super((Pointer)null); allocate(scope, handle); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output size(); public native QueueSize size(Output size);
}

// A queue that randomizes the order of elements.
//
// Arguments:
// * scope: A Scope object
// * component_types:
//     The type of each component in a value.
@Namespace("tensorflow::ops") @NoOffset public static class RandomShuffleQueue extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public RandomShuffleQueue(Pointer p) { super(p); }

  // Optional attribute setters for RandomShuffleQueue :
  //
  // Shapes(const gtl::ArraySlice<TensorShape>&): Defaults to []
  //     The shape of each component in a value. The length of this attr must
  // be either 0 or the same as the length of component_types. If the length of
  // this attr is 0, the shapes of queue elements are not constrained, and
  // only one element may be dequeued at a time.
  // Capacity(int64): Defaults to -1
  //     The upper bound on the number of elements in this queue.
  // Negative numbers mean no limit.
  // MinAfterDequeue(int64): Defaults to 0
  //     Dequeue will block unless there would be this
  // many elements after the dequeue or the queue is closed. This
  // ensures a minimum level of mixing of elements.
  // Seed(int64): Defaults to 0
  //     If either seed or seed2 is set to be non-zero, the random number
  // generator is seeded by the given seed.  Otherwise, a random seed is used.
  // Seed2(int64): Defaults to 0
  //     A second seed to avoid seed collision.
  // Container(StringPiece): Defaults to ""
  //     If non-empty, this queue is placed in the given container.
  // Otherwise, a default container is used.
  // SharedName(StringPiece): Defaults to ""
  //     If non-empty, this queue will be shared under the given name
  // across multiple sessions.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Shapes(@Cast("const tensorflow::gtl::ArraySlice<tensorflow::TensorShape>*") @ByRef TensorShapeVector x);

    public native @ByVal Attrs Capacity(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs MinAfterDequeue(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs Container(@StringPiece BytePointer x);
    public native @ByVal Attrs Container(@StringPiece String x);

    public native @ByVal Attrs SharedName(@StringPiece BytePointer x);
    public native @ByVal Attrs SharedName(@StringPiece String x);

    public native @ByRef @Cast("tensorflow::gtl::ArraySlice<tensorflow::TensorShape>*") TensorShapeVector shapes_(); public native Attrs shapes_(TensorShapeVector shapes_);
    public native @Cast("tensorflow::int64") long capacity_(); public native Attrs capacity_(long capacity_);
    public native @Cast("tensorflow::int64") long min_after_dequeue_(); public native Attrs min_after_dequeue_(long min_after_dequeue_);
    public native @Cast("tensorflow::int64") long seed_(); public native Attrs seed_(long seed_);
    public native @Cast("tensorflow::int64") long seed2_(); public native Attrs seed2_(long seed2_);
    public native @StringPiece BytePointer container_(); public native Attrs container_(BytePointer container_);
    public native @StringPiece BytePointer shared_name_(); public native Attrs shared_name_(BytePointer shared_name_);
  }
  public RandomShuffleQueue(@Const @ByRef Scope scope, @Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector component_types) { super((Pointer)null); allocate(scope, component_types); }
  private native void allocate(@Const @ByRef Scope scope, @Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector component_types);
  public RandomShuffleQueue(@Const @ByRef Scope scope, @Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector component_types, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, component_types, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector component_types, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Shapes(@Cast("const tensorflow::gtl::ArraySlice<tensorflow::TensorShape>*") @ByRef TensorShapeVector x);
  public static native @ByVal Attrs Capacity(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs MinAfterDequeue(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs Container(@StringPiece BytePointer x);
  public static native @ByVal Attrs Container(@StringPiece String x);
  public static native @ByVal Attrs SharedName(@StringPiece BytePointer x);
  public static native @ByVal Attrs SharedName(@StringPiece String x);

  public native @ByRef Output handle(); public native RandomShuffleQueue handle(Output handle);
}

// A stack that produces elements in first-in last-out order.
//
// Arguments:
// * scope: A Scope object
// * elem_type:
//     The type of the elements on the stack.
@Namespace("tensorflow::ops") @NoOffset public static class Stack extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Stack(Pointer p) { super(p); }

  // Optional attribute setters for Stack :
  //
  // StackName(StringPiece): Defaults to ""
  //     Overrides the name used for the temporary stack resource. Default
  // value is the name of the 'Stack' op (which is guaranteed unique).
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs StackName(@StringPiece BytePointer x);
    public native @ByVal Attrs StackName(@StringPiece String x);

    public native @StringPiece BytePointer stack_name_(); public native Attrs stack_name_(BytePointer stack_name_);
  }
  public Stack(@Const @ByRef Scope scope, @Cast("tensorflow::DataType") int elem_type) { super((Pointer)null); allocate(scope, elem_type); }
  private native void allocate(@Const @ByRef Scope scope, @Cast("tensorflow::DataType") int elem_type);
  public Stack(@Const @ByRef Scope scope, @Cast("tensorflow::DataType") int elem_type, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, elem_type, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @Cast("tensorflow::DataType") int elem_type, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs StackName(@StringPiece BytePointer x);
  public static native @ByVal Attrs StackName(@StringPiece String x);

  public native @ByRef Output handle(); public native Stack handle(Output handle);
}

// Delete the stack from its resource container.
//
// Arguments:
// * scope: A Scope object
// * handle: The handle to a stack.
@Namespace("tensorflow::ops") @NoOffset public static class StackClose extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public StackClose(Pointer p) { super(p); }

  public StackClose(@Const @ByRef Scope scope, @ByVal Input handle) { super((Pointer)null); allocate(scope, handle); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle);
  public native @ByVal @Name("operator tensorflow::ops::Operation") Operation asOperation();

  public native @ByRef Operation operation(); public native StackClose operation(Operation operation);
}

// Pop the element at the top of the stack.
//
// Arguments:
// * scope: A Scope object
// * handle: The handle to a stack.
// * elem_type:
//     The type of the elem that is popped.
@Namespace("tensorflow::ops") @NoOffset public static class StackPop extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public StackPop(Pointer p) { super(p); }

  public StackPop(@Const @ByRef Scope scope, @ByVal Input handle,
           @Cast("tensorflow::DataType") int elem_type) { super((Pointer)null); allocate(scope, handle, elem_type); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle,
           @Cast("tensorflow::DataType") int elem_type);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output elem(); public native StackPop elem(Output elem);
}

// Push an element onto the stack.
//
// Arguments:
// * scope: A Scope object
// * handle: The handle to a stack.
// * elem: The tensor to be pushed onto the stack.
@Namespace("tensorflow::ops") @NoOffset public static class StackPush extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public StackPush(Pointer p) { super(p); }

  // Optional attribute setters for StackPush :
  //
  // SwapMemory(bool): Defaults to false
  //     Swap `elem` to CPU. Default to false.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs SwapMemory(@Cast("bool") boolean x);

    public native @Cast("bool") boolean swap_memory_(); public native Attrs swap_memory_(boolean swap_memory_);
  }
  public StackPush(@Const @ByRef Scope scope, @ByVal Input handle,
            @ByVal Input elem) { super((Pointer)null); allocate(scope, handle, elem); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle,
            @ByVal Input elem);
  public StackPush(@Const @ByRef Scope scope, @ByVal Input handle,
            @ByVal Input elem, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, handle, elem, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle,
            @ByVal Input elem, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs SwapMemory(@Cast("bool") boolean x);

  public native @ByRef Output output(); public native StackPush output(Output output);
}

// An array of Tensors of given size, with data written via Write and read
//
// via Read or Pack.
//
// Arguments:
// * scope: A Scope object
// * size: The size of the array.
// * dtype:
//     The type of the elements on the tensor_array.
@Namespace("tensorflow::ops") @NoOffset public static class TensorArray extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TensorArray(Pointer p) { super(p); }

  // Optional attribute setters for TensorArray :
  //
  // DynamicSize(bool): Defaults to false
  //     A boolean that determines whether writes to the TensorArray
  // are allowed to grow the size.  By default, this is not allowed.
  // ClearAfterRead(bool): Defaults to true
  //     If true (default), Tensors in the TensorArray are cleared
  // after being read.  This disables multiple read semantics but allows early
  // release of memory.
  // TensorArrayName(StringPiece): Defaults to ""
  //     Overrides the name used for the temporary tensor_array
  // resource. Default value is the name of the 'TensorArray' op (which
  // is guaranteed unique).
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs DynamicSize(@Cast("bool") boolean x);

    public native @ByVal Attrs ClearAfterRead(@Cast("bool") boolean x);

    public native @ByVal Attrs TensorArrayName(@StringPiece BytePointer x);
    public native @ByVal Attrs TensorArrayName(@StringPiece String x);

    public native @Cast("bool") boolean dynamic_size_(); public native Attrs dynamic_size_(boolean dynamic_size_);
    public native @Cast("bool") boolean clear_after_read_(); public native Attrs clear_after_read_(boolean clear_after_read_);
    public native @StringPiece BytePointer tensor_array_name_(); public native Attrs tensor_array_name_(BytePointer tensor_array_name_);
  }
  public TensorArray(@Const @ByRef Scope scope, @ByVal Input size,
              @Cast("tensorflow::DataType") int dtype) { super((Pointer)null); allocate(scope, size, dtype); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input size,
              @Cast("tensorflow::DataType") int dtype);
  public TensorArray(@Const @ByRef Scope scope, @ByVal Input size,
              @Cast("tensorflow::DataType") int dtype, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, size, dtype, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input size,
              @Cast("tensorflow::DataType") int dtype, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs DynamicSize(@Cast("bool") boolean x);
  public static native @ByVal Attrs ClearAfterRead(@Cast("bool") boolean x);
  public static native @ByVal Attrs TensorArrayName(@StringPiece BytePointer x);
  public static native @ByVal Attrs TensorArrayName(@StringPiece String x);

  public native @ByRef Output handle(); public native TensorArray handle(Output handle);
}

// Delete the TensorArray from its resource container.  This enables
//
// the user to close and release the resource in the middle of a step/run.
//
// Arguments:
// * scope: A Scope object
// * handle: The handle to a TensorArray (output of TensorArray or TensorArrayGrad).
@Namespace("tensorflow::ops") @NoOffset public static class TensorArrayClose extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TensorArrayClose(Pointer p) { super(p); }

  public TensorArrayClose(@Const @ByRef Scope scope, @ByVal Input handle) { super((Pointer)null); allocate(scope, handle); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle);
  public native @ByVal @Name("operator tensorflow::ops::Operation") Operation asOperation();

  public native @ByRef Operation operation(); public native TensorArrayClose operation(Operation operation);
}

// Concat the elements from the TensorArray into value `value`.
//
// Takes `T` elements of shapes
//
//   ```
//   (n0 x d0 x d1 x ...), (n1 x d0 x d1 x ...), ..., (n(T-1) x d0 x d1 x ...)
//   ```
//
// and concatenates them into a Tensor of shape:
//
//   ```(n0 + n1 + ... + n(T-1) x d0 x d1 x ...)```
//
// All elements must have the same shape (excepting the first dimension).
//
// Arguments:
// * scope: A Scope object
// * handle: The handle to a TensorArray.
// * flow_in: A float scalar that enforces proper chaining of operations.
// * dtype:
//     The type of the elem that is returned.
@Namespace("tensorflow::ops") @NoOffset public static class TensorArrayConcat extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TensorArrayConcat(Pointer p) { super(p); }

  // Optional attribute setters for TensorArrayConcat :
  //
  // ElementShapeExcept0(TensorShape): Defaults to <unknown>
  //     The expected shape of an element, if known,
  // excluding the first dimension. Used to validate the shapes of
  // TensorArray elements. If this shape is not fully specified, concatenating
  // zero-size TensorArrays is an error.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs ElementShapeExcept0(@ByVal TensorShape x);

    public native @ByRef TensorShape element_shape_except0_(); public native Attrs element_shape_except0_(TensorShape element_shape_except0_);
  }
  public TensorArrayConcat(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input flow_in, @Cast("tensorflow::DataType") int dtype) { super((Pointer)null); allocate(scope, handle, flow_in, dtype); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input flow_in, @Cast("tensorflow::DataType") int dtype);
  public TensorArrayConcat(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input flow_in, @Cast("tensorflow::DataType") int dtype,
                    @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, handle, flow_in, dtype, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input flow_in, @Cast("tensorflow::DataType") int dtype,
                    @Const @ByRef Attrs attrs);

  public static native @ByVal Attrs ElementShapeExcept0(@ByVal TensorShape x);

  public native @ByRef Output value(); public native TensorArrayConcat value(Output value);
  public native @ByRef Output lengths(); public native TensorArrayConcat lengths(Output lengths);
}

// Gather specific elements from the TensorArray into output `value`.
//
// All elements selected by `indices` must have the same shape.
//
// Arguments:
// * scope: A Scope object
// * handle: The handle to a TensorArray.
// * indices: The locations in the TensorArray from which to read tensor elements.
// * flow_in: A float scalar that enforces proper chaining of operations.
// * dtype:
//     The type of the elem that is returned.
@Namespace("tensorflow::ops") @NoOffset public static class TensorArrayGather extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TensorArrayGather(Pointer p) { super(p); }

  // Optional attribute setters for TensorArrayGather :
  //
  // ElementShape(TensorShape): Defaults to <unknown>
  //     The expected shape of an element, if known. Used to
  // validate the shapes of TensorArray elements. If this shape is not
  // fully specified, gathering zero-size TensorArrays is an error.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs ElementShape(@ByVal TensorShape x);

    public native @ByRef TensorShape element_shape_(); public native Attrs element_shape_(TensorShape element_shape_);
  }
  public TensorArrayGather(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input indices,
                    @ByVal Input flow_in, @Cast("tensorflow::DataType") int dtype) { super((Pointer)null); allocate(scope, handle, indices, flow_in, dtype); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input indices,
                    @ByVal Input flow_in, @Cast("tensorflow::DataType") int dtype);
  public TensorArrayGather(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input indices,
                    @ByVal Input flow_in, @Cast("tensorflow::DataType") int dtype, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, handle, indices, flow_in, dtype, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input indices,
                    @ByVal Input flow_in, @Cast("tensorflow::DataType") int dtype, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs ElementShape(@ByVal TensorShape x);

  public native @ByRef Output value(); public native TensorArrayGather value(Output value);
}

// Creates a TensorArray for storing the gradients of values in the given handle.
//
// If the given TensorArray gradient already exists, returns a reference to it.
//
// Locks the size of the original TensorArray by disabling its dynamic size flag.
//
// **A note about the input flow_in:**
//
// The handle flow_in forces the execution of the gradient lookup to occur
// only after certain other operations have occurred.  For example, when
// the forward TensorArray is dynamically sized, writes to this TensorArray
// may resize the object.  The gradient TensorArray is statically sized based
// on the size of the forward TensorArray when this operation executes.
// Furthermore, the size of the forward TensorArray is frozen by this call.
// As a result, the flow is used to ensure that the call to generate the gradient
// TensorArray only happens after all writes are executed.
//
// In the case of dynamically sized TensorArrays, gradient computation should
// only be performed on read operations that have themselves been chained via
// flow to occur only after all writes have executed. That way the final size
// of the forward TensorArray is known when this operation is called.
//
// **A note about the source attribute:**
//
// TensorArray gradient calls use an accumulator TensorArray object.  If
// multiple gradients are calculated and run in the same session, the multiple
// gradient nodes may accidentally flow throuth the same accumulator TensorArray.
// This double counts and generally breaks the TensorArray gradient flow.
//
// The solution is to identify which gradient call this particular
// TensorArray gradient is being called in.  This is performed by identifying
// a unique string (e.g. "gradients", "gradients_1", ...) from the input
// gradient Tensor's name.  This string is used as a suffix when creating
// the TensorArray gradient object here (the attribute `source`).
//
// The attribute `source` is added as a suffix to the forward TensorArray's
// name when performing the creation / lookup, so that each separate gradient
// calculation gets its own TensorArray accumulator.
//
// Arguments:
// * scope: A Scope object
// * handle: The handle to the forward TensorArray.
// * flow_in: A float scalar that enforces proper chaining of operations.
// * source:
//     The gradient source string, used to decide which gradient TensorArray
// to return.
@Namespace("tensorflow::ops") @NoOffset public static class TensorArrayGrad extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TensorArrayGrad(Pointer p) { super(p); }

  public TensorArrayGrad(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input flow_in, @StringPiece BytePointer source) { super((Pointer)null); allocate(scope, handle, flow_in, source); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input flow_in, @StringPiece BytePointer source);
  public TensorArrayGrad(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input flow_in, @StringPiece String source) { super((Pointer)null); allocate(scope, handle, flow_in, source); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input flow_in, @StringPiece String source);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output grad_handle(); public native TensorArrayGrad grad_handle(Output grad_handle);
}

// Pack the elements from the TensorArray into output `value`.
//
// **WARNING: This op is deprecated.**
//
// Instead of this op, use `TensorArrayGather` with
// `indices = RangeOp(0, TensorArraySizeOp)`.
//
// All elements must have the same shape.
//
// Arguments:
// * scope: A Scope object
// * handle: The handle to a TensorArray.
// * flow_in: A float scalar that enforces proper chaining of operations.
// * dtype:
//     The type of the elem that is returned.
@Namespace("tensorflow::ops") @NoOffset public static class TensorArrayPack extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TensorArrayPack(Pointer p) { super(p); }

  // Optional attribute setters for TensorArrayPack :
  //
  // ElementShape(TensorShape): Defaults to <unknown>
  //     The expected shape of an element, if known. Used to
  // validate the shapes of TensorArray elements. If this shape is not
  // fully specified, packing zero-size TensorArrays is an error.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs ElementShape(@ByVal TensorShape x);

    public native @ByRef TensorShape element_shape_(); public native Attrs element_shape_(TensorShape element_shape_);
  }
  public TensorArrayPack(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input flow_in, @Cast("tensorflow::DataType") int dtype) { super((Pointer)null); allocate(scope, handle, flow_in, dtype); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input flow_in, @Cast("tensorflow::DataType") int dtype);
  public TensorArrayPack(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input flow_in, @Cast("tensorflow::DataType") int dtype, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, handle, flow_in, dtype, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input flow_in, @Cast("tensorflow::DataType") int dtype, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs ElementShape(@ByVal TensorShape x);

  public native @ByRef Output value(); public native TensorArrayPack value(Output value);
}

// Read an element from the TensorArray into output `value`.
//
// Arguments:
// * scope: A Scope object
// * handle: The handle to a TensorArray.
// * flow_in: A float scalar that enforces proper chaining of operations.
// * dtype:
//     The type of the elem that is returned.
@Namespace("tensorflow::ops") @NoOffset public static class TensorArrayRead extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TensorArrayRead(Pointer p) { super(p); }

  public TensorArrayRead(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input index,
                  @ByVal Input flow_in, @Cast("tensorflow::DataType") int dtype) { super((Pointer)null); allocate(scope, handle, index, flow_in, dtype); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input index,
                  @ByVal Input flow_in, @Cast("tensorflow::DataType") int dtype);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output value(); public native TensorArrayRead value(Output value);
}

// Scatter the data from the input value into specific TensorArray elements.
//
// `indices` must be a vector, its length must match the first dim of `value`.
//
// Arguments:
// * scope: A Scope object
// * handle: The handle to a TensorArray.
// * indices: The locations at which to write the tensor elements.
// * value: The concatenated tensor to write to the TensorArray.
// * flow_in: A float scalar that enforces proper chaining of operations.
@Namespace("tensorflow::ops") @NoOffset public static class TensorArrayScatter extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TensorArrayScatter(Pointer p) { super(p); }

  public TensorArrayScatter(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input indices,
                     @ByVal Input value, @ByVal Input flow_in) { super((Pointer)null); allocate(scope, handle, indices, value, flow_in); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input indices,
                     @ByVal Input value, @ByVal Input flow_in);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output flow_out(); public native TensorArrayScatter flow_out(Output flow_out);
}

// Get the current size of the TensorArray.
//
// Arguments:
// * scope: A Scope object
// * handle: The handle to a TensorArray (output of TensorArray or TensorArrayGrad).
// * flow_in: A float scalar that enforces proper chaining of operations.
@Namespace("tensorflow::ops") @NoOffset public static class TensorArraySize extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TensorArraySize(Pointer p) { super(p); }

  public TensorArraySize(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input flow_in) { super((Pointer)null); allocate(scope, handle, flow_in); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input flow_in);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output size(); public native TensorArraySize size(Output size);
}

// Split the data from the input value into TensorArray elements.
//
// Assuming that `lengths` takes on values
//
//   ```(n0, n1, ..., n(T-1))```
//
// and that `value` has shape
//
//   ```(n0 + n1 + ... + n(T-1) x d0 x d1 x ...)```,
//
// this splits values into a TensorArray with T tensors.
//
// TensorArray index t will be the subtensor of values with starting position
//
//   ```(n0 + n1 + ... + n(t-1), 0, 0, ...)```
//
// and having size
//
//   ```nt x d0 x d1 x ...```
//
// Arguments:
// * scope: A Scope object
// * handle: The handle to a TensorArray.
// * value: The concatenated tensor to write to the TensorArray.
// * lengths: The vector of lengths, how to split the rows of value into the
// TensorArray.
// * flow_in: A float scalar that enforces proper chaining of operations.
@Namespace("tensorflow::ops") @NoOffset public static class TensorArraySplit extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TensorArraySplit(Pointer p) { super(p); }

  public TensorArraySplit(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input value,
                   @ByVal Input lengths, @ByVal Input flow_in) { super((Pointer)null); allocate(scope, handle, value, lengths, flow_in); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input value,
                   @ByVal Input lengths, @ByVal Input flow_in);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output flow_out(); public native TensorArraySplit flow_out(Output flow_out);
}

// Unpack the data from the input value into TensorArray elements.
//
// **WARNING: This op is deprecated.**
//
// Instead of this op, use `TensorArrayScatter` with
// `indices = RangeOp(0, SizeOp(value)[0])`.
//
// Arguments:
// * scope: A Scope object
// * handle: The handle to a TensorArray.
// * value: The concatenated tensor to write to the TensorArray.
// * flow_in: A float scalar that enforces proper chaining of operations.
@Namespace("tensorflow::ops") @NoOffset public static class TensorArrayUnpack extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TensorArrayUnpack(Pointer p) { super(p); }

  public TensorArrayUnpack(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input value,
                    @ByVal Input flow_in) { super((Pointer)null); allocate(scope, handle, value, flow_in); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input value,
                    @ByVal Input flow_in);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output flow_out(); public native TensorArrayUnpack flow_out(Output flow_out);
}

// Push an element onto the tensor_array.
//
// Arguments:
// * scope: A Scope object
// * handle: The handle to a TensorArray.
// * index: The position to write to inside the TensorArray.
// * value: The tensor to write to the TensorArray.
// * flow_in: A float scalar that enforces proper chaining of operations.
@Namespace("tensorflow::ops") @NoOffset public static class TensorArrayWrite extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TensorArrayWrite(Pointer p) { super(p); }

  public TensorArrayWrite(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input index,
                   @ByVal Input value, @ByVal Input flow_in) { super((Pointer)null); allocate(scope, handle, index, value, flow_in); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input handle, @ByVal Input index,
                   @ByVal Input value, @ByVal Input flow_in);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output flow_out(); public native TensorArrayWrite flow_out(Output flow_out);
}

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_DATA_FLOW_OPS_H_


// Parsed from tensorflow/cc/ops/image_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_IMAGE_OPS_H_
// #define TENSORFLOW_CC_OPS_IMAGE_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"

// Deprecated. Disallowed in GraphDef version >= 2.
//
// DEPRECATED at GraphDef version 2:
// Use AdjustContrastv2 instead.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class AdjustContrast extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public AdjustContrast(Pointer p) { super(p); }

  public AdjustContrast(@Const @ByRef Scope scope, @ByVal Input images, @ByVal Input contrast_factor,
                 @ByVal Input min_value, @ByVal Input max_value) { super((Pointer)null); allocate(scope, images, contrast_factor, min_value, max_value); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input images, @ByVal Input contrast_factor,
                 @ByVal Input min_value, @ByVal Input max_value);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native AdjustContrast output(Output output);
}

// Adjust the contrast of one or more images.
//
// `images` is a tensor of at least 3 dimensions.  The last 3 dimensions are
// interpreted as `[height, width, channels]`.  The other dimensions only
// represent a collection of images, such as `[batch, height, width, channels].`
//
// Contrast is adjusted independently for each channel of each image.
//
// For each channel, the Op first computes the mean of the image pixels in the
// channel and then adjusts each component of each pixel to
// `(x - mean) * contrast_factor + mean`.
//
// Arguments:
// * scope: A Scope object
// * images: Images to adjust.  At least 3-D.
// * contrast_factor: A float multiplier for adjusting contrast.
@Namespace("tensorflow::ops") @NoOffset public static class AdjustContrastv2 extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public AdjustContrastv2(Pointer p) { super(p); }

  public AdjustContrastv2(@Const @ByRef Scope scope, @ByVal Input images, @ByVal Input contrast_factor) { super((Pointer)null); allocate(scope, images, contrast_factor); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input images, @ByVal Input contrast_factor);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native AdjustContrastv2 output(Output output);
}

// Extracts crops from the input image tensor and bilinearly resizes them (possibly
//
// with aspect ratio change) to a common output size specified by `crop_size`. This
// is more general than the `crop_to_bounding_box` op which extracts a fixed size
// slice from the input image and does not allow resizing or aspect ratio change.
//
// Returns a tensor with `crops` from the input `image` at positions defined at the
// bounding box locations in `boxes`. The cropped boxes are all resized (with
// bilinear interpolation) to a fixed `size = [crop_height, crop_width]`. The
// result is a 4-D tensor `[num_boxes, crop_height, crop_width, depth]`.
//
// Arguments:
// * scope: A Scope object
// * image: A 4-D tensor of shape `[batch, image_height, image_width, depth]`.
// Both `image_height` and `image_width` need to be positive.
// * boxes: A 2-D tensor of shape `[num_boxes, 4]`. The `i`-th row of the tensor
// specifies the coordinates of a box in the `box_ind[i]` image and is specified
// in normalized coordinates `[y1, x1, y2, x2]`. A normalized coordinate value of
// `y` is mapped to the image coordinate at `y * (image_height - 1)`, so as the
// `[0, 1]` interval of normalized image height is mapped to
// `[0, image_height - 1] in image height coordinates. We do allow y1 > y2, in
// which case the sampled crop is an up-down flipped version of the original
// image. The width dimension is treated similarly. Normalized coordinates
// outside the `[0, 1]` range are allowed, in which case we use
// `extrapolation_value` to extrapolate the input image values.
// * box_ind: A 1-D tensor of shape `[num_boxes]` with int32 values in `[0, batch)`.
// The value of `box_ind[i]` specifies the image that the `i`-th box refers to.
// * crop_size: A 1-D tensor of 2 elements, `size = [crop_height, crop_width]`. All
// cropped image patches are resized to this size. The aspect ratio of the image
// content is not preserved. Both `crop_height` and `crop_width` need to be
// positive.
@Namespace("tensorflow::ops") @NoOffset public static class CropAndResize extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public CropAndResize(Pointer p) { super(p); }

  // Optional attribute setters for CropAndResize :
  //
  // Method(StringPiece): Defaults to "bilinear"
  //     A string specifying the interpolation method. Only 'bilinear' is
  // supported for now.
  // ExtrapolationValue(float): Defaults to 0
  //     Value used for extrapolation, when applicable.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Method(@StringPiece BytePointer x);
    public native @ByVal Attrs Method(@StringPiece String x);

    public native @ByVal Attrs ExtrapolationValue(float x);

    public native @StringPiece BytePointer method_(); public native Attrs method_(BytePointer method_);
    public native float extrapolation_value_(); public native Attrs extrapolation_value_(float extrapolation_value_);
  }
  public CropAndResize(@Const @ByRef Scope scope, @ByVal Input image,
                @ByVal Input boxes, @ByVal Input box_ind,
                @ByVal Input crop_size) { super((Pointer)null); allocate(scope, image, boxes, box_ind, crop_size); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input image,
                @ByVal Input boxes, @ByVal Input box_ind,
                @ByVal Input crop_size);
  public CropAndResize(@Const @ByRef Scope scope, @ByVal Input image,
                @ByVal Input boxes, @ByVal Input box_ind,
                @ByVal Input crop_size, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, image, boxes, box_ind, crop_size, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input image,
                @ByVal Input boxes, @ByVal Input box_ind,
                @ByVal Input crop_size, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Method(@StringPiece BytePointer x);
  public static native @ByVal Attrs Method(@StringPiece String x);
  public static native @ByVal Attrs ExtrapolationValue(float x);

  public native @ByRef Output crops(); public native CropAndResize crops(Output crops);
}

// Computes the gradient of the crop_and_resize op wrt the input boxes tensor.
//
// Arguments:
// * scope: A Scope object
// * grads: A 4-D tensor of shape `[num_boxes, crop_height, crop_width, depth]`.
// * image: A 4-D tensor of shape `[batch, image_height, image_width, depth]`.
// Both `image_height` and `image_width` need to be positive.
// * boxes: A 2-D tensor of shape `[num_boxes, 4]`. The `i`-th row of the tensor
// specifies the coordinates of a box in the `box_ind[i]` image and is specified
// in normalized coordinates `[y1, x1, y2, x2]`. A normalized coordinate value of
// `y` is mapped to the image coordinate at `y * (image_height - 1)`, so as the
// `[0, 1]` interval of normalized image height is mapped to
// `[0, image_height - 1] in image height coordinates. We do allow y1 > y2, in
// which case the sampled crop is an up-down flipped version of the original
// image. The width dimension is treated similarly. Normalized coordinates
// outside the `[0, 1]` range are allowed, in which case we use
// `extrapolation_value` to extrapolate the input image values.
// * box_ind: A 1-D tensor of shape `[num_boxes]` with int32 values in `[0, batch)`.
// The value of `box_ind[i]` specifies the image that the `i`-th box refers to.
@Namespace("tensorflow::ops") @NoOffset public static class CropAndResizeGradBoxes extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public CropAndResizeGradBoxes(Pointer p) { super(p); }

  // Optional attribute setters for CropAndResizeGradBoxes :
  //
  // Method(StringPiece): Defaults to "bilinear"
  //     A string specifying the interpolation method. Only 'bilinear' is
  // supported for now.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Method(@StringPiece BytePointer x);
    public native @ByVal Attrs Method(@StringPiece String x);

    public native @StringPiece BytePointer method_(); public native Attrs method_(BytePointer method_);
  }
  public CropAndResizeGradBoxes(@Const @ByRef Scope scope,
                         @ByVal Input grads, @ByVal Input image, @ByVal Input boxes,
                         @ByVal Input box_ind) { super((Pointer)null); allocate(scope, grads, image, boxes, box_ind); }
  private native void allocate(@Const @ByRef Scope scope,
                         @ByVal Input grads, @ByVal Input image, @ByVal Input boxes,
                         @ByVal Input box_ind);
  public CropAndResizeGradBoxes(@Const @ByRef Scope scope,
                         @ByVal Input grads, @ByVal Input image, @ByVal Input boxes,
                         @ByVal Input box_ind, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, grads, image, boxes, box_ind, attrs); }
  private native void allocate(@Const @ByRef Scope scope,
                         @ByVal Input grads, @ByVal Input image, @ByVal Input boxes,
                         @ByVal Input box_ind, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Method(@StringPiece BytePointer x);
  public static native @ByVal Attrs Method(@StringPiece String x);

  public native @ByRef Output output(); public native CropAndResizeGradBoxes output(Output output);
}

// Computes the gradient of the crop_and_resize op wrt the input image tensor.
//
// Arguments:
// * scope: A Scope object
// * grads: A 4-D tensor of shape `[num_boxes, crop_height, crop_width, depth]`.
// * boxes: A 2-D tensor of shape `[num_boxes, 4]`. The `i`-th row of the tensor
// specifies the coordinates of a box in the `box_ind[i]` image and is specified
// in normalized coordinates `[y1, x1, y2, x2]`. A normalized coordinate value of
// `y` is mapped to the image coordinate at `y * (image_height - 1)`, so as the
// `[0, 1]` interval of normalized image height is mapped to
// `[0, image_height - 1] in image height coordinates. We do allow y1 > y2, in
// which case the sampled crop is an up-down flipped version of the original
// image. The width dimension is treated similarly. Normalized coordinates
// outside the `[0, 1]` range are allowed, in which case we use
// `extrapolation_value` to extrapolate the input image values.
// * box_ind: A 1-D tensor of shape `[num_boxes]` with int32 values in `[0, batch)`.
// The value of `box_ind[i]` specifies the image that the `i`-th box refers to.
// * image_size: A 1-D tensor with value `[batch, image_height, image_width, depth]`
// containing the original image size. Both `image_height` and `image_width` need
// to be positive.
@Namespace("tensorflow::ops") @NoOffset public static class CropAndResizeGradImage extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public CropAndResizeGradImage(Pointer p) { super(p); }

  // Optional attribute setters for CropAndResizeGradImage :
  //
  // Method(StringPiece): Defaults to "bilinear"
  //     A string specifying the interpolation method. Only 'bilinear' is
  // supported for now.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Method(@StringPiece BytePointer x);
    public native @ByVal Attrs Method(@StringPiece String x);

    public native @StringPiece BytePointer method_(); public native Attrs method_(BytePointer method_);
  }
  public CropAndResizeGradImage(@Const @ByRef Scope scope,
                         @ByVal Input grads, @ByVal Input boxes, @ByVal Input box_ind,
                         @ByVal Input image_size, @Cast("tensorflow::DataType") int T) { super((Pointer)null); allocate(scope, grads, boxes, box_ind, image_size, T); }
  private native void allocate(@Const @ByRef Scope scope,
                         @ByVal Input grads, @ByVal Input boxes, @ByVal Input box_ind,
                         @ByVal Input image_size, @Cast("tensorflow::DataType") int T);
  public CropAndResizeGradImage(@Const @ByRef Scope scope,
                         @ByVal Input grads, @ByVal Input boxes, @ByVal Input box_ind,
                         @ByVal Input image_size, @Cast("tensorflow::DataType") int T, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, grads, boxes, box_ind, image_size, T, attrs); }
  private native void allocate(@Const @ByRef Scope scope,
                         @ByVal Input grads, @ByVal Input boxes, @ByVal Input box_ind,
                         @ByVal Input image_size, @Cast("tensorflow::DataType") int T, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Method(@StringPiece BytePointer x);
  public static native @ByVal Attrs Method(@StringPiece String x);

  public native @ByRef Output output(); public native CropAndResizeGradImage output(Output output);
}

// Decode the first frame of a GIF-encoded image to a uint8 tensor.
//
// GIF with frame or transparency compression are not supported
// convert animated GIF from compressed to uncompressed by:
//
// convert $src.gif -coalesce $dst.gif
//
// Arguments:
// * scope: A Scope object
// * contents: 0-D.  The GIF-encoded image.
@Namespace("tensorflow::ops") @NoOffset public static class DecodeGif extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public DecodeGif(Pointer p) { super(p); }

  public DecodeGif(@Const @ByRef Scope scope, @ByVal Input contents) { super((Pointer)null); allocate(scope, contents); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input contents);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output image(); public native DecodeGif image(Output image);
}

// Decode a JPEG-encoded image to a uint8 tensor.
//
// The attr `channels` indicates the desired number of color channels for the
// decoded image.
//
// Accepted values are:
//
// *   0: Use the number of channels in the JPEG-encoded image.
// *   1: output a grayscale image.
// *   3: output an RGB image.
//
// If needed, the JPEG-encoded image is transformed to match the requested number
// of color channels.
//
// The attr `ratio` allows downscaling the image by an integer factor during
// decoding.  Allowed values are: 1, 2, 4, and 8.  This is much faster than
// downscaling the image later.
//
// Arguments:
// * scope: A Scope object
// * contents: 0-D.  The JPEG-encoded image.
@Namespace("tensorflow::ops") @NoOffset public static class DecodeJpeg extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public DecodeJpeg(Pointer p) { super(p); }

  // Optional attribute setters for DecodeJpeg :
  //
  // Channels(int64): Defaults to 0
  //     Number of color channels for the decoded image.
  // Ratio(int64): Defaults to 1
  //     Downscaling ratio.
  // FancyUpscaling(bool): Defaults to true
  //     If true use a slower but nicer upscaling of the
  // chroma planes (yuv420/422 only).
  // TryRecoverTruncated(bool): Defaults to false
  //     If true try to recover an image from truncated input.
  // AcceptableFraction(float): Defaults to 1
  //     The minimum required fraction of lines before a truncated
  // input is accepted.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Channels(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs Ratio(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs FancyUpscaling(@Cast("bool") boolean x);

    public native @ByVal Attrs TryRecoverTruncated(@Cast("bool") boolean x);

    public native @ByVal Attrs AcceptableFraction(float x);

    public native @Cast("tensorflow::int64") long channels_(); public native Attrs channels_(long channels_);
    public native @Cast("tensorflow::int64") long ratio_(); public native Attrs ratio_(long ratio_);
    public native @Cast("bool") boolean fancy_upscaling_(); public native Attrs fancy_upscaling_(boolean fancy_upscaling_);
    public native @Cast("bool") boolean try_recover_truncated_(); public native Attrs try_recover_truncated_(boolean try_recover_truncated_);
    public native float acceptable_fraction_(); public native Attrs acceptable_fraction_(float acceptable_fraction_);
  }
  public DecodeJpeg(@Const @ByRef Scope scope, @ByVal Input contents) { super((Pointer)null); allocate(scope, contents); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input contents);
  public DecodeJpeg(@Const @ByRef Scope scope, @ByVal Input contents,
             @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, contents, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input contents,
             @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Channels(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs Ratio(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs FancyUpscaling(@Cast("bool") boolean x);
  public static native @ByVal Attrs TryRecoverTruncated(@Cast("bool") boolean x);
  public static native @ByVal Attrs AcceptableFraction(float x);

  public native @ByRef Output image(); public native DecodeJpeg image(Output image);
}

// Decode a PNG-encoded image to a uint8 or uint16 tensor.
//
// The attr `channels` indicates the desired number of color channels for the
// decoded image.
//
// Accepted values are:
//
// *   0: Use the number of channels in the PNG-encoded image.
// *   1: output a grayscale image.
// *   3: output an RGB image.
// *   4: output an RGBA image.
//
// If needed, the PNG-encoded image is transformed to match the requested number
// of color channels.
//
// Arguments:
// * scope: A Scope object
// * contents: 0-D.  The PNG-encoded image.
@Namespace("tensorflow::ops") @NoOffset public static class DecodePng extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public DecodePng(Pointer p) { super(p); }

  // Optional attribute setters for DecodePng :
  //
  // Channels(int64): Defaults to 0
  //     Number of color channels for the decoded image.
  // Dtype(DataType): Defaults to DT_UINT8
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Channels(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs Dtype(@Cast("tensorflow::DataType") int x);

    public native @Cast("tensorflow::int64") long channels_(); public native Attrs channels_(long channels_);
    public native @Cast("tensorflow::DataType") int dtype_(); public native Attrs dtype_(int dtype_);
  }
  public DecodePng(@Const @ByRef Scope scope, @ByVal Input contents) { super((Pointer)null); allocate(scope, contents); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input contents);
  public DecodePng(@Const @ByRef Scope scope, @ByVal Input contents,
            @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, contents, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input contents,
            @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Channels(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs Dtype(@Cast("tensorflow::DataType") int x);

  public native @ByRef Output image(); public native DecodePng image(Output image);
}

// Draw bounding boxes on a batch of images.
//
// Outputs a copy of `images` but draws on top of the pixels zero or more bounding
// boxes specified by the locations in `boxes`. The coordinates of the each
// bounding box in `boxes` are encoded as `[y_min, x_min, y_max, x_max]`. The
// bounding box coordinates are floats in `[0.0, 1.0]` relative to the width and
// height of the underlying image.
//
// For example, if an image is 100 x 200 pixels and the bounding box is
// `[0.1, 0.2, 0.5, 0.9]`, the bottom-left and upper-right coordinates of the
// bounding box will be `(10, 40)` to `(50, 180)`.
//
// Parts of the bounding box may fall outside the image.
//
// Arguments:
// * scope: A Scope object
// * images: 4-D with shape `[batch, height, width, depth]`. A batch of images.
// * boxes: 3-D with shape `[batch, num_bounding_boxes, 4]` containing bounding
// boxes.
@Namespace("tensorflow::ops") @NoOffset public static class DrawBoundingBoxes extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public DrawBoundingBoxes(Pointer p) { super(p); }

  public DrawBoundingBoxes(@Const @ByRef Scope scope, @ByVal Input images, @ByVal Input boxes) { super((Pointer)null); allocate(scope, images, boxes); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input images, @ByVal Input boxes);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native DrawBoundingBoxes output(Output output);
}

// JPEG-encode an image.
//
// `image` is a 3-D uint8 Tensor of shape `[height, width, channels]`.
//
// The attr `format` can be used to override the color format of the encoded
// output.  Values can be:
//
// *   `''`: Use a default format based on the number of channels in the image.
// *   `grayscale`: Output a grayscale JPEG image.  The `channels` dimension
//     of `image` must be 1.
// *   `rgb`: Output an RGB JPEG image. The `channels` dimension
//     of `image` must be 3.
//
// If `format` is not specified or is the empty string, a default format is picked
// in function of the number of channels in `image`:
//
// *   1: Output a grayscale image.
// *   3: Output an RGB image.
//
// Arguments:
// * scope: A Scope object
// * image: 3-D with shape `[height, width, channels]`.
@Namespace("tensorflow::ops") @NoOffset public static class EncodeJpeg extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public EncodeJpeg(Pointer p) { super(p); }

  // Optional attribute setters for EncodeJpeg :
  //
  // Format(StringPiece): Defaults to ""
  //     Per pixel image format.
  // Quality(int64): Defaults to 95
  //     Quality of the compression from 0 to 100 (higher is better and slower).
  // Progressive(bool): Defaults to false
  //     If True, create a JPEG that loads progressively (coarse to fine).
  // OptimizeSize(bool): Defaults to false
  //     If True, spend CPU/RAM to reduce size with no quality change.
  // ChromaDownsampling(bool): Defaults to true
  //     See http://en.wikipedia.org/wiki/Chroma_subsampling.
  // DensityUnit(StringPiece): Defaults to "in"
  //     Unit used to specify `x_density` and `y_density`:
  // pixels per inch (`'in'`) or centimeter (`'cm'`).
  // XDensity(int64): Defaults to 300
  //     Horizontal pixels per density unit.
  // YDensity(int64): Defaults to 300
  //     Vertical pixels per density unit.
  // XmpMetadata(StringPiece): Defaults to ""
  //     If not empty, embed this XMP metadata in the image header.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Format(@StringPiece BytePointer x);
    public native @ByVal Attrs Format(@StringPiece String x);

    public native @ByVal Attrs Quality(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs Progressive(@Cast("bool") boolean x);

    public native @ByVal Attrs OptimizeSize(@Cast("bool") boolean x);

    public native @ByVal Attrs ChromaDownsampling(@Cast("bool") boolean x);

    public native @ByVal Attrs DensityUnit(@StringPiece BytePointer x);
    public native @ByVal Attrs DensityUnit(@StringPiece String x);

    public native @ByVal Attrs XDensity(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs YDensity(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs XmpMetadata(@StringPiece BytePointer x);
    public native @ByVal Attrs XmpMetadata(@StringPiece String x);

    public native @StringPiece BytePointer format_(); public native Attrs format_(BytePointer format_);
    public native @Cast("tensorflow::int64") long quality_(); public native Attrs quality_(long quality_);
    public native @Cast("bool") boolean progressive_(); public native Attrs progressive_(boolean progressive_);
    public native @Cast("bool") boolean optimize_size_(); public native Attrs optimize_size_(boolean optimize_size_);
    public native @Cast("bool") boolean chroma_downsampling_(); public native Attrs chroma_downsampling_(boolean chroma_downsampling_);
    public native @StringPiece BytePointer density_unit_(); public native Attrs density_unit_(BytePointer density_unit_);
    public native @Cast("tensorflow::int64") long x_density_(); public native Attrs x_density_(long x_density_);
    public native @Cast("tensorflow::int64") long y_density_(); public native Attrs y_density_(long y_density_);
    public native @StringPiece BytePointer xmp_metadata_(); public native Attrs xmp_metadata_(BytePointer xmp_metadata_);
  }
  public EncodeJpeg(@Const @ByRef Scope scope, @ByVal Input image) { super((Pointer)null); allocate(scope, image); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input image);
  public EncodeJpeg(@Const @ByRef Scope scope, @ByVal Input image,
             @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, image, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input image,
             @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Format(@StringPiece BytePointer x);
  public static native @ByVal Attrs Format(@StringPiece String x);
  public static native @ByVal Attrs Quality(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs Progressive(@Cast("bool") boolean x);
  public static native @ByVal Attrs OptimizeSize(@Cast("bool") boolean x);
  public static native @ByVal Attrs ChromaDownsampling(@Cast("bool") boolean x);
  public static native @ByVal Attrs DensityUnit(@StringPiece BytePointer x);
  public static native @ByVal Attrs DensityUnit(@StringPiece String x);
  public static native @ByVal Attrs XDensity(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs YDensity(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs XmpMetadata(@StringPiece BytePointer x);
  public static native @ByVal Attrs XmpMetadata(@StringPiece String x);

  public native @ByRef Output contents(); public native EncodeJpeg contents(Output contents);
}

// PNG-encode an image.
//
// `image` is a 3-D uint8 or uint16 Tensor of shape `[height, width, channels]`
// where `channels` is:
//
// *   1: for grayscale.
// *   2: for grayscale + alpha.
// *   3: for RGB.
// *   4: for RGBA.
//
// The ZLIB compression level, `compression`, can be -1 for the PNG-encoder
// default or a value from 0 to 9.  9 is the highest compression level, generating
// the smallest output, but is slower.
//
// Arguments:
// * scope: A Scope object
// * image: 3-D with shape `[height, width, channels]`.
@Namespace("tensorflow::ops") @NoOffset public static class EncodePng extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public EncodePng(Pointer p) { super(p); }

  // Optional attribute setters for EncodePng :
  //
  // Compression(int64): Defaults to -1
  //     Compression level.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Compression(@Cast("tensorflow::int64") long x);

    public native @Cast("tensorflow::int64") long compression_(); public native Attrs compression_(long compression_);
  }
  public EncodePng(@Const @ByRef Scope scope, @ByVal Input image) { super((Pointer)null); allocate(scope, image); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input image);
  public EncodePng(@Const @ByRef Scope scope, @ByVal Input image,
            @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, image, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input image,
            @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Compression(@Cast("tensorflow::int64") long x);

  public native @ByRef Output contents(); public native EncodePng contents(Output contents);
}

// Extracts a glimpse from the input tensor.
//
// Returns a set of windows called glimpses extracted at location
// `offsets` from the input tensor. If the windows only partially
// overlaps the inputs, the non overlapping areas will be filled with
// random noise.
//
// The result is a 4-D tensor of shape `[batch_size, glimpse_height,
// glimpse_width, channels]`. The channels and batch dimensions are the
// same as that of the input tensor. The height and width of the output
// windows are specified in the `size` parameter.
//
// The argument `normalized` and `centered` controls how the windows are built:
//
// * If the coordinates are normalized but not centered, 0.0 and 1.0
//   correspond to the minimum and maximum of each height and width
//   dimension.
// * If the coordinates are both normalized and centered, they range from
//   -1.0 to 1.0. The coordinates (-1.0, -1.0) correspond to the upper
//   left corner, the lower right corner is located at (1.0, 1.0) and the
//   center is at (0, 0).
// * If the coordinates are not normalized they are interpreted as
//   numbers of pixels.
//
// Arguments:
// * scope: A Scope object
// * input: A 4-D float tensor of shape `[batch_size, height, width, channels]`.
// * size: A 1-D tensor of 2 elements containing the size of the glimpses
// to extract.  The glimpse height must be specified first, following
// by the glimpse width.
// * offsets: A 2-D integer tensor of shape `[batch_size, 2]` containing
// the x, y locations of the center of each window.
@Namespace("tensorflow::ops") @NoOffset public static class ExtractGlimpse extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ExtractGlimpse(Pointer p) { super(p); }

  // Optional attribute setters for ExtractGlimpse :
  //
  // Centered(bool): Defaults to true
  //     indicates if the offset coordinates are centered relative to
  // the image, in which case the (0, 0) offset is relative to the center
  // of the input images. If false, the (0,0) offset corresponds to the
  // upper left corner of the input images.
  // Normalized(bool): Defaults to true
  //     indicates if the offset coordinates are normalized.
  // UniformNoise(bool): Defaults to true
  //     indicates if the noise should be generated using a
  // uniform distribution or a gaussian distribution.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Centered(@Cast("bool") boolean x);

    public native @ByVal Attrs Normalized(@Cast("bool") boolean x);

    public native @ByVal Attrs UniformNoise(@Cast("bool") boolean x);

    public native @Cast("bool") boolean centered_(); public native Attrs centered_(boolean centered_);
    public native @Cast("bool") boolean normalized_(); public native Attrs normalized_(boolean normalized_);
    public native @Cast("bool") boolean uniform_noise_(); public native Attrs uniform_noise_(boolean uniform_noise_);
  }
  public ExtractGlimpse(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input size, @ByVal Input offsets) { super((Pointer)null); allocate(scope, input, size, offsets); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input size, @ByVal Input offsets);
  public ExtractGlimpse(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input size, @ByVal Input offsets, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, size, offsets, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input size, @ByVal Input offsets, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Centered(@Cast("bool") boolean x);
  public static native @ByVal Attrs Normalized(@Cast("bool") boolean x);
  public static native @ByVal Attrs UniformNoise(@Cast("bool") boolean x);

  public native @ByRef Output glimpse(); public native ExtractGlimpse glimpse(Output glimpse);
}

// Convert one or more images from HSV to RGB.
//
// Outputs a tensor of the same shape as the `images` tensor, containing the RGB
// value of the pixels. The output is only well defined if the value in `images`
// are in `[0,1]`.
//
// See `rgb_to_hsv` for a description of the HSV encoding.
//
// Arguments:
// * scope: A Scope object
// * images: 1-D or higher rank. HSV data to convert. Last dimension must be size 3.
@Namespace("tensorflow::ops") @NoOffset public static class HSVToRGB extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public HSVToRGB(Pointer p) { super(p); }

  public HSVToRGB(@Const @ByRef Scope scope, @ByVal Input images) { super((Pointer)null); allocate(scope, images); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input images);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native HSVToRGB output(Output output);
}

// Greedily selects a subset of bounding boxes in descending order of score,
//
// pruning away boxes that have high intersection-over-union (IOU) overlap
// with previously selected boxes.  Bounding boxes are supplied as
// [y1, x1, y2, x2], where (y1, x1) and (y2, x2) are the coordinates of any
// diagonal pair of box corners and the coordinates can be provided as normalized
// (i.e., lying in the interval [0, 1]) or absolute.  Note that this algorithm
// is agnostic to where the origin is in the coordinate system.  Note that this
// algorithm is invariant to orthogonal transformations and translations
// of the coordinate system; thus translating or reflections of the coordinate
// system result in the same boxes being selected by the algorithm.
//
// The output of this operation is a set of integers indexing into the input
// collection of bounding boxes representing the selected boxes.  The bounding
// box coordinates corresponding to the selected indices can then be obtained
// using the tf.gather operation.  For example:
//
//   selected_indices = tf.image.non_max_suppression(
//       boxes, scores, max_output_size, iou_threshold)
//   selected_boxes = tf.gather(boxes, selected_indices)
//
// Arguments:
// * scope: A Scope object
// * boxes: A 2-D float tensor of shape `[num_boxes, 4]`.
// * scores: A 1-D float tensor of shape `[num_boxes]` representing a single
// score corresponding to each box (each row of boxes).
// * max_output_size: A scalar integer tensor representing the maximum number of
// boxes to be selected by non max suppression.
@Namespace("tensorflow::ops") @NoOffset public static class NonMaxSuppression extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public NonMaxSuppression(Pointer p) { super(p); }

  // Optional attribute setters for NonMaxSuppression :
  //
  // IouThreshold(float): Defaults to 0.5
  //     A float representing the threshold for deciding whether boxes
  // overlap too much with respect to IOU.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs IouThreshold(float x);

    public native float iou_threshold_(); public native Attrs iou_threshold_(float iou_threshold_);
  }
  public NonMaxSuppression(@Const @ByRef Scope scope, @ByVal Input boxes, @ByVal Input scores,
                    @ByVal Input max_output_size) { super((Pointer)null); allocate(scope, boxes, scores, max_output_size); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input boxes, @ByVal Input scores,
                    @ByVal Input max_output_size);
  public NonMaxSuppression(@Const @ByRef Scope scope, @ByVal Input boxes, @ByVal Input scores,
                    @ByVal Input max_output_size, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, boxes, scores, max_output_size, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input boxes, @ByVal Input scores,
                    @ByVal Input max_output_size, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs IouThreshold(float x);

  public native @ByRef Output selected_indices(); public native NonMaxSuppression selected_indices(Output selected_indices);
}

// Converts one or more images from RGB to HSV.
//
// Outputs a tensor of the same shape as the `images` tensor, containing the HSV
// value of the pixels. The output is only well defined if the value in `images`
// are in `[0,1]`.
//
// `output[..., 0]` contains hue, `output[..., 1]` contains saturation, and
// `output[..., 2]` contains value. All HSV values are in `[0,1]`. A hue of 0
// corresponds to pure red, hue 1/3 is pure green, and 2/3 is pure blue.
//
// Arguments:
// * scope: A Scope object
// * images: 1-D or higher rank. RGB data to convert. Last dimension must be size 3.
@Namespace("tensorflow::ops") @NoOffset public static class RGBToHSV extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public RGBToHSV(Pointer p) { super(p); }

  public RGBToHSV(@Const @ByRef Scope scope, @ByVal Input images) { super((Pointer)null); allocate(scope, images); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input images);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native RGBToHSV output(Output output);
}

// Randomly crop `image`.
//
// DEPRECATED at GraphDef version 8:
// Random crop is now pure Python.
//
// `size` is a 1-D int64 tensor with 2 elements representing the crop height and
// width.  The values must be non negative.
//
// This Op picks a random location in `image` and crops a `height` by `width`
// rectangle from that location.  The random location is picked so the cropped
// area will fit inside the original image.
//
// Arguments:
// * scope: A Scope object
// * image: 3-D of shape `[height, width, channels]`.
// * size: 1-D of length 2 containing: `crop_height`, `crop_width`..
@Namespace("tensorflow::ops") @NoOffset public static class RandomCrop extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public RandomCrop(Pointer p) { super(p); }

  // Optional attribute setters for RandomCrop :
  //
  // Seed(int64): Defaults to 0
  //     If either seed or seed2 are set to be non-zero, the random number
  // generator is seeded by the given seed.  Otherwise, it is seeded by a
  // random seed.
  // Seed2(int64): Defaults to 0
  //     An second seed to avoid seed collision.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);

    public native @Cast("tensorflow::int64") long seed_(); public native Attrs seed_(long seed_);
    public native @Cast("tensorflow::int64") long seed2_(); public native Attrs seed2_(long seed2_);
  }
  public RandomCrop(@Const @ByRef Scope scope, @ByVal Input image,
             @ByVal Input size) { super((Pointer)null); allocate(scope, image, size); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input image,
             @ByVal Input size);
  public RandomCrop(@Const @ByRef Scope scope, @ByVal Input image,
             @ByVal Input size, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, image, size, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input image,
             @ByVal Input size, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);

  public native @ByRef Output output(); public native RandomCrop output(Output output);
}

// Resize `images` to `size` using area interpolation.
//
// Input images can be of different types but output images are always float.
//
// Arguments:
// * scope: A Scope object
// * images: 4-D with shape `[batch, height, width, channels]`.
// * size: = A 1-D int32 Tensor of 2 elements: `new_height, new_width`.  The
// new size for the images.
@Namespace("tensorflow::ops") @NoOffset public static class ResizeArea extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ResizeArea(Pointer p) { super(p); }

  // Optional attribute setters for ResizeArea :
  //
  // AlignCorners(bool): Defaults to false
  //     If true, rescale input by (new_height - 1) / (height - 1), which
  // exactly aligns the 4 corners of images and resized images. If false, rescale
  // by new_height / height. Treat similarly the width dimension.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs AlignCorners(@Cast("bool") boolean x);

    public native @Cast("bool") boolean align_corners_(); public native Attrs align_corners_(boolean align_corners_);
  }
  public ResizeArea(@Const @ByRef Scope scope, @ByVal Input images,
             @ByVal Input size) { super((Pointer)null); allocate(scope, images, size); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input images,
             @ByVal Input size);
  public ResizeArea(@Const @ByRef Scope scope, @ByVal Input images,
             @ByVal Input size, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, images, size, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input images,
             @ByVal Input size, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs AlignCorners(@Cast("bool") boolean x);

  public native @ByRef Output resized_images(); public native ResizeArea resized_images(Output resized_images);
}

// Resize `images` to `size` using bicubic interpolation.
//
// Input images can be of different types but output images are always float.
//
// Arguments:
// * scope: A Scope object
// * images: 4-D with shape `[batch, height, width, channels]`.
// * size: = A 1-D int32 Tensor of 2 elements: `new_height, new_width`.  The
// new size for the images.
@Namespace("tensorflow::ops") @NoOffset public static class ResizeBicubic extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ResizeBicubic(Pointer p) { super(p); }

  // Optional attribute setters for ResizeBicubic :
  //
  // AlignCorners(bool): Defaults to false
  //     If true, rescale input by (new_height - 1) / (height - 1), which
  // exactly aligns the 4 corners of images and resized images. If false, rescale
  // by new_height / height. Treat similarly the width dimension.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs AlignCorners(@Cast("bool") boolean x);

    public native @Cast("bool") boolean align_corners_(); public native Attrs align_corners_(boolean align_corners_);
  }
  public ResizeBicubic(@Const @ByRef Scope scope, @ByVal Input images, @ByVal Input size) { super((Pointer)null); allocate(scope, images, size); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input images, @ByVal Input size);
  public ResizeBicubic(@Const @ByRef Scope scope, @ByVal Input images, @ByVal Input size, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, images, size, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input images, @ByVal Input size, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs AlignCorners(@Cast("bool") boolean x);

  public native @ByRef Output resized_images(); public native ResizeBicubic resized_images(Output resized_images);
}

// Resize `images` to `size` using bilinear interpolation.
//
// Input images can be of different types but output images are always float.
//
// Arguments:
// * scope: A Scope object
// * images: 4-D with shape `[batch, height, width, channels]`.
// * size: = A 1-D int32 Tensor of 2 elements: `new_height, new_width`.  The
// new size for the images.
@Namespace("tensorflow::ops") @NoOffset public static class ResizeBilinear extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ResizeBilinear(Pointer p) { super(p); }

  // Optional attribute setters for ResizeBilinear :
  //
  // AlignCorners(bool): Defaults to false
  //     If true, rescale input by (new_height - 1) / (height - 1), which
  // exactly aligns the 4 corners of images and resized images. If false, rescale
  // by new_height / height. Treat similarly the width dimension.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs AlignCorners(@Cast("bool") boolean x);

    public native @Cast("bool") boolean align_corners_(); public native Attrs align_corners_(boolean align_corners_);
  }
  public ResizeBilinear(@Const @ByRef Scope scope, @ByVal Input images, @ByVal Input size) { super((Pointer)null); allocate(scope, images, size); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input images, @ByVal Input size);
  public ResizeBilinear(@Const @ByRef Scope scope, @ByVal Input images, @ByVal Input size, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, images, size, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input images, @ByVal Input size, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs AlignCorners(@Cast("bool") boolean x);

  public native @ByRef Output resized_images(); public native ResizeBilinear resized_images(Output resized_images);
}

// Computes the gradient of bilinear interpolation.
//
// Arguments:
// * scope: A Scope object
// * grads: 4-D with shape `[batch, height, width, channels]`.
// * original_image: 4-D with shape `[batch, orig_height, orig_width, channels]`,
// The image tensor that was resized.
@Namespace("tensorflow::ops") @NoOffset public static class ResizeBilinearGrad extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ResizeBilinearGrad(Pointer p) { super(p); }

  // Optional attribute setters for ResizeBilinearGrad :
  //
  // AlignCorners(bool): Defaults to false
  //     If true, rescale grads by (orig_height - 1) / (height - 1), which
  // exactly aligns the 4 corners of grads and original_image. If false, rescale by
  // orig_height / height. Treat similarly the width dimension.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs AlignCorners(@Cast("bool") boolean x);

    public native @Cast("bool") boolean align_corners_(); public native Attrs align_corners_(boolean align_corners_);
  }
  public ResizeBilinearGrad(@Const @ByRef Scope scope, @ByVal Input grads, @ByVal Input original_image) { super((Pointer)null); allocate(scope, grads, original_image); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input grads, @ByVal Input original_image);
  public ResizeBilinearGrad(@Const @ByRef Scope scope, @ByVal Input grads, @ByVal Input original_image, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, grads, original_image, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input grads, @ByVal Input original_image, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs AlignCorners(@Cast("bool") boolean x);

  public native @ByRef Output output(); public native ResizeBilinearGrad output(Output output);
}

// Resize `images` to `size` using nearest neighbor interpolation.
//
// Arguments:
// * scope: A Scope object
// * images: 4-D with shape `[batch, height, width, channels]`.
// * size: = A 1-D int32 Tensor of 2 elements: `new_height, new_width`.  The
// new size for the images.
@Namespace("tensorflow::ops") @NoOffset public static class ResizeNearestNeighbor extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ResizeNearestNeighbor(Pointer p) { super(p); }

  // Optional attribute setters for ResizeNearestNeighbor :
  //
  // AlignCorners(bool): Defaults to false
  //     If true, rescale input by (new_height - 1) / (height - 1), which
  // exactly aligns the 4 corners of images and resized images. If false, rescale
  // by new_height / height. Treat similarly the width dimension.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs AlignCorners(@Cast("bool") boolean x);

    public native @Cast("bool") boolean align_corners_(); public native Attrs align_corners_(boolean align_corners_);
  }
  public ResizeNearestNeighbor(@Const @ByRef Scope scope,
                        @ByVal Input images, @ByVal Input size) { super((Pointer)null); allocate(scope, images, size); }
  private native void allocate(@Const @ByRef Scope scope,
                        @ByVal Input images, @ByVal Input size);
  public ResizeNearestNeighbor(@Const @ByRef Scope scope,
                        @ByVal Input images, @ByVal Input size, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, images, size, attrs); }
  private native void allocate(@Const @ByRef Scope scope,
                        @ByVal Input images, @ByVal Input size, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs AlignCorners(@Cast("bool") boolean x);

  public native @ByRef Output resized_images(); public native ResizeNearestNeighbor resized_images(Output resized_images);
}

// Computes the gradient of nearest neighbor interpolation.
//
// Arguments:
// * scope: A Scope object
// * grads: 4-D with shape `[batch, height, width, channels]`.
// * size: = A 1-D int32 Tensor of 2 elements: `orig_height, orig_width`. The
// original input size.
@Namespace("tensorflow::ops") @NoOffset public static class ResizeNearestNeighborGrad extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ResizeNearestNeighborGrad(Pointer p) { super(p); }

  // Optional attribute setters for ResizeNearestNeighborGrad :
  //
  // AlignCorners(bool): Defaults to false
  //     If true, rescale grads by (orig_height - 1) / (height - 1), which
  // exactly aligns the 4 corners of grads and original_image. If false, rescale by
  // orig_height / height. Treat similarly the width dimension.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs AlignCorners(@Cast("bool") boolean x);

    public native @Cast("bool") boolean align_corners_(); public native Attrs align_corners_(boolean align_corners_);
  }
  public ResizeNearestNeighborGrad(@Const @ByRef Scope scope,
                            @ByVal Input grads,
                            @ByVal Input size) { super((Pointer)null); allocate(scope, grads, size); }
  private native void allocate(@Const @ByRef Scope scope,
                            @ByVal Input grads,
                            @ByVal Input size);
  public ResizeNearestNeighborGrad(@Const @ByRef Scope scope,
                            @ByVal Input grads,
                            @ByVal Input size, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, grads, size, attrs); }
  private native void allocate(@Const @ByRef Scope scope,
                            @ByVal Input grads,
                            @ByVal Input size, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs AlignCorners(@Cast("bool") boolean x);

  public native @ByRef Output output(); public native ResizeNearestNeighborGrad output(Output output);
}

// Generate a single randomly distorted bounding box for an image.
//
// Bounding box annotations are often supplied in addition to ground-truth labels
// in image recognition or object localization tasks. A common technique for
// training such a system is to randomly distort an image while preserving
// its content, i.e. *data augmentation*. This Op outputs a randomly distorted
// localization of an object, i.e. bounding box, given an `image_size`,
// `bounding_boxes` and a series of constraints.
//
// The output of this Op is a single bounding box that may be used to crop the
// original image. The output is returned as 3 tensors: `begin`, `size` and
// `bboxes`. The first 2 tensors can be fed directly into `tf.slice` to crop the
// image. The latter may be supplied to `tf.image.draw_bounding_box` to visualize
// what the bounding box looks like.
//
// Bounding boxes are supplied and returned as `[y_min, x_min, y_max, x_max]`. The
// bounding box coordinates are floats in `[0.0, 1.0]` relative to the width and
// height of the underlying image.
//
// For example,
//
//     # Generate a single distorted bounding box.
//     begin, size, bbox_for_draw = tf.image.sample_distorted_bounding_box(
//         tf.shape(image),
//         bounding_boxes=bounding_boxes)
//
//     # Draw the bounding box in an image summary.
//     image_with_box = tf.image.draw_bounding_boxes(tf.expand_dims(image, 0),
//                                                   bbox_for_draw)
//     tf.image_summary('images_with_box', image_with_box)
//
//     # Employ the bounding box to distort the image.
//     distorted_image = tf.slice(image, begin, size)
//
// Note that if no bounding box information is available, setting
// `use_image_if_no_bounding_boxes = true` will assume there is a single implicit
// bounding box covering the whole image. If `use_image_if_no_bounding_boxes` is
// false and no bounding boxes are supplied, an error is raised.
//
// Arguments:
// * scope: A Scope object
// * image_size: 1-D, containing `[height, width, channels]`.
// * bounding_boxes: 3-D with shape `[batch, N, 4]` describing the N bounding boxes
// associated with the image.
@Namespace("tensorflow::ops") @NoOffset public static class SampleDistortedBoundingBox extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SampleDistortedBoundingBox(Pointer p) { super(p); }

  // Optional attribute setters for SampleDistortedBoundingBox :
  //
  // Seed(int64): Defaults to 0
  //     If either `seed` or `seed2` are set to non-zero, the random number
  // generator is seeded by the given `seed`.  Otherwise, it is seeded by a random
  // seed.
  // Seed2(int64): Defaults to 0
  //     A second seed to avoid seed collision.
  // MinObjectCovered(float): Defaults to 0.1
  //     The cropped area of the image must contain at least this
  // fraction of any bounding box supplied.
  // AspectRatioRange(const gtl::ArraySlice<float>&): Defaults to [0.75, 1.33]
  //     The cropped area of the image must have an aspect ratio =
  // width / height within this range.
  // AreaRange(const gtl::ArraySlice<float>&): Defaults to [0.05, 1]
  //     The cropped area of the image must contain a fraction of the
  // supplied image within in this range.
  // MaxAttempts(int64): Defaults to 100
  //     Number of attempts at generating a cropped region of the image
  // of the specified constraints. After `max_attempts` failures, return the entire
  // image.
  // UseImageIfNoBoundingBoxes(bool): Defaults to false
  //     Controls behavior if no bounding boxes supplied.
  // If true, assume an implicit bounding box covering the whole input. If false,
  // raise an error.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs MinObjectCovered(float x);

    public native @ByVal Attrs AspectRatioRange(@ArraySlice FloatPointer x);
    public native @ByVal Attrs AspectRatioRange(@ArraySlice FloatBuffer x);
    public native @ByVal Attrs AspectRatioRange(@ArraySlice float... x);

    public native @ByVal Attrs AreaRange(@ArraySlice FloatPointer x);
    public native @ByVal Attrs AreaRange(@ArraySlice FloatBuffer x);
    public native @ByVal Attrs AreaRange(@ArraySlice float... x);

    public native @ByVal Attrs MaxAttempts(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs UseImageIfNoBoundingBoxes(@Cast("bool") boolean x);

    public native @Cast("tensorflow::int64") long seed_(); public native Attrs seed_(long seed_);
    public native @Cast("tensorflow::int64") long seed2_(); public native Attrs seed2_(long seed2_);
    public native float min_object_covered_(); public native Attrs min_object_covered_(float min_object_covered_);
    public native @ArraySlice FloatPointer aspect_ratio_range_(); public native Attrs aspect_ratio_range_(FloatPointer aspect_ratio_range_);
    public native @ArraySlice FloatPointer area_range_(); public native Attrs area_range_(FloatPointer area_range_);
    public native @Cast("tensorflow::int64") long max_attempts_(); public native Attrs max_attempts_(long max_attempts_);
    public native @Cast("bool") boolean use_image_if_no_bounding_boxes_(); public native Attrs use_image_if_no_bounding_boxes_(boolean use_image_if_no_bounding_boxes_);
  }
  public SampleDistortedBoundingBox(@Const @ByRef Scope scope,
                             @ByVal Input image_size,
                             @ByVal Input bounding_boxes) { super((Pointer)null); allocate(scope, image_size, bounding_boxes); }
  private native void allocate(@Const @ByRef Scope scope,
                             @ByVal Input image_size,
                             @ByVal Input bounding_boxes);
  public SampleDistortedBoundingBox(@Const @ByRef Scope scope,
                             @ByVal Input image_size,
                             @ByVal Input bounding_boxes, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, image_size, bounding_boxes, attrs); }
  private native void allocate(@Const @ByRef Scope scope,
                             @ByVal Input image_size,
                             @ByVal Input bounding_boxes, @Const @ByRef Attrs attrs);

  public static native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs MinObjectCovered(float x);
  public static native @ByVal Attrs AspectRatioRange(@ArraySlice FloatPointer x);
  public static native @ByVal Attrs AspectRatioRange(@ArraySlice FloatBuffer x);
  public static native @ByVal Attrs AspectRatioRange(@ArraySlice float... x);
  public static native @ByVal Attrs AreaRange(@ArraySlice FloatPointer x);
  public static native @ByVal Attrs AreaRange(@ArraySlice FloatBuffer x);
  public static native @ByVal Attrs AreaRange(@ArraySlice float... x);
  public static native @ByVal Attrs MaxAttempts(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs UseImageIfNoBoundingBoxes(@Cast("bool") boolean x);

  public native @ByRef Output begin(); public native SampleDistortedBoundingBox begin(Output begin);
  public native @ByRef Output size(); public native SampleDistortedBoundingBox size(Output size);
  public native @ByRef Output bboxes(); public native SampleDistortedBoundingBox bboxes(Output bboxes);
}

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_IMAGE_OPS_H_


// Parsed from tensorflow/cc/ops/io_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_IO_OPS_H_
// #define TENSORFLOW_CC_OPS_IO_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"

// A Reader that outputs fixed-length records from a file.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class FixedLengthRecordReader extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public FixedLengthRecordReader(Pointer p) { super(p); }

  // Optional attribute setters for FixedLengthRecordReader :
  //
  // HeaderBytes(int64): Defaults to 0
  // FooterBytes(int64): Defaults to 0
  // Container(StringPiece): Defaults to ""
  //     If non-empty, this reader is placed in the given container.
  // Otherwise, a default container is used.
  // SharedName(StringPiece): Defaults to ""
  //     If non-empty, this reader is named in the given bucket
  // with this shared_name. Otherwise, the node name is used instead.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs HeaderBytes(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs FooterBytes(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs Container(@StringPiece BytePointer x);
    public native @ByVal Attrs Container(@StringPiece String x);

    public native @ByVal Attrs SharedName(@StringPiece BytePointer x);
    public native @ByVal Attrs SharedName(@StringPiece String x);

    public native @Cast("tensorflow::int64") long header_bytes_(); public native Attrs header_bytes_(long header_bytes_);
    public native @Cast("tensorflow::int64") long footer_bytes_(); public native Attrs footer_bytes_(long footer_bytes_);
    public native @StringPiece BytePointer container_(); public native Attrs container_(BytePointer container_);
    public native @StringPiece BytePointer shared_name_(); public native Attrs shared_name_(BytePointer shared_name_);
  }
  public FixedLengthRecordReader(@Const @ByRef Scope scope, @Cast("tensorflow::int64") long record_bytes) { super((Pointer)null); allocate(scope, record_bytes); }
  private native void allocate(@Const @ByRef Scope scope, @Cast("tensorflow::int64") long record_bytes);
  public FixedLengthRecordReader(@Const @ByRef Scope scope, @Cast("tensorflow::int64") long record_bytes,
                          @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, record_bytes, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @Cast("tensorflow::int64") long record_bytes,
                          @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs HeaderBytes(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs FooterBytes(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs Container(@StringPiece BytePointer x);
  public static native @ByVal Attrs Container(@StringPiece String x);
  public static native @ByVal Attrs SharedName(@StringPiece BytePointer x);
  public static native @ByVal Attrs SharedName(@StringPiece String x);

  public native @ByRef Output reader_handle(); public native FixedLengthRecordReader reader_handle(Output reader_handle);
}

// A Reader that outputs the queued work as both the key and value.
//
// To use, enqueue strings in a Queue.  ReaderRead will take the front
// work string and output (work, work).
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class IdentityReader extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IdentityReader(Pointer p) { super(p); }

  // Optional attribute setters for IdentityReader :
  //
  // Container(StringPiece): Defaults to ""
  //     If non-empty, this reader is placed in the given container.
  // Otherwise, a default container is used.
  // SharedName(StringPiece): Defaults to ""
  //     If non-empty, this reader is named in the given bucket
  // with this shared_name. Otherwise, the node name is used instead.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Container(@StringPiece BytePointer x);
    public native @ByVal Attrs Container(@StringPiece String x);

    public native @ByVal Attrs SharedName(@StringPiece BytePointer x);
    public native @ByVal Attrs SharedName(@StringPiece String x);

    public native @StringPiece BytePointer container_(); public native Attrs container_(BytePointer container_);
    public native @StringPiece BytePointer shared_name_(); public native Attrs shared_name_(BytePointer shared_name_);
  }
  public IdentityReader(@Const @ByRef Scope scope) { super((Pointer)null); allocate(scope); }
  private native void allocate(@Const @ByRef Scope scope);
  public IdentityReader(@Const @ByRef Scope scope, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Container(@StringPiece BytePointer x);
  public static native @ByVal Attrs Container(@StringPiece String x);
  public static native @ByVal Attrs SharedName(@StringPiece BytePointer x);
  public static native @ByVal Attrs SharedName(@StringPiece String x);

  public native @ByRef Output reader_handle(); public native IdentityReader reader_handle(Output reader_handle);
}

// Returns the set of files matching a pattern.
//
// Note that this routine only supports wildcard characters in the
// basename portion of the pattern, not in the directory portion.
//
// Arguments:
// * scope: A Scope object
// * pattern: A (scalar) shell wildcard pattern.
@Namespace("tensorflow::ops") @NoOffset public static class MatchingFiles extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public MatchingFiles(Pointer p) { super(p); }

  public MatchingFiles(@Const @ByRef Scope scope, @ByVal Input pattern) { super((Pointer)null); allocate(scope, pattern); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input pattern);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output filenames(); public native MatchingFiles filenames(Output filenames);
}

// Reads and outputs the entire contents of the input filename.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class ReadFile extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ReadFile(Pointer p) { super(p); }

  public ReadFile(@Const @ByRef Scope scope, @ByVal Input filename) { super((Pointer)null); allocate(scope, filename); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input filename);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output contents(); public native ReadFile contents(Output contents);
}

// Returns the number of records this Reader has produced.
//
// This is the same as the number of ReaderRead executions that have
// succeeded.
//
// Arguments:
// * scope: A Scope object
// * reader_handle: Handle to a Reader.
@Namespace("tensorflow::ops") @NoOffset public static class ReaderNumRecordsProduced extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ReaderNumRecordsProduced(Pointer p) { super(p); }

  public ReaderNumRecordsProduced(@Const @ByRef Scope scope,
                           @ByVal Input reader_handle) { super((Pointer)null); allocate(scope, reader_handle); }
  private native void allocate(@Const @ByRef Scope scope,
                           @ByVal Input reader_handle);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output records_produced(); public native ReaderNumRecordsProduced records_produced(Output records_produced);
}

// Returns the number of work units this Reader has finished processing.
//
// Arguments:
// * scope: A Scope object
// * reader_handle: Handle to a Reader.
@Namespace("tensorflow::ops") @NoOffset public static class ReaderNumWorkUnitsCompleted extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ReaderNumWorkUnitsCompleted(Pointer p) { super(p); }

  public ReaderNumWorkUnitsCompleted(@Const @ByRef Scope scope,
                              @ByVal Input reader_handle) { super((Pointer)null); allocate(scope, reader_handle); }
  private native void allocate(@Const @ByRef Scope scope,
                              @ByVal Input reader_handle);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output units_completed(); public native ReaderNumWorkUnitsCompleted units_completed(Output units_completed);
}

// Returns the next record (key, value pair) produced by a Reader.
//
// Will dequeue from the input queue if necessary (e.g. when the
// Reader needs to start reading from a new file since it has finished
// with the previous file).
//
// Arguments:
// * scope: A Scope object
// * reader_handle: Handle to a Reader.
// * queue_handle: Handle to a Queue, with string work items.
@Namespace("tensorflow::ops") @NoOffset public static class ReaderRead extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ReaderRead(Pointer p) { super(p); }

  public ReaderRead(@Const @ByRef Scope scope, @ByVal Input reader_handle, @ByVal Input queue_handle) { super((Pointer)null); allocate(scope, reader_handle, queue_handle); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input reader_handle, @ByVal Input queue_handle);

  public native @ByRef Output key(); public native ReaderRead key(Output key);
  public native @ByRef Output value(); public native ReaderRead value(Output value);
}

// Returns up to `num_records` (key, value) pairs produced by a Reader.
//
// Will dequeue from the input queue if necessary (e.g. when the
// Reader needs to start reading from a new file since it has finished
// with the previous file).
// It may return less than `num_records` even before the last batch.
//
// Arguments:
// * scope: A Scope object
// * reader_handle: Handle to a `Reader`.
// * queue_handle: Handle to a `Queue`, with string work items.
// * num_records: number of records to read from `Reader`.
@Namespace("tensorflow::ops") @NoOffset public static class ReaderReadUpTo extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ReaderReadUpTo(Pointer p) { super(p); }

  public ReaderReadUpTo(@Const @ByRef Scope scope, @ByVal Input reader_handle, @ByVal Input queue_handle,
                 @ByVal Input num_records) { super((Pointer)null); allocate(scope, reader_handle, queue_handle, num_records); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input reader_handle, @ByVal Input queue_handle,
                 @ByVal Input num_records);

  public native @ByRef Output keys(); public native ReaderReadUpTo keys(Output keys);
  public native @ByRef Output values(); public native ReaderReadUpTo values(Output values);
}

// Restore a Reader to its initial clean state.
//
// Arguments:
// * scope: A Scope object
// * reader_handle: Handle to a Reader.
@Namespace("tensorflow::ops") @NoOffset public static class ReaderReset extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ReaderReset(Pointer p) { super(p); }

  public ReaderReset(@Const @ByRef Scope scope, @ByVal Input reader_handle) { super((Pointer)null); allocate(scope, reader_handle); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input reader_handle);
  public native @ByVal @Name("operator tensorflow::ops::Operation") Operation asOperation();

  public native @ByRef Operation operation(); public native ReaderReset operation(Operation operation);
}

// Restore a reader to a previously saved state.
//
// Not all Readers support being restored, so this can produce an
// Unimplemented error.
//
// Arguments:
// * scope: A Scope object
// * reader_handle: Handle to a Reader.
// * state: Result of a ReaderSerializeState of a Reader with type
// matching reader_handle.
@Namespace("tensorflow::ops") @NoOffset public static class ReaderRestoreState extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ReaderRestoreState(Pointer p) { super(p); }

  public ReaderRestoreState(@Const @ByRef Scope scope, @ByVal Input reader_handle, @ByVal Input state) { super((Pointer)null); allocate(scope, reader_handle, state); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input reader_handle, @ByVal Input state);
  public native @ByVal @Name("operator tensorflow::ops::Operation") Operation asOperation();

  public native @ByRef Operation operation(); public native ReaderRestoreState operation(Operation operation);
}

// Produce a string tensor that encodes the state of a Reader.
//
// Not all Readers support being serialized, so this can produce an
// Unimplemented error.
//
// Arguments:
// * scope: A Scope object
// * reader_handle: Handle to a Reader.
@Namespace("tensorflow::ops") @NoOffset public static class ReaderSerializeState extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ReaderSerializeState(Pointer p) { super(p); }

  public ReaderSerializeState(@Const @ByRef Scope scope, @ByVal Input reader_handle) { super((Pointer)null); allocate(scope, reader_handle); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input reader_handle);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output state(); public native ReaderSerializeState state(Output state);
}

// Restores a tensor from checkpoint files.
//
// Reads a tensor stored in one or several files. If there are several files (for
// instance because a tensor was saved as slices), `file_pattern` may contain
// wildcard symbols (`*` and `?`) in the filename portion only, not in the
// directory portion.
//
// If a `file_pattern` matches several files, `preferred_shard` can be used to hint
// in which file the requested tensor is likely to be found. This op will first
// open the file at index `preferred_shard` in the list of matching files and try
// to restore tensors from that file.  Only if some tensors or tensor slices are
// not found in that first file, then the Op opens all the files. Setting
// `preferred_shard` to match the value passed as the `shard` input
// of a matching `Save` Op may speed up Restore.  This attribute only affects
// performance, not correctness.  The default value -1 means files are processed in
// order.
//
// See also `RestoreSlice`.
//
// Arguments:
// * scope: A Scope object
// * file_pattern: Must have a single element. The pattern of the files from
// which we read the tensor.
// * tensor_name: Must have a single element. The name of the tensor to be
// restored.
// * dt:
//     The type of the tensor to be restored.
@Namespace("tensorflow::ops") @NoOffset public static class Restore extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Restore(Pointer p) { super(p); }

  // Optional attribute setters for Restore :
  //
  // PreferredShard(int64): Defaults to -1
  //     Index of file to open first if multiple files match
  // `file_pattern`.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs PreferredShard(@Cast("tensorflow::int64") long x);

    public native @Cast("tensorflow::int64") long preferred_shard_(); public native Attrs preferred_shard_(long preferred_shard_);
  }
  public Restore(@Const @ByRef Scope scope, @ByVal Input file_pattern, @ByVal Input tensor_name, @Cast("tensorflow::DataType") int dt) { super((Pointer)null); allocate(scope, file_pattern, tensor_name, dt); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input file_pattern, @ByVal Input tensor_name, @Cast("tensorflow::DataType") int dt);
  public Restore(@Const @ByRef Scope scope, @ByVal Input file_pattern, @ByVal Input tensor_name, @Cast("tensorflow::DataType") int dt, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, file_pattern, tensor_name, dt, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input file_pattern, @ByVal Input tensor_name, @Cast("tensorflow::DataType") int dt, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs PreferredShard(@Cast("tensorflow::int64") long x);

  public native @ByRef Output tensor(); public native Restore tensor(Output tensor);
}

// Restores a tensor from checkpoint files.
//
// This is like `Restore` except that restored tensor can be listed as filling
// only a slice of a larger tensor.  `shape_and_slice` specifies the shape of the
// larger tensor and the slice that the restored tensor covers.
//
// The `shape_and_slice` input has the same format as the
// elements of the `shapes_and_slices` input of the `SaveSlices` op.
//
// Arguments:
// * scope: A Scope object
// * file_pattern: Must have a single element. The pattern of the files from
// which we read the tensor.
// * tensor_name: Must have a single element. The name of the tensor to be
// restored.
// * shape_and_slice: Scalar. The shapes and slice specifications to use when
// restoring a tensors.
// * dt:
//     The type of the tensor to be restored.
@Namespace("tensorflow::ops") @NoOffset public static class RestoreSlice extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public RestoreSlice(Pointer p) { super(p); }

  // Optional attribute setters for RestoreSlice :
  //
  // PreferredShard(int64): Defaults to -1
  //     Index of file to open first if multiple files match
  // `file_pattern`. See the documentation for `Restore`.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs PreferredShard(@Cast("tensorflow::int64") long x);

    public native @Cast("tensorflow::int64") long preferred_shard_(); public native Attrs preferred_shard_(long preferred_shard_);
  }
  public RestoreSlice(@Const @ByRef Scope scope, @ByVal Input file_pattern, @ByVal Input tensor_name,
               @ByVal Input shape_and_slice, @Cast("tensorflow::DataType") int dt) { super((Pointer)null); allocate(scope, file_pattern, tensor_name, shape_and_slice, dt); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input file_pattern, @ByVal Input tensor_name,
               @ByVal Input shape_and_slice, @Cast("tensorflow::DataType") int dt);
  public RestoreSlice(@Const @ByRef Scope scope, @ByVal Input file_pattern, @ByVal Input tensor_name,
               @ByVal Input shape_and_slice, @Cast("tensorflow::DataType") int dt, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, file_pattern, tensor_name, shape_and_slice, dt, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input file_pattern, @ByVal Input tensor_name,
               @ByVal Input shape_and_slice, @Cast("tensorflow::DataType") int dt, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs PreferredShard(@Cast("tensorflow::int64") long x);

  public native @ByRef Output tensor(); public native RestoreSlice tensor(Output tensor);
}

// Saves the input tensors to disk.
//
// The size of `tensor_names` must match the number of tensors in `data`. `data[i]`
// is written to `filename` with name `tensor_names[i]`.
//
// See also `SaveSlices`.
//
// Arguments:
// * scope: A Scope object
// * filename: Must have a single element. The name of the file to which we write
// the tensor.
// * tensor_names: Shape `[N]`. The names of the tensors to be saved.
// * data: `N` tensors to save.
@Namespace("tensorflow::ops") @NoOffset public static class Save extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Save(Pointer p) { super(p); }

  public Save(@Const @ByRef Scope scope, @ByVal Input filename,
       @ByVal Input tensor_names, @ByVal InputList data) { super((Pointer)null); allocate(scope, filename, tensor_names, data); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input filename,
       @ByVal Input tensor_names, @ByVal InputList data);
  public native @ByVal @Name("operator tensorflow::ops::Operation") Operation asOperation();

  public native @ByRef Operation operation(); public native Save operation(Operation operation);
}

// Saves input tensors slices to disk.
//
// This is like `Save` except that tensors can be listed in the saved file as being
// a slice of a larger tensor.  `shapes_and_slices` specifies the shape of the
// larger tensor and the slice that this tensor covers. `shapes_and_slices` must
// have as many elements as `tensor_names`.
//
// Elements of the `shapes_and_slices` input must either be:
//
// *  The empty string, in which case the corresponding tensor is
//    saved normally.
// *  A string of the form `dim0 dim1 ... dimN-1 slice-spec` where the
//    `dimI` are the dimensions of the larger tensor and `slice-spec`
//    specifies what part is covered by the tensor to save.
//
// `slice-spec` itself is a `:`-separated list: `slice0:slice1:...:sliceN-1`
// where each `sliceI` is either:
//
// *  The string `-` meaning that the slice covers all indices of this dimension
// *  `start,length` where `start` and `length` are integers.  In that
//    case the slice covers `length` indices starting at `start`.
//
// See also `Save`.
//
// Arguments:
// * scope: A Scope object
// * filename: Must have a single element. The name of the file to which we write the
// tensor.
// * tensor_names: Shape `[N]`. The names of the tensors to be saved.
// * shapes_and_slices: Shape `[N]`.  The shapes and slice specifications to use when
// saving the tensors.
// * data: `N` tensors to save.
@Namespace("tensorflow::ops") @NoOffset public static class SaveSlices extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SaveSlices(Pointer p) { super(p); }

  public SaveSlices(@Const @ByRef Scope scope, @ByVal Input filename,
             @ByVal Input tensor_names, @ByVal Input shapes_and_slices, @ByVal InputList data) { super((Pointer)null); allocate(scope, filename, tensor_names, shapes_and_slices, data); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input filename,
             @ByVal Input tensor_names, @ByVal Input shapes_and_slices, @ByVal InputList data);
  public native @ByVal @Name("operator tensorflow::ops::Operation") Operation asOperation();

  public native @ByRef Operation operation(); public native SaveSlices operation(Operation operation);
}

// Generate a sharded filename. The filename is printf formatted as
//
//    %s-%05d-of-%05d, basename, shard, num_shards.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class ShardedFilename extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ShardedFilename(Pointer p) { super(p); }

  public ShardedFilename(@Const @ByRef Scope scope, @ByVal Input basename, @ByVal Input shard,
                  @ByVal Input num_shards) { super((Pointer)null); allocate(scope, basename, shard, num_shards); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input basename, @ByVal Input shard,
                  @ByVal Input num_shards);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output filename(); public native ShardedFilename filename(Output filename);
}

// Generate a glob pattern matching all sharded file names.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class ShardedFilespec extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ShardedFilespec(Pointer p) { super(p); }

  public ShardedFilespec(@Const @ByRef Scope scope, @ByVal Input basename, @ByVal Input num_shards) { super((Pointer)null); allocate(scope, basename, num_shards); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input basename, @ByVal Input num_shards);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output filename(); public native ShardedFilespec filename(Output filename);
}

// A Reader that outputs the records from a TensorFlow Records file.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class TFRecordReader extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TFRecordReader(Pointer p) { super(p); }

  // Optional attribute setters for TFRecordReader :
  //
  // Container(StringPiece): Defaults to ""
  //     If non-empty, this reader is placed in the given container.
  // Otherwise, a default container is used.
  // SharedName(StringPiece): Defaults to ""
  //     If non-empty, this reader is named in the given bucket
  // with this shared_name. Otherwise, the node name is used instead.
  // CompressionType(StringPiece): Defaults to ""
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Container(@StringPiece BytePointer x);
    public native @ByVal Attrs Container(@StringPiece String x);

    public native @ByVal Attrs SharedName(@StringPiece BytePointer x);
    public native @ByVal Attrs SharedName(@StringPiece String x);

    public native @ByVal Attrs CompressionType(@StringPiece BytePointer x);
    public native @ByVal Attrs CompressionType(@StringPiece String x);

    public native @StringPiece BytePointer container_(); public native Attrs container_(BytePointer container_);
    public native @StringPiece BytePointer shared_name_(); public native Attrs shared_name_(BytePointer shared_name_);
    public native @StringPiece BytePointer compression_type_(); public native Attrs compression_type_(BytePointer compression_type_);
  }
  public TFRecordReader(@Const @ByRef Scope scope) { super((Pointer)null); allocate(scope); }
  private native void allocate(@Const @ByRef Scope scope);
  public TFRecordReader(@Const @ByRef Scope scope, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Container(@StringPiece BytePointer x);
  public static native @ByVal Attrs Container(@StringPiece String x);
  public static native @ByVal Attrs SharedName(@StringPiece BytePointer x);
  public static native @ByVal Attrs SharedName(@StringPiece String x);
  public static native @ByVal Attrs CompressionType(@StringPiece BytePointer x);
  public static native @ByVal Attrs CompressionType(@StringPiece String x);

  public native @ByRef Output reader_handle(); public native TFRecordReader reader_handle(Output reader_handle);
}

// A Reader that outputs the lines of a file delimited by '\n'.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class TextLineReader extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TextLineReader(Pointer p) { super(p); }

  // Optional attribute setters for TextLineReader :
  //
  // SkipHeaderLines(int64): Defaults to 0
  //     Number of lines to skip from the beginning of every file.
  // Container(StringPiece): Defaults to ""
  //     If non-empty, this reader is placed in the given container.
  // Otherwise, a default container is used.
  // SharedName(StringPiece): Defaults to ""
  //     If non-empty, this reader is named in the given bucket
  // with this shared_name. Otherwise, the node name is used instead.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs SkipHeaderLines(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs Container(@StringPiece BytePointer x);
    public native @ByVal Attrs Container(@StringPiece String x);

    public native @ByVal Attrs SharedName(@StringPiece BytePointer x);
    public native @ByVal Attrs SharedName(@StringPiece String x);

    public native @Cast("tensorflow::int64") long skip_header_lines_(); public native Attrs skip_header_lines_(long skip_header_lines_);
    public native @StringPiece BytePointer container_(); public native Attrs container_(BytePointer container_);
    public native @StringPiece BytePointer shared_name_(); public native Attrs shared_name_(BytePointer shared_name_);
  }
  public TextLineReader(@Const @ByRef Scope scope) { super((Pointer)null); allocate(scope); }
  private native void allocate(@Const @ByRef Scope scope);
  public TextLineReader(@Const @ByRef Scope scope, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs SkipHeaderLines(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs Container(@StringPiece BytePointer x);
  public static native @ByVal Attrs Container(@StringPiece String x);
  public static native @ByVal Attrs SharedName(@StringPiece BytePointer x);
  public static native @ByVal Attrs SharedName(@StringPiece String x);

  public native @ByRef Output reader_handle(); public native TextLineReader reader_handle(Output reader_handle);
}

// A Reader that outputs the entire contents of a file as a value.
//
// To use, enqueue filenames in a Queue.  The output of ReaderRead will
// be a filename (key) and the contents of that file (value).
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class WholeFileReader extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public WholeFileReader(Pointer p) { super(p); }

  // Optional attribute setters for WholeFileReader :
  //
  // Container(StringPiece): Defaults to ""
  //     If non-empty, this reader is placed in the given container.
  // Otherwise, a default container is used.
  // SharedName(StringPiece): Defaults to ""
  //     If non-empty, this reader is named in the given bucket
  // with this shared_name. Otherwise, the node name is used instead.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Container(@StringPiece BytePointer x);
    public native @ByVal Attrs Container(@StringPiece String x);

    public native @ByVal Attrs SharedName(@StringPiece BytePointer x);
    public native @ByVal Attrs SharedName(@StringPiece String x);

    public native @StringPiece BytePointer container_(); public native Attrs container_(BytePointer container_);
    public native @StringPiece BytePointer shared_name_(); public native Attrs shared_name_(BytePointer shared_name_);
  }
  public WholeFileReader(@Const @ByRef Scope scope) { super((Pointer)null); allocate(scope); }
  private native void allocate(@Const @ByRef Scope scope);
  public WholeFileReader(@Const @ByRef Scope scope, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Container(@StringPiece BytePointer x);
  public static native @ByVal Attrs Container(@StringPiece String x);
  public static native @ByVal Attrs SharedName(@StringPiece BytePointer x);
  public static native @ByVal Attrs SharedName(@StringPiece String x);

  public native @ByRef Output reader_handle(); public native WholeFileReader reader_handle(Output reader_handle);
}

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_IO_OPS_H_


// Parsed from tensorflow/cc/ops/linalg_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_LINALG_OPS_H_
// #define TENSORFLOW_CC_OPS_LINALG_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"

// TODO: add doc.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class BatchCholesky extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public BatchCholesky(Pointer p) { super(p); }

  public BatchCholesky(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native BatchCholesky output(Output output);
}

// TODO: add doc.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class BatchCholeskyGrad extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public BatchCholeskyGrad(Pointer p) { super(p); }

  public BatchCholeskyGrad(@Const @ByRef Scope scope, @ByVal Input l,
                    @ByVal Input grad) { super((Pointer)null); allocate(scope, l, grad); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input l,
                    @ByVal Input grad);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native BatchCholeskyGrad output(Output output);
}

// TODO: add doc.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class BatchMatrixDeterminant extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public BatchMatrixDeterminant(Pointer p) { super(p); }

  public BatchMatrixDeterminant(@Const @ByRef Scope scope,
                         @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope,
                         @ByVal Input input);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native BatchMatrixDeterminant output(Output output);
}

// TODO: add doc.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class BatchMatrixInverse extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public BatchMatrixInverse(Pointer p) { super(p); }

  // Optional attribute setters for BatchMatrixInverse :
  //
  // Adjoint(bool): Defaults to false
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Adjoint(@Cast("bool") boolean x);

    public native @Cast("bool") boolean adjoint_(); public native Attrs adjoint_(boolean adjoint_);
  }
  public BatchMatrixInverse(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public BatchMatrixInverse(@Const @ByRef Scope scope, @ByVal Input input, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Adjoint(@Cast("bool") boolean x);

  public native @ByRef Output output(); public native BatchMatrixInverse output(Output output);
}

// TODO: add doc.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class BatchMatrixSolve extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public BatchMatrixSolve(Pointer p) { super(p); }

  // Optional attribute setters for BatchMatrixSolve :
  //
  // Adjoint(bool): Defaults to false
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Adjoint(@Cast("bool") boolean x);

    public native @Cast("bool") boolean adjoint_(); public native Attrs adjoint_(boolean adjoint_);
  }
  public BatchMatrixSolve(@Const @ByRef Scope scope, @ByVal Input matrix, @ByVal Input rhs) { super((Pointer)null); allocate(scope, matrix, rhs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input matrix, @ByVal Input rhs);
  public BatchMatrixSolve(@Const @ByRef Scope scope, @ByVal Input matrix, @ByVal Input rhs, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, matrix, rhs, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input matrix, @ByVal Input rhs, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Adjoint(@Cast("bool") boolean x);

  public native @ByRef Output output(); public native BatchMatrixSolve output(Output output);
}

// TODO: add doc.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class BatchMatrixSolveLs extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public BatchMatrixSolveLs(Pointer p) { super(p); }

  // Optional attribute setters for BatchMatrixSolveLs :
  //
  // Fast(bool): Defaults to true
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Fast(@Cast("bool") boolean x);

    public native @Cast("bool") boolean fast_(); public native Attrs fast_(boolean fast_);
  }
  public BatchMatrixSolveLs(@Const @ByRef Scope scope, @ByVal Input matrix, @ByVal Input rhs,
                     @ByVal Input l2_regularizer) { super((Pointer)null); allocate(scope, matrix, rhs, l2_regularizer); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input matrix, @ByVal Input rhs,
                     @ByVal Input l2_regularizer);
  public BatchMatrixSolveLs(@Const @ByRef Scope scope, @ByVal Input matrix, @ByVal Input rhs,
                     @ByVal Input l2_regularizer, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, matrix, rhs, l2_regularizer, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input matrix, @ByVal Input rhs,
                     @ByVal Input l2_regularizer, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Fast(@Cast("bool") boolean x);

  public native @ByRef Output output(); public native BatchMatrixSolveLs output(Output output);
}

// TODO: add doc.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class BatchMatrixTriangularSolve extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public BatchMatrixTriangularSolve(Pointer p) { super(p); }

  // Optional attribute setters for BatchMatrixTriangularSolve :
  //
  // Lower(bool): Defaults to true
  // Adjoint(bool): Defaults to false
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Lower(@Cast("bool") boolean x);

    public native @ByVal Attrs Adjoint(@Cast("bool") boolean x);

    public native @Cast("bool") boolean lower_(); public native Attrs lower_(boolean lower_);
    public native @Cast("bool") boolean adjoint_(); public native Attrs adjoint_(boolean adjoint_);
  }
  public BatchMatrixTriangularSolve(@Const @ByRef Scope scope,
                             @ByVal Input matrix,
                             @ByVal Input rhs) { super((Pointer)null); allocate(scope, matrix, rhs); }
  private native void allocate(@Const @ByRef Scope scope,
                             @ByVal Input matrix,
                             @ByVal Input rhs);
  public BatchMatrixTriangularSolve(@Const @ByRef Scope scope,
                             @ByVal Input matrix,
                             @ByVal Input rhs, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, matrix, rhs, attrs); }
  private native void allocate(@Const @ByRef Scope scope,
                             @ByVal Input matrix,
                             @ByVal Input rhs, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Lower(@Cast("bool") boolean x);
  public static native @ByVal Attrs Adjoint(@Cast("bool") boolean x);

  public native @ByRef Output output(); public native BatchMatrixTriangularSolve output(Output output);
}

// TODO: add doc.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class BatchSelfAdjointEig extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public BatchSelfAdjointEig(Pointer p) { super(p); }

  public BatchSelfAdjointEig(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native BatchSelfAdjointEig output(Output output);
}

// TODO: add doc.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class BatchSelfAdjointEigV2 extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public BatchSelfAdjointEigV2(Pointer p) { super(p); }

  // Optional attribute setters for BatchSelfAdjointEigV2 :
  //
  // ComputeV(bool): Defaults to true
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs ComputeV(@Cast("bool") boolean x);

    public native @Cast("bool") boolean compute_v_(); public native Attrs compute_v_(boolean compute_v_);
  }
  public BatchSelfAdjointEigV2(@Const @ByRef Scope scope,
                        @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope,
                        @ByVal Input input);
  public BatchSelfAdjointEigV2(@Const @ByRef Scope scope,
                        @ByVal Input input, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, attrs); }
  private native void allocate(@Const @ByRef Scope scope,
                        @ByVal Input input, @Const @ByRef Attrs attrs);

  public static native @ByVal Attrs ComputeV(@Cast("bool") boolean x);

  public native @ByRef Output e(); public native BatchSelfAdjointEigV2 e(Output e);
  public native @ByRef Output v(); public native BatchSelfAdjointEigV2 v(Output v);
}

// TODO: add doc.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class BatchSvd extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public BatchSvd(Pointer p) { super(p); }

  // Optional attribute setters for BatchSvd :
  //
  // ComputeUv(bool): Defaults to true
  // FullMatrices(bool): Defaults to false
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs ComputeUv(@Cast("bool") boolean x);

    public native @ByVal Attrs FullMatrices(@Cast("bool") boolean x);

    public native @Cast("bool") boolean compute_uv_(); public native Attrs compute_uv_(boolean compute_uv_);
    public native @Cast("bool") boolean full_matrices_(); public native Attrs full_matrices_(boolean full_matrices_);
  }
  public BatchSvd(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public BatchSvd(@Const @ByRef Scope scope, @ByVal Input input,
           @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
           @Const @ByRef Attrs attrs);

  public static native @ByVal Attrs ComputeUv(@Cast("bool") boolean x);
  public static native @ByVal Attrs FullMatrices(@Cast("bool") boolean x);

  public native @ByRef Output s(); public native BatchSvd s(Output s);
  public native @ByRef Output u(); public native BatchSvd u(Output u);
  public native @ByRef Output v(); public native BatchSvd v(Output v);
}

// Computes the Cholesky decomposition of one or more square matrices.
//
// The input is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions
// form square matrices, with the same constraints as the single matrix Cholesky
// decomposition above. The output is a tensor of the same shape as the input
// containing the Cholesky decompositions for all input submatrices `[..., :, :]`.
//
// Arguments:
// * scope: A Scope object
// * input: Shape is `[..., M, M]`.
@Namespace("tensorflow::ops") @NoOffset public static class Cholesky extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Cholesky(Pointer p) { super(p); }

  public Cholesky(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native Cholesky output(Output output);
}

// Computes the reverse mode backpropagated gradient of the Cholesky algorithm.
//
// For an explanation see "Differentiation of the Cholesky algorithm" by
// Iain Murray http://arxiv.org/abs/1602.07527.
//
// Arguments:
// * scope: A Scope object
// * l: Output of batch Cholesky algorithm l = cholesky(A). Shape is `[..., M, M]`.
// Algorithm depends only on lower triangular part of the innermost matrices of
// this tensor.
// * grad: df/dl where f is some scalar function. Shape is `[..., M, M]`.
// Algorithm depends only on lower triangular part of the innermost matrices of
// this tensor.
@Namespace("tensorflow::ops") @NoOffset public static class CholeskyGrad extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public CholeskyGrad(Pointer p) { super(p); }

  public CholeskyGrad(@Const @ByRef Scope scope, @ByVal Input l,
               @ByVal Input grad) { super((Pointer)null); allocate(scope, l, grad); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input l,
               @ByVal Input grad);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native CholeskyGrad output(Output output);
}

// Computes the determinant of one ore more square matrices.
//
// The input is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions
// form square matrices. The output is a tensor containing the determinants
// for all input submatrices `[..., :, :]`.
//
// Arguments:
// * scope: A Scope object
// * input: Shape is `[..., M, M]`.
@Namespace("tensorflow::ops") @NoOffset public static class MatrixDeterminant extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public MatrixDeterminant(Pointer p) { super(p); }

  public MatrixDeterminant(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native MatrixDeterminant output(Output output);
}

// Computes the inverse of one or more square invertible matrices or their
//
// adjoints (conjugate transposes).
//
// The input is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions
// form square matrices. The output is a tensor of the same shape as the input
// containing the inverse for all input submatrices `[..., :, :]`.
//
// The op uses LU decomposition with partial pivoting to compute the inverses.
//
// If a matrix is not invertible there is no guarantee what the op does. It
// may detect the condition and raise an exception or it may simply return a
// garbage result.
//
// Arguments:
// * scope: A Scope object
// * input: Shape is `[..., M, M]`.
@Namespace("tensorflow::ops") @NoOffset public static class MatrixInverse extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public MatrixInverse(Pointer p) { super(p); }

  // Optional attribute setters for MatrixInverse :
  //
  // Adjoint(bool): Defaults to false
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Adjoint(@Cast("bool") boolean x);

    public native @Cast("bool") boolean adjoint_(); public native Attrs adjoint_(boolean adjoint_);
  }
  public MatrixInverse(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public MatrixInverse(@Const @ByRef Scope scope, @ByVal Input input,
                @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
                @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Adjoint(@Cast("bool") boolean x);

  public native @ByRef Output output(); public native MatrixInverse output(Output output);
}

// Solves systems of linear equations.
//
// `Matrix` is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions
// form square matrices. `Rhs` is a tensor of shape `[..., M, K]`. The `output` is
// a tensor shape `[..., M, K]`.  If `adjoint` is `False` then each output matrix
// satisfies `matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]`.
// If `adjoint` is `True` then each output matrix satisfies
// `adjoint(matrix[..., :, :]) * output[..., :, :] = rhs[..., :, :]`.
//
// Arguments:
// * scope: A Scope object
// * matrix: Shape is `[..., M, M]`.
// * rhs: Shape is `[..., M, K]`.
@Namespace("tensorflow::ops") @NoOffset public static class MatrixSolve extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public MatrixSolve(Pointer p) { super(p); }

  // Optional attribute setters for MatrixSolve :
  //
  // Adjoint(bool): Defaults to false
  //     Boolean indicating whether to solve with `matrix` or its (block-wise)
  // adjoint.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Adjoint(@Cast("bool") boolean x);

    public native @Cast("bool") boolean adjoint_(); public native Attrs adjoint_(boolean adjoint_);
  }
  public MatrixSolve(@Const @ByRef Scope scope, @ByVal Input matrix,
              @ByVal Input rhs) { super((Pointer)null); allocate(scope, matrix, rhs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input matrix,
              @ByVal Input rhs);
  public MatrixSolve(@Const @ByRef Scope scope, @ByVal Input matrix,
              @ByVal Input rhs, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, matrix, rhs, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input matrix,
              @ByVal Input rhs, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Adjoint(@Cast("bool") boolean x);

  public native @ByRef Output output(); public native MatrixSolve output(Output output);
}

// Solves one or more linear least-squares problems.
//
// `matrix` is a tensor of shape `[..., M, N]` whose inner-most 2 dimensions
// form matrices of size `[M, N]`. Rhs is a tensor of shape `[..., M, K]`.
// The output is a tensor shape `[..., N, K]` where each output matrix solves
// each of the equations matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]
// in the least squares sense.
//
// matrix and right-hand sides in the batch:
//
// `matrix`=\\(A \in \Re^{m \times n}\\),
// `rhs`=\\(B  \in \Re^{m \times k}\\),
// `output`=\\(X  \in \Re^{n \times k}\\),
// `l2_regularizer`=\\(\lambda\\).
//
// If `fast` is `True`, then the solution is computed by solving the normal
// equations using Cholesky decomposition. Specifically, if \\(m \ge n\\) then
// \\(X = (A^T A + \lambda I)^{-1} A^T B\\), which solves the least-squares
// problem \\(X = \mathrm{argmin}_{Z \in \Re^{n \times k}} ||A Z - B||_F^2 +
// \lambda ||Z||_F^2\\). If \\(m \lt n\\) then `output` is computed as
// \\(X = A^T (A A^T + \lambda I)^{-1} B\\), which (for \\(\lambda = 0\\)) is the
// minimum-norm solution to the under-determined linear system, i.e.
// \\(X = \mathrm{argmin}_{Z \in \Re^{n \times k}} ||Z||_F^2 \\), subject to
// \\(A Z = B\\). Notice that the fast path is only numerically stable when
// \\(A\\) is numerically full rank and has a condition number
// \\(\mathrm{cond}(A) \lt \frac{1}{\sqrt{\epsilon_{mach}}}\\) or\\(\lambda\\) is
// sufficiently large.
//
// If `fast` is `False` an algorithm based on the numerically robust complete
// orthogonal decomposition is used. This computes the minimum-norm
// least-squares solution, even when \\(A\\) is rank deficient. This path is
// typically 6-7 times slower than the fast path. If `fast` is `False` then
// `l2_regularizer` is ignored.
//
// Arguments:
// * scope: A Scope object
// * matrix: Shape is `[..., M, N]`.
// * rhs: Shape is `[..., M, K]`.
// * l2_regularizer: Scalar tensor.
@Namespace("tensorflow::ops") @NoOffset public static class MatrixSolveLs extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public MatrixSolveLs(Pointer p) { super(p); }

  // Optional attribute setters for MatrixSolveLs :
  //
  // Fast(bool): Defaults to true
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Fast(@Cast("bool") boolean x);

    public native @Cast("bool") boolean fast_(); public native Attrs fast_(boolean fast_);
  }
  public MatrixSolveLs(@Const @ByRef Scope scope, @ByVal Input matrix, @ByVal Input rhs, @ByVal Input l2_regularizer) { super((Pointer)null); allocate(scope, matrix, rhs, l2_regularizer); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input matrix, @ByVal Input rhs, @ByVal Input l2_regularizer);
  public MatrixSolveLs(@Const @ByRef Scope scope, @ByVal Input matrix, @ByVal Input rhs, @ByVal Input l2_regularizer, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, matrix, rhs, l2_regularizer, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input matrix, @ByVal Input rhs, @ByVal Input l2_regularizer, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Fast(@Cast("bool") boolean x);

  public native @ByRef Output output(); public native MatrixSolveLs output(Output output);
}

// Solves systems of linear equations with upper or lower triangular matrices by
//
// backsubstitution.
//
// `matrix` is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions form
// square matrices. If `lower` is `True` then the strictly upper triangular part
// of each inner-most matrix is assumed to be zero and not accessed.
// If `lower` is False then the strictly lower triangular part of each inner-most
// matrix is assumed to be zero and not accessed.
// `rhs` is a tensor of shape `[..., M, K]`.
//
// The output is a tensor of shape `[..., M, K]`. If `adjoint` is
// `True` then the innermost matrices in output` satisfy matrix equations
// `matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]`.
// If `adjoint` is `False` then the strictly then the  innermost matrices in
// `output` satisfy matrix equations
// `adjoint(matrix[..., i, k]) * output[..., k, j] = rhs[..., i, j]`.
//
// Arguments:
// * scope: A Scope object
// * matrix: Shape is `[..., M, M]`.
// * rhs: Shape is `[..., M, K]`.
@Namespace("tensorflow::ops") @NoOffset public static class MatrixTriangularSolve extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public MatrixTriangularSolve(Pointer p) { super(p); }

  // Optional attribute setters for MatrixTriangularSolve :
  //
  // Lower(bool): Defaults to true
  //     Boolean indicating whether the innermost matrices in `matrix` are
  // lower or upper triangular.
  // Adjoint(bool): Defaults to false
  //     Boolean indicating whether to solve with `matrix` or its (block-wise)
  // adjoint.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Lower(@Cast("bool") boolean x);

    public native @ByVal Attrs Adjoint(@Cast("bool") boolean x);

    public native @Cast("bool") boolean lower_(); public native Attrs lower_(boolean lower_);
    public native @Cast("bool") boolean adjoint_(); public native Attrs adjoint_(boolean adjoint_);
  }
  public MatrixTriangularSolve(@Const @ByRef Scope scope,
                        @ByVal Input matrix, @ByVal Input rhs) { super((Pointer)null); allocate(scope, matrix, rhs); }
  private native void allocate(@Const @ByRef Scope scope,
                        @ByVal Input matrix, @ByVal Input rhs);
  public MatrixTriangularSolve(@Const @ByRef Scope scope,
                        @ByVal Input matrix, @ByVal Input rhs, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, matrix, rhs, attrs); }
  private native void allocate(@Const @ByRef Scope scope,
                        @ByVal Input matrix, @ByVal Input rhs, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Lower(@Cast("bool") boolean x);
  public static native @ByVal Attrs Adjoint(@Cast("bool") boolean x);

  public native @ByRef Output output(); public native MatrixTriangularSolve output(Output output);
}

// Computes the Eigen Decomposition of a batch of square self-adjoint matrices.
//
// DEPRECATED at GraphDef version 11:
// Use SelfAdjointEigV2 instead..
//
// The input is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions
// form square matrices, with the same constraints as the single matrix
// SelfAdjointEig.
//
// The result is a [..., M+1, M] matrix with [..., 0,:] containing the
// eigenvalues, and subsequent [...,1:, :] containing the eigenvectors.
//
// Arguments:
// * scope: A Scope object
// * input: Shape is `[..., M, M]`.
@Namespace("tensorflow::ops") @NoOffset public static class SelfAdjointEig extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SelfAdjointEig(Pointer p) { super(p); }

  public SelfAdjointEig(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native SelfAdjointEig output(Output output);
}

// Computes the eigen decomposition of one or more square self-adjoint matrices.
//
// Computes the eigenvalues and (optionally) eigenvectors of each inner matrix in
// `input` such that `input[..., :, :] = v[..., :, :] * diag(e[..., :])`.
//
// ```prettyprint
// # a is a tensor.
// # e is a tensor of eigenvalues.
// # v is a tensor of eigenvectors.
// e, v = self_adjoint_eig(a)
// e = self_adjoint_eig(a, compute_v=False)
// ```
//
// Arguments:
// * scope: A Scope object
// * input: `Tensor` input of shape `[N, N]`.
@Namespace("tensorflow::ops") @NoOffset public static class SelfAdjointEigV2 extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SelfAdjointEigV2(Pointer p) { super(p); }

  // Optional attribute setters for SelfAdjointEigV2 :
  //
  // ComputeV(bool): Defaults to true
  //     If `True` then eigenvectors will be computed and returned in `v`.
  // Otherwise, only the eigenvalues will be computed.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs ComputeV(@Cast("bool") boolean x);

    public native @Cast("bool") boolean compute_v_(); public native Attrs compute_v_(boolean compute_v_);
  }
  public SelfAdjointEigV2(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public SelfAdjointEigV2(@Const @ByRef Scope scope, @ByVal Input input, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @Const @ByRef Attrs attrs);

  public static native @ByVal Attrs ComputeV(@Cast("bool") boolean x);

  public native @ByRef Output e(); public native SelfAdjointEigV2 e(Output e);
  public native @ByRef Output v(); public native SelfAdjointEigV2 v(Output v);
}

// Computes the singular value decompositions of one or more matrices.
//
// Computes the SVD of each inner matrix in `input` such that
// `input[..., :, :] = u[..., :, :] * diag(s[..., :, :]) * transpose(v[..., :, :])`
//
// ```prettyprint
// # a is a tensor containing a batch of matrices.
// # s is a tensor of singular values for each matrix.
// # u is the tensor containing of left singular vectors for each matrix.
// # v is the tensor containing of right singular vectors for each matrix.
// s, u, v = svd(a)
// s, _, _ = svd(a, compute_uv=False)
// ```
//
// Arguments:
// * scope: A Scope object
// * input: A tensor of shape `[..., M, N]` whose inner-most 2 dimensions
// form matrices of size `[M, N]`. Let `P` be the minimum of `M` and `N`.
@Namespace("tensorflow::ops") @NoOffset public static class Svd extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Svd(Pointer p) { super(p); }

  // Optional attribute setters for Svd :
  //
  // ComputeUv(bool): Defaults to true
  //     If true, left and right singular vectors will be
  // computed and returned in `u` and `v`, respectively.
  // If false, `u` and `v` are not set and should never referenced.
  // FullMatrices(bool): Defaults to false
  //     If true, compute full-sized `u` and `v`. If false
  // (the default), compute only the leading `P` singular vectors.
  // Ignored if `compute_uv` is `False`.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs ComputeUv(@Cast("bool") boolean x);

    public native @ByVal Attrs FullMatrices(@Cast("bool") boolean x);

    public native @Cast("bool") boolean compute_uv_(); public native Attrs compute_uv_(boolean compute_uv_);
    public native @Cast("bool") boolean full_matrices_(); public native Attrs full_matrices_(boolean full_matrices_);
  }
  public Svd(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public Svd(@Const @ByRef Scope scope, @ByVal Input input, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @Const @ByRef Attrs attrs);

  public static native @ByVal Attrs ComputeUv(@Cast("bool") boolean x);
  public static native @ByVal Attrs FullMatrices(@Cast("bool") boolean x);

  public native @ByRef Output s(); public native Svd s(Output s);
  public native @ByRef Output u(); public native Svd u(Output u);
  public native @ByRef Output v(); public native Svd v(Output v);
}

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_LINALG_OPS_H_


// Parsed from tensorflow/cc/ops/logging_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_LOGGING_OPS_H_
// #define TENSORFLOW_CC_OPS_LOGGING_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"

// Asserts that the given condition is true.
//
// If `condition` evaluates to false, print the list of tensors in `data`.
// `summarize` determines how many entries of the tensors to print.
//
// Arguments:
// * scope: A Scope object
// * condition: The condition to evaluate.
// * data: The tensors to print out when condition is false.
@Namespace("tensorflow::ops") @NoOffset public static class Assert extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Assert(Pointer p) { super(p); }

  // Optional attribute setters for Assert :
  //
  // Summarize(int64): Defaults to 3
  //     Print this many entries of each tensor.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Summarize(@Cast("tensorflow::int64") long x);

    public native @Cast("tensorflow::int64") long summarize_(); public native Attrs summarize_(long summarize_);
  }
  public Assert(@Const @ByRef Scope scope, @ByVal Input condition,
         @ByVal InputList data) { super((Pointer)null); allocate(scope, condition, data); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input condition,
         @ByVal InputList data);
  public Assert(@Const @ByRef Scope scope, @ByVal Input condition,
         @ByVal InputList data, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, condition, data, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input condition,
         @ByVal InputList data, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Operation") Operation asOperation();

  public static native @ByVal Attrs Summarize(@Cast("tensorflow::int64") long x);

  public native @ByRef Operation operation(); public native Assert operation(Operation operation);
}

// Outputs a `Summary` protocol buffer with audio.
//
// The summary has up to `max_outputs` summary values containing audio. The
// audio is built from `tensor` which must be 3-D with shape `[batch_size,
// frames, channels]` or 2-D with shape `[batch_size, frames]`. The values are
// assumed to be in the range of `[-1.0, 1.0]` with a sample rate of `sample_rate`.
//
// The `tag` argument is a scalar `Tensor` of type `string`.  It is used to
// build the `tag` of the summary values:
//
// *  If `max_outputs` is 1, the summary value tag is '*tag*/audio'.
// *  If `max_outputs` is greater than 1, the summary value tags are
//    generated sequentially as '*tag*/audio/0', '*tag*/audio/1', etc.
//
// Arguments:
// * scope: A Scope object
// * tag: Scalar. Used to build the `tag` attribute of the summary values.
// * tensor: 2-D of shape `[batch_size, frames]`.
// * sample_rate:
//     The sample rate of the signal in hertz.
@Namespace("tensorflow::ops") @NoOffset public static class AudioSummary extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public AudioSummary(Pointer p) { super(p); }

  // Optional attribute setters for AudioSummary :
  //
  // MaxOutputs(int64): Defaults to 3
  //     Max number of batch elements to generate audio for.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs MaxOutputs(@Cast("tensorflow::int64") long x);

    public native @Cast("tensorflow::int64") long max_outputs_(); public native Attrs max_outputs_(long max_outputs_);
  }
  public AudioSummary(@Const @ByRef Scope scope, @ByVal Input tag,
               @ByVal Input tensor, float sample_rate) { super((Pointer)null); allocate(scope, tag, tensor, sample_rate); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input tag,
               @ByVal Input tensor, float sample_rate);
  public AudioSummary(@Const @ByRef Scope scope, @ByVal Input tag,
               @ByVal Input tensor, float sample_rate, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, tag, tensor, sample_rate, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input tag,
               @ByVal Input tensor, float sample_rate, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs MaxOutputs(@Cast("tensorflow::int64") long x);

  public native @ByRef Output summary(); public native AudioSummary summary(Output summary);
}

// Outputs a `Summary` protocol buffer with a histogram.
//
// The generated
// [`Summary`](https://www.tensorflow.org/code/tensorflow/core/framework/summary.proto)
// has one summary value containing a histogram for `values`.
//
// This op reports an `InvalidArgument` error if any value is not finite.
//
// Arguments:
// * scope: A Scope object
// * tag: Scalar.  Tag to use for the `Summary.Value`.
// * values: Any shape. Values to use to build the histogram.
@Namespace("tensorflow::ops") @NoOffset public static class HistogramSummary extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public HistogramSummary(Pointer p) { super(p); }

  public HistogramSummary(@Const @ByRef Scope scope, @ByVal Input tag, @ByVal Input values) { super((Pointer)null); allocate(scope, tag, values); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input tag, @ByVal Input values);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output summary(); public native HistogramSummary summary(Output summary);
}

// Outputs a `Summary` protocol buffer with images.
//
// The summary has up to `max_images` summary values containing images. The
// images are built from `tensor` which must be 4-D with shape `[batch_size,
// height, width, channels]` and where `channels` can be:
//
// *  1: `tensor` is interpreted as Grayscale.
// *  3: `tensor` is interpreted as RGB.
// *  4: `tensor` is interpreted as RGBA.
//
// The images have the same number of channels as the input tensor. For float
// input, the values are normalized one image at a time to fit in the range
// `[0, 255]`.  `uint8` values are unchanged.  The op uses two different
// normalization algorithms:
//
// *  If the input values are all positive, they are rescaled so the largest one
//    is 255.
//
// *  If any input value is negative, the values are shifted so input value 0.0
//    is at 127.  They are then rescaled so that either the smallest value is 0,
//    or the largest one is 255.
//
// The `tag` argument is a scalar `Tensor` of type `string`.  It is used to
// build the `tag` of the summary values:
//
// *  If `max_images` is 1, the summary value tag is '*tag*/image'.
// *  If `max_images` is greater than 1, the summary value tags are
//    generated sequentially as '*tag*/image/0', '*tag*/image/1', etc.
//
// The `bad_color` argument is the color to use in the generated images for
// non-finite input values.  It is a `unit8` 1-D tensor of length `channels`.
// Each element must be in the range `[0, 255]` (It represents the value of a
// pixel in the output image).  Non-finite values in the input tensor are
// replaced by this tensor in the output image.  The default value is the color
// red.
//
// Arguments:
// * scope: A Scope object
// * tag: Scalar. Used to build the `tag` attribute of the summary values.
// * tensor: 4-D of shape `[batch_size, height, width, channels]` where
// `channels` is 1, 3, or 4.
@Namespace("tensorflow::ops") @NoOffset public static class ImageSummary extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ImageSummary(Pointer p) { super(p); }

  // Optional attribute setters for ImageSummary :
  //
  // MaxImages(int64): Defaults to 3
  //     Max number of batch elements to generate images for.
  // BadColor(const TensorProto&): Defaults to Tensor<type: uint8 shape: [4] values: 255 0 0...>
  //     Color to use for pixels with non-finite values.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs MaxImages(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs BadColor(@Const @ByRef TensorProto x);

    public native @Cast("tensorflow::int64") long max_images_(); public native Attrs max_images_(long max_images_);
    public native @ByRef TensorProto bad_color_(); public native Attrs bad_color_(TensorProto bad_color_);
  }
  public ImageSummary(@Const @ByRef Scope scope, @ByVal Input tag,
               @ByVal Input tensor) { super((Pointer)null); allocate(scope, tag, tensor); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input tag,
               @ByVal Input tensor);
  public ImageSummary(@Const @ByRef Scope scope, @ByVal Input tag,
               @ByVal Input tensor, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, tag, tensor, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input tag,
               @ByVal Input tensor, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs MaxImages(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs BadColor(@Const @ByRef TensorProto x);

  public native @ByRef Output summary(); public native ImageSummary summary(Output summary);
}

// Merges summaries.
//
// This op creates a
// [`Summary`](https://www.tensorflow.org/code/tensorflow/core/framework/summary.proto)
// protocol buffer that contains the union of all the values in the input
// summaries.
//
// When the Op is run, it reports an `InvalidArgument` error if multiple values
// in the summaries to merge use the same tag.
//
// Arguments:
// * scope: A Scope object
// * inputs: Can be of any shape.  Each must contain serialized `Summary` protocol
// buffers.
@Namespace("tensorflow::ops") @NoOffset public static class MergeSummary extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public MergeSummary(Pointer p) { super(p); }

  public MergeSummary(@Const @ByRef Scope scope, @ByVal InputList inputs) { super((Pointer)null); allocate(scope, inputs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal InputList inputs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output summary(); public native MergeSummary summary(Output summary);
}

// Prints a list of tensors.
//
// Passes `input` through to `output` and prints `data` when evaluating.
//
// Arguments:
// * scope: A Scope object
// * input: The tensor passed to `output`
// * data: A list of tensors to print out when op is evaluated.
@Namespace("tensorflow::ops") @NoOffset public static class Print extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Print(Pointer p) { super(p); }

  // Optional attribute setters for Print :
  //
  // Message(StringPiece): Defaults to ""
  //     A string, prefix of the error message.
  // FirstN(int64): Defaults to -1
  //     Only log `first_n` number of times. -1 disables logging.
  // Summarize(int64): Defaults to 3
  //     Only print this many entries of each tensor.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Message(@StringPiece BytePointer x);
    public native @ByVal Attrs Message(@StringPiece String x);

    public native @ByVal Attrs FirstN(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs Summarize(@Cast("tensorflow::int64") long x);

    public native @StringPiece BytePointer message_(); public native Attrs message_(BytePointer message_);
    public native @Cast("tensorflow::int64") long first_n_(); public native Attrs first_n_(long first_n_);
    public native @Cast("tensorflow::int64") long summarize_(); public native Attrs summarize_(long summarize_);
  }
  public Print(@Const @ByRef Scope scope, @ByVal Input input,
        @ByVal InputList data) { super((Pointer)null); allocate(scope, input, data); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
        @ByVal InputList data);
  public Print(@Const @ByRef Scope scope, @ByVal Input input,
        @ByVal InputList data, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, data, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
        @ByVal InputList data, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Message(@StringPiece BytePointer x);
  public static native @ByVal Attrs Message(@StringPiece String x);
  public static native @ByVal Attrs FirstN(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs Summarize(@Cast("tensorflow::int64") long x);

  public native @ByRef Output output(); public native Print output(Output output);
}

// Outputs a `Summary` protocol buffer with scalar values.
//
// The input `tags` and `values` must have the same shape.  The generated summary
// has a summary value for each tag-value pair in `tags` and `values`.
//
// Arguments:
// * scope: A Scope object
// * tags: Tags for the summary.
// * values: Same shape as `tags.  Values for the summary.
@Namespace("tensorflow::ops") @NoOffset public static class ScalarSummary extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ScalarSummary(Pointer p) { super(p); }

  public ScalarSummary(@Const @ByRef Scope scope, @ByVal Input tags,
                @ByVal Input values) { super((Pointer)null); allocate(scope, tags, values); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input tags,
                @ByVal Input values);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output summary(); public native ScalarSummary summary(Output summary);
}

// Outputs a `Summary` protocol buffer with a tensor.
//
// Arguments:
// * scope: A Scope object
// * tensor: A tensor to serialize.
// * display_name:
//     A name to associate with the data series.
@Namespace("tensorflow::ops") @NoOffset public static class TensorSummary extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TensorSummary(Pointer p) { super(p); }

  // Optional attribute setters for TensorSummary :
  //
  // Description(StringPiece): Defaults to ""
  //     An optional long description of the data being output.
  // Labels(const gtl::ArraySlice<string>&): Defaults to []
  //     a list of strings used to specify how the data can be interpreted, e.g.
  // a string tensor containing jpg images should have 'encoding:image/jpg'; a
  // string tensor with foo protos should have 'encoding:proto/X/Y/foo.proto';
  // a numeric tensor containing bounding boxes may have
  // 'bounding_box:x1,y1,x2,y2,'. If the tensor is a part of a group of related
  // outputs, that can be encoded through a 'group:$groupName/$roleInGroup' label.
  // Labels may be formatted as 'prefix:value'. The prefix may be re-used.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Description(@StringPiece BytePointer x);
    public native @ByVal Attrs Description(@StringPiece String x);

    public native @ByVal Attrs Labels(@Cast("const tensorflow::gtl::ArraySlice<std::string>*") @ByRef StringVector x);

    public native @StringPiece BytePointer description_(); public native Attrs description_(BytePointer description_);
    public native @ByRef @Cast("tensorflow::gtl::ArraySlice<std::string>*") StringVector labels_(); public native Attrs labels_(StringVector labels_);
  }
  public TensorSummary(@Const @ByRef Scope scope, @ByVal Input tensor, @StringPiece BytePointer display_name) { super((Pointer)null); allocate(scope, tensor, display_name); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input tensor, @StringPiece BytePointer display_name);
  public TensorSummary(@Const @ByRef Scope scope, @ByVal Input tensor, @StringPiece String display_name) { super((Pointer)null); allocate(scope, tensor, display_name); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input tensor, @StringPiece String display_name);
  public TensorSummary(@Const @ByRef Scope scope, @ByVal Input tensor, @StringPiece BytePointer display_name, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, tensor, display_name, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input tensor, @StringPiece BytePointer display_name, @Const @ByRef Attrs attrs);
  public TensorSummary(@Const @ByRef Scope scope, @ByVal Input tensor, @StringPiece String display_name, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, tensor, display_name, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input tensor, @StringPiece String display_name, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Description(@StringPiece BytePointer x);
  public static native @ByVal Attrs Description(@StringPiece String x);
  public static native @ByVal Attrs Labels(@Cast("const tensorflow::gtl::ArraySlice<std::string>*") @ByRef StringVector x);

  public native @ByRef Output summary(); public native TensorSummary summary(Output summary);
}

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_LOGGING_OPS_H_


// Parsed from tensorflow/cc/ops/math_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_MATH_OPS_H_
// #define TENSORFLOW_CC_OPS_MATH_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"

// Computes the absolute value of a tensor.
//
// Given a tensor `x`, this operation returns a tensor containing the absolute
// value of each element in `x`. For example, if x is an input element and y is
// an output element, this operation computes \\(y = |x|\\).
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Abs extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Abs(Pointer p) { super(p); }

  public Abs(@Const @ByRef Scope scope, @ByVal Input x) { super((Pointer)null); allocate(scope, x); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output y(); public native Abs y(Output y);
}

// Computes acos of x element-wise.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Acos extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Acos(Pointer p) { super(p); }

  public Acos(@Const @ByRef Scope scope, @ByVal Input x) { super((Pointer)null); allocate(scope, x); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output y(); public native Acos y(Output y);
}

// Returns x + y element-wise.
//
// *NOTE*: `Add` supports broadcasting. `AddN` does not. More about broadcasting
// [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Add extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Add(Pointer p) { super(p); }

  public Add(@Const @ByRef Scope scope, @ByVal Input x,
      @ByVal Input y) { super((Pointer)null); allocate(scope, x, y); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x,
      @ByVal Input y);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output z(); public native Add z(Output z);
}

// Add all input tensors element wise.
//
// Arguments:
// * scope: A Scope object
// * inputs: Must all be the same size and shape.
@Namespace("tensorflow::ops") @NoOffset public static class AddN extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public AddN(Pointer p) { super(p); }

  public AddN(@Const @ByRef Scope scope, @ByVal InputList inputs) { super((Pointer)null); allocate(scope, inputs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal InputList inputs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output sum(); public native AddN sum(Output sum);
}

// Computes the "logical and" of elements across dimensions of a tensor.
//
// Reduces `input` along the dimensions given in `reduction_indices`. Unless
// `keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
// `reduction_indices`. If `keep_dims` is true, the reduced dimensions are
// retained with length 1.
//
// Arguments:
// * scope: A Scope object
// * input: The tensor to reduce.
// * reduction_indices: The dimensions to reduce.
@Namespace("tensorflow::ops") @NoOffset public static class All extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public All(Pointer p) { super(p); }

  // Optional attribute setters for All :
  //
  // KeepDims(bool): Defaults to false
  //     If true, retain reduced dimensions with length 1.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs KeepDims(@Cast("bool") boolean x);

    public native @Cast("bool") boolean keep_dims_(); public native Attrs keep_dims_(boolean keep_dims_);
  }
  public All(@Const @ByRef Scope scope, @ByVal Input input,
      @ByVal Input reduction_indices) { super((Pointer)null); allocate(scope, input, reduction_indices); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
      @ByVal Input reduction_indices);
  public All(@Const @ByRef Scope scope, @ByVal Input input,
      @ByVal Input reduction_indices, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, reduction_indices, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
      @ByVal Input reduction_indices, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs KeepDims(@Cast("bool") boolean x);

  public native @ByRef Output output(); public native All output(Output output);
}

// Computes the "logical or" of elements across dimensions of a tensor.
//
// Reduces `input` along the dimensions given in `reduction_indices`. Unless
// `keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
// `reduction_indices`. If `keep_dims` is true, the reduced dimensions are
// retained with length 1.
//
// Arguments:
// * scope: A Scope object
// * input: The tensor to reduce.
// * reduction_indices: The dimensions to reduce.
@Namespace("tensorflow::ops") @NoOffset public static class Any extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Any(Pointer p) { super(p); }

  // Optional attribute setters for Any :
  //
  // KeepDims(bool): Defaults to false
  //     If true, retain reduced dimensions with length 1.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs KeepDims(@Cast("bool") boolean x);

    public native @Cast("bool") boolean keep_dims_(); public native Attrs keep_dims_(boolean keep_dims_);
  }
  public Any(@Const @ByRef Scope scope, @ByVal Input input,
      @ByVal Input reduction_indices) { super((Pointer)null); allocate(scope, input, reduction_indices); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
      @ByVal Input reduction_indices);
  public Any(@Const @ByRef Scope scope, @ByVal Input input,
      @ByVal Input reduction_indices, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, reduction_indices, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
      @ByVal Input reduction_indices, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs KeepDims(@Cast("bool") boolean x);

  public native @ByRef Output output(); public native Any output(Output output);
}

// Returns the index with the largest value across dimensions of a tensor.
//
// Arguments:
// * scope: A Scope object
// * dimension: int32, 0 <= dimension < rank(input).  Describes which dimension
// of the input Tensor to reduce across. For vectors, use dimension = 0.
@Namespace("tensorflow::ops") @NoOffset public static class ArgMax extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ArgMax(Pointer p) { super(p); }

  public ArgMax(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input dimension) { super((Pointer)null); allocate(scope, input, dimension); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input dimension);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native ArgMax output(Output output);
}

// Returns the index with the smallest value across dimensions of a tensor.
//
// Arguments:
// * scope: A Scope object
// * dimension: int32, 0 <= dimension < rank(input).  Describes which dimension
// of the input Tensor to reduce across. For vectors, use dimension = 0.
@Namespace("tensorflow::ops") @NoOffset public static class ArgMin extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ArgMin(Pointer p) { super(p); }

  public ArgMin(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input dimension) { super((Pointer)null); allocate(scope, input, dimension); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input dimension);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native ArgMin output(Output output);
}

// Computes asin of x element-wise.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Asin extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Asin(Pointer p) { super(p); }

  public Asin(@Const @ByRef Scope scope, @ByVal Input x) { super((Pointer)null); allocate(scope, x); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output y(); public native Asin y(Output y);
}

// Computes atan of x element-wise.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Atan extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Atan(Pointer p) { super(p); }

  public Atan(@Const @ByRef Scope scope, @ByVal Input x) { super((Pointer)null); allocate(scope, x); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output y(); public native Atan y(Output y);
}

// TODO: add doc.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class BatchFFT extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public BatchFFT(Pointer p) { super(p); }

  public BatchFFT(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native BatchFFT output(Output output);
}

// TODO: add doc.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class BatchFFT2D extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public BatchFFT2D(Pointer p) { super(p); }

  public BatchFFT2D(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native BatchFFT2D output(Output output);
}

// TODO: add doc.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class BatchFFT3D extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public BatchFFT3D(Pointer p) { super(p); }

  public BatchFFT3D(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native BatchFFT3D output(Output output);
}

// TODO: add doc.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class BatchIFFT extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public BatchIFFT(Pointer p) { super(p); }

  public BatchIFFT(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native BatchIFFT output(Output output);
}

// TODO: add doc.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class BatchIFFT2D extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public BatchIFFT2D(Pointer p) { super(p); }

  public BatchIFFT2D(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native BatchIFFT2D output(Output output);
}

// TODO: add doc.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class BatchIFFT3D extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public BatchIFFT3D(Pointer p) { super(p); }

  public BatchIFFT3D(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native BatchIFFT3D output(Output output);
}

// Multiplies slices of two tensors in batches.
//
// Multiplies all slices of `Tensor` `x` and `y` (each slice can be
// viewed as an element of a batch), and arranges the individual results
// in a single output tensor of the same batch size. Each of the
// individual slices can optionally be adjointed (to adjoint a matrix
// means to transpose and conjugate it) before multiplication by setting
// the `adj_x` or `adj_y` flag to `True`, which are by default `False`.
//
// The input tensors `x` and `y` are 3-D or higher with shape `[..., r_x, c_x]`
// and `[..., r_y, c_y]`.
//
// The output tensor is 3-D or higher with shape `[..., r_o, c_o]`, where:
//
//     r_o = c_x if adj_x else r_x
//     c_o = r_y if adj_y else c_y
//
// It is computed as:
//
//     output[..., :, :] = matrix(x[..., :, :]) * matrix(y[..., :, :])
//
// Arguments:
// * scope: A Scope object
// * x: 3-D or higher with shape `[..., r_x, c_x]`.
// * y: 3-D or higher with shape `[..., r_y, c_y]`.
@Namespace("tensorflow::ops") @NoOffset public static class BatchMatMul extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public BatchMatMul(Pointer p) { super(p); }

  // Optional attribute setters for BatchMatMul :
  //
  // AdjX(bool): Defaults to false
  //     If `True`, adjoint the slices of `x`. Defaults to `False`.
  // AdjY(bool): Defaults to false
  //     If `True`, adjoint the slices of `y`. Defaults to `False`.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs AdjX(@Cast("bool") boolean x);

    public native @ByVal Attrs AdjY(@Cast("bool") boolean x);

    public native @Cast("bool") boolean adj_x_(); public native Attrs adj_x_(boolean adj_x_);
    public native @Cast("bool") boolean adj_y_(); public native Attrs adj_y_(boolean adj_y_);
  }
  public BatchMatMul(@Const @ByRef Scope scope, @ByVal Input x,
              @ByVal Input y) { super((Pointer)null); allocate(scope, x, y); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x,
              @ByVal Input y);
  public BatchMatMul(@Const @ByRef Scope scope, @ByVal Input x,
              @ByVal Input y, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, x, y, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x,
              @ByVal Input y, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs AdjX(@Cast("bool") boolean x);
  public static native @ByVal Attrs AdjY(@Cast("bool") boolean x);

  public native @ByRef Output output(); public native BatchMatMul output(Output output);
}

// Compute the regularized incomplete beta integral \\(I_x(a, b)\\).
//
// The regularized incomplete beta integral is defined as:
//
// ```
// I_x(a, b) = \frac{B(x; a, b)}{B(a, b)}
// ```
// where
//
// ```
// B(x; a, b) = \int_0^x t^{a-1} (1 - t)^{b-1} dt
// ```
//
// is the incomplete beta function and \\(B(a, b)\\) is the *complete*
// beta function.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Betainc extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Betainc(Pointer p) { super(p); }

  public Betainc(@Const @ByRef Scope scope, @ByVal Input a,
          @ByVal Input b, @ByVal Input x) { super((Pointer)null); allocate(scope, a, b, x); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input a,
          @ByVal Input b, @ByVal Input x);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output z(); public native Betainc z(Output z);
}

// Cast x of type SrcT to y of DstT.
//
// Arguments:
// * scope: A Scope object
@Name("class tensorflow::ops::Cast") @NoOffset public static class CastOp extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public CastOp(Pointer p) { super(p); }

  public CastOp(@Const @ByRef Scope scope, @ByVal Input x, @Cast("tensorflow::DataType") int DstT) { super((Pointer)null); allocate(scope, x, DstT); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x, @Cast("tensorflow::DataType") int DstT);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output y(); public native CastOp y(Output y);
}

// Returns element-wise smallest integer in not less than x.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Ceil extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Ceil(Pointer p) { super(p); }

  public Ceil(@Const @ByRef Scope scope, @ByVal Input x) { super((Pointer)null); allocate(scope, x); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output y(); public native Ceil y(Output y);
}

// Converts two real numbers to a complex number.
//
// Given a tensor `real` representing the real part of a complex number, and a
// tensor `imag` representing the imaginary part of a complex number, this
// operation returns complex numbers elementwise of the form \\(a + bj\\), where
// *a* represents the `real` part and *b* represents the `imag` part.
//
// The input tensors `real` and `imag` must have the same shape.
//
// For example:
//
// ```
// # tensor 'real' is [2.25, 3.25]
// # tensor `imag` is [4.75, 5.75]
// tf.complex(real, imag) ==> [[2.25 + 4.75j], [3.25 + 5.75j]]
// ```
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Complex extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Complex(Pointer p) { super(p); }

  // Optional attribute setters for Complex :
  //
  // Tout(DataType): Defaults to DT_COMPLEX64
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Tout(@Cast("tensorflow::DataType") int x);

    public native @Cast("tensorflow::DataType") int Tout_(); public native Attrs Tout_(int Tout_);
  }
  public Complex(@Const @ByRef Scope scope, @ByVal Input real,
          @ByVal Input imag) { super((Pointer)null); allocate(scope, real, imag); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input real,
          @ByVal Input imag);
  public Complex(@Const @ByRef Scope scope, @ByVal Input real,
          @ByVal Input imag, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, real, imag, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input real,
          @ByVal Input imag, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Tout(@Cast("tensorflow::DataType") int x);

  public native @ByRef Output out(); public native Complex out(Output out);
}

// Computes the complex absolute value of a tensor.
//
// Given a tensor `x` of complex numbers, this operation returns a tensor of type
// `float` or `double` that is the absolute value of each element in `x`. All
// elements in `x` must be complex numbers of the form \\(a + bj\\). The absolute
// value is computed as \\( \sqrt{a^2 + b^2}\\).
//
// For example:
//
// ```
// # tensor 'x' is [[-2.25 + 4.75j], [-3.25 + 5.75j]]
// tf.complex_abs(x) ==> [5.25594902, 6.60492229]
// ```
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class ComplexAbs extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ComplexAbs(Pointer p) { super(p); }

  // Optional attribute setters for ComplexAbs :
  //
  // Tout(DataType): Defaults to DT_FLOAT
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Tout(@Cast("tensorflow::DataType") int x);

    public native @Cast("tensorflow::DataType") int Tout_(); public native Attrs Tout_(int Tout_);
  }
  public ComplexAbs(@Const @ByRef Scope scope, @ByVal Input x) { super((Pointer)null); allocate(scope, x); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x);
  public ComplexAbs(@Const @ByRef Scope scope, @ByVal Input x, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, x, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Tout(@Cast("tensorflow::DataType") int x);

  public native @ByRef Output y(); public native ComplexAbs y(Output y);
}

// Returns the complex conjugate of a complex number.
//
// Given a tensor `input` of complex numbers, this operation returns a tensor of
// complex numbers that are the complex conjugate of each element in `input`. The
// complex numbers in `input` must be of the form \\(a + bj\\), where *a* is the
// real part and *b* is the imaginary part.
//
// The complex conjugate returned by this operation is of the form \\(a - bj\\).
//
// For example:
//
// ```
// # tensor 'input' is [-2.25 + 4.75j, 3.25 + 5.75j]
// tf.conj(input) ==> [-2.25 - 4.75j, 3.25 - 5.75j]
// ```
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Conj extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Conj(Pointer p) { super(p); }

  public Conj(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native Conj output(Output output);
}

// Computes cos of x element-wise.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Cos extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Cos(Pointer p) { super(p); }

  public Cos(@Const @ByRef Scope scope, @ByVal Input x) { super((Pointer)null); allocate(scope, x); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output y(); public native Cos y(Output y);
}

// Compute the pairwise cross product.
//
// `a` and `b` must be the same shape; they can either be simple 3-element vectors,
// or any shape where the innermost dimension is 3. In the latter case, each pair
// of corresponding 3-element vectors is cross-multiplied independently.
//
// Arguments:
// * scope: A Scope object
// * a: A tensor containing 3-element vectors.
// * b: Another tensor, of same type and shape as `a`.
@Namespace("tensorflow::ops") @NoOffset public static class Cross extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Cross(Pointer p) { super(p); }

  public Cross(@Const @ByRef Scope scope, @ByVal Input a,
        @ByVal Input b) { super((Pointer)null); allocate(scope, a, b); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input a,
        @ByVal Input b);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output product(); public native Cross product(Output product);
}

// Compute the cumulative product of the tensor `x` along `axis`.
//
// By default, this op performs an inclusive cumprod, which means that the first
// element of the input is identical to the first element of the output:
// ```prettyprint
// tf.cumprod([a, b, c]) ==> [a, a * b, a * b * c]
// ```
//
// By setting the `exclusive` kwarg to `True`, an exclusive cumprod is
// performed instead:
// ```prettyprint
// tf.cumprod([a, b, c], exclusive=True) ==> [0, a, a * b]
// ```
//
// By setting the `reverse` kwarg to `True`, the cumprod is performed in the
// opposite direction:
// ```prettyprint
// tf.cumprod([a, b, c], reverse=True) ==> [a * b * c, b * c, c]
// ```
// This is more efficient than using separate `tf.reverse` ops.
//
// The `reverse` and `exclusive` kwargs can also be combined:
// ```prettyprint
// tf.cumprod([a, b, c], exclusive=True, reverse=True) ==> [b * c, c, 0]
// ```
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Cumprod extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Cumprod(Pointer p) { super(p); }

  // Optional attribute setters for Cumprod :
  //
  // Exclusive(bool): Defaults to false
  // Reverse(bool): Defaults to false
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Exclusive(@Cast("bool") boolean x);

    public native @ByVal Attrs Reverse(@Cast("bool") boolean x);

    public native @Cast("bool") boolean exclusive_(); public native Attrs exclusive_(boolean exclusive_);
    public native @Cast("bool") boolean reverse_(); public native Attrs reverse_(boolean reverse_);
  }
  public Cumprod(@Const @ByRef Scope scope, @ByVal Input x,
          @ByVal Input axis) { super((Pointer)null); allocate(scope, x, axis); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x,
          @ByVal Input axis);
  public Cumprod(@Const @ByRef Scope scope, @ByVal Input x,
          @ByVal Input axis, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, x, axis, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x,
          @ByVal Input axis, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Exclusive(@Cast("bool") boolean x);
  public static native @ByVal Attrs Reverse(@Cast("bool") boolean x);

  public native @ByRef Output out(); public native Cumprod out(Output out);
}

// Compute the cumulative sum of the tensor `x` along `axis`.
//
// By default, this op performs an inclusive cumsum, which means that the first
// element of the input is identical to the first element of the output:
// ```prettyprint
// tf.cumsum([a, b, c]) ==> [a, a + b, a + b + c]
// ```
//
// By setting the `exclusive` kwarg to `True`, an exclusive cumsum is
// performed instead:
// ```prettyprint
// tf.cumsum([a, b, c], exclusive=True) ==> [0, a, a + b]
// ```
//
// By setting the `reverse` kwarg to `True`, the cumsum is performed in the
// opposite direction:
// ```prettyprint
// tf.cumsum([a, b, c], reverse=True) ==> [a + b + c, b + c, c]
// ```
// This is more efficient than using separate `tf.reverse` ops.
//
// The `reverse` and `exclusive` kwargs can also be combined:
// ```prettyprint
// tf.cumsum([a, b, c], exclusive=True, reverse=True) ==> [b + c, c, 0]
// ```
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Cumsum extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Cumsum(Pointer p) { super(p); }

  // Optional attribute setters for Cumsum :
  //
  // Exclusive(bool): Defaults to false
  // Reverse(bool): Defaults to false
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Exclusive(@Cast("bool") boolean x);

    public native @ByVal Attrs Reverse(@Cast("bool") boolean x);

    public native @Cast("bool") boolean exclusive_(); public native Attrs exclusive_(boolean exclusive_);
    public native @Cast("bool") boolean reverse_(); public native Attrs reverse_(boolean reverse_);
  }
  public Cumsum(@Const @ByRef Scope scope, @ByVal Input x,
         @ByVal Input axis) { super((Pointer)null); allocate(scope, x, axis); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x,
         @ByVal Input axis);
  public Cumsum(@Const @ByRef Scope scope, @ByVal Input x,
         @ByVal Input axis, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, x, axis, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x,
         @ByVal Input axis, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Exclusive(@Cast("bool") boolean x);
  public static native @ByVal Attrs Reverse(@Cast("bool") boolean x);

  public native @ByRef Output out(); public native Cumsum out(Output out);
}

// Computes Psi, the derivative of Lgamma (the log of the absolute value of
//
// `Gamma(x)`), element-wise.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Digamma extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Digamma(Pointer p) { super(p); }

  public Digamma(@Const @ByRef Scope scope, @ByVal Input x) { super((Pointer)null); allocate(scope, x); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output y(); public native Digamma y(Output y);
}

// Returns x / y element-wise.
//
// *NOTE*: `Div` supports broadcasting. More about broadcasting
// [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Div extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Div(Pointer p) { super(p); }

  public Div(@Const @ByRef Scope scope, @ByVal Input x,
      @ByVal Input y) { super((Pointer)null); allocate(scope, x, y); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x,
      @ByVal Input y);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output z(); public native Div z(Output z);
}

// Returns the truth value of (x == y) element-wise.
//
// *NOTE*: `Equal` supports broadcasting. More about broadcasting
// [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Equal extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Equal(Pointer p) { super(p); }

  public Equal(@Const @ByRef Scope scope, @ByVal Input x,
        @ByVal Input y) { super((Pointer)null); allocate(scope, x, y); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x,
        @ByVal Input y);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output z(); public native Equal z(Output z);
}

// Computes the Gauss error function of `x` element-wise.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Erf extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Erf(Pointer p) { super(p); }

  public Erf(@Const @ByRef Scope scope, @ByVal Input x) { super((Pointer)null); allocate(scope, x); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output y(); public native Erf y(Output y);
}

// Computes the complementary error function of `x` element-wise.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Erfc extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Erfc(Pointer p) { super(p); }

  public Erfc(@Const @ByRef Scope scope, @ByVal Input x) { super((Pointer)null); allocate(scope, x); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output y(); public native Erfc y(Output y);
}

// Computes exponential of x element-wise.  \\(y = e^x\\).
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Exp extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Exp(Pointer p) { super(p); }

  public Exp(@Const @ByRef Scope scope, @ByVal Input x) { super((Pointer)null); allocate(scope, x); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output y(); public native Exp y(Output y);
}

// Compute the 1-dimensional discrete Fourier Transform over the inner-most
//
// dimension of `input`.
//
// Arguments:
// * scope: A Scope object
// * input: A complex64 tensor.
@Namespace("tensorflow::ops") @NoOffset public static class FFT extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public FFT(Pointer p) { super(p); }

  public FFT(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native FFT output(Output output);
}

// Compute the 2-dimensional discrete Fourier Transform over the inner-most
//
// 2 dimensions of `input`.
//
// Arguments:
// * scope: A Scope object
// * input: A complex64 tensor.
@Namespace("tensorflow::ops") @NoOffset public static class FFT2D extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public FFT2D(Pointer p) { super(p); }

  public FFT2D(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native FFT2D output(Output output);
}

// Compute the 3-dimensional discrete Fourier Transform over the inner-most 3
//
// dimensions of `input`.
//
// Arguments:
// * scope: A Scope object
// * input: A complex64 tensor.
@Namespace("tensorflow::ops") @NoOffset public static class FFT3D extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public FFT3D(Pointer p) { super(p); }

  public FFT3D(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native FFT3D output(Output output);
}

// Returns element-wise largest integer not greater than x.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Floor extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Floor(Pointer p) { super(p); }

  public Floor(@Const @ByRef Scope scope, @ByVal Input x) { super((Pointer)null); allocate(scope, x); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output y(); public native Floor y(Output y);
}

// Returns the truth value of (x > y) element-wise.
//
// *NOTE*: `Greater` supports broadcasting. More about broadcasting
// [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Greater extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Greater(Pointer p) { super(p); }

  public Greater(@Const @ByRef Scope scope, @ByVal Input x,
          @ByVal Input y) { super((Pointer)null); allocate(scope, x, y); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x,
          @ByVal Input y);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output z(); public native Greater z(Output z);
}

// Returns the truth value of (x >= y) element-wise.
//
// *NOTE*: `GreaterEqual` supports broadcasting. More about broadcasting
// [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class GreaterEqual extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public GreaterEqual(Pointer p) { super(p); }

  public GreaterEqual(@Const @ByRef Scope scope, @ByVal Input x,
               @ByVal Input y) { super((Pointer)null); allocate(scope, x, y); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x,
               @ByVal Input y);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output z(); public native GreaterEqual z(Output z);
}

// Compute the inverse 1-dimensional discrete Fourier Transform over the inner-most
//
// dimension of `input`.
//
// Arguments:
// * scope: A Scope object
// * input: A complex64 tensor.
@Namespace("tensorflow::ops") @NoOffset public static class IFFT extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IFFT(Pointer p) { super(p); }

  public IFFT(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native IFFT output(Output output);
}

// Compute the inverse 2-dimensional discrete Fourier Transform over the inner-most
//
// 2 dimensions of `input`.
//
// Arguments:
// * scope: A Scope object
// * input: A complex64 tensor.
@Namespace("tensorflow::ops") @NoOffset public static class IFFT2D extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IFFT2D(Pointer p) { super(p); }

  public IFFT2D(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native IFFT2D output(Output output);
}

// Compute the inverse 3-dimensional discrete Fourier Transform over the inner-most
//
// 3 dimensions of `input`.
//
// Arguments:
// * scope: A Scope object
// * input: A complex64 tensor.
@Namespace("tensorflow::ops") @NoOffset public static class IFFT3D extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IFFT3D(Pointer p) { super(p); }

  public IFFT3D(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native IFFT3D output(Output output);
}

// Compute the lower regularized incomplete Gamma function `Q(a, x)`.
//
// The lower regularized incomplete Gamma function is defined as:
//
// ```
// P(a, x) = gamma(a, x) / Gamma(a) = 1 - Q(a, x)
// ```
// where
// ```
// gamma(a, x) = int_{0}^{x} t^{a-1} exp(-t) dt
// ```
// is the lower incomplete Gamma function.
//
// Note, above `Q(a, x)` (`Igammac`) is the upper regularized complete
// Gamma function.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Igamma extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Igamma(Pointer p) { super(p); }

  public Igamma(@Const @ByRef Scope scope, @ByVal Input a,
         @ByVal Input x) { super((Pointer)null); allocate(scope, a, x); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input a,
         @ByVal Input x);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output z(); public native Igamma z(Output z);
}

// Compute the upper regularized incomplete Gamma function `Q(a, x)`.
//
// The upper regularized incomplete Gamma function is defined as:
//
// ```
// Q(a, x) = Gamma(a, x) / Gamma(a) = 1 - P(a, x)
// ```
// where
// ```
// Gamma(a, x) = int_{x}^{\infty} t^{a-1} exp(-t) dt
// ```
// is the upper incomplete Gama function.
//
// Note, above `P(a, x)` (`Igamma`) is the lower regularized complete
// Gamma function.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Igammac extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Igammac(Pointer p) { super(p); }

  public Igammac(@Const @ByRef Scope scope, @ByVal Input a,
          @ByVal Input x) { super((Pointer)null); allocate(scope, a, x); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input a,
          @ByVal Input x);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output z(); public native Igammac z(Output z);
}

// Returns the imaginary part of a complex number.
//
// Given a tensor `input` of complex numbers, this operation returns a tensor of
// type `float` that is the imaginary part of each element in `input`. All
// elements in `input` must be complex numbers of the form \\(a + bj\\), where *a*
// is the real part and *b* is the imaginary part returned by this operation.
//
// For example:
//
// ```
// # tensor 'input' is [-2.25 + 4.75j, 3.25 + 5.75j]
// tf.imag(input) ==> [4.75, 5.75]
// ```
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Imag extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Imag(Pointer p) { super(p); }

  // Optional attribute setters for Imag :
  //
  // Tout(DataType): Defaults to DT_FLOAT
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Tout(@Cast("tensorflow::DataType") int x);

    public native @Cast("tensorflow::DataType") int Tout_(); public native Attrs Tout_(int Tout_);
  }
  public Imag(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public Imag(@Const @ByRef Scope scope, @ByVal Input input, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Tout(@Cast("tensorflow::DataType") int x);

  public native @ByRef Output output(); public native Imag output(Output output);
}

// Computes the reciprocal of x element-wise.
//
// I.e., \\(y = 1 / x\\).
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Inv extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Inv(Pointer p) { super(p); }

  public Inv(@Const @ByRef Scope scope, @ByVal Input x) { super((Pointer)null); allocate(scope, x); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output y(); public native Inv y(Output y);
}

// Computes the gradient for the inverse of `x` wrt its input.
//
// Specifically, `grad = -dy * y*y`, where `y = 1/x`, and `dy`
// is the corresponding input gradient.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class InvGrad extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public InvGrad(Pointer p) { super(p); }

  public InvGrad(@Const @ByRef Scope scope, @ByVal Input x,
          @ByVal Input y) { super((Pointer)null); allocate(scope, x, y); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x,
          @ByVal Input y);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output z(); public native InvGrad z(Output z);
}

// Returns which elements of x are finite.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class IsFinite extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IsFinite(Pointer p) { super(p); }

  public IsFinite(@Const @ByRef Scope scope, @ByVal Input x) { super((Pointer)null); allocate(scope, x); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output y(); public native IsFinite y(Output y);
}

// Returns which elements of x are Inf.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class IsInf extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IsInf(Pointer p) { super(p); }

  public IsInf(@Const @ByRef Scope scope, @ByVal Input x) { super((Pointer)null); allocate(scope, x); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output y(); public native IsInf y(Output y);
}

// Returns which elements of x are NaN.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class IsNan extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IsNan(Pointer p) { super(p); }

  public IsNan(@Const @ByRef Scope scope, @ByVal Input x) { super((Pointer)null); allocate(scope, x); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output y(); public native IsNan y(Output y);
}

// Returns the truth value of (x < y) element-wise.
//
// *NOTE*: `Less` supports broadcasting. More about broadcasting
// [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Less extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Less(Pointer p) { super(p); }

  public Less(@Const @ByRef Scope scope, @ByVal Input x,
       @ByVal Input y) { super((Pointer)null); allocate(scope, x, y); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x,
       @ByVal Input y);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output z(); public native Less z(Output z);
}

// Returns the truth value of (x <= y) element-wise.
//
// *NOTE*: `LessEqual` supports broadcasting. More about broadcasting
// [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class LessEqual extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public LessEqual(Pointer p) { super(p); }

  public LessEqual(@Const @ByRef Scope scope, @ByVal Input x,
            @ByVal Input y) { super((Pointer)null); allocate(scope, x, y); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x,
            @ByVal Input y);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output z(); public native LessEqual z(Output z);
}

// Computes the log of the absolute value of `Gamma(x)` element-wise.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Lgamma extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Lgamma(Pointer p) { super(p); }

  public Lgamma(@Const @ByRef Scope scope, @ByVal Input x) { super((Pointer)null); allocate(scope, x); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output y(); public native Lgamma y(Output y);
}

// Generates values in an interval.
//
// A sequence of `num` evenly-spaced values are generated beginning at `start`.
// If `num > 1`, the values in the sequence increase by `stop - start / num - 1`,
// so that the last one is exactly `stop`.
//
// For example:
//
// ```
// tf.linspace(10.0, 12.0, 3, name="linspace") => [ 10.0  11.0  12.0]
// ```
//
// Arguments:
// * scope: A Scope object
// * start: First entry in the range.
// * stop: Last entry in the range.
// * num: Number of values to generate.
@Namespace("tensorflow::ops") @NoOffset public static class LinSpace extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public LinSpace(Pointer p) { super(p); }

  public LinSpace(@Const @ByRef Scope scope, @ByVal Input start,
           @ByVal Input stop, @ByVal Input num) { super((Pointer)null); allocate(scope, start, stop, num); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input start,
           @ByVal Input stop, @ByVal Input num);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native LinSpace output(Output output);
}

// Computes natural logarithm of x element-wise.
//
// I.e., \\(y = \log_e x\\).
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Log extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Log(Pointer p) { super(p); }

  public Log(@Const @ByRef Scope scope, @ByVal Input x) { super((Pointer)null); allocate(scope, x); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output y(); public native Log y(Output y);
}

// Returns the truth value of x AND y element-wise.
//
// *NOTE*: `LogicalAnd` supports broadcasting. More about broadcasting
// [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class LogicalAnd extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public LogicalAnd(Pointer p) { super(p); }

  public LogicalAnd(@Const @ByRef Scope scope, @ByVal Input x,
             @ByVal Input y) { super((Pointer)null); allocate(scope, x, y); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x,
             @ByVal Input y);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output z(); public native LogicalAnd z(Output z);
}

// Returns the truth value of NOT x element-wise.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class LogicalNot extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public LogicalNot(Pointer p) { super(p); }

  public LogicalNot(@Const @ByRef Scope scope, @ByVal Input x) { super((Pointer)null); allocate(scope, x); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output y(); public native LogicalNot y(Output y);
}

// Returns the truth value of x OR y element-wise.
//
// *NOTE*: `LogicalOr` supports broadcasting. More about broadcasting
// [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class LogicalOr extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public LogicalOr(Pointer p) { super(p); }

  public LogicalOr(@Const @ByRef Scope scope, @ByVal Input x,
            @ByVal Input y) { super((Pointer)null); allocate(scope, x, y); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x,
            @ByVal Input y);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output z(); public native LogicalOr z(Output z);
}

// Multiply the matrix "a" by the matrix "b".
//
// The inputs must be two-dimensional matrices and the inner dimension of
// "a" (after being transposed if transpose_a is true) must match the
// outer dimension of "b" (after being transposed if transposed_b is
// true).
//
// *Note*: The default kernel implementation for MatMul on GPUs uses
// cublas.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class MatMul extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public MatMul(Pointer p) { super(p); }

  // Optional attribute setters for MatMul :
  //
  // TransposeA(bool): Defaults to false
  //     If true, "a" is transposed before multiplication.
  // TransposeB(bool): Defaults to false
  //     If true, "b" is transposed before multiplication.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs TransposeA(@Cast("bool") boolean x);

    public native @ByVal Attrs TransposeB(@Cast("bool") boolean x);

    public native @Cast("bool") boolean transpose_a_(); public native Attrs transpose_a_(boolean transpose_a_);
    public native @Cast("bool") boolean transpose_b_(); public native Attrs transpose_b_(boolean transpose_b_);
  }
  public MatMul(@Const @ByRef Scope scope, @ByVal Input a,
         @ByVal Input b) { super((Pointer)null); allocate(scope, a, b); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input a,
         @ByVal Input b);
  public MatMul(@Const @ByRef Scope scope, @ByVal Input a,
         @ByVal Input b, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, a, b, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input a,
         @ByVal Input b, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs TransposeA(@Cast("bool") boolean x);
  public static native @ByVal Attrs TransposeB(@Cast("bool") boolean x);

  public native @ByRef Output product(); public native MatMul product(Output product);
}

// Computes the maximum of elements across dimensions of a tensor.
//
// Reduces `input` along the dimensions given in `reduction_indices`. Unless
// `keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
// `reduction_indices`. If `keep_dims` is true, the reduced dimensions are
// retained with length 1.
//
// Arguments:
// * scope: A Scope object
// * input: The tensor to reduce.
// * reduction_indices: The dimensions to reduce.
@Namespace("tensorflow::ops") @NoOffset public static class Max extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Max(Pointer p) { super(p); }

  // Optional attribute setters for Max :
  //
  // KeepDims(bool): Defaults to false
  //     If true, retain reduced dimensions with length 1.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs KeepDims(@Cast("bool") boolean x);

    public native @Cast("bool") boolean keep_dims_(); public native Attrs keep_dims_(boolean keep_dims_);
  }
  public Max(@Const @ByRef Scope scope, @ByVal Input input,
      @ByVal Input reduction_indices) { super((Pointer)null); allocate(scope, input, reduction_indices); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
      @ByVal Input reduction_indices);
  public Max(@Const @ByRef Scope scope, @ByVal Input input,
      @ByVal Input reduction_indices, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, reduction_indices, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
      @ByVal Input reduction_indices, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs KeepDims(@Cast("bool") boolean x);

  public native @ByRef Output output(); public native Max output(Output output);
}

// Returns the max of x and y (i.e. x > y ? x : y) element-wise.
//
// *NOTE*: `Maximum` supports broadcasting. More about broadcasting
// [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Maximum extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Maximum(Pointer p) { super(p); }

  public Maximum(@Const @ByRef Scope scope, @ByVal Input x,
          @ByVal Input y) { super((Pointer)null); allocate(scope, x, y); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x,
          @ByVal Input y);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output z(); public native Maximum z(Output z);
}

// Computes the mean of elements across dimensions of a tensor.
//
// Reduces `input` along the dimensions given in `reduction_indices`. Unless
// `keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
// `reduction_indices`. If `keep_dims` is true, the reduced dimensions are
// retained with length 1.
//
// Arguments:
// * scope: A Scope object
// * input: The tensor to reduce.
// * reduction_indices: The dimensions to reduce.
@Namespace("tensorflow::ops") @NoOffset public static class Mean extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Mean(Pointer p) { super(p); }

  // Optional attribute setters for Mean :
  //
  // KeepDims(bool): Defaults to false
  //     If true, retain reduced dimensions with length 1.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs KeepDims(@Cast("bool") boolean x);

    public native @Cast("bool") boolean keep_dims_(); public native Attrs keep_dims_(boolean keep_dims_);
  }
  public Mean(@Const @ByRef Scope scope, @ByVal Input input,
       @ByVal Input reduction_indices) { super((Pointer)null); allocate(scope, input, reduction_indices); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
       @ByVal Input reduction_indices);
  public Mean(@Const @ByRef Scope scope, @ByVal Input input,
       @ByVal Input reduction_indices, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, reduction_indices, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
       @ByVal Input reduction_indices, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs KeepDims(@Cast("bool") boolean x);

  public native @ByRef Output output(); public native Mean output(Output output);
}

// Computes the minimum of elements across dimensions of a tensor.
//
// Reduces `input` along the dimensions given in `reduction_indices`. Unless
// `keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
// `reduction_indices`. If `keep_dims` is true, the reduced dimensions are
// retained with length 1.
//
// Arguments:
// * scope: A Scope object
// * input: The tensor to reduce.
// * reduction_indices: The dimensions to reduce.
@Namespace("tensorflow::ops") @NoOffset public static class Min extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Min(Pointer p) { super(p); }

  // Optional attribute setters for Min :
  //
  // KeepDims(bool): Defaults to false
  //     If true, retain reduced dimensions with length 1.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs KeepDims(@Cast("bool") boolean x);

    public native @Cast("bool") boolean keep_dims_(); public native Attrs keep_dims_(boolean keep_dims_);
  }
  public Min(@Const @ByRef Scope scope, @ByVal Input input,
      @ByVal Input reduction_indices) { super((Pointer)null); allocate(scope, input, reduction_indices); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
      @ByVal Input reduction_indices);
  public Min(@Const @ByRef Scope scope, @ByVal Input input,
      @ByVal Input reduction_indices, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, reduction_indices, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
      @ByVal Input reduction_indices, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs KeepDims(@Cast("bool") boolean x);

  public native @ByRef Output output(); public native Min output(Output output);
}

// Returns the min of x and y (i.e. x < y ? x : y) element-wise.
//
// *NOTE*: `Minimum` supports broadcasting. More about broadcasting
// [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Minimum extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Minimum(Pointer p) { super(p); }

  public Minimum(@Const @ByRef Scope scope, @ByVal Input x,
          @ByVal Input y) { super((Pointer)null); allocate(scope, x, y); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x,
          @ByVal Input y);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output z(); public native Minimum z(Output z);
}

// Returns element-wise remainder of division.
//
// *NOTE*: `Mod` supports broadcasting. More about broadcasting
// [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Mod extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Mod(Pointer p) { super(p); }

  public Mod(@Const @ByRef Scope scope, @ByVal Input x,
      @ByVal Input y) { super((Pointer)null); allocate(scope, x, y); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x,
      @ByVal Input y);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output z(); public native Mod z(Output z);
}

// Returns x * y element-wise.
//
// *NOTE*: `Mul` supports broadcasting. More about broadcasting
// [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Mul extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Mul(Pointer p) { super(p); }

  public Mul(@Const @ByRef Scope scope, @ByVal Input x,
      @ByVal Input y) { super((Pointer)null); allocate(scope, x, y); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x,
      @ByVal Input y);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output z(); public native Mul z(Output z);
}

// Computes numerical negative value element-wise.
//
// I.e., \\(y = -x\\).
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Neg extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Neg(Pointer p) { super(p); }

  public Neg(@Const @ByRef Scope scope, @ByVal Input x) { super((Pointer)null); allocate(scope, x); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output y(); public native Neg y(Output y);
}

// Returns the truth value of (x != y) element-wise.
//
// *NOTE*: `NotEqual` supports broadcasting. More about broadcasting
// [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class NotEqual extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public NotEqual(Pointer p) { super(p); }

  public NotEqual(@Const @ByRef Scope scope, @ByVal Input x,
           @ByVal Input y) { super((Pointer)null); allocate(scope, x, y); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x,
           @ByVal Input y);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output z(); public native NotEqual z(Output z);
}

// Compute the polygamma function \\(\psi^{(n)}(x)\\).
//
// The polygamma function is defined as:
//
// ```
// \psi^{(n)}(x) = \frac{d^n}{dx^n} \psi(x)
// ```
// where \\(\psi(x)\\) is the digamma function.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Polygamma extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Polygamma(Pointer p) { super(p); }

  public Polygamma(@Const @ByRef Scope scope, @ByVal Input a,
            @ByVal Input x) { super((Pointer)null); allocate(scope, a, x); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input a,
            @ByVal Input x);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output z(); public native Polygamma z(Output z);
}

// Computes the power of one value to another.
//
// Given a tensor `x` and a tensor `y`, this operation computes \\(x^y\\) for
// corresponding elements in `x` and `y`. For example:
//
// ```
// # tensor 'x' is [[2, 2]], [3, 3]]
// # tensor 'y' is [[8, 16], [2, 3]]
// tf.pow(x, y) ==> [[256, 65536], [9, 27]]
// ```
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Pow extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Pow(Pointer p) { super(p); }

  public Pow(@Const @ByRef Scope scope, @ByVal Input x,
      @ByVal Input y) { super((Pointer)null); allocate(scope, x, y); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x,
      @ByVal Input y);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output z(); public native Pow z(Output z);
}

// Computes the product of elements across dimensions of a tensor.
//
// Reduces `input` along the dimensions given in `reduction_indices`. Unless
// `keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
// `reduction_indices`. If `keep_dims` is true, the reduced dimensions are
// retained with length 1.
//
// Arguments:
// * scope: A Scope object
// * input: The tensor to reduce.
// * reduction_indices: The dimensions to reduce.
@Namespace("tensorflow::ops") @NoOffset public static class Prod extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Prod(Pointer p) { super(p); }

  // Optional attribute setters for Prod :
  //
  // KeepDims(bool): Defaults to false
  //     If true, retain reduced dimensions with length 1.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs KeepDims(@Cast("bool") boolean x);

    public native @Cast("bool") boolean keep_dims_(); public native Attrs keep_dims_(boolean keep_dims_);
  }
  public Prod(@Const @ByRef Scope scope, @ByVal Input input,
       @ByVal Input reduction_indices) { super((Pointer)null); allocate(scope, input, reduction_indices); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
       @ByVal Input reduction_indices);
  public Prod(@Const @ByRef Scope scope, @ByVal Input input,
       @ByVal Input reduction_indices, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, reduction_indices, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
       @ByVal Input reduction_indices, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs KeepDims(@Cast("bool") boolean x);

  public native @ByRef Output output(); public native Prod output(Output output);
}

// Creates a sequence of integers.
//
// This operation creates a sequence of integers that begins at `start` and
// extends by increments of `delta` up to but not including `limit`.
//
// For example:
//
// ```
// # 'start' is 3
// # 'limit' is 18
// # 'delta' is 3
// tf.range(start, limit, delta) ==> [3, 6, 9, 12, 15]
// ```
//
// Arguments:
// * scope: A Scope object
// * start: 0-D (scalar). First entry in the sequence.
// * limit: 0-D (scalar). Upper limit of sequence, exclusive.
// * delta: 0-D (scalar). Optional. Default is 1. Number that increments `start`.
@Namespace("tensorflow::ops") @NoOffset public static class Range extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Range(Pointer p) { super(p); }

  public Range(@Const @ByRef Scope scope, @ByVal Input start,
        @ByVal Input limit, @ByVal Input delta) { super((Pointer)null); allocate(scope, start, limit, delta); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input start,
        @ByVal Input limit, @ByVal Input delta);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native Range output(Output output);
}

// Returns the real part of a complex number.
//
// Given a tensor `input` of complex numbers, this operation returns a tensor of
// type `float` that is the real part of each element in `input`. All elements in
// `input` must be complex numbers of the form \\(a + bj\\), where *a* is the real
//  part returned by this operation and *b* is the imaginary part.
//
// For example:
//
// ```
// # tensor 'input' is [-2.25 + 4.75j, 3.25 + 5.75j]
// tf.real(input) ==> [-2.25, 3.25]
// ```
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Real extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Real(Pointer p) { super(p); }

  // Optional attribute setters for Real :
  //
  // Tout(DataType): Defaults to DT_FLOAT
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Tout(@Cast("tensorflow::DataType") int x);

    public native @Cast("tensorflow::DataType") int Tout_(); public native Attrs Tout_(int Tout_);
  }
  public Real(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public Real(@Const @ByRef Scope scope, @ByVal Input input, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Tout(@Cast("tensorflow::DataType") int x);

  public native @ByRef Output output(); public native Real output(Output output);
}

// Computes reciprocal of square root of x element-wise.
//
// I.e., \\(y = 1 / \sqrt{x}\\).
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Rsqrt extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Rsqrt(Pointer p) { super(p); }

  public Rsqrt(@Const @ByRef Scope scope, @ByVal Input x) { super((Pointer)null); allocate(scope, x); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output y(); public native Rsqrt y(Output y);
}

// Computes the gradient for the rsqrt of `x` wrt its input.
//
// Specifically, `grad = dy * -0.5 * y^3`, where `y = rsqrt(x)`, and `dy`
// is the corresponding input gradient.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class RsqrtGrad extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public RsqrtGrad(Pointer p) { super(p); }

  public RsqrtGrad(@Const @ByRef Scope scope, @ByVal Input x,
            @ByVal Input y) { super((Pointer)null); allocate(scope, x, y); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x,
            @ByVal Input y);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output z(); public native RsqrtGrad z(Output z);
}

// Computes the maximum along segments of a tensor.
//
// Read [the section on Segmentation](../../api_docs/python/math_ops.md#segmentation)
// for an explanation of segments.
//
// Computes a tensor such that
// \\(output_i = \max_j(data_j)\\) where `max` is over `j` such
// that `segment_ids[j] == i`.
//
// <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
// <img style="width:100%" src="../../images/SegmentMax.png" alt>
// </div>
//
// Arguments:
// * scope: A Scope object
// * segment_ids: A 1-D tensor whose rank is equal to the rank of `data`'s
// first dimension.  Values should be sorted and can be repeated.
@Namespace("tensorflow::ops") @NoOffset public static class SegmentMax extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SegmentMax(Pointer p) { super(p); }

  public SegmentMax(@Const @ByRef Scope scope, @ByVal Input data,
             @ByVal Input segment_ids) { super((Pointer)null); allocate(scope, data, segment_ids); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input data,
             @ByVal Input segment_ids);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native SegmentMax output(Output output);
}

// Computes the mean along segments of a tensor.
//
// Read [the section on
// Segmentation](../../api_docs/python/math_ops.md#segmentation) for an explanation
// of segments.
//
// Computes a tensor such that
// \\(output_i = \frac{\sum_j data_j}{N}\\) where `mean` is
// over `j` such that `segment_ids[j] == i` and `N` is the total number of
// values summed.
//
// <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
// <img style="width:100%" src="../../images/SegmentMean.png" alt>
// </div>
//
// Arguments:
// * scope: A Scope object
// * segment_ids: A 1-D tensor whose rank is equal to the rank of `data`'s
// first dimension.  Values should be sorted and can be repeated.
@Namespace("tensorflow::ops") @NoOffset public static class SegmentMean extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SegmentMean(Pointer p) { super(p); }

  public SegmentMean(@Const @ByRef Scope scope, @ByVal Input data,
              @ByVal Input segment_ids) { super((Pointer)null); allocate(scope, data, segment_ids); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input data,
              @ByVal Input segment_ids);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native SegmentMean output(Output output);
}

// Computes the minimum along segments of a tensor.
//
// Read [the section on
// Segmentation](../../api_docs/python/math_ops.md#segmentation) for an explanation
// of segments.
//
// Computes a tensor such that
// \\(output_i = \min_j(data_j)\\) where `min` is over `j` such
// that `segment_ids[j] == i`.
//
// <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
// <img style="width:100%" src="../../images/SegmentMin.png" alt>
// </div>
//
// Arguments:
// * scope: A Scope object
// * segment_ids: A 1-D tensor whose rank is equal to the rank of `data`'s
// first dimension.  Values should be sorted and can be repeated.
@Namespace("tensorflow::ops") @NoOffset public static class SegmentMin extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SegmentMin(Pointer p) { super(p); }

  public SegmentMin(@Const @ByRef Scope scope, @ByVal Input data,
             @ByVal Input segment_ids) { super((Pointer)null); allocate(scope, data, segment_ids); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input data,
             @ByVal Input segment_ids);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native SegmentMin output(Output output);
}

// Computes the product along segments of a tensor.
//
// Read [the section on
// Segmentation](../../api_docs/python/math_ops.md#segmentation) for an explanation
// of segments.
//
// Computes a tensor such that
// \\(output_i = \prod_j data_j\\) where the product is over `j` such
// that `segment_ids[j] == i`.
//
// <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
// <img style="width:100%" src="../../images/SegmentProd.png" alt>
// </div>
//
// Arguments:
// * scope: A Scope object
// * segment_ids: A 1-D tensor whose rank is equal to the rank of `data`'s
// first dimension.  Values should be sorted and can be repeated.
@Namespace("tensorflow::ops") @NoOffset public static class SegmentProd extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SegmentProd(Pointer p) { super(p); }

  public SegmentProd(@Const @ByRef Scope scope, @ByVal Input data,
              @ByVal Input segment_ids) { super((Pointer)null); allocate(scope, data, segment_ids); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input data,
              @ByVal Input segment_ids);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native SegmentProd output(Output output);
}

// Computes the sum along segments of a tensor.
//
// Read [the section on Segmentation](../../api_docs/python/math_ops.md#segmentation)
// for an explanation of segments.
//
// Computes a tensor such that
// \\(output_i = \sum_j data_j\\) where sum is over `j` such
// that `segment_ids[j] == i`.
//
// <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
// <img style="width:100%" src="../../images/SegmentSum.png" alt>
// </div>
//
// Arguments:
// * scope: A Scope object
// * segment_ids: A 1-D tensor whose rank is equal to the rank of `data`'s
// first dimension.  Values should be sorted and can be repeated.
@Namespace("tensorflow::ops") @NoOffset public static class SegmentSum extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SegmentSum(Pointer p) { super(p); }

  public SegmentSum(@Const @ByRef Scope scope, @ByVal Input data,
             @ByVal Input segment_ids) { super((Pointer)null); allocate(scope, data, segment_ids); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input data,
             @ByVal Input segment_ids);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native SegmentSum output(Output output);
}

// Selects elements from `t` or `e`, depending on `condition`.
//
// The `t`, and `e` tensors must all have the same shape,
// and the output will also have that shape.  The `condition` tensor
// must be a scalar if `t` and `e` are scalars.  If `t` and `e` are vectors
// or higher rank, then `condition` must be either a vector with size
// matching the first dimension of `t`, or must have the same shape as `t`.
//
// The `condition` tensor acts as a mask that chooses, based on the value at each
// element, whether the corresponding element / row in the output should be
// taken from `t` (if true) or `e` (if false).
//
// If `condition` is a vector and `t` and `e` are higher rank matrices, then
// it chooses which row (outer dimension) to copy from `t` and `e`.
// If `condition` has the same shape as `t` and `e`, then it chooses which
// element to copy from `t` and `e`.
//
// For example:
//
// ```prettyprint
// # 'condition' tensor is [[True,  False]
// #                        [False, True]]
// # 't' is [[1, 2],
// #         [3, 4]]
// # 'e' is [[5, 6],
// #         [7, 8]]
// select(condition, t, e) ==> [[1, 6],
//                              [7, 4]]
//
//
// # 'condition' tensor is [True, False]
// # 't' is [[1, 2],
// #         [3, 4]]
// # 'e' is [[5, 6],
// #         [7, 8]]
// select(condition, t, e) ==> [[1, 2],
//                              [7, 8]]
//
// ```
//
// Arguments:
// * scope: A Scope object
// * t: = A `Tensor` which may have the same shape as `condition`.
// If `condition` is rank 1, `t` may have higher rank,
// but its first dimension must match the size of `condition`.
// * e: = A `Tensor` with the same type and shape as `t`.
@Namespace("tensorflow::ops") @NoOffset public static class Select extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Select(Pointer p) { super(p); }

  public Select(@Const @ByRef Scope scope, @ByVal Input condition,
         @ByVal Input t, @ByVal Input e) { super((Pointer)null); allocate(scope, condition, t, e); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input condition,
         @ByVal Input t, @ByVal Input e);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native Select output(Output output);
}

// Computes sigmoid of `x` element-wise.
//
// Specifically, `y = 1 / (1 + exp(-x))`.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Sigmoid extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Sigmoid(Pointer p) { super(p); }

  public Sigmoid(@Const @ByRef Scope scope, @ByVal Input x) { super((Pointer)null); allocate(scope, x); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output y(); public native Sigmoid y(Output y);
}

// Computes the gradient of the sigmoid of `x` wrt its input.
//
// Specifically, `grad = dy * y * (1 - y)`, where `y = sigmoid(x)`, and
// `dy` is the corresponding input gradient.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class SigmoidGrad extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SigmoidGrad(Pointer p) { super(p); }

  public SigmoidGrad(@Const @ByRef Scope scope, @ByVal Input x,
              @ByVal Input y) { super((Pointer)null); allocate(scope, x, y); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x,
              @ByVal Input y);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output z(); public native SigmoidGrad z(Output z);
}

// Returns an element-wise indication of the sign of a number.
//
// `y = sign(x) = -1` if `x < 0`; 0 if `x == 0`; 1 if `x > 0`.
//
// For complex numbers, `y = sign(x) = x / |x|` if `x != 0`, otherwise `y = 0`.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Sign extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Sign(Pointer p) { super(p); }

  public Sign(@Const @ByRef Scope scope, @ByVal Input x) { super((Pointer)null); allocate(scope, x); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output y(); public native Sign y(Output y);
}

// Computes sin of x element-wise.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Sin extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Sin(Pointer p) { super(p); }

  public Sin(@Const @ByRef Scope scope, @ByVal Input x) { super((Pointer)null); allocate(scope, x); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output y(); public native Sin y(Output y);
}

// Multiply matrix "a" by matrix "b".
//
// The inputs must be two-dimensional matrices and the inner dimension of "a" must
// match the outer dimension of "b". This op is optimized for the case where at
// least one of "a" or "b" is sparse. The breakeven for using this versus a dense
// matrix multiply on one platform was 30% zero values in the sparse matrix.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class SparseMatMul extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SparseMatMul(Pointer p) { super(p); }

  // Optional attribute setters for SparseMatMul :
  //
  // TransposeA(bool): Defaults to false
  // TransposeB(bool): Defaults to false
  // AIsSparse(bool): Defaults to false
  // BIsSparse(bool): Defaults to false
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs TransposeA(@Cast("bool") boolean x);

    public native @ByVal Attrs TransposeB(@Cast("bool") boolean x);

    public native @ByVal Attrs AIsSparse(@Cast("bool") boolean x);

    public native @ByVal Attrs BIsSparse(@Cast("bool") boolean x);

    public native @Cast("bool") boolean transpose_a_(); public native Attrs transpose_a_(boolean transpose_a_);
    public native @Cast("bool") boolean transpose_b_(); public native Attrs transpose_b_(boolean transpose_b_);
    public native @Cast("bool") boolean a_is_sparse_(); public native Attrs a_is_sparse_(boolean a_is_sparse_);
    public native @Cast("bool") boolean b_is_sparse_(); public native Attrs b_is_sparse_(boolean b_is_sparse_);
  }
  public SparseMatMul(@Const @ByRef Scope scope, @ByVal Input a,
               @ByVal Input b) { super((Pointer)null); allocate(scope, a, b); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input a,
               @ByVal Input b);
  public SparseMatMul(@Const @ByRef Scope scope, @ByVal Input a,
               @ByVal Input b, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, a, b, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input a,
               @ByVal Input b, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs TransposeA(@Cast("bool") boolean x);
  public static native @ByVal Attrs TransposeB(@Cast("bool") boolean x);
  public static native @ByVal Attrs AIsSparse(@Cast("bool") boolean x);
  public static native @ByVal Attrs BIsSparse(@Cast("bool") boolean x);

  public native @ByRef Output product(); public native SparseMatMul product(Output product);
}

// Computes the mean along sparse segments of a tensor.
//
// Read [the section on
// Segmentation](../../api_docs/python/math_ops.md#segmentation) for an explanation
// of segments.
//
// Like `SegmentMean`, but `segment_ids` can have rank less than `data`'s first
// dimension, selecting a subset of dimension 0, specified by `indices`.
//
// Arguments:
// * scope: A Scope object
// * indices: A 1-D tensor. Has same rank as `segment_ids`.
// * segment_ids: A 1-D tensor. Values should be sorted and can be repeated.
@Namespace("tensorflow::ops") @NoOffset public static class SparseSegmentMean extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SparseSegmentMean(Pointer p) { super(p); }

  public SparseSegmentMean(@Const @ByRef Scope scope, @ByVal Input data, @ByVal Input indices,
                    @ByVal Input segment_ids) { super((Pointer)null); allocate(scope, data, indices, segment_ids); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input data, @ByVal Input indices,
                    @ByVal Input segment_ids);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native SparseSegmentMean output(Output output);
}

// Computes gradients for SparseSegmentMean.
//
// Returns tensor "output" with same shape as grad, except for dimension 0 whose
// value is output_dim0.
//
// Arguments:
// * scope: A Scope object
// * grad: gradient propagated to the SparseSegmentMean op.
// * indices: indices passed to the corresponding SparseSegmentMean op.
// * segment_ids: segment_ids passed to the corresponding SparseSegmentMean op.
// * output_dim0: dimension 0 of "data" passed to SparseSegmentMean op.
@Namespace("tensorflow::ops") @NoOffset public static class SparseSegmentMeanGrad extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SparseSegmentMeanGrad(Pointer p) { super(p); }

  public SparseSegmentMeanGrad(@Const @ByRef Scope scope,
                        @ByVal Input grad, @ByVal Input indices, @ByVal Input segment_ids,
                        @ByVal Input output_dim0) { super((Pointer)null); allocate(scope, grad, indices, segment_ids, output_dim0); }
  private native void allocate(@Const @ByRef Scope scope,
                        @ByVal Input grad, @ByVal Input indices, @ByVal Input segment_ids,
                        @ByVal Input output_dim0);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native SparseSegmentMeanGrad output(Output output);
}

// Computes the sum along sparse segments of a tensor divided by the sqrt of N.
//
// N is the size of the segment being reduced.
//
// Read [the section on
// Segmentation](../../api_docs/python/math_ops.md#segmentation) for an explanation
// of segments.
//
// Arguments:
// * scope: A Scope object
// * indices: A 1-D tensor. Has same rank as `segment_ids`.
// * segment_ids: A 1-D tensor. Values should be sorted and can be repeated.
@Namespace("tensorflow::ops") @NoOffset public static class SparseSegmentSqrtN extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SparseSegmentSqrtN(Pointer p) { super(p); }

  public SparseSegmentSqrtN(@Const @ByRef Scope scope, @ByVal Input data, @ByVal Input indices,
                     @ByVal Input segment_ids) { super((Pointer)null); allocate(scope, data, indices, segment_ids); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input data, @ByVal Input indices,
                     @ByVal Input segment_ids);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native SparseSegmentSqrtN output(Output output);
}

// Computes gradients for SparseSegmentSqrtN.
//
// Returns tensor "output" with same shape as grad, except for dimension 0 whose
// value is output_dim0.
//
// Arguments:
// * scope: A Scope object
// * grad: gradient propagated to the SparseSegmentSqrtN op.
// * indices: indices passed to the corresponding SparseSegmentSqrtN op.
// * segment_ids: segment_ids passed to the corresponding SparseSegmentSqrtN op.
// * output_dim0: dimension 0 of "data" passed to SparseSegmentSqrtN op.
@Namespace("tensorflow::ops") @NoOffset public static class SparseSegmentSqrtNGrad extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SparseSegmentSqrtNGrad(Pointer p) { super(p); }

  public SparseSegmentSqrtNGrad(@Const @ByRef Scope scope,
                         @ByVal Input grad, @ByVal Input indices, @ByVal Input segment_ids,
                         @ByVal Input output_dim0) { super((Pointer)null); allocate(scope, grad, indices, segment_ids, output_dim0); }
  private native void allocate(@Const @ByRef Scope scope,
                         @ByVal Input grad, @ByVal Input indices, @ByVal Input segment_ids,
                         @ByVal Input output_dim0);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native SparseSegmentSqrtNGrad output(Output output);
}

// Computes the sum along sparse segments of a tensor.
//
// Read [the section on
// Segmentation](../../api_docs/python/math_ops.md#segmentation) for an explanation
// of segments.
//
// Like `SegmentSum`, but `segment_ids` can have rank less than `data`'s first
// dimension, selecting a subset of dimension 0, specified by `indices`.
//
// For example:
//
// ```prettyprint
// c = tf.constant([[1,2,3,4], [-1,-2,-3,-4], [5,6,7,8]])
//
// # Select two rows, one segment.
// tf.sparse_segment_sum(c, tf.constant([0, 1]), tf.constant([0, 0]))
//   ==> [[0 0 0 0]]
//
// # Select two rows, two segment.
// tf.sparse_segment_sum(c, tf.constant([0, 1]), tf.constant([0, 1]))
//   ==> [[ 1  2  3  4]
//        [-1 -2 -3 -4]]
//
// # Select all rows, two segments.
// tf.sparse_segment_sum(c, tf.constant([0, 1, 2]), tf.constant([0, 0, 1]))
//   ==> [[0 0 0 0]
//        [5 6 7 8]]
//
// # Which is equivalent to:
// tf.segment_sum(c, tf.constant([0, 0, 1]))
// ```
//
// Arguments:
// * scope: A Scope object
// * indices: A 1-D tensor. Has same rank as `segment_ids`.
// * segment_ids: A 1-D tensor. Values should be sorted and can be repeated.
@Namespace("tensorflow::ops") @NoOffset public static class SparseSegmentSum extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SparseSegmentSum(Pointer p) { super(p); }

  public SparseSegmentSum(@Const @ByRef Scope scope, @ByVal Input data, @ByVal Input indices,
                   @ByVal Input segment_ids) { super((Pointer)null); allocate(scope, data, indices, segment_ids); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input data, @ByVal Input indices,
                   @ByVal Input segment_ids);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native SparseSegmentSum output(Output output);
}

// Computes square root of x element-wise.
//
// I.e., \\(y = \sqrt{x} = x^{1/2}\\).
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Sqrt extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Sqrt(Pointer p) { super(p); }

  public Sqrt(@Const @ByRef Scope scope, @ByVal Input x) { super((Pointer)null); allocate(scope, x); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output y(); public native Sqrt y(Output y);
}

// Computes the gradient for the sqrt of `x` wrt its input.
//
// Specifically, `grad = dy * 0.5 / y`, where `y = sqrt(x)`, and `dy`
// is the corresponding input gradient.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class SqrtGrad extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SqrtGrad(Pointer p) { super(p); }

  public SqrtGrad(@Const @ByRef Scope scope, @ByVal Input x,
           @ByVal Input y) { super((Pointer)null); allocate(scope, x, y); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x,
           @ByVal Input y);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output z(); public native SqrtGrad z(Output z);
}

// Computes square of x element-wise.
//
// I.e., \\(y = x * x = x^2\\).
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Square extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Square(Pointer p) { super(p); }

  public Square(@Const @ByRef Scope scope, @ByVal Input x) { super((Pointer)null); allocate(scope, x); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output y(); public native Square y(Output y);
}

// Returns (x - y)(x - y) element-wise.
//
// *NOTE*: `SquaredDifference` supports broadcasting. More about broadcasting
// [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class SquaredDifference extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SquaredDifference(Pointer p) { super(p); }

  public SquaredDifference(@Const @ByRef Scope scope, @ByVal Input x,
                    @ByVal Input y) { super((Pointer)null); allocate(scope, x, y); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x,
                    @ByVal Input y);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output z(); public native SquaredDifference z(Output z);
}

// Returns x - y element-wise.
//
// *NOTE*: `Sub` supports broadcasting. More about broadcasting
// [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Sub extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Sub(Pointer p) { super(p); }

  public Sub(@Const @ByRef Scope scope, @ByVal Input x,
      @ByVal Input y) { super((Pointer)null); allocate(scope, x, y); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x,
      @ByVal Input y);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output z(); public native Sub z(Output z);
}

// Computes the sum of elements across dimensions of a tensor.
//
// Reduces `input` along the dimensions given in `reduction_indices`. Unless
// `keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
// `reduction_indices`. If `keep_dims` is true, the reduced dimensions are
// retained with length 1.
//
// Arguments:
// * scope: A Scope object
// * input: The tensor to reduce.
// * reduction_indices: The dimensions to reduce.
@Namespace("tensorflow::ops") @NoOffset public static class Sum extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Sum(Pointer p) { super(p); }

  // Optional attribute setters for Sum :
  //
  // KeepDims(bool): Defaults to false
  //     If true, retain reduced dimensions with length 1.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs KeepDims(@Cast("bool") boolean x);

    public native @Cast("bool") boolean keep_dims_(); public native Attrs keep_dims_(boolean keep_dims_);
  }
  public Sum(@Const @ByRef Scope scope, @ByVal Input input,
      @ByVal Input reduction_indices) { super((Pointer)null); allocate(scope, input, reduction_indices); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
      @ByVal Input reduction_indices);
  public Sum(@Const @ByRef Scope scope, @ByVal Input input,
      @ByVal Input reduction_indices, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, reduction_indices, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
      @ByVal Input reduction_indices, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs KeepDims(@Cast("bool") boolean x);

  public native @ByRef Output output(); public native Sum output(Output output);
}

// Computes tan of x element-wise.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Tan extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Tan(Pointer p) { super(p); }

  public Tan(@Const @ByRef Scope scope, @ByVal Input x) { super((Pointer)null); allocate(scope, x); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output y(); public native Tan y(Output y);
}

// Computes hyperbolic tangent of `x` element-wise.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Tanh extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Tanh(Pointer p) { super(p); }

  public Tanh(@Const @ByRef Scope scope, @ByVal Input x) { super((Pointer)null); allocate(scope, x); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output y(); public native Tanh y(Output y);
}

// Computes the gradient for the tanh of `x` wrt its input.
//
// Specifically, `grad = dy * (1 - y*y)`, where `y = tanh(x)`, and `dy`
// is the corresponding input gradient.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class TanhGrad extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TanhGrad(Pointer p) { super(p); }

  public TanhGrad(@Const @ByRef Scope scope, @ByVal Input x,
           @ByVal Input y) { super((Pointer)null); allocate(scope, x, y); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x,
           @ByVal Input y);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output z(); public native TanhGrad z(Output z);
}

// Computes the sum along segments of a tensor.
//
// Read [the section on
// Segmentation](../../api_docs/python/math_ops.md#segmentation) for an explanation
// of segments.
//
// Computes a tensor such that
// `(output[i] = sum_{j...} data[j...]` where the sum is over tuples `j...` such
// that `segment_ids[j...] == i`.  Unlike `SegmentSum`, `segment_ids`
// need not be sorted and need not cover all values in the full
// range of valid values.
//
// If the sum is empty for a given segment ID `i`, `output[i] = 0`.
//
// `num_segments` should equal the number of distinct segment IDs.
//
// <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
// <img style="width:100%" src="../../images/UnsortedSegmentSum.png" alt>
// </div>
//
// Arguments:
// * scope: A Scope object
// * segment_ids: A tensor whose shape is a prefix of `data.shape`.
@Namespace("tensorflow::ops") @NoOffset public static class UnsortedSegmentSum extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public UnsortedSegmentSum(Pointer p) { super(p); }

  public UnsortedSegmentSum(@Const @ByRef Scope scope, @ByVal Input data, @ByVal Input segment_ids,
                     @ByVal Input num_segments) { super((Pointer)null); allocate(scope, data, segment_ids, num_segments); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input data, @ByVal Input segment_ids,
                     @ByVal Input num_segments);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native UnsortedSegmentSum output(Output output);
}

// Compute the Hurwitz zeta function \\(\zeta(x, q)\\).
//
// The Hurwitz zeta function is defined as:
//
// ```
// \zeta(x, q) = \sum_{n=0}^{\infty} (q + n)^{-x}
// ```
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Zeta extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Zeta(Pointer p) { super(p); }

  public Zeta(@Const @ByRef Scope scope, @ByVal Input x,
       @ByVal Input q) { super((Pointer)null); allocate(scope, x, q); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input x,
       @ByVal Input q);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output z(); public native Zeta z(Output z);
}

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_MATH_OPS_H_


// Parsed from tensorflow/cc/ops/nn_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_NN_OPS_H_
// #define TENSORFLOW_CC_OPS_NN_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"

// Performs average pooling on the input.
//
// Each entry in `output` is the mean of the corresponding size `ksize`
// window in `value`.
//
// Arguments:
// * scope: A Scope object
// * value: 4-D with shape `[batch, height, width, channels]`.
// * ksize:
//     The size of the sliding window for each dimension of `value`.
// * strides:
//     The stride of the sliding window for each dimension of `value`.
// * padding:
//     The type of padding algorithm to use.
@Namespace("tensorflow::ops") @NoOffset public static class AvgPool extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public AvgPool(Pointer p) { super(p); }

  // Optional attribute setters for AvgPool :
  //
  // DataFormat(StringPiece): Defaults to "NHWC"
  //     Specify the data format of the input and output data. With the
  // default format "NHWC", the data is stored in the order of:
  //     [batch, in_height, in_width, in_channels].
  // Alternatively, the format could be "NCHW", the data storage order of:
  //     [batch, in_channels, in_height, in_width].
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs DataFormat(@StringPiece BytePointer x);
    public native @ByVal Attrs DataFormat(@StringPiece String x);

    public native @StringPiece BytePointer data_format_(); public native Attrs data_format_(BytePointer data_format_);
  }
  public AvgPool(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides,
          @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, value, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides,
          @StringPiece BytePointer padding);
  public AvgPool(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides,
          @StringPiece String padding) { super((Pointer)null); allocate(scope, value, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides,
          @StringPiece String padding);
  public AvgPool(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice int[] ksize, @ArraySlice int[] strides,
          @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, value, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice int[] ksize, @ArraySlice int[] strides,
          @StringPiece BytePointer padding);
  public AvgPool(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides,
          @StringPiece String padding) { super((Pointer)null); allocate(scope, value, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides,
          @StringPiece String padding);
  public AvgPool(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides,
          @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, value, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides,
          @StringPiece BytePointer padding);
  public AvgPool(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice int[] ksize, @ArraySlice int[] strides,
          @StringPiece String padding) { super((Pointer)null); allocate(scope, value, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice int[] ksize, @ArraySlice int[] strides,
          @StringPiece String padding);
  public AvgPool(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides,
          @StringPiece BytePointer padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, value, ksize, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides,
          @StringPiece BytePointer padding, @Const @ByRef Attrs attrs);
  public AvgPool(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides,
          @StringPiece String padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, value, ksize, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides,
          @StringPiece String padding, @Const @ByRef Attrs attrs);
  public AvgPool(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice int[] ksize, @ArraySlice int[] strides,
          @StringPiece BytePointer padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, value, ksize, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice int[] ksize, @ArraySlice int[] strides,
          @StringPiece BytePointer padding, @Const @ByRef Attrs attrs);
  public AvgPool(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides,
          @StringPiece String padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, value, ksize, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides,
          @StringPiece String padding, @Const @ByRef Attrs attrs);
  public AvgPool(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides,
          @StringPiece BytePointer padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, value, ksize, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides,
          @StringPiece BytePointer padding, @Const @ByRef Attrs attrs);
  public AvgPool(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice int[] ksize, @ArraySlice int[] strides,
          @StringPiece String padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, value, ksize, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice int[] ksize, @ArraySlice int[] strides,
          @StringPiece String padding, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs DataFormat(@StringPiece BytePointer x);
  public static native @ByVal Attrs DataFormat(@StringPiece String x);

  public native @ByRef Output output(); public native AvgPool output(Output output);
}

// Performs 3D average pooling on the input.
//
// Arguments:
// * scope: A Scope object
// * input: Shape `[batch, depth, rows, cols, channels]` tensor to pool over.
// * ksize:
//     1-D tensor of length 5. The size of the window for each dimension of
// the input tensor. Must have `ksize[0] = ksize[4] = 1`.
// * strides:
//     1-D tensor of length 5. The stride of the sliding window for each
// dimension of `input`. Must have `strides[0] = strides[4] = 1`.
// * padding:
//     The type of padding algorithm to use.
@Namespace("tensorflow::ops") @NoOffset public static class AvgPool3D extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public AvgPool3D(Pointer p) { super(p); }

  public AvgPool3D(@Const @ByRef Scope scope, @ByVal Input input,
            @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
            @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides, @StringPiece BytePointer padding);
  public AvgPool3D(@Const @ByRef Scope scope, @ByVal Input input,
            @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, input, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
            @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides, @StringPiece String padding);
  public AvgPool3D(@Const @ByRef Scope scope, @ByVal Input input,
            @ArraySlice int[] ksize, @ArraySlice int[] strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
            @ArraySlice int[] ksize, @ArraySlice int[] strides, @StringPiece BytePointer padding);
  public AvgPool3D(@Const @ByRef Scope scope, @ByVal Input input,
            @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, input, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
            @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides, @StringPiece String padding);
  public AvgPool3D(@Const @ByRef Scope scope, @ByVal Input input,
            @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
            @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides, @StringPiece BytePointer padding);
  public AvgPool3D(@Const @ByRef Scope scope, @ByVal Input input,
            @ArraySlice int[] ksize, @ArraySlice int[] strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, input, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
            @ArraySlice int[] ksize, @ArraySlice int[] strides, @StringPiece String padding);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native AvgPool3D output(Output output);
}

// Computes gradients of average pooling function.
//
// Arguments:
// * scope: A Scope object
// * orig_input_shape: The original input dimensions.
// * grad: Output backprop of shape `[batch, depth, rows, cols, channels]`.
// * ksize:
//     1-D tensor of length 5. The size of the window for each dimension of
// the input tensor. Must have `ksize[0] = ksize[4] = 1`.
// * strides:
//     1-D tensor of length 5. The stride of the sliding window for each
// dimension of `input`. Must have `strides[0] = strides[4] = 1`.
// * padding:
//     The type of padding algorithm to use.
@Namespace("tensorflow::ops") @NoOffset public static class AvgPool3DGrad extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public AvgPool3DGrad(Pointer p) { super(p); }

  public AvgPool3DGrad(@Const @ByRef Scope scope, @ByVal Input orig_input_shape, @ByVal Input grad, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides,
                @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, orig_input_shape, grad, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input orig_input_shape, @ByVal Input grad, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides,
                @StringPiece BytePointer padding);
  public AvgPool3DGrad(@Const @ByRef Scope scope, @ByVal Input orig_input_shape, @ByVal Input grad, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides,
                @StringPiece String padding) { super((Pointer)null); allocate(scope, orig_input_shape, grad, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input orig_input_shape, @ByVal Input grad, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides,
                @StringPiece String padding);
  public AvgPool3DGrad(@Const @ByRef Scope scope, @ByVal Input orig_input_shape, @ByVal Input grad, @ArraySlice int[] ksize, @ArraySlice int[] strides,
                @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, orig_input_shape, grad, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input orig_input_shape, @ByVal Input grad, @ArraySlice int[] ksize, @ArraySlice int[] strides,
                @StringPiece BytePointer padding);
  public AvgPool3DGrad(@Const @ByRef Scope scope, @ByVal Input orig_input_shape, @ByVal Input grad, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides,
                @StringPiece String padding) { super((Pointer)null); allocate(scope, orig_input_shape, grad, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input orig_input_shape, @ByVal Input grad, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides,
                @StringPiece String padding);
  public AvgPool3DGrad(@Const @ByRef Scope scope, @ByVal Input orig_input_shape, @ByVal Input grad, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides,
                @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, orig_input_shape, grad, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input orig_input_shape, @ByVal Input grad, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides,
                @StringPiece BytePointer padding);
  public AvgPool3DGrad(@Const @ByRef Scope scope, @ByVal Input orig_input_shape, @ByVal Input grad, @ArraySlice int[] ksize, @ArraySlice int[] strides,
                @StringPiece String padding) { super((Pointer)null); allocate(scope, orig_input_shape, grad, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input orig_input_shape, @ByVal Input grad, @ArraySlice int[] ksize, @ArraySlice int[] strides,
                @StringPiece String padding);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native AvgPool3DGrad output(Output output);
}

// Computes gradients of the average pooling function.
//
// Arguments:
// * scope: A Scope object
// * orig_input_shape: 1-D.  Shape of the original input to `avg_pool`.
// * grad: 4-D with shape `[batch, height, width, channels]`.  Gradients w.r.t.
// the output of `avg_pool`.
// * ksize:
//     The size of the sliding window for each dimension of the input.
// * strides:
//     The stride of the sliding window for each dimension of the input.
// * padding:
//     The type of padding algorithm to use.
@Namespace("tensorflow::ops") @NoOffset public static class AvgPoolGrad extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public AvgPoolGrad(Pointer p) { super(p); }

  // Optional attribute setters for AvgPoolGrad :
  //
  // DataFormat(StringPiece): Defaults to "NHWC"
  //     Specify the data format of the input and output data. With the
  // default format "NHWC", the data is stored in the order of:
  //     [batch, in_height, in_width, in_channels].
  // Alternatively, the format could be "NCHW", the data storage order of:
  //     [batch, in_channels, in_height, in_width].
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs DataFormat(@StringPiece BytePointer x);
    public native @ByVal Attrs DataFormat(@StringPiece String x);

    public native @StringPiece BytePointer data_format_(); public native Attrs data_format_(BytePointer data_format_);
  }
  public AvgPoolGrad(@Const @ByRef Scope scope, @ByVal Input orig_input_shape, @ByVal Input grad, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides,
              @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, orig_input_shape, grad, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input orig_input_shape, @ByVal Input grad, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides,
              @StringPiece BytePointer padding);
  public AvgPoolGrad(@Const @ByRef Scope scope, @ByVal Input orig_input_shape, @ByVal Input grad, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides,
              @StringPiece String padding) { super((Pointer)null); allocate(scope, orig_input_shape, grad, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input orig_input_shape, @ByVal Input grad, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides,
              @StringPiece String padding);
  public AvgPoolGrad(@Const @ByRef Scope scope, @ByVal Input orig_input_shape, @ByVal Input grad, @ArraySlice int[] ksize, @ArraySlice int[] strides,
              @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, orig_input_shape, grad, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input orig_input_shape, @ByVal Input grad, @ArraySlice int[] ksize, @ArraySlice int[] strides,
              @StringPiece BytePointer padding);
  public AvgPoolGrad(@Const @ByRef Scope scope, @ByVal Input orig_input_shape, @ByVal Input grad, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides,
              @StringPiece String padding) { super((Pointer)null); allocate(scope, orig_input_shape, grad, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input orig_input_shape, @ByVal Input grad, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides,
              @StringPiece String padding);
  public AvgPoolGrad(@Const @ByRef Scope scope, @ByVal Input orig_input_shape, @ByVal Input grad, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides,
              @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, orig_input_shape, grad, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input orig_input_shape, @ByVal Input grad, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides,
              @StringPiece BytePointer padding);
  public AvgPoolGrad(@Const @ByRef Scope scope, @ByVal Input orig_input_shape, @ByVal Input grad, @ArraySlice int[] ksize, @ArraySlice int[] strides,
              @StringPiece String padding) { super((Pointer)null); allocate(scope, orig_input_shape, grad, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input orig_input_shape, @ByVal Input grad, @ArraySlice int[] ksize, @ArraySlice int[] strides,
              @StringPiece String padding);
  public AvgPoolGrad(@Const @ByRef Scope scope, @ByVal Input orig_input_shape, @ByVal Input grad, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides,
              @StringPiece BytePointer padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, orig_input_shape, grad, ksize, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input orig_input_shape, @ByVal Input grad, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides,
              @StringPiece BytePointer padding, @Const @ByRef Attrs attrs);
  public AvgPoolGrad(@Const @ByRef Scope scope, @ByVal Input orig_input_shape, @ByVal Input grad, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides,
              @StringPiece String padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, orig_input_shape, grad, ksize, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input orig_input_shape, @ByVal Input grad, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides,
              @StringPiece String padding, @Const @ByRef Attrs attrs);
  public AvgPoolGrad(@Const @ByRef Scope scope, @ByVal Input orig_input_shape, @ByVal Input grad, @ArraySlice int[] ksize, @ArraySlice int[] strides,
              @StringPiece BytePointer padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, orig_input_shape, grad, ksize, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input orig_input_shape, @ByVal Input grad, @ArraySlice int[] ksize, @ArraySlice int[] strides,
              @StringPiece BytePointer padding, @Const @ByRef Attrs attrs);
  public AvgPoolGrad(@Const @ByRef Scope scope, @ByVal Input orig_input_shape, @ByVal Input grad, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides,
              @StringPiece String padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, orig_input_shape, grad, ksize, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input orig_input_shape, @ByVal Input grad, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides,
              @StringPiece String padding, @Const @ByRef Attrs attrs);
  public AvgPoolGrad(@Const @ByRef Scope scope, @ByVal Input orig_input_shape, @ByVal Input grad, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides,
              @StringPiece BytePointer padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, orig_input_shape, grad, ksize, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input orig_input_shape, @ByVal Input grad, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides,
              @StringPiece BytePointer padding, @Const @ByRef Attrs attrs);
  public AvgPoolGrad(@Const @ByRef Scope scope, @ByVal Input orig_input_shape, @ByVal Input grad, @ArraySlice int[] ksize, @ArraySlice int[] strides,
              @StringPiece String padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, orig_input_shape, grad, ksize, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input orig_input_shape, @ByVal Input grad, @ArraySlice int[] ksize, @ArraySlice int[] strides,
              @StringPiece String padding, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs DataFormat(@StringPiece BytePointer x);
  public static native @ByVal Attrs DataFormat(@StringPiece String x);

  public native @ByRef Output output(); public native AvgPoolGrad output(Output output);
}

// Batch normalization.
//
// DEPRECATED at GraphDef version 9:
// Use tf.nn.batch_normalization().
//
// This op is deprecated. Prefer `tf.nn.batch_normalization`.
//
// Arguments:
// * scope: A Scope object
// * t: A 4D input Tensor.
// * m: A 1D mean Tensor with size matching the last dimension of t.
// This is the first output from tf.nn.moments,
// or a saved moving average thereof.
// * v: A 1D variance Tensor with size matching the last dimension of t.
// This is the second output from tf.nn.moments,
// or a saved moving average thereof.
// * beta: A 1D beta Tensor with size matching the last dimension of t.
// An offset to be added to the normalized tensor.
// * gamma: A 1D gamma Tensor with size matching the last dimension of t.
// If "scale_after_normalization" is true, this tensor will be multiplied
// with the normalized tensor.
// * variance_epsilon:
//     A small float number to avoid dividing by 0.
// * scale_after_normalization:
//     A bool indicating whether the resulted tensor
// needs to be multiplied with gamma.
@Namespace("tensorflow::ops") @NoOffset public static class BatchNormWithGlobalNormalization extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public BatchNormWithGlobalNormalization(Pointer p) { super(p); }

  public BatchNormWithGlobalNormalization(@Const @ByRef Scope scope,
                                   @ByVal Input t,
                                   @ByVal Input m,
                                   @ByVal Input v,
                                   @ByVal Input beta,
                                   @ByVal Input gamma, float variance_epsilon, @Cast("bool") boolean scale_after_normalization) { super((Pointer)null); allocate(scope, t, m, v, beta, gamma, variance_epsilon, scale_after_normalization); }
  private native void allocate(@Const @ByRef Scope scope,
                                   @ByVal Input t,
                                   @ByVal Input m,
                                   @ByVal Input v,
                                   @ByVal Input beta,
                                   @ByVal Input gamma, float variance_epsilon, @Cast("bool") boolean scale_after_normalization);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output result(); public native BatchNormWithGlobalNormalization result(Output result);
}

// Gradients for batch normalization.
//
// DEPRECATED at GraphDef version 9:
// Use tf.nn.batch_normalization().
//
// This op is deprecated. See `tf.nn.batch_normalization`.
//
// Arguments:
// * scope: A Scope object
// * t: A 4D input Tensor.
// * m: A 1D mean Tensor with size matching the last dimension of t.
// This is the first output from tf.nn.moments,
// or a saved moving average thereof.
// * v: A 1D variance Tensor with size matching the last dimension of t.
// This is the second output from tf.nn.moments,
// or a saved moving average thereof.
// * gamma: A 1D gamma Tensor with size matching the last dimension of t.
// If "scale_after_normalization" is true, this Tensor will be multiplied
// with the normalized Tensor.
// * backprop: 4D backprop Tensor.
// * variance_epsilon:
//     A small float number to avoid dividing by 0.
// * scale_after_normalization:
//     A bool indicating whether the resulted tensor
// needs to be multiplied with gamma.
@Namespace("tensorflow::ops") @NoOffset public static class BatchNormWithGlobalNormalizationGrad extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public BatchNormWithGlobalNormalizationGrad(Pointer p) { super(p); }

  public BatchNormWithGlobalNormalizationGrad(@Const @ByRef Scope scope,
                                       @ByVal Input t,
                                       @ByVal Input m,
                                       @ByVal Input v,
                                       @ByVal Input gamma,
                                       @ByVal Input backprop, float variance_epsilon, @Cast("bool") boolean scale_after_normalization) { super((Pointer)null); allocate(scope, t, m, v, gamma, backprop, variance_epsilon, scale_after_normalization); }
  private native void allocate(@Const @ByRef Scope scope,
                                       @ByVal Input t,
                                       @ByVal Input m,
                                       @ByVal Input v,
                                       @ByVal Input gamma,
                                       @ByVal Input backprop, float variance_epsilon, @Cast("bool") boolean scale_after_normalization);

  public native @ByRef Output dx(); public native BatchNormWithGlobalNormalizationGrad dx(Output dx);
  public native @ByRef Output dm(); public native BatchNormWithGlobalNormalizationGrad dm(Output dm);
  public native @ByRef Output dv(); public native BatchNormWithGlobalNormalizationGrad dv(Output dv);
  public native @ByRef Output db(); public native BatchNormWithGlobalNormalizationGrad db(Output db);
  public native @ByRef Output dg(); public native BatchNormWithGlobalNormalizationGrad dg(Output dg);
}

// Adds `bias` to `value`.
//
// This is a special case of `tf.add` where `bias` is restricted to be 1-D.
// Broadcasting is supported, so `value` may have any number of dimensions.
//
// Arguments:
// * scope: A Scope object
// * value: Any number of dimensions.
// * bias: 1-D with size the last dimension of `value`.
@Namespace("tensorflow::ops") @NoOffset public static class BiasAdd extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public BiasAdd(Pointer p) { super(p); }

  // Optional attribute setters for BiasAdd :
  //
  // DataFormat(StringPiece): Defaults to "NHWC"
  //     Specify the data format of the input and output data. With the
  // default format "NHWC", the bias tensor will be added to the last dimension
  // of the value tensor.
  // Alternatively, the format could be "NCHW", the data storage order of:
  //     [batch, in_channels, in_height, in_width].
  // The tensor will be added to "in_channels", the third-to-the-last
  //     dimension.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs DataFormat(@StringPiece BytePointer x);
    public native @ByVal Attrs DataFormat(@StringPiece String x);

    public native @StringPiece BytePointer data_format_(); public native Attrs data_format_(BytePointer data_format_);
  }
  public BiasAdd(@Const @ByRef Scope scope, @ByVal Input value,
          @ByVal Input bias) { super((Pointer)null); allocate(scope, value, bias); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input value,
          @ByVal Input bias);
  public BiasAdd(@Const @ByRef Scope scope, @ByVal Input value,
          @ByVal Input bias, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, value, bias, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input value,
          @ByVal Input bias, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs DataFormat(@StringPiece BytePointer x);
  public static native @ByVal Attrs DataFormat(@StringPiece String x);

  public native @ByRef Output output(); public native BiasAdd output(Output output);
}

// The backward operation for "BiasAdd" on the "bias" tensor.
//
// It accumulates all the values from out_backprop into the feature dimension.
// For NHWC data format, the feature dimension is the last. For NCHW data format,
// the feature dimension is the third-to-last.
//
// Arguments:
// * scope: A Scope object
// * out_backprop: Any number of dimensions.
@Namespace("tensorflow::ops") @NoOffset public static class BiasAddGrad extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public BiasAddGrad(Pointer p) { super(p); }

  // Optional attribute setters for BiasAddGrad :
  //
  // DataFormat(StringPiece): Defaults to "NHWC"
  //     Specify the data format of the input and output data. With the
  // default format "NHWC", the bias tensor will be added to the last dimension
  // of the value tensor.
  // Alternatively, the format could be "NCHW", the data storage order of:
  //     [batch, in_channels, in_height, in_width].
  // The tensor will be added to "in_channels", the third-to-the-last
  //     dimension.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs DataFormat(@StringPiece BytePointer x);
    public native @ByVal Attrs DataFormat(@StringPiece String x);

    public native @StringPiece BytePointer data_format_(); public native Attrs data_format_(BytePointer data_format_);
  }
  public BiasAddGrad(@Const @ByRef Scope scope, @ByVal Input out_backprop) { super((Pointer)null); allocate(scope, out_backprop); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input out_backprop);
  public BiasAddGrad(@Const @ByRef Scope scope, @ByVal Input out_backprop, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, out_backprop, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input out_backprop, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs DataFormat(@StringPiece BytePointer x);
  public static native @ByVal Attrs DataFormat(@StringPiece String x);

  public native @ByRef Output output(); public native BiasAddGrad output(Output output);
}

// Adds `bias` to `value`.
//
// This is a deprecated version of BiasAdd and will be soon removed.
//
// This is a special case of `tf.add` where `bias` is restricted to be 1-D.
// Broadcasting is supported, so `value` may have any number of dimensions.
//
// Arguments:
// * scope: A Scope object
// * value: Any number of dimensions.
// * bias: 1-D with size the last dimension of `value`.
@Namespace("tensorflow::ops") @NoOffset public static class BiasAddV1 extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public BiasAddV1(Pointer p) { super(p); }

  public BiasAddV1(@Const @ByRef Scope scope, @ByVal Input value,
            @ByVal Input bias) { super((Pointer)null); allocate(scope, value, bias); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input value,
            @ByVal Input bias);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native BiasAddV1 output(Output output);
}

// Computes a 2-D convolution given 4-D `input` and `filter` tensors.
//
// Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
// and a filter / kernel tensor of shape
// `[filter_height, filter_width, in_channels, out_channels]`, this op
// performs the following:
//
// 1. Flattens the filter to a 2-D matrix with shape
//    `[filter_height * filter_width * in_channels, output_channels]`.
// 2. Extracts image patches from the input tensor to form a *virtual*
//    tensor of shape `[batch, out_height, out_width,
//    filter_height * filter_width * in_channels]`.
// 3. For each patch, right-multiplies the filter matrix and the image patch
//    vector.
//
// In detail, with the default NHWC format,
//
//     output[b, i, j, k] =
//         sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q] *
//                         filter[di, dj, q, k]
//
// Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
// horizontal and vertices strides, `strides = [1, stride, stride, 1]`.
//
// Arguments:
// * scope: A Scope object
// * strides:
//     1-D of length 4.  The stride of the sliding window for each dimension
// of `input`. Must be in the same order as the dimension specified with format.
// * padding:
//     The type of padding algorithm to use.
@Namespace("tensorflow::ops") @NoOffset public static class Conv2D extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Conv2D(Pointer p) { super(p); }

  // Optional attribute setters for Conv2D :
  //
  // UseCudnnOnGpu(bool): Defaults to true
  // DataFormat(StringPiece): Defaults to "NHWC"
  //     Specify the data format of the input and output data. With the
  // default format "NHWC", the data is stored in the order of:
  //     [batch, in_height, in_width, in_channels].
  // Alternatively, the format could be "NCHW", the data storage order of:
  //     [batch, in_channels, in_height, in_width].
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs UseCudnnOnGpu(@Cast("bool") boolean x);

    public native @ByVal Attrs DataFormat(@StringPiece BytePointer x);
    public native @ByVal Attrs DataFormat(@StringPiece String x);

    public native @Cast("bool") boolean use_cudnn_on_gpu_(); public native Attrs use_cudnn_on_gpu_(boolean use_cudnn_on_gpu_);
    public native @StringPiece BytePointer data_format_(); public native Attrs data_format_(BytePointer data_format_);
  }
  public Conv2D(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input filter, @ArraySlice IntPointer strides,
         @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, filter, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input filter, @ArraySlice IntPointer strides,
         @StringPiece BytePointer padding);
  public Conv2D(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input filter, @ArraySlice IntBuffer strides,
         @StringPiece String padding) { super((Pointer)null); allocate(scope, input, filter, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input filter, @ArraySlice IntBuffer strides,
         @StringPiece String padding);
  public Conv2D(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input filter, @ArraySlice int[] strides,
         @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, filter, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input filter, @ArraySlice int[] strides,
         @StringPiece BytePointer padding);
  public Conv2D(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input filter, @ArraySlice IntPointer strides,
         @StringPiece String padding) { super((Pointer)null); allocate(scope, input, filter, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input filter, @ArraySlice IntPointer strides,
         @StringPiece String padding);
  public Conv2D(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input filter, @ArraySlice IntBuffer strides,
         @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, filter, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input filter, @ArraySlice IntBuffer strides,
         @StringPiece BytePointer padding);
  public Conv2D(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input filter, @ArraySlice int[] strides,
         @StringPiece String padding) { super((Pointer)null); allocate(scope, input, filter, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input filter, @ArraySlice int[] strides,
         @StringPiece String padding);
  public Conv2D(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input filter, @ArraySlice IntPointer strides,
         @StringPiece BytePointer padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, filter, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input filter, @ArraySlice IntPointer strides,
         @StringPiece BytePointer padding, @Const @ByRef Attrs attrs);
  public Conv2D(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input filter, @ArraySlice IntBuffer strides,
         @StringPiece String padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, filter, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input filter, @ArraySlice IntBuffer strides,
         @StringPiece String padding, @Const @ByRef Attrs attrs);
  public Conv2D(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input filter, @ArraySlice int[] strides,
         @StringPiece BytePointer padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, filter, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input filter, @ArraySlice int[] strides,
         @StringPiece BytePointer padding, @Const @ByRef Attrs attrs);
  public Conv2D(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input filter, @ArraySlice IntPointer strides,
         @StringPiece String padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, filter, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input filter, @ArraySlice IntPointer strides,
         @StringPiece String padding, @Const @ByRef Attrs attrs);
  public Conv2D(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input filter, @ArraySlice IntBuffer strides,
         @StringPiece BytePointer padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, filter, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input filter, @ArraySlice IntBuffer strides,
         @StringPiece BytePointer padding, @Const @ByRef Attrs attrs);
  public Conv2D(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input filter, @ArraySlice int[] strides,
         @StringPiece String padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, filter, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input filter, @ArraySlice int[] strides,
         @StringPiece String padding, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs UseCudnnOnGpu(@Cast("bool") boolean x);
  public static native @ByVal Attrs DataFormat(@StringPiece BytePointer x);
  public static native @ByVal Attrs DataFormat(@StringPiece String x);

  public native @ByRef Output output(); public native Conv2D output(Output output);
}

// Computes the gradients of convolution with respect to the filter.
//
// Arguments:
// * scope: A Scope object
// * input: 4-D with shape `[batch, in_height, in_width, in_channels]`.
// * filter_sizes: An integer vector representing the tensor shape of `filter`,
// where `filter` is a 4-D
// `[filter_height, filter_width, in_channels, out_channels]` tensor.
// * out_backprop: 4-D with shape `[batch, out_height, out_width, out_channels]`.
// Gradients w.r.t. the output of the convolution.
// * strides:
//     The stride of the sliding window for each dimension of the input
// of the convolution. Must be in the same order as the dimension specified with
// format.
// * padding:
//     The type of padding algorithm to use.
@Namespace("tensorflow::ops") @NoOffset public static class Conv2DBackpropFilter extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Conv2DBackpropFilter(Pointer p) { super(p); }

  // Optional attribute setters for Conv2DBackpropFilter :
  //
  // UseCudnnOnGpu(bool): Defaults to true
  // DataFormat(StringPiece): Defaults to "NHWC"
  //     Specify the data format of the input and output data. With the
  // default format "NHWC", the data is stored in the order of:
  //     [batch, in_height, in_width, in_channels].
  // Alternatively, the format could be "NCHW", the data storage order of:
  //     [batch, in_channels, in_height, in_width].
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs UseCudnnOnGpu(@Cast("bool") boolean x);

    public native @ByVal Attrs DataFormat(@StringPiece BytePointer x);
    public native @ByVal Attrs DataFormat(@StringPiece String x);

    public native @Cast("bool") boolean use_cudnn_on_gpu_(); public native Attrs use_cudnn_on_gpu_(boolean use_cudnn_on_gpu_);
    public native @StringPiece BytePointer data_format_(); public native Attrs data_format_(BytePointer data_format_);
  }
  public Conv2DBackpropFilter(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter_sizes,
                       @ByVal Input out_backprop, @ArraySlice IntPointer strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, filter_sizes, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter_sizes,
                       @ByVal Input out_backprop, @ArraySlice IntPointer strides, @StringPiece BytePointer padding);
  public Conv2DBackpropFilter(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter_sizes,
                       @ByVal Input out_backprop, @ArraySlice IntBuffer strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, input, filter_sizes, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter_sizes,
                       @ByVal Input out_backprop, @ArraySlice IntBuffer strides, @StringPiece String padding);
  public Conv2DBackpropFilter(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter_sizes,
                       @ByVal Input out_backprop, @ArraySlice int[] strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, filter_sizes, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter_sizes,
                       @ByVal Input out_backprop, @ArraySlice int[] strides, @StringPiece BytePointer padding);
  public Conv2DBackpropFilter(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter_sizes,
                       @ByVal Input out_backprop, @ArraySlice IntPointer strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, input, filter_sizes, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter_sizes,
                       @ByVal Input out_backprop, @ArraySlice IntPointer strides, @StringPiece String padding);
  public Conv2DBackpropFilter(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter_sizes,
                       @ByVal Input out_backprop, @ArraySlice IntBuffer strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, filter_sizes, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter_sizes,
                       @ByVal Input out_backprop, @ArraySlice IntBuffer strides, @StringPiece BytePointer padding);
  public Conv2DBackpropFilter(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter_sizes,
                       @ByVal Input out_backprop, @ArraySlice int[] strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, input, filter_sizes, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter_sizes,
                       @ByVal Input out_backprop, @ArraySlice int[] strides, @StringPiece String padding);
  public Conv2DBackpropFilter(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter_sizes,
                       @ByVal Input out_backprop, @ArraySlice IntPointer strides, @StringPiece BytePointer padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, filter_sizes, out_backprop, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter_sizes,
                       @ByVal Input out_backprop, @ArraySlice IntPointer strides, @StringPiece BytePointer padding, @Const @ByRef Attrs attrs);
  public Conv2DBackpropFilter(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter_sizes,
                       @ByVal Input out_backprop, @ArraySlice IntBuffer strides, @StringPiece String padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, filter_sizes, out_backprop, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter_sizes,
                       @ByVal Input out_backprop, @ArraySlice IntBuffer strides, @StringPiece String padding, @Const @ByRef Attrs attrs);
  public Conv2DBackpropFilter(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter_sizes,
                       @ByVal Input out_backprop, @ArraySlice int[] strides, @StringPiece BytePointer padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, filter_sizes, out_backprop, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter_sizes,
                       @ByVal Input out_backprop, @ArraySlice int[] strides, @StringPiece BytePointer padding, @Const @ByRef Attrs attrs);
  public Conv2DBackpropFilter(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter_sizes,
                       @ByVal Input out_backprop, @ArraySlice IntPointer strides, @StringPiece String padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, filter_sizes, out_backprop, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter_sizes,
                       @ByVal Input out_backprop, @ArraySlice IntPointer strides, @StringPiece String padding, @Const @ByRef Attrs attrs);
  public Conv2DBackpropFilter(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter_sizes,
                       @ByVal Input out_backprop, @ArraySlice IntBuffer strides, @StringPiece BytePointer padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, filter_sizes, out_backprop, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter_sizes,
                       @ByVal Input out_backprop, @ArraySlice IntBuffer strides, @StringPiece BytePointer padding, @Const @ByRef Attrs attrs);
  public Conv2DBackpropFilter(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter_sizes,
                       @ByVal Input out_backprop, @ArraySlice int[] strides, @StringPiece String padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, filter_sizes, out_backprop, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter_sizes,
                       @ByVal Input out_backprop, @ArraySlice int[] strides, @StringPiece String padding, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs UseCudnnOnGpu(@Cast("bool") boolean x);
  public static native @ByVal Attrs DataFormat(@StringPiece BytePointer x);
  public static native @ByVal Attrs DataFormat(@StringPiece String x);

  public native @ByRef Output output(); public native Conv2DBackpropFilter output(Output output);
}

// Computes the gradients of convolution with respect to the input.
//
// Arguments:
// * scope: A Scope object
// * input_sizes: An integer vector representing the shape of `input`,
// where `input` is a 4-D `[batch, height, width, channels]` tensor.
// * filter: 4-D with shape
// `[filter_height, filter_width, in_channels, out_channels]`.
// * out_backprop: 4-D with shape `[batch, out_height, out_width, out_channels]`.
// Gradients w.r.t. the output of the convolution.
// * strides:
//     The stride of the sliding window for each dimension of the input
// of the convolution. Must be in the same order as the dimension specified with
// format.
// * padding:
//     The type of padding algorithm to use.
@Namespace("tensorflow::ops") @NoOffset public static class Conv2DBackpropInput extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Conv2DBackpropInput(Pointer p) { super(p); }

  // Optional attribute setters for Conv2DBackpropInput :
  //
  // UseCudnnOnGpu(bool): Defaults to true
  // DataFormat(StringPiece): Defaults to "NHWC"
  //     Specify the data format of the input and output data. With the
  // default format "NHWC", the data is stored in the order of:
  //     [batch, in_height, in_width, in_channels].
  // Alternatively, the format could be "NCHW", the data storage order of:
  //     [batch, in_channels, in_height, in_width].
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs UseCudnnOnGpu(@Cast("bool") boolean x);

    public native @ByVal Attrs DataFormat(@StringPiece BytePointer x);
    public native @ByVal Attrs DataFormat(@StringPiece String x);

    public native @Cast("bool") boolean use_cudnn_on_gpu_(); public native Attrs use_cudnn_on_gpu_(boolean use_cudnn_on_gpu_);
    public native @StringPiece BytePointer data_format_(); public native Attrs data_format_(BytePointer data_format_);
  }
  public Conv2DBackpropInput(@Const @ByRef Scope scope, @ByVal Input input_sizes, @ByVal Input filter,
                      @ByVal Input out_backprop, @ArraySlice IntPointer strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input_sizes, filter, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input_sizes, @ByVal Input filter,
                      @ByVal Input out_backprop, @ArraySlice IntPointer strides, @StringPiece BytePointer padding);
  public Conv2DBackpropInput(@Const @ByRef Scope scope, @ByVal Input input_sizes, @ByVal Input filter,
                      @ByVal Input out_backprop, @ArraySlice IntBuffer strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, input_sizes, filter, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input_sizes, @ByVal Input filter,
                      @ByVal Input out_backprop, @ArraySlice IntBuffer strides, @StringPiece String padding);
  public Conv2DBackpropInput(@Const @ByRef Scope scope, @ByVal Input input_sizes, @ByVal Input filter,
                      @ByVal Input out_backprop, @ArraySlice int[] strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input_sizes, filter, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input_sizes, @ByVal Input filter,
                      @ByVal Input out_backprop, @ArraySlice int[] strides, @StringPiece BytePointer padding);
  public Conv2DBackpropInput(@Const @ByRef Scope scope, @ByVal Input input_sizes, @ByVal Input filter,
                      @ByVal Input out_backprop, @ArraySlice IntPointer strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, input_sizes, filter, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input_sizes, @ByVal Input filter,
                      @ByVal Input out_backprop, @ArraySlice IntPointer strides, @StringPiece String padding);
  public Conv2DBackpropInput(@Const @ByRef Scope scope, @ByVal Input input_sizes, @ByVal Input filter,
                      @ByVal Input out_backprop, @ArraySlice IntBuffer strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input_sizes, filter, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input_sizes, @ByVal Input filter,
                      @ByVal Input out_backprop, @ArraySlice IntBuffer strides, @StringPiece BytePointer padding);
  public Conv2DBackpropInput(@Const @ByRef Scope scope, @ByVal Input input_sizes, @ByVal Input filter,
                      @ByVal Input out_backprop, @ArraySlice int[] strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, input_sizes, filter, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input_sizes, @ByVal Input filter,
                      @ByVal Input out_backprop, @ArraySlice int[] strides, @StringPiece String padding);
  public Conv2DBackpropInput(@Const @ByRef Scope scope, @ByVal Input input_sizes, @ByVal Input filter,
                      @ByVal Input out_backprop, @ArraySlice IntPointer strides, @StringPiece BytePointer padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input_sizes, filter, out_backprop, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input_sizes, @ByVal Input filter,
                      @ByVal Input out_backprop, @ArraySlice IntPointer strides, @StringPiece BytePointer padding, @Const @ByRef Attrs attrs);
  public Conv2DBackpropInput(@Const @ByRef Scope scope, @ByVal Input input_sizes, @ByVal Input filter,
                      @ByVal Input out_backprop, @ArraySlice IntBuffer strides, @StringPiece String padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input_sizes, filter, out_backprop, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input_sizes, @ByVal Input filter,
                      @ByVal Input out_backprop, @ArraySlice IntBuffer strides, @StringPiece String padding, @Const @ByRef Attrs attrs);
  public Conv2DBackpropInput(@Const @ByRef Scope scope, @ByVal Input input_sizes, @ByVal Input filter,
                      @ByVal Input out_backprop, @ArraySlice int[] strides, @StringPiece BytePointer padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input_sizes, filter, out_backprop, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input_sizes, @ByVal Input filter,
                      @ByVal Input out_backprop, @ArraySlice int[] strides, @StringPiece BytePointer padding, @Const @ByRef Attrs attrs);
  public Conv2DBackpropInput(@Const @ByRef Scope scope, @ByVal Input input_sizes, @ByVal Input filter,
                      @ByVal Input out_backprop, @ArraySlice IntPointer strides, @StringPiece String padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input_sizes, filter, out_backprop, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input_sizes, @ByVal Input filter,
                      @ByVal Input out_backprop, @ArraySlice IntPointer strides, @StringPiece String padding, @Const @ByRef Attrs attrs);
  public Conv2DBackpropInput(@Const @ByRef Scope scope, @ByVal Input input_sizes, @ByVal Input filter,
                      @ByVal Input out_backprop, @ArraySlice IntBuffer strides, @StringPiece BytePointer padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input_sizes, filter, out_backprop, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input_sizes, @ByVal Input filter,
                      @ByVal Input out_backprop, @ArraySlice IntBuffer strides, @StringPiece BytePointer padding, @Const @ByRef Attrs attrs);
  public Conv2DBackpropInput(@Const @ByRef Scope scope, @ByVal Input input_sizes, @ByVal Input filter,
                      @ByVal Input out_backprop, @ArraySlice int[] strides, @StringPiece String padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input_sizes, filter, out_backprop, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input_sizes, @ByVal Input filter,
                      @ByVal Input out_backprop, @ArraySlice int[] strides, @StringPiece String padding, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs UseCudnnOnGpu(@Cast("bool") boolean x);
  public static native @ByVal Attrs DataFormat(@StringPiece BytePointer x);
  public static native @ByVal Attrs DataFormat(@StringPiece String x);

  public native @ByRef Output output(); public native Conv2DBackpropInput output(Output output);
}

// Computes a 3-D convolution given 5-D `input` and `filter` tensors.
//
// In signal processing, cross-correlation is a measure of similarity of
// two waveforms as a function of a time-lag applied to one of them. This
// is also known as a sliding dot product or sliding inner-product.
//
// Our Conv3D implements a form of cross-correlation.
//
// Arguments:
// * scope: A Scope object
// * input: Shape `[batch, in_depth, in_height, in_width, in_channels]`.
// * filter: Shape `[filter_depth, filter_height, filter_width, in_channels,
// out_channels]`. `in_channels` must match between `input` and `filter`.
// * strides:
//     1-D tensor of length 5. The stride of the sliding window for each
// dimension of `input`. Must have `strides[0] = strides[4] = 1`.
// * padding:
//     The type of padding algorithm to use.
@Namespace("tensorflow::ops") @NoOffset public static class Conv3D extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Conv3D(Pointer p) { super(p); }

  public Conv3D(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input filter, @ArraySlice IntPointer strides,
         @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, filter, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input filter, @ArraySlice IntPointer strides,
         @StringPiece BytePointer padding);
  public Conv3D(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input filter, @ArraySlice IntBuffer strides,
         @StringPiece String padding) { super((Pointer)null); allocate(scope, input, filter, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input filter, @ArraySlice IntBuffer strides,
         @StringPiece String padding);
  public Conv3D(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input filter, @ArraySlice int[] strides,
         @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, filter, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input filter, @ArraySlice int[] strides,
         @StringPiece BytePointer padding);
  public Conv3D(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input filter, @ArraySlice IntPointer strides,
         @StringPiece String padding) { super((Pointer)null); allocate(scope, input, filter, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input filter, @ArraySlice IntPointer strides,
         @StringPiece String padding);
  public Conv3D(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input filter, @ArraySlice IntBuffer strides,
         @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, filter, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input filter, @ArraySlice IntBuffer strides,
         @StringPiece BytePointer padding);
  public Conv3D(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input filter, @ArraySlice int[] strides,
         @StringPiece String padding) { super((Pointer)null); allocate(scope, input, filter, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input filter, @ArraySlice int[] strides,
         @StringPiece String padding);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native Conv3D output(Output output);
}

// Computes the gradients of 3-D convolution with respect to the filter.
//
// DEPRECATED at GraphDef version 10:
// Use Conv3DBackpropFilterV2.
//
// Arguments:
// * scope: A Scope object
// * input: Shape `[batch, depth, rows, cols, in_channels]`.
// * filter: Shape `[depth, rows, cols, in_channels, out_channels]`.
// `in_channels` must match between `input` and `filter`.
// * out_backprop: Backprop signal of shape `[batch, out_depth, out_rows, out_cols,
// out_channels]`.
// * strides:
//     1-D tensor of length 5. The stride of the sliding window for each
// dimension of `input`. Must have `strides[0] = strides[4] = 1`.
// * padding:
//     The type of padding algorithm to use.
@Namespace("tensorflow::ops") @NoOffset public static class Conv3DBackpropFilter extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Conv3DBackpropFilter(Pointer p) { super(p); }

  public Conv3DBackpropFilter(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter,
                       @ByVal Input out_backprop, @ArraySlice IntPointer strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, filter, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter,
                       @ByVal Input out_backprop, @ArraySlice IntPointer strides, @StringPiece BytePointer padding);
  public Conv3DBackpropFilter(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter,
                       @ByVal Input out_backprop, @ArraySlice IntBuffer strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, input, filter, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter,
                       @ByVal Input out_backprop, @ArraySlice IntBuffer strides, @StringPiece String padding);
  public Conv3DBackpropFilter(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter,
                       @ByVal Input out_backprop, @ArraySlice int[] strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, filter, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter,
                       @ByVal Input out_backprop, @ArraySlice int[] strides, @StringPiece BytePointer padding);
  public Conv3DBackpropFilter(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter,
                       @ByVal Input out_backprop, @ArraySlice IntPointer strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, input, filter, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter,
                       @ByVal Input out_backprop, @ArraySlice IntPointer strides, @StringPiece String padding);
  public Conv3DBackpropFilter(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter,
                       @ByVal Input out_backprop, @ArraySlice IntBuffer strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, filter, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter,
                       @ByVal Input out_backprop, @ArraySlice IntBuffer strides, @StringPiece BytePointer padding);
  public Conv3DBackpropFilter(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter,
                       @ByVal Input out_backprop, @ArraySlice int[] strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, input, filter, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter,
                       @ByVal Input out_backprop, @ArraySlice int[] strides, @StringPiece String padding);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native Conv3DBackpropFilter output(Output output);
}

// Computes the gradients of 3-D convolution with respect to the filter.
//
// Arguments:
// * scope: A Scope object
// * input: Shape `[batch, depth, rows, cols, in_channels]`.
// * filter_sizes: An integer vector representing the tensor shape of `filter`,
// where `filter` is a 5-D
// `[filter_depth, filter_height, filter_width, in_channels, out_channels]`
// tensor.
// * out_backprop: Backprop signal of shape `[batch, out_depth, out_rows, out_cols,
// out_channels]`.
// * strides:
//     1-D tensor of length 5. The stride of the sliding window for each
// dimension of `input`. Must have `strides[0] = strides[4] = 1`.
// * padding:
//     The type of padding algorithm to use.
@Namespace("tensorflow::ops") @NoOffset public static class Conv3DBackpropFilterV2 extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Conv3DBackpropFilterV2(Pointer p) { super(p); }

  public Conv3DBackpropFilterV2(@Const @ByRef Scope scope,
                         @ByVal Input input, @ByVal Input filter_sizes, @ByVal Input out_backprop,
                         @ArraySlice IntPointer strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, filter_sizes, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                         @ByVal Input input, @ByVal Input filter_sizes, @ByVal Input out_backprop,
                         @ArraySlice IntPointer strides, @StringPiece BytePointer padding);
  public Conv3DBackpropFilterV2(@Const @ByRef Scope scope,
                         @ByVal Input input, @ByVal Input filter_sizes, @ByVal Input out_backprop,
                         @ArraySlice IntBuffer strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, input, filter_sizes, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                         @ByVal Input input, @ByVal Input filter_sizes, @ByVal Input out_backprop,
                         @ArraySlice IntBuffer strides, @StringPiece String padding);
  public Conv3DBackpropFilterV2(@Const @ByRef Scope scope,
                         @ByVal Input input, @ByVal Input filter_sizes, @ByVal Input out_backprop,
                         @ArraySlice int[] strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, filter_sizes, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                         @ByVal Input input, @ByVal Input filter_sizes, @ByVal Input out_backprop,
                         @ArraySlice int[] strides, @StringPiece BytePointer padding);
  public Conv3DBackpropFilterV2(@Const @ByRef Scope scope,
                         @ByVal Input input, @ByVal Input filter_sizes, @ByVal Input out_backprop,
                         @ArraySlice IntPointer strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, input, filter_sizes, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                         @ByVal Input input, @ByVal Input filter_sizes, @ByVal Input out_backprop,
                         @ArraySlice IntPointer strides, @StringPiece String padding);
  public Conv3DBackpropFilterV2(@Const @ByRef Scope scope,
                         @ByVal Input input, @ByVal Input filter_sizes, @ByVal Input out_backprop,
                         @ArraySlice IntBuffer strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, filter_sizes, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                         @ByVal Input input, @ByVal Input filter_sizes, @ByVal Input out_backprop,
                         @ArraySlice IntBuffer strides, @StringPiece BytePointer padding);
  public Conv3DBackpropFilterV2(@Const @ByRef Scope scope,
                         @ByVal Input input, @ByVal Input filter_sizes, @ByVal Input out_backprop,
                         @ArraySlice int[] strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, input, filter_sizes, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                         @ByVal Input input, @ByVal Input filter_sizes, @ByVal Input out_backprop,
                         @ArraySlice int[] strides, @StringPiece String padding);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native Conv3DBackpropFilterV2 output(Output output);
}

// Computes the gradients of 3-D convolution with respect to the input.
//
// DEPRECATED at GraphDef version 10:
// Use Conv3DBackpropInputV2.
//
// Arguments:
// * scope: A Scope object
// * input: Shape `[batch, depth, rows, cols, in_channels]`.
// * filter: Shape `[depth, rows, cols, in_channels, out_channels]`.
// `in_channels` must match between `input` and `filter`.
// * out_backprop: Backprop signal of shape `[batch, out_depth, out_rows, out_cols,
// out_channels]`.
// * strides:
//     1-D tensor of length 5. The stride of the sliding window for each
// dimension of `input`. Must have `strides[0] = strides[4] = 1`.
// * padding:
//     The type of padding algorithm to use.
@Namespace("tensorflow::ops") @NoOffset public static class Conv3DBackpropInput extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Conv3DBackpropInput(Pointer p) { super(p); }

  public Conv3DBackpropInput(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter,
                      @ByVal Input out_backprop, @ArraySlice IntPointer strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, filter, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter,
                      @ByVal Input out_backprop, @ArraySlice IntPointer strides, @StringPiece BytePointer padding);
  public Conv3DBackpropInput(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter,
                      @ByVal Input out_backprop, @ArraySlice IntBuffer strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, input, filter, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter,
                      @ByVal Input out_backprop, @ArraySlice IntBuffer strides, @StringPiece String padding);
  public Conv3DBackpropInput(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter,
                      @ByVal Input out_backprop, @ArraySlice int[] strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, filter, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter,
                      @ByVal Input out_backprop, @ArraySlice int[] strides, @StringPiece BytePointer padding);
  public Conv3DBackpropInput(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter,
                      @ByVal Input out_backprop, @ArraySlice IntPointer strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, input, filter, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter,
                      @ByVal Input out_backprop, @ArraySlice IntPointer strides, @StringPiece String padding);
  public Conv3DBackpropInput(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter,
                      @ByVal Input out_backprop, @ArraySlice IntBuffer strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, filter, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter,
                      @ByVal Input out_backprop, @ArraySlice IntBuffer strides, @StringPiece BytePointer padding);
  public Conv3DBackpropInput(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter,
                      @ByVal Input out_backprop, @ArraySlice int[] strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, input, filter, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ByVal Input filter,
                      @ByVal Input out_backprop, @ArraySlice int[] strides, @StringPiece String padding);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native Conv3DBackpropInput output(Output output);
}

// Computes the gradients of 3-D convolution with respect to the input.
//
// Arguments:
// * scope: A Scope object
// * input_sizes: An integer vector representing the tensor shape of `input`,
// where `input` is a 5-D
// `[batch, depth, rows, cols, in_channels]` tensor.
// * filter: Shape `[depth, rows, cols, in_channels, out_channels]`.
// `in_channels` must match between `input` and `filter`.
// * out_backprop: Backprop signal of shape `[batch, out_depth, out_rows, out_cols,
// out_channels]`.
// * strides:
//     1-D tensor of length 5. The stride of the sliding window for each
// dimension of `input`. Must have `strides[0] = strides[4] = 1`.
// * padding:
//     The type of padding algorithm to use.
@Namespace("tensorflow::ops") @NoOffset public static class Conv3DBackpropInputV2 extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Conv3DBackpropInputV2(Pointer p) { super(p); }

  public Conv3DBackpropInputV2(@Const @ByRef Scope scope,
                        @ByVal Input input_sizes,
                        @ByVal Input filter, @ByVal Input out_backprop, @ArraySlice IntPointer strides,
                        @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input_sizes, filter, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                        @ByVal Input input_sizes,
                        @ByVal Input filter, @ByVal Input out_backprop, @ArraySlice IntPointer strides,
                        @StringPiece BytePointer padding);
  public Conv3DBackpropInputV2(@Const @ByRef Scope scope,
                        @ByVal Input input_sizes,
                        @ByVal Input filter, @ByVal Input out_backprop, @ArraySlice IntBuffer strides,
                        @StringPiece String padding) { super((Pointer)null); allocate(scope, input_sizes, filter, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                        @ByVal Input input_sizes,
                        @ByVal Input filter, @ByVal Input out_backprop, @ArraySlice IntBuffer strides,
                        @StringPiece String padding);
  public Conv3DBackpropInputV2(@Const @ByRef Scope scope,
                        @ByVal Input input_sizes,
                        @ByVal Input filter, @ByVal Input out_backprop, @ArraySlice int[] strides,
                        @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input_sizes, filter, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                        @ByVal Input input_sizes,
                        @ByVal Input filter, @ByVal Input out_backprop, @ArraySlice int[] strides,
                        @StringPiece BytePointer padding);
  public Conv3DBackpropInputV2(@Const @ByRef Scope scope,
                        @ByVal Input input_sizes,
                        @ByVal Input filter, @ByVal Input out_backprop, @ArraySlice IntPointer strides,
                        @StringPiece String padding) { super((Pointer)null); allocate(scope, input_sizes, filter, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                        @ByVal Input input_sizes,
                        @ByVal Input filter, @ByVal Input out_backprop, @ArraySlice IntPointer strides,
                        @StringPiece String padding);
  public Conv3DBackpropInputV2(@Const @ByRef Scope scope,
                        @ByVal Input input_sizes,
                        @ByVal Input filter, @ByVal Input out_backprop, @ArraySlice IntBuffer strides,
                        @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input_sizes, filter, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                        @ByVal Input input_sizes,
                        @ByVal Input filter, @ByVal Input out_backprop, @ArraySlice IntBuffer strides,
                        @StringPiece BytePointer padding);
  public Conv3DBackpropInputV2(@Const @ByRef Scope scope,
                        @ByVal Input input_sizes,
                        @ByVal Input filter, @ByVal Input out_backprop, @ArraySlice int[] strides,
                        @StringPiece String padding) { super((Pointer)null); allocate(scope, input_sizes, filter, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                        @ByVal Input input_sizes,
                        @ByVal Input filter, @ByVal Input out_backprop, @ArraySlice int[] strides,
                        @StringPiece String padding);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native Conv3DBackpropInputV2 output(Output output);
}

// Computes a 2-D depthwise convolution given 4-D `input` and `filter` tensors.
//
// Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
// and a filter / kernel tensor of shape
// `[filter_height, filter_width, in_channels, channel_multiplier]`, containing
// `in_channels` convolutional filters of depth 1, `depthwise_conv2d` applies
// a different filter to each input channel (expanding from 1 channel to
// `channel_multiplier` channels for each), then concatenates the results
// together. Thus, the output has `in_channels * channel_multiplier` channels.
//
// for k in 0..in_channels-1
//   for q in 0..channel_multiplier-1
//     output[b, i, j, k * channel_multiplier + q] =
//       sum_{di, dj} input[b, strides[1] * i + di, strides[2] * j + dj, k] *
//                         filter[di, dj, k, q]
//
// Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
// horizontal and vertices strides, `strides = [1, stride, stride, 1]`.
//
// Arguments:
// * scope: A Scope object
// * strides:
//     1-D of length 4.  The stride of the sliding window for each dimension
// of `input`.
// * padding:
//     The type of padding algorithm to use.
@Namespace("tensorflow::ops") @NoOffset public static class DepthwiseConv2dNative extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public DepthwiseConv2dNative(Pointer p) { super(p); }

  public DepthwiseConv2dNative(@Const @ByRef Scope scope,
                        @ByVal Input input, @ByVal Input filter, @ArraySlice IntPointer strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, filter, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                        @ByVal Input input, @ByVal Input filter, @ArraySlice IntPointer strides, @StringPiece BytePointer padding);
  public DepthwiseConv2dNative(@Const @ByRef Scope scope,
                        @ByVal Input input, @ByVal Input filter, @ArraySlice IntBuffer strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, input, filter, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                        @ByVal Input input, @ByVal Input filter, @ArraySlice IntBuffer strides, @StringPiece String padding);
  public DepthwiseConv2dNative(@Const @ByRef Scope scope,
                        @ByVal Input input, @ByVal Input filter, @ArraySlice int[] strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, filter, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                        @ByVal Input input, @ByVal Input filter, @ArraySlice int[] strides, @StringPiece BytePointer padding);
  public DepthwiseConv2dNative(@Const @ByRef Scope scope,
                        @ByVal Input input, @ByVal Input filter, @ArraySlice IntPointer strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, input, filter, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                        @ByVal Input input, @ByVal Input filter, @ArraySlice IntPointer strides, @StringPiece String padding);
  public DepthwiseConv2dNative(@Const @ByRef Scope scope,
                        @ByVal Input input, @ByVal Input filter, @ArraySlice IntBuffer strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, filter, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                        @ByVal Input input, @ByVal Input filter, @ArraySlice IntBuffer strides, @StringPiece BytePointer padding);
  public DepthwiseConv2dNative(@Const @ByRef Scope scope,
                        @ByVal Input input, @ByVal Input filter, @ArraySlice int[] strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, input, filter, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                        @ByVal Input input, @ByVal Input filter, @ArraySlice int[] strides, @StringPiece String padding);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native DepthwiseConv2dNative output(Output output);
}

// Computes the gradients of depthwise convolution with respect to the filter.
//
// Arguments:
// * scope: A Scope object
// * input: 4-D with shape `[batch, in_height, in_width, in_channels]`.
// * filter_sizes: An integer vector representing the tensor shape of `filter`,
// where `filter` is a 4-D
// `[filter_height, filter_width, in_channels, depthwise_multiplier]` tensor.
// * out_backprop: 4-D with shape `[batch, out_height, out_width, out_channels]`.
// Gradients w.r.t. the output of the convolution.
// * strides:
//     The stride of the sliding window for each dimension of the input
// of the convolution.
// * padding:
//     The type of padding algorithm to use.
@Namespace("tensorflow::ops") @NoOffset public static class DepthwiseConv2dNativeBackpropFilter extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public DepthwiseConv2dNativeBackpropFilter(Pointer p) { super(p); }

  public DepthwiseConv2dNativeBackpropFilter(@Const @ByRef Scope scope,
                                      @ByVal Input input,
                                      @ByVal Input filter_sizes,
                                      @ByVal Input out_backprop,
                                      @ArraySlice IntPointer strides,
                                      @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, filter_sizes, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                                      @ByVal Input input,
                                      @ByVal Input filter_sizes,
                                      @ByVal Input out_backprop,
                                      @ArraySlice IntPointer strides,
                                      @StringPiece BytePointer padding);
  public DepthwiseConv2dNativeBackpropFilter(@Const @ByRef Scope scope,
                                      @ByVal Input input,
                                      @ByVal Input filter_sizes,
                                      @ByVal Input out_backprop,
                                      @ArraySlice IntBuffer strides,
                                      @StringPiece String padding) { super((Pointer)null); allocate(scope, input, filter_sizes, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                                      @ByVal Input input,
                                      @ByVal Input filter_sizes,
                                      @ByVal Input out_backprop,
                                      @ArraySlice IntBuffer strides,
                                      @StringPiece String padding);
  public DepthwiseConv2dNativeBackpropFilter(@Const @ByRef Scope scope,
                                      @ByVal Input input,
                                      @ByVal Input filter_sizes,
                                      @ByVal Input out_backprop,
                                      @ArraySlice int[] strides,
                                      @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, filter_sizes, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                                      @ByVal Input input,
                                      @ByVal Input filter_sizes,
                                      @ByVal Input out_backprop,
                                      @ArraySlice int[] strides,
                                      @StringPiece BytePointer padding);
  public DepthwiseConv2dNativeBackpropFilter(@Const @ByRef Scope scope,
                                      @ByVal Input input,
                                      @ByVal Input filter_sizes,
                                      @ByVal Input out_backprop,
                                      @ArraySlice IntPointer strides,
                                      @StringPiece String padding) { super((Pointer)null); allocate(scope, input, filter_sizes, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                                      @ByVal Input input,
                                      @ByVal Input filter_sizes,
                                      @ByVal Input out_backprop,
                                      @ArraySlice IntPointer strides,
                                      @StringPiece String padding);
  public DepthwiseConv2dNativeBackpropFilter(@Const @ByRef Scope scope,
                                      @ByVal Input input,
                                      @ByVal Input filter_sizes,
                                      @ByVal Input out_backprop,
                                      @ArraySlice IntBuffer strides,
                                      @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, filter_sizes, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                                      @ByVal Input input,
                                      @ByVal Input filter_sizes,
                                      @ByVal Input out_backprop,
                                      @ArraySlice IntBuffer strides,
                                      @StringPiece BytePointer padding);
  public DepthwiseConv2dNativeBackpropFilter(@Const @ByRef Scope scope,
                                      @ByVal Input input,
                                      @ByVal Input filter_sizes,
                                      @ByVal Input out_backprop,
                                      @ArraySlice int[] strides,
                                      @StringPiece String padding) { super((Pointer)null); allocate(scope, input, filter_sizes, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                                      @ByVal Input input,
                                      @ByVal Input filter_sizes,
                                      @ByVal Input out_backprop,
                                      @ArraySlice int[] strides,
                                      @StringPiece String padding);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native DepthwiseConv2dNativeBackpropFilter output(Output output);
}

// Computes the gradients of depthwise convolution with respect to the input.
//
// Arguments:
// * scope: A Scope object
// * input_sizes: An integer vector representing the shape of `input`,
// where `input` is a 4-D `[batch, height, width, channels]` tensor.
// * filter: 4-D with shape
// `[filter_height, filter_width, in_channels, depthwise_multiplier]`.
// * out_backprop: 4-D with shape `[batch, out_height, out_width, out_channels]`.
// Gradients w.r.t. the output of the convolution.
// * strides:
//     The stride of the sliding window for each dimension of the input
// of the convolution.
// * padding:
//     The type of padding algorithm to use.
@Namespace("tensorflow::ops") @NoOffset public static class DepthwiseConv2dNativeBackpropInput extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public DepthwiseConv2dNativeBackpropInput(Pointer p) { super(p); }

  public DepthwiseConv2dNativeBackpropInput(@Const @ByRef Scope scope,
                                     @ByVal Input input_sizes,
                                     @ByVal Input filter,
                                     @ByVal Input out_backprop, @ArraySlice IntPointer strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input_sizes, filter, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                                     @ByVal Input input_sizes,
                                     @ByVal Input filter,
                                     @ByVal Input out_backprop, @ArraySlice IntPointer strides, @StringPiece BytePointer padding);
  public DepthwiseConv2dNativeBackpropInput(@Const @ByRef Scope scope,
                                     @ByVal Input input_sizes,
                                     @ByVal Input filter,
                                     @ByVal Input out_backprop, @ArraySlice IntBuffer strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, input_sizes, filter, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                                     @ByVal Input input_sizes,
                                     @ByVal Input filter,
                                     @ByVal Input out_backprop, @ArraySlice IntBuffer strides, @StringPiece String padding);
  public DepthwiseConv2dNativeBackpropInput(@Const @ByRef Scope scope,
                                     @ByVal Input input_sizes,
                                     @ByVal Input filter,
                                     @ByVal Input out_backprop, @ArraySlice int[] strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input_sizes, filter, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                                     @ByVal Input input_sizes,
                                     @ByVal Input filter,
                                     @ByVal Input out_backprop, @ArraySlice int[] strides, @StringPiece BytePointer padding);
  public DepthwiseConv2dNativeBackpropInput(@Const @ByRef Scope scope,
                                     @ByVal Input input_sizes,
                                     @ByVal Input filter,
                                     @ByVal Input out_backprop, @ArraySlice IntPointer strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, input_sizes, filter, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                                     @ByVal Input input_sizes,
                                     @ByVal Input filter,
                                     @ByVal Input out_backprop, @ArraySlice IntPointer strides, @StringPiece String padding);
  public DepthwiseConv2dNativeBackpropInput(@Const @ByRef Scope scope,
                                     @ByVal Input input_sizes,
                                     @ByVal Input filter,
                                     @ByVal Input out_backprop, @ArraySlice IntBuffer strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input_sizes, filter, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                                     @ByVal Input input_sizes,
                                     @ByVal Input filter,
                                     @ByVal Input out_backprop, @ArraySlice IntBuffer strides, @StringPiece BytePointer padding);
  public DepthwiseConv2dNativeBackpropInput(@Const @ByRef Scope scope,
                                     @ByVal Input input_sizes,
                                     @ByVal Input filter,
                                     @ByVal Input out_backprop, @ArraySlice int[] strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, input_sizes, filter, out_backprop, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                                     @ByVal Input input_sizes,
                                     @ByVal Input filter,
                                     @ByVal Input out_backprop, @ArraySlice int[] strides, @StringPiece String padding);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native DepthwiseConv2dNativeBackpropInput output(Output output);
}

// Computes the grayscale dilation of 4-D `input` and 3-D `filter` tensors.
//
// The `input` tensor has shape `[batch, in_height, in_width, depth]` and the
// `filter` tensor has shape `[filter_height, filter_width, depth]`, i.e., each
// input channel is processed independently of the others with its own structuring
// function. The `output` tensor has shape
// `[batch, out_height, out_width, depth]`. The spatial dimensions of the output
// tensor depend on the `padding` algorithm. We currently only support the default
// "NHWC" `data_format`.
//
// In detail, the grayscale morphological 2-D dilation is the max-sum correlation
// (for consistency with `conv2d`, we use unmirrored filters):
//
//     output[b, y, x, c] =
//        max_{dy, dx} input[b,
//                           strides[1] * y + rates[1] * dy,
//                           strides[2] * x + rates[2] * dx,
//                           c] +
//                     filter[dy, dx, c]
//
// Max-pooling is a special case when the filter has size equal to the pooling
// kernel size and contains all zeros.
//
// Note on duality: The dilation of `input` by the `filter` is equal to the
// negation of the erosion of `-input` by the reflected `filter`.
//
// Arguments:
// * scope: A Scope object
// * input: 4-D with shape `[batch, in_height, in_width, depth]`.
// * filter: 3-D with shape `[filter_height, filter_width, depth]`.
// * strides:
//     The stride of the sliding window for each dimension of the input
// tensor. Must be: `[1, stride_height, stride_width, 1]`.
// * rates:
//     The input stride for atrous morphological dilation. Must be:
// `[1, rate_height, rate_width, 1]`.
// * padding:
//     The type of padding algorithm to use.
@Namespace("tensorflow::ops") @NoOffset public static class Dilation2D extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Dilation2D(Pointer p) { super(p); }

  public Dilation2D(@Const @ByRef Scope scope, @ByVal Input input,
             @ByVal Input filter, @ArraySlice IntPointer strides, @ArraySlice IntPointer rates, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, filter, strides, rates, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
             @ByVal Input filter, @ArraySlice IntPointer strides, @ArraySlice IntPointer rates, @StringPiece BytePointer padding);
  public Dilation2D(@Const @ByRef Scope scope, @ByVal Input input,
             @ByVal Input filter, @ArraySlice IntBuffer strides, @ArraySlice IntBuffer rates, @StringPiece String padding) { super((Pointer)null); allocate(scope, input, filter, strides, rates, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
             @ByVal Input filter, @ArraySlice IntBuffer strides, @ArraySlice IntBuffer rates, @StringPiece String padding);
  public Dilation2D(@Const @ByRef Scope scope, @ByVal Input input,
             @ByVal Input filter, @ArraySlice int[] strides, @ArraySlice int[] rates, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, filter, strides, rates, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
             @ByVal Input filter, @ArraySlice int[] strides, @ArraySlice int[] rates, @StringPiece BytePointer padding);
  public Dilation2D(@Const @ByRef Scope scope, @ByVal Input input,
             @ByVal Input filter, @ArraySlice IntPointer strides, @ArraySlice IntPointer rates, @StringPiece String padding) { super((Pointer)null); allocate(scope, input, filter, strides, rates, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
             @ByVal Input filter, @ArraySlice IntPointer strides, @ArraySlice IntPointer rates, @StringPiece String padding);
  public Dilation2D(@Const @ByRef Scope scope, @ByVal Input input,
             @ByVal Input filter, @ArraySlice IntBuffer strides, @ArraySlice IntBuffer rates, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, filter, strides, rates, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
             @ByVal Input filter, @ArraySlice IntBuffer strides, @ArraySlice IntBuffer rates, @StringPiece BytePointer padding);
  public Dilation2D(@Const @ByRef Scope scope, @ByVal Input input,
             @ByVal Input filter, @ArraySlice int[] strides, @ArraySlice int[] rates, @StringPiece String padding) { super((Pointer)null); allocate(scope, input, filter, strides, rates, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
             @ByVal Input filter, @ArraySlice int[] strides, @ArraySlice int[] rates, @StringPiece String padding);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native Dilation2D output(Output output);
}

// Computes the gradient of morphological 2-D dilation with respect to the filter.
//
// Arguments:
// * scope: A Scope object
// * input: 4-D with shape `[batch, in_height, in_width, depth]`.
// * filter: 3-D with shape `[filter_height, filter_width, depth]`.
// * out_backprop: 4-D with shape `[batch, out_height, out_width, depth]`.
// * strides:
//     1-D of length 4. The stride of the sliding window for each dimension of
// the input tensor. Must be: `[1, stride_height, stride_width, 1]`.
// * rates:
//     1-D of length 4. The input stride for atrous morphological dilation.
// Must be: `[1, rate_height, rate_width, 1]`.
// * padding:
//     The type of padding algorithm to use.
@Namespace("tensorflow::ops") @NoOffset public static class Dilation2DBackpropFilter extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Dilation2DBackpropFilter(Pointer p) { super(p); }

  public Dilation2DBackpropFilter(@Const @ByRef Scope scope,
                           @ByVal Input input,
                           @ByVal Input filter,
                           @ByVal Input out_backprop, @ArraySlice IntPointer strides, @ArraySlice IntPointer rates, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, filter, out_backprop, strides, rates, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                           @ByVal Input input,
                           @ByVal Input filter,
                           @ByVal Input out_backprop, @ArraySlice IntPointer strides, @ArraySlice IntPointer rates, @StringPiece BytePointer padding);
  public Dilation2DBackpropFilter(@Const @ByRef Scope scope,
                           @ByVal Input input,
                           @ByVal Input filter,
                           @ByVal Input out_backprop, @ArraySlice IntBuffer strides, @ArraySlice IntBuffer rates, @StringPiece String padding) { super((Pointer)null); allocate(scope, input, filter, out_backprop, strides, rates, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                           @ByVal Input input,
                           @ByVal Input filter,
                           @ByVal Input out_backprop, @ArraySlice IntBuffer strides, @ArraySlice IntBuffer rates, @StringPiece String padding);
  public Dilation2DBackpropFilter(@Const @ByRef Scope scope,
                           @ByVal Input input,
                           @ByVal Input filter,
                           @ByVal Input out_backprop, @ArraySlice int[] strides, @ArraySlice int[] rates, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, filter, out_backprop, strides, rates, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                           @ByVal Input input,
                           @ByVal Input filter,
                           @ByVal Input out_backprop, @ArraySlice int[] strides, @ArraySlice int[] rates, @StringPiece BytePointer padding);
  public Dilation2DBackpropFilter(@Const @ByRef Scope scope,
                           @ByVal Input input,
                           @ByVal Input filter,
                           @ByVal Input out_backprop, @ArraySlice IntPointer strides, @ArraySlice IntPointer rates, @StringPiece String padding) { super((Pointer)null); allocate(scope, input, filter, out_backprop, strides, rates, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                           @ByVal Input input,
                           @ByVal Input filter,
                           @ByVal Input out_backprop, @ArraySlice IntPointer strides, @ArraySlice IntPointer rates, @StringPiece String padding);
  public Dilation2DBackpropFilter(@Const @ByRef Scope scope,
                           @ByVal Input input,
                           @ByVal Input filter,
                           @ByVal Input out_backprop, @ArraySlice IntBuffer strides, @ArraySlice IntBuffer rates, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, filter, out_backprop, strides, rates, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                           @ByVal Input input,
                           @ByVal Input filter,
                           @ByVal Input out_backprop, @ArraySlice IntBuffer strides, @ArraySlice IntBuffer rates, @StringPiece BytePointer padding);
  public Dilation2DBackpropFilter(@Const @ByRef Scope scope,
                           @ByVal Input input,
                           @ByVal Input filter,
                           @ByVal Input out_backprop, @ArraySlice int[] strides, @ArraySlice int[] rates, @StringPiece String padding) { super((Pointer)null); allocate(scope, input, filter, out_backprop, strides, rates, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                           @ByVal Input input,
                           @ByVal Input filter,
                           @ByVal Input out_backprop, @ArraySlice int[] strides, @ArraySlice int[] rates, @StringPiece String padding);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output filter_backprop(); public native Dilation2DBackpropFilter filter_backprop(Output filter_backprop);
}

// Computes the gradient of morphological 2-D dilation with respect to the input.
//
// Arguments:
// * scope: A Scope object
// * input: 4-D with shape `[batch, in_height, in_width, depth]`.
// * filter: 3-D with shape `[filter_height, filter_width, depth]`.
// * out_backprop: 4-D with shape `[batch, out_height, out_width, depth]`.
// * strides:
//     1-D of length 4. The stride of the sliding window for each dimension of
// the input tensor. Must be: `[1, stride_height, stride_width, 1]`.
// * rates:
//     1-D of length 4. The input stride for atrous morphological dilation.
// Must be: `[1, rate_height, rate_width, 1]`.
// * padding:
//     The type of padding algorithm to use.
@Namespace("tensorflow::ops") @NoOffset public static class Dilation2DBackpropInput extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Dilation2DBackpropInput(Pointer p) { super(p); }

  public Dilation2DBackpropInput(@Const @ByRef Scope scope,
                          @ByVal Input input,
                          @ByVal Input filter,
                          @ByVal Input out_backprop, @ArraySlice IntPointer strides, @ArraySlice IntPointer rates, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, filter, out_backprop, strides, rates, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                          @ByVal Input input,
                          @ByVal Input filter,
                          @ByVal Input out_backprop, @ArraySlice IntPointer strides, @ArraySlice IntPointer rates, @StringPiece BytePointer padding);
  public Dilation2DBackpropInput(@Const @ByRef Scope scope,
                          @ByVal Input input,
                          @ByVal Input filter,
                          @ByVal Input out_backprop, @ArraySlice IntBuffer strides, @ArraySlice IntBuffer rates, @StringPiece String padding) { super((Pointer)null); allocate(scope, input, filter, out_backprop, strides, rates, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                          @ByVal Input input,
                          @ByVal Input filter,
                          @ByVal Input out_backprop, @ArraySlice IntBuffer strides, @ArraySlice IntBuffer rates, @StringPiece String padding);
  public Dilation2DBackpropInput(@Const @ByRef Scope scope,
                          @ByVal Input input,
                          @ByVal Input filter,
                          @ByVal Input out_backprop, @ArraySlice int[] strides, @ArraySlice int[] rates, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, filter, out_backprop, strides, rates, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                          @ByVal Input input,
                          @ByVal Input filter,
                          @ByVal Input out_backprop, @ArraySlice int[] strides, @ArraySlice int[] rates, @StringPiece BytePointer padding);
  public Dilation2DBackpropInput(@Const @ByRef Scope scope,
                          @ByVal Input input,
                          @ByVal Input filter,
                          @ByVal Input out_backprop, @ArraySlice IntPointer strides, @ArraySlice IntPointer rates, @StringPiece String padding) { super((Pointer)null); allocate(scope, input, filter, out_backprop, strides, rates, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                          @ByVal Input input,
                          @ByVal Input filter,
                          @ByVal Input out_backprop, @ArraySlice IntPointer strides, @ArraySlice IntPointer rates, @StringPiece String padding);
  public Dilation2DBackpropInput(@Const @ByRef Scope scope,
                          @ByVal Input input,
                          @ByVal Input filter,
                          @ByVal Input out_backprop, @ArraySlice IntBuffer strides, @ArraySlice IntBuffer rates, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, filter, out_backprop, strides, rates, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                          @ByVal Input input,
                          @ByVal Input filter,
                          @ByVal Input out_backprop, @ArraySlice IntBuffer strides, @ArraySlice IntBuffer rates, @StringPiece BytePointer padding);
  public Dilation2DBackpropInput(@Const @ByRef Scope scope,
                          @ByVal Input input,
                          @ByVal Input filter,
                          @ByVal Input out_backprop, @ArraySlice int[] strides, @ArraySlice int[] rates, @StringPiece String padding) { super((Pointer)null); allocate(scope, input, filter, out_backprop, strides, rates, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                          @ByVal Input input,
                          @ByVal Input filter,
                          @ByVal Input out_backprop, @ArraySlice int[] strides, @ArraySlice int[] rates, @StringPiece String padding);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output in_backprop(); public native Dilation2DBackpropInput in_backprop(Output in_backprop);
}

// Computes exponential linear: `exp(features) - 1` if < 0, `features` otherwise.
//
// See [Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)
// ](http://arxiv.org/abs/1511.07289)
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Elu extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Elu(Pointer p) { super(p); }

  public Elu(@Const @ByRef Scope scope, @ByVal Input features) { super((Pointer)null); allocate(scope, features); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input features);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output activations(); public native Elu activations(Output activations);
}

// Computes gradients for the exponential linear (Elu) operation.
//
// Arguments:
// * scope: A Scope object
// * gradients: The backpropagated gradients to the corresponding Elu operation.
// * outputs: The outputs of the corresponding Elu operation.
@Namespace("tensorflow::ops") @NoOffset public static class EluGrad extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public EluGrad(Pointer p) { super(p); }

  public EluGrad(@Const @ByRef Scope scope, @ByVal Input gradients,
          @ByVal Input outputs) { super((Pointer)null); allocate(scope, gradients, outputs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input gradients,
          @ByVal Input outputs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output backprops(); public native EluGrad backprops(Output backprops);
}

// Performs fractional average pooling on the input.
//
// Fractional average pooling is similar to Fractional max pooling in the pooling
// region generation step. The only difference is that after pooling regions are
// generated, a mean operation is performed instead of a max operation in each
// pooling region.
//
// Arguments:
// * scope: A Scope object
// * value: 4-D with shape `[batch, height, width, channels]`.
// * pooling_ratio:
//     Pooling ratio for each dimension of `value`, currently only
// supports row and col dimension and should be >= 1.0. For example, a valid
// pooling ratio looks like [1.0, 1.44, 1.73, 1.0]. The first and last elements
// must be 1.0 because we don't allow pooling on batch and channels
// dimensions. 1.44 and 1.73 are pooling ratio on height and width dimensions
// respectively.
@Namespace("tensorflow::ops") @NoOffset public static class FractionalAvgPool extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public FractionalAvgPool(Pointer p) { super(p); }

  // Optional attribute setters for FractionalAvgPool :
  //
  // PseudoRandom(bool): Defaults to false
  //     When set to True, generates the pooling sequence in a
  // pseudorandom fashion, otherwise, in a random fashion. Check paper [Benjamin
  // Graham, Fractional Max-Pooling] (http://arxiv.org/abs/1412.6071) for
  // difference between pseudorandom and random.
  // Overlapping(bool): Defaults to false
  //     When set to True, it means when pooling, the values at the boundary
  // of adjacent pooling cells are used by both cells. For example:
  //
  // `index  0  1  2  3  4`
  //
  // `value  20 5  16 3  7`
  //
  // If the pooling sequence is [0, 2, 4], then 16, at index 2 will be used twice.
  // The result would be [41/3, 26/3] for fractional avg pooling.
  // Deterministic(bool): Defaults to false
  //     When set to True, a fixed pooling region will be used when
  // iterating over a FractionalAvgPool node in the computation graph. Mainly used
  // in unit test to make FractionalAvgPool deterministic.
  // Seed(int64): Defaults to 0
  //     If either seed or seed2 are set to be non-zero, the random number
  // generator is seeded by the given seed.  Otherwise, it is seeded by a
  // random seed.
  // Seed2(int64): Defaults to 0
  //     An second seed to avoid seed collision.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs PseudoRandom(@Cast("bool") boolean x);

    public native @ByVal Attrs Overlapping(@Cast("bool") boolean x);

    public native @ByVal Attrs Deterministic(@Cast("bool") boolean x);

    public native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);

    public native @Cast("bool") boolean pseudo_random_(); public native Attrs pseudo_random_(boolean pseudo_random_);
    public native @Cast("bool") boolean overlapping_(); public native Attrs overlapping_(boolean overlapping_);
    public native @Cast("bool") boolean deterministic_(); public native Attrs deterministic_(boolean deterministic_);
    public native @Cast("tensorflow::int64") long seed_(); public native Attrs seed_(long seed_);
    public native @Cast("tensorflow::int64") long seed2_(); public native Attrs seed2_(long seed2_);
  }
  public FractionalAvgPool(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice FloatPointer pooling_ratio) { super((Pointer)null); allocate(scope, value, pooling_ratio); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice FloatPointer pooling_ratio);
  public FractionalAvgPool(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice FloatBuffer pooling_ratio) { super((Pointer)null); allocate(scope, value, pooling_ratio); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice FloatBuffer pooling_ratio);
  public FractionalAvgPool(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice float... pooling_ratio) { super((Pointer)null); allocate(scope, value, pooling_ratio); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice float... pooling_ratio);
  public FractionalAvgPool(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice FloatPointer pooling_ratio, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, value, pooling_ratio, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice FloatPointer pooling_ratio, @Const @ByRef Attrs attrs);
  public FractionalAvgPool(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice FloatBuffer pooling_ratio, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, value, pooling_ratio, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice FloatBuffer pooling_ratio, @Const @ByRef Attrs attrs);
  public FractionalAvgPool(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice float[] pooling_ratio, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, value, pooling_ratio, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice float[] pooling_ratio, @Const @ByRef Attrs attrs);

  public static native @ByVal Attrs PseudoRandom(@Cast("bool") boolean x);
  public static native @ByVal Attrs Overlapping(@Cast("bool") boolean x);
  public static native @ByVal Attrs Deterministic(@Cast("bool") boolean x);
  public static native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);

  public native @ByRef Output output(); public native FractionalAvgPool output(Output output);
  public native @ByRef Output row_pooling_sequence(); public native FractionalAvgPool row_pooling_sequence(Output row_pooling_sequence);
  public native @ByRef Output col_pooling_sequence(); public native FractionalAvgPool col_pooling_sequence(Output col_pooling_sequence);
}

// Computes gradient of the FractionalAvgPool function.
//
// Unlike FractionalMaxPoolGrad, we don't need to find arg_max for
// FractionalAvgPoolGrad, we just need to evenly back-propagate each element of
// out_backprop to those indices that form the same pooling cell. Therefore, we
// just need to know the shape of original input tensor, instead of the whole
// tensor.
//
// Arguments:
// * scope: A Scope object
// * orig_input_tensor_shape: Original input tensor shape for `fractional_avg_pool`
// * out_backprop: 4-D with shape `[batch, height, width, channels]`.  Gradients
// w.r.t. the output of `fractional_avg_pool`.
// * row_pooling_sequence: row pooling sequence, form pooling region with
// col_pooling_sequence.
// * col_pooling_sequence: column pooling sequence, form pooling region with
// row_pooling sequence.
@Namespace("tensorflow::ops") @NoOffset public static class FractionalAvgPoolGrad extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public FractionalAvgPoolGrad(Pointer p) { super(p); }

  // Optional attribute setters for FractionalAvgPoolGrad :
  //
  // Overlapping(bool): Defaults to false
  //     When set to True, it means when pooling, the values at the boundary
  // of adjacent pooling cells are used by both cells. For example:
  //
  // `index  0  1  2  3  4`
  //
  // `value  20 5  16 3  7`
  //
  // If the pooling sequence is [0, 2, 4], then 16, at index 2 will be used twice.
  // The result would be [41/3, 26/3] for fractional avg pooling.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Overlapping(@Cast("bool") boolean x);

    public native @Cast("bool") boolean overlapping_(); public native Attrs overlapping_(boolean overlapping_);
  }
  public FractionalAvgPoolGrad(@Const @ByRef Scope scope,
                        @ByVal Input orig_input_tensor_shape,
                        @ByVal Input out_backprop,
                        @ByVal Input row_pooling_sequence,
                        @ByVal Input col_pooling_sequence) { super((Pointer)null); allocate(scope, orig_input_tensor_shape, out_backprop, row_pooling_sequence, col_pooling_sequence); }
  private native void allocate(@Const @ByRef Scope scope,
                        @ByVal Input orig_input_tensor_shape,
                        @ByVal Input out_backprop,
                        @ByVal Input row_pooling_sequence,
                        @ByVal Input col_pooling_sequence);
  public FractionalAvgPoolGrad(@Const @ByRef Scope scope,
                        @ByVal Input orig_input_tensor_shape,
                        @ByVal Input out_backprop,
                        @ByVal Input row_pooling_sequence,
                        @ByVal Input col_pooling_sequence, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, orig_input_tensor_shape, out_backprop, row_pooling_sequence, col_pooling_sequence, attrs); }
  private native void allocate(@Const @ByRef Scope scope,
                        @ByVal Input orig_input_tensor_shape,
                        @ByVal Input out_backprop,
                        @ByVal Input row_pooling_sequence,
                        @ByVal Input col_pooling_sequence, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Overlapping(@Cast("bool") boolean x);

  public native @ByRef Output output(); public native FractionalAvgPoolGrad output(Output output);
}

// Performs fractional max pooling on the input.
//
// Fractional max pooling is slightly different than regular max pooling.  In
// regular max pooling, you downsize an input set by taking the maximum value of
// smaller N x N subsections of the set (often 2x2), and try to reduce the set by
// a factor of N, where N is an integer.  Fractional max pooling, as you might
// expect from the word "fractional", means that the overall reduction ratio N
// does not have to be an integer.
//
// The sizes of the pooling regions are generated randomly but are fairly uniform.
// For example, let's look at the height dimension, and the constraints on the
// list of rows that will be pool boundaries.
//
// First we define the following:
//
// 1.  input_row_length : the number of rows from the input set
// 2.  output_row_length : which will be smaller than the input
// 3.  alpha = input_row_length / output_row_length : our reduction ratio
// 4.  K = floor(alpha)
// 5.  row_pooling_sequence : this is the result list of pool boundary rows
//
// Then, row_pooling_sequence should satisfy:
//
// 1.  a[0] = 0 : the first value of the sequence is 0
// 2.  a[end] = input_row_length : the last value of the sequence is the size
// 3.  K <= (a[i+1] - a[i]) <= K+1 : all intervals are K or K+1 size
// 4.  length(row_pooling_sequence) = output_row_length+1
//
// For more details on fractional max pooling, see this paper:
// [Benjamin Graham, Fractional Max-Pooling]
// (http://arxiv.org/abs/1412.6071)
//
// Arguments:
// * scope: A Scope object
// * value: 4-D with shape `[batch, height, width, channels]`.
// * pooling_ratio:
//     Pooling ratio for each dimension of `value`, currently only
// supports row and col dimension and should be >= 1.0. For example, a valid
// pooling ratio looks like [1.0, 1.44, 1.73, 1.0]. The first and last elements
// must be 1.0 because we don't allow pooling on batch and channels
// dimensions. 1.44 and 1.73 are pooling ratio on height and width dimensions
// respectively.
@Namespace("tensorflow::ops") @NoOffset public static class FractionalMaxPool extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public FractionalMaxPool(Pointer p) { super(p); }

  // Optional attribute setters for FractionalMaxPool :
  //
  // PseudoRandom(bool): Defaults to false
  //     When set to True, generates the pooling sequence in a
  // pseudorandom fashion, otherwise, in a random fashion. Check paper [Benjamin
  // Graham, Fractional Max-Pooling] (http://arxiv.org/abs/1412.6071) for
  // difference between pseudorandom and random.
  // Overlapping(bool): Defaults to false
  //     When set to True, it means when pooling, the values at the boundary
  // of adjacent pooling cells are used by both cells. For example:
  //
  // `index  0  1  2  3  4`
  //
  // `value  20 5  16 3  7`
  //
  // If the pooling sequence is [0, 2, 4], then 16, at index 2 will be used twice.
  // The result would be [20, 16] for fractional max pooling.
  // Deterministic(bool): Defaults to false
  //     When set to True, a fixed pooling region will be used when
  // iterating over a FractionalMaxPool node in the computation graph. Mainly used
  // in unit test to make FractionalMaxPool deterministic.
  // Seed(int64): Defaults to 0
  //     If either seed or seed2 are set to be non-zero, the random number
  // generator is seeded by the given seed.  Otherwise, it is seeded by a
  // random seed.
  // Seed2(int64): Defaults to 0
  //     An second seed to avoid seed collision.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs PseudoRandom(@Cast("bool") boolean x);

    public native @ByVal Attrs Overlapping(@Cast("bool") boolean x);

    public native @ByVal Attrs Deterministic(@Cast("bool") boolean x);

    public native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);

    public native @Cast("bool") boolean pseudo_random_(); public native Attrs pseudo_random_(boolean pseudo_random_);
    public native @Cast("bool") boolean overlapping_(); public native Attrs overlapping_(boolean overlapping_);
    public native @Cast("bool") boolean deterministic_(); public native Attrs deterministic_(boolean deterministic_);
    public native @Cast("tensorflow::int64") long seed_(); public native Attrs seed_(long seed_);
    public native @Cast("tensorflow::int64") long seed2_(); public native Attrs seed2_(long seed2_);
  }
  public FractionalMaxPool(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice FloatPointer pooling_ratio) { super((Pointer)null); allocate(scope, value, pooling_ratio); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice FloatPointer pooling_ratio);
  public FractionalMaxPool(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice FloatBuffer pooling_ratio) { super((Pointer)null); allocate(scope, value, pooling_ratio); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice FloatBuffer pooling_ratio);
  public FractionalMaxPool(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice float... pooling_ratio) { super((Pointer)null); allocate(scope, value, pooling_ratio); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice float... pooling_ratio);
  public FractionalMaxPool(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice FloatPointer pooling_ratio, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, value, pooling_ratio, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice FloatPointer pooling_ratio, @Const @ByRef Attrs attrs);
  public FractionalMaxPool(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice FloatBuffer pooling_ratio, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, value, pooling_ratio, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice FloatBuffer pooling_ratio, @Const @ByRef Attrs attrs);
  public FractionalMaxPool(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice float[] pooling_ratio, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, value, pooling_ratio, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input value, @ArraySlice float[] pooling_ratio, @Const @ByRef Attrs attrs);

  public static native @ByVal Attrs PseudoRandom(@Cast("bool") boolean x);
  public static native @ByVal Attrs Overlapping(@Cast("bool") boolean x);
  public static native @ByVal Attrs Deterministic(@Cast("bool") boolean x);
  public static native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);

  public native @ByRef Output output(); public native FractionalMaxPool output(Output output);
  public native @ByRef Output row_pooling_sequence(); public native FractionalMaxPool row_pooling_sequence(Output row_pooling_sequence);
  public native @ByRef Output col_pooling_sequence(); public native FractionalMaxPool col_pooling_sequence(Output col_pooling_sequence);
}

// Computes gradient of the FractionalMaxPool function.
//
// Arguments:
// * scope: A Scope object
// * orig_input: Original input for `fractional_max_pool`
// * orig_output: Original output for `fractional_max_pool`
// * out_backprop: 4-D with shape `[batch, height, width, channels]`.  Gradients
// w.r.t. the output of `fractional_max_pool`.
// * row_pooling_sequence: row pooling sequence, form pooling region with
// col_pooling_sequence.
// * col_pooling_sequence: column pooling sequence, form pooling region with
// row_pooling sequence.
@Namespace("tensorflow::ops") @NoOffset public static class FractionalMaxPoolGrad extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public FractionalMaxPoolGrad(Pointer p) { super(p); }

  // Optional attribute setters for FractionalMaxPoolGrad :
  //
  // Overlapping(bool): Defaults to false
  //     When set to True, it means when pooling, the values at the boundary
  // of adjacent pooling cells are used by both cells. For example:
  //
  // `index  0  1  2  3  4`
  //
  // `value  20 5  16 3  7`
  //
  // If the pooling sequence is [0, 2, 4], then 16, at index 2 will be used twice.
  // The result would be [20, 16] for fractional max pooling.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Overlapping(@Cast("bool") boolean x);

    public native @Cast("bool") boolean overlapping_(); public native Attrs overlapping_(boolean overlapping_);
  }
  public FractionalMaxPoolGrad(@Const @ByRef Scope scope,
                        @ByVal Input orig_input,
                        @ByVal Input orig_output,
                        @ByVal Input out_backprop,
                        @ByVal Input row_pooling_sequence,
                        @ByVal Input col_pooling_sequence) { super((Pointer)null); allocate(scope, orig_input, orig_output, out_backprop, row_pooling_sequence, col_pooling_sequence); }
  private native void allocate(@Const @ByRef Scope scope,
                        @ByVal Input orig_input,
                        @ByVal Input orig_output,
                        @ByVal Input out_backprop,
                        @ByVal Input row_pooling_sequence,
                        @ByVal Input col_pooling_sequence);
  public FractionalMaxPoolGrad(@Const @ByRef Scope scope,
                        @ByVal Input orig_input,
                        @ByVal Input orig_output,
                        @ByVal Input out_backprop,
                        @ByVal Input row_pooling_sequence,
                        @ByVal Input col_pooling_sequence, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, orig_input, orig_output, out_backprop, row_pooling_sequence, col_pooling_sequence, attrs); }
  private native void allocate(@Const @ByRef Scope scope,
                        @ByVal Input orig_input,
                        @ByVal Input orig_output,
                        @ByVal Input out_backprop,
                        @ByVal Input row_pooling_sequence,
                        @ByVal Input col_pooling_sequence, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Overlapping(@Cast("bool") boolean x);

  public native @ByRef Output output(); public native FractionalMaxPoolGrad output(Output output);
}

// Performs a resize and padding as a preprocess during a convolution.
//
// It's often possible to do spatial transformations more efficiently as part of
// the packing stage of a convolution, so this op allows for an optimized
// implementation where these stages are fused together. This prevents the need to
// write out the intermediate results as whole tensors, reducing memory pressure,
// and we can get some latency gains by merging the transformation calculations.
// The data_format attribute for Conv2D isn't supported by this op, and defaults to
// 'NHWC' order.
// Internally this op uses a single per-graph scratch buffer, which means that it
// will block if multiple versions are being run in parallel. This is because this
// operator is primarily an optimization to minimize memory usage.
//
// Arguments:
// * scope: A Scope object
// * input: 4-D with shape `[batch, in_height, in_width, in_channels]`.
// * size: A 1-D int32 Tensor of 2 elements: `new_height, new_width`.  The
// new size for the images.
// * paddings: A two-column matrix specifying the padding sizes. The number of
// rows must be the same as the rank of `input`.
// * filter: 4-D with shape
// `[filter_height, filter_width, in_channels, out_channels]`.
// * strides:
//     1-D of length 4.  The stride of the sliding window for each dimension
// of `input`. Must be in the same order as the dimension specified with format.
// * padding:
//     The type of padding algorithm to use.
@Namespace("tensorflow::ops") @NoOffset public static class FusedResizeAndPadConv2D extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public FusedResizeAndPadConv2D(Pointer p) { super(p); }

  // Optional attribute setters for FusedResizeAndPadConv2D :
  //
  // ResizeAlignCorners(bool): Defaults to false
  //     If true, rescale input by (new_height - 1) / (height - 1),
  // which exactly aligns the 4 corners of images and resized images. If false, rescale
  // by new_height / height. Treat similarly the width dimension.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs ResizeAlignCorners(@Cast("bool") boolean x);

    public native @Cast("bool") boolean resize_align_corners_(); public native Attrs resize_align_corners_(boolean resize_align_corners_);
  }
  public FusedResizeAndPadConv2D(@Const @ByRef Scope scope,
                          @ByVal Input input,
                          @ByVal Input size, @ByVal Input paddings, @ByVal Input filter, @StringPiece BytePointer mode, @ArraySlice IntPointer strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, size, paddings, filter, mode, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                          @ByVal Input input,
                          @ByVal Input size, @ByVal Input paddings, @ByVal Input filter, @StringPiece BytePointer mode, @ArraySlice IntPointer strides, @StringPiece BytePointer padding);
  public FusedResizeAndPadConv2D(@Const @ByRef Scope scope,
                          @ByVal Input input,
                          @ByVal Input size, @ByVal Input paddings, @ByVal Input filter, @StringPiece String mode, @ArraySlice IntBuffer strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, input, size, paddings, filter, mode, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                          @ByVal Input input,
                          @ByVal Input size, @ByVal Input paddings, @ByVal Input filter, @StringPiece String mode, @ArraySlice IntBuffer strides, @StringPiece String padding);
  public FusedResizeAndPadConv2D(@Const @ByRef Scope scope,
                          @ByVal Input input,
                          @ByVal Input size, @ByVal Input paddings, @ByVal Input filter, @StringPiece BytePointer mode, @ArraySlice int[] strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, size, paddings, filter, mode, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                          @ByVal Input input,
                          @ByVal Input size, @ByVal Input paddings, @ByVal Input filter, @StringPiece BytePointer mode, @ArraySlice int[] strides, @StringPiece BytePointer padding);
  public FusedResizeAndPadConv2D(@Const @ByRef Scope scope,
                          @ByVal Input input,
                          @ByVal Input size, @ByVal Input paddings, @ByVal Input filter, @StringPiece String mode, @ArraySlice IntPointer strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, input, size, paddings, filter, mode, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                          @ByVal Input input,
                          @ByVal Input size, @ByVal Input paddings, @ByVal Input filter, @StringPiece String mode, @ArraySlice IntPointer strides, @StringPiece String padding);
  public FusedResizeAndPadConv2D(@Const @ByRef Scope scope,
                          @ByVal Input input,
                          @ByVal Input size, @ByVal Input paddings, @ByVal Input filter, @StringPiece BytePointer mode, @ArraySlice IntBuffer strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, size, paddings, filter, mode, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                          @ByVal Input input,
                          @ByVal Input size, @ByVal Input paddings, @ByVal Input filter, @StringPiece BytePointer mode, @ArraySlice IntBuffer strides, @StringPiece BytePointer padding);
  public FusedResizeAndPadConv2D(@Const @ByRef Scope scope,
                          @ByVal Input input,
                          @ByVal Input size, @ByVal Input paddings, @ByVal Input filter, @StringPiece String mode, @ArraySlice int[] strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, input, size, paddings, filter, mode, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                          @ByVal Input input,
                          @ByVal Input size, @ByVal Input paddings, @ByVal Input filter, @StringPiece String mode, @ArraySlice int[] strides, @StringPiece String padding);
  public FusedResizeAndPadConv2D(@Const @ByRef Scope scope,
                          @ByVal Input input,
                          @ByVal Input size, @ByVal Input paddings, @ByVal Input filter, @StringPiece BytePointer mode, @ArraySlice IntPointer strides, @StringPiece BytePointer padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, size, paddings, filter, mode, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope,
                          @ByVal Input input,
                          @ByVal Input size, @ByVal Input paddings, @ByVal Input filter, @StringPiece BytePointer mode, @ArraySlice IntPointer strides, @StringPiece BytePointer padding, @Const @ByRef Attrs attrs);
  public FusedResizeAndPadConv2D(@Const @ByRef Scope scope,
                          @ByVal Input input,
                          @ByVal Input size, @ByVal Input paddings, @ByVal Input filter, @StringPiece String mode, @ArraySlice IntBuffer strides, @StringPiece String padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, size, paddings, filter, mode, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope,
                          @ByVal Input input,
                          @ByVal Input size, @ByVal Input paddings, @ByVal Input filter, @StringPiece String mode, @ArraySlice IntBuffer strides, @StringPiece String padding, @Const @ByRef Attrs attrs);
  public FusedResizeAndPadConv2D(@Const @ByRef Scope scope,
                          @ByVal Input input,
                          @ByVal Input size, @ByVal Input paddings, @ByVal Input filter, @StringPiece BytePointer mode, @ArraySlice int[] strides, @StringPiece BytePointer padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, size, paddings, filter, mode, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope,
                          @ByVal Input input,
                          @ByVal Input size, @ByVal Input paddings, @ByVal Input filter, @StringPiece BytePointer mode, @ArraySlice int[] strides, @StringPiece BytePointer padding, @Const @ByRef Attrs attrs);
  public FusedResizeAndPadConv2D(@Const @ByRef Scope scope,
                          @ByVal Input input,
                          @ByVal Input size, @ByVal Input paddings, @ByVal Input filter, @StringPiece String mode, @ArraySlice IntPointer strides, @StringPiece String padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, size, paddings, filter, mode, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope,
                          @ByVal Input input,
                          @ByVal Input size, @ByVal Input paddings, @ByVal Input filter, @StringPiece String mode, @ArraySlice IntPointer strides, @StringPiece String padding, @Const @ByRef Attrs attrs);
  public FusedResizeAndPadConv2D(@Const @ByRef Scope scope,
                          @ByVal Input input,
                          @ByVal Input size, @ByVal Input paddings, @ByVal Input filter, @StringPiece BytePointer mode, @ArraySlice IntBuffer strides, @StringPiece BytePointer padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, size, paddings, filter, mode, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope,
                          @ByVal Input input,
                          @ByVal Input size, @ByVal Input paddings, @ByVal Input filter, @StringPiece BytePointer mode, @ArraySlice IntBuffer strides, @StringPiece BytePointer padding, @Const @ByRef Attrs attrs);
  public FusedResizeAndPadConv2D(@Const @ByRef Scope scope,
                          @ByVal Input input,
                          @ByVal Input size, @ByVal Input paddings, @ByVal Input filter, @StringPiece String mode, @ArraySlice int[] strides, @StringPiece String padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, size, paddings, filter, mode, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope,
                          @ByVal Input input,
                          @ByVal Input size, @ByVal Input paddings, @ByVal Input filter, @StringPiece String mode, @ArraySlice int[] strides, @StringPiece String padding, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs ResizeAlignCorners(@Cast("bool") boolean x);

  public native @ByRef Output output(); public native FusedResizeAndPadConv2D output(Output output);
}

// Says whether the targets are in the top `K` predictions.
//
// This outputs a `batch_size` bool array, an entry `out[i]` is `true` if the
// prediction for the target class is among the top `k` predictions among
// all predictions for example `i`. Note that the behavior of `InTopK` differs
// from the `TopK` op in its handling of ties; if multiple classes have the
// same prediction value and straddle the top-`k` boundary, all of those
// classes are considered to be in the top `k`.
//
// More formally, let
//
//   \\(predictions_i\\) be the predictions for all classes for example `i`,
//   \\(targets_i\\) be the target class for example `i`,
//   \\(out_i\\) be the output for example `i`,
//
// $$out_i = predictions_{i, targets_i} \in TopKIncludingTies(predictions_i)$$
//
// Arguments:
// * scope: A Scope object
// * predictions: A `batch_size` x `classes` tensor.
// * targets: A `batch_size` vector of class ids.
// * k:
//     Number of top elements to look at for computing precision.
@Namespace("tensorflow::ops") @NoOffset public static class InTopK extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public InTopK(Pointer p) { super(p); }

  public InTopK(@Const @ByRef Scope scope, @ByVal Input predictions,
         @ByVal Input targets, @Cast("tensorflow::int64") long k) { super((Pointer)null); allocate(scope, predictions, targets, k); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input predictions,
         @ByVal Input targets, @Cast("tensorflow::int64") long k);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output precision(); public native InTopK precision(Output precision);
}

// L2 Loss.
//
// Computes half the L2 norm of a tensor without the `sqrt`:
//
//     output = sum(t ** 2) / 2
//
// Arguments:
// * scope: A Scope object
// * t: Typically 2-D, but may have any dimensions.
@Namespace("tensorflow::ops") @NoOffset public static class L2Loss extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public L2Loss(Pointer p) { super(p); }

  public L2Loss(@Const @ByRef Scope scope, @ByVal Input t) { super((Pointer)null); allocate(scope, t); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input t);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native L2Loss output(Output output);
}

// Local Response Normalization.
//
// The 4-D `input` tensor is treated as a 3-D array of 1-D vectors (along the last
// dimension), and each vector is normalized independently.  Within a given vector,
// each component is divided by the weighted, squared sum of inputs within
// `depth_radius`.  In detail,
//
//     sqr_sum[a, b, c, d] =
//         sum(input[a, b, c, d - depth_radius : d + depth_radius + 1] ** 2)
//     output = input / (bias + alpha * sqr_sum) ** beta
//
// For details, see [Krizhevsky et al., ImageNet classification with deep
// convolutional neural networks (NIPS 2012)]
// (http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks).
//
// Arguments:
// * scope: A Scope object
// * input: 4-D.
@Namespace("tensorflow::ops") @NoOffset public static class LRN extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public LRN(Pointer p) { super(p); }

  // Optional attribute setters for LRN :
  //
  // DepthRadius(int64): Defaults to 5
  //     0-D.  Half-width of the 1-D normalization window.
  // Bias(float): Defaults to 1
  //     An offset (usually positive to avoid dividing by 0).
  // Alpha(float): Defaults to 1
  //     A scale factor, usually positive.
  // Beta(float): Defaults to 0.5
  //     An exponent.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs DepthRadius(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs Bias(float x);

    public native @ByVal Attrs Alpha(float x);

    public native @ByVal Attrs Beta(float x);

    public native @Cast("tensorflow::int64") long depth_radius_(); public native Attrs depth_radius_(long depth_radius_);
    public native float bias_(); public native Attrs bias_(float bias_);
    public native float alpha_(); public native Attrs alpha_(float alpha_);
    public native float beta_(); public native Attrs beta_(float beta_);
  }
  public LRN(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public LRN(@Const @ByRef Scope scope, @ByVal Input input, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs DepthRadius(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs Bias(float x);
  public static native @ByVal Attrs Alpha(float x);
  public static native @ByVal Attrs Beta(float x);

  public native @ByRef Output output(); public native LRN output(Output output);
}

// Gradients for Local Response Normalization.
//
// Arguments:
// * scope: A Scope object
// * input_grads: 4-D with shape `[batch, height, width, channels]`.
// * input_image: 4-D with shape `[batch, height, width, channels]`.
// * output_image: 4-D with shape `[batch, height, width, channels]`.
@Namespace("tensorflow::ops") @NoOffset public static class LRNGrad extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public LRNGrad(Pointer p) { super(p); }

  // Optional attribute setters for LRNGrad :
  //
  // DepthRadius(int64): Defaults to 5
  //     A depth radius.
  // Bias(float): Defaults to 1
  //     An offset (usually > 0 to avoid dividing by 0).
  // Alpha(float): Defaults to 1
  //     A scale factor, usually positive.
  // Beta(float): Defaults to 0.5
  //     An exponent.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs DepthRadius(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs Bias(float x);

    public native @ByVal Attrs Alpha(float x);

    public native @ByVal Attrs Beta(float x);

    public native @Cast("tensorflow::int64") long depth_radius_(); public native Attrs depth_radius_(long depth_radius_);
    public native float bias_(); public native Attrs bias_(float bias_);
    public native float alpha_(); public native Attrs alpha_(float alpha_);
    public native float beta_(); public native Attrs beta_(float beta_);
  }
  public LRNGrad(@Const @ByRef Scope scope, @ByVal Input input_grads,
          @ByVal Input input_image, @ByVal Input output_image) { super((Pointer)null); allocate(scope, input_grads, input_image, output_image); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input_grads,
          @ByVal Input input_image, @ByVal Input output_image);
  public LRNGrad(@Const @ByRef Scope scope, @ByVal Input input_grads,
          @ByVal Input input_image, @ByVal Input output_image, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input_grads, input_image, output_image, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input_grads,
          @ByVal Input input_image, @ByVal Input output_image, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs DepthRadius(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs Bias(float x);
  public static native @ByVal Attrs Alpha(float x);
  public static native @ByVal Attrs Beta(float x);

  public native @ByRef Output output(); public native LRNGrad output(Output output);
}

// Computes log softmax activations.
//
// For each batch `i` and class `j` we have
//
//     logsoftmax[i, j] = logits[i, j] - log(sum(exp(logits[i])))
//
// Arguments:
// * scope: A Scope object
// * logits: 2-D with shape `[batch_size, num_classes]`.
@Namespace("tensorflow::ops") @NoOffset public static class LogSoftmax extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public LogSoftmax(Pointer p) { super(p); }

  public LogSoftmax(@Const @ByRef Scope scope, @ByVal Input logits) { super((Pointer)null); allocate(scope, logits); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input logits);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output logsoftmax(); public native LogSoftmax logsoftmax(Output logsoftmax);
}

// Performs max pooling on the input.
//
// Arguments:
// * scope: A Scope object
// * input: 4-D input to pool over.
// * ksize:
//     The size of the window for each dimension of the input tensor.
// * strides:
//     The stride of the sliding window for each dimension of the
// input tensor.
// * padding:
//     The type of padding algorithm to use.
@Namespace("tensorflow::ops") @NoOffset public static class MaxPool extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public MaxPool(Pointer p) { super(p); }

  // Optional attribute setters for MaxPool :
  //
  // DataFormat(StringPiece): Defaults to "NHWC"
  //     Specify the data format of the input and output data. With the
  // default format "NHWC", the data is stored in the order of:
  //     [batch, in_height, in_width, in_channels].
  // Alternatively, the format could be "NCHW", the data storage order of:
  //     [batch, in_channels, in_height, in_width].
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs DataFormat(@StringPiece BytePointer x);
    public native @ByVal Attrs DataFormat(@StringPiece String x);

    public native @StringPiece BytePointer data_format_(); public native Attrs data_format_(BytePointer data_format_);
  }
  public MaxPool(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides,
          @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides,
          @StringPiece BytePointer padding);
  public MaxPool(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides,
          @StringPiece String padding) { super((Pointer)null); allocate(scope, input, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides,
          @StringPiece String padding);
  public MaxPool(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice int[] ksize, @ArraySlice int[] strides,
          @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice int[] ksize, @ArraySlice int[] strides,
          @StringPiece BytePointer padding);
  public MaxPool(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides,
          @StringPiece String padding) { super((Pointer)null); allocate(scope, input, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides,
          @StringPiece String padding);
  public MaxPool(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides,
          @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides,
          @StringPiece BytePointer padding);
  public MaxPool(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice int[] ksize, @ArraySlice int[] strides,
          @StringPiece String padding) { super((Pointer)null); allocate(scope, input, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice int[] ksize, @ArraySlice int[] strides,
          @StringPiece String padding);
  public MaxPool(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides,
          @StringPiece BytePointer padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, ksize, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides,
          @StringPiece BytePointer padding, @Const @ByRef Attrs attrs);
  public MaxPool(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides,
          @StringPiece String padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, ksize, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides,
          @StringPiece String padding, @Const @ByRef Attrs attrs);
  public MaxPool(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice int[] ksize, @ArraySlice int[] strides,
          @StringPiece BytePointer padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, ksize, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice int[] ksize, @ArraySlice int[] strides,
          @StringPiece BytePointer padding, @Const @ByRef Attrs attrs);
  public MaxPool(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides,
          @StringPiece String padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, ksize, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides,
          @StringPiece String padding, @Const @ByRef Attrs attrs);
  public MaxPool(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides,
          @StringPiece BytePointer padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, ksize, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides,
          @StringPiece BytePointer padding, @Const @ByRef Attrs attrs);
  public MaxPool(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice int[] ksize, @ArraySlice int[] strides,
          @StringPiece String padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, ksize, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice int[] ksize, @ArraySlice int[] strides,
          @StringPiece String padding, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs DataFormat(@StringPiece BytePointer x);
  public static native @ByVal Attrs DataFormat(@StringPiece String x);

  public native @ByRef Output output(); public native MaxPool output(Output output);
}

// Performs 3D max pooling on the input.
//
// Arguments:
// * scope: A Scope object
// * input: Shape `[batch, depth, rows, cols, channels]` tensor to pool over.
// * ksize:
//     1-D tensor of length 5. The size of the window for each dimension of
// the input tensor. Must have `ksize[0] = ksize[4] = 1`.
// * strides:
//     1-D tensor of length 5. The stride of the sliding window for each
// dimension of `input`. Must have `strides[0] = strides[4] = 1`.
// * padding:
//     The type of padding algorithm to use.
@Namespace("tensorflow::ops") @NoOffset public static class MaxPool3D extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public MaxPool3D(Pointer p) { super(p); }

  public MaxPool3D(@Const @ByRef Scope scope, @ByVal Input input,
            @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
            @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides, @StringPiece BytePointer padding);
  public MaxPool3D(@Const @ByRef Scope scope, @ByVal Input input,
            @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, input, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
            @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides, @StringPiece String padding);
  public MaxPool3D(@Const @ByRef Scope scope, @ByVal Input input,
            @ArraySlice int[] ksize, @ArraySlice int[] strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
            @ArraySlice int[] ksize, @ArraySlice int[] strides, @StringPiece BytePointer padding);
  public MaxPool3D(@Const @ByRef Scope scope, @ByVal Input input,
            @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, input, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
            @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides, @StringPiece String padding);
  public MaxPool3D(@Const @ByRef Scope scope, @ByVal Input input,
            @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
            @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides, @StringPiece BytePointer padding);
  public MaxPool3D(@Const @ByRef Scope scope, @ByVal Input input,
            @ArraySlice int[] ksize, @ArraySlice int[] strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, input, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
            @ArraySlice int[] ksize, @ArraySlice int[] strides, @StringPiece String padding);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native MaxPool3D output(Output output);
}

// Computes gradients of max pooling function.
//
// Arguments:
// * scope: A Scope object
// * orig_input: The original input tensor.
// * orig_output: The original output tensor.
// * grad: Output backprop of shape `[batch, depth, rows, cols, channels]`.
// * ksize:
//     1-D tensor of length 5. The size of the window for each dimension of
// the input tensor. Must have `ksize[0] = ksize[4] = 1`.
// * strides:
//     1-D tensor of length 5. The stride of the sliding window for each
// dimension of `input`. Must have `strides[0] = strides[4] = 1`.
// * padding:
//     The type of padding algorithm to use.
@Namespace("tensorflow::ops") @NoOffset public static class MaxPool3DGrad extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public MaxPool3DGrad(Pointer p) { super(p); }

  public MaxPool3DGrad(@Const @ByRef Scope scope, @ByVal Input orig_input, @ByVal Input orig_output,
                @ByVal Input grad, @ArraySlice IntPointer ksize,
                @ArraySlice IntPointer strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, orig_input, orig_output, grad, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input orig_input, @ByVal Input orig_output,
                @ByVal Input grad, @ArraySlice IntPointer ksize,
                @ArraySlice IntPointer strides, @StringPiece BytePointer padding);
  public MaxPool3DGrad(@Const @ByRef Scope scope, @ByVal Input orig_input, @ByVal Input orig_output,
                @ByVal Input grad, @ArraySlice IntBuffer ksize,
                @ArraySlice IntBuffer strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, orig_input, orig_output, grad, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input orig_input, @ByVal Input orig_output,
                @ByVal Input grad, @ArraySlice IntBuffer ksize,
                @ArraySlice IntBuffer strides, @StringPiece String padding);
  public MaxPool3DGrad(@Const @ByRef Scope scope, @ByVal Input orig_input, @ByVal Input orig_output,
                @ByVal Input grad, @ArraySlice int[] ksize,
                @ArraySlice int[] strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, orig_input, orig_output, grad, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input orig_input, @ByVal Input orig_output,
                @ByVal Input grad, @ArraySlice int[] ksize,
                @ArraySlice int[] strides, @StringPiece BytePointer padding);
  public MaxPool3DGrad(@Const @ByRef Scope scope, @ByVal Input orig_input, @ByVal Input orig_output,
                @ByVal Input grad, @ArraySlice IntPointer ksize,
                @ArraySlice IntPointer strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, orig_input, orig_output, grad, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input orig_input, @ByVal Input orig_output,
                @ByVal Input grad, @ArraySlice IntPointer ksize,
                @ArraySlice IntPointer strides, @StringPiece String padding);
  public MaxPool3DGrad(@Const @ByRef Scope scope, @ByVal Input orig_input, @ByVal Input orig_output,
                @ByVal Input grad, @ArraySlice IntBuffer ksize,
                @ArraySlice IntBuffer strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, orig_input, orig_output, grad, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input orig_input, @ByVal Input orig_output,
                @ByVal Input grad, @ArraySlice IntBuffer ksize,
                @ArraySlice IntBuffer strides, @StringPiece BytePointer padding);
  public MaxPool3DGrad(@Const @ByRef Scope scope, @ByVal Input orig_input, @ByVal Input orig_output,
                @ByVal Input grad, @ArraySlice int[] ksize,
                @ArraySlice int[] strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, orig_input, orig_output, grad, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input orig_input, @ByVal Input orig_output,
                @ByVal Input grad, @ArraySlice int[] ksize,
                @ArraySlice int[] strides, @StringPiece String padding);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native MaxPool3DGrad output(Output output);
}

// Computes gradients of the maxpooling function.
//
// Arguments:
// * scope: A Scope object
// * orig_input: The original input tensor.
// * orig_output: The original output tensor.
// * grad: 4-D.  Gradients w.r.t. the output of `max_pool`.
// * ksize:
//     The size of the window for each dimension of the input tensor.
// * strides:
//     The stride of the sliding window for each dimension of the
// input tensor.
// * padding:
//     The type of padding algorithm to use.
@Namespace("tensorflow::ops") @NoOffset public static class MaxPoolGrad extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public MaxPoolGrad(Pointer p) { super(p); }

  // Optional attribute setters for MaxPoolGrad :
  //
  // DataFormat(StringPiece): Defaults to "NHWC"
  //     Specify the data format of the input and output data. With the
  // default format "NHWC", the data is stored in the order of:
  //     [batch, in_height, in_width, in_channels].
  // Alternatively, the format could be "NCHW", the data storage order of:
  //     [batch, in_channels, in_height, in_width].
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs DataFormat(@StringPiece BytePointer x);
    public native @ByVal Attrs DataFormat(@StringPiece String x);

    public native @StringPiece BytePointer data_format_(); public native Attrs data_format_(BytePointer data_format_);
  }
  public MaxPoolGrad(@Const @ByRef Scope scope, @ByVal Input orig_input, @ByVal Input orig_output,
              @ByVal Input grad, @ArraySlice IntPointer ksize,
              @ArraySlice IntPointer strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, orig_input, orig_output, grad, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input orig_input, @ByVal Input orig_output,
              @ByVal Input grad, @ArraySlice IntPointer ksize,
              @ArraySlice IntPointer strides, @StringPiece BytePointer padding);
  public MaxPoolGrad(@Const @ByRef Scope scope, @ByVal Input orig_input, @ByVal Input orig_output,
              @ByVal Input grad, @ArraySlice IntBuffer ksize,
              @ArraySlice IntBuffer strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, orig_input, orig_output, grad, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input orig_input, @ByVal Input orig_output,
              @ByVal Input grad, @ArraySlice IntBuffer ksize,
              @ArraySlice IntBuffer strides, @StringPiece String padding);
  public MaxPoolGrad(@Const @ByRef Scope scope, @ByVal Input orig_input, @ByVal Input orig_output,
              @ByVal Input grad, @ArraySlice int[] ksize,
              @ArraySlice int[] strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, orig_input, orig_output, grad, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input orig_input, @ByVal Input orig_output,
              @ByVal Input grad, @ArraySlice int[] ksize,
              @ArraySlice int[] strides, @StringPiece BytePointer padding);
  public MaxPoolGrad(@Const @ByRef Scope scope, @ByVal Input orig_input, @ByVal Input orig_output,
              @ByVal Input grad, @ArraySlice IntPointer ksize,
              @ArraySlice IntPointer strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, orig_input, orig_output, grad, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input orig_input, @ByVal Input orig_output,
              @ByVal Input grad, @ArraySlice IntPointer ksize,
              @ArraySlice IntPointer strides, @StringPiece String padding);
  public MaxPoolGrad(@Const @ByRef Scope scope, @ByVal Input orig_input, @ByVal Input orig_output,
              @ByVal Input grad, @ArraySlice IntBuffer ksize,
              @ArraySlice IntBuffer strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, orig_input, orig_output, grad, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input orig_input, @ByVal Input orig_output,
              @ByVal Input grad, @ArraySlice IntBuffer ksize,
              @ArraySlice IntBuffer strides, @StringPiece BytePointer padding);
  public MaxPoolGrad(@Const @ByRef Scope scope, @ByVal Input orig_input, @ByVal Input orig_output,
              @ByVal Input grad, @ArraySlice int[] ksize,
              @ArraySlice int[] strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, orig_input, orig_output, grad, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input orig_input, @ByVal Input orig_output,
              @ByVal Input grad, @ArraySlice int[] ksize,
              @ArraySlice int[] strides, @StringPiece String padding);
  public MaxPoolGrad(@Const @ByRef Scope scope, @ByVal Input orig_input, @ByVal Input orig_output,
              @ByVal Input grad, @ArraySlice IntPointer ksize,
              @ArraySlice IntPointer strides, @StringPiece BytePointer padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, orig_input, orig_output, grad, ksize, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input orig_input, @ByVal Input orig_output,
              @ByVal Input grad, @ArraySlice IntPointer ksize,
              @ArraySlice IntPointer strides, @StringPiece BytePointer padding, @Const @ByRef Attrs attrs);
  public MaxPoolGrad(@Const @ByRef Scope scope, @ByVal Input orig_input, @ByVal Input orig_output,
              @ByVal Input grad, @ArraySlice IntBuffer ksize,
              @ArraySlice IntBuffer strides, @StringPiece String padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, orig_input, orig_output, grad, ksize, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input orig_input, @ByVal Input orig_output,
              @ByVal Input grad, @ArraySlice IntBuffer ksize,
              @ArraySlice IntBuffer strides, @StringPiece String padding, @Const @ByRef Attrs attrs);
  public MaxPoolGrad(@Const @ByRef Scope scope, @ByVal Input orig_input, @ByVal Input orig_output,
              @ByVal Input grad, @ArraySlice int[] ksize,
              @ArraySlice int[] strides, @StringPiece BytePointer padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, orig_input, orig_output, grad, ksize, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input orig_input, @ByVal Input orig_output,
              @ByVal Input grad, @ArraySlice int[] ksize,
              @ArraySlice int[] strides, @StringPiece BytePointer padding, @Const @ByRef Attrs attrs);
  public MaxPoolGrad(@Const @ByRef Scope scope, @ByVal Input orig_input, @ByVal Input orig_output,
              @ByVal Input grad, @ArraySlice IntPointer ksize,
              @ArraySlice IntPointer strides, @StringPiece String padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, orig_input, orig_output, grad, ksize, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input orig_input, @ByVal Input orig_output,
              @ByVal Input grad, @ArraySlice IntPointer ksize,
              @ArraySlice IntPointer strides, @StringPiece String padding, @Const @ByRef Attrs attrs);
  public MaxPoolGrad(@Const @ByRef Scope scope, @ByVal Input orig_input, @ByVal Input orig_output,
              @ByVal Input grad, @ArraySlice IntBuffer ksize,
              @ArraySlice IntBuffer strides, @StringPiece BytePointer padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, orig_input, orig_output, grad, ksize, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input orig_input, @ByVal Input orig_output,
              @ByVal Input grad, @ArraySlice IntBuffer ksize,
              @ArraySlice IntBuffer strides, @StringPiece BytePointer padding, @Const @ByRef Attrs attrs);
  public MaxPoolGrad(@Const @ByRef Scope scope, @ByVal Input orig_input, @ByVal Input orig_output,
              @ByVal Input grad, @ArraySlice int[] ksize,
              @ArraySlice int[] strides, @StringPiece String padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, orig_input, orig_output, grad, ksize, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input orig_input, @ByVal Input orig_output,
              @ByVal Input grad, @ArraySlice int[] ksize,
              @ArraySlice int[] strides, @StringPiece String padding, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs DataFormat(@StringPiece BytePointer x);
  public static native @ByVal Attrs DataFormat(@StringPiece String x);

  public native @ByRef Output output(); public native MaxPoolGrad output(Output output);
}

// Computes gradients of the maxpooling function.
//
// Arguments:
// * scope: A Scope object
// * input: The original input.
// * grad: 4-D with shape `[batch, height, width, channels]`.  Gradients w.r.t. the
// output of `max_pool`.
// * argmax: The indices of the maximum values chosen for each output of `max_pool`.
// * ksize:
//     The size of the window for each dimension of the input tensor.
// * strides:
//     The stride of the sliding window for each dimension of the
// input tensor.
// * padding:
//     The type of padding algorithm to use.
@Namespace("tensorflow::ops") @NoOffset public static class MaxPoolGradWithArgmax extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public MaxPoolGradWithArgmax(Pointer p) { super(p); }

  public MaxPoolGradWithArgmax(@Const @ByRef Scope scope,
                        @ByVal Input input, @ByVal Input grad, @ByVal Input argmax, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, grad, argmax, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                        @ByVal Input input, @ByVal Input grad, @ByVal Input argmax, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides, @StringPiece BytePointer padding);
  public MaxPoolGradWithArgmax(@Const @ByRef Scope scope,
                        @ByVal Input input, @ByVal Input grad, @ByVal Input argmax, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, input, grad, argmax, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                        @ByVal Input input, @ByVal Input grad, @ByVal Input argmax, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides, @StringPiece String padding);
  public MaxPoolGradWithArgmax(@Const @ByRef Scope scope,
                        @ByVal Input input, @ByVal Input grad, @ByVal Input argmax, @ArraySlice int[] ksize, @ArraySlice int[] strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, grad, argmax, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                        @ByVal Input input, @ByVal Input grad, @ByVal Input argmax, @ArraySlice int[] ksize, @ArraySlice int[] strides, @StringPiece BytePointer padding);
  public MaxPoolGradWithArgmax(@Const @ByRef Scope scope,
                        @ByVal Input input, @ByVal Input grad, @ByVal Input argmax, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, input, grad, argmax, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                        @ByVal Input input, @ByVal Input grad, @ByVal Input argmax, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides, @StringPiece String padding);
  public MaxPoolGradWithArgmax(@Const @ByRef Scope scope,
                        @ByVal Input input, @ByVal Input grad, @ByVal Input argmax, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, grad, argmax, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                        @ByVal Input input, @ByVal Input grad, @ByVal Input argmax, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides, @StringPiece BytePointer padding);
  public MaxPoolGradWithArgmax(@Const @ByRef Scope scope,
                        @ByVal Input input, @ByVal Input grad, @ByVal Input argmax, @ArraySlice int[] ksize, @ArraySlice int[] strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, input, grad, argmax, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope,
                        @ByVal Input input, @ByVal Input grad, @ByVal Input argmax, @ArraySlice int[] ksize, @ArraySlice int[] strides, @StringPiece String padding);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native MaxPoolGradWithArgmax output(Output output);
}

// Performs max pooling on the input and outputs both max values and indices.
//
// The indices in `argmax` are flattened, so that a maximum value at position
// `[b, y, x, c]` becomes flattened index
// `((b * height + y) * width + x) * channels + c`.
//
// Arguments:
// * scope: A Scope object
// * input: 4-D with shape `[batch, height, width, channels]`.  Input to pool over.
// * ksize:
//     The size of the window for each dimension of the input tensor.
// * strides:
//     The stride of the sliding window for each dimension of the
// input tensor.
// * padding:
//     The type of padding algorithm to use.
@Namespace("tensorflow::ops") @NoOffset public static class MaxPoolWithArgmax extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public MaxPoolWithArgmax(Pointer p) { super(p); }

  // Optional attribute setters for MaxPoolWithArgmax :
  //
  // Targmax(DataType): Defaults to DT_INT64
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Targmax(@Cast("tensorflow::DataType") int x);

    public native @Cast("tensorflow::DataType") int Targmax_(); public native Attrs Targmax_(int Targmax_);
  }
  public MaxPoolWithArgmax(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides, @StringPiece BytePointer padding);
  public MaxPoolWithArgmax(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, input, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides, @StringPiece String padding);
  public MaxPoolWithArgmax(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice int[] ksize, @ArraySlice int[] strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice int[] ksize, @ArraySlice int[] strides, @StringPiece BytePointer padding);
  public MaxPoolWithArgmax(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, input, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides, @StringPiece String padding);
  public MaxPoolWithArgmax(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides, @StringPiece BytePointer padding) { super((Pointer)null); allocate(scope, input, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides, @StringPiece BytePointer padding);
  public MaxPoolWithArgmax(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice int[] ksize, @ArraySlice int[] strides, @StringPiece String padding) { super((Pointer)null); allocate(scope, input, ksize, strides, padding); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice int[] ksize, @ArraySlice int[] strides, @StringPiece String padding);
  public MaxPoolWithArgmax(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides, @StringPiece BytePointer padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, ksize, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides, @StringPiece BytePointer padding, @Const @ByRef Attrs attrs);
  public MaxPoolWithArgmax(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides, @StringPiece String padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, ksize, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides, @StringPiece String padding, @Const @ByRef Attrs attrs);
  public MaxPoolWithArgmax(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice int[] ksize, @ArraySlice int[] strides, @StringPiece BytePointer padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, ksize, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice int[] ksize, @ArraySlice int[] strides, @StringPiece BytePointer padding, @Const @ByRef Attrs attrs);
  public MaxPoolWithArgmax(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides, @StringPiece String padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, ksize, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice IntPointer ksize, @ArraySlice IntPointer strides, @StringPiece String padding, @Const @ByRef Attrs attrs);
  public MaxPoolWithArgmax(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides, @StringPiece BytePointer padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, ksize, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice IntBuffer ksize, @ArraySlice IntBuffer strides, @StringPiece BytePointer padding, @Const @ByRef Attrs attrs);
  public MaxPoolWithArgmax(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice int[] ksize, @ArraySlice int[] strides, @StringPiece String padding, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, ksize, strides, padding, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @ArraySlice int[] ksize, @ArraySlice int[] strides, @StringPiece String padding, @Const @ByRef Attrs attrs);

  public static native @ByVal Attrs Targmax(@Cast("tensorflow::DataType") int x);

  public native @ByRef Output output(); public native MaxPoolWithArgmax output(Output output);
  public native @ByRef Output argmax(); public native MaxPoolWithArgmax argmax(Output argmax);
}

// Computes rectified linear: `max(features, 0)`.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Relu extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Relu(Pointer p) { super(p); }

  public Relu(@Const @ByRef Scope scope, @ByVal Input features) { super((Pointer)null); allocate(scope, features); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input features);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output activations(); public native Relu activations(Output activations);
}

// Computes rectified linear 6: `min(max(features, 0), 6)`.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Relu6 extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Relu6(Pointer p) { super(p); }

  public Relu6(@Const @ByRef Scope scope, @ByVal Input features) { super((Pointer)null); allocate(scope, features); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input features);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output activations(); public native Relu6 activations(Output activations);
}

// Computes rectified linear 6 gradients for a Relu6 operation.
//
// Arguments:
// * scope: A Scope object
// * gradients: The backpropagated gradients to the corresponding Relu6 operation.
// * features: The features passed as input to the corresponding Relu6 operation.
@Namespace("tensorflow::ops") @NoOffset public static class Relu6Grad extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Relu6Grad(Pointer p) { super(p); }

  public Relu6Grad(@Const @ByRef Scope scope, @ByVal Input gradients,
            @ByVal Input features) { super((Pointer)null); allocate(scope, gradients, features); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input gradients,
            @ByVal Input features);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output backprops(); public native Relu6Grad backprops(Output backprops);
}

// Computes rectified linear gradients for a Relu operation.
//
// Arguments:
// * scope: A Scope object
// * gradients: The backpropagated gradients to the corresponding Relu operation.
// * features: The features passed as input to the corresponding Relu operation, OR
// the outputs of that operation (both work equivalently).
@Namespace("tensorflow::ops") @NoOffset public static class ReluGrad extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ReluGrad(Pointer p) { super(p); }

  public ReluGrad(@Const @ByRef Scope scope, @ByVal Input gradients,
           @ByVal Input features) { super((Pointer)null); allocate(scope, gradients, features); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input gradients,
           @ByVal Input features);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output backprops(); public native ReluGrad backprops(Output backprops);
}

// Computes softmax activations.
//
// For each batch `i` and class `j` we have
//
//     softmax[i, j] = exp(logits[i, j]) / sum_j(exp(logits[i, j]))
//
// Arguments:
// * scope: A Scope object
// * logits: 2-D with shape `[batch_size, num_classes]`.
@Namespace("tensorflow::ops") @NoOffset public static class Softmax extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Softmax(Pointer p) { super(p); }

  public Softmax(@Const @ByRef Scope scope, @ByVal Input logits) { super((Pointer)null); allocate(scope, logits); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input logits);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output softmax(); public native Softmax softmax(Output softmax);
}

// Computes softmax cross entropy cost and gradients to backpropagate.
//
// Inputs are the logits, not probabilities.
//
// Arguments:
// * scope: A Scope object
// * features: batch_size x num_classes matrix
// * labels: batch_size x num_classes matrix
// The caller must ensure that each batch of labels represents a valid
// probability distribution.
@Namespace("tensorflow::ops") @NoOffset public static class SoftmaxCrossEntropyWithLogits extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SoftmaxCrossEntropyWithLogits(Pointer p) { super(p); }

  public SoftmaxCrossEntropyWithLogits(@Const @ByRef Scope scope,
                                @ByVal Input features,
                                @ByVal Input labels) { super((Pointer)null); allocate(scope, features, labels); }
  private native void allocate(@Const @ByRef Scope scope,
                                @ByVal Input features,
                                @ByVal Input labels);

  public native @ByRef Output loss(); public native SoftmaxCrossEntropyWithLogits loss(Output loss);
  public native @ByRef Output backprop(); public native SoftmaxCrossEntropyWithLogits backprop(Output backprop);
}

// Computes softplus: `log(exp(features) + 1)`.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Softplus extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Softplus(Pointer p) { super(p); }

  public Softplus(@Const @ByRef Scope scope, @ByVal Input features) { super((Pointer)null); allocate(scope, features); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input features);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output activations(); public native Softplus activations(Output activations);
}

// Computes softplus gradients for a softplus operation.
//
// Arguments:
// * scope: A Scope object
// * gradients: The backpropagated gradients to the corresponding softplus operation.
// * features: The features passed as input to the corresponding softplus operation.
@Namespace("tensorflow::ops") @NoOffset public static class SoftplusGrad extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SoftplusGrad(Pointer p) { super(p); }

  public SoftplusGrad(@Const @ByRef Scope scope, @ByVal Input gradients, @ByVal Input features) { super((Pointer)null); allocate(scope, gradients, features); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input gradients, @ByVal Input features);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output backprops(); public native SoftplusGrad backprops(Output backprops);
}

// Computes softsign: `features / (abs(features) + 1)`.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Softsign extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Softsign(Pointer p) { super(p); }

  public Softsign(@Const @ByRef Scope scope, @ByVal Input features) { super((Pointer)null); allocate(scope, features); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input features);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output activations(); public native Softsign activations(Output activations);
}

// Computes softsign gradients for a softsign operation.
//
// Arguments:
// * scope: A Scope object
// * gradients: The backpropagated gradients to the corresponding softsign operation.
// * features: The features passed as input to the corresponding softsign operation.
@Namespace("tensorflow::ops") @NoOffset public static class SoftsignGrad extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SoftsignGrad(Pointer p) { super(p); }

  public SoftsignGrad(@Const @ByRef Scope scope, @ByVal Input gradients, @ByVal Input features) { super((Pointer)null); allocate(scope, gradients, features); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input gradients, @ByVal Input features);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output backprops(); public native SoftsignGrad backprops(Output backprops);
}

// Computes softmax cross entropy cost and gradients to backpropagate.
//
// Unlike `SoftmaxCrossEntropyWithLogits`, this operation does not accept
// a matrix of label probabilities, but rather a single label per row
// of features.  This label is considered to have probability 1.0 for the
// given row.
//
// Inputs are the logits, not probabilities.
//
// Arguments:
// * scope: A Scope object
// * features: batch_size x num_classes matrix
// * labels: batch_size vector with values in [0, num_classes).
// This is the label for the given minibatch entry.
@Namespace("tensorflow::ops") @NoOffset public static class SparseSoftmaxCrossEntropyWithLogits extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SparseSoftmaxCrossEntropyWithLogits(Pointer p) { super(p); }

  public SparseSoftmaxCrossEntropyWithLogits(@Const @ByRef Scope scope,
                                      @ByVal Input features,
                                      @ByVal Input labels) { super((Pointer)null); allocate(scope, features, labels); }
  private native void allocate(@Const @ByRef Scope scope,
                                      @ByVal Input features,
                                      @ByVal Input labels);

  public native @ByRef Output loss(); public native SparseSoftmaxCrossEntropyWithLogits loss(Output loss);
  public native @ByRef Output backprop(); public native SparseSoftmaxCrossEntropyWithLogits backprop(Output backprop);
}

// Finds values and indices of the `k` largest elements for the last dimension.
//
// DEPRECATED at GraphDef version 7:
// Use TopKV2 instead.
//
// If the input is a vector (rank-1), finds the `k` largest entries in the vector
// and outputs their values and indices as vectors.  Thus `values[j]` is the
// `j`-th largest entry in `input`, and its index is `indices[j]`.
//
// For matrices (resp. higher rank input), computes the top `k` entries in each
// row (resp. vector along the last dimension).  Thus,
//
//     values.shape = indices.shape = input.shape[:-1] + [k]
//
// If two elements are equal, the lower-index element appears first.
//
// If `k` varies dynamically, use `TopKV2` below.
//
// Arguments:
// * scope: A Scope object
// * input: 1-D or higher with last dimension at least `k`.
// * k:
//     Number of top elements to look for along the last dimension (along each
// row for matrices).
@Namespace("tensorflow::ops") @NoOffset public static class TopK extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TopK(Pointer p) { super(p); }

  // Optional attribute setters for TopK :
  //
  // Sorted(bool): Defaults to true
  //     If true the resulting `k` elements will be sorted by the values in
  // descending order.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Sorted(@Cast("bool") boolean x);

    public native @Cast("bool") boolean sorted_(); public native Attrs sorted_(boolean sorted_);
  }
  public TopK(@Const @ByRef Scope scope, @ByVal Input input, @Cast("tensorflow::int64") long k) { super((Pointer)null); allocate(scope, input, k); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @Cast("tensorflow::int64") long k);
  public TopK(@Const @ByRef Scope scope, @ByVal Input input, @Cast("tensorflow::int64") long k,
       @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, k, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input, @Cast("tensorflow::int64") long k,
       @Const @ByRef Attrs attrs);

  public static native @ByVal Attrs Sorted(@Cast("bool") boolean x);

  public native @ByRef Output values(); public native TopK values(Output values);
  public native @ByRef Output indices(); public native TopK indices(Output indices);
}

// Finds values and indices of the `k` largest elements for the last dimension.
//
// If the input is a vector (rank-1), finds the `k` largest entries in the vector
// and outputs their values and indices as vectors.  Thus `values[j]` is the
// `j`-th largest entry in `input`, and its index is `indices[j]`.
//
// For matrices (resp. higher rank input), computes the top `k` entries in each
// row (resp. vector along the last dimension).  Thus,
//
//     values.shape = indices.shape = input.shape[:-1] + [k]
//
// If two elements are equal, the lower-index element appears first.
//
// This is the same as `TopK`, but takes `k` as in input rather than an attr.
//
// Arguments:
// * scope: A Scope object
// * input: 1-D or higher with last dimension at least `k`.
// * k: 0-D.  Number of top elements to look for along the last dimension (along each
// row for matrices).
@Namespace("tensorflow::ops") @NoOffset public static class TopKV2 extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TopKV2(Pointer p) { super(p); }

  // Optional attribute setters for TopKV2 :
  //
  // Sorted(bool): Defaults to true
  //     If true the resulting `k` elements will be sorted by the values in
  // descending order.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Sorted(@Cast("bool") boolean x);

    public native @Cast("bool") boolean sorted_(); public native Attrs sorted_(boolean sorted_);
  }
  public TopKV2(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input k) { super((Pointer)null); allocate(scope, input, k); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input k);
  public TopKV2(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input k, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, k, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
         @ByVal Input k, @Const @ByRef Attrs attrs);

  public static native @ByVal Attrs Sorted(@Cast("bool") boolean x);

  public native @ByRef Output values(); public native TopKV2 values(Output values);
  public native @ByRef Output indices(); public native TopKV2 indices(Output indices);
}

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_NN_OPS_H_


// Parsed from tensorflow/cc/ops/no_op.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_NO_OP_H_
// #define TENSORFLOW_CC_OPS_NO_OP_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"

// Does nothing. Only useful as a placeholder for control edges.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class NoOp extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public NoOp(Pointer p) { super(p); }

  public NoOp(@Const @ByRef Scope scope) { super((Pointer)null); allocate(scope); }
  private native void allocate(@Const @ByRef Scope scope);
  public native @ByVal @Name("operator tensorflow::ops::Operation") Operation asOperation();

  public native @ByRef Operation operation(); public native NoOp operation(Operation operation);
}

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_NO_OP_H_


// Parsed from tensorflow/cc/ops/parsing_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_PARSING_OPS_H_
// #define TENSORFLOW_CC_OPS_PARSING_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"

// Convert CSV records to tensors. Each column maps to one tensor.
//
// RFC 4180 format is expected for the CSV records.
// (https://tools.ietf.org/html/rfc4180)
// Note that we allow leading and trailing spaces with int or float field.
//
// Arguments:
// * scope: A Scope object
// * records: Each string is a record/row in the csv and all records should have
// the same format.
// * record_defaults: One tensor per column of the input record, with either a
// scalar default value for that column or empty if the column is required.
@Namespace("tensorflow::ops") @NoOffset public static class DecodeCSV extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public DecodeCSV(Pointer p) { super(p); }

  // Optional attribute setters for DecodeCSV :
  //
  // FieldDelim(StringPiece): Defaults to ","
  //     delimiter to separate fields in a record.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs FieldDelim(@StringPiece BytePointer x);
    public native @ByVal Attrs FieldDelim(@StringPiece String x);

    public native @StringPiece BytePointer field_delim_(); public native Attrs field_delim_(BytePointer field_delim_);
  }
  public DecodeCSV(@Const @ByRef Scope scope, @ByVal Input records,
            @ByVal InputList record_defaults) { super((Pointer)null); allocate(scope, records, record_defaults); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input records,
            @ByVal InputList record_defaults);
  public DecodeCSV(@Const @ByRef Scope scope, @ByVal Input records,
            @ByVal InputList record_defaults, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, records, record_defaults, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input records,
            @ByVal InputList record_defaults, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator []") Output get(@Cast("size_t") long index);


  public static native @ByVal Attrs FieldDelim(@StringPiece BytePointer x);
  public static native @ByVal Attrs FieldDelim(@StringPiece String x);

  public native @ByRef @Cast("tensorflow::ops::OutputList*") StringVector output(); public native DecodeCSV output(StringVector output);
}

// Convert JSON-encoded Example records to binary protocol buffer strings.
//
// This op translates a tensor containing Example records, encoded using
// the [standard JSON
// mapping](https://developers.google.com/protocol-buffers/docs/proto3#json),
// into a tensor containing the same records encoded as binary protocol
// buffers. The resulting tensor can then be fed to any of the other
// Example-parsing ops.
//
// Arguments:
// * scope: A Scope object
// * json_examples: Each string is a JSON object serialized according to the JSON
// mapping of the Example proto.
@Namespace("tensorflow::ops") @NoOffset public static class DecodeJSONExample extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public DecodeJSONExample(Pointer p) { super(p); }

  public DecodeJSONExample(@Const @ByRef Scope scope, @ByVal Input json_examples) { super((Pointer)null); allocate(scope, json_examples); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input json_examples);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output binary_examples(); public native DecodeJSONExample binary_examples(Output binary_examples);
}

// Reinterpret the bytes of a string as a vector of numbers.
//
// Arguments:
// * scope: A Scope object
// * bytes: All the elements must have the same length.
@Namespace("tensorflow::ops") @NoOffset public static class DecodeRaw extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public DecodeRaw(Pointer p) { super(p); }

  // Optional attribute setters for DecodeRaw :
  //
  // LittleEndian(bool): Defaults to true
  //     Whether the input `bytes` are in little-endian order.
  // Ignored for `out_type` values that are stored in a single byte like
  // `uint8`.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs LittleEndian(@Cast("bool") boolean x);

    public native @Cast("bool") boolean little_endian_(); public native Attrs little_endian_(boolean little_endian_);
  }
  public DecodeRaw(@Const @ByRef Scope scope, @ByVal Input bytes,
            @Cast("tensorflow::DataType") int out_type) { super((Pointer)null); allocate(scope, bytes, out_type); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input bytes,
            @Cast("tensorflow::DataType") int out_type);
  public DecodeRaw(@Const @ByRef Scope scope, @ByVal Input bytes,
            @Cast("tensorflow::DataType") int out_type, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, bytes, out_type, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input bytes,
            @Cast("tensorflow::DataType") int out_type, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs LittleEndian(@Cast("bool") boolean x);

  public native @ByRef Output output(); public native DecodeRaw output(Output output);
}

// Transforms a vector of brain.Example protos (as strings) into typed tensors.
//
// Arguments:
// * scope: A Scope object
// * serialized: A vector containing a batch of binary serialized Example protos.
// * names: A vector containing the names of the serialized protos.
// May contain, for example, table key (descriptive) names for the
// corresponding serialized protos.  These are purely useful for debugging
// purposes, and the presence of values here has no effect on the output.
// May also be an empty vector if no names are available.
// If non-empty, this vector must be the same length as "serialized".
// * sparse_keys: A list of Nsparse string Tensors (scalars).
// The keys expected in the Examples' features associated with sparse values.
// * dense_keys: A list of Ndense string Tensors (scalars).
// The keys expected in the Examples' features associated with dense values.
// * dense_defaults: A list of Ndense Tensors (some may be empty).
// dense_defaults[j] provides default values
// when the example's feature_map lacks dense_key[j].  If an empty Tensor is
// provided for dense_defaults[j], then the Feature dense_keys[j] is required.
// The input type is inferred from dense_defaults[j], even when it's empty.
// If dense_defaults[j] is not empty, its shape must match dense_shapes[j].
// * sparse_types:
//     A list of Nsparse types; the data types of data in each Feature
// given in sparse_keys.
// Currently the ParseExample supports DT_FLOAT (FloatList),
// DT_INT64 (Int64List), and DT_STRING (BytesList).
// * dense_shapes:
//     A list of Ndense shapes; the shapes of data in each Feature
// given in dense_keys.
// The number of elements in the Feature corresponding to dense_key[j]
// must always equal dense_shapes[j].NumEntries().
// If dense_shapes[j] == (D0, D1, ..., DN) then the shape of output
// Tensor dense_values[j] will be (|serialized|, D0, D1, ..., DN):
// The dense outputs are just the inputs row-stacked by batch.
@Namespace("tensorflow::ops") @NoOffset public static class ParseExample extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ParseExample(Pointer p) { super(p); }

  public ParseExample(@Const @ByRef Scope scope, @ByVal Input serialized, @ByVal Input names,
               @ByVal InputList sparse_keys,
               @ByVal InputList dense_keys,
               @ByVal InputList dense_defaults, @Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector sparse_types, @Cast("const tensorflow::gtl::ArraySlice<tensorflow::TensorShape>*") @ByRef TensorShapeVector dense_shapes) { super((Pointer)null); allocate(scope, serialized, names, sparse_keys, dense_keys, dense_defaults, sparse_types, dense_shapes); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input serialized, @ByVal Input names,
               @ByVal InputList sparse_keys,
               @ByVal InputList dense_keys,
               @ByVal InputList dense_defaults, @Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector sparse_types, @Cast("const tensorflow::gtl::ArraySlice<tensorflow::TensorShape>*") @ByRef TensorShapeVector dense_shapes);

  public native @ByRef @Cast("tensorflow::ops::OutputList*") StringVector sparse_indices(); public native ParseExample sparse_indices(StringVector sparse_indices);
  public native @ByRef @Cast("tensorflow::ops::OutputList*") StringVector sparse_values(); public native ParseExample sparse_values(StringVector sparse_values);
  public native @ByRef @Cast("tensorflow::ops::OutputList*") StringVector sparse_shapes(); public native ParseExample sparse_shapes(StringVector sparse_shapes);
  public native @ByRef @Cast("tensorflow::ops::OutputList*") StringVector dense_values(); public native ParseExample dense_values(StringVector dense_values);
}

// Transforms a scalar brain.SequenceExample proto (as strings) into typed tensors.
//
// Arguments:
// * scope: A Scope object
// * serialized: A scalar containing a binary serialized SequenceExample proto.
// * feature_list_dense_missing_assumed_empty: A vector listing the
// FeatureList keys which may be missing from the SequenceExample.  If the
// associated FeatureList is missing, it is treated as empty.  By default,
// any FeatureList not listed in this vector must exist in the SequenceExample.
// * context_sparse_keys: A list of Ncontext_sparse string Tensors (scalars).
// The keys expected in the Examples' features associated with context_sparse
// values.
// * context_dense_keys: A list of Ncontext_dense string Tensors (scalars).
// The keys expected in the SequenceExamples' context features associated with
// dense values.
// * feature_list_sparse_keys: A list of Nfeature_list_sparse string Tensors
// (scalars).  The keys expected in the FeatureLists associated with sparse
// values.
// * feature_list_dense_keys: A list of Nfeature_list_dense string Tensors (scalars).
// The keys expected in the SequenceExamples' feature_lists associated
// with lists of dense values.
// * context_dense_defaults: A list of Ncontext_dense Tensors (some may be empty).
// context_dense_defaults[j] provides default values
// when the SequenceExample's context map lacks context_dense_key[j].
// If an empty Tensor is provided for context_dense_defaults[j],
// then the Feature context_dense_keys[j] is required.
// The input type is inferred from context_dense_defaults[j], even when it's
// empty.  If context_dense_defaults[j] is not empty, its shape must match
// context_dense_shapes[j].
// * debug_name: A scalar containing the name of the serialized proto.
// May contain, for example, table key (descriptive) name for the
// corresponding serialized proto.  This is purely useful for debugging
// purposes, and the presence of values here has no effect on the output.
// May also be an empty scalar if no name is available.
@Namespace("tensorflow::ops") @NoOffset public static class ParseSingleSequenceExample extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ParseSingleSequenceExample(Pointer p) { super(p); }

  // Optional attribute setters for ParseSingleSequenceExample :
  //
  // ContextSparseTypes(const DataTypeSlice&): Defaults to []
  //     A list of Ncontext_sparse types; the data types of data in
  // each context Feature given in context_sparse_keys.
  // Currently the ParseSingleSequenceExample supports DT_FLOAT (FloatList),
  // DT_INT64 (Int64List), and DT_STRING (BytesList).
  // FeatureListDenseTypes(const DataTypeSlice&): Defaults to []
  // ContextDenseShapes(const gtl::ArraySlice<TensorShape>&): Defaults to []
  //     A list of Ncontext_dense shapes; the shapes of data in
  // each context Feature given in context_dense_keys.
  // The number of elements in the Feature corresponding to context_dense_key[j]
  // must always equal context_dense_shapes[j].NumEntries().
  // The shape of context_dense_values[j] will match context_dense_shapes[j].
  // FeatureListSparseTypes(const DataTypeSlice&): Defaults to []
  //     A list of Nfeature_list_sparse types; the data types
  // of data in each FeatureList given in feature_list_sparse_keys.
  // Currently the ParseSingleSequenceExample supports DT_FLOAT (FloatList),
  // DT_INT64 (Int64List), and DT_STRING (BytesList).
  // FeatureListDenseShapes(const gtl::ArraySlice<TensorShape>&): Defaults to []
  //     A list of Nfeature_list_dense shapes; the shapes of
  // data in each FeatureList given in feature_list_dense_keys.
  // The shape of each Feature in the FeatureList corresponding to
  // feature_list_dense_key[j] must always equal
  // feature_list_dense_shapes[j].NumEntries().
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs ContextSparseTypes(@Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector x);

    public native @ByVal Attrs FeatureListDenseTypes(@Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector x);

    public native @ByVal Attrs ContextDenseShapes(@Cast("const tensorflow::gtl::ArraySlice<tensorflow::TensorShape>*") @ByRef TensorShapeVector x);

    public native @ByVal Attrs FeatureListSparseTypes(@Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector x);

    public native @ByVal Attrs FeatureListDenseShapes(@Cast("const tensorflow::gtl::ArraySlice<tensorflow::TensorShape>*") @ByRef TensorShapeVector x);

    public native @ByRef @Cast("tensorflow::DataTypeSlice*") DataTypeVector context_sparse_types_(); public native Attrs context_sparse_types_(DataTypeVector context_sparse_types_);
    public native @ByRef @Cast("tensorflow::DataTypeSlice*") DataTypeVector feature_list_dense_types_(); public native Attrs feature_list_dense_types_(DataTypeVector feature_list_dense_types_);
    public native @ByRef @Cast("tensorflow::gtl::ArraySlice<tensorflow::TensorShape>*") TensorShapeVector context_dense_shapes_(); public native Attrs context_dense_shapes_(TensorShapeVector context_dense_shapes_);
    public native @ByRef @Cast("tensorflow::DataTypeSlice*") DataTypeVector feature_list_sparse_types_(); public native Attrs feature_list_sparse_types_(DataTypeVector feature_list_sparse_types_);
    public native @ByRef @Cast("tensorflow::gtl::ArraySlice<tensorflow::TensorShape>*") TensorShapeVector feature_list_dense_shapes_(); public native Attrs feature_list_dense_shapes_(TensorShapeVector feature_list_dense_shapes_);
  }
  public ParseSingleSequenceExample(@Const @ByRef Scope scope,
                             @ByVal Input serialized,
                             @ByVal Input feature_list_dense_missing_assumed_empty,
                             @ByVal InputList context_sparse_keys,
                             @ByVal InputList context_dense_keys,
                             @ByVal InputList feature_list_sparse_keys,
                             @ByVal InputList feature_list_dense_keys,
                             @ByVal InputList context_dense_defaults,
                             @ByVal Input debug_name) { super((Pointer)null); allocate(scope, serialized, feature_list_dense_missing_assumed_empty, context_sparse_keys, context_dense_keys, feature_list_sparse_keys, feature_list_dense_keys, context_dense_defaults, debug_name); }
  private native void allocate(@Const @ByRef Scope scope,
                             @ByVal Input serialized,
                             @ByVal Input feature_list_dense_missing_assumed_empty,
                             @ByVal InputList context_sparse_keys,
                             @ByVal InputList context_dense_keys,
                             @ByVal InputList feature_list_sparse_keys,
                             @ByVal InputList feature_list_dense_keys,
                             @ByVal InputList context_dense_defaults,
                             @ByVal Input debug_name);
  public ParseSingleSequenceExample(@Const @ByRef Scope scope,
                             @ByVal Input serialized,
                             @ByVal Input feature_list_dense_missing_assumed_empty,
                             @ByVal InputList context_sparse_keys,
                             @ByVal InputList context_dense_keys,
                             @ByVal InputList feature_list_sparse_keys,
                             @ByVal InputList feature_list_dense_keys,
                             @ByVal InputList context_dense_defaults,
                             @ByVal Input debug_name, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, serialized, feature_list_dense_missing_assumed_empty, context_sparse_keys, context_dense_keys, feature_list_sparse_keys, feature_list_dense_keys, context_dense_defaults, debug_name, attrs); }
  private native void allocate(@Const @ByRef Scope scope,
                             @ByVal Input serialized,
                             @ByVal Input feature_list_dense_missing_assumed_empty,
                             @ByVal InputList context_sparse_keys,
                             @ByVal InputList context_dense_keys,
                             @ByVal InputList feature_list_sparse_keys,
                             @ByVal InputList feature_list_dense_keys,
                             @ByVal InputList context_dense_defaults,
                             @ByVal Input debug_name, @Const @ByRef Attrs attrs);

  public static native @ByVal Attrs ContextSparseTypes(@Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector x);
  public static native @ByVal Attrs FeatureListDenseTypes(@Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector x);
  public static native @ByVal Attrs ContextDenseShapes(@Cast("const tensorflow::gtl::ArraySlice<tensorflow::TensorShape>*") @ByRef TensorShapeVector x);
  public static native @ByVal Attrs FeatureListSparseTypes(@Cast("const tensorflow::DataTypeSlice*") @ByRef DataTypeVector x);
  public static native @ByVal Attrs FeatureListDenseShapes(@Cast("const tensorflow::gtl::ArraySlice<tensorflow::TensorShape>*") @ByRef TensorShapeVector x);

  public native @ByRef @Cast("tensorflow::ops::OutputList*") StringVector context_sparse_indices(); public native ParseSingleSequenceExample context_sparse_indices(StringVector context_sparse_indices);
  public native @ByRef @Cast("tensorflow::ops::OutputList*") StringVector context_sparse_values(); public native ParseSingleSequenceExample context_sparse_values(StringVector context_sparse_values);
  public native @ByRef @Cast("tensorflow::ops::OutputList*") StringVector context_sparse_shapes(); public native ParseSingleSequenceExample context_sparse_shapes(StringVector context_sparse_shapes);
  public native @ByRef @Cast("tensorflow::ops::OutputList*") StringVector context_dense_values(); public native ParseSingleSequenceExample context_dense_values(StringVector context_dense_values);
  public native @ByRef @Cast("tensorflow::ops::OutputList*") StringVector feature_list_sparse_indices(); public native ParseSingleSequenceExample feature_list_sparse_indices(StringVector feature_list_sparse_indices);
  public native @ByRef @Cast("tensorflow::ops::OutputList*") StringVector feature_list_sparse_values(); public native ParseSingleSequenceExample feature_list_sparse_values(StringVector feature_list_sparse_values);
  public native @ByRef @Cast("tensorflow::ops::OutputList*") StringVector feature_list_sparse_shapes(); public native ParseSingleSequenceExample feature_list_sparse_shapes(StringVector feature_list_sparse_shapes);
  public native @ByRef @Cast("tensorflow::ops::OutputList*") StringVector feature_list_dense_values(); public native ParseSingleSequenceExample feature_list_dense_values(StringVector feature_list_dense_values);
}

// Transforms a serialized tensorflow.TensorProto proto into a Tensor.
//
// Arguments:
// * scope: A Scope object
// * serialized: A scalar string containing a serialized TensorProto proto.
// * out_type:
//     The type of the serialized tensor.  The provided type must match the
// type of the serialized tensor and no implicit conversion will take place.
@Namespace("tensorflow::ops") @NoOffset public static class ParseTensor extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ParseTensor(Pointer p) { super(p); }

  public ParseTensor(@Const @ByRef Scope scope, @ByVal Input serialized, @Cast("tensorflow::DataType") int out_type) { super((Pointer)null); allocate(scope, serialized, out_type); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input serialized, @Cast("tensorflow::DataType") int out_type);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native ParseTensor output(Output output);
}

// Converts each string in the input Tensor to the specified numeric type.
//
// (Note that int32 overflow results in an error while float overflow
// results in a rounded value.)
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class StringToNumber extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public StringToNumber(Pointer p) { super(p); }

  // Optional attribute setters for StringToNumber :
  //
  // OutType(DataType): Defaults to DT_FLOAT
  //     The numeric type to interpret each string in string_tensor as.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs OutType(@Cast("tensorflow::DataType") int x);

    public native @Cast("tensorflow::DataType") int out_type_(); public native Attrs out_type_(int out_type_);
  }
  public StringToNumber(@Const @ByRef Scope scope, @ByVal Input string_tensor) { super((Pointer)null); allocate(scope, string_tensor); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input string_tensor);
  public StringToNumber(@Const @ByRef Scope scope, @ByVal Input string_tensor, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, string_tensor, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input string_tensor, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs OutType(@Cast("tensorflow::DataType") int x);

  public native @ByRef Output output(); public native StringToNumber output(Output output);
}

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_PARSING_OPS_H_


// Parsed from tensorflow/cc/ops/random_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_RANDOM_OPS_H_
// #define TENSORFLOW_CC_OPS_RANDOM_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"

// Draws samples from a multinomial distribution.
//
// Arguments:
// * scope: A Scope object
// * logits: 2-D Tensor with shape `[batch_size, num_classes]`.  Each slice `[i, :]`
// represents the unnormalized log probabilities for all classes.
// * num_samples: 0-D.  Number of independent samples to draw for each row slice.
@Namespace("tensorflow::ops") @NoOffset public static class Multinomial extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Multinomial(Pointer p) { super(p); }

  // Optional attribute setters for Multinomial :
  //
  // Seed(int64): Defaults to 0
  //     If either seed or seed2 is set to be non-zero, the internal random number
  // generator is seeded by the given seed.  Otherwise, a random seed is used.
  // Seed2(int64): Defaults to 0
  //     A second seed to avoid seed collision.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);

    public native @Cast("tensorflow::int64") long seed_(); public native Attrs seed_(long seed_);
    public native @Cast("tensorflow::int64") long seed2_(); public native Attrs seed2_(long seed2_);
  }
  public Multinomial(@Const @ByRef Scope scope, @ByVal Input logits,
              @ByVal Input num_samples) { super((Pointer)null); allocate(scope, logits, num_samples); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input logits,
              @ByVal Input num_samples);
  public Multinomial(@Const @ByRef Scope scope, @ByVal Input logits,
              @ByVal Input num_samples, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, logits, num_samples, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input logits,
              @ByVal Input num_samples, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);

  public native @ByRef Output output(); public native Multinomial output(Output output);
}

// Outputs random values from a normal distribution. The parameters may each be a
//
// scalar which applies to the entire output, or a vector of length shape[0] which
// stores the parameters for each batch.
//
// Arguments:
// * scope: A Scope object
// * shape: The shape of the output tensor. Batches are indexed by the 0th dimension.
// * means: The mean parameter of each batch.
// * stdevs: The standard deviation parameter of each batch. Must be greater than 0.
// * minvals: The minimum cutoff. May be -infinity.
// * maxvals: The maximum cutoff. May be +infinity, and must be more than the minval
// for each batch.
@Namespace("tensorflow::ops") @NoOffset public static class ParameterizedTruncatedNormal extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ParameterizedTruncatedNormal(Pointer p) { super(p); }

  // Optional attribute setters for ParameterizedTruncatedNormal :
  //
  // Seed(int64): Defaults to 0
  //     If either `seed` or `seed2` are set to be non-zero, the random number
  // generator is seeded by the given seed.  Otherwise, it is seeded by a
  // random seed.
  // Seed2(int64): Defaults to 0
  //     A second seed to avoid seed collision.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);

    public native @Cast("tensorflow::int64") long seed_(); public native Attrs seed_(long seed_);
    public native @Cast("tensorflow::int64") long seed2_(); public native Attrs seed2_(long seed2_);
  }
  public ParameterizedTruncatedNormal(@Const @ByRef Scope scope,
                               @ByVal Input shape,
                               @ByVal Input means,
                               @ByVal Input stdevs,
                               @ByVal Input minvals,
                               @ByVal Input maxvals) { super((Pointer)null); allocate(scope, shape, means, stdevs, minvals, maxvals); }
  private native void allocate(@Const @ByRef Scope scope,
                               @ByVal Input shape,
                               @ByVal Input means,
                               @ByVal Input stdevs,
                               @ByVal Input minvals,
                               @ByVal Input maxvals);
  public ParameterizedTruncatedNormal(@Const @ByRef Scope scope,
                               @ByVal Input shape,
                               @ByVal Input means,
                               @ByVal Input stdevs,
                               @ByVal Input minvals,
                               @ByVal Input maxvals, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, shape, means, stdevs, minvals, maxvals, attrs); }
  private native void allocate(@Const @ByRef Scope scope,
                               @ByVal Input shape,
                               @ByVal Input means,
                               @ByVal Input stdevs,
                               @ByVal Input minvals,
                               @ByVal Input maxvals, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);

  public native @ByRef Output output(); public native ParameterizedTruncatedNormal output(Output output);
}

// Outputs random values from the Gamma distribution(s) described by alpha.
//
// This op uses the algorithm by Marsaglia et al. to acquire samples via
// transformation-rejection from pairs of uniform and normal random variables.
// See http://dl.acm.org/citation.cfm?id=358414
//
// Arguments:
// * scope: A Scope object
// * shape: 1-D integer tensor. Shape of independent samples to draw from each
// distribution described by the shape parameters given in alpha.
// * alpha: A tensor in which each scalar is a "shape" parameter describing the
// associated gamma distribution.
@Namespace("tensorflow::ops") @NoOffset public static class RandomGamma extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public RandomGamma(Pointer p) { super(p); }

  // Optional attribute setters for RandomGamma :
  //
  // Seed(int64): Defaults to 0
  //     If either `seed` or `seed2` are set to be non-zero, the random number
  // generator is seeded by the given seed.  Otherwise, it is seeded by a
  // random seed.
  // Seed2(int64): Defaults to 0
  //     A second seed to avoid seed collision.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);

    public native @Cast("tensorflow::int64") long seed_(); public native Attrs seed_(long seed_);
    public native @Cast("tensorflow::int64") long seed2_(); public native Attrs seed2_(long seed2_);
  }
  public RandomGamma(@Const @ByRef Scope scope, @ByVal Input shape,
              @ByVal Input alpha) { super((Pointer)null); allocate(scope, shape, alpha); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input shape,
              @ByVal Input alpha);
  public RandomGamma(@Const @ByRef Scope scope, @ByVal Input shape,
              @ByVal Input alpha, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, shape, alpha, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input shape,
              @ByVal Input alpha, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);

  public native @ByRef Output output(); public native RandomGamma output(Output output);
}

// Randomly shuffles a tensor along its first dimension.
//
//   The tensor is shuffled along dimension 0, such that each `value[j]` is mapped
//   to one and only one `output[i]`. For example, a mapping that might occur for a
//   3x2 tensor is:
//
// ```prettyprint
// [[1, 2],       [[5, 6],
//  [3, 4],  ==>   [1, 2],
//  [5, 6]]        [3, 4]]
// ```
//
// Arguments:
// * scope: A Scope object
// * value: The tensor to be shuffled.
@Namespace("tensorflow::ops") @NoOffset public static class RandomShuffle extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public RandomShuffle(Pointer p) { super(p); }

  // Optional attribute setters for RandomShuffle :
  //
  // Seed(int64): Defaults to 0
  //     If either `seed` or `seed2` are set to be non-zero, the random number
  // generator is seeded by the given seed.  Otherwise, it is seeded by a
  // random seed.
  // Seed2(int64): Defaults to 0
  //     A second seed to avoid seed collision.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);

    public native @Cast("tensorflow::int64") long seed_(); public native Attrs seed_(long seed_);
    public native @Cast("tensorflow::int64") long seed2_(); public native Attrs seed2_(long seed2_);
  }
  public RandomShuffle(@Const @ByRef Scope scope, @ByVal Input value) { super((Pointer)null); allocate(scope, value); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input value);
  public RandomShuffle(@Const @ByRef Scope scope, @ByVal Input value,
                @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, value, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input value,
                @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);

  public native @ByRef Output output(); public native RandomShuffle output(Output output);
}

// Outputs random values from a normal distribution.
//
// The generated values will have mean 0 and standard deviation 1.
//
// Arguments:
// * scope: A Scope object
// * shape: The shape of the output tensor.
// * dtype:
//     The type of the output.
@Namespace("tensorflow::ops") @NoOffset public static class RandomStandardNormal extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public RandomStandardNormal(Pointer p) { super(p); }

  // Optional attribute setters for RandomStandardNormal :
  //
  // Seed(int64): Defaults to 0
  //     If either `seed` or `seed2` are set to be non-zero, the random number
  // generator is seeded by the given seed.  Otherwise, it is seeded by a
  // random seed.
  // Seed2(int64): Defaults to 0
  //     A second seed to avoid seed collision.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);

    public native @Cast("tensorflow::int64") long seed_(); public native Attrs seed_(long seed_);
    public native @Cast("tensorflow::int64") long seed2_(); public native Attrs seed2_(long seed2_);
  }
  public RandomStandardNormal(@Const @ByRef Scope scope, @ByVal Input shape, @Cast("tensorflow::DataType") int dtype) { super((Pointer)null); allocate(scope, shape, dtype); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input shape, @Cast("tensorflow::DataType") int dtype);
  public RandomStandardNormal(@Const @ByRef Scope scope, @ByVal Input shape, @Cast("tensorflow::DataType") int dtype, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, shape, dtype, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input shape, @Cast("tensorflow::DataType") int dtype, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);

  public native @ByRef Output output(); public native RandomStandardNormal output(Output output);
}

// Outputs random values from a uniform distribution.
//
// The generated values follow a uniform distribution in the range `[0, 1)`. The
// lower bound 0 is included in the range, while the upper bound 1 is excluded.
//
// Arguments:
// * scope: A Scope object
// * shape: The shape of the output tensor.
// * dtype:
//     The type of the output.
@Namespace("tensorflow::ops") @NoOffset public static class RandomUniform extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public RandomUniform(Pointer p) { super(p); }

  // Optional attribute setters for RandomUniform :
  //
  // Seed(int64): Defaults to 0
  //     If either `seed` or `seed2` are set to be non-zero, the random number
  // generator is seeded by the given seed.  Otherwise, it is seeded by a
  // random seed.
  // Seed2(int64): Defaults to 0
  //     A second seed to avoid seed collision.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);

    public native @Cast("tensorflow::int64") long seed_(); public native Attrs seed_(long seed_);
    public native @Cast("tensorflow::int64") long seed2_(); public native Attrs seed2_(long seed2_);
  }
  public RandomUniform(@Const @ByRef Scope scope, @ByVal Input shape,
                @Cast("tensorflow::DataType") int dtype) { super((Pointer)null); allocate(scope, shape, dtype); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input shape,
                @Cast("tensorflow::DataType") int dtype);
  public RandomUniform(@Const @ByRef Scope scope, @ByVal Input shape,
                @Cast("tensorflow::DataType") int dtype, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, shape, dtype, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input shape,
                @Cast("tensorflow::DataType") int dtype, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);

  public native @ByRef Output output(); public native RandomUniform output(Output output);
}

// Outputs random integers from a uniform distribution.
//
// The generated values are uniform integers in the range `[minval, maxval)`.
// The lower bound `minval` is included in the range, while the upper bound
// `maxval` is excluded.
//
// The random integers are slightly biased unless `maxval - minval` is an exact
// power of two.  The bias is small for values of `maxval - minval` significantly
// smaller than the range of the output (either `2^32` or `2^64`).
//
// Arguments:
// * scope: A Scope object
// * shape: The shape of the output tensor.
// * minval: 0-D.  Inclusive lower bound on the generated integers.
// * maxval: 0-D.  Exclusive upper bound on the generated integers.
@Namespace("tensorflow::ops") @NoOffset public static class RandomUniformInt extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public RandomUniformInt(Pointer p) { super(p); }

  // Optional attribute setters for RandomUniformInt :
  //
  // Seed(int64): Defaults to 0
  //     If either `seed` or `seed2` are set to be non-zero, the random number
  // generator is seeded by the given seed.  Otherwise, it is seeded by a
  // random seed.
  // Seed2(int64): Defaults to 0
  //     A second seed to avoid seed collision.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);

    public native @Cast("tensorflow::int64") long seed_(); public native Attrs seed_(long seed_);
    public native @Cast("tensorflow::int64") long seed2_(); public native Attrs seed2_(long seed2_);
  }
  public RandomUniformInt(@Const @ByRef Scope scope, @ByVal Input shape, @ByVal Input minval,
                   @ByVal Input maxval) { super((Pointer)null); allocate(scope, shape, minval, maxval); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input shape, @ByVal Input minval,
                   @ByVal Input maxval);
  public RandomUniformInt(@Const @ByRef Scope scope, @ByVal Input shape, @ByVal Input minval,
                   @ByVal Input maxval, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, shape, minval, maxval, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input shape, @ByVal Input minval,
                   @ByVal Input maxval, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);

  public native @ByRef Output output(); public native RandomUniformInt output(Output output);
}

// Outputs random values from a truncated normal distribution.
//
// The generated values follow a normal distribution with mean 0 and standard
// deviation 1, except that values whose magnitude is more than 2 standard
// deviations from the mean are dropped and re-picked.
//
// Arguments:
// * scope: A Scope object
// * shape: The shape of the output tensor.
// * dtype:
//     The type of the output.
@Namespace("tensorflow::ops") @NoOffset public static class TruncatedNormal extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TruncatedNormal(Pointer p) { super(p); }

  // Optional attribute setters for TruncatedNormal :
  //
  // Seed(int64): Defaults to 0
  //     If either `seed` or `seed2` are set to be non-zero, the random number
  // generator is seeded by the given seed.  Otherwise, it is seeded by a
  // random seed.
  // Seed2(int64): Defaults to 0
  //     A second seed to avoid seed collision.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);

    public native @Cast("tensorflow::int64") long seed_(); public native Attrs seed_(long seed_);
    public native @Cast("tensorflow::int64") long seed2_(); public native Attrs seed2_(long seed2_);
  }
  public TruncatedNormal(@Const @ByRef Scope scope, @ByVal Input shape, @Cast("tensorflow::DataType") int dtype) { super((Pointer)null); allocate(scope, shape, dtype); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input shape, @Cast("tensorflow::DataType") int dtype);
  public TruncatedNormal(@Const @ByRef Scope scope, @ByVal Input shape, @Cast("tensorflow::DataType") int dtype, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, shape, dtype, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input shape, @Cast("tensorflow::DataType") int dtype, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Seed(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs Seed2(@Cast("tensorflow::int64") long x);

  public native @ByRef Output output(); public native TruncatedNormal output(Output output);
}

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_RANDOM_OPS_H_


// Parsed from tensorflow/cc/ops/sparse_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_SPARSE_OPS_H_
// #define TENSORFLOW_CC_OPS_SPARSE_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"

// Deserialize and concatenate `SparseTensors` from a serialized minibatch.
//
// The input `serialized_sparse` must be a string matrix of shape `[N x 3]` where
// `N` is the minibatch size and the rows correspond to packed outputs of
// `SerializeSparse`.  The ranks of the original `SparseTensor` objects
// must all match.  When the final `SparseTensor` is created, it has rank one
// higher than the ranks of the incoming `SparseTensor` objects
// (they have been concatenated along a new row dimension).
//
// The output `SparseTensor` object's shape values for all dimensions but the
// first are the max across the input `SparseTensor` objects' shape values
// for the corresponding dimensions.  Its first shape value is `N`, the minibatch
// size.
//
// The input `SparseTensor` objects' indices are assumed ordered in
// standard lexicographic order.  If this is not the case, after this
// step run `SparseReorder` to restore index ordering.
//
// For example, if the serialized input is a `[2 x 3]` matrix representing two
// original `SparseTensor` objects:
//
//     index = [ 0]
//             [10]
//             [20]
//     values = [1, 2, 3]
//     shape = [50]
//
// and
//
//     index = [ 2]
//             [10]
//     values = [4, 5]
//     shape = [30]
//
// then the final deserialized `SparseTensor` will be:
//
//     index = [0  0]
//             [0 10]
//             [0 20]
//             [1  2]
//             [1 10]
//     values = [1, 2, 3, 4, 5]
//     shape = [2 50]
//
// Arguments:
// * scope: A Scope object
// * serialized_sparse: 2-D, The `N` serialized `SparseTensor` objects.
// Must have 3 columns.
// * dtype:
//     The `dtype` of the serialized `SparseTensor` objects.
@Namespace("tensorflow::ops") @NoOffset public static class DeserializeManySparse extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public DeserializeManySparse(Pointer p) { super(p); }

  public DeserializeManySparse(@Const @ByRef Scope scope,
                        @ByVal Input serialized_sparse, @Cast("tensorflow::DataType") int dtype) { super((Pointer)null); allocate(scope, serialized_sparse, dtype); }
  private native void allocate(@Const @ByRef Scope scope,
                        @ByVal Input serialized_sparse, @Cast("tensorflow::DataType") int dtype);

  public native @ByRef Output sparse_indices(); public native DeserializeManySparse sparse_indices(Output sparse_indices);
  public native @ByRef Output sparse_values(); public native DeserializeManySparse sparse_values(Output sparse_values);
  public native @ByRef Output sparse_shape(); public native DeserializeManySparse sparse_shape(Output sparse_shape);
}

// Serialize an `N`-minibatch `SparseTensor` into an `[N, 3]` string `Tensor`.
//
// The `SparseTensor` must have rank `R` greater than 1, and the first dimension
// is treated as the minibatch dimension.  Elements of the `SparseTensor`
// must be sorted in increasing order of this first dimension.  The serialized
// `SparseTensor` objects going into each row of `serialized_sparse` will have
// rank `R-1`.
//
// The minibatch size `N` is extracted from `sparse_shape[0]`.
//
// Arguments:
// * scope: A Scope object
// * sparse_indices: 2-D.  The `indices` of the minibatch `SparseTensor`.
// * sparse_values: 1-D.  The `values` of the minibatch `SparseTensor`.
// * sparse_shape: 1-D.  The `shape` of the minibatch `SparseTensor`.
@Namespace("tensorflow::ops") @NoOffset public static class SerializeManySparse extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SerializeManySparse(Pointer p) { super(p); }

  public SerializeManySparse(@Const @ByRef Scope scope, @ByVal Input sparse_indices, @ByVal Input sparse_values,
                      @ByVal Input sparse_shape) { super((Pointer)null); allocate(scope, sparse_indices, sparse_values, sparse_shape); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input sparse_indices, @ByVal Input sparse_values,
                      @ByVal Input sparse_shape);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output serialized_sparse(); public native SerializeManySparse serialized_sparse(Output serialized_sparse);
}

// Serialize a `SparseTensor` into a string 3-vector (1-D `Tensor`) object.
//
// Arguments:
// * scope: A Scope object
// * sparse_indices: 2-D.  The `indices` of the `SparseTensor`.
// * sparse_values: 1-D.  The `values` of the `SparseTensor`.
// * sparse_shape: 1-D.  The `shape` of the `SparseTensor`.
@Namespace("tensorflow::ops") @NoOffset public static class SerializeSparse extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SerializeSparse(Pointer p) { super(p); }

  public SerializeSparse(@Const @ByRef Scope scope, @ByVal Input sparse_indices, @ByVal Input sparse_values,
                  @ByVal Input sparse_shape) { super((Pointer)null); allocate(scope, sparse_indices, sparse_values, sparse_shape); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input sparse_indices, @ByVal Input sparse_values,
                  @ByVal Input sparse_shape);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output serialized_sparse(); public native SerializeSparse serialized_sparse(Output serialized_sparse);
}

// Adds two `SparseTensor` objects to produce another `SparseTensor`.
//
// The input `SparseTensor` objects' indices are assumed ordered in standard
// lexicographic order.  If this is not the case, before this step run
// `SparseReorder` to restore index ordering.
//
// By default, if two values sum to zero at some index, the output `SparseTensor`
// would still include that particular location in its index, storing a zero in the
// corresponding value slot.  To override this, callers can specify `thresh`,
// indicating that if the sum has a magnitude strictly smaller than `thresh`, its
// corresponding value and index would then not be included.  In particular,
// `thresh == 0` (default) means everything is kept and actual thresholding happens
// only for a positive value.
//
// In the following shapes, `nnz` is the count after taking `thresh` into account.
//
// Arguments:
// * scope: A Scope object
// * a_indices: 2-D.  The `indices` of the first `SparseTensor`, size `[nnz, ndims]` Matrix.
// * a_values: 1-D.  The `values` of the first `SparseTensor`, size `[nnz]` Vector.
// * a_shape: 1-D.  The `shape` of the first `SparseTensor`, size `[ndims]` Vector.
// * b_indices: 2-D.  The `indices` of the second `SparseTensor`, size `[nnz, ndims]` Matrix.
// * b_values: 1-D.  The `values` of the second `SparseTensor`, size `[nnz]` Vector.
// * b_shape: 1-D.  The `shape` of the second `SparseTensor`, size `[ndims]` Vector.
// * thresh: 0-D.  The magnitude threshold that determines if an output value/index
// pair takes space.
@Namespace("tensorflow::ops") @NoOffset public static class SparseAdd extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SparseAdd(Pointer p) { super(p); }

  public SparseAdd(@Const @ByRef Scope scope, @ByVal Input a_indices,
            @ByVal Input a_values, @ByVal Input a_shape,
            @ByVal Input b_indices, @ByVal Input b_values, @ByVal Input b_shape, @ByVal Input thresh) { super((Pointer)null); allocate(scope, a_indices, a_values, a_shape, b_indices, b_values, b_shape, thresh); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input a_indices,
            @ByVal Input a_values, @ByVal Input a_shape,
            @ByVal Input b_indices, @ByVal Input b_values, @ByVal Input b_shape, @ByVal Input thresh);

  public native @ByRef Output sum_indices(); public native SparseAdd sum_indices(Output sum_indices);
  public native @ByRef Output sum_values(); public native SparseAdd sum_values(Output sum_values);
  public native @ByRef Output sum_shape(); public native SparseAdd sum_shape(Output sum_shape);
}

// The gradient operator for the SparseAdd op.
//
// The SparseAdd op calculates A + B, where A, B, and the sum are all represented
// as `SparseTensor` objects.  This op takes in the upstream gradient w.r.t.
// non-empty values of the sum, and outputs the gradients w.r.t. the non-empty
// values of A and B.
//
// Arguments:
// * scope: A Scope object
// * backprop_val_grad: 1-D with shape `[nnz(sum)]`.  The gradient with respect to
// the non-empty values of the sum.
// * a_indices: 2-D.  The `indices` of the `SparseTensor` A, size `[nnz(A), ndims]`.
// * b_indices: 2-D.  The `indices` of the `SparseTensor` B, size `[nnz(B), ndims]`.
// * sum_indices: 2-D.  The `indices` of the sum `SparseTensor`, size
// `[nnz(sum), ndims]`.
@Namespace("tensorflow::ops") @NoOffset public static class SparseAddGrad extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SparseAddGrad(Pointer p) { super(p); }

  public SparseAddGrad(@Const @ByRef Scope scope, @ByVal Input backprop_val_grad, @ByVal Input a_indices,
                @ByVal Input b_indices, @ByVal Input sum_indices) { super((Pointer)null); allocate(scope, backprop_val_grad, a_indices, b_indices, sum_indices); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input backprop_val_grad, @ByVal Input a_indices,
                @ByVal Input b_indices, @ByVal Input sum_indices);

  public native @ByRef Output a_val_grad(); public native SparseAddGrad a_val_grad(Output a_val_grad);
  public native @ByRef Output b_val_grad(); public native SparseAddGrad b_val_grad(Output b_val_grad);
}

// Concatenates a list of `SparseTensor` along the specified dimension.
//
// Concatenation is with respect to the dense versions of these sparse tensors.
// It is assumed that each input is a `SparseTensor` whose elements are ordered
// along increasing dimension number.
//
// All inputs' shapes must match, except for the concat dimension.  The
// `indices`, `values`, and `shapes` lists must have the same length.
//
// The output shape is identical to the inputs', except along the concat
// dimension, where it is the sum of the inputs' sizes along that dimension.
//
// The output elements will be resorted to preserve the sort order along
// increasing dimension number.
//
// This op runs in `O(M log M)` time, where `M` is the total number of non-empty
// values across all inputs. This is due to the need for an internal sort in
// order to concatenate efficiently across an arbitrary dimension.
//
// For example, if `concat_dim = 1` and the inputs are
//
//     sp_inputs[0]: shape = [2, 3]
//     [0, 2]: "a"
//     [1, 0]: "b"
//     [1, 1]: "c"
//
//     sp_inputs[1]: shape = [2, 4]
//     [0, 1]: "d"
//     [0, 2]: "e"
//
// then the output will be
//
//     shape = [2, 7]
//     [0, 2]: "a"
//     [0, 4]: "d"
//     [0, 5]: "e"
//     [1, 0]: "b"
//     [1, 1]: "c"
//
// Graphically this is equivalent to doing
//
//     [    a] concat [  d e  ] = [    a   d e  ]
//     [b c  ]        [       ]   [b c          ]
//
// Arguments:
// * scope: A Scope object
// * indices: 2-D.  Indices of each input `SparseTensor`.
// * values: 1-D.  Non-empty values of each `SparseTensor`.
// * shapes: 1-D.  Shapes of each `SparseTensor`.
// * concat_dim:
//     Dimension to concatenate along. Must be in range [-rank, rank),
// where rank is the number of dimensions in each input `SparseTensor`.
@Namespace("tensorflow::ops") @NoOffset public static class SparseConcat extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SparseConcat(Pointer p) { super(p); }

  public SparseConcat(@Const @ByRef Scope scope, @ByVal InputList indices, @ByVal InputList values,
               @ByVal InputList shapes, @Cast("tensorflow::int64") long concat_dim) { super((Pointer)null); allocate(scope, indices, values, shapes, concat_dim); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal InputList indices, @ByVal InputList values,
               @ByVal InputList shapes, @Cast("tensorflow::int64") long concat_dim);

  public native @ByRef Output output_indices(); public native SparseConcat output_indices(Output output_indices);
  public native @ByRef Output output_values(); public native SparseConcat output_values(Output output_values);
  public native @ByRef Output output_shape(); public native SparseConcat output_shape(Output output_shape);
}

// Adds up a SparseTensor and a dense Tensor, using these special rules:
//
// (1) Broadcasts the dense side to have the same shape as the sparse side, if
//     eligible;
// (2) Then, only the dense values pointed to by the indices of the SparseTensor
//     participate in the cwise addition.
//
// By these rules, the result is a logical SparseTensor with exactly the same
// indices and shape, but possibly with different non-zero values.  The output of
// this Op is the resultant non-zero values.
//
// Arguments:
// * scope: A Scope object
// * sp_indices: 2-D.  `N x R` matrix with the indices of non-empty values in a
// SparseTensor, possibly not in canonical ordering.
// * sp_values: 1-D.  `N` non-empty values corresponding to `sp_indices`.
// * sp_shape: 1-D.  Shape of the input SparseTensor.
// * dense: `R`-D.  The dense Tensor operand.
@Namespace("tensorflow::ops") @NoOffset public static class SparseDenseCwiseAdd extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SparseDenseCwiseAdd(Pointer p) { super(p); }

  public SparseDenseCwiseAdd(@Const @ByRef Scope scope, @ByVal Input sp_indices, @ByVal Input sp_values,
                      @ByVal Input sp_shape, @ByVal Input dense) { super((Pointer)null); allocate(scope, sp_indices, sp_values, sp_shape, dense); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input sp_indices, @ByVal Input sp_values,
                      @ByVal Input sp_shape, @ByVal Input dense);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native SparseDenseCwiseAdd output(Output output);
}

// Component-wise divides a SparseTensor by a dense Tensor.
//
// *Limitation*: this Op only broadcasts the dense side to the sparse side, but not
// the other direction.
//
// Arguments:
// * scope: A Scope object
// * sp_indices: 2-D.  `N x R` matrix with the indices of non-empty values in a
// SparseTensor, possibly not in canonical ordering.
// * sp_values: 1-D.  `N` non-empty values corresponding to `sp_indices`.
// * sp_shape: 1-D.  Shape of the input SparseTensor.
// * dense: `R`-D.  The dense Tensor operand.
@Namespace("tensorflow::ops") @NoOffset public static class SparseDenseCwiseDiv extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SparseDenseCwiseDiv(Pointer p) { super(p); }

  public SparseDenseCwiseDiv(@Const @ByRef Scope scope, @ByVal Input sp_indices, @ByVal Input sp_values,
                      @ByVal Input sp_shape, @ByVal Input dense) { super((Pointer)null); allocate(scope, sp_indices, sp_values, sp_shape, dense); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input sp_indices, @ByVal Input sp_values,
                      @ByVal Input sp_shape, @ByVal Input dense);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native SparseDenseCwiseDiv output(Output output);
}

// Component-wise multiplies a SparseTensor by a dense Tensor.
//
// The output locations corresponding to the implicitly zero elements in the sparse
// tensor will be zero (i.e., will not take up storage space), regardless of the
// contents of the dense tensor (even if it's +/-INF and that INF*0 == NaN).
//
// *Limitation*: this Op only broadcasts the dense side to the sparse side, but not
// the other direction.
//
// Arguments:
// * scope: A Scope object
// * sp_indices: 2-D.  `N x R` matrix with the indices of non-empty values in a
// SparseTensor, possibly not in canonical ordering.
// * sp_values: 1-D.  `N` non-empty values corresponding to `sp_indices`.
// * sp_shape: 1-D.  Shape of the input SparseTensor.
// * dense: `R`-D.  The dense Tensor operand.
@Namespace("tensorflow::ops") @NoOffset public static class SparseDenseCwiseMul extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SparseDenseCwiseMul(Pointer p) { super(p); }

  public SparseDenseCwiseMul(@Const @ByRef Scope scope, @ByVal Input sp_indices, @ByVal Input sp_values,
                      @ByVal Input sp_shape, @ByVal Input dense) { super((Pointer)null); allocate(scope, sp_indices, sp_values, sp_shape, dense); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input sp_indices, @ByVal Input sp_values,
                      @ByVal Input sp_shape, @ByVal Input dense);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native SparseDenseCwiseMul output(Output output);
}

// Computes the sum of elements across dimensions of a SparseTensor.
//
// This Op takes a SparseTensor and is the sparse counterpart to
// `tf.reduce_sum()`.  In particular, this Op also returns a dense `Tensor`
// instead of a sparse one.
//
// Reduces `sp_input` along the dimensions given in `reduction_axes`.  Unless
// `keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
// `reduction_axes`. If `keep_dims` is true, the reduced dimensions are retained
// with length 1.
//
// If `reduction_axes` has no entries, all dimensions are reduced, and a tensor
// with a single element is returned.  Additionally, the axes can be negative,
// which are interpreted according to the indexing rules in Python.
//
// Arguments:
// * scope: A Scope object
// * input_indices: 2-D.  `N x R` matrix with the indices of non-empty values in a
// SparseTensor, possibly not in canonical ordering.
// * input_values: 1-D.  `N` non-empty values corresponding to `input_indices`.
// * input_shape: 1-D.  Shape of the input SparseTensor.
// * reduction_axes: 1-D.  Length-`K` vector containing the reduction axes.
@Namespace("tensorflow::ops") @NoOffset public static class SparseReduceSum extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SparseReduceSum(Pointer p) { super(p); }

  // Optional attribute setters for SparseReduceSum :
  //
  // KeepDims(bool): Defaults to false
  //     If true, retain reduced dimensions with length 1.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs KeepDims(@Cast("bool") boolean x);

    public native @Cast("bool") boolean keep_dims_(); public native Attrs keep_dims_(boolean keep_dims_);
  }
  public SparseReduceSum(@Const @ByRef Scope scope, @ByVal Input input_indices, @ByVal Input input_values,
                  @ByVal Input input_shape, @ByVal Input reduction_axes) { super((Pointer)null); allocate(scope, input_indices, input_values, input_shape, reduction_axes); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input_indices, @ByVal Input input_values,
                  @ByVal Input input_shape, @ByVal Input reduction_axes);
  public SparseReduceSum(@Const @ByRef Scope scope, @ByVal Input input_indices, @ByVal Input input_values,
                  @ByVal Input input_shape, @ByVal Input reduction_axes, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input_indices, input_values, input_shape, reduction_axes, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input_indices, @ByVal Input input_values,
                  @ByVal Input input_shape, @ByVal Input reduction_axes, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs KeepDims(@Cast("bool") boolean x);

  public native @ByRef Output output(); public native SparseReduceSum output(Output output);
}

// Computes the sum of elements across dimensions of a SparseTensor.
//
// This Op takes a SparseTensor and is the sparse counterpart to
// `tf.reduce_sum()`.  In contrast to SparseReduceSum, this Op returns a
// SparseTensor.
//
// Reduces `sp_input` along the dimensions given in `reduction_axes`.  Unless
// `keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
// `reduction_axes`. If `keep_dims` is true, the reduced dimensions are retained
// with length 1.
//
// If `reduction_axes` has no entries, all dimensions are reduced, and a tensor
// with a single element is returned.  Additionally, the axes can be negative,
// which are interpreted according to the indexing rules in Python.
//
// Arguments:
// * scope: A Scope object
// * input_indices: 2-D.  `N x R` matrix with the indices of non-empty values in a
// SparseTensor, possibly not in canonical ordering.
// * input_values: 1-D.  `N` non-empty values corresponding to `input_indices`.
// * input_shape: 1-D.  Shape of the input SparseTensor.
// * reduction_axes: 1-D.  Length-`K` vector containing the reduction axes.
@Namespace("tensorflow::ops") @NoOffset public static class SparseReduceSumSparse extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SparseReduceSumSparse(Pointer p) { super(p); }

  // Optional attribute setters for SparseReduceSumSparse :
  //
  // KeepDims(bool): Defaults to false
  //     If true, retain reduced dimensions with length 1.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs KeepDims(@Cast("bool") boolean x);

    public native @Cast("bool") boolean keep_dims_(); public native Attrs keep_dims_(boolean keep_dims_);
  }
  public SparseReduceSumSparse(@Const @ByRef Scope scope,
                        @ByVal Input input_indices,
                        @ByVal Input input_values,
                        @ByVal Input input_shape,
                        @ByVal Input reduction_axes) { super((Pointer)null); allocate(scope, input_indices, input_values, input_shape, reduction_axes); }
  private native void allocate(@Const @ByRef Scope scope,
                        @ByVal Input input_indices,
                        @ByVal Input input_values,
                        @ByVal Input input_shape,
                        @ByVal Input reduction_axes);
  public SparseReduceSumSparse(@Const @ByRef Scope scope,
                        @ByVal Input input_indices,
                        @ByVal Input input_values,
                        @ByVal Input input_shape,
                        @ByVal Input reduction_axes, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input_indices, input_values, input_shape, reduction_axes, attrs); }
  private native void allocate(@Const @ByRef Scope scope,
                        @ByVal Input input_indices,
                        @ByVal Input input_values,
                        @ByVal Input input_shape,
                        @ByVal Input reduction_axes, @Const @ByRef Attrs attrs);

  public static native @ByVal Attrs KeepDims(@Cast("bool") boolean x);

  public native @ByRef Output output_indices(); public native SparseReduceSumSparse output_indices(Output output_indices);
  public native @ByRef Output output_values(); public native SparseReduceSumSparse output_values(Output output_values);
  public native @ByRef Output output_shape(); public native SparseReduceSumSparse output_shape(Output output_shape);
}

// Reorders a SparseTensor into the canonical, row-major ordering.
//
// Note that by convention, all sparse ops preserve the canonical ordering along
// increasing dimension number. The only time ordering can be violated is during
// manual manipulation of the indices and values vectors to add entries.
//
// Reordering does not affect the shape of the SparseTensor.
//
// If the tensor has rank `R` and `N` non-empty values, `input_indices` has
// shape `[N, R]`, input_values has length `N`, and input_shape has length `R`.
//
// Arguments:
// * scope: A Scope object
// * input_indices: 2-D.  `N x R` matrix with the indices of non-empty values in a
// SparseTensor, possibly not in canonical ordering.
// * input_values: 1-D.  `N` non-empty values corresponding to `input_indices`.
// * input_shape: 1-D.  Shape of the input SparseTensor.
@Namespace("tensorflow::ops") @NoOffset public static class SparseReorder extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SparseReorder(Pointer p) { super(p); }

  public SparseReorder(@Const @ByRef Scope scope, @ByVal Input input_indices, @ByVal Input input_values,
                @ByVal Input input_shape) { super((Pointer)null); allocate(scope, input_indices, input_values, input_shape); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input_indices, @ByVal Input input_values,
                @ByVal Input input_shape);

  public native @ByRef Output output_indices(); public native SparseReorder output_indices(Output output_indices);
  public native @ByRef Output output_values(); public native SparseReorder output_values(Output output_values);
}

// Reshapes a SparseTensor to represent values in a new dense shape.
//
// This operation has the same semantics as reshape on the represented dense
// tensor.  The `input_indices` are recomputed based on the requested `new_shape`.
//
// If one component of `new_shape` is the special value -1, the size of that
// dimension is computed so that the total dense size remains constant.  At
// most one component of `new_shape` can be -1.  The number of dense elements
// implied by `new_shape` must be the same as the number of dense elements
// originally implied by `input_shape`.
//
// Reshaping does not affect the order of values in the SparseTensor.
//
// If the input tensor has rank `R_in` and `N` non-empty values, and `new_shape`
// has length `R_out`, then `input_indices` has shape `[N, R_in]`,
// `input_shape` has length `R_in`, `output_indices` has shape `[N, R_out]`, and
// `output_shape` has length `R_out`.
//
// Arguments:
// * scope: A Scope object
// * input_indices: 2-D.  `N x R_in` matrix with the indices of non-empty values in a
// SparseTensor.
// * input_shape: 1-D.  `R_in` vector with the input SparseTensor's dense shape.
// * new_shape: 1-D.  `R_out` vector with the requested new dense shape.
@Namespace("tensorflow::ops") @NoOffset public static class SparseReshape extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SparseReshape(Pointer p) { super(p); }

  public SparseReshape(@Const @ByRef Scope scope, @ByVal Input input_indices, @ByVal Input input_shape,
                @ByVal Input new_shape) { super((Pointer)null); allocate(scope, input_indices, input_shape, new_shape); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input_indices, @ByVal Input input_shape,
                @ByVal Input new_shape);

  public native @ByRef Output output_indices(); public native SparseReshape output_indices(Output output_indices);
  public native @ByRef Output output_shape(); public native SparseReshape output_shape(Output output_shape);
}

// Applies softmax to a batched N-D `SparseTensor`.
//
// The inputs represent an N-D SparseTensor  with logical shape `[..., B, C]`
// (where `N >= 2`), and with indices sorted in the canonical lexicographic order.
//
// This op is equivalent to applying the normal `tf.nn.softmax()` to each innermost
// logical submatrix with shape `[B, C]`, but with the catch that *the implicitly
// zero elements do not participate*.  Specifically, the algorithm is equivalent
// to the following:
//
//   (1) Applies `tf.nn.softmax()` to a densified view of each innermost submatrix
//       with shape `[B, C]`, along the size-C dimension;
//   (2) Masks out the original implicitly-zero locations;
//   (3) Renormalizes the remaining elements.
//
// Hence, the `SparseTensor` result has exactly the same non-zero indices and
// shape.
//
// Arguments:
// * scope: A Scope object
// * sp_indices: 2-D.  `NNZ x R` matrix with the indices of non-empty values in a
// SparseTensor, in canonical ordering.
// * sp_values: 1-D.  `NNZ` non-empty values corresponding to `sp_indices`.
// * sp_shape: 1-D.  Shape of the input SparseTensor.
@Namespace("tensorflow::ops") @NoOffset public static class SparseSoftmax extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SparseSoftmax(Pointer p) { super(p); }

  public SparseSoftmax(@Const @ByRef Scope scope, @ByVal Input sp_indices, @ByVal Input sp_values,
                @ByVal Input sp_shape) { super((Pointer)null); allocate(scope, sp_indices, sp_values, sp_shape); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input sp_indices, @ByVal Input sp_values,
                @ByVal Input sp_shape);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native SparseSoftmax output(Output output);
}

// Returns the element-wise max of two SparseTensors.
//
// Assumes the two SparseTensors have the same shape, i.e., no broadcasting.
//
// Arguments:
// * scope: A Scope object
// * a_indices: 2-D.  `N x R` matrix with the indices of non-empty values in a
// SparseTensor, in the canonical lexicographic ordering.
// * a_values: 1-D.  `N` non-empty values corresponding to `a_indices`.
// * a_shape: 1-D.  Shape of the input SparseTensor.
// * b_indices: counterpart to `a_indices` for the other operand.
// * b_values: counterpart to `a_values` for the other operand; must be of the same dtype.
// * b_shape: counterpart to `a_shape` for the other operand; the two shapes must be equal.
@Namespace("tensorflow::ops") @NoOffset public static class SparseSparseMaximum extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SparseSparseMaximum(Pointer p) { super(p); }

  public SparseSparseMaximum(@Const @ByRef Scope scope, @ByVal Input a_indices, @ByVal Input a_values,
                      @ByVal Input a_shape, @ByVal Input b_indices, @ByVal Input b_values,
                      @ByVal Input b_shape) { super((Pointer)null); allocate(scope, a_indices, a_values, a_shape, b_indices, b_values, b_shape); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input a_indices, @ByVal Input a_values,
                      @ByVal Input a_shape, @ByVal Input b_indices, @ByVal Input b_values,
                      @ByVal Input b_shape);

  public native @ByRef Output output_indices(); public native SparseSparseMaximum output_indices(Output output_indices);
  public native @ByRef Output output_values(); public native SparseSparseMaximum output_values(Output output_values);
}

// Returns the element-wise min of two SparseTensors.
//
// Assumes the two SparseTensors have the same shape, i.e., no broadcasting.
//
// Arguments:
// * scope: A Scope object
// * a_indices: 2-D.  `N x R` matrix with the indices of non-empty values in a
// SparseTensor, in the canonical lexicographic ordering.
// * a_values: 1-D.  `N` non-empty values corresponding to `a_indices`.
// * a_shape: 1-D.  Shape of the input SparseTensor.
// * b_indices: counterpart to `a_indices` for the other operand.
// * b_values: counterpart to `a_values` for the other operand; must be of the same dtype.
// * b_shape: counterpart to `a_shape` for the other operand; the two shapes must be equal.
@Namespace("tensorflow::ops") @NoOffset public static class SparseSparseMinimum extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SparseSparseMinimum(Pointer p) { super(p); }

  public SparseSparseMinimum(@Const @ByRef Scope scope, @ByVal Input a_indices, @ByVal Input a_values,
                      @ByVal Input a_shape, @ByVal Input b_indices, @ByVal Input b_values,
                      @ByVal Input b_shape) { super((Pointer)null); allocate(scope, a_indices, a_values, a_shape, b_indices, b_values, b_shape); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input a_indices, @ByVal Input a_values,
                      @ByVal Input a_shape, @ByVal Input b_indices, @ByVal Input b_values,
                      @ByVal Input b_shape);

  public native @ByRef Output output_indices(); public native SparseSparseMinimum output_indices(Output output_indices);
  public native @ByRef Output output_values(); public native SparseSparseMinimum output_values(Output output_values);
}

// Split a `SparseTensor` into `num_split` tensors along one dimension.
//
// If the `shape[split_dim]` is not an integer multiple of `num_split`. Slices
// `[0 : shape[split_dim] % num_split]` gets one extra dimension.
// For example, if `split_dim = 1` and `num_split = 2` and the input is
//
//     input_tensor = shape = [2, 7]
//     [    a   d e  ]
//     [b c          ]
//
// Graphically the output tensors are:
//
//     output_tensor[0] = shape = [2, 4]
//     [    a  ]
//     [b c    ]
//
//     output_tensor[1] = shape = [2, 3]
//     [ d e  ]
//     [      ]
//
// Arguments:
// * scope: A Scope object
// * split_dim: 0-D.  The dimension along which to split.  Must be in the range
// `[0, rank(shape))`.
// * indices: 2-D tensor represents the indices of the sparse tensor.
// * values: 1-D tensor represents the values of the sparse tensor.
// * shape: 1-D. tensor represents the shape of the sparse tensor.
// output indices: A list of 1-D tensors represents the indices of the output
// sparse tensors.
// * num_split:
//     The number of ways to split.
@Namespace("tensorflow::ops") @NoOffset public static class SparseSplit extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SparseSplit(Pointer p) { super(p); }

  public SparseSplit(@Const @ByRef Scope scope, @ByVal Input split_dim, @ByVal Input indices,
              @ByVal Input values, @ByVal Input shape,
              @Cast("tensorflow::int64") long num_split) { super((Pointer)null); allocate(scope, split_dim, indices, values, shape, num_split); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input split_dim, @ByVal Input indices,
              @ByVal Input values, @ByVal Input shape,
              @Cast("tensorflow::int64") long num_split);

  public native @ByRef @Cast("tensorflow::ops::OutputList*") StringVector output_indices(); public native SparseSplit output_indices(StringVector output_indices);
  public native @ByRef @Cast("tensorflow::ops::OutputList*") StringVector output_values(); public native SparseSplit output_values(StringVector output_values);
  public native @ByRef @Cast("tensorflow::ops::OutputList*") StringVector output_shape(); public native SparseSplit output_shape(StringVector output_shape);
}

// Adds up a `SparseTensor` and a dense `Tensor`, producing a dense `Tensor`.
//
// This Op does not require `a_indices` be sorted in standard lexicographic order.
//
// Arguments:
// * scope: A Scope object
// * a_indices: 2-D.  The `indices` of the `SparseTensor`, with shape `[nnz, ndims]`.
// * a_values: 1-D.  The `values` of the `SparseTensor`, with shape `[nnz]`.
// * a_shape: 1-D.  The `shape` of the `SparseTensor`, with shape `[ndims]`.
// * b: `ndims`-D Tensor.  With shape `a_shape`.
@Namespace("tensorflow::ops") @NoOffset public static class SparseTensorDenseAdd extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SparseTensorDenseAdd(Pointer p) { super(p); }

  public SparseTensorDenseAdd(@Const @ByRef Scope scope, @ByVal Input a_indices, @ByVal Input a_values,
                       @ByVal Input a_shape, @ByVal Input b) { super((Pointer)null); allocate(scope, a_indices, a_values, a_shape, b); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input a_indices, @ByVal Input a_values,
                       @ByVal Input a_shape, @ByVal Input b);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native SparseTensorDenseAdd output(Output output);
}

// Multiply SparseTensor (of rank 2) "A" by dense matrix "B".
//
// No validity checking is performed on the indices of A.  However, the following
// input format is recommended for optimal behavior:
//
// if adjoint_a == false:
//   A should be sorted in lexicographically increasing order.  Use SparseReorder
//   if you're not sure.
// if adjoint_a == true:
//   A should be sorted in order of increasing dimension 1 (i.e., "column major"
//   order instead of "row major" order).
//
// Arguments:
// * scope: A Scope object
// * a_indices: 2-D.  The `indices` of the `SparseTensor`, size `[nnz, 2]` Matrix.
// * a_values: 1-D.  The `values` of the `SparseTensor`, size `[nnz]` Vector.
// * a_shape: 1-D.  The `shape` of the `SparseTensor`, size `[2]` Vector.
// * b: 2-D.  A dense Matrix.
@Namespace("tensorflow::ops") @NoOffset public static class SparseTensorDenseMatMul extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SparseTensorDenseMatMul(Pointer p) { super(p); }

  // Optional attribute setters for SparseTensorDenseMatMul :
  //
  // AdjointA(bool): Defaults to false
  //     Use the adjoint of A in the matrix multiply.  If A is complex, this
  // is transpose(conj(A)).  Otherwise it's transpose(A).
  // AdjointB(bool): Defaults to false
  //     Use the adjoint of B in the matrix multiply.  If B is complex, this
  // is transpose(conj(B)).  Otherwise it's transpose(B).
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs AdjointA(@Cast("bool") boolean x);

    public native @ByVal Attrs AdjointB(@Cast("bool") boolean x);

    public native @Cast("bool") boolean adjoint_a_(); public native Attrs adjoint_a_(boolean adjoint_a_);
    public native @Cast("bool") boolean adjoint_b_(); public native Attrs adjoint_b_(boolean adjoint_b_);
  }
  public SparseTensorDenseMatMul(@Const @ByRef Scope scope,
                          @ByVal Input a_indices,
                          @ByVal Input a_values,
                          @ByVal Input a_shape,
                          @ByVal Input b) { super((Pointer)null); allocate(scope, a_indices, a_values, a_shape, b); }
  private native void allocate(@Const @ByRef Scope scope,
                          @ByVal Input a_indices,
                          @ByVal Input a_values,
                          @ByVal Input a_shape,
                          @ByVal Input b);
  public SparseTensorDenseMatMul(@Const @ByRef Scope scope,
                          @ByVal Input a_indices,
                          @ByVal Input a_values,
                          @ByVal Input a_shape,
                          @ByVal Input b, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, a_indices, a_values, a_shape, b, attrs); }
  private native void allocate(@Const @ByRef Scope scope,
                          @ByVal Input a_indices,
                          @ByVal Input a_values,
                          @ByVal Input a_shape,
                          @ByVal Input b, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs AdjointA(@Cast("bool") boolean x);
  public static native @ByVal Attrs AdjointB(@Cast("bool") boolean x);

  public native @ByRef Output product(); public native SparseTensorDenseMatMul product(Output product);
}

// Converts a sparse representation into a dense tensor.
//
// Builds an array `dense` with shape `output_shape` such that
//
// ```prettyprint
// # If sparse_indices is scalar
// dense[i] = (i == sparse_indices ? sparse_values : default_value)
//
// # If sparse_indices is a vector, then for each i
// dense[sparse_indices[i]] = sparse_values[i]
//
// # If sparse_indices is an n by d matrix, then for each i in [0, n)
// dense[sparse_indices[i][0], ..., sparse_indices[i][d-1]] = sparse_values[i]
// ```
//
// All other values in `dense` are set to `default_value`.  If `sparse_values` is a
// scalar, all sparse indices are set to this single value.
//
// Indices should be sorted in lexicographic order, and indices must not
// contain any repeats. If `validate_indices` is true, these properties
// are checked during execution.
//
// Arguments:
// * scope: A Scope object
// * sparse_indices: 0-D, 1-D, or 2-D.  `sparse_indices[i]` contains the complete
// index where `sparse_values[i]` will be placed.
// * output_shape: 1-D.  Shape of the dense output tensor.
// * sparse_values: 1-D.  Values corresponding to each row of `sparse_indices`,
// or a scalar value to be used for all sparse indices.
// * default_value: Scalar value to set for indices not specified in
// `sparse_indices`.
@Namespace("tensorflow::ops") @NoOffset public static class SparseToDense extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SparseToDense(Pointer p) { super(p); }

  // Optional attribute setters for SparseToDense :
  //
  // ValidateIndices(bool): Defaults to true
  //     If true, indices are checked to make sure they are sorted in
  // lexicographic order and that there are no repeats.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs ValidateIndices(@Cast("bool") boolean x);

    public native @Cast("bool") boolean validate_indices_(); public native Attrs validate_indices_(boolean validate_indices_);
  }
  public SparseToDense(@Const @ByRef Scope scope, @ByVal Input sparse_indices, @ByVal Input output_shape,
                @ByVal Input sparse_values, @ByVal Input default_value) { super((Pointer)null); allocate(scope, sparse_indices, output_shape, sparse_values, default_value); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input sparse_indices, @ByVal Input output_shape,
                @ByVal Input sparse_values, @ByVal Input default_value);
  public SparseToDense(@Const @ByRef Scope scope, @ByVal Input sparse_indices, @ByVal Input output_shape,
                @ByVal Input sparse_values, @ByVal Input default_value, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, sparse_indices, output_shape, sparse_values, default_value, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input sparse_indices, @ByVal Input output_shape,
                @ByVal Input sparse_values, @ByVal Input default_value, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs ValidateIndices(@Cast("bool") boolean x);

  public native @ByRef Output dense(); public native SparseToDense dense(Output dense);
}

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_SPARSE_OPS_H_


// Parsed from tensorflow/cc/ops/state_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_STATE_OPS_H_
// #define TENSORFLOW_CC_OPS_STATE_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"

// Update 'ref' by assigning 'value' to it.
//
// This operation outputs "ref" after the assignment is done.
// This makes it easier to chain operations that need to use the reset value.
//
// Arguments:
// * scope: A Scope object
// * ref: Should be from a `Variable` node. May be uninitialized.
// * value: The value to be assigned to the variable.
@Namespace("tensorflow::ops") @NoOffset public static class Assign extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Assign(Pointer p) { super(p); }

  // Optional attribute setters for Assign :
  //
  // ValidateShape(bool): Defaults to true
  //     If true, the operation will validate that the shape
  // of 'value' matches the shape of the Tensor being assigned to.  If false,
  // 'ref' will take on the shape of 'value'.
  // UseLocking(bool): Defaults to true
  //     If True, the assignment will be protected by a lock;
  // otherwise the behavior is undefined, but may exhibit less contention.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs ValidateShape(@Cast("bool") boolean x);

    public native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

    public native @Cast("bool") boolean validate_shape_(); public native Attrs validate_shape_(boolean validate_shape_);
    public native @Cast("bool") boolean use_locking_(); public native Attrs use_locking_(boolean use_locking_);
  }
  public Assign(@Const @ByRef Scope scope, @ByVal Input ref,
         @ByVal Input value) { super((Pointer)null); allocate(scope, ref, value); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input ref,
         @ByVal Input value);
  public Assign(@Const @ByRef Scope scope, @ByVal Input ref,
         @ByVal Input value, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, ref, value, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input ref,
         @ByVal Input value, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs ValidateShape(@Cast("bool") boolean x);
  public static native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

  public native @ByRef Output output_ref(); public native Assign output_ref(Output output_ref);
}

// Update 'ref' by adding 'value' to it.
//
// This operation outputs "ref" after the update is done.
// This makes it easier to chain operations that need to use the reset value.
//
// Arguments:
// * scope: A Scope object
// * ref: Should be from a `Variable` node.
// * value: The value to be added to the variable.
@Namespace("tensorflow::ops") @NoOffset public static class AssignAdd extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public AssignAdd(Pointer p) { super(p); }

  // Optional attribute setters for AssignAdd :
  //
  // UseLocking(bool): Defaults to false
  //     If True, the addition will be protected by a lock;
  // otherwise the behavior is undefined, but may exhibit less contention.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

    public native @Cast("bool") boolean use_locking_(); public native Attrs use_locking_(boolean use_locking_);
  }
  public AssignAdd(@Const @ByRef Scope scope, @ByVal Input ref,
            @ByVal Input value) { super((Pointer)null); allocate(scope, ref, value); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input ref,
            @ByVal Input value);
  public AssignAdd(@Const @ByRef Scope scope, @ByVal Input ref,
            @ByVal Input value, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, ref, value, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input ref,
            @ByVal Input value, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

  public native @ByRef Output output_ref(); public native AssignAdd output_ref(Output output_ref);
}

// Update 'ref' by subtracting 'value' from it.
//
// This operation outputs "ref" after the update is done.
// This makes it easier to chain operations that need to use the reset value.
//
// Arguments:
// * scope: A Scope object
// * ref: Should be from a `Variable` node.
// * value: The value to be subtracted to the variable.
@Namespace("tensorflow::ops") @NoOffset public static class AssignSub extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public AssignSub(Pointer p) { super(p); }

  // Optional attribute setters for AssignSub :
  //
  // UseLocking(bool): Defaults to false
  //     If True, the subtraction will be protected by a lock;
  // otherwise the behavior is undefined, but may exhibit less contention.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

    public native @Cast("bool") boolean use_locking_(); public native Attrs use_locking_(boolean use_locking_);
  }
  public AssignSub(@Const @ByRef Scope scope, @ByVal Input ref,
            @ByVal Input value) { super((Pointer)null); allocate(scope, ref, value); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input ref,
            @ByVal Input value);
  public AssignSub(@Const @ByRef Scope scope, @ByVal Input ref,
            @ByVal Input value, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, ref, value, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input ref,
            @ByVal Input value, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

  public native @ByRef Output output_ref(); public native AssignSub output_ref(Output output_ref);
}

// Increments 'ref' until it reaches 'limit'.
//
// This operation outputs "ref" after the update is done.  This makes it
// easier to chain operations that need to use the updated value.
//
// Arguments:
// * scope: A Scope object
// * ref: Should be from a scalar `Variable` node.
// * limit:
//     If incrementing ref would bring it above limit, instead generates an
// 'OutOfRange' error.
@Namespace("tensorflow::ops") @NoOffset public static class CountUpTo extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public CountUpTo(Pointer p) { super(p); }

  public CountUpTo(@Const @ByRef Scope scope, @ByVal Input ref, @Cast("tensorflow::int64") long limit) { super((Pointer)null); allocate(scope, ref, limit); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input ref, @Cast("tensorflow::int64") long limit);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native CountUpTo output(Output output);
}

// Destroys the temporary variable and returns its final value.
//
// Sets output to the value of the Tensor pointed to by 'ref', then destroys
// the temporary variable called 'var_name'.
// All other uses of 'ref' *must* have executed before this op.
// This is typically achieved by chaining the ref through each assign op, or by
// using control dependencies.
//
// Outputs the final value of the tensor pointed to by 'ref'.
//
// Arguments:
// * scope: A Scope object
// * ref: A reference to the temporary variable tensor.
// * var_name:
//     Name of the temporary variable, usually the name of the matching
// 'TemporaryVariable' op.
@Namespace("tensorflow::ops") @NoOffset public static class DestroyTemporaryVariable extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public DestroyTemporaryVariable(Pointer p) { super(p); }

  public DestroyTemporaryVariable(@Const @ByRef Scope scope,
                           @ByVal Input ref, @StringPiece BytePointer var_name) { super((Pointer)null); allocate(scope, ref, var_name); }
  private native void allocate(@Const @ByRef Scope scope,
                           @ByVal Input ref, @StringPiece BytePointer var_name);
  public DestroyTemporaryVariable(@Const @ByRef Scope scope,
                           @ByVal Input ref, @StringPiece String var_name) { super((Pointer)null); allocate(scope, ref, var_name); }
  private native void allocate(@Const @ByRef Scope scope,
                           @ByVal Input ref, @StringPiece String var_name);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output value(); public native DestroyTemporaryVariable value(Output value);
}

// Checks whether a tensor has been initialized.
//
// Outputs boolean scalar indicating whether the tensor has been initialized.
//
// Arguments:
// * scope: A Scope object
// * ref: Should be from a `Variable` node. May be uninitialized.
@Namespace("tensorflow::ops") @NoOffset public static class IsVariableInitialized extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IsVariableInitialized(Pointer p) { super(p); }

  public IsVariableInitialized(@Const @ByRef Scope scope,
                        @ByVal Input ref) { super((Pointer)null); allocate(scope, ref); }
  private native void allocate(@Const @ByRef Scope scope,
                        @ByVal Input ref);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output is_initialized(); public native IsVariableInitialized is_initialized(Output is_initialized);
}

// Adds sparse updates to a variable reference.
//
// This operation computes
//
//     # Scalar indices
//     ref[indices, ...] += updates[...]
//
//     # Vector indices (for each i)
//     ref[indices[i], ...] += updates[i, ...]
//
//     # High rank indices (for each i, ..., j)
//     ref[indices[i, ..., j], ...] += updates[i, ..., j, ...]
//
// This operation outputs `ref` after the update is done.
// This makes it easier to chain operations that need to use the reset value.
//
// Duplicate entries are handled correctly: if multiple `indices` reference
// the same location, their contributions add.
//
// Requires `updates.shape = indices.shape + ref.shape[1:]`.
//
// <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
// <img style="width:100%" src="../../images/ScatterAdd.png" alt>
// </div>
//
// Arguments:
// * scope: A Scope object
// * ref: Should be from a `Variable` node.
// * indices: A tensor of indices into the first dimension of `ref`.
// * updates: A tensor of updated values to add to `ref`.
@Namespace("tensorflow::ops") @NoOffset public static class ScatterAdd extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ScatterAdd(Pointer p) { super(p); }

  // Optional attribute setters for ScatterAdd :
  //
  // UseLocking(bool): Defaults to false
  //     If True, the addition will be protected by a lock;
  // otherwise the behavior is undefined, but may exhibit less contention.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

    public native @Cast("bool") boolean use_locking_(); public native Attrs use_locking_(boolean use_locking_);
  }
  public ScatterAdd(@Const @ByRef Scope scope, @ByVal Input ref,
             @ByVal Input indices, @ByVal Input updates) { super((Pointer)null); allocate(scope, ref, indices, updates); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input ref,
             @ByVal Input indices, @ByVal Input updates);
  public ScatterAdd(@Const @ByRef Scope scope, @ByVal Input ref,
             @ByVal Input indices, @ByVal Input updates,
             @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, ref, indices, updates, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input ref,
             @ByVal Input indices, @ByVal Input updates,
             @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

  public native @ByRef Output output_ref(); public native ScatterAdd output_ref(Output output_ref);
}

// Divides a variable reference by sparse updates.
//
// This operation computes
//
//     # Scalar indices
//     ref[indices, ...] /= updates[...]
//
//     # Vector indices (for each i)
//     ref[indices[i], ...] /= updates[i, ...]
//
//     # High rank indices (for each i, ..., j)
//     ref[indices[i, ..., j], ...] /= updates[i, ..., j, ...]
//
// This operation outputs `ref` after the update is done.
// This makes it easier to chain operations that need to use the reset value.
//
// Duplicate entries are handled correctly: if multiple `indices` reference
// the same location, their contributions divide.
//
// Requires `updates.shape = indices.shape + ref.shape[1:]`.
//
// Arguments:
// * scope: A Scope object
// * ref: Should be from a `Variable` node.
// * indices: A tensor of indices into the first dimension of `ref`.
// * updates: A tensor of values that `ref` is divided by.
@Namespace("tensorflow::ops") @NoOffset public static class ScatterDiv extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ScatterDiv(Pointer p) { super(p); }

  // Optional attribute setters for ScatterDiv :
  //
  // UseLocking(bool): Defaults to false
  //     If True, the operation will be protected by a lock;
  // otherwise the behavior is undefined, but may exhibit less contention.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

    public native @Cast("bool") boolean use_locking_(); public native Attrs use_locking_(boolean use_locking_);
  }
  public ScatterDiv(@Const @ByRef Scope scope, @ByVal Input ref,
             @ByVal Input indices, @ByVal Input updates) { super((Pointer)null); allocate(scope, ref, indices, updates); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input ref,
             @ByVal Input indices, @ByVal Input updates);
  public ScatterDiv(@Const @ByRef Scope scope, @ByVal Input ref,
             @ByVal Input indices, @ByVal Input updates,
             @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, ref, indices, updates, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input ref,
             @ByVal Input indices, @ByVal Input updates,
             @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

  public native @ByRef Output output_ref(); public native ScatterDiv output_ref(Output output_ref);
}

// Multiplies sparse updates into a variable reference.
//
// This operation computes
//
//     # Scalar indices
//     ref[indices, ...] *= updates[...]
//
//     # Vector indices (for each i)
//     ref[indices[i], ...] *= updates[i, ...]
//
//     # High rank indices (for each i, ..., j)
//     ref[indices[i, ..., j], ...] *= updates[i, ..., j, ...]
//
// This operation outputs `ref` after the update is done.
// This makes it easier to chain operations that need to use the reset value.
//
// Duplicate entries are handled correctly: if multiple `indices` reference
// the same location, their contributions multiply.
//
// Requires `updates.shape = indices.shape + ref.shape[1:]`.
//
// Arguments:
// * scope: A Scope object
// * ref: Should be from a `Variable` node.
// * indices: A tensor of indices into the first dimension of `ref`.
// * updates: A tensor of updated values to multiply to `ref`.
@Namespace("tensorflow::ops") @NoOffset public static class ScatterMul extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ScatterMul(Pointer p) { super(p); }

  // Optional attribute setters for ScatterMul :
  //
  // UseLocking(bool): Defaults to false
  //     If True, the operation will be protected by a lock;
  // otherwise the behavior is undefined, but may exhibit less contention.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

    public native @Cast("bool") boolean use_locking_(); public native Attrs use_locking_(boolean use_locking_);
  }
  public ScatterMul(@Const @ByRef Scope scope, @ByVal Input ref,
             @ByVal Input indices, @ByVal Input updates) { super((Pointer)null); allocate(scope, ref, indices, updates); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input ref,
             @ByVal Input indices, @ByVal Input updates);
  public ScatterMul(@Const @ByRef Scope scope, @ByVal Input ref,
             @ByVal Input indices, @ByVal Input updates,
             @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, ref, indices, updates, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input ref,
             @ByVal Input indices, @ByVal Input updates,
             @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

  public native @ByRef Output output_ref(); public native ScatterMul output_ref(Output output_ref);
}

// Subtracts sparse updates to a variable reference.
//
//     # Scalar indices
//     ref[indices, ...] -= updates[...]
//
//     # Vector indices (for each i)
//     ref[indices[i], ...] -= updates[i, ...]
//
//     # High rank indices (for each i, ..., j)
//     ref[indices[i, ..., j], ...] -= updates[i, ..., j, ...]
//
// This operation outputs `ref` after the update is done.
// This makes it easier to chain operations that need to use the reset value.
//
// Duplicate entries are handled correctly: if multiple `indices` reference
// the same location, their (negated) contributions add.
//
// Requires `updates.shape = indices.shape + ref.shape[1:]`.
//
// <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
// <img style="width:100%" src="../../images/ScatterSub.png" alt>
// </div>
//
// Arguments:
// * scope: A Scope object
// * ref: Should be from a `Variable` node.
// * indices: A tensor of indices into the first dimension of `ref`.
// * updates: A tensor of updated values to subtract from `ref`.
@Namespace("tensorflow::ops") @NoOffset public static class ScatterSub extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ScatterSub(Pointer p) { super(p); }

  // Optional attribute setters for ScatterSub :
  //
  // UseLocking(bool): Defaults to false
  //     If True, the subtraction will be protected by a lock;
  // otherwise the behavior is undefined, but may exhibit less contention.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

    public native @Cast("bool") boolean use_locking_(); public native Attrs use_locking_(boolean use_locking_);
  }
  public ScatterSub(@Const @ByRef Scope scope, @ByVal Input ref,
             @ByVal Input indices, @ByVal Input updates) { super((Pointer)null); allocate(scope, ref, indices, updates); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input ref,
             @ByVal Input indices, @ByVal Input updates);
  public ScatterSub(@Const @ByRef Scope scope, @ByVal Input ref,
             @ByVal Input indices, @ByVal Input updates,
             @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, ref, indices, updates, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input ref,
             @ByVal Input indices, @ByVal Input updates,
             @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

  public native @ByRef Output output_ref(); public native ScatterSub output_ref(Output output_ref);
}

// Applies sparse updates to a variable reference.
//
// This operation computes
//
//     # Scalar indices
//     ref[indices, ...] = updates[...]
//
//     # Vector indices (for each i)
//     ref[indices[i], ...] = updates[i, ...]
//
//     # High rank indices (for each i, ..., j)
//     ref[indices[i, ..., j], ...] = updates[i, ..., j, ...]
//
// This operation outputs `ref` after the update is done.
// This makes it easier to chain operations that need to use the reset value.
//
// If values in `ref` is to be updated more than once, because there are
// duplicate entires in `indices`, the order at which the updates happen
// for each value is undefined.
//
// Requires `updates.shape = indices.shape + ref.shape[1:]`.
//
// <div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
// <img style="width:100%" src="../../images/ScatterUpdate.png" alt>
// </div>
//
// Arguments:
// * scope: A Scope object
// * ref: Should be from a `Variable` node.
// * indices: A tensor of indices into the first dimension of `ref`.
// * updates: A tensor of updated values to store in `ref`.
@Namespace("tensorflow::ops") @NoOffset public static class ScatterUpdate extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ScatterUpdate(Pointer p) { super(p); }

  // Optional attribute setters for ScatterUpdate :
  //
  // UseLocking(bool): Defaults to true
  //     If True, the assignment will be protected by a lock;
  // otherwise the behavior is undefined, but may exhibit less contention.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

    public native @Cast("bool") boolean use_locking_(); public native Attrs use_locking_(boolean use_locking_);
  }
  public ScatterUpdate(@Const @ByRef Scope scope, @ByVal Input ref,
                @ByVal Input indices, @ByVal Input updates) { super((Pointer)null); allocate(scope, ref, indices, updates); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input ref,
                @ByVal Input indices, @ByVal Input updates);
  public ScatterUpdate(@Const @ByRef Scope scope, @ByVal Input ref,
                @ByVal Input indices, @ByVal Input updates, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, ref, indices, updates, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input ref,
                @ByVal Input indices, @ByVal Input updates, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

  public native @ByRef Output output_ref(); public native ScatterUpdate output_ref(Output output_ref);
}

// Returns a tensor that may be mutated, but only persists within a single step.
//
// This is an experimental op for internal use only and it is possible to use this
// op in unsafe ways.  DO NOT USE unless you fully understand the risks.
//
// It is the caller's responsibility to ensure that 'ref' is eventually passed to a
// matching 'DestroyTemporaryVariable' op after all other uses have completed.
//
// Outputs a ref to the tensor state so it may be read or modified.
//
//   E.g.
//       var = state_ops._temporary_variable([1, 2], types.float_)
//       var_name = var.op.name
//       var = state_ops.assign(var, [[4.0, 5.0]])
//       var = state_ops.assign_add(var, [[6.0, 7.0]])
//       final = state_ops._destroy_temporary_variable(var, var_name=var_name)
//
// Arguments:
// * scope: A Scope object
// * shape:
//     The shape of the variable tensor.
// * dtype:
//     The type of elements in the variable tensor.
@Namespace("tensorflow::ops") @NoOffset public static class TemporaryVariable extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TemporaryVariable(Pointer p) { super(p); }

  // Optional attribute setters for TemporaryVariable :
  //
  // VarName(StringPiece): Defaults to ""
  //     Overrides the name used for the temporary variable resource. Default
  // value is the name of the 'TemporaryVariable' op (which is guaranteed unique).
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs VarName(@StringPiece BytePointer x);
    public native @ByVal Attrs VarName(@StringPiece String x);

    public native @StringPiece BytePointer var_name_(); public native Attrs var_name_(BytePointer var_name_);
  }
  public TemporaryVariable(@Const @ByRef Scope scope, @ByVal TensorShape shape, @Cast("tensorflow::DataType") int dtype) { super((Pointer)null); allocate(scope, shape, dtype); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal TensorShape shape, @Cast("tensorflow::DataType") int dtype);
  public TemporaryVariable(@Const @ByRef Scope scope, @ByVal TensorShape shape, @Cast("tensorflow::DataType") int dtype, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, shape, dtype, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal TensorShape shape, @Cast("tensorflow::DataType") int dtype, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs VarName(@StringPiece BytePointer x);
  public static native @ByVal Attrs VarName(@StringPiece String x);

  public native @ByRef Output ref(); public native TemporaryVariable ref(Output ref);
}

// Holds state in the form of a tensor that persists across steps.
//
// Outputs a ref to the tensor state so it may be read or modified.
// TODO(zhifengc/mrry): Adds a pointer to a more detail document
// about sharing states in tensorflow.
//
// Arguments:
// * scope: A Scope object
// * shape:
//     The shape of the variable tensor.
// * dtype:
//     The type of elements in the variable tensor.
@Namespace("tensorflow::ops") @NoOffset public static class Variable extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Variable(Pointer p) { super(p); }

  // Optional attribute setters for Variable :
  //
  // Container(StringPiece): Defaults to ""
  //     If non-empty, this variable is placed in the given container.
  // Otherwise, a default container is used.
  // SharedName(StringPiece): Defaults to ""
  //     If non-empty, this variable is named in the given bucket
  // with this shared_name. Otherwise, the node name is used instead.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Container(@StringPiece BytePointer x);
    public native @ByVal Attrs Container(@StringPiece String x);

    public native @ByVal Attrs SharedName(@StringPiece BytePointer x);
    public native @ByVal Attrs SharedName(@StringPiece String x);

    public native @StringPiece BytePointer container_(); public native Attrs container_(BytePointer container_);
    public native @StringPiece BytePointer shared_name_(); public native Attrs shared_name_(BytePointer shared_name_);
  }
  public Variable(@Const @ByRef Scope scope, @ByVal TensorShape shape, @Cast("tensorflow::DataType") int dtype) { super((Pointer)null); allocate(scope, shape, dtype); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal TensorShape shape, @Cast("tensorflow::DataType") int dtype);
  public Variable(@Const @ByRef Scope scope, @ByVal TensorShape shape, @Cast("tensorflow::DataType") int dtype,
           @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, shape, dtype, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal TensorShape shape, @Cast("tensorflow::DataType") int dtype,
           @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Container(@StringPiece BytePointer x);
  public static native @ByVal Attrs Container(@StringPiece String x);
  public static native @ByVal Attrs SharedName(@StringPiece BytePointer x);
  public static native @ByVal Attrs SharedName(@StringPiece String x);

  public native @ByRef Output ref(); public native Variable ref(Output ref);
}

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_STATE_OPS_H_


// Parsed from tensorflow/cc/ops/string_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_STRING_OPS_H_
// #define TENSORFLOW_CC_OPS_STRING_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"

// Converts each entry in the given tensor to strings.  Supports many numeric
//
// types and boolean.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class AsString extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public AsString(Pointer p) { super(p); }

  // Optional attribute setters for AsString :
  //
  // Precision(int64): Defaults to -1
  //     The post-decimal precision to use for floating point numbers.
  // Only used if precision > -1.
  // Scientific(bool): Defaults to false
  //     Use scientific notation for floating point numbers.
  // Shortest(bool): Defaults to false
  //     Use shortest representation (either scientific or standard) for
  // floating point numbers.
  // Width(int64): Defaults to -1
  //     Pad pre-decimal numbers to this width.
  // Applies to both floating point and integer numbers.
  // Only used if width > -1.
  // Fill(StringPiece): Defaults to ""
  //     The value to pad if width > -1.  If empty, pads with spaces.
  // Another typical value is '0'.  String cannot be longer than 1 character.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Precision(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs Scientific(@Cast("bool") boolean x);

    public native @ByVal Attrs Shortest(@Cast("bool") boolean x);

    public native @ByVal Attrs Width(@Cast("tensorflow::int64") long x);

    public native @ByVal Attrs Fill(@StringPiece BytePointer x);
    public native @ByVal Attrs Fill(@StringPiece String x);

    public native @Cast("tensorflow::int64") long precision_(); public native Attrs precision_(long precision_);
    public native @Cast("bool") boolean scientific_(); public native Attrs scientific_(boolean scientific_);
    public native @Cast("bool") boolean shortest_(); public native Attrs shortest_(boolean shortest_);
    public native @Cast("tensorflow::int64") long width_(); public native Attrs width_(long width_);
    public native @StringPiece BytePointer fill_(); public native Attrs fill_(BytePointer fill_);
  }
  public AsString(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public AsString(@Const @ByRef Scope scope, @ByVal Input input,
           @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
           @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Precision(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs Scientific(@Cast("bool") boolean x);
  public static native @ByVal Attrs Shortest(@Cast("bool") boolean x);
  public static native @ByVal Attrs Width(@Cast("tensorflow::int64") long x);
  public static native @ByVal Attrs Fill(@StringPiece BytePointer x);
  public static native @ByVal Attrs Fill(@StringPiece String x);

  public native @ByRef Output output(); public native AsString output(Output output);
}

// Decode web-safe base64-encoded strings.
//
// Input may or may not have padding at the end. See EncodeBase64 for padding.
// Web-safe means that input must use - and _ instead of + and /.
//
// Arguments:
// * scope: A Scope object
// * input: Base64 strings to decode.
@Namespace("tensorflow::ops") @NoOffset public static class DecodeBase64 extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public DecodeBase64(Pointer p) { super(p); }

  public DecodeBase64(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native DecodeBase64 output(Output output);
}

// Encode strings into web-safe base64 format.
//
// Refer to the following article for more information on base64 format:
// en.wikipedia.org/wiki/Base64. Base64 strings may have padding with '=' at the
// end so that the encoded has length multiple of 4. See Padding section of the
// link above.
//
// Web-safe means that the encoder uses - and _ instead of + and /.
//
// Arguments:
// * scope: A Scope object
// * input: Strings to be encoded.
@Namespace("tensorflow::ops") @NoOffset public static class EncodeBase64 extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public EncodeBase64(Pointer p) { super(p); }

  // Optional attribute setters for EncodeBase64 :
  //
  // Pad(bool): Defaults to false
  //     Bool whether padding is applied at the ends.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Pad(@Cast("bool") boolean x);

    public native @Cast("bool") boolean pad_(); public native Attrs pad_(boolean pad_);
  }
  public EncodeBase64(@Const @ByRef Scope scope, @ByVal Input input) { super((Pointer)null); allocate(scope, input); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input);
  public EncodeBase64(@Const @ByRef Scope scope, @ByVal Input input,
               @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, input, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
               @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Pad(@Cast("bool") boolean x);

  public native @ByRef Output output(); public native EncodeBase64 output(Output output);
}

// Joins a string Tensor across the given dimensions.
//
// Computes the string join across dimensions in the given string Tensor of shape
// `[d_0, d_1, ..., d_n-1]`.  Returns a new Tensor created by joining the input
// strings with the given separator (default: empty string).  Negative indices are
// counted backwards from the end, with `-1` being equivalent to `n - 1`.  Passing
// an empty `reduction_indices` joins all strings in linear index order and outputs
// a scalar string.
//
//
// For example:
//
// ```
// # tensor `a` is [["a", "b"], ["c", "d"]]
// tf.reduce_join(a, 0) ==> ["ac", "bd"]
// tf.reduce_join(a, 1) ==> ["ab", "cd"]
// tf.reduce_join(a, -2) = tf.reduce_join(a, 0) ==> ["ac", "bd"]
// tf.reduce_join(a, -1) = tf.reduce_join(a, 1) ==> ["ab", "cd"]
// tf.reduce_join(a, 0, keep_dims=True) ==> [["ac", "bd"]]
// tf.reduce_join(a, 1, keep_dims=True) ==> [["ab"], ["cd"]]
// tf.reduce_join(a, 0, separator=".") ==> ["a.c", "b.d"]
// tf.reduce_join(a, [0, 1]) ==> ["acbd"]
// tf.reduce_join(a, [1, 0]) ==> ["abcd"]
// tf.reduce_join(a, []) ==> ["abcd"]
// ```
//
// Arguments:
// * scope: A Scope object
// * inputs: The input to be joined.  All reduced indices must have non-zero size.
// * reduction_indices: The dimensions to reduce over.  Dimensions are reduced in the
// order specified.  Omitting `reduction_indices` is equivalent to passing
// `[n-1, n-2, ..., 0]`.  Negative indices from `-n` to `-1` are supported.
@Namespace("tensorflow::ops") @NoOffset public static class ReduceJoin extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ReduceJoin(Pointer p) { super(p); }

  // Optional attribute setters for ReduceJoin :
  //
  // KeepDims(bool): Defaults to false
  //     If `True`, retain reduced dimensions with length `1`.
  // Separator(StringPiece): Defaults to ""
  //     The separator to use when joining.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs KeepDims(@Cast("bool") boolean x);

    public native @ByVal Attrs Separator(@StringPiece BytePointer x);
    public native @ByVal Attrs Separator(@StringPiece String x);

    public native @Cast("bool") boolean keep_dims_(); public native Attrs keep_dims_(boolean keep_dims_);
    public native @StringPiece BytePointer separator_(); public native Attrs separator_(BytePointer separator_);
  }
  public ReduceJoin(@Const @ByRef Scope scope, @ByVal Input inputs,
             @ByVal Input reduction_indices) { super((Pointer)null); allocate(scope, inputs, reduction_indices); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input inputs,
             @ByVal Input reduction_indices);
  public ReduceJoin(@Const @ByRef Scope scope, @ByVal Input inputs,
             @ByVal Input reduction_indices, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, inputs, reduction_indices, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input inputs,
             @ByVal Input reduction_indices, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs KeepDims(@Cast("bool") boolean x);
  public static native @ByVal Attrs Separator(@StringPiece BytePointer x);
  public static native @ByVal Attrs Separator(@StringPiece String x);

  public native @ByRef Output output(); public native ReduceJoin output(Output output);
}

// Joins the strings in the given list of string tensors into one tensor;
//
// with the given separator (default is an empty separator).
//
// Arguments:
// * scope: A Scope object
// * inputs: A list of string tensors.  The tensors must all have the same shape,
// or be scalars.  Scalars may be mixed in; these will be broadcast to the shape
// of non-scalar inputs.
@Namespace("tensorflow::ops") @NoOffset public static class StringJoin extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public StringJoin(Pointer p) { super(p); }

  // Optional attribute setters for StringJoin :
  //
  // Separator(StringPiece): Defaults to ""
  //     string, an optional join separator.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs Separator(@StringPiece BytePointer x);
    public native @ByVal Attrs Separator(@StringPiece String x);

    public native @StringPiece BytePointer separator_(); public native Attrs separator_(BytePointer separator_);
  }
  public StringJoin(@Const @ByRef Scope scope, @ByVal InputList inputs) { super((Pointer)null); allocate(scope, inputs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal InputList inputs);
  public StringJoin(@Const @ByRef Scope scope, @ByVal InputList inputs, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, inputs, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal InputList inputs, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs Separator(@StringPiece BytePointer x);
  public static native @ByVal Attrs Separator(@StringPiece String x);

  public native @ByRef Output output(); public native StringJoin output(Output output);
}

// Split elements of `input` based on `delimiter` into a `SparseTensor`.
//
// Let N be the size of source (typically N will be the batch size). Split each
// element of `input` based on `delimiter` and return a `SparseTensor`
// containing the splitted tokens. Empty tokens are ignored.
//
// `delimiter` can be empty or a single character. If `delimiter` is an empty
//  string, each element of `input` is split into individual 1 character strings.
//
// For example:
//   N = 2, input[0] is 'hello world' and input[1] is 'a b c', then the output
//   will be
//
//   indices = [0, 0;
//              0, 1;
//              1, 0;
//              1, 1;
//              1, 2]
//   shape = [2, 3]
//   values = ['hello', 'world', 'a', 'b', 'c']
//
// Arguments:
// * scope: A Scope object
// * input: 1-D. Strings to split.
// * delimiter: 0-D. Delimiter character, or empty string.
@Namespace("tensorflow::ops") @NoOffset public static class StringSplit extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public StringSplit(Pointer p) { super(p); }

  public StringSplit(@Const @ByRef Scope scope, @ByVal Input input,
              @ByVal Input delimiter) { super((Pointer)null); allocate(scope, input, delimiter); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input input,
              @ByVal Input delimiter);

  public native @ByRef Output indices(); public native StringSplit indices(Output indices);
  public native @ByRef Output values(); public native StringSplit values(Output values);
  public native @ByRef Output shape(); public native StringSplit shape(Output shape);
}

// Converts each string in the input Tensor to its hash mod by a number of buckets.
//
// The hash function is deterministic on the content of the string within the
// process.
//
// Note that the hash function may change from time to time.
// This functionality will be deprecated and it's recommended to use
// `tf.string_to_hash_bucket_fast()` or `tf.string_to_hash_bucket_strong()`.
//
// Arguments:
// * scope: A Scope object
// * num_buckets:
//     The number of buckets.
@Namespace("tensorflow::ops") @NoOffset public static class StringToHashBucket extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public StringToHashBucket(Pointer p) { super(p); }

  public StringToHashBucket(@Const @ByRef Scope scope, @ByVal Input string_tensor, @Cast("tensorflow::int64") long num_buckets) { super((Pointer)null); allocate(scope, string_tensor, num_buckets); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input string_tensor, @Cast("tensorflow::int64") long num_buckets);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native StringToHashBucket output(Output output);
}

// Converts each string in the input Tensor to its hash mod by a number of buckets.
//
// The hash function is deterministic on the content of the string within the
// process and will never change. However, it is not suitable for cryptography.
// This function may be used when CPU time is scarce and inputs are trusted or
// unimportant. There is a risk of adversaries constructing inputs that all hash
// to the same bucket. To prevent this problem, use a strong hash function with
// `tf.string_to_hash_bucket_strong`.
//
// Arguments:
// * scope: A Scope object
// * input: The strings to assign a hash bucket.
// * num_buckets:
//     The number of buckets.
@Namespace("tensorflow::ops") @NoOffset public static class StringToHashBucketFast extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public StringToHashBucketFast(Pointer p) { super(p); }

  public StringToHashBucketFast(@Const @ByRef Scope scope,
                         @ByVal Input input, @Cast("tensorflow::int64") long num_buckets) { super((Pointer)null); allocate(scope, input, num_buckets); }
  private native void allocate(@Const @ByRef Scope scope,
                         @ByVal Input input, @Cast("tensorflow::int64") long num_buckets);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native StringToHashBucketFast output(Output output);
}

// Converts each string in the input Tensor to its hash mod by a number of buckets.
//
// The hash function is deterministic on the content of the string within the
// process. The hash function is a keyed hash function, where attribute `key`
// defines the key of the hash function. `key` is an array of 2 elements.
//
// A strong hash is important when inputs may be malicious, e.g. URLs with
// additional components. Adversaries could try to make their inputs hash to the
// same bucket for a denial-of-service attack or to skew the results. A strong
// hash prevents this by making it dificult, if not infeasible, to compute inputs
// that hash to the same bucket. This comes at a cost of roughly 4x higher compute
// time than tf.string_to_hash_bucket_fast.
//
// Arguments:
// * scope: A Scope object
// * input: The strings to assign a hash bucket.
// * num_buckets:
//     The number of buckets.
// * key:
//     The key for the keyed hash function passed as a list of two uint64
// elements.
@Namespace("tensorflow::ops") @NoOffset public static class StringToHashBucketStrong extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public StringToHashBucketStrong(Pointer p) { super(p); }

  public StringToHashBucketStrong(@Const @ByRef Scope scope,
                           @ByVal Input input, @Cast("tensorflow::int64") long num_buckets,
                           @ArraySlice IntPointer key) { super((Pointer)null); allocate(scope, input, num_buckets, key); }
  private native void allocate(@Const @ByRef Scope scope,
                           @ByVal Input input, @Cast("tensorflow::int64") long num_buckets,
                           @ArraySlice IntPointer key);
  public StringToHashBucketStrong(@Const @ByRef Scope scope,
                           @ByVal Input input, @Cast("tensorflow::int64") long num_buckets,
                           @ArraySlice IntBuffer key) { super((Pointer)null); allocate(scope, input, num_buckets, key); }
  private native void allocate(@Const @ByRef Scope scope,
                           @ByVal Input input, @Cast("tensorflow::int64") long num_buckets,
                           @ArraySlice IntBuffer key);
  public StringToHashBucketStrong(@Const @ByRef Scope scope,
                           @ByVal Input input, @Cast("tensorflow::int64") long num_buckets,
                           @ArraySlice int... key) { super((Pointer)null); allocate(scope, input, num_buckets, key); }
  private native void allocate(@Const @ByRef Scope scope,
                           @ByVal Input input, @Cast("tensorflow::int64") long num_buckets,
                           @ArraySlice int... key);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output output(); public native StringToHashBucketStrong output(Output output);
}

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_STRING_OPS_H_


// Parsed from tensorflow/cc/ops/training_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_TRAINING_OPS_H_
// #define TENSORFLOW_CC_OPS_TRAINING_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"

// Update '*var' according to the adadelta scheme.
//
// accum = rho() * accum + (1 - rho()) * grad.square();
// update = (update_accum + epsilon).sqrt() * (accum + epsilon()).rsqrt() * grad;
// update_accum = rho() * update_accum + (1 - rho()) * update.square();
// var -= update;
//
// Arguments:
// * scope: A Scope object
// * var: Should be from a Variable().
// * accum: Should be from a Variable().
// * accum_update: Should be from a Variable().
// * lr: Scaling factor. Must be a scalar.
// * rho: Decay factor. Must be a scalar.
// * epsilon: Constant factor. Must be a scalar.
// * grad: The gradient.
@Namespace("tensorflow::ops") @NoOffset public static class ApplyAdadelta extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ApplyAdadelta(Pointer p) { super(p); }

  // Optional attribute setters for ApplyAdadelta :
  //
  // UseLocking(bool): Defaults to false
  //     If True, updating of the var, accum and update_accum tensors will be protected by
  // a lock; otherwise the behavior is undefined, but may exhibit less contention.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

    public native @Cast("bool") boolean use_locking_(); public native Attrs use_locking_(boolean use_locking_);
  }
  public ApplyAdadelta(@Const @ByRef Scope scope, @ByVal Input var,
                @ByVal Input accum, @ByVal Input accum_update, @ByVal Input lr,
                @ByVal Input rho, @ByVal Input epsilon,
                @ByVal Input grad) { super((Pointer)null); allocate(scope, var, accum, accum_update, lr, rho, epsilon, grad); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input var,
                @ByVal Input accum, @ByVal Input accum_update, @ByVal Input lr,
                @ByVal Input rho, @ByVal Input epsilon,
                @ByVal Input grad);
  public ApplyAdadelta(@Const @ByRef Scope scope, @ByVal Input var,
                @ByVal Input accum, @ByVal Input accum_update, @ByVal Input lr,
                @ByVal Input rho, @ByVal Input epsilon,
                @ByVal Input grad, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, var, accum, accum_update, lr, rho, epsilon, grad, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input var,
                @ByVal Input accum, @ByVal Input accum_update, @ByVal Input lr,
                @ByVal Input rho, @ByVal Input epsilon,
                @ByVal Input grad, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

  public native @ByRef Output out(); public native ApplyAdadelta out(Output out);
}

// Update '*var' according to the adagrad scheme.
//
// accum += grad * grad
// var -= lr * grad * (1 / sqrt(accum))
//
// Arguments:
// * scope: A Scope object
// * var: Should be from a Variable().
// * accum: Should be from a Variable().
// * lr: Scaling factor. Must be a scalar.
// * grad: The gradient.
@Namespace("tensorflow::ops") @NoOffset public static class ApplyAdagrad extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ApplyAdagrad(Pointer p) { super(p); }

  // Optional attribute setters for ApplyAdagrad :
  //
  // UseLocking(bool): Defaults to false
  //     If `True`, updating of the var and accum tensors will be protected
  // by a lock; otherwise the behavior is undefined, but may exhibit less
  // contention.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

    public native @Cast("bool") boolean use_locking_(); public native Attrs use_locking_(boolean use_locking_);
  }
  public ApplyAdagrad(@Const @ByRef Scope scope, @ByVal Input var,
               @ByVal Input accum, @ByVal Input lr,
               @ByVal Input grad) { super((Pointer)null); allocate(scope, var, accum, lr, grad); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input var,
               @ByVal Input accum, @ByVal Input lr,
               @ByVal Input grad);
  public ApplyAdagrad(@Const @ByRef Scope scope, @ByVal Input var,
               @ByVal Input accum, @ByVal Input lr,
               @ByVal Input grad, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, var, accum, lr, grad, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input var,
               @ByVal Input accum, @ByVal Input lr,
               @ByVal Input grad, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

  public native @ByRef Output out(); public native ApplyAdagrad out(Output out);
}

// Update '*var' according to the proximal adagrad scheme.
//
// Arguments:
// * scope: A Scope object
// * var: Should be from a Variable().
// * gradient_accumulator: Should be from a Variable().
// * gradient_squared_accumulator: Should be from a Variable().
// * grad: The gradient.
// * lr: Scaling factor. Must be a scalar.
// * l1: L1 regularization. Must be a scalar.
// * l2: L2 regularization. Must be a scalar.
// * global_step: Training step number. Must be a scalar.
@Namespace("tensorflow::ops") @NoOffset public static class ApplyAdagradDA extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ApplyAdagradDA(Pointer p) { super(p); }

  // Optional attribute setters for ApplyAdagradDA :
  //
  // UseLocking(bool): Defaults to false
  //     If True, updating of the var and accum tensors will be protected by
  // a lock; otherwise the behavior is undefined, but may exhibit less contention.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

    public native @Cast("bool") boolean use_locking_(); public native Attrs use_locking_(boolean use_locking_);
  }
  public ApplyAdagradDA(@Const @ByRef Scope scope, @ByVal Input var,
                 @ByVal Input gradient_accumulator,
                 @ByVal Input gradient_squared_accumulator,
                 @ByVal Input grad, @ByVal Input lr,
                 @ByVal Input l1, @ByVal Input l2,
                 @ByVal Input global_step) { super((Pointer)null); allocate(scope, var, gradient_accumulator, gradient_squared_accumulator, grad, lr, l1, l2, global_step); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input var,
                 @ByVal Input gradient_accumulator,
                 @ByVal Input gradient_squared_accumulator,
                 @ByVal Input grad, @ByVal Input lr,
                 @ByVal Input l1, @ByVal Input l2,
                 @ByVal Input global_step);
  public ApplyAdagradDA(@Const @ByRef Scope scope, @ByVal Input var,
                 @ByVal Input gradient_accumulator,
                 @ByVal Input gradient_squared_accumulator,
                 @ByVal Input grad, @ByVal Input lr,
                 @ByVal Input l1, @ByVal Input l2,
                 @ByVal Input global_step, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, var, gradient_accumulator, gradient_squared_accumulator, grad, lr, l1, l2, global_step, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input var,
                 @ByVal Input gradient_accumulator,
                 @ByVal Input gradient_squared_accumulator,
                 @ByVal Input grad, @ByVal Input lr,
                 @ByVal Input l1, @ByVal Input l2,
                 @ByVal Input global_step, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

  public native @ByRef Output out(); public native ApplyAdagradDA out(Output out);
}

// Update '*var' according to the Adam algorithm.
//
// lr_t <- learning_rate * sqrt(1 - beta2^t) / (1 - beta1^t)
// m_t <- beta1 * m_{t-1} + (1 - beta1) * g_t
// v_t <- beta2 * v_{t-1} + (1 - beta2) * g_t * g_t
// variable <- variable - lr_t * m_t / (sqrt(v_t) + epsilon)
//
// Arguments:
// * scope: A Scope object
// * var: Should be from a Variable().
// * m: Should be from a Variable().
// * v: Should be from a Variable().
// * beta1_power: Must be a scalar.
// * beta2_power: Must be a scalar.
// * lr: Scaling factor. Must be a scalar.
// * beta1: Momentum factor. Must be a scalar.
// * beta2: Momentum factor. Must be a scalar.
// * epsilon: Ridge term. Must be a scalar.
// * grad: The gradient.
@Namespace("tensorflow::ops") @NoOffset public static class ApplyAdam extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ApplyAdam(Pointer p) { super(p); }

  // Optional attribute setters for ApplyAdam :
  //
  // UseLocking(bool): Defaults to false
  //     If `True`, updating of the var, m, and v tensors will be protected
  // by a lock; otherwise the behavior is undefined, but may exhibit less
  // contention.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

    public native @Cast("bool") boolean use_locking_(); public native Attrs use_locking_(boolean use_locking_);
  }
  public ApplyAdam(@Const @ByRef Scope scope, @ByVal Input var,
            @ByVal Input m, @ByVal Input v,
            @ByVal Input beta1_power, @ByVal Input beta2_power, @ByVal Input lr, @ByVal Input beta1, @ByVal Input beta2, @ByVal Input epsilon, @ByVal Input grad) { super((Pointer)null); allocate(scope, var, m, v, beta1_power, beta2_power, lr, beta1, beta2, epsilon, grad); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input var,
            @ByVal Input m, @ByVal Input v,
            @ByVal Input beta1_power, @ByVal Input beta2_power, @ByVal Input lr, @ByVal Input beta1, @ByVal Input beta2, @ByVal Input epsilon, @ByVal Input grad);
  public ApplyAdam(@Const @ByRef Scope scope, @ByVal Input var,
            @ByVal Input m, @ByVal Input v,
            @ByVal Input beta1_power, @ByVal Input beta2_power, @ByVal Input lr, @ByVal Input beta1, @ByVal Input beta2, @ByVal Input epsilon, @ByVal Input grad, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, var, m, v, beta1_power, beta2_power, lr, beta1, beta2, epsilon, grad, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input var,
            @ByVal Input m, @ByVal Input v,
            @ByVal Input beta1_power, @ByVal Input beta2_power, @ByVal Input lr, @ByVal Input beta1, @ByVal Input beta2, @ByVal Input epsilon, @ByVal Input grad, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

  public native @ByRef Output out(); public native ApplyAdam out(Output out);
}

// Update '*var' according to the Ftrl-proximal scheme.
//
// accum_new = accum + grad * grad
// linear += grad + (accum_new^(-lr_power) - accum^(-lr_power)) / lr * var
// quadratic = 1.0 / (accum_new^(lr_power) * lr) + 2 * l2
// var = (sign(linear) * l1 - linear) / quadratic if |linear| > l1 else 0.0
// accum = accum_new
//
// Arguments:
// * scope: A Scope object
// * var: Should be from a Variable().
// * accum: Should be from a Variable().
// * linear: Should be from a Variable().
// * grad: The gradient.
// * lr: Scaling factor. Must be a scalar.
// * l1: L1 regulariation. Must be a scalar.
// * l2: L2 regulariation. Must be a scalar.
// * lr_power: Scaling factor. Must be a scalar.
@Namespace("tensorflow::ops") @NoOffset public static class ApplyFtrl extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ApplyFtrl(Pointer p) { super(p); }

  // Optional attribute setters for ApplyFtrl :
  //
  // UseLocking(bool): Defaults to false
  //     If `True`, updating of the var and accum tensors will be protected
  // by a lock; otherwise the behavior is undefined, but may exhibit less
  // contention.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

    public native @Cast("bool") boolean use_locking_(); public native Attrs use_locking_(boolean use_locking_);
  }
  public ApplyFtrl(@Const @ByRef Scope scope, @ByVal Input var,
            @ByVal Input accum, @ByVal Input linear,
            @ByVal Input grad, @ByVal Input lr,
            @ByVal Input l1, @ByVal Input l2,
            @ByVal Input lr_power) { super((Pointer)null); allocate(scope, var, accum, linear, grad, lr, l1, l2, lr_power); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input var,
            @ByVal Input accum, @ByVal Input linear,
            @ByVal Input grad, @ByVal Input lr,
            @ByVal Input l1, @ByVal Input l2,
            @ByVal Input lr_power);
  public ApplyFtrl(@Const @ByRef Scope scope, @ByVal Input var,
            @ByVal Input accum, @ByVal Input linear,
            @ByVal Input grad, @ByVal Input lr,
            @ByVal Input l1, @ByVal Input l2,
            @ByVal Input lr_power, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, var, accum, linear, grad, lr, l1, l2, lr_power, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input var,
            @ByVal Input accum, @ByVal Input linear,
            @ByVal Input grad, @ByVal Input lr,
            @ByVal Input l1, @ByVal Input l2,
            @ByVal Input lr_power, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

  public native @ByRef Output out(); public native ApplyFtrl out(Output out);
}

// Update '*var' by subtracting 'alpha' * 'delta' from it.
//
// Arguments:
// * scope: A Scope object
// * var: Should be from a Variable().
// * alpha: Scaling factor. Must be a scalar.
// * delta: The change.
@Namespace("tensorflow::ops") @NoOffset public static class ApplyGradientDescent extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ApplyGradientDescent(Pointer p) { super(p); }

  // Optional attribute setters for ApplyGradientDescent :
  //
  // UseLocking(bool): Defaults to false
  //     If `True`, the subtraction will be protected by a lock;
  // otherwise the behavior is undefined, but may exhibit less contention.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

    public native @Cast("bool") boolean use_locking_(); public native Attrs use_locking_(boolean use_locking_);
  }
  public ApplyGradientDescent(@Const @ByRef Scope scope, @ByVal Input var, @ByVal Input alpha,
                       @ByVal Input delta) { super((Pointer)null); allocate(scope, var, alpha, delta); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input var, @ByVal Input alpha,
                       @ByVal Input delta);
  public ApplyGradientDescent(@Const @ByRef Scope scope, @ByVal Input var, @ByVal Input alpha,
                       @ByVal Input delta, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, var, alpha, delta, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input var, @ByVal Input alpha,
                       @ByVal Input delta, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

  public native @ByRef Output out(); public native ApplyGradientDescent out(Output out);
}

// Update '*var' according to the momentum scheme. Set use_nesterov = True if you
//
// want to use Nesterov momentum.
//
// accum = accum * momentum + grad
// var -= lr * accum
//
// Arguments:
// * scope: A Scope object
// * var: Should be from a Variable().
// * accum: Should be from a Variable().
// * lr: Scaling factor. Must be a scalar.
// * grad: The gradient.
// * momentum: Momentum. Must be a scalar.
@Namespace("tensorflow::ops") @NoOffset public static class ApplyMomentum extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ApplyMomentum(Pointer p) { super(p); }

  // Optional attribute setters for ApplyMomentum :
  //
  // UseLocking(bool): Defaults to false
  //     If `True`, updating of the var and accum tensors will be protected
  // by a lock; otherwise the behavior is undefined, but may exhibit less
  // contention.
  // UseNesterov(bool): Defaults to false
  //     If `True`, the tensor passed to compute grad will be
  // var - lr * momentum * accum, so in the end, the var you get is actually
  // var - lr * momentum * accum.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

    public native @ByVal Attrs UseNesterov(@Cast("bool") boolean x);

    public native @Cast("bool") boolean use_locking_(); public native Attrs use_locking_(boolean use_locking_);
    public native @Cast("bool") boolean use_nesterov_(); public native Attrs use_nesterov_(boolean use_nesterov_);
  }
  public ApplyMomentum(@Const @ByRef Scope scope, @ByVal Input var,
                @ByVal Input accum, @ByVal Input lr,
                @ByVal Input grad, @ByVal Input momentum) { super((Pointer)null); allocate(scope, var, accum, lr, grad, momentum); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input var,
                @ByVal Input accum, @ByVal Input lr,
                @ByVal Input grad, @ByVal Input momentum);
  public ApplyMomentum(@Const @ByRef Scope scope, @ByVal Input var,
                @ByVal Input accum, @ByVal Input lr,
                @ByVal Input grad, @ByVal Input momentum,
                @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, var, accum, lr, grad, momentum, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input var,
                @ByVal Input accum, @ByVal Input lr,
                @ByVal Input grad, @ByVal Input momentum,
                @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs UseLocking(@Cast("bool") boolean x);
  public static native @ByVal Attrs UseNesterov(@Cast("bool") boolean x);

  public native @ByRef Output out(); public native ApplyMomentum out(Output out);
}

// Update '*var' and '*accum' according to FOBOS with Adagrad learning rate.
//
// accum += grad * grad
// prox_v = var - lr * grad * (1 / sqrt(accum))
// var = sign(prox_v)/(1+lr*l2) * max{|prox_v|-lr*l1,0}
//
// Arguments:
// * scope: A Scope object
// * var: Should be from a Variable().
// * accum: Should be from a Variable().
// * lr: Scaling factor. Must be a scalar.
// * l1: L1 regularization. Must be a scalar.
// * l2: L2 regularization. Must be a scalar.
// * grad: The gradient.
@Namespace("tensorflow::ops") @NoOffset public static class ApplyProximalAdagrad extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ApplyProximalAdagrad(Pointer p) { super(p); }

  // Optional attribute setters for ApplyProximalAdagrad :
  //
  // UseLocking(bool): Defaults to false
  //     If True, updating of the var and accum tensors will be protected by
  // a lock; otherwise the behavior is undefined, but may exhibit less contention.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

    public native @Cast("bool") boolean use_locking_(); public native Attrs use_locking_(boolean use_locking_);
  }
  public ApplyProximalAdagrad(@Const @ByRef Scope scope, @ByVal Input var, @ByVal Input accum,
                       @ByVal Input lr, @ByVal Input l1,
                       @ByVal Input l2, @ByVal Input grad) { super((Pointer)null); allocate(scope, var, accum, lr, l1, l2, grad); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input var, @ByVal Input accum,
                       @ByVal Input lr, @ByVal Input l1,
                       @ByVal Input l2, @ByVal Input grad);
  public ApplyProximalAdagrad(@Const @ByRef Scope scope, @ByVal Input var, @ByVal Input accum,
                       @ByVal Input lr, @ByVal Input l1,
                       @ByVal Input l2, @ByVal Input grad, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, var, accum, lr, l1, l2, grad, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input var, @ByVal Input accum,
                       @ByVal Input lr, @ByVal Input l1,
                       @ByVal Input l2, @ByVal Input grad, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

  public native @ByRef Output out(); public native ApplyProximalAdagrad out(Output out);
}

// Update '*var' as FOBOS algorithm with fixed learning rate.
//
// prox_v = var - alpha * delta
// var = sign(prox_v)/(1+alpha*l2) * max{|prox_v|-alpha*l1,0}
//
// Arguments:
// * scope: A Scope object
// * var: Should be from a Variable().
// * alpha: Scaling factor. Must be a scalar.
// * l1: L1 regularization. Must be a scalar.
// * l2: L2 regularization. Must be a scalar.
// * delta: The change.
@Namespace("tensorflow::ops") @NoOffset public static class ApplyProximalGradientDescent extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ApplyProximalGradientDescent(Pointer p) { super(p); }

  // Optional attribute setters for ApplyProximalGradientDescent :
  //
  // UseLocking(bool): Defaults to false
  //     If True, the subtraction will be protected by a lock;
  // otherwise the behavior is undefined, but may exhibit less contention.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

    public native @Cast("bool") boolean use_locking_(); public native Attrs use_locking_(boolean use_locking_);
  }
  public ApplyProximalGradientDescent(@Const @ByRef Scope scope,
                               @ByVal Input var,
                               @ByVal Input alpha,
                               @ByVal Input l1,
                               @ByVal Input l2,
                               @ByVal Input delta) { super((Pointer)null); allocate(scope, var, alpha, l1, l2, delta); }
  private native void allocate(@Const @ByRef Scope scope,
                               @ByVal Input var,
                               @ByVal Input alpha,
                               @ByVal Input l1,
                               @ByVal Input l2,
                               @ByVal Input delta);
  public ApplyProximalGradientDescent(@Const @ByRef Scope scope,
                               @ByVal Input var,
                               @ByVal Input alpha,
                               @ByVal Input l1,
                               @ByVal Input l2,
                               @ByVal Input delta, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, var, alpha, l1, l2, delta, attrs); }
  private native void allocate(@Const @ByRef Scope scope,
                               @ByVal Input var,
                               @ByVal Input alpha,
                               @ByVal Input l1,
                               @ByVal Input l2,
                               @ByVal Input delta, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

  public native @ByRef Output out(); public native ApplyProximalGradientDescent out(Output out);
}

// Update '*var' according to the RMSProp algorithm.
//
// Note that in dense implement of this algorithm, ms and mom will
// update even if the grad is zero, but in this sparse implement, ms
// and mom will not update in iterations the grad is zero.
//
// mean_square = decay * mean_square + (1-decay) * gradient ** 2
// Delta = learning_rate * gradient / sqrt(mean_square + epsilon)
//
// ms <- rho * ms_{t-1} + (1-rho) * grad * grad
// mom <- momentum * mom_{t-1} + lr * grad / sqrt(ms + epsilon)
// var <- var - mom
//
// Arguments:
// * scope: A Scope object
// * var: Should be from a Variable().
// * ms: Should be from a Variable().
// * mom: Should be from a Variable().
// * lr: Scaling factor. Must be a scalar.
// * rho: Decay rate. Must be a scalar.
// * epsilon: Ridge term. Must be a scalar.
// * grad: The gradient.
@Namespace("tensorflow::ops") @NoOffset public static class ApplyRMSProp extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ApplyRMSProp(Pointer p) { super(p); }

  // Optional attribute setters for ApplyRMSProp :
  //
  // UseLocking(bool): Defaults to false
  //     If `True`, updating of the var, m, and v tensors will be protected
  // by a lock; otherwise the behavior is undefined, but may exhibit less
  // contention.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

    public native @Cast("bool") boolean use_locking_(); public native Attrs use_locking_(boolean use_locking_);
  }
  public ApplyRMSProp(@Const @ByRef Scope scope, @ByVal Input var,
               @ByVal Input ms, @ByVal Input mom,
               @ByVal Input lr, @ByVal Input rho,
               @ByVal Input momentum, @ByVal Input epsilon, @ByVal Input grad) { super((Pointer)null); allocate(scope, var, ms, mom, lr, rho, momentum, epsilon, grad); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input var,
               @ByVal Input ms, @ByVal Input mom,
               @ByVal Input lr, @ByVal Input rho,
               @ByVal Input momentum, @ByVal Input epsilon, @ByVal Input grad);
  public ApplyRMSProp(@Const @ByRef Scope scope, @ByVal Input var,
               @ByVal Input ms, @ByVal Input mom,
               @ByVal Input lr, @ByVal Input rho,
               @ByVal Input momentum, @ByVal Input epsilon, @ByVal Input grad, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, var, ms, mom, lr, rho, momentum, epsilon, grad, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input var,
               @ByVal Input ms, @ByVal Input mom,
               @ByVal Input lr, @ByVal Input rho,
               @ByVal Input momentum, @ByVal Input epsilon, @ByVal Input grad, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

  public native @ByRef Output out(); public native ApplyRMSProp out(Output out);
}

// var: Should be from a Variable().
//
// Arguments:
// * scope: A Scope object
// * accum: Should be from a Variable().
// * accum_update: : Should be from a Variable().
// * lr: Learning rate. Must be a scalar.
// * rho: Decay factor. Must be a scalar.
// * epsilon: Constant factor. Must be a scalar.
// * grad: The gradient.
// * indices: A vector of indices into the first dimension of var and accum.
@Namespace("tensorflow::ops") @NoOffset public static class SparseApplyAdadelta extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SparseApplyAdadelta(Pointer p) { super(p); }

  // Optional attribute setters for SparseApplyAdadelta :
  //
  // UseLocking(bool): Defaults to false
  //     If True, updating of the var and accum tensors will be protected by
  // a lock; otherwise the behavior is undefined, but may exhibit less contention.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

    public native @Cast("bool") boolean use_locking_(); public native Attrs use_locking_(boolean use_locking_);
  }
  public SparseApplyAdadelta(@Const @ByRef Scope scope, @ByVal Input var, @ByVal Input accum,
                      @ByVal Input accum_update,
                      @ByVal Input lr, @ByVal Input rho,
                      @ByVal Input epsilon, @ByVal Input grad, @ByVal Input indices) { super((Pointer)null); allocate(scope, var, accum, accum_update, lr, rho, epsilon, grad, indices); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input var, @ByVal Input accum,
                      @ByVal Input accum_update,
                      @ByVal Input lr, @ByVal Input rho,
                      @ByVal Input epsilon, @ByVal Input grad, @ByVal Input indices);
  public SparseApplyAdadelta(@Const @ByRef Scope scope, @ByVal Input var, @ByVal Input accum,
                      @ByVal Input accum_update,
                      @ByVal Input lr, @ByVal Input rho,
                      @ByVal Input epsilon, @ByVal Input grad, @ByVal Input indices, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, var, accum, accum_update, lr, rho, epsilon, grad, indices, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input var, @ByVal Input accum,
                      @ByVal Input accum_update,
                      @ByVal Input lr, @ByVal Input rho,
                      @ByVal Input epsilon, @ByVal Input grad, @ByVal Input indices, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

  public native @ByRef Output out(); public native SparseApplyAdadelta out(Output out);
}

// Update relevant entries in '*var' and '*accum' according to the adagrad scheme.
//
// That is for rows we have grad for, we update var and accum as follows:
// accum += grad * grad
// var -= lr * grad * (1 / sqrt(accum))
//
// Arguments:
// * scope: A Scope object
// * var: Should be from a Variable().
// * accum: Should be from a Variable().
// * lr: Learning rate. Must be a scalar.
// * grad: The gradient.
// * indices: A vector of indices into the first dimension of var and accum.
@Namespace("tensorflow::ops") @NoOffset public static class SparseApplyAdagrad extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SparseApplyAdagrad(Pointer p) { super(p); }

  // Optional attribute setters for SparseApplyAdagrad :
  //
  // UseLocking(bool): Defaults to false
  //     If `True`, updating of the var and accum tensors will be protected
  // by a lock; otherwise the behavior is undefined, but may exhibit less
  // contention.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

    public native @Cast("bool") boolean use_locking_(); public native Attrs use_locking_(boolean use_locking_);
  }
  public SparseApplyAdagrad(@Const @ByRef Scope scope, @ByVal Input var, @ByVal Input accum,
                     @ByVal Input lr, @ByVal Input grad,
                     @ByVal Input indices) { super((Pointer)null); allocate(scope, var, accum, lr, grad, indices); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input var, @ByVal Input accum,
                     @ByVal Input lr, @ByVal Input grad,
                     @ByVal Input indices);
  public SparseApplyAdagrad(@Const @ByRef Scope scope, @ByVal Input var, @ByVal Input accum,
                     @ByVal Input lr, @ByVal Input grad,
                     @ByVal Input indices, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, var, accum, lr, grad, indices, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input var, @ByVal Input accum,
                     @ByVal Input lr, @ByVal Input grad,
                     @ByVal Input indices, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

  public native @ByRef Output out(); public native SparseApplyAdagrad out(Output out);
}

// Update entries in '*var' and '*accum' according to the proximal adagrad scheme.
//
// Arguments:
// * scope: A Scope object
// * var: Should be from a Variable().
// * gradient_accumulator: Should be from a Variable().
// * gradient_squared_accumulator: Should be from a Variable().
// * grad: The gradient.
// * indices: A vector of indices into the first dimension of var and accum.
// * lr: Learning rate. Must be a scalar.
// * l1: L1 regularization. Must be a scalar.
// * l2: L2 regularization. Must be a scalar.
// * global_step: Training step number. Must be a scalar.
@Namespace("tensorflow::ops") @NoOffset public static class SparseApplyAdagradDA extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SparseApplyAdagradDA(Pointer p) { super(p); }

  // Optional attribute setters for SparseApplyAdagradDA :
  //
  // UseLocking(bool): Defaults to false
  //     If True, updating of the var and accum tensors will be protected by
  // a lock; otherwise the behavior is undefined, but may exhibit less contention.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

    public native @Cast("bool") boolean use_locking_(); public native Attrs use_locking_(boolean use_locking_);
  }
  public SparseApplyAdagradDA(@Const @ByRef Scope scope, @ByVal Input var, @ByVal Input gradient_accumulator,
                       @ByVal Input gradient_squared_accumulator,
                       @ByVal Input grad, @ByVal Input indices, @ByVal Input lr,
                       @ByVal Input l1, @ByVal Input l2,
                       @ByVal Input global_step) { super((Pointer)null); allocate(scope, var, gradient_accumulator, gradient_squared_accumulator, grad, indices, lr, l1, l2, global_step); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input var, @ByVal Input gradient_accumulator,
                       @ByVal Input gradient_squared_accumulator,
                       @ByVal Input grad, @ByVal Input indices, @ByVal Input lr,
                       @ByVal Input l1, @ByVal Input l2,
                       @ByVal Input global_step);
  public SparseApplyAdagradDA(@Const @ByRef Scope scope, @ByVal Input var, @ByVal Input gradient_accumulator,
                       @ByVal Input gradient_squared_accumulator,
                       @ByVal Input grad, @ByVal Input indices, @ByVal Input lr,
                       @ByVal Input l1, @ByVal Input l2,
                       @ByVal Input global_step, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, var, gradient_accumulator, gradient_squared_accumulator, grad, indices, lr, l1, l2, global_step, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input var, @ByVal Input gradient_accumulator,
                       @ByVal Input gradient_squared_accumulator,
                       @ByVal Input grad, @ByVal Input indices, @ByVal Input lr,
                       @ByVal Input l1, @ByVal Input l2,
                       @ByVal Input global_step, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

  public native @ByRef Output out(); public native SparseApplyAdagradDA out(Output out);
}

// Update relevant entries in '*var' according to the Ftrl-proximal scheme.
//
// That is for rows we have grad for, we update var, accum and linear as follows:
// accum_new = accum + grad * grad
// linear += grad + (accum_new^(-lr_power) - accum^(-lr_power)) / lr * var
// quadratic = 1.0 / (accum_new^(lr_power) * lr) + 2 * l2
// var = (sign(linear) * l1 - linear) / quadratic if |linear| > l1 else 0.0
// accum = accum_new
//
// Arguments:
// * scope: A Scope object
// * var: Should be from a Variable().
// * accum: Should be from a Variable().
// * linear: Should be from a Variable().
// * grad: The gradient.
// * indices: A vector of indices into the first dimension of var and accum.
// * lr: Scaling factor. Must be a scalar.
// * l1: L1 regularization. Must be a scalar.
// * l2: L2 regularization. Must be a scalar.
// * lr_power: Scaling factor. Must be a scalar.
@Namespace("tensorflow::ops") @NoOffset public static class SparseApplyFtrl extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SparseApplyFtrl(Pointer p) { super(p); }

  // Optional attribute setters for SparseApplyFtrl :
  //
  // UseLocking(bool): Defaults to false
  //     If `True`, updating of the var and accum tensors will be protected
  // by a lock; otherwise the behavior is undefined, but may exhibit less
  // contention.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

    public native @Cast("bool") boolean use_locking_(); public native Attrs use_locking_(boolean use_locking_);
  }
  public SparseApplyFtrl(@Const @ByRef Scope scope, @ByVal Input var,
                  @ByVal Input accum, @ByVal Input linear, @ByVal Input grad, @ByVal Input indices, @ByVal Input lr, @ByVal Input l1, @ByVal Input l2, @ByVal Input lr_power) { super((Pointer)null); allocate(scope, var, accum, linear, grad, indices, lr, l1, l2, lr_power); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input var,
                  @ByVal Input accum, @ByVal Input linear, @ByVal Input grad, @ByVal Input indices, @ByVal Input lr, @ByVal Input l1, @ByVal Input l2, @ByVal Input lr_power);
  public SparseApplyFtrl(@Const @ByRef Scope scope, @ByVal Input var,
                  @ByVal Input accum, @ByVal Input linear, @ByVal Input grad, @ByVal Input indices, @ByVal Input lr, @ByVal Input l1, @ByVal Input l2, @ByVal Input lr_power, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, var, accum, linear, grad, indices, lr, l1, l2, lr_power, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input var,
                  @ByVal Input accum, @ByVal Input linear, @ByVal Input grad, @ByVal Input indices, @ByVal Input lr, @ByVal Input l1, @ByVal Input l2, @ByVal Input lr_power, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

  public native @ByRef Output out(); public native SparseApplyFtrl out(Output out);
}

// Update relevant entries in '*var' and '*accum' according to the momentum scheme.
//
// Set use_nesterov = True if you want to use Nesterov momentum.
//
// That is for rows we have grad for, we update var and accum as follows:
//
// accum = accum * momentum + grad
// var -= lr * accum
//
// Arguments:
// * scope: A Scope object
// * var: Should be from a Variable().
// * accum: Should be from a Variable().
// * lr: Learning rate. Must be a scalar.
// * grad: The gradient.
// * indices: A vector of indices into the first dimension of var and accum.
// * momentum: Momentum. Must be a scalar.
@Namespace("tensorflow::ops") @NoOffset public static class SparseApplyMomentum extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SparseApplyMomentum(Pointer p) { super(p); }

  // Optional attribute setters for SparseApplyMomentum :
  //
  // UseLocking(bool): Defaults to false
  //     If `True`, updating of the var and accum tensors will be protected
  // by a lock; otherwise the behavior is undefined, but may exhibit less
  // contention.
  // UseNesterov(bool): Defaults to false
  //     If `True`, the tensor passed to compute grad will be
  // var - lr * momentum * accum, so in the end, the var you get is actually
  // var - lr * momentum * accum.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

    public native @ByVal Attrs UseNesterov(@Cast("bool") boolean x);

    public native @Cast("bool") boolean use_locking_(); public native Attrs use_locking_(boolean use_locking_);
    public native @Cast("bool") boolean use_nesterov_(); public native Attrs use_nesterov_(boolean use_nesterov_);
  }
  public SparseApplyMomentum(@Const @ByRef Scope scope, @ByVal Input var, @ByVal Input accum,
                      @ByVal Input lr, @ByVal Input grad,
                      @ByVal Input indices, @ByVal Input momentum) { super((Pointer)null); allocate(scope, var, accum, lr, grad, indices, momentum); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input var, @ByVal Input accum,
                      @ByVal Input lr, @ByVal Input grad,
                      @ByVal Input indices, @ByVal Input momentum);
  public SparseApplyMomentum(@Const @ByRef Scope scope, @ByVal Input var, @ByVal Input accum,
                      @ByVal Input lr, @ByVal Input grad,
                      @ByVal Input indices, @ByVal Input momentum, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, var, accum, lr, grad, indices, momentum, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input var, @ByVal Input accum,
                      @ByVal Input lr, @ByVal Input grad,
                      @ByVal Input indices, @ByVal Input momentum, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs UseLocking(@Cast("bool") boolean x);
  public static native @ByVal Attrs UseNesterov(@Cast("bool") boolean x);

  public native @ByRef Output out(); public native SparseApplyMomentum out(Output out);
}

// Sparse update entries in '*var' and '*accum' according to FOBOS algorithm.
//
// That is for rows we have grad for, we update var and accum as follows:
// accum += grad * grad
// prox_v = var
// prox_v -= lr * grad * (1 / sqrt(accum))
// var = sign(prox_v)/(1+lr*l2) * max{|prox_v|-lr*l1,0}
//
// Arguments:
// * scope: A Scope object
// * var: Should be from a Variable().
// * accum: Should be from a Variable().
// * lr: Learning rate. Must be a scalar.
// * l1: L1 regularization. Must be a scalar.
// * l2: L2 regularization. Must be a scalar.
// * grad: The gradient.
// * indices: A vector of indices into the first dimension of var and accum.
@Namespace("tensorflow::ops") @NoOffset public static class SparseApplyProximalAdagrad extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SparseApplyProximalAdagrad(Pointer p) { super(p); }

  // Optional attribute setters for SparseApplyProximalAdagrad :
  //
  // UseLocking(bool): Defaults to false
  //     If True, updating of the var and accum tensors will be protected by
  // a lock; otherwise the behavior is undefined, but may exhibit less contention.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

    public native @Cast("bool") boolean use_locking_(); public native Attrs use_locking_(boolean use_locking_);
  }
  public SparseApplyProximalAdagrad(@Const @ByRef Scope scope,
                             @ByVal Input var,
                             @ByVal Input accum,
                             @ByVal Input lr,
                             @ByVal Input l1,
                             @ByVal Input l2,
                             @ByVal Input grad,
                             @ByVal Input indices) { super((Pointer)null); allocate(scope, var, accum, lr, l1, l2, grad, indices); }
  private native void allocate(@Const @ByRef Scope scope,
                             @ByVal Input var,
                             @ByVal Input accum,
                             @ByVal Input lr,
                             @ByVal Input l1,
                             @ByVal Input l2,
                             @ByVal Input grad,
                             @ByVal Input indices);
  public SparseApplyProximalAdagrad(@Const @ByRef Scope scope,
                             @ByVal Input var,
                             @ByVal Input accum,
                             @ByVal Input lr,
                             @ByVal Input l1,
                             @ByVal Input l2,
                             @ByVal Input grad,
                             @ByVal Input indices, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, var, accum, lr, l1, l2, grad, indices, attrs); }
  private native void allocate(@Const @ByRef Scope scope,
                             @ByVal Input var,
                             @ByVal Input accum,
                             @ByVal Input lr,
                             @ByVal Input l1,
                             @ByVal Input l2,
                             @ByVal Input grad,
                             @ByVal Input indices, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

  public native @ByRef Output out(); public native SparseApplyProximalAdagrad out(Output out);
}

// Sparse update '*var' as FOBOS algorithm with fixed learning rate.
//
// That is for rows we have grad for, we update var as follows:
// prox_v = var - alpha * grad
// var = sign(prox_v)/(1+alpha*l2) * max{|prox_v|-alpha*l1,0}
//
// Arguments:
// * scope: A Scope object
// * var: Should be from a Variable().
// * alpha: Scaling factor. Must be a scalar.
// * l1: L1 regularization. Must be a scalar.
// * l2: L2 regularization. Must be a scalar.
// * grad: The gradient.
// * indices: A vector of indices into the first dimension of var and accum.
@Namespace("tensorflow::ops") @NoOffset public static class SparseApplyProximalGradientDescent extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SparseApplyProximalGradientDescent(Pointer p) { super(p); }

  // Optional attribute setters for SparseApplyProximalGradientDescent :
  //
  // UseLocking(bool): Defaults to false
  //     If True, the subtraction will be protected by a lock;
  // otherwise the behavior is undefined, but may exhibit less contention.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

    public native @Cast("bool") boolean use_locking_(); public native Attrs use_locking_(boolean use_locking_);
  }
  public SparseApplyProximalGradientDescent(@Const @ByRef Scope scope,
                                     @ByVal Input var,
                                     @ByVal Input alpha,
                                     @ByVal Input l1,
                                     @ByVal Input l2,
                                     @ByVal Input grad,
                                     @ByVal Input indices) { super((Pointer)null); allocate(scope, var, alpha, l1, l2, grad, indices); }
  private native void allocate(@Const @ByRef Scope scope,
                                     @ByVal Input var,
                                     @ByVal Input alpha,
                                     @ByVal Input l1,
                                     @ByVal Input l2,
                                     @ByVal Input grad,
                                     @ByVal Input indices);
  public SparseApplyProximalGradientDescent(@Const @ByRef Scope scope,
                                     @ByVal Input var,
                                     @ByVal Input alpha,
                                     @ByVal Input l1,
                                     @ByVal Input l2,
                                     @ByVal Input grad,
                                     @ByVal Input indices, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, var, alpha, l1, l2, grad, indices, attrs); }
  private native void allocate(@Const @ByRef Scope scope,
                                     @ByVal Input var,
                                     @ByVal Input alpha,
                                     @ByVal Input l1,
                                     @ByVal Input l2,
                                     @ByVal Input grad,
                                     @ByVal Input indices, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

  public native @ByRef Output out(); public native SparseApplyProximalGradientDescent out(Output out);
}

// Update '*var' according to the RMSProp algorithm.
//
// Note that in dense implement of this algorithm, ms and mom will
// update even if the grad is zero, but in this sparse implement, ms
// and mom will not update in iterations the grad is zero.
//
// mean_square = decay * mean_square + (1-decay) * gradient ** 2
// Delta = learning_rate * gradient / sqrt(mean_square + epsilon)
//
// ms <- rho * ms_{t-1} + (1-rho) * grad * grad
// mom <- momentum * mom_{t-1} + lr * grad / sqrt(ms + epsilon)
// var <- var - mom
//
// Arguments:
// * scope: A Scope object
// * var: Should be from a Variable().
// * ms: Should be from a Variable().
// * mom: Should be from a Variable().
// * lr: Scaling factor. Must be a scalar.
// * rho: Decay rate. Must be a scalar.
// * epsilon: Ridge term. Must be a scalar.
// * grad: The gradient.
// * indices: A vector of indices into the first dimension of var, ms and mom.
@Namespace("tensorflow::ops") @NoOffset public static class SparseApplyRMSProp extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SparseApplyRMSProp(Pointer p) { super(p); }

  // Optional attribute setters for SparseApplyRMSProp :
  //
  // UseLocking(bool): Defaults to false
  //     If `True`, updating of the var, m, and v tensors will be protected
  // by a lock; otherwise the behavior is undefined, but may exhibit less
  // contention.
  public static class Attrs extends Pointer {
      static { Loader.load(); }
      /** Default native constructor. */
      public Attrs() { super((Pointer)null); allocate(); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public Attrs(long size) { super((Pointer)null); allocateArray(size); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public Attrs(Pointer p) { super(p); }
      private native void allocate();
      private native void allocateArray(long size);
      @Override public Attrs position(long position) {
          return (Attrs)super.position(position);
      }
  
    public native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

    public native @Cast("bool") boolean use_locking_(); public native Attrs use_locking_(boolean use_locking_);
  }
  public SparseApplyRMSProp(@Const @ByRef Scope scope, @ByVal Input var, @ByVal Input ms, @ByVal Input mom, @ByVal Input lr, @ByVal Input rho, @ByVal Input momentum,
                     @ByVal Input epsilon, @ByVal Input grad, @ByVal Input indices) { super((Pointer)null); allocate(scope, var, ms, mom, lr, rho, momentum, epsilon, grad, indices); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input var, @ByVal Input ms, @ByVal Input mom, @ByVal Input lr, @ByVal Input rho, @ByVal Input momentum,
                     @ByVal Input epsilon, @ByVal Input grad, @ByVal Input indices);
  public SparseApplyRMSProp(@Const @ByRef Scope scope, @ByVal Input var, @ByVal Input ms, @ByVal Input mom, @ByVal Input lr, @ByVal Input rho, @ByVal Input momentum,
                     @ByVal Input epsilon, @ByVal Input grad, @ByVal Input indices, @Const @ByRef Attrs attrs) { super((Pointer)null); allocate(scope, var, ms, mom, lr, rho, momentum, epsilon, grad, indices, attrs); }
  private native void allocate(@Const @ByRef Scope scope, @ByVal Input var, @ByVal Input ms, @ByVal Input mom, @ByVal Input lr, @ByVal Input rho, @ByVal Input momentum,
                     @ByVal Input epsilon, @ByVal Input grad, @ByVal Input indices, @Const @ByRef Attrs attrs);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public static native @ByVal Attrs UseLocking(@Cast("bool") boolean x);

  public native @ByRef Output out(); public native SparseApplyRMSProp out(Output out);
}

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_TRAINING_OPS_H_


// Parsed from tensorflow/cc/ops/user_ops.h

// This file is MACHINE GENERATED! Do not edit.

// #ifndef TENSORFLOW_CC_OPS_USER_OPS_H_
// #define TENSORFLOW_CC_OPS_USER_OPS_H_

// This file is MACHINE GENERATED! Do not edit.

// #include "tensorflow/cc/framework/ops.h"
// #include "tensorflow/cc/framework/scope.h"
// #include "tensorflow/core/framework/tensor.h"
// #include "tensorflow/core/framework/tensor_shape.h"
// #include "tensorflow/core/framework/types.h"
// #include "tensorflow/core/lib/gtl/array_slice.h"

// Output a fact about factorials.
//
// Arguments:
// * scope: A Scope object
@Namespace("tensorflow::ops") @NoOffset public static class Fact extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Fact(Pointer p) { super(p); }

  public Fact(@Const @ByRef Scope scope) { super((Pointer)null); allocate(scope); }
  private native void allocate(@Const @ByRef Scope scope);
  public native @ByVal @Name("operator tensorflow::ops::Output") Output asOutput();
  public native @ByVal @Name("operator tensorflow::ops::Input") Input asInput();
  public native Node node();

  public native @ByRef Output fact(); public native Fact fact(Output fact);
}

  // namespace ops
  // namespace tensorflow

// #endif  // TENSORFLOW_CC_OPS_USER_OPS_H_


}
