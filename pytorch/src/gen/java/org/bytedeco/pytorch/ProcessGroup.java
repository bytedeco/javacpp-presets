// Targeted by JavaCPP version 1.5.13-SNAPSHOT: DO NOT EDIT THIS FILE

package org.bytedeco.pytorch;

import org.bytedeco.pytorch.Allocator;
import org.bytedeco.pytorch.Function;
import org.bytedeco.pytorch.Module;
import org.bytedeco.javacpp.annotation.Cast;
import java.nio.*;
import org.bytedeco.javacpp.*;
import org.bytedeco.javacpp.annotation.*;

import static org.bytedeco.javacpp.presets.javacpp.*;
import static org.bytedeco.openblas.global.openblas_nolapack.*;
import static org.bytedeco.openblas.global.openblas.*;
import org.bytedeco.javacpp.chrono.*;
import static org.bytedeco.javacpp.global.chrono.*;

import static org.bytedeco.pytorch.global.torch.*;


// ProcessGroup is a base class that captures collective and point to
// point communication in a fixed set of processes.
//
// The functions specified in the class below describe the API alone;
// implementations are provided in subclasses.
//
// Every function that performs I/O is executed asynchronously by a
// thread pool owned by the ProcessGroup (by default). They return an
// object that can be used to wait for completion or error.
//
// The ProcessGroup can instantiate subgroups with fewer or an equal
// number of members. Implementations must take care that multiple
// process groups can be used in parallel and synchronize accordingly.
//
// The ProcessGroup assumes a fixed set of processes. If the set
// changes, existing instances must be destructed and instantiation
// and initialization must start from scratch. For members of the
// process group to find each other (referred to as rendezvous from
// hereon)
//
@Namespace("c10d") @NoOffset @Properties(inherit = org.bytedeco.pytorch.presets.torch.class)
public class ProcessGroup extends CustomClassHolder {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ProcessGroup(Pointer p) { super(p); }

  @NoOffset public static class MergeOptions extends CustomClassHolder {
      static { Loader.load(); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public MergeOptions(Pointer p) { super(p); }
      /** Native array allocator. Access with {@link Pointer#position(long)}. */
      public MergeOptions(long size) { super((Pointer)null); allocateArray(size); }
      private native void allocateArray(long size);
      @Override public MergeOptions position(long position) {
          return (MergeOptions)super.position(position);
      }
      @Override public MergeOptions getPointer(long i) {
          return new MergeOptions((Pointer)this).offsetAddress(i);
      }
  
    public MergeOptions(
            @Const @ByVal(nullValue = "std::chrono::milliseconds(kProcessGroupDefaultTimeout)") Milliseconds timeout,
            @Const @ByVal(nullValue = "std::optional<std::string>(std::nullopt)") StringOptional group_name,
            @Const @ByVal(nullValue = "std::optional<std::string>(std::nullopt)") StringOptional group_desc) { super((Pointer)null); allocate(timeout, group_name, group_desc); }
    private native void allocate(
            @Const @ByVal(nullValue = "std::chrono::milliseconds(kProcessGroupDefaultTimeout)") Milliseconds timeout,
            @Const @ByVal(nullValue = "std::optional<std::string>(std::nullopt)") StringOptional group_name,
            @Const @ByVal(nullValue = "std::optional<std::string>(std::nullopt)") StringOptional group_desc);
    public MergeOptions() { super((Pointer)null); allocate(); }
    private native void allocate();
    
    

    public native @ByRef Milliseconds timeout(); public native MergeOptions timeout(Milliseconds setter);
    public native @ByRef StringOptional group_name(); public native MergeOptions group_name(StringOptional setter);
    public native @ByRef StringOptional group_desc(); public native MergeOptions group_desc(StringOptional setter);
  }

  public enum BackendType {
    UNDEFINED((byte)(0)),
    GLOO((byte)(1)),
    NCCL((byte)(2)),
    UCC((byte)(3)),
    MPI((byte)(4)),
    XCCL((byte)(5)),
    CUSTOM((byte)(6));

      public final byte value;
      private BackendType(byte v) { this.value = v; }
      private BackendType(BackendType e) { this.value = e.value; }
      public BackendType intern() { for (BackendType e : values()) if (e.value == value) return e; return this; }
      @Override public String toString() { return intern().name(); }
  }

  public static native @StdString BytePointer backendTypeToString(BackendType type);
  public static native @StdString String backendTypeToString(@Cast("c10d::ProcessGroup::BackendType") byte type);

  public static native BackendType strToBackendType(@StdString BytePointer backend);
  public static native @Cast("c10d::ProcessGroup::BackendType") byte strToBackendType(@StdString String backend);

  // Not used, set for backwards compatibility and only used for TypeDef in
  // Ops.cpp
  public ProcessGroup(int rank, int size) { super((Pointer)null); allocate(rank, size); }
  @IntrusivePtr @Name("c10::make_intrusive<c10d::ProcessGroup>") private native void allocate(int rank, int size);

  public ProcessGroup(
        @IntrusivePtr("c10d::Store") @Cast({"", "c10::intrusive_ptr<c10d::Store>&"}) Store store,
        int rank,
        int size) { super((Pointer)null); allocate(store, rank, size); }
  @IntrusivePtr @Name("c10::make_intrusive<c10d::ProcessGroup>") private native void allocate(
        @IntrusivePtr("c10d::Store") @Cast({"", "c10::intrusive_ptr<c10d::Store>&"}) Store store,
        int rank,
        int size);

  public native int getRank();

  public native int getSize();

  // Returns an unique opaque ID of this process group object.
  public native @Cast("int64_t") long getID();

  // Returns an unique opaque ID of a backend for the specific backend type
  // that can correlate with this process group's collectives.
  public native @Cast("int64_t") long getBackendID(BackendType backend_type);
  public native @Cast("int64_t") long getBackendID(@Cast("c10d::ProcessGroup::BackendType") byte backend_type);

  public native @StdString BytePointer getBackendName();

  public native BackendType getBackendType();

  public native @Cast("bool") boolean backendSupportsSequenceNumbers(BackendType backendType);
  public native @Cast("bool") boolean backendSupportsSequenceNumbers(@Cast("c10d::ProcessGroup::BackendType") byte backendType);

  public native void setTimeout(@ByVal Milliseconds timeout);

  public native @Cast("int64_t") long incrementSplitCount();

  public native void startCoalescing(DeviceType deviceType);
  public native void startCoalescing(@Cast("c10::DeviceType") byte deviceType);

  public native @IntrusivePtr("c10d::Work") @Cast({"", "c10::intrusive_ptr<c10d::Work>&"}) Work endCoalescing(DeviceType deviceType);
  public native @IntrusivePtr("c10d::Work") @Cast({"", "c10::intrusive_ptr<c10d::Work>&"}) Work endCoalescing(@Cast("c10::DeviceType") byte deviceType);

  public native @IntrusivePtr("c10d::Work") @Cast({"", "c10::intrusive_ptr<c10d::Work>&"}) Work broadcast(
        @ByRef TensorVector tensors,
        @Const @ByRef(nullValue = "c10d::BroadcastOptions()") BroadcastOptions opts);
  public native @IntrusivePtr("c10d::Work") @Cast({"", "c10::intrusive_ptr<c10d::Work>&"}) Work broadcast(
        @ByRef TensorVector tensors);

  public native @IntrusivePtr("c10d::Work") @Cast({"", "c10::intrusive_ptr<c10d::Work>&"}) Work allreduce(
        @ByRef TensorVector tensors,
        @Const @ByRef(nullValue = "c10d::AllreduceOptions()") AllreduceOptions opts);
  public native @IntrusivePtr("c10d::Work") @Cast({"", "c10::intrusive_ptr<c10d::Work>&"}) Work allreduce(
        @ByRef TensorVector tensors);

  public native @IntrusivePtr("c10d::Work") @Cast({"", "c10::intrusive_ptr<c10d::Work>&"}) Work allreduce_coalesced(
        @ByRef TensorVector tensors,
        @Const @ByRef(nullValue = "c10d::AllreduceCoalescedOptions()") AllreduceCoalescedOptions opts);
  public native @IntrusivePtr("c10d::Work") @Cast({"", "c10::intrusive_ptr<c10d::Work>&"}) Work allreduce_coalesced(
        @ByRef TensorVector tensors);

  public native @IntrusivePtr("c10d::Work") @Cast({"", "c10::intrusive_ptr<c10d::Work>&"}) Work reduce(
        @ByRef TensorVector tensors,
        @Const @ByRef(nullValue = "c10d::ReduceOptions()") ReduceOptions opts);
  public native @IntrusivePtr("c10d::Work") @Cast({"", "c10::intrusive_ptr<c10d::Work>&"}) Work reduce(
        @ByRef TensorVector tensors);

  public native @IntrusivePtr("c10d::Work") @Cast({"", "c10::intrusive_ptr<c10d::Work>&"}) Work allgather(
        @StdVector TensorVector outputTensors,
        @ByRef TensorVector inputTensors,
        @Const @ByRef(nullValue = "c10d::AllgatherOptions()") AllgatherOptions opts);
  public native @IntrusivePtr("c10d::Work") @Cast({"", "c10::intrusive_ptr<c10d::Work>&"}) Work allgather(
        @StdVector TensorVector outputTensors,
        @ByRef TensorVector inputTensors);

  // Gathers a single tensor inputBuffer into a single buffer outputBuffer that
  // is interpreted as a contiguous collection of size inputBuffer * WORLD_SIZE.
  // For implementers of ProcessGroup API and advanced users only.
  // Note: this function will be deprecated in near future.
  public native @IntrusivePtr("c10d::Work") @Cast({"", "c10::intrusive_ptr<c10d::Work>&"}) Work _allgather_base(
        @ByRef Tensor outputBuffer,
        @ByRef Tensor inputBuffer,
        @Const @ByRef(nullValue = "c10d::AllgatherOptions()") AllgatherOptions opts);
  public native @IntrusivePtr("c10d::Work") @Cast({"", "c10::intrusive_ptr<c10d::Work>&"}) Work _allgather_base(
        @ByRef Tensor outputBuffer,
        @ByRef Tensor inputBuffer);

  // This function is deprecated and will be moved out of ProcessGroup to comms:
  // * do not add dependencies on this function,
  // * do not implement it in your ProcessGroup, implement _allgather_base
  //   instead.
  public native @IntrusivePtr("c10d::Work") @Cast({"", "c10::intrusive_ptr<c10d::Work>&"}) Work allgather_coalesced(
        @StdVector TensorVector outputTensorLists,
        @ByRef TensorVector inputTensors,
        @Const @ByRef(nullValue = "c10d::AllgatherOptions()") AllgatherOptions opts);
  public native @IntrusivePtr("c10d::Work") @Cast({"", "c10::intrusive_ptr<c10d::Work>&"}) Work allgather_coalesced(
        @StdVector TensorVector outputTensorLists,
        @ByRef TensorVector inputTensors);

  // This function is a coalesced version of `allgather_into_tensor` (currently
  // still named as `_allgather_base`). Each tensor in the vector corresponds to
  // an input/output of one `allgather_into_tensor` operation.
  public native @IntrusivePtr("c10d::Work") @Cast({"", "c10::intrusive_ptr<c10d::Work>&"}) Work allgather_into_tensor_coalesced(
        @ByRef TensorVector outputTensors,
        @ByRef TensorVector inputTensors,
        @Const @ByRef(nullValue = "c10d::AllgatherOptions()") AllgatherOptions opts);
  public native @IntrusivePtr("c10d::Work") @Cast({"", "c10::intrusive_ptr<c10d::Work>&"}) Work allgather_into_tensor_coalesced(
        @ByRef TensorVector outputTensors,
        @ByRef TensorVector inputTensors);

  public native @IntrusivePtr("c10d::Work") @Cast({"", "c10::intrusive_ptr<c10d::Work>&"}) Work gather(
        @StdVector TensorVector outputTensors,
        @ByRef TensorVector inputTensors,
        @Const @ByRef(nullValue = "c10d::GatherOptions()") GatherOptions opts);
  public native @IntrusivePtr("c10d::Work") @Cast({"", "c10::intrusive_ptr<c10d::Work>&"}) Work gather(
        @StdVector TensorVector outputTensors,
        @ByRef TensorVector inputTensors);

  public native @IntrusivePtr("c10d::Work") @Cast({"", "c10::intrusive_ptr<c10d::Work>&"}) Work scatter(
        @ByRef TensorVector outputTensors,
        @StdVector TensorVector inputTensors,
        @Const @ByRef(nullValue = "c10d::ScatterOptions()") ScatterOptions opts);
  public native @IntrusivePtr("c10d::Work") @Cast({"", "c10::intrusive_ptr<c10d::Work>&"}) Work scatter(
        @ByRef TensorVector outputTensors,
        @StdVector TensorVector inputTensors);

  public native @IntrusivePtr("c10d::Work") @Cast({"", "c10::intrusive_ptr<c10d::Work>&"}) Work reduce_scatter(
        @ByRef TensorVector outputTensors,
        @StdVector TensorVector inputTensors,
        @Const @ByRef(nullValue = "c10d::ReduceScatterOptions()") ReduceScatterOptions opts);
  public native @IntrusivePtr("c10d::Work") @Cast({"", "c10::intrusive_ptr<c10d::Work>&"}) Work reduce_scatter(
        @ByRef TensorVector outputTensors,
        @StdVector TensorVector inputTensors);

  public native @IntrusivePtr("c10d::Work") @Cast({"", "c10::intrusive_ptr<c10d::Work>&"}) Work _reduce_scatter_base(
        @ByRef Tensor outputBuffer,
        @ByRef Tensor inputBuffer,
        @Const @ByRef(nullValue = "c10d::ReduceScatterOptions()") ReduceScatterOptions opts);
  public native @IntrusivePtr("c10d::Work") @Cast({"", "c10::intrusive_ptr<c10d::Work>&"}) Work _reduce_scatter_base(
        @ByRef Tensor outputBuffer,
        @ByRef Tensor inputBuffer);

  // This function is a coalesced version of `reduce_scatter_tensor` (currently
  // still named as `_reduce_scatter_base`). Each tensor in the vector
  // corresponds to an input/output of one `reduce_scatter_tensor` operation.
  public native @IntrusivePtr("c10d::Work") @Cast({"", "c10::intrusive_ptr<c10d::Work>&"}) Work reduce_scatter_tensor_coalesced(
        @ByRef TensorVector outputTensors,
        @ByRef TensorVector inputTensors,
        @Const @ByRef(nullValue = "c10d::ReduceScatterOptions()") ReduceScatterOptions opts);
  public native @IntrusivePtr("c10d::Work") @Cast({"", "c10::intrusive_ptr<c10d::Work>&"}) Work reduce_scatter_tensor_coalesced(
        @ByRef TensorVector outputTensors,
        @ByRef TensorVector inputTensors);

  public native @IntrusivePtr("c10d::Work") @Cast({"", "c10::intrusive_ptr<c10d::Work>&"}) Work alltoall_base(
        @ByRef Tensor outputBuffer,
        @ByRef Tensor inputBuffer,
        @Cast("std::vector<int64_t>*") @ByRef LongVector outputSplitSizes,
        @Cast("std::vector<int64_t>*") @ByRef LongVector inputSplitSizes,
        @Const @ByRef(nullValue = "c10d::AllToAllOptions()") AllToAllOptions opts);
  public native @IntrusivePtr("c10d::Work") @Cast({"", "c10::intrusive_ptr<c10d::Work>&"}) Work alltoall_base(
        @ByRef Tensor outputBuffer,
        @ByRef Tensor inputBuffer,
        @Cast("std::vector<int64_t>*") @ByRef LongVector outputSplitSizes,
        @Cast("std::vector<int64_t>*") @ByRef LongVector inputSplitSizes);

  public native @IntrusivePtr("c10d::Work") @Cast({"", "c10::intrusive_ptr<c10d::Work>&"}) Work alltoall(
        @ByRef TensorVector outputTensors,
        @ByRef TensorVector inputTensors,
        @Const @ByRef(nullValue = "c10d::AllToAllOptions()") AllToAllOptions opts);
  public native @IntrusivePtr("c10d::Work") @Cast({"", "c10::intrusive_ptr<c10d::Work>&"}) Work alltoall(
        @ByRef TensorVector outputTensors,
        @ByRef TensorVector inputTensors);

  public native void monitoredBarrier(
        @Const @ByRef BarrierOptions opts,
        @Cast("bool") boolean wait_all_ranks/*=false*/);
  public native void monitoredBarrier(
        @Const @ByRef BarrierOptions opts);

  // Agrees on an initial sequence number for the whole group by having rank 0
  // create it and broadcast it to other ranks using the store. Only implemented
  // for GLOO and NCCL backends currently.
  public native void setSequenceNumberForGroup();

  // Retrieves the current sequence number for the whole group, which should be
  // in sync. If the returned number is not consistent across the group, it
  // may indicate that there is some sort of collective desynchronization.
  public native @Cast("uint64_t") long getSequenceNumberForGroup();

  public native @IntrusivePtr("c10d::Work") @Cast({"", "c10::intrusive_ptr<c10d::Work>&"}) Work send(
        @ByRef TensorVector tensors,
        int dstRank,
        int tag);

  public native @IntrusivePtr("c10d::Work") @Cast({"", "c10::intrusive_ptr<c10d::Work>&"}) Work recv(
        @ByRef TensorVector tensors,
        int srcRank,
        int tag);

  public native @IntrusivePtr("c10d::Work") @Cast({"", "c10::intrusive_ptr<c10d::Work>&"}) Work recvAnysource(
        @ByRef TensorVector tensors,
        int tag);

  public native @IntrusivePtr("c10d::Work") @Cast({"", "c10::intrusive_ptr<c10d::Work>&"}) Work barrier(
        @Const @ByRef(nullValue = "c10d::BarrierOptions()") BarrierOptions opts);
  public native @IntrusivePtr("c10d::Work") @Cast({"", "c10::intrusive_ptr<c10d::Work>&"}) Work barrier();

  public native @Cast("bool") boolean hasBackends();

  public native void setBackend(
        DeviceType deviceType,
        BackendType backendType,
        @Const @ByRef BackendOptional backend);
  public native void setBackend(
        @Cast("c10::DeviceType") byte deviceType,
        @Cast("c10d::ProcessGroup::BackendType") byte backendType,
        @Const @ByRef BackendOptional backend);

  public native @IntrusivePtr("c10d::Backend") @Cast({"", "c10::intrusive_ptr<c10d::Backend>&"}) Backend getDefaultBackend();

  public native void setDefaultBackend(BackendType backendType);
  public native void setDefaultBackend(@Cast("c10d::ProcessGroup::BackendType") byte backendType);

  public native void setDefaultBackend(@StdString BytePointer backend);
  public native void setDefaultBackend(@StdString String backend);

  public native @IntrusivePtr("c10d::Backend") @Cast({"", "c10::intrusive_ptr<c10d::Backend>&"}) Backend getBackend(DeviceType deviceType);
  public native @IntrusivePtr("c10d::Backend") @Cast({"", "c10::intrusive_ptr<c10d::Backend>&"}) Backend getBackend(@Cast("c10::DeviceType") byte deviceType);

  public native @IntrusivePtr("c10d::Backend") @Cast({"", "c10::intrusive_ptr<c10d::Backend>&"}) Backend getBackend(BackendType backendType);

  // Return device types supported by this ProcessGroup.
  // Note: the return type is `Device` rather than `DeviceType` for the purpose
  // of easy comparison at Python level. The `Device` will have default index
  // (-1).
  public native @StdVector Device getDeviceTypes();

  public native void registerOnCompletionHook(
        @ByRef(true) WorkInfoConsumer hook);

  public native void waitForPendingWorks();

  public native void shutdown();

  public native void abort();

  public native @Cast("bool") boolean hasHooks();

  public native @StdString BytePointer getGroupName();
  public native void setGroupName(@StdString BytePointer name);
  public native void setGroupName(@StdString String name);
  public native @StdString BytePointer getGroupDesc();
  public native void setGroupDesc(@StdString BytePointer name);
  public native void setGroupDesc(@StdString String name);
  public native void enableCollectivesTiming();

  public native void release_resources();

  // ProcessGroups optionally can be "bound" to a specific device.
  // Currently this is only for nccl and allows for some opt-in
  // optimizations such as automatic use of ncclCommSplit.  The device
  // is specified in `init_process_group` and eventually makes it
  // here and then down into the actual backend instances.
  public native @ByVal DeviceOptional getBoundDeviceId();

  public native @IntrusivePtr("c10d::Store") @Cast({"", "c10::intrusive_ptr<c10d::Store>&"}) Store getStore();

  public native void setBoundDeviceId(@ByVal DeviceOptional device);

  // This creates a new subgroup using the specified ranks.
  // The current rank must be included in the list of new_ranks.
  public native @IntrusivePtr("c10d::ProcessGroup") @Cast({"", "c10::intrusive_ptr<c10d::ProcessGroup>&"}) ProcessGroup splitGroup(
        @StdVector IntPointer ranks,
        @Optional Milliseconds timeout,
        @Const @ByRef BackendOptionsOptional opts,
        @Const @ByRef StringOptional name,
        @Const @ByRef StringOptional groupDesc);
  public native @IntrusivePtr("c10d::ProcessGroup") @Cast({"", "c10::intrusive_ptr<c10d::ProcessGroup>&"}) ProcessGroup splitGroup(
        @StdVector IntBuffer ranks,
        @Optional Milliseconds timeout,
        @Const @ByRef BackendOptionsOptional opts,
        @Const @ByRef StringOptional name,
        @Const @ByRef StringOptional groupDesc);
  public native @IntrusivePtr("c10d::ProcessGroup") @Cast({"", "c10::intrusive_ptr<c10d::ProcessGroup>&"}) ProcessGroup splitGroup(
        @StdVector int[] ranks,
        @Optional Milliseconds timeout,
        @Const @ByRef BackendOptionsOptional opts,
        @Const @ByRef StringOptional name,
        @Const @ByRef StringOptional groupDesc);

  // This creates a new subgroup using the specified ranks.
  // The current rank must be included in the list of new_ranks.
  public native @IntrusivePtr("c10d::ProcessGroup") @Cast({"", "c10::intrusive_ptr<c10d::ProcessGroup>&"}) ProcessGroup mergeRemoteGroup(
        @IntrusivePtr("c10d::Store") @Cast({"", "c10::intrusive_ptr<c10d::Store>&"}) Store store,
        @Const @ByRef MergeOptions opts,
        int size);
}
