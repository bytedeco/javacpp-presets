// Targeted by JavaCPP version 1.5.11-SNAPSHOT: DO NOT EDIT THIS FILE

package org.bytedeco.pytorch;

import org.bytedeco.pytorch.Allocator;
import org.bytedeco.pytorch.Function;
import org.bytedeco.pytorch.chrono.*;
import org.bytedeco.pytorch.Module;
import org.bytedeco.javacpp.annotation.Cast;
import org.bytedeco.pytorch.helper.*;
import java.nio.*;
import org.bytedeco.javacpp.*;
import org.bytedeco.javacpp.annotation.*;

import static org.bytedeco.javacpp.presets.javacpp.*;
import static org.bytedeco.openblas.global.openblas_nolapack.*;
import static org.bytedeco.openblas.global.openblas.*;

import static org.bytedeco.pytorch.global.torch.*;


@Namespace("c10d") @NoOffset @Properties(inherit = org.bytedeco.pytorch.presets.torch.class)
public class Logger extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Logger(Pointer p) { super(p); }

  public Logger(@SharedPtr Reducer reducer) { super((Pointer)null); allocate(reducer); }
  @SharedPtr @Name("std::make_shared<c10d::Logger>") private native void allocate(@SharedPtr Reducer reducer);
  // Set logging data that can be got during DistributedDataParallel
  // construction time.
  public native void set_construction_data_and_log(
        @StdString BytePointer module_name,
        @StdVector IntPointer device_ids,
        int output_device,
        @Cast("bool") boolean broadcast_buffers,
        @Cast("bool") boolean has_sync_bn,
        @Cast("bool") boolean static_graph);
  public native void set_construction_data_and_log(
        @StdString String module_name,
        @StdVector IntBuffer device_ids,
        int output_device,
        @Cast("bool") boolean broadcast_buffers,
        @Cast("bool") boolean has_sync_bn,
        @Cast("bool") boolean static_graph);
  public native void set_construction_data_and_log(
        @StdString BytePointer module_name,
        @StdVector int[] device_ids,
        int output_device,
        @Cast("bool") boolean broadcast_buffers,
        @Cast("bool") boolean has_sync_bn,
        @Cast("bool") boolean static_graph);
  public native void set_construction_data_and_log(
        @StdString String module_name,
        @StdVector IntPointer device_ids,
        int output_device,
        @Cast("bool") boolean broadcast_buffers,
        @Cast("bool") boolean has_sync_bn,
        @Cast("bool") boolean static_graph);
  public native void set_construction_data_and_log(
        @StdString BytePointer module_name,
        @StdVector IntBuffer device_ids,
        int output_device,
        @Cast("bool") boolean broadcast_buffers,
        @Cast("bool") boolean has_sync_bn,
        @Cast("bool") boolean static_graph);
  public native void set_construction_data_and_log(
        @StdString String module_name,
        @StdVector int[] device_ids,
        int output_device,
        @Cast("bool") boolean broadcast_buffers,
        @Cast("bool") boolean has_sync_bn,
        @Cast("bool") boolean static_graph);

  public native void set_static_graph();

  // An interface for users to get DDPLoggingData and log them
  // in the applications. Explanation of logging fields are in
  // "struct DDPLoggingData" of "torch/c10/util/Logging.h".
  public native @ByVal DDPLoggingData get_ddp_logging_data();

  // Stream insertion operator for logging data to stream under
  // TORCH_DISTRIBUTED_DEBUG.
  

  // Set environment variables.
  public native void set_env_variables();
  // Set parameters stats.
  public native void set_parameter_stats();
  // Get size of each bucket (Bytes).
  public native @ByVal @Cast("std::vector<int64_t>*") LongVector get_bucket_sizes();
  // Get variable indices for each bucket.
  public native @ByVal SizeTVectorVector get_per_bucket_variable_indices();
  // Set comm. hook, if used
  public native void set_comm_hook(@StdString BytePointer hook);
  public native void set_comm_hook(@StdString String hook);
  // Set running with uneven input detection (model.join() context manager)
  public native void set_uneven_input_join();

  // Reset performance stats at current iteration
  public native void reset_performance_stats();

  // Calculate avg stats using cpu timer and gpu timer
  // that has been recorded in reducer.
  public native void calculate_avg_time(
        @Cast("int64_t*") @ByRef LongPointer avg_time,
        @Cast("int64_t*") @ByRef LongPointer time_duration,
        @ByRef Timer timer,
        Timer.Event start_event,
        Timer.Event end_event);
  public native void calculate_avg_time(
        @Cast("int64_t*") @ByRef LongBuffer avg_time,
        @Cast("int64_t*") @ByRef LongBuffer time_duration,
        @ByRef Timer timer,
        @Cast("c10d::Timer::Event") int start_event,
        @Cast("c10d::Timer::Event") int end_event);
  public native void calculate_avg_time(
        @Cast("int64_t*") @ByRef long[] avg_time,
        @Cast("int64_t*") @ByRef long[] time_duration,
        @ByRef Timer timer,
        Timer.Event start_event,
        Timer.Event end_event);
  public native void calculate_avg_time(
        @Cast("int64_t*") @ByRef LongPointer avg_time,
        @Cast("int64_t*") @ByRef LongPointer time_duration,
        @ByRef Timer timer,
        @Cast("c10d::Timer::Event") int start_event,
        @Cast("c10d::Timer::Event") int end_event);
  public native void calculate_avg_time(
        @Cast("int64_t*") @ByRef LongBuffer avg_time,
        @Cast("int64_t*") @ByRef LongBuffer time_duration,
        @ByRef Timer timer,
        Timer.Event start_event,
        Timer.Event end_event);
  public native void calculate_avg_time(
        @Cast("int64_t*") @ByRef long[] avg_time,
        @Cast("int64_t*") @ByRef long[] time_duration,
        @ByRef Timer timer,
        @Cast("c10d::Timer::Event") int start_event,
        @Cast("c10d::Timer::Event") int end_event);

  // Set the absolute time of the event that has been recorded in reducer.
  public native void set_event_time(@Cast("int64_t*") @ByRef LongPointer event_time, @ByRef Timer timer, Timer.Event event);
  public native void set_event_time(@Cast("int64_t*") @ByRef LongBuffer event_time, @ByRef Timer timer, @Cast("c10d::Timer::Event") int event);
  public native void set_event_time(@Cast("int64_t*") @ByRef long[] event_time, @ByRef Timer timer, Timer.Event event);
  public native void set_event_time(@Cast("int64_t*") @ByRef LongPointer event_time, @ByRef Timer timer, @Cast("c10d::Timer::Event") int event);
  public native void set_event_time(@Cast("int64_t*") @ByRef LongBuffer event_time, @ByRef Timer timer, Timer.Event event);
  public native void set_event_time(@Cast("int64_t*") @ByRef long[] event_time, @ByRef Timer timer, @Cast("c10d::Timer::Event") int event);
  // Set stats that can be collected only during
  // training loop. It is called at the beginning of forward call
  // to record the run time stats of sampled iterations that previously ran.
  // GPU performance stats are collected only for single process
  // single device program and single device module right now.
  // TODO to support single process multiple devices and multi device modules,
  // events need to be created and recorded on multiple devices.
  public native void set_runtime_stats_and_log();

  // Called when DDP/reducer is failing with an error. The
  // logging data structure will have two fields filled: "has_error" indicating
  // that this iteration encountered an error and other fields are not valid,
  // and "error", a string which contains the error message that DDP failed
  // with.

  // When running without static graph, called when reducer is destroyed to log
  // if graph was actually static and is a candidate for static graph
  // optimization.
  public native void log_if_graph_static(@Cast("bool") boolean is_static);
}
