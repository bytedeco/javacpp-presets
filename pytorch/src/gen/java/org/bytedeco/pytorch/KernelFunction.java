// Targeted by JavaCPP version 1.5.7: DO NOT EDIT THIS FILE

package org.bytedeco.pytorch;

import org.bytedeco.pytorch.Allocator;
import org.bytedeco.pytorch.Function;
import org.bytedeco.pytorch.Module;
import java.nio.*;
import org.bytedeco.javacpp.*;
import org.bytedeco.javacpp.annotation.*;

import static org.bytedeco.javacpp.presets.javacpp.*;
import static org.bytedeco.openblas.global.openblas_nolapack.*;
import static org.bytedeco.openblas.global.openblas.*;

import static org.bytedeco.pytorch.global.torch.*;


/**
 * KernelFunction is similar to std::function but stores a kernel function.
 * You can create a KernelFunction from a boxed or unboxed function/functor/lambda
 * and call it in a boxed or unboxed way. If the way it was created doesn't
 * match the way it was called, it will do boxing or unboxing as necessary.
 */
@Namespace("c10") @NoOffset @Properties(inherit = org.bytedeco.pytorch.presets.torch.class)
public class KernelFunction extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public KernelFunction(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public KernelFunction(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public KernelFunction position(long position) {
        return (KernelFunction)super.position(position);
    }
    @Override public KernelFunction getPointer(long i) {
        return new KernelFunction((Pointer)this).offsetAddress(i);
    }

  // This is how boxed kernels are actually stored
  //
  // Note [Plumbing Keys Through The Dispatcher]
  // Benchmarks have shown that it is expensive for the dispatcher to read from thread-local storage (TLS)
  // upon every dispatch call into order to compute which kernel to dispatch to.
  //
  // To mitigate this, we've updated the calling convention inside the dispatcher to expect every kernel that it stores
  // to have a first argument of type DispatchKeySet.
  //
  // What are the invariants of the DispatchKeySet when it gets passed to a kernel?
  // - All keys to the left of the current dispatch key have been masked out.
  //   (e.g. a Tracing kernel that takes in the DispatchKeySet will expect the highest bit to be DispatchKey::Tracer)
  // - All other keys that dispatcher normally would have computed through TLS + global state + op arguments
  //   are still in the set.
  //
  // Kernels can then opt into using this keyset to save the dispatcher from doing repeated work during redispatches:
  // recalculating the highest-priority dispatch key, which involves reading from TLS. Instead, the kernels that opt in will
  // calculate an updated DispatchKeySet directly from the old one, and pass the updated set directly into the dispatcher
  // upon redispatching.
  //
  // This is an opt-in mechanism: Kernels can automatically opt in by setting the first argument in their signature
  // to be of type DispatchKeySet. See the kernels in VariableTypeEverything.cpp and TraceTypeEverything.cpp for examples.
  //
  // The mechanism for optionally passing that DispatchKeySet into the kernel lives in make_boxed_from_unboxed_functor.h.
  // See Note [Plumbing Keys Through The Dispatcher 2] for details.
  public static class InternalBoxedKernelFunction extends FunctionPointer {
      static { Loader.load(); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public    InternalBoxedKernelFunction(Pointer p) { super(p); }
      protected InternalBoxedKernelFunction() { allocate(); }
      private native void allocate();
      public native void call(OperatorKernel arg0, @Const @ByRef OperatorHandle arg1, @ByVal DispatchKeySet arg2, @Cast("c10::Stack*") IValueVector arg3);
  }
  // This is the public API for how boxed kernels are defined
  public static class BoxedKernelFunction extends FunctionPointer {
      static { Loader.load(); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public    BoxedKernelFunction(Pointer p) { super(p); }
      protected BoxedKernelFunction() { allocate(); }
      private native void allocate();
      public native void call(@Const @ByRef OperatorHandle arg0, @Cast("c10::Stack*") IValueVector arg1);
  }
  public static class BoxedKernelFunction_withDispatchKeys extends FunctionPointer {
      static { Loader.load(); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public    BoxedKernelFunction_withDispatchKeys(Pointer p) { super(p); }
      protected BoxedKernelFunction_withDispatchKeys() { allocate(); }
      private native void allocate();
      public native void call(@Const @ByRef OperatorHandle arg0, @ByVal DispatchKeySet arg1, @Cast("c10::Stack*") IValueVector arg2);
  }

  public KernelFunction() { super((Pointer)null); allocate(); }
  private native void allocate();

  // Fast path for dispatch to allow not touching the boxed kernel in
  // the common case where unboxed is available.
  public native @Cast("bool") boolean isValidUnboxed();
  public native @Cast("bool") boolean isValid();
  public native @Cast("bool") boolean isFallthrough();

  /**
   * Call the function in a boxed way.
   * If the kernel function was created with an unboxed function,
   * this will call an unboxing wrapper which then calls into that
   * unboxed function.
   *
   * Example:
   *
   * > void boxed_func(OperatorKernel*, Stack* stack) {...}
   * > KernelFunction func = KernelFunction::makeFromBoxedFunction(&boxed_func);
   * > Tensor result = func.callBoxed(stack);
   *
   * Or, with an unboxed implementation:
   *
   * > KernelFunction func = KernelFunction::makeFromUnboxedLambda(
   * >      [] (Tensor a, bool b) -> Tensor {...});
   * > Tensor result = func.callBoxed(stack);
   */
  public native void callBoxed(@Const @ByRef OperatorHandle opHandle, @ByVal DispatchKeySet dispatchKeySet, @Cast("c10::Stack*") IValueVector stack);

  /**
   * Call the function in an unboxed way.
   * If the kernel function was created with a boxed function,
   * this will box all inputs and then call into that boxed function.
   *
   * Note that this doesn't work for all types yet.
   *
   * Example:
   *
   * > KernelFunction func = KernelFunction::makeFromUnboxedLambda(
   * >      [] (Tensor a, bool b) -> Tensor {...});
   * > Tensor result = func.call<Tensor, Tensor, bool>(tensor1, true);
   *
   * Or, with a boxed implementation:
   *
   * > void boxed_func(OperatorKernel*, Stack* stack) {...}
   * > KernelFunction func = KernelFunction::makeFromBoxedFunction(&boxed_func);
   * > Tensor result = func.call<Tensor, Tensor, bool>(tensor1, true);
   */

  /**
   * Create a KernelFunction from a boxed function.
   *
   * Example:
   *
   * > void boxed_func(OperatorKernel*, Stack* stack) {...}
   * > KernelFunction func = KernelFunction::makeFromBoxedFunction<&boxed_func>();
   */

  /**
   * TODO: This will only be useful if we write a backend fallback that plumbs dispatch keys (currently there are none)
   * See Note [Plumbing Keys Through The Dispatcher] for details.
   */

  /**
   * Create a KernelFunction from an unboxed functor.
   *
   * Example:
   *
   * > class MyFunctor final : public c10::OperatorKernel {
   * >   public:
   * >     Tensor operator()(Tensor a, Tensor b) {...}
   * > };
   * > KernelFunction func = KernelFunction::makeFromUnboxedFunctor<MyFunctor>(std::make_unique<MyFunctor>());
   */

  /**
   * Create a KernelFunction from a boxed functor.
   *
   * Example:
   *
   * > class MyFunctor final : public c10::OperatorKernel {
   * >   public:
   * >     void operator()(const OperatorHandle&, DispatchKeySet, Stack*) {...}
   * > };
   * > KernelFunction func = KernelFunction::makeFromBoxedFunctor(std::make_unique<MyFunctor>());
   */

  /**
   * Create a KernelFunction from an unboxed function.
   * This is usually better than KernelFunction::makeFromUnboxedRuntimeFunction
   * because knowing the function pointer as a template argument (i.e. at
   * compile time) allows the compiler to inline the function into its
   * unboxing wrapper and yields better performance when calling the function.
   *
   * Example:
   *
   * > Tensor unboxed_func(Tensor a, Tensor b) {...}
   * > KernelFunction func = KernelFunction::makeFromUnboxedFunction<decltype(unboxed_func), &unboxed_func>();
   */

  /**
   * Create a KernelFunction from an unboxed function.
   * KernelFunction::makeFromUnboxedFunction is usually a better choice than
   * this if you know the function pointer at compile time, see doc comment
   * there for an explanation.
   *
   * Example:
   *
   * > Tensor unboxed_func(Tensor a, Tensor b) {...}
   * > KernelFunction func = KernelFunction::makeFromUnboxedRuntimeFunction(&unboxed_func);
   */

  public static native @ByVal KernelFunction makeFallthrough();
  public static native @ByVal KernelFunction makeAmbiguousAutogradOther();
  public static native @ByVal KernelFunction makeNamedNotSupported();

  /**
   * Create a KernelFunction from an unboxed lambda.
   *
   * Example:
   *
   * > KernelFunction func = KernelFunction::makeFromUnboxedLambda(
   * >      [] (Tensor a, bool b) -> Tensor {...});
   */

  public native @StdString BytePointer dumpState();
  // For testing internal invariants only
  public native @Cast("bool") boolean _equalsBoxedAndUnboxed(@Const @ByRef KernelFunction arg0);
}
