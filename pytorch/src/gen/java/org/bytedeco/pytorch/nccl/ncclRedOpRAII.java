// Targeted by JavaCPP version 1.5.13-SNAPSHOT: DO NOT EDIT THIS FILE

package org.bytedeco.pytorch.nccl;

import org.bytedeco.pytorch.Allocator;
import org.bytedeco.pytorch.Backend;
import java.nio.*;
import org.bytedeco.javacpp.*;
import org.bytedeco.javacpp.annotation.*;

import static org.bytedeco.javacpp.presets.javacpp.*;
import org.bytedeco.cuda.cudart.*;
import static org.bytedeco.cuda.global.cudart.*;
import org.bytedeco.cuda.nccl.*;
import static org.bytedeco.cuda.global.nccl.*;
import static org.bytedeco.openblas.global.openblas_nolapack.*;
import static org.bytedeco.openblas.global.openblas.*;
import org.bytedeco.javacpp.chrono.*;
import static org.bytedeco.javacpp.global.chrono.*;
import org.bytedeco.pytorch.*;
import static org.bytedeco.pytorch.global.torch.*;
import org.bytedeco.cuda.cublas.*;
import static org.bytedeco.cuda.global.cublas.*;
import org.bytedeco.cuda.cudnn.*;
import static org.bytedeco.cuda.global.cudnn.*;
import org.bytedeco.cuda.cusparse.*;
import static org.bytedeco.cuda.global.cusparse.*;
import org.bytedeco.cuda.cusolver.*;
import static org.bytedeco.cuda.global.cusolver.*;
import org.bytedeco.cuda.cupti.*;
import static org.bytedeco.cuda.global.cupti.*;
import org.bytedeco.pytorch.cuda.*;
import static org.bytedeco.pytorch.global.torch_cuda.*;

import static org.bytedeco.pytorch.global.torch_nccl.*;


// Helper that automatically cleans up premul sums.
@Namespace("c10d") @NoOffset @Properties(inherit = org.bytedeco.pytorch.presets.torch_nccl.class)
public class ncclRedOpRAII extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ncclRedOpRAII(Pointer p) { super(p); }

  public ncclRedOpRAII() { super((Pointer)null); allocate(); }
  private native void allocate();
  public ncclRedOpRAII(@Cast("ncclRedOp_t") int op) { super((Pointer)null); allocate(op); }
  private native void allocate(@Cast("ncclRedOp_t") int op);
  public ncclRedOpRAII(@Cast("ncclRedOp_t") int op, ncclComm comm) { super((Pointer)null); allocate(op, comm); }
  private native void allocate(@Cast("ncclRedOp_t") int op, ncclComm comm);
  
  
  public ncclRedOpRAII(@ByRef(true) ncclRedOpRAII tmp) { super((Pointer)null); allocate(tmp); }
  @NoException(true) private native void allocate(@ByRef(true) ncclRedOpRAII tmp);
// #if defined(ENABLE_NCCL_PREMUL_SUM_SUPPORT)
// #endif // ENABLE_NCCL_PREMUL_SUM_SUPPORT
  public native @Cast("ncclRedOp_t") @Name("operator ncclRedOp_t") int asInt();
  public native @Cast("ncclRedOp_t") int op_(); public native ncclRedOpRAII op_(int setter);
  public native ncclComm comm_(); public native ncclRedOpRAII comm_(ncclComm setter);
  public native @Cast("bool") boolean premul_sum_(); public native ncclRedOpRAII premul_sum_(boolean setter);
}
