// Targeted by JavaCPP version 1.4.4: DO NOT EDIT THIS FILE

package org.bytedeco.javacpp;

import java.nio.*;
import org.bytedeco.javacpp.*;
import org.bytedeco.javacpp.annotation.*;

import static org.bytedeco.javacpp.cuda.*;

public class nvinfer extends org.bytedeco.javacpp.presets.nvinfer {
    static { Loader.load(); }

// Parsed from NvInfer.h

/*
 * Copyright 1993-2018 NVIDIA Corporation.  All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee.  Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE.  IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users.  These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item.  Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

// #ifndef NV_INFER_H
// #define NV_INFER_H

// #include <cstddef>
// #include <cstdint>

/** TensorRT major version. */
public static final int NV_TENSORRT_MAJOR = 5;
/** TensorRT minor version. */
public static final int NV_TENSORRT_MINOR = 0;
/** TensorRT patch version. */
public static final int NV_TENSORRT_PATCH = 0;
/** TensorRT build number. */
public static final int NV_TENSORRT_BUILD = 10;

/** Shared object library major version number. */
public static final int NV_TENSORRT_SONAME_MAJOR = 5;
/** Shared object library minor version number. */
public static final int NV_TENSORRT_SONAME_MINOR = 0;
/** Shared object library patch version number. */
public static final int NV_TENSORRT_SONAME_PATCH = 0;

// #if __cplusplus > 201103L
// #define _TENSORRT_FINAL final
// #else


/** Defines which symbols are exported */
// #define _TENSORRT_FINAL
// #endif
// #ifdef TENSORRT_BUILD_LIB
// #define TENSORRTAPI __attribute__((visibility("default")))
// #else


//!
//!
//!
//!

//!
//!
//!
// #define TENSORRTAPI
// #endif

/**
 *  \mainpage
 * 
 *  This is the API documentation for the NVIDIA TensorRT library. It provides information on individual functions, classes
 *  and methods. Use the index on the left to navigate the documentation.
 * 
 *  Please see the accompanying user guide and samples for higher-level information and general advice on using TensorRT.
 * 
 <p>
 * 
 *  \file NvInfer.h
 * 
 *  This is the top-level API file for TensorRT.
 *  */

// forward declare some CUDA types to avoid an include dependency

@Opaque public static class cublasContext extends Pointer {
    /** Empty constructor. Calls {@code super((Pointer)null)}. */
    public cublasContext() { super((Pointer)null); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public cublasContext(Pointer p) { super(p); }
}
@Opaque public static class cudnnContext extends Pointer {
    /** Empty constructor. Calls {@code super((Pointer)null)}. */
    public cudnnContext() { super((Pointer)null); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public cudnnContext(Pointer p) { super(p); }
}

/** Forward declaration of cudaStream_t. */
@Opaque public static class CUstream_st extends Pointer {
    /** Empty constructor. Calls {@code super((Pointer)null)}. */
    public CUstream_st() { super((Pointer)null); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public CUstream_st(Pointer p) { super(p); }
}
/** Forward declaration of cudaEvent_t. */
@Opaque public static class CUevent_st extends Pointer {
    /** Empty constructor. Calls {@code super((Pointer)null)}. */
    public CUevent_st() { super((Pointer)null); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public CUevent_st(Pointer p) { super(p); }
}



//!
//!
//!
@MemberGetter public static native int NV_TENSORRT_VERSION();
public static final int NV_TENSORRT_VERSION = NV_TENSORRT_VERSION(); // major, minor, patch

/**
 *  \namespace nvinfer1
 * 
 *  \brief The TensorRT API version 1 namespace.
 *  */



/**
 *  \enum DataType
 *  \brief The type of weights and tensors.
 *  */
@Namespace("nvinfer1") public enum DataType {
    /** FP32 format. */
    kFLOAT(0),
    /** FP16 format. */
    kHALF(1),
    /** quantized INT8 format. */
    kINT8(2),
    /** INT32 format. */
    kINT32(3);

    public final int value;
    private DataType(int v) { this.value = v; }
    private DataType(DataType e) { this.value = e.value; }
    public DataType intern() { for (DataType e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}



/**
 *  \enum DeviceType
 *  \brief The device that this layer/network will execute on.
 * 
 *  */
@Namespace("nvinfer1") public enum DeviceType {
    /** GPU Device */
    kGPU(0),
    kDLA(1),
    /** DLA core 0 */
    kDLA0(kDLA),
    /** DLA Core 1 */
    kDLA1(kDLA.value + 1);

    public final int value;
    private DeviceType(int v) { this.value = v; }
    private DeviceType(DeviceType e) { this.value = e.value; }
    public DeviceType intern() { for (DeviceType e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}


/**
 *  \enum DimensionType
 *  \brief The type of data encoded across this dimension.
 *  */
@Namespace("nvinfer1") public enum DimensionType {
    /** Elements correspond to different spatial data. */
    kSPATIAL(0),
    /** Elements correspond to different channels. */
    kCHANNEL(1),
    /** Elements correspond to different batch index. */
    kINDEX(2),
    /** Elements correspond to different sequence values. */
    kSEQUENCE(3);

    public final int value;
    private DimensionType(int v) { this.value = v; }
    private DimensionType(DimensionType e) { this.value = e.value; }
    public DimensionType intern() { for (DimensionType e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}



/**
 *  \class Dims
 *  \brief Structure to define the dimensions of a tensor.
 * 
 *  \note: Currently the following formats are supported for layer inputs and outputs:
 *  * zero or more index dimensions followed by one channel and two spatial dimensions (e.g. CHW)
 *  * one time series dimension followed by one index dimension followed by one channel dimension (i.e. TNC)
 *  */
@Namespace("nvinfer1") public static class Dims extends Pointer {
    static { Loader.load(); }
    /** Default native constructor. */
    public Dims() { super((Pointer)null); allocate(); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public Dims(long size) { super((Pointer)null); allocateArray(size); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Dims(Pointer p) { super(p); }
    private native void allocate();
    private native void allocateArray(long size);
    @Override public Dims position(long position) {
        return (Dims)super.position(position);
    }

    /** The maximum number of dimensions supported for a tensor. */
    @MemberGetter public static native int MAX_DIMS();
    public static final int MAX_DIMS = MAX_DIMS();
    /** The number of dimensions. */
    public native int nbDims(); public native Dims nbDims(int nbDims);
    /** The extent of each dimension. */
    public native int d(int i); public native Dims d(int i, int d);
    @MemberGetter public native IntPointer d();
    /** The type of each dimension. */
    public native DimensionType type(int i); public native Dims type(int i, DimensionType type);
    @MemberGetter public native @Cast("nvinfer1::DimensionType*") IntPointer type();
}

/**
 *  \class Dims2
 *  \brief Descriptor for two-dimensional data.
 *  */
@Namespace("nvinfer1") public static class Dims2 extends Dims {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Dims2(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public Dims2(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public Dims2 position(long position) {
        return (Dims2)super.position(position);
    }

    /**
     *  \brief Construct an empty Dims2 object.
     *  */
    
    
    //!
    //!
    //!
    public Dims2() { super((Pointer)null); allocate(); }
    private native void allocate();

    /**
     *  \brief Construct a Dims2 from 2 elements.
     * 
     *  @param d0 The first element.
     *  @param d1 The second element.
     *  */
    public Dims2(int d0, int d1) { super((Pointer)null); allocate(d0, d1); }
    private native void allocate(int d0, int d1);
}

/**
 *  \class DimsHW
 *  \brief Descriptor for two-dimensional spatial data.
 *  */
@Namespace("nvinfer1") public static class DimsHW extends Dims2 {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public DimsHW(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public DimsHW(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public DimsHW position(long position) {
        return (DimsHW)super.position(position);
    }

    /**
     *  \brief Construct an empty DimsHW object.
     *  */
    
    
    //!
    //!
    //!
    public DimsHW() { super((Pointer)null); allocate(); }
    private native void allocate();

    /**
     *  \brief Construct a DimsHW given height and width.
     * 
     *  @param Height the height of the data
     *  @param Width the width of the data
     *  */
    
    
    //!
    //!
    //!
    public DimsHW(int height, int width) { super((Pointer)null); allocate(height, width); }
    private native void allocate(int height, int width);

    /**
     *  \brief Get the height.
     * 
     *  @return The height.
     *  */
    
    
    //!
    //!
    //!
    public native @ByRef IntPointer h();

    /**
     *  \brief Get the height.
     * 
     *  @return The height.
     *  */

    /**
     *  \brief Get the width.
     * 
     *  @return The width.
     *  */
    
    
    //!
    //!
    //!
    public native @ByRef IntPointer w();

    /**
     *  \brief Get the width.
     * 
     *  @return The width.
     *  */
}

/**
 *  \class Dims3
 *  \brief Descriptor for three-dimensional data.
 *  */
@Namespace("nvinfer1") public static class Dims3 extends Dims {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Dims3(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public Dims3(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public Dims3 position(long position) {
        return (Dims3)super.position(position);
    }

    /**
     *  \brief Construct an empty Dims3 object.
     *  */
    
    
    //!
    //!
    //!
    public Dims3() { super((Pointer)null); allocate(); }
    private native void allocate();

    /**
     *  \brief Construct a Dims3 from 3 elements.
     * 
     *  @param d0 The first element.
     *  @param d1 The second element.
     *  @param d2 The third element.
     *  */
    public Dims3(int d0, int d1, int d2) { super((Pointer)null); allocate(d0, d1, d2); }
    private native void allocate(int d0, int d1, int d2);
}

/**
 *  \class DimsCHW
 *  \brief Descriptor for data with one channel dimension and two spatial dimensions.
 *  */
@Namespace("nvinfer1") public static class DimsCHW extends Dims3 {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public DimsCHW(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public DimsCHW(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public DimsCHW position(long position) {
        return (DimsCHW)super.position(position);
    }

    /**
     *  \brief Construct an empty DimsCHW object.
     *  */
    
    
    //!
    //!
    //!
    public DimsCHW() { super((Pointer)null); allocate(); }
    private native void allocate();

    /**
     *  \brief Construct a DimsCHW given channel count, height and width.
     * 
     *  @param channels The channel count.
     *  @param height The height of the data.
     *  @param width The width of the data.
     *  */
    
    
    //!
    //!
    //!
    public DimsCHW(int channels, int height, int width) { super((Pointer)null); allocate(channels, height, width); }
    private native void allocate(int channels, int height, int width);

    /**
     *  \brief Get the channel count.
     * 
     *  @return The channel count.
     *  */
    
    
    //!
    //!
    //!
    public native @ByRef IntPointer c();

    /**
     *  \brief Get the channel count.
     * 
     *  @return The channel count.
     *  */

    /**
     *  \brief Get the height.
     * 
     *  @return The height.
     *  */
    
    
    //!
    //!
    //!
    public native @ByRef IntPointer h();

    /**
     *  \brief Get the height.
     * 
     *  @return The height.
     *  */

    /**
     *  \brief Get the width.
     * 
     *  @return The width.
     *  */
    
    
    //!
    //!
    //!
    public native @ByRef IntPointer w();

    /**
     *  \brief Get the width.
     * 
     *  @return The width.
     *  */
}

/**
 *  \class Dims4
 *  \brief Descriptor for four-dimensional data.
 *  */
@Namespace("nvinfer1") public static class Dims4 extends Dims {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Dims4(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public Dims4(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public Dims4 position(long position) {
        return (Dims4)super.position(position);
    }

    /**
     *  \brief Construct an empty Dims2 object.
     *  */
    
    
    //!
    //!
    //!
    public Dims4() { super((Pointer)null); allocate(); }
    private native void allocate();

    /**
     *  \brief Construct a Dims4 from 4 elements.
     * 
     *  @param d0 The first element.
     *  @param d1 The second element.
     *  @param d2 The third element.
     *  @param d3 The fourth element.
     *  */
    public Dims4(int d0, int d1, int d2, int d3) { super((Pointer)null); allocate(d0, d1, d2, d3); }
    private native void allocate(int d0, int d1, int d2, int d3);
}

/**
 *  \class DimsNCHW
 *  \brief Descriptor for data with one index dimension, one channel dimension and two spatial dimensions.
 *  */
@Namespace("nvinfer1") public static class DimsNCHW extends Dims4 {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public DimsNCHW(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public DimsNCHW(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public DimsNCHW position(long position) {
        return (DimsNCHW)super.position(position);
    }

    /**
     *  \brief Construct an empty DimsNCHW object.
     *  */
    
    
    //!
    //!
    //!
    public DimsNCHW() { super((Pointer)null); allocate(); }
    private native void allocate();

    /**
     *  \brief Construct a DimsNCHW given batch size, channel count, height and width.
     * 
     *  @param batchSize The batch size (commonly denoted N).
     *  @param channels The channel count.
     *  @param height The height of the data.
     *  @param width The width of the data.
     *  */
    
    
    //!
    //!
    //!
    public DimsNCHW(int batchSize, int channels, int height, int width) { super((Pointer)null); allocate(batchSize, channels, height, width); }
    private native void allocate(int batchSize, int channels, int height, int width);

    /**
     *  \brief Get the index count.
     * 
     *  @return The index count.
     *  */
    
    
    //!
    //!
    //!
    public native @ByRef IntPointer n();

    /**
     *  \brief Get the index count.
     * 
     *  @return The index count.
     *  */

    /**
     *  \brief Get the channel count.
     * 
     *  @return The channel count.
     *  */
    
    
    //!
    //!
    //!
    public native @ByRef IntPointer c();

    /**
     *  \brief Get the channel count.
     * 
     *  @return The channel count.
     *  */

    /**
     *  \brief Get the height.
     * 
     *  @return The height.
     *  */
    
    
    //!
    //!
    //!
    public native @ByRef IntPointer h();

    /**
     *  \brief Get the height.
     * 
     *  @return The height.
     *  */

    /**
     *  \brief Get the width.
     * 
     *  @return The width.
     *  */
    
    
    //!
    //!
    //!
    public native @ByRef IntPointer w();

    /**
     *  \brief Get the width.
     * 
     *  @return The width.
     *  */
}

/**
 *  \class Weights
 * 
 *  \brief An array of weights used as a layer parameter.
 * 
 *  The weights are held by reference until the engine has been built. Therefore the data referenced
 *  by \p values field should be preserved until the build is complete.
 *  */
@Namespace("nvinfer1") public static class Weights extends Pointer {
    static { Loader.load(); }
    /** Default native constructor. */
    public Weights() { super((Pointer)null); allocate(); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public Weights(long size) { super((Pointer)null); allocateArray(size); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Weights(Pointer p) { super(p); }
    private native void allocate();
    private native void allocateArray(long size);
    @Override public Weights position(long position) {
        return (Weights)super.position(position);
    }

    /** The type of the weights. */
    public native DataType type(); public native Weights type(DataType type);
    /** The weight values, in a contiguous array. */
    @MemberGetter public native @Const Pointer values();
    /** The number of weights in the array. */
    public native @Cast("int64_t") long count(); public native Weights count(long count);
}

/**
 *  \class IHostMemory
 * 
 *  \brief Class to handle library allocated memory that is accessible to the user.
 * 
 *  The memory allocated via the host memory object is owned by the library and will
 *  be de-allocated when the destroy method is called.
 *  */
@Namespace("nvinfer1") public static class IHostMemory extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IHostMemory(Pointer p) { super(p); }

    /** A pointer to the raw data that is owned by the library. */
    public native Pointer data();
    /** The size in bytes of the data that was allocated. */
    public native @Cast("std::size_t") long size();
    /** The type of the memory that was allocated. */
    public native DataType type();
    /** Destroy the allocated memory. */
    public native void destroy();
}

/**
 *  \enum LayerType
 * 
 *  \brief The type values of layer classes.
 * 
 *  @see ILayer::getType()
 *  */
@Namespace("nvinfer1") public enum LayerType {
    /** Convolution layer. */
    kCONVOLUTION(0),
    /** Fully connected layer. */
    kFULLY_CONNECTED(1),
    /** Activation layer. */
    kACTIVATION(2),
    /** Pooling layer. */
    kPOOLING(3),
    /** LRN layer. */
    kLRN(4),
    /** Scale Layer. */
    kSCALE(5),
    /** SoftMax layer. */
    kSOFTMAX(6),
    /** Deconvolution layer. */
    kDECONVOLUTION(7),
    /** Concatenation layer. */
    kCONCATENATION(8),
    /** Elementwise layer. */
    kELEMENTWISE(9),
    /** Plugin layer. */
    kPLUGIN(10),
    /** RNN Layer. */
    kRNN(11),
    /** UnaryOp Operation Layer. */
    kUNARY(12),
    /** Padding Layer. */
    kPADDING(13),
    /** Shuffle Layer. */
    kSHUFFLE(14),
    /** Reduce layer. */
    kREDUCE(15),
    /** TopK Layer. */
    kTOPK(16),
    /** Gather Layer. */
    kGATHER(17),
    /** Matrix Multiply Layer. */
    kMATRIX_MULTIPLY(18),
    /** Ragged softmax Layer. */
    kRAGGED_SOFTMAX(19),
    /** Constant Layer. */
    kCONSTANT(20),
    /** RNNv2 layer. */
    kRNN_V2(21),
    /** Identity layer. */
    kIDENTITY(22);

    public final int value;
    private LayerType(int v) { this.value = v; }
    private LayerType(LayerType e) { this.value = e.value; }
    public LayerType intern() { for (LayerType e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}



/**
 *  \enum TensorLocation
 *  \brief The location for tensor data storage, device or host.
 *  */
@Namespace("nvinfer1") public enum TensorLocation {
    /** Data stored on device. */
    kDEVICE(0),
    /** Data stored on host. */
    kHOST(1);

    public final int value;
    private TensorLocation(int v) { this.value = v; }
    private TensorLocation(TensorLocation e) { this.value = e.value; }
    public TensorLocation intern() { for (TensorLocation e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}



/**
 *  \class ITensor
 * 
 *  \brief A tensor in a network definition.
 * 
 *  to remove a tensor from a network definition, use INetworkDefinition::removeTensor()
 *  */
@Namespace("nvinfer1") public static class ITensor extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ITensor(Pointer p) { super(p); }

    /**
     *  \brief Set the tensor name.
     * 
     *  For a network input, the name is assigned by the application. For tensors which are layer outputs,
     *  a default name is assigned consisting of the layer name followed by the index of the output in brackets.
     * 
     *  This method copies the name string.
     * 
     *  @param name The name.
     * 
     *  @see getName()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native void setName(String name);
    public native void setName(@Cast("const char*") BytePointer name);

    /**
     *  \brief Get the tensor name.
     * 
     *  @return The name, as a pointer to a NULL-terminated character sequence.
     * 
     *  @see setName()
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    public native String getName();

    /**
     *  \brief Set the dimensions of a tensor.
     * 
     *  For a network input the name is assigned by the application. For a network output it is computed based on
     *  the layer parameters and the inputs to the layer. If a tensor size or a parameter is modified in the network,
     *  the dimensions of all dependent tensors will be recomputed.
     * 
     *  This call is only legal for network input tensors, since the dimensions of layer output tensors are inferred based on
     *  layer inputs and parameters.
     * 
     *  @param dimensions The dimensions of the tensor.
     * 
     *  @see getDimensions()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native void setDimensions(@ByVal Dims dimensions); // only valid for input tensors

    /**
     *  \brief Get the dimensions of a tensor.
     * 
     *  @return The dimensions of the tensor.
     * 
     *  @see setDimensions()
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    public native @ByVal Dims getDimensions();

    /**
     *  \brief Set the data type of a tensor.
     * 
     *  @param type The data type of the tensor.
     * 
     *  The type is unchanged if the type is
     *  invalid for the given tensor.
     * 
     *  If the tensor is a network input or output,
     *  then the tensor type cannot be DataType::kINT8.
     * 
     *  @see getType()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native void setType(DataType type);
    public native void setType(@Cast("nvinfer1::DataType") int type);

    /**
     *  \brief Get the data type of a tensor.
     * 
     *  @return The data type of the tensor.
     * 
     *  @see setType()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native DataType getType();

    /**
     *  \brief Set user calibration scales
     * 
     *  Currently, only symmetric ranges are supported.
     *  Therefore, the larger of the absolute values of the provided bounds is used.
     * 
     *  @return Whether the dynamic range was set successfully
     *  */
    
    
    //!
    //!
    public native @Cast("bool") boolean setDynamicRange(float min, float max);

    /**
     *  \brief Whether the tensor is a network input.
     *  */
    
    
    //!
    //!
    public native @Cast("bool") boolean isNetworkInput();

    /**
     *  \brief Whether the tensor is a network output.
     *  */
    public native @Cast("bool") boolean isNetworkOutput();
    /**
     *  \brief Set whether to enable broadcast of tensor across the batch.
     * 
     *  When a tensor is broadcast across a batch, it has the same value for every member in the batch.
     *  Memory is only allocated once for the single member.
     * 
     *  This method is only valid for network input tensors, since the flags of layer output tensors are inferred based on
     *  layer inputs and parameters.
     *  If this state is modified for a tensor in the network, the states of all dependent tensors will be recomputed.
     * 
     *  @param broadcastAcrossBatch Whether to enable broadcast of tensor across the batch.
     * 
     *  @see getBroadcastAcrossBatch()
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native void setBroadcastAcrossBatch(@Cast("bool") boolean broadcastAcrossBatch);

    /**
     *  \brief Check if tensor is broadcast across the batch.
     * 
     *  When a tensor is broadcast across a batch, it has the same value for every member in the batch.
     *  Memory is only allocated once for the single member.
     * 
     *  @return True if tensor is broadcast across the batch, false otherwise.
     * 
     *  @see setBroadcastAcrossBatch()
     *  */
    
    
    //!
    //!
    public native @Cast("bool") boolean getBroadcastAcrossBatch();

    /**
     *  \brief Get the storage location of a tensor.
     *  @return The location of tensor data.
     *  @see setLocation()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native TensorLocation getLocation();

    /**
     *  \brief Set the storage location of a tensor
     *  @param location the location of tensor data
     * 
     *  Only input tensors for storing sequence lengths for RNNv2 are supported.
     *  Using host storage for layers that do not support it will generate
     *  errors at build time.
     * 
     *  @see getLocation()
     *  */
    public native void setLocation(TensorLocation location);
    public native void setLocation(@Cast("nvinfer1::TensorLocation") int location);
}

/**
 *  \class ILayer
 * 
 *  \brief Base class for all layer classes in a network definition.
 *  */
@Namespace("nvinfer1") public static class ILayer extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ILayer(Pointer p) { super(p); }

    /**
     *  \brief Return the type of a layer.
     * 
     *  @see LayerType
     *  */
    
    
    //!
    //!
    //!
    //!
    public native LayerType getType();

    /**
     *  \brief Set the name of a layer.
     * 
     *  This method copies the name string.
     * 
     *  @see getName()
     *  */
    
    
    //!
    //!
    //!
    public native void setName(String name);
    public native void setName(@Cast("const char*") BytePointer name);

    /**
     *  \brief Return the name of a layer.
     * 
     <p>
     *  @see setName()
     *  */
    
    
    //!
    //!
    public native String getName();

    /**
     *  \brief Get the number of inputs of a layer.
     *  */
    
    
    //!
    //!
    //!
    //!
    public native int getNbInputs();

    /**
     *  \brief Get the layer input corresponding to the given index.
     * 
     *  @param index The index of the input tensor.
     * 
     *  @return The input tensor, or nullptr if the index is out of range.
     *  */
    
    
    //!
    //!
    public native ITensor getInput(int index);

    /**
     *  \brief Get the number of outputs of a layer.
     *  */
    
    
    //!
    //!
    //!
    public native int getNbOutputs();

    /**
     *  \brief Get the layer output corresponding to the given index.
     * 
     *  @return The indexed output tensor, or nullptr if the index is out of range.
     *  */
    
    
    //!
    //!
    //!
    //!
    public native ITensor getOutput(int index);

    /**
     *  \brief replace an input of this layer with a specific tensor
     * 
     *  Note that this method cannot change the number of inputs to a layer.  The index argument must be less
     *  than the value of getNbInputs()
     * 
     *  @param index the index of the input to modify.
     *  @param tensor the new input tensor
     *  */
    
    
    
    //!
    //!
    //!
    //!
    public native void setInput(int index, @ByRef ITensor tensor);


    /**
     *  \brief Set the computational precision of this layer
     * 
     *  setting the precision forces TensorRT to choose implementations which run at this precision. If precision is not set,
     *  TensorRT will select the computational precision based on performance considerations and the flags specified to the builder.
     * 
     *  @param precision the computational precision.
     * 
     *  @see getPrecision() precisionIsSet() resetPrecision() */

    
    
    //!
    //!
    //!
    public native void setPrecision(DataType dataType);
    public native void setPrecision(@Cast("nvinfer1::DataType") int dataType);

    /**
     *  \brief get the computational precision of this layer
     * 
     *  @return the computational precision
     * 
     *  @see setPrecision() precisionIsSet() resetPrecision() */

    
    
    //!
    //!
    //!
    public native DataType getPrecision();

    /**
     *  \brief whether the computational precision has been set for this layer
     * 
     *  @return whether the computational precision has been explicitly set
     * 
     *  @see setPrecision() getPrecision() resetPrecision() */

    
    
    //!
    //!
    public native @Cast("bool") boolean precisionIsSet();

    /**
     *  \brief reset the computational precision for this layer
     * 
     *  @see setPrecision() getPrecision() precisionIsSet() */

    
    
    //!
    //!
    //!
    //!
    public native void resetPrecision();

    /**
     *  \brief Set the output type of this layer
     * 
     *  setting the output type constrains TensorRT to choose implementations which generate output data with the given type.
     *  If it is not set, TensorRT will select the implementation based on performance considerations and the flags specified to the builder.
     * 
     *  @param index the index of the output to set
     *  @param dataType the type of the output
     * 
     *  @see getOutputType() outputTypeIsSet() resetOutputType() */

    
    
    //!
    //!
    //!
    public native void setOutputType(int index, DataType dataType);
    public native void setOutputType(int index, @Cast("nvinfer1::DataType") int dataType);

    /**
     *  \brief get the output type of this layer
     * 
     *  @param index the index of the output
     *  @return the output precision. If no precision has been set, DataType::kFLOAT will be returned
     * 
     *  @see getOutputType() outputTypeIsSet() resetOutputType() */

    
    
    //!
    //!
    //!
    public native DataType getOutputType(int index);

    /**
     *  \brief whether the output type has been set for this layer
     * 
     *  @param index the index of the output
     *  @return whether the output type has been explicitly set
     * 
     *  @see setOutputType() getOutputType() resetOutputType() */

    
    
    //!
    //!
    //!
    public native @Cast("bool") boolean outputTypeIsSet(int index);

    /**
     *  \brief reset the output type for this layer
     * 
     *  @param index the index of the output
     * 
     *  @see setOutputType() getOutputType() outputTypeIsSet() */

    public native void resetOutputType(int index);
}

/**
 *  \class IConvolutionLayer
 * 
 *  \brief A convolution layer in a network definition.
 * 
 *  This layer performs a correlation operation between 3-dimensional filter with a 4-dimensional tensor to produce another 4-dimensional tensor.
 * 
 *  The HW output size of the convolution is set according to the \p INetworkCustomDimensions set in INetworkDefinition::setCustomConvolutionDimensions().
 * 
 *  An optional bias argument is supported, which adds a per-channel constant to each value in the output.
 *  */
@Namespace("nvinfer1") public static class IConvolutionLayer extends ILayer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IConvolutionLayer(Pointer p) { super(p); }

    /**
     *  \brief Set the HW kernel size of the convolution.
     * 
     *  If executing this layer on DLA, both height and width of kernel size must be in the range [1,16].
     * 
     *  @see getKernelSize()
     *  */
    
    
    //!
    //!
    //!
    public native void setKernelSize(@ByVal DimsHW kernelSize);

    /**
     *  \brief Get the HW kernel size of the convolution.
     * 
     *  @see setKernelSize()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native @ByVal DimsHW getKernelSize();

    /**
     *  \brief Set the number of output maps for the convolution.
     * 
     *  If executing this layer on DLA, the number of output maps must be in the range [1,8192].
     * 
     *  @see getNbOutputMaps()
     *  */
    
    
    //!
    //!
    //!
    public native void setNbOutputMaps(int nbOutputMaps);

    /**
     *  \brief Get the number of output maps for the convolution.
     * 
     *  @see setNbOutputMaps()
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native int getNbOutputMaps();

    /**
     *  \brief Get the stride of the convolution.
     * 
     *  Default: (1,1)
     * 
     *  If executing this layer on DLA, both height and width of stride must be in the range [1,8].
     * 
     *  @see setStride()
     *  */
    
    
    //!
    //!
    public native void setStride(@ByVal DimsHW stride);

    /**
     *  \brief Get the stride of the convolution.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    public native @ByVal DimsHW getStride();

    /**
     *  \brief Set the padding of the convolution.
     * 
     *  The input will be zero-padded by this number of elements in the height and width directions. Padding is symmetric.
     * 
     *  Default: (0,0)
     * 
     *  If executing this layer on DLA, both height and width of padding must be in the range [0,15].
     * 
     *  @see getPadding()
     *  */
    
    
    //!
    //!
    //!
    public native void setPadding(@ByVal DimsHW padding);

    /**
     *  \brief Get the padding of the convolution.
     * 
     *  @see setPadding()
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    public native @ByVal DimsHW getPadding(); // padding defaults to 0

    /**
     *  \brief Set the number of groups for a convolution.
     * 
     *  The input tensor channels are  divided into \p nbGroups groups, and a convolution is executed for each group, using a filter per group. The results of the group
     *  convolutions are concatenated to form the output.
     * 
     *  \note When using groups in int8 mode, the size of the groups (i.e. the channel count divided by the group count) must be a multiple of 4 for both input and output.
     * 
     *  Default: 1
     * 
     *  @see getNbGroups()
     *  */
    
    
    //!
    //!
    //!
    public native void setNbGroups(int nbGroups);

    /**
     *  \brief Set the number of groups for a convolution.
     * 
     *  @see setNbGroups()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native int getNbGroups();

    /**
     *  \brief Set the kernel weights for the convolution.
     * 
     *  The weights are specified as a contiguous array in \p GKCRS order, where \p G is the number of groups, \p K the number of output feature maps, \p C the number of
     *  input channels, and \p R and \p S are the height and width of the filter.
     * 
     *  @see getKernelWeights()
     *  */
    
    
    //!
    //!
    //!
    public native void setKernelWeights(@ByVal Weights weights);

    /**
     *  \brief Get the kernel weights for the convolution.
     * 
     *  @see setKernelWeights()
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native @ByVal Weights getKernelWeights();

    /**
     *  \brief Set the bias weights for the convolution.
     * 
     *  Bias is optional. To omit bias, set the count value of the weights structure to zero.
     * 
     *  The bias is applied per-channel, so the number of weights (if non-zero) must be equal to the number of output feature maps.
     * 
     *  @see getBiasWeights()
     *  */
    
    
    //!
    //!
    //!
    public native void setBiasWeights(@ByVal Weights weights);

    /**
     *  \brief Get the bias weights for the convolution.
     * 
     *  @see setBiasWeights()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native @ByVal Weights getBiasWeights();

    /**
     *  \brief Set the dilation for a convolution.
     * 
     *  Default: (1,1)
     * 
     *  @see getDilation()
     *  */
    
    
    //!
    //!
    //!
    public native void setDilation(@ByVal DimsHW dims);

    /**
     *  \brief Get the dilation for a convolution.
     * 
     *  @see setDilation()
     *  */
    public native @ByVal DimsHW getDilation();
}

/** \class IFullyConnectedLayer
 * 
 *  \brief A fully connected layer in a network definition.
 *  This layer expects an input tensor of three or more non-batch dimensions.  The input is automatically
 *  reshaped into an {@code MxV} tensor {@code X}, where {@code V} is a product of the last three dimensions and {@code M}
 *  is a product of the remaining dimensions (where the product over 0 dimensions is defined as 1).  For example:
 * 
 *  - If the input tensor has shape {@code {C, H, W}}, then the tensor is reshaped into {@code {1, C*H*W}}.
 *  - If the input tensor has shape {@code {P, C, H, W}}, then the tensor is reshaped into {@code {P, C*H*W}}.
 * 
 *  The layer then performs the following operation:
 * 
 *  ~~~
 *  Y := matmul(X, W^T) + bias
 *  ~~~
 * 
 *  Where {@code X} is the {@code MxV} tensor defined above, {@code W} is the {@code KxV} weight tensor
 *  of the layer, and {@code bias} is a row vector size {@code K} that is broadcasted to
 *  {@code MxK}.  {@code K} is the number of output channels, and configurable via
 *  setNbOutputChannels().  If {@code bias} is not specified, it is implicitly {@code 0}.
 * 
 *  The {@code MxK} result {@code Y} is then reshaped such that the last three dimensions are {@code {K, 1, 1}} and
 *  the remaining dimensions match the dimensions of the input tensor. For example:
 * 
 *  - If the input tensor has shape {@code {C, H, W}}, then the output tensor will have shape {@code {K, 1, 1}}.
 *  - If the input tensor has shape {@code {P, C, H, W}}, then the output tensor will have shape {@code {P, K, 1, 1}}. */
@Namespace("nvinfer1") public static class IFullyConnectedLayer extends ILayer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IFullyConnectedLayer(Pointer p) { super(p); }

    /**
     *  \brief Set the number of output channels {@code K} from the fully connected layer.
     * 
     *  If executing this layer on DLA, number of output channels must in the range [1,8192].
     * 
     *  @see getNbOutputChannels()
     *  */
    
    
    //!
    //!
    //!
    public native void setNbOutputChannels(int nbOutputs);

    /**
     *  \brief Get the number of output channels {@code K} from the fully connected layer.
     * 
     *  @see setNbOutputChannels()
     *  */
    
    
    //!
    //!
    //!
    public native int getNbOutputChannels();

    /**
     *  \brief Set the kernel weights, given as a {@code KxC} matrix in row-major order.
     * 
     *  @see getKernelWeights()
     *  */
    
    
    //!
    //!
    //!
    public native void setKernelWeights(@ByVal Weights weights);

    /**
     *  \brief Get the kernel weights.
     * 
     *  @see setKernelWeights()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native @ByVal Weights getKernelWeights();

    /**
     *  \brief Set the bias weights.
     * 
     *  Bias is optional. To omit bias, set the count value in the weights structure to zero.
     * 
     *  @see getBiasWeightsWeights()
     *  */
    
    
    //!
    //!
    //!
    public native void setBiasWeights(@ByVal Weights weights);

    /**
     *  \brief Get the bias weights.
     * 
     *  @see setBiasWeightsWeights()
     *  */
    public native @ByVal Weights getBiasWeights();
}

/**
 *  \enum ActivationType
 * 
 *  \brief Enumerates the types of activation to perform in an activation layer.
 *  */
@Namespace("nvinfer1") public enum ActivationType {
    /** Rectified linear activation. */
    kRELU(0),
    /** Sigmoid activation. */
    kSIGMOID(1),
    /** TanH activation. */
    kTANH(2);

    public final int value;
    private ActivationType(int v) { this.value = v; }
    private ActivationType(ActivationType e) { this.value = e.value; }
    public ActivationType intern() { for (ActivationType e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}



/**
 *  \class IActivationLayer
 * 
 *  \brief An Activation layer in a network definition.
 * 
 *  This layer applies a per-element activation function to its input.
 * 
 *  The output has the same shape as the input.
 *  */
@Namespace("nvinfer1") public static class IActivationLayer extends ILayer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IActivationLayer(Pointer p) { super(p); }

    /**
     *  \brief Set the type of activation to be performed.
     * 
     *  @see getActivationType(), ActivationType
     *  */
    
    
    //!
    //!
    //!
    public native void setActivationType(ActivationType type);
    public native void setActivationType(@Cast("nvinfer1::ActivationType") int type);

    /**
     *  \brief Get the type of activation to be performed.
     * 
     *  @see setActivationType(), ActivationType
     *  */
    public native ActivationType getActivationType();
}

/**
 *  \enum PoolingType
 * 
 *  \brief The type of pooling to perform in a pooling layer.
 *  */
@Namespace("nvinfer1") public enum PoolingType {
    kMAX(0),              // Maximum over elements
    kAVERAGE(1),          // Average over elements. If the tensor is padded, the count includes the padding
    kMAX_AVERAGE_BLEND(2);// Blending between the max pooling and average pooling: (1-blendFactor)*maxPool + blendFactor*avgPool

    public final int value;
    private PoolingType(int v) { this.value = v; }
    private PoolingType(PoolingType e) { this.value = e.value; }
    public PoolingType intern() { for (PoolingType e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}



/** \class IPoolingLayer
 * 
 *  \brief A Pooling layer in a network definition.
 * 
 *  The layer applies a reduction operation within a window over the input.
 * 
 *  The output size is determined from the input size using the formula set by INetworkDefinition::setCustomPoolingDimensions().
 *  */
@Namespace("nvinfer1") public static class IPoolingLayer extends ILayer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IPoolingLayer(Pointer p) { super(p); }

    /**
     *  \brief Set the type of activation to be performed.
     * 
     *  DLA only supports kMAX and kAVERAGE.
     * 
     *  @see getPoolingType(), PoolingType
     *  */
    
    
    //!
    //!
    //!
    public native void setPoolingType(PoolingType type);
    public native void setPoolingType(@Cast("nvinfer1::PoolingType") int type);

    /**
     *  \brief Get the type of activation to be performed.
     * 
     *  @see setPoolingType(), PoolingType
     *  */
    
    
    //!
    //!
    //!
    //!
    public native PoolingType getPoolingType();

    /**
     *  \brief Set the window size for pooling.
     * 
     *  If executing this layer on DLA, both height and width of window size must be in the range [1,8].
     * 
     *  @see getWindowSize()
     *  */
    
    
    //!
    //!
    //!
    public native void setWindowSize(@ByVal DimsHW windowSize);

    /**
     *  \brief Get the window size for pooling.
     * 
     *  @see setWindowSize()
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native @ByVal DimsHW getWindowSize();

    /**
     *  \brief Set the stride for pooling.
     * 
     *  Default: 1
     * 
     *  If executing this layer on DLA, both height and width of stride must be in the range [1,16].
     * 
     *  @see getStride()
     *  */
    
    
    //!
    //!
    //!
    public native void setStride(@ByVal DimsHW stride);

    /**
     *  \brief Get the stride for pooling.
     * 
     *  @see setStride()
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native @ByVal DimsHW getStride();

    /**
     *  \brief Set the padding for pooling.
     * 
     *  Default: 0
     * 
     *  If executing this layer on DLA, both height and width of padding must be in the range [0,7].
     * 
     *  @see getStride()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native void setPadding(@ByVal DimsHW padding);

    /**
     *  \brief Get the padding for pooling.
     * 
     *  Default: 0
     * 
     *  @see getStride()
     *  */
    
    
    //!
    //!
    //!
    public native @ByVal DimsHW getPadding();

    /**
     *  \brief Set the blending factor for the max_average_blend mode: max_average_blendPool = (1-blendFactor)*maxPool + blendFactor*avgPool
     *  blendFactor is a user value in [0,1] with the default value of 0.0
     *  This value only applies for the kMAX_AVERAGE_BLEND mode.
     * 
     *  @see getBlendFactor()
     *  */
    
    
    //!
    //!
    //!
    public native void setBlendFactor(float blendFactor);

    /**
     *  \brief Get the blending factor for the max_average_blend mode: max_average_blendPool = (1-blendFactor)*maxPool + blendFactor*avgPool
     *  blendFactor is a user value in [0,1] with the default value of 0.0
     *  In modes other than kMAX_AVERAGE_BLEND, blendFactor is ignored.
     * 
     *  @see setBlendFactor()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native float getBlendFactor();

    /**
     *  \brief Set whether average pooling uses as a denominator the overlap area between the window and the unpadded input.
     *  If this is not set, the denominator is the overlap between the pooling window and the padded input.
     * 
     *  Default: true
     * 
     *  @see getAverageCountExcludesPadding()
     *  */
    
    
    //!
    //!
    //!
    public native void setAverageCountExcludesPadding(@Cast("bool") boolean exclusive);

    /**
     *  \brief Get whether exclusive pooling uses as a denominator the overlap area betwen the window and the unpadded input.
     * 
     *  @see setAverageCountExcludesPadding()
     *  */
    public native @Cast("bool") boolean getAverageCountExcludesPadding();
}

/**
 *  \class ILRNLayer
 * 
 *  \brief A LRN layer in a network definition.
 * 
 *  The output size is the same as the input size.
 *  */
@Namespace("nvinfer1") public static class ILRNLayer extends ILayer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ILRNLayer(Pointer p) { super(p); }

    /**
     *  \brief Set the LRN window size.
     * 
     *  The window size must be odd and in the range of [1, 15].
     *  @see setWindowStride()
     *  */
    
    
    //!
    //!
    //!
    public native void setWindowSize(int windowSize);

    /**
     *  \brief Get the LRN window size.
     * 
     *  @see getWindowStride()
     *  */
    
    
    //!
    //!
    //!
    public native int getWindowSize();

    /**
     *  \brief Set the LRN alpha value.
     * 
     *  The valid range is [-1e20, 1e20].
     *  @see getAlpha()
     *  */
    
    
    //!
    //!
    //!
    public native void setAlpha(float alpha);

    /**
     *  \brief Get the LRN alpha value.
     * 
     *  @see setAlpha()
     *  */
    
    
    //!
    //!
    //!
    public native float getAlpha();

    /**
     *  \brief Set the LRN beta value.
     * 
     *  The valid range is [0.01, 1e5f].
     *  @see getBeta()
     *  */
    
    
    //!
    //!
    //!
    public native void setBeta(float beta);

    /**
     *  \brief Get the LRN beta value.
     * 
     *  @see setBeta()
     *  */
    
    
    //!
    //!
    //!
    public native float getBeta();

    /**
     *  \brief Set the LRN K value.
     * 
     *  The valid range is [1e-5, 1e10].
     *  @see getK()
     *  */
    
    
    //!
    //!
    //!
    public native void setK(float k);

    /**
     *  \brief Get the LRN K value.
     * 
     *  @see setK()
     *  */
    public native float getK();
}

/**
 *  \brief Controls how scale is applied in a Scale layer.
 * 
 *  @see IScaleLayer
 *  */
@Namespace("nvinfer1") public enum ScaleMode {
    /** Identical coefficients across all elements of the tensor. */
    kUNIFORM(0),
    /** Per-channel coefficients. The channel dimension is assumed to be the third to last dimension */
    kCHANNEL(1),
    /** Elementwise coefficients. */
    kELEMENTWISE(2);

    public final int value;
    private ScaleMode(int v) { this.value = v; }
    private ScaleMode(ScaleMode e) { this.value = e.value; }
    public ScaleMode intern() { for (ScaleMode e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}



/**
 *  \class IScaleLayer
 * 
 *  \brief A Scale layer in a network definition.
 * 
 *  This layer applies a per-element computation to its input:
 * 
 *  \p output = (\p input* \p scale + \p shift)^ \p power
 * 
 *  The coefficients can be applied on a per-tensor, per-channel, or per-element basis.
 * 
 *  \note If the number of weights is 0, then a default value is used for shift, power, and scale.
 *        The default shift is 0, the default power is 1, and the default scale is 1.
 * 
 *  The output size is the same as the input size.
 * 
 *  \note The input tensor for this layer is required to have a minimum of 3 dimensions.
 * 
 *  @see ScaleMode
 *  */
@Namespace("nvinfer1") public static class IScaleLayer extends ILayer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IScaleLayer(Pointer p) { super(p); }

    /**
     *  \brief Set the scale mode.
     * 
     *  @see getMode()
     *  */
    
    
    //!
    //!
    //!
    public native void setMode(ScaleMode mode);
    public native void setMode(@Cast("nvinfer1::ScaleMode") int mode);

    /**
     *  \brief Set the scale mode.
     * 
     *  @see setMode()
     *  */
    
    
    //!
    //!
    //!
    public native ScaleMode getMode();

    /**
     *  \brief Set the shift value.
     * 
     *  @see getShift()
     *  */
    
    
    //!
    //!
    //!
    public native void setShift(@ByVal Weights shift);

    /**
     *  \brief Get the shift value.
     * 
     *  @see setShift()
     *  */
    
    
    //!
    //!
    //!
    public native @ByVal Weights getShift();

    /**
     *  \brief Set the scale value.
     * 
     *  @see getScale()
     *  */
    
    
    //!
    //!
    //!
    public native void setScale(@ByVal Weights scale);

    /**
     *  \brief Get the scale value.
     * 
     *  @see setScale()
     *  */
    
    
    //!
    //!
    //!
    public native @ByVal Weights getScale();

    /**
     *  \brief Set the power value.
     * 
     *  @see getPower()
     *  */
    
    
    //!
    //!
    //!
    public native void setPower(@ByVal Weights power);

    /**
     *  \brief Get the power value.
     * 
     *  @see setPower()
     *  */
    public native @ByVal Weights getPower();
}

/**
 *  \class ISoftMaxLayer
 * 
 *  \brief A Softmax layer in a network definition.
 * 
 *  This layer applies a per-channel softmax to its input.
 * 
 *  The output size is the same as the input size.
 *  */
@Namespace("nvinfer1") public static class ISoftMaxLayer extends ILayer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ISoftMaxLayer(Pointer p) { super(p); }

    /**
     *  \brief Set the axis along which softmax is computed. Currently, only one axis can be set.
     * 
     *  The axis is specified by setting the bit corresponding to the axis, after excluding the batch dimension, to 1.
     *  Let's say we have an NCHW tensor as input (three non-batch dimensions).
     *  Bit 0 corresponds to the C dimension boolean.
     *  Bit 1 corresponds to the H dimension boolean.
     *  Bit 2 corresponds to the W dimension boolean.
     *  For example, to perform softmax on axis R of a NPQRCHW input, set bit 2.
     * 
     *  By default, softmax is performed on the axis which is the number of non-batch axes minus three. It is 0 if there are fewer than 3 non-batch axes.
     *  For example, if the input is NCHW, the default axis is C. If the input is NHW, then the default axis is H.
     * 
     *  @param axes The axis along which softmax is computed.
     *  */
    
    
    //!
    //!
    //!
    public native void setAxes(@Cast("uint32_t") int axes);

    /**
     *  \brief Get the axis along which softmax occurs.
     * 
     *  @see setAxes()
     *  */
    public native @Cast("uint32_t") int getAxes();
}

/**
 *  \class IConcatenationLayer
 * 
 *  \brief A concatenation layer in a network definition.
 * 
 *  The output channel size is the sum of the channel sizes of the inputs.
 *  The other output sizes are the same as the other input sizes,
 *  which must all match.
 *  */
@Namespace("nvinfer1") public static class IConcatenationLayer extends ILayer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IConcatenationLayer(Pointer p) { super(p); }

    /**
     *  \brief Set the axis along which concatenation occurs.
     * 
     *  0 is the major axis (excluding the batch dimension). The default is the number of non-batch axes in the tensor minus three (e.g.
     *  for an NCHW input it would be 0), or 0 if there are fewer than 3 non-batch axes.
     * 
     *  @param axis The axis along which concatenation occurs.
     *  */
    
    
    //!
    //!
    //!
    public native void setAxis(int axis);

    /**
     *  \brief Get the axis along which concatenation occurs.
     * 
     *  @see setAxis()
     *  */
    public native int getAxis();
}

/**
 *  \class IDeconvolutionLayer
 * 
 *  \brief A deconvolution layer in a network definition.
 * 
 *  The output size is defined using the formula set by INetworkDefinition::setDeconvolutionOutputDimensionsFormula().
 *  */
@Namespace("nvinfer1") public static class IDeconvolutionLayer extends ILayer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IDeconvolutionLayer(Pointer p) { super(p); }

    /**
     *  \brief Set the HW kernel size of the convolution.
     * 
     *  If executing this layer on DLA, both height and width of kernel size must be in the range [1,16].
     * 
     *  @see getKernelSize()
     *  */
    
    
    //!
    //!
    //!
    public native void setKernelSize(@ByVal DimsHW kernelSize);

    /**
     *  \brief Get the HW kernel size of the deconvolution.
     * 
     *  @see setKernelSize()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native @ByVal DimsHW getKernelSize();

    /**
     *  \brief Set the number of output feature maps for the deconvolution.
     * 
     *  If executing this layer on DLA, the number of output maps must be in the range [1,8192].
     * 
     *  @see getNbOutputMaps()
     *  */
    
    
    //!
    //!
    //!
    public native void setNbOutputMaps(int nbOutputMaps);

    /**
     *  \brief Get the number of output feature maps for the deconvolution.
     * 
     *  @see setNbOutputMaps()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native int getNbOutputMaps();

    /**
     *  \brief Get the stride of the deconvolution.
     * 
     *  If executing this layer on DLA, both height and width of stride must be in the range [1,8].
     * 
     *  @see setStride()
     *  */
    
    
    //!
    //!
    //!
    public native void setStride(@ByVal DimsHW stride);

    /**
     *  \brief Get the stride of the deconvolution.
     * 
     *  Default: (1,1)
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    public native @ByVal DimsHW getStride();

    /**
     *  \brief Set the padding of the deconvolution.
     * 
     *  The output will be trimmed by this number of elements on each side in the height and width directions. In other words, it resembles the inverse of a convolution layer with this padding size.
     *  Padding is symmetric, and negative padding is not supported.
     * 
     *  Default: (0,0)
     * 
     *  If executing this layer on DLA, both height and width of padding must be in the range [0,15].
     * 
     *  @see getPadding()
     *  */
    
    
    //!
    //!
    //!
    public native void setPadding(@ByVal DimsHW padding);

    /**
     *  \brief Get the padding of the deconvolution.
     * 
     *  @see setPadding()
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    public native @ByVal DimsHW getPadding(); // padding defaults to 0

    /**
     *  \brief Set the number of groups for a deconvolution.
     * 
     *  The input tensor channels are divided into \p nbGroups groups, and a deconvolution is executed for each group, using a filter per group. The results of the group
     *  convolutions are concatenated to form the output.
     * 
     *  \note When using groups in int8 mode, the size of the groups (i.e. the channel count divided by the group count) must be a multiple of 4 for both input and output.
     * 
     *  Default: 1
     * 
     *  @see getNbGroups()
     *  */
    
    
    //!
    //!
    //!
    public native void setNbGroups(int nbGroups);

    /**
     *  \brief Get the number of groups for a deconvolution.
     * 
     *  @see setNbGroups()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native int getNbGroups();

    /**
     *  \brief Set the kernel weights for the deconvolution.
     * 
     *  The weights are specified as a contiguous array in \p CKRS order, where \p C the number of
     *  input channels, \p K the number of output feature maps, and \p R and \p S are the height and width of the filter.
     * 
     *  @see getWeights()
     *  */
    
    
    //!
    //!
    //!
    public native void setKernelWeights(@ByVal Weights weights);

    /**
     *  \brief Get the kernel weights for the deconvolution.
     * 
     *  @see setNbGroups()
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native @ByVal Weights getKernelWeights();

    /**
     *  \brief Set the bias weights for the deconvolution.
     * 
     *  Bias is optional. To omit bias, set the count value of the weights structure to zero.
     * 
     *  The bias is applied per-feature-map, so the number of weights (if non-zero) must be equal to the number of output feature maps.
     * 
     *  @see getBiasWeights()
     *  */
    
    
    //!
    //!
    //!
    public native void setBiasWeights(@ByVal Weights weights);

    /**
     *  \brief Get the bias weights for the deconvolution.
     * 
     *  @see getBiasWeights()
     *  */
    public native @ByVal Weights getBiasWeights();
}

/**
 *  \enum ElementWiseOperation
 * 
 *  \brief Enumerates the binary operations that may be performed by an ElementWise layer.
 * 
 *  @see IElementWiseLayer
 *  */
@Namespace("nvinfer1") public enum ElementWiseOperation {
    /** Sum of the two elements. */
    kSUM(0),
    /** Product of the two elements. */
    kPROD(1),
    /** Maximum of the two elements. */
    kMAX(2),
    /** Minimum of the two elements. */
    kMIN(3),
    /** Substract the second element from the first. */
    kSUB(4),
    /** Divide the first element by the second. */
    kDIV(5),
    /** The first element to the power of the second element. */
    kPOW(6);

    public final int value;
    private ElementWiseOperation(int v) { this.value = v; }
    private ElementWiseOperation(ElementWiseOperation e) { this.value = e.value; }
    public ElementWiseOperation intern() { for (ElementWiseOperation e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}



/**
 *  \class IElementWiseLayer
 * 
 *  \brief A elementwise layer in a network definition.
 * 
 *  This layer applies a per-element binary operation between corresponding elements of two tensors.
 * 
 *  The input dimensions of the two input tensors must be equal, and the output tensor is the same size as each input.
 *  */
@Namespace("nvinfer1") public static class IElementWiseLayer extends ILayer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IElementWiseLayer(Pointer p) { super(p); }

    /**
     *  \brief Set the binary operation for the layer.
     * 
     *  DLA supports only kSUM, kPROD, kMAX and kMIN.
     * 
     *  @see getOperation(), ElementWiseOperation
     * 
     *  @see getBiasWeights()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native void setOperation(ElementWiseOperation type);
    public native void setOperation(@Cast("nvinfer1::ElementWiseOperation") int type);

    /**
     *  \brief Get the binary operation for the layer.
     * 
     *  @see setOperation(), ElementWiseOperation
     * 
     *  @see setBiasWeights()
     *  */
    public native ElementWiseOperation getOperation();
}

@Namespace("nvinfer1") public static class IGatherLayer extends ILayer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IGatherLayer(Pointer p) { super(p); }

    /**
     *  \brief Set the non-batch dimension axis to gather on.
     *   The axis must be less than the number of non-batch dimensions in the data input.
     * 
     *  @see getGatherAxis()
     *  */
    
    
    //!
    //!
    //!
    public native void setGatherAxis(int axis);

    /**
     *  \brief Get the non-batch dimension axis to gather on.
     * 
     *  @see setGatherAxis()
     *  */
    public native int getGatherAxis();
}

/**
 *  \enum RNNOperation
 * 
 *  \brief Enumerates the RNN operations that may be performed by an RNN layer.
 * 
 *  __Equation definitions__
 * 
 *  In the equations below, we use the following naming convention:
 * 
 *  ~~~
 *  t := current time step
 * 
 *  i := input gate
 *  o := output gate
 *  f := forget gate
 *  z := update gate
 *  r := reset gate
 *  c := cell gate
 *  h := hidden gate
 * 
 *  g[t] denotes the output of gate g at timestep t, e.g.
 *  f[t] is the output of the forget gate f.
 * 
 *  X[t] := input tensor for timestep t
 *  C[t] := cell state for timestep t
 *  H[t] := hidden state for timestep t
 * 
 *  W[g] := W (input) parameter weight matrix for gate g
 *  R[g] := U (recurrent) parameter weight matrix for gate g
 *  Wb[g] := W (input) parameter bias vector for gate g
 *  Rb[g] := U (recurrent) parameter bias vector for gate g
 * 
 *  Unless otherwise specified, all operations apply pointwise
 *  to elements of each operand tensor.
 * 
 *  ReLU(X) := max(X, 0)
 *  tanh(X) := hyperbolic tangent of X
 *  sigmoid(X) := 1 / (1 + exp(-X))
 *  exp(X) := e^X
 * 
 *  A.B denotes matrix multiplication of A and B.
 *  A*B denotes pointwise multiplication of A and B.
 *  ~~~
 * 
 *  __Equations__
 * 
 *  Depending on the value of RNNOperation chosen, each sub-layer of the RNN
 *  layer will perform one of the following operations:
 * 
 *  ~~~
 *  ::kRELU
 * 
 *    H[t] := ReLU(W[i].X[t] + R[i].H[t-1] + Wb[i] + Rb[i])
 * 
 *  ::kTANH
 * 
 *    H[t] := tanh(W[i].X[t] + R[i].H[t-1] + Wb[i] + Rb[i])
 * 
 *  ::kLSTM
 * 
 *    i[t] := sigmoid(W[i].X[t] + R[i].H[t-1] + Wb[i] + Rb[i])
 *    f[t] := sigmoid(W[f].X[t] + R[f].H[t-1] + Wb[f] + Rb[f])
 *    o[t] := sigmoid(W[o].X[t] + R[o].H[t-1] + Wb[o] + Rb[o])
 *    c[t] :=    tanh(W[c].X[t] + R[c].H[t-1] + Wb[c] + Rb[c])
 * 
 *    C[t] := f[t]*C[t-1] + i[t]*c[t]
 *    H[t] := o[t]*tanh(C[t])
 * 
 *  ::kGRU
 * 
 *    z[t] := sigmoid(W[z].X[t] + R[z].H[t-1] + Wb[z] + Rb[z])
 *    r[t] := sigmoid(W[r].X[t] + R[r].H[t-1] + Wb[r] + Rb[r])
 *    h[t] := tanh(W[h].X[t] + r[t]*(R[h].H[t-1] + Rb[h]) + Wb[h])
 * 
 *    H[t] := (1 - z[t])*h[t] + z[t]*H[t-1]
 *  ~~~
 * 
 *  @see IRNNLayer, IRNNv2Layer
 *  */
@Namespace("nvinfer1") public enum RNNOperation {
    /** Single gate RNN w/ ReLU activation function. */
    kRELU(0),
    /** Single gate RNN w/ TANH activation function. */
    kTANH(1),
    /** Four-gate LSTM network w/o peephole connections. */
    kLSTM(2),
    /** Three-gate network consisting of Gated Recurrent Units. */
    kGRU(3);

    public final int value;
    private RNNOperation(int v) { this.value = v; }
    private RNNOperation(RNNOperation e) { this.value = e.value; }
    public RNNOperation intern() { for (RNNOperation e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}



/**
 *  \enum RNNDirection
 * 
 *  \brief Enumerates the RNN direction that may be performed by an RNN layer.
 * 
 *  @see IRNNLayer, IRNNv2Layer
 *  */
@Namespace("nvinfer1") public enum RNNDirection {
    /** Network iterations from first input to last input. */
    kUNIDIRECTION(0),
    /** Network iterates from first to last and vice versa and outputs concatenated. */
    kBIDIRECTION(1);

    public final int value;
    private RNNDirection(int v) { this.value = v; }
    private RNNDirection(RNNDirection e) { this.value = e.value; }
    public RNNDirection intern() { for (RNNDirection e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}



/**
 *  \enum RNNInputMode
 * 
 *  \brief Enumerates the RNN input modes that may occur with an RNN layer.
 * 
 *  If the RNN is configured with RNNInputMode::kLINEAR, then for each gate {@code g} in the first layer of the RNN,
 *  the input vector {@code X[t]} (length {@code E}) is left-multiplied by the gate's corresponding weight matrix {@code W[g]}
 *  (dimensions {@code HxE}) as usual, before being used to compute the gate output as described by \ref RNNOperation.
 * 
 *  If the RNN is configured with RNNInputMode::kSKIP, then this initial matrix multiplication is "skipped"
 *  and {@code W[g]} is conceptually an identity matrix.  In this case, the input vector {@code X[t]} must have length {@code H}
 *  (the size of the hidden state).
 * 
 *  @see IRNNLayer, IRNNv2Layer
 *  */
@Namespace("nvinfer1") public enum RNNInputMode {
    /** Perform the normal matrix multiplication in the first recurrent layer. */
    kLINEAR(0),
    /** No operation is performed on the first recurrent layer. */
    kSKIP(1);

    public final int value;
    private RNNInputMode(int v) { this.value = v; }
    private RNNInputMode(RNNInputMode e) { this.value = e.value; }
    public RNNInputMode intern() { for (RNNInputMode e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}



/**
 *  \class IRNNLayer
 * 
 *  \brief A RNN layer in a network definition.
 * 
 *  This layer applies an RNN operation on the inputs.
 * 
 *  @deprecated This interface is superseded by IRNNv2Layer.
 *  */
@Namespace("nvinfer1") public static class IRNNLayer extends ILayer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IRNNLayer(Pointer p) { super(p); }

    /**
     *  \brief Get the number of layers in the RNN.
     * 
     *  @return The number of layers in the RNN.
     *  */
    
    
    //!
    //!
    //!
    //!
    public native @Cast("unsigned") int getLayerCount();

    /**
     *  \brief Get the size of the hidden layers.
     * 
     *  The hidden size is the value of hiddenSize parameter passed into addRNN().
     * 
     *  @return The internal hidden layer size for the RNN.
     *  @see getDirection(), addRNN()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native @Cast("std::size_t") long getHiddenSize();

    /**
     *  \brief Get the sequence length.
     * 
     *  The sequence length is the maximum number of time steps passed into the addRNN() function.
     *  This is also the maximum number of input tensors that the RNN can process at once.
     * 
     *  @return the maximum number of time steps that can be executed by a single call RNN layer.
     *  */
    
    
    //!
    //!
    //!
    public native int getSeqLength();

    /**
     *  \brief Set the operation of the RNN layer.
     * 
     *  @see getOperation(), RNNOperation
     *  */
    
    
    //!
    //!
    //!
    public native void setOperation(RNNOperation op);
    public native void setOperation(@Cast("nvinfer1::RNNOperation") int op);

    /**
     *  \brief Get the operation of the RNN layer.
     * 
     *  @see setOperation(), RNNOperation
     *  */
    
    
    //!
    //!
    //!
    public native RNNOperation getOperation();

    /**
     *  \brief Set the operation of the RNN layer.
     * 
     *  @see getInputMode(), RNNInputMode
     *  */
    
    
    //!
    //!
    //!
    public native void setInputMode(RNNInputMode op);
    public native void setInputMode(@Cast("nvinfer1::RNNInputMode") int op);

    /**
     *  \brief Get the operation of the RNN layer.
     * 
     *  @see setInputMode(), RNNInputMode
     *  */
    
    
    //!
    //!
    //!
    public native RNNInputMode getInputMode();

    /**
     *  \brief Set the direction of the RNN layer.
     * 
     *  The direction determines if the RNN is run
     *  as a unidirectional(left to right) or
     *  bidirectional(left to right and right to left).
     *  In the ::kBIDIRECTION case the
     *  output is concatenated together, resulting
     *  in output size of 2x getHiddenSize().
     *  @see getDirection(), RNNDirection
     *  */
    
    
    //!
    //!
    //!
    public native void setDirection(RNNDirection op);
    public native void setDirection(@Cast("nvinfer1::RNNDirection") int op);

    /**
     *  \brief Get the direction of the RNN layer.
     * 
     *  @see setDirection(), RNNDirection
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    public native RNNDirection getDirection();

    /**
     *  @param weights The weight structure holding the weight parameters.
     * 
     *  \brief Set the weight parameters for the RNN.
     * 
     *  The trained weights for the weight parameter matrices of the RNN.
     *  The #DataType for this structure must be ::kFLOAT or ::kHALF, and must be the same
     *  datatype as the input tensor.
     * 
     *  The layout of the weight structure depends on the #RNNOperation, #RNNInputMode, and
     *  #RNNDirection of the layer.  The array specified by {@code weights.values} contains a sequence of
     *  parameter matrices, where each parameter matrix is linearly appended after the previous
     *  without padding; e.g., if parameter matrix 0 and 1 have M and N elements respectively, then
     *  the layout of {@code weights.values} in memory looks like:
     * 
     *  ~~~
     *  index | 0 1 2 3 4 ...  M-2 M-1 | M M+1  ... M+N-2 M+N-1 | M+N M+N+1 M+N+2 ...    | ...
     *  data  |-- parameter matrix 0 --|-- parameter matrix 1 --|-- parameter matrix 2 --| ...
     *  ~~~
     * 
     *  The following sections describe \ref setRNNWeightsOrder "the order of weight matrices" and
     *  \ref setRNNWeightsLayout "the layout of elements within a weight matrix".
     * 
     *  \section setRNNWeightsOrder Order of weight matrices
     * 
     *  The parameter matrices are ordered as described below:
     * 
     *  ~~~
     *     Let G(op, l) be defined to be a function that produces lists of parameter names, as follows:
     * 
     *          G(::kRELU, l) := [ Wl[i], Rl[i] ]
     *          G(::kTANH, l) := [ Wl[i], Rl[i] ]
     *          G(::kLSTM, l) := [ Wl[f], Wl[i], Wl[c], Wl[o], Rl[f], Rl[i], Rl[c], Rl[o] ]
     *          G(::kGRU, l)  := [ Wl[z], Wl[r], Wl[h], Rl[z], Rl[r], Rl[h] ]
     * 
     *     where Wl[g] and Rl[g] are the names of the input and recurrent
     *     input weight matrices for gate g, layer index l.
     * 
     *     See RNNOperation for an overview of the naming convention used for gates.
     * 
     *     If getDirection() == ::kUNIDIRECTION, then l identifies the stacked layer of the
     *     RNN, with l=0 being the first recurrent layer and l=L-1 being the last recurrent layer.
     * 
     *     If getDirection() == ::kBIDIRECTION, then (l % 2) identifies the direction of the
     *     recurrent layer (forward if 0, or backward if 1), and (l / 2) identifies the position
     *     of the recurrent layer within the (forward or backward) stack.
     * 
     *     Let op := getOperation(),
     *         L  := { ::kUNIDIRECTION => getLayerCount()
     *               { ::kBIDIRECTION => (2 * getLayerCount())
     * 
     *     Then the ordering of parameter matrices is the list produced by concatenating
     *     G(op, 0), G(op, 1), G(op, 2), ..., G(op, L-1).
     *  ~~~
     * 
     *  For example:
     * 
     *     - an RNN with {@code getLayerCount() == 3}, {@code getDirection() == ::kUNIDIRECTION},
     *       and {@code getOperation() == ::kRELU} has the following order:
     * 
     *       {@code [ W0[i], R0[i], W1[i], R1[i], W2[i], R2[i] ]}
     * 
     *     - an RNN with {@code getLayerCount() == 2}, {@code getDirection() == ::kUNIDIRECTION},
     *       and {@code getOperation() == ::kGRU} has the following order:
     * 
     *       {@code [ W0[z], W0[r], W0[h], R0[z], R0[r], R0[h], W1[z], W1[r], W1[h], R1[z], R1[r], R1[h] ]}
     * 
     *     - an RNN with {@code getLayerCount() == 2}, {@code getDirection() == ::kBIDIRECTION},
     *       and {@code getOperation() == ::kRELU} has the following order:
     * 
     *       {@code [ W0_fw[i], R0_fw[i], W0_bw[i], R0_bw[i], W1_fw[i], R1_fw[i], W1_bw[i], R1_bw[i] ]}
     * 
     *       (fw = "forward", bw = "backward")
     * 
     *  \section setRNNWeightsLayout Layout of elements within a weight matrix
     * 
     *  Each parameter matrix is row-major in memory, and has the following dimensions:
     * 
     *  ~~~
     *      Let K := { ::kUNIDIRECTION => 1
     *               { ::kBIDIRECTION => 2
     *          l := layer index (as described above)
     *          H := getHiddenSize()
     *          E := getDataLength() (the embedding length)
     *          isW := true if the matrix is an input (W) matrix, and false if
     *                 the matrix is a recurrent input (R) matrix.
     * 
     *     if isW:
     *        if l < K and ::kSKIP:
     *           (numRows, numCols) := (0, 0) # input matrix is skipped
     *        elif l < K and ::kLINEAR:
     *           (numRows, numCols) := (H, E) # input matrix acts on input data size E
     *        elif l >= K:
     *           (numRows, numCols) := (H, K * H) # input matrix acts on previous hidden state
     *     else: # not isW
     *        (numRows, numCols) := (H, H)
     *  ~~~
     * 
     *  In other words, the input weights of the first layer of the RNN (if
     *  not skipped) transform a {@code getDataLength()}-size column
     *  vector into a {@code getHiddenSize()}-size column vector.  The input
     *  weights of subsequent layers transform a {@code K*getHiddenSize()}-size
     *  column vector into a {@code getHiddenSize()}-size column vector.  {@code K=2} in
     *  the bidirectional case to account for the full hidden state being
     *  the concatenation of the forward and backward RNN hidden states.
     * 
     *  The recurrent weight matrices for all layers all have shape {@code (H, H)},
     *  both in the unidirectional and bidirectional cases.  (In the
     *  bidirectional case, each recurrent weight matrix for the (forward or
     *  backward) RNN cell operates on the previous (forward or
     *  backward) RNN cell's hidden state, which is size {@code H}).
     * 
     *  @see getWeights(), #RNNOperation
     *  */
    
    
    //!
    //!
    //!
    public native void setWeights(@ByVal Weights weights);

    /**
     *  \brief Get the W weights for the RNN.
     * 
     *  @see setWeights()
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    public native @ByVal Weights getWeights();

    /**
     *  @param bias The weight structure holding the bias parameters.
     * 
     *  \brief Set the bias parameters for the RNN.
     * 
     *  The trained weights for the bias parameter vectors of the RNN.
     *  The #DataType for this structure must be ::kFLOAT or ::kHALF, and must be the same
     *  datatype as the input tensor.
     * 
     *  The layout of the weight structure depends on the #RNNOperation, #RNNInputMode, and
     *  #RNNDirection of the layer.  The array specified by {@code weights.values} contains a sequence of
     *  bias vectors, where each bias vector is linearly appended after the previous
     *  without padding; e.g., if bias vector 0 and 1 have M and N elements respectively, then
     *  the layout of {@code weights.values} in memory looks like:
     * 
     *  ~~~
     *  index | 0 1 2 3 4 ...  M-2 M-1 | M M+1  ... M+N-2 M+N-1 | M+N M+N+1 M+N+2 ...   | ...
     *  data  |--   bias vector 0    --|--   bias vector 1    --|--   bias vector 2   --| ...
     *  ~~~
     * 
     *  The ordering of bias vectors is similar to the \ref setRNNWeightsOrder "ordering of weight matrices"
     *  as described in setWeights().  To determine the order of bias vectors for a given RNN configuration,
     *  determine the ordered list of weight matrices {@code [ W0, W1, ..., Wn ]}.  Then replace each weight matrix
     *  with its corresponding bias vector, i.e. apply the following transform (for layer {@code l}, gate {@code g}):
     * 
     *  - {@code Wl[g]} becomes {@code Wbl[g]}
     *  - {@code Rl[g]} becomes {@code Rbl[g]}
     * 
     *  For example:
     * 
     *     - an RNN with {@code getLayerCount() == 3}, {@code getDirection() == ::kUNIDIRECTION},
     *       and {@code getOperation() == ::kRELU} has the following order:
     * 
     *       {@code [ Wb0[i], Rb0[i], Wb1[i], Rb1[i], Wb2[i], Rb2[i] ]}
     * 
     *     - an RNN with {@code getLayerCount() == 2}, {@code getDirection() == ::kUNIDIRECTION},
     *       and {@code getOperation() == ::kGRU} has the following order:
     * 
     *       {@code [ Wb0[z], Wb0[r], Wb0[h], Rb0[z], Rb0[r], Rb0[h], Wb1[z], Wb1[r], Wb1[h], Rb1[z], Rb1[r], Rb1[h] ]}
     * 
     *     - an RNN with {@code getLayerCount() == 2}, {@code getDirection() == ::kBIDIRECTION},
     *       and {@code getOperation() == ::kRELU} has the following order:
     * 
     *       {@code [ Wb0_fw[i], Rb0_fw[i], Wb0_bw[i], Rb0_bw[i], Wb1_fw[i], Rb1_fw[i], Wb1_bw[i], Rb1_bw[i] ]}
     * 
     *       (fw = "forward", bw = "backward")
     * 
     *  Each bias vector has a fixed size, getHiddenSize().
     * 
     *  @see getBias(), #RNNOperation
     *  */
    
    
    //!
    //!
    //!
    public native void setBias(@ByVal Weights bias);

    /**
     *  \brief Get the bias parameter vector for the RNN.
     * 
     *  @see setBias()
     *  */
    
    
    //!
    //!
    //!
    public native @ByVal Weights getBias();

    /**
     *  \brief Get the length of the data being processed by the RNN for use in computing
     *  other values.
     * 
     *  @see setHiddenState(), setCellState()
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    public native int getDataLength();

    /**
     *  @param hidden The initial hidden state of the RNN.
     * 
     *  \brief Set the initial hidden state of the RNN with the provided \p hidden ITensor.
     * 
     *  The layout for \p hidden is a linear layout of a 3D matrix:
     *   - C - The number of layers in the RNN, it must match getLayerCount().
     *   - H - The number of mini-batches for each time sequence.
     *   - W - The size of the per layer hidden states, it must match getHiddenSize().
     * 
     *  The amount of space required is doubled if getDirection() is ::kBIDIRECTION with the bidirectional states coming after the unidirectional states.
     * 
     *  If hidden is not specified, then the initial hidden state is set to zero.
     * 
     *  @see getHiddenState()
     *  */
    
    
    //!
    //!
    //!
    public native void setHiddenState(@ByRef ITensor hidden);

    /**
     *  \brief Get the initial hidden state of the RNN.
     * 
     *  @return nullptr if no initial hidden tensor was specified, the initial hidden data otherwise.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    public native ITensor getHiddenState();

    /**
     *  @param cell The initial cell state of the RNN.
     * 
     *  \brief Set the initial cell state of the RNN with the provided \p cell ITensor.
     * 
     *  The layout for \p cell is a linear layout of a 3D matrix:
     *   - C - The number of layers in the RNN, it must match getLayerCount().
     *   - H - The number of mini-batches for each time sequence.
     *   - W - The size of the per layer hidden states, it must match getHiddenSize().
     * 
     *  If \p cell is not specified, then the initial cell state is set to zero.
     * 
     *  The amount of space required is doubled if getDirection() is ::kBIDIRECTION with the bidirectional states coming after the unidirectional states.
     * 
     *  The cell state only affects LSTM RNN's.
     * 
     *  @see getCellState()
     *  */
    
    
    //!
    //!
    //!
    public native void setCellState(@ByRef ITensor cell);

    /**
     *  \brief Get the initial cell state of the RNN.
     * 
     *  @return nullptr if no initial cell tensor was specified, the initial cell data otherwise.
     *  */
    public native ITensor getCellState();
}

/**
 *  \enum RNNGateType
 * 
 *  \brief Identifies an individual gate within an RNN cell.
 * 
 *  @see RNNOperation
 *  */
@Namespace("nvinfer1") public enum RNNGateType {
    /** Input gate  (i). */
    kINPUT(0),
    /** Output gate (o). */
    kOUTPUT(1),
    /** Forget gate (f). */
    kFORGET(2),
    /** Update gate (z). */
    kUPDATE(3),
    /** Reset gate  (r). */
    kRESET(4),
    /** Cell gate   (c). */
    kCELL(5),
    /** Hidden gate (h). */
    kHIDDEN(6);

    public final int value;
    private RNNGateType(int v) { this.value = v; }
    private RNNGateType(RNNGateType e) { this.value = e.value; }
    public RNNGateType intern() { for (RNNGateType e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}



/**
 *  \class IRNNv2Layer
 * 
 *  \brief An RNN layer in a network definition, version 2.
 * 
 *  This layer supersedes IRNNLayer.
 *  */
@Namespace("nvinfer1") public static class IRNNv2Layer extends ILayer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IRNNv2Layer(Pointer p) { super(p); }

    public native int getLayerCount();   //< Get the layer count of the RNN
    public native int getHiddenSize();   //< Get the hidden size of the RNN
    public native int getMaxSeqLength(); //< Get the maximum sequence length of the RNN
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    public native int getDataLength();   //< Get the maximum data length of the RNN

    /**
     *  \brief Specify individual sequence lengths in the batch with the ITensor pointed to by
     *  \p seqLengths.
     * 
     *  The \p seqLengths ITensor should be a {N1, ..., Np} tensor, where N1..Np are the index dimensions
     *  of the input tensor to the RNN.
     * 
     *  If this is not specified, then the RNN layer assumes all sequences are size getMaxSeqLength().
     * 
     *  All sequence lengths in \p seqLengths should be in the range [1, getMaxSeqLength()].  Zero-length
     *  sequences are not supported.
     * 
     *  This tensor must be of type DataType::kINT32.
     *  */
    
    
    //!
    //!
    //!
    //!
    public native void setSequenceLengths(@ByRef ITensor seqLengths);

    /**
     *  \brief Get the sequence lengths specified for the RNN.
     * 
     *  @return nullptr if no sequence lengths were specified, the sequence length data otherwise.
     * 
     *  @see setSequenceLengths()
     *  */
    
    
    //!
    //!
    public native ITensor getSequenceLengths();

    /**
     *  \brief Set the operation of the RNN layer.
     *  @see getOperation(), RNNOperation
     *  */
    
    
    //!
    //!
    public native void setOperation(RNNOperation op);
    public native void setOperation(@Cast("nvinfer1::RNNOperation") int op);

    /**
     *  \brief Get the operation of the RNN layer.
     *  @see setOperation(), RNNOperation
     *  */
    
    
    //!
    //!
    public native RNNOperation getOperation();

    /**
     *  \brief Set the input mode of the RNN layer.
     *  @see getInputMode(), RNNInputMode
     *  */
    
    
    //!
    //!
    public native void setInputMode(RNNInputMode op);
    public native void setInputMode(@Cast("nvinfer1::RNNInputMode") int op);

    /**
     *  \brief Get the input mode of the RNN layer.
     *  @see setInputMode(), RNNInputMode
     *  */
    
    
    //!
    //!
    public native RNNInputMode getInputMode();

    /**
     *  \brief Set the direction of the RNN layer.
     *  @see getDirection(), RNNDirection
     *  */
    
    
    //!
    //!
    public native void setDirection(RNNDirection op);
    public native void setDirection(@Cast("nvinfer1::RNNDirection") int op);

    /**
     *  \brief Get the direction of the RNN layer.
     *  @see setDirection(), RNNDirection
     *  */
    
    
    //!
    //!
    //!
    public native RNNDirection getDirection();

    /**
     *  \brief Set the weight parameters for an individual gate in the RNN.
     * 
     *  @param layerIndex The index of the layer that contains this gate.  See the section
     *         \ref setRNNWeightsOrder "Order of weight matrices" in IRNNLayer::setWeights()
     *         for a description of the layer index.
     *  @param gate The name of the gate within the RNN layer.  The gate name must correspond
     *         to one of the gates used by this layer's #RNNOperation.
     *  @param isW True if the weight parameters are for the input matrix W[g]
     *         and false if they are for the recurrent input matrix R[g].  See
     *         #RNNOperation for equations showing how these matrices are used
     *         in the RNN gate.
     *  @param weights The weight structure holding the weight parameters, which are stored
     *         as a row-major 2D matrix.  See \ref setRNNWeightsLayout "the layout of elements within a weight matrix"
     *         in IRNNLayer::setWeights() for documentation on the expected
     *         dimensions of this matrix.
     *  */
    
    
    //!
    //!
    public native void setWeightsForGate(int layerIndex, RNNGateType gate, @Cast("bool") boolean isW, @ByVal Weights weights);
    public native void setWeightsForGate(int layerIndex, @Cast("nvinfer1::RNNGateType") int gate, @Cast("bool") boolean isW, @ByVal Weights weights);

    /**
     *  \brief Get the weight parameters for an individual gate in the RNN.
     *  @see setWeightsForGate()
     *  */
    
    
    //!
    //!
    //!
    public native @ByVal Weights getWeightsForGate(int layerIndex, RNNGateType gate, @Cast("bool") boolean isW);
    public native @ByVal Weights getWeightsForGate(int layerIndex, @Cast("nvinfer1::RNNGateType") int gate, @Cast("bool") boolean isW);

    /**
     *  \brief Set the bias parameters for an individual gate in the RNN.
     * 
     *  @param layerIndex The index of the layer that contains this gate.  See the section
     *         \ref setRNNWeightsOrder "Order of weight matrices" in IRNNLayer::setWeights()
     *         for a description of the layer index.
     *  @param gate The name of the gate within the RNN layer.  The gate name must correspond
     *         to one of the gates used by this layer's #RNNOperation.
     *  @param isW True if the bias parameters are for the input bias Wb[g]
     *         and false if they are for the recurrent input bias Rb[g].  See
     *         #RNNOperation for equations showing how these bias vectors are used
     *         in the RNN gate.
     *  @param bias The weight structure holding the bias parameters, which should be an
     *         array of size getHiddenSize().
     *  */
    
    
    //!
    //!
    public native void setBiasForGate(int layerIndex, RNNGateType gate, @Cast("bool") boolean isW, @ByVal Weights bias);
    public native void setBiasForGate(int layerIndex, @Cast("nvinfer1::RNNGateType") int gate, @Cast("bool") boolean isW, @ByVal Weights bias);

    /**
     *  \brief Get the bias parameters for an individual gate in the RNN.
     *  @see setBiasForGate()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native @ByVal Weights getBiasForGate(int layerIndex, RNNGateType gate, @Cast("bool") boolean isW);
    public native @ByVal Weights getBiasForGate(int layerIndex, @Cast("nvinfer1::RNNGateType") int gate, @Cast("bool") boolean isW);

    /**
     *  \brief Set the initial hidden state of the RNN with the provided \p hidden ITensor.
     * 
     *  The \p hidden ITensor should have the dimensions {@code {N1, ..., Np, L, H}}, where:
     * 
     *   - {@code N1..Np} are the index dimensions specified by the input tensor
     *   - {@code L} is the number of layers in the RNN, equal to getLayerCount()
     *   - {@code H} is the hidden state for each layer, equal to getHiddenSize() if getDirection is ::kUNIDIRECTION, and 2x getHiddenSize() otherwise.
     *  */
    
    
    //!
    //!
    public native void setHiddenState(@ByRef ITensor hidden);

    /**
     *  \brief Get the initial hidden state of the RNN.
     *  @see setHiddenState()
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native ITensor getHiddenState();

    /**
     *  \brief Set the initial cell state of the LSTM with the provided \p cell ITensor.
     * 
     *  The \p cell ITensor should have the dimensions {@code {N1, ..., Np, L, H}}, where:
     * 
     *   - {@code N1..Np} are the index dimensions specified by the input tensor
     *   - {@code L} is the number of layers in the RNN, equal to getLayerCount()
     *   - {@code H} is the hidden state for each layer, equal to getHiddenSize() if getDirection is ::kUNIDIRECTION, and 2x getHiddenSize() otherwise.
     * 
     *  It is an error to call setCellState() on an RNN layer that is not configured with RNNOperation::kLSTM.
     *  */
    
    
    //!
    //!
    public native void setCellState(@ByRef ITensor cell);

    /**
     *  \brief Get the initial cell state of the RNN.
     *  @see setCellState()
     *  */
    public native ITensor getCellState();
}

/**
 *  \class IOutputDimensionsFormula
 * 
 *  \brief Application-implemented interface to compute layer output sizes.
 *  */
@Namespace("nvinfer1") public static class IOutputDimensionsFormula extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IOutputDimensionsFormula(Pointer p) { super(p); }

    /**
     *  \brief Application-implemented interface to compute the HW output dimensions of a layer from the layer input and parameters.
     * 
     *  @param inputDims The input dimensions of the layer.
     *  @param kernelSize The kernel size (or window size, for a pooling layer) parameter of the layer operation.
     *  @param stride The stride parameter for the layer.
     *  @param padding The padding parameter of the layer.
     *  @param dilation The dilation parameter of the layer (only applicable to convolutions).
     *  @param layerName The name of the layer.
     * 
     *  @return The output size of the layer
     * 
     *  Note that for dilated convolutions, the dilation is applied to the kernel size before this routine is called.
     *  */
    public native @ByVal DimsHW compute(@ByVal DimsHW inputDims, @ByVal DimsHW kernelSize, @ByVal DimsHW stride, @ByVal DimsHW padding, @ByVal DimsHW dilation, String layerName);
    public native @ByVal DimsHW compute(@ByVal DimsHW inputDims, @ByVal DimsHW kernelSize, @ByVal DimsHW stride, @ByVal DimsHW padding, @ByVal DimsHW dilation, @Cast("const char*") BytePointer layerName);
}

/**
 *  \enum PluginFormatType
 * 
 *  \brief Format of the input/output tensors.
 * 
 *  @see IPluginExt::getPluginFormats()
 *  */
@Namespace("nvinfer1") public enum PluginFormat {
    /** NCHW. */
    kNCHW((byte)0),
    /** NCHW with 2-element packed channels. */
    kNC2HW2((byte)1),
    /** NHWC with 8-element packed channels (C must be a multiple of 8). */
    kNHWC8((byte)2);

    public final byte value;
    private PluginFormat(byte v) { this.value = v; }
    private PluginFormat(PluginFormat e) { this.value = e.value; }
    public PluginFormat intern() { for (PluginFormat e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}



/** \class IPlugin
 * 
 *  \brief Plugin class for user-implemented layers.
 * 
 *  Plugins are a mechanism for applications to implement custom layers. Each plugin is owned by the application, and its lifetime
 *  must span any use of it by TensorRT
 *  */
@Namespace("nvinfer1") public static class IPlugin extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IPlugin(Pointer p) { super(p); }

    /**
     *  \brief Get the number of outputs from the layer.
     * 
     *  @return The number of outputs.
     * 
     *  This function is called by the implementations of INetworkDefinition and IBuilder. In particular, it is called prior to any call to initialize().
     *  */
    
    
    //!
    //!
    //!
    //!
    public native int getNbOutputs();

    /**
     *  \brief Get the dimension of an output tensor.
     * 
     *  @param index The index of the output tensor.
     *  @param inputs The input tensors.
     *  @param nbInputDims The number of input tensors.
     * 
     *  This function is called by the implementations of INetworkDefinition and IBuilder. In particular, it is called prior to any call to initialize().
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    public native @ByVal Dims getOutputDimensions(int index, @Const Dims inputs, int nbInputDims);

    /**
     *  \brief Configure the layer.
     * 
     *  This function is called by the builder prior to initialize(). It provides an opportunity for the layer to make algorithm choices on the basis
     *  of its weights, dimensions, and maximum batch size. The type is assumed to be FP32 and format NCHW.
     * 
     *  @param inputDims The input tensor dimensions.
     *  @param nbInputs The number of inputs.
     *  @param outputDims The output tensor dimensions.
     *  @param nbOutputs The number of outputs.
     *  @param maxBatchSize The maximum batch size.
     * 
     *  The dimensions passed here do not include the outermost batch size (i.e. for 2-D image networks, they will be 3-dimensional CHW dimensions).
     * 
     *  This method is not called for PluginExt classes; configureWithFormat is called instead.
     *  */
    
    
    //!
    //!
    //!
    public native void configure(@Const Dims inputDims, int nbInputs, @Const Dims outputDims, int nbOutputs, int maxBatchSize);

    /**
     *  \brief Initialize the layer for execution. This is called when the engine is created.
     * 
     *  @return 0 for success, else non-zero (which will cause engine termination).
     *  */
    
    
    //!
    //!
    public native int initialize();

    /**
     *  \brief Release resources acquired during plugin layer initialization. This is called when the engine is destroyed.
     *  @see initialize()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native void terminate();

    /**
     *  \brief Find the workspace size required by the layer.
     * 
     *  This function is called during engine startup, after initialize(). The workspace size returned should be sufficient for any
     *  batch size up to the maximum.
     * 
     *  @return The workspace size.
     *  */
    
    
    //!
    //!
    //!
    //!
    public native @Cast("size_t") long getWorkspaceSize(int maxBatchSize);

    /**
     *  \brief Execute the layer.
     * 
     *  @param batchSize The number of inputs in the batch.
     *  @param inputs The memory for the input tensors.
     *  @param outputs The memory for the output tensors.
     *  @param workspace Workspace for execution.
     *  @param stream The stream in which to execute the kernels.
     * 
     *  @return 0 for success, else non-zero (which will cause engine termination).
     *  */
    
    
    //!
    //!
    //!
    public native int enqueue(int batchSize, @Cast("const void*const*") PointerPointer inputs, @Cast("void**") PointerPointer outputs, Pointer workspace, CUstream_st stream);
    public native int enqueue(int batchSize, @Cast("const void*const*") @ByPtrPtr Pointer inputs, @Cast("void**") @ByPtrPtr Pointer outputs, Pointer workspace, CUstream_st stream);

    /**
     *  \brief Find the size of the serialization buffer required.
     * 
     *  @return The size of the serialization buffer.
     *  */
    
    
    //!
    //!
    //!
    //!
    public native @Cast("size_t") long getSerializationSize();

    /**
     *  \brief Serialize the layer.
     * 
     *  @param buffer A pointer to a buffer of size at least that returned by getSerializationSize().
     * 
     *  @see getSerializationSize()
     *  */
    public native void serialize(Pointer buffer);
}

/**
 *  \class IPluginExt
 * 
 *  \brief Plugin class for user-implemented layers.
 * 
 *  Plugins are a mechanism for applications to implement custom layers. Each plugin is owned by the application, and its lifetime
 *  must span any use of it by TensorRT.
 *  */
@Namespace("nvinfer1") public static class IPluginExt extends IPlugin {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IPluginExt(Pointer p) { super(p); }

    /**
     *  \brief Return the API version with which this plugin was built.
     * 
     *  Do not override this method as it is used by the TensorRT library to maintain backwards-compatibility with plugins.
     *  */
    
    
    //!
    //!
    //!
    //!
    public native int getTensorRTVersion();

    /**
     *  \brief Check format support.
     * 
     *  @param type DataType requested.
     *  @param format PluginFormat requested.
     *  @return true if the plugin supports the type-format combination.
     * 
     *  This function is called by the implementations of INetworkDefinition, IBuilder, and ICudaEngine.
     *  In particular, it is called when creating an engine and when deserializing an engine.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native @Cast("bool") boolean supportsFormat(DataType type, PluginFormat format);
    public native @Cast("bool") boolean supportsFormat(@Cast("nvinfer1::DataType") int type, @Cast("nvinfer1::PluginFormat") byte format);

    /**
     *  \brief Configure the layer.
     * 
     *  This function is called by the builder prior to initialize(). It provides an opportunity for the layer to make algorithm choices on the basis
     *  of its weights, dimensions, and maximum batch size.
     * 
     *  @param inputDims The input tensor dimensions.
     *  @param nbInputs The number of inputs.
     *  @param outputDims The output tensor dimensions.
     *  @param nbOutputs The number of outputs.
     *  @param type The data type selected for the engine.
     *  @param format The format selected for the engine.
     *  @param maxBatchSize The maximum batch size.
     * 
     *  The dimensions passed here do not include the outermost batch size (i.e. for 2-D image networks, they will be 3-dimensional CHW dimensions).
     *  */
    
    
    //!
    //!
    public native void configureWithFormat(@Const Dims inputDims, int nbInputs, @Const Dims outputDims, int nbOutputs, DataType type, PluginFormat format, int maxBatchSize);
    public native void configureWithFormat(@Const Dims inputDims, int nbInputs, @Const Dims outputDims, int nbOutputs, @Cast("nvinfer1::DataType") int type, @Cast("nvinfer1::PluginFormat") byte format, int maxBatchSize);

    /**
     *  \brief Return the plugin type. Should match the plugin name returned by the corresponding plugin creator */
    // \see IPluginCreator::getPluginName()
    /** */
    
    
    //!
    //!
    public native String getPluginType();

    /**
     *  \brief Return the plugin version. Should match the plugin version returned by the corresponding plugin creator */
    // \see IPluginCreator::getPluginVersion()
    /** */
    public native String getPluginVersion();

    ////!
    ////! \brief Destroy the plugin object. This will be called when the network, builder or engine is destroyed.
    ////!
    public native void destroy();

    ////!
    ////! \brief Clone the plugin object. This copies over internal plugin parameters and returns a new plugin object with these parameters
    ////!
    public native IPluginExt clone();
}

/**
 *  \class IPluginLayer
 * 
 *  \brief Layer type for plugins.
 * 
 *  @see IPluginExt
 *  */
@Namespace("nvinfer1") public static class IPluginLayer extends ILayer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IPluginLayer(Pointer p) { super(p); }

    /**
     *  \brief Get the plugin for the layer.
     * 
     *  @see IPluginExt
     *  */
    public native @ByRef IPlugin getPlugin();
}

/**
 *  \enum FieldType
 *  \brief The possible field types for custom layer.
 *  */

@Namespace("nvinfer1") public enum PluginFieldType {
    /** FP16 field type. */
    kFLOAT16(0),
    /** FP32 field type. */
    kFLOAT32(1),
    /** FP64 field type. */
    kFLOAT64(2),
    /** INT8 field type. */
    kINT8(3),
    /** INT16 field type. */
    kINT16(4),
    /** INT32 field type. */
    kINT32(5),
    /** char field type. */
    kCHAR(6),
    /** nvinfer1::Dims field type. */
    kDIMS(7),
    kUNKNOWN(8);

    public final int value;
    private PluginFieldType(int v) { this.value = v; }
    private PluginFieldType(PluginFieldType e) { this.value = e.value; }
    public PluginFieldType intern() { for (PluginFieldType e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}

/**
 *  \class PluginField
 * 
 *  \brief Structure containing plugin attribute field names and associated data
 *  This information can be parsed to decode necessary plugin metadata
 * 
 *  */
@Namespace("nvinfer1") @NoOffset public static class PluginField extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public PluginField(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public PluginField(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public PluginField position(long position) {
        return (PluginField)super.position(position);
    }

    /**
     *  \brief Plugin field attribute name
     *  */
    
    //!
    //!
    @MemberGetter public native String name();
    /**
     *  \brief Plugin field attribute data
     *  */
    
    //!
    //!
    @MemberGetter public native @Const Pointer data();
    /**
     *  \brief Plugin field attribute type
     *  @see PluginFieldType
     *  */
    
    //!
    //!
    public native PluginFieldType type(); public native PluginField type(PluginFieldType type);
    /**
     *  \brief Number of data entries in the Plugin attribute
     *  */
    public native int length(); public native PluginField length(int length);

    public PluginField(String name_/*=nullptr*/, @Const Pointer data_/*=nullptr*/, PluginFieldType type_/*=nvinfer1::PluginFieldType::kUNKNOWN*/, int length_/*=0*/) { super((Pointer)null); allocate(name_, data_, type_, length_); }
    private native void allocate(String name_/*=nullptr*/, @Const Pointer data_/*=nullptr*/, PluginFieldType type_/*=nvinfer1::PluginFieldType::kUNKNOWN*/, int length_/*=0*/);
    public PluginField() { super((Pointer)null); allocate(); }
    private native void allocate();
    public PluginField(@Cast("const char*") BytePointer name_/*=nullptr*/, @Const Pointer data_/*=nullptr*/, @Cast("nvinfer1::PluginFieldType") int type_/*=nvinfer1::PluginFieldType::kUNKNOWN*/, int length_/*=0*/) { super((Pointer)null); allocate(name_, data_, type_, length_); }
    private native void allocate(@Cast("const char*") BytePointer name_/*=nullptr*/, @Const Pointer data_/*=nullptr*/, @Cast("nvinfer1::PluginFieldType") int type_/*=nvinfer1::PluginFieldType::kUNKNOWN*/, int length_/*=0*/);
}

@Namespace("nvinfer1") public static class PluginFieldCollection extends Pointer {
    static { Loader.load(); }
    /** Default native constructor. */
    public PluginFieldCollection() { super((Pointer)null); allocate(); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public PluginFieldCollection(long size) { super((Pointer)null); allocateArray(size); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public PluginFieldCollection(Pointer p) { super(p); }
    private native void allocate();
    private native void allocateArray(long size);
    @Override public PluginFieldCollection position(long position) {
        return (PluginFieldCollection)super.position(position);
    }

    /** Number of PluginField entries */
    public native int nbFields(); public native PluginFieldCollection nbFields(int nbFields);
    /** Pointer to PluginField entries */
    @MemberGetter public native @Const PluginField fields();
}

/**
 *  \class IPluginCreator
 * 
 *  \brief Plugin creator class for user implemented layers
 * 
 *  @see IPlugin and IPluginFactory
 *  */

@Namespace("nvinfer1") public static class IPluginCreator extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IPluginCreator(Pointer p) { super(p); }

    /**
     *  \brief Return the version of the API the plugin creator was compiled with
     *  */
    
    
    //!
    //!
    public native int getTensorRTVersion();

    /**
     *  \brief Return the plugin name
     *  */
    
    
    //!
    //!
    public native String getPluginName();

    /**
     *  \brief Return the plugin version
     *  */
    
    
    //!
    //!
    public native String getPluginVersion();

    /**
     *  \brief Return a list of fields that needs to be passed to createPlugin
     *  @see PluginFieldCollection
     *  */
    
    
    //!
    //!
    public native @Const PluginFieldCollection getFieldNames();

    /**
     *  \brief \Return a plugin object. Return nullptr in case of error
     *  */
    
    
    //!
    //!
    public native IPluginExt createPlugin(String name, @Const PluginFieldCollection fc);
    public native IPluginExt createPlugin(@Cast("const char*") BytePointer name, @Const PluginFieldCollection fc);

    /**
     *  \brief \Called during deserialization of plugin layer. Return a plugin object
     *  */
    public native IPluginExt deserializePlugin(String name, @Const Pointer serialData, @Cast("size_t") long serialLength);
    public native IPluginExt deserializePlugin(@Cast("const char*") BytePointer name, @Const Pointer serialData, @Cast("size_t") long serialLength);
}

@Namespace("nvinfer1") public static class IPluginRegistry extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IPluginRegistry(Pointer p) { super(p); }

    /**
     *  \brief Register a plugin creator. Returns false if one with same type
     *  is already registered
     *  */
    
    
    //!
    //!
    public native @Cast("bool") boolean registerCreator(@ByRef IPluginCreator arg0);

    /**
     *  \brief Return all the registered plugin creators and the number of
     *  registered plugin creators. Returns nullptr if none found
     *  */
    
    
    //!
    //!
    public native @Cast("nvinfer1::IPluginCreator*const*") PointerPointer getPluginCreatorList(IntPointer numCreators);

    /**
     *  \brief Return plugin creator based on type and version
     *  */
    public native IPluginCreator getPluginCreator(String pluginType, String pluginVersion);
    public native IPluginCreator getPluginCreator(@Cast("const char*") BytePointer pluginType, @Cast("const char*") BytePointer pluginVersion);
}

/**
 *  \enum UnaryOperation
 * 
 *  \brief Enumerates the unary operations that may be performed by a Unary layer.
 * 
 *  @see IUnaryLayer
 *  */
@Namespace("nvinfer1") public enum UnaryOperation {
    /** Exponentiation. */
    kEXP(0),
    /** Log (base e). */
    kLOG(1),
    /** Square root. */
    kSQRT(2),
    /** Reciprocal. */
    kRECIP(3),
    /** Absolute value. */
    kABS(4),
    /** Negation. */
    kNEG(5);

    public final int value;
    private UnaryOperation(int v) { this.value = v; }
    private UnaryOperation(UnaryOperation e) { this.value = e.value; }
    public UnaryOperation intern() { for (UnaryOperation e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}



/**
 *  \class IUnaryLayer
 * 
 *  \brief Layer that represents an unary operation.
 *  */
@Namespace("nvinfer1") public static class IUnaryLayer extends ILayer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IUnaryLayer(Pointer p) { super(p); }

    /**
     *  \brief Set the unary operation for the layer.
     * 
     *  @see getOperation(), UnaryOperation
     *  */
    
    
    //!
    //!
    //!
    public native void setOperation(UnaryOperation op);
    public native void setOperation(@Cast("nvinfer1::UnaryOperation") int op);

    /**
     *  \brief Get the unary operation for the layer.
     * 
     *  @see setOperation(), UnaryOperation
     *  */
    public native UnaryOperation getOperation();
}

/**
 *  \enum ReduceOperation
 * 
 *  \brief Enumerates the reduce operations that may be performed by a Reduce layer.
 *  */
@Namespace("nvinfer1") public enum ReduceOperation {
    kSUM(0),
    kPROD(1),
    kMAX(2),
    kMIN(3),
    kAVG(4);

    public final int value;
    private ReduceOperation(int v) { this.value = v; }
    private ReduceOperation(ReduceOperation e) { this.value = e.value; }
    public ReduceOperation intern() { for (ReduceOperation e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}



/**
 *  \class IReduceLayer
 * 
 *  \brief Layer that represents a reduction operator.
 *  */
@Namespace("nvinfer1") public static class IReduceLayer extends ILayer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IReduceLayer(Pointer p) { super(p); }

    /**
     *  \brief Set the reduce operation for the layer.
     * 
     *  @see getOperation(), ReduceOperation
     *  */
    
    
    //!
    //!
    //!
    public native void setOperation(ReduceOperation op);
    public native void setOperation(@Cast("nvinfer1::ReduceOperation") int op);

    /**
     *  \brief Get the reduce operation for the layer.
     * 
     *  @see setOperation(), ReduceOperation
     *  */
    
    
    //!
    //!
    //!
    public native ReduceOperation getOperation();

    /**
     *  \brief Set the axes over which to reduce.
     * 
     *  @see getReduceAxes
     *  */
    
    
    //!
    //!
    //!
    public native void setReduceAxes(@Cast("uint32_t") int reduceAxes);

    /**
     *  \brief Get the axes over which to reduce for the layer.
     * 
     *  @see setReduceAxes
     *  */
    
    
    //!
    //!
    //!
    public native @Cast("uint32_t") int getReduceAxes();

    /**
     *  \brief Set the boolean that specifies whether or not to keep the reduced dimensions for the layer.
     * 
     *  @see getKeepDimensions
     *  */
    
    
    //!
    //!
    //!
    public native void setKeepDimensions(@Cast("bool") boolean keepDimensions);

    /**
     *  \brief Get the boolean that specifies whether or not to keep the reduced dimensions for the layer.
     * 
     *  @see setKeepDimensions
     *  */
    public native @Cast("bool") boolean getKeepDimensions();
}

/**
 *  \class IPaddingLayer
 * 
 *  \brief Layer that represents a padding operation.
 * 
 *  The padding layer adds zero-padding at the start and end of the input tensor. It only supports padding along the two innermost dimensions.
 *  Applying negative padding results in cropping of the input.
 *  */
@Namespace("nvinfer1") public static class IPaddingLayer extends ILayer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IPaddingLayer(Pointer p) { super(p); }

    /**
     *  \brief Set the padding that is applied at the start of the tensor.
     * 
     *  Negative padding results in trimming the edge by the specified amount
     * 
     *  @see getPrePadding
     *  */
    
    
    //!
    //!
    //!
    public native void setPrePadding(@ByVal DimsHW padding);

    /**
     *  \brief Set the padding that is applied at the start of the tensor.
     * 
     *  @see setPrePadding
     *  */
    
    
    //!
    //!
    //!
    //!
    public native @ByVal DimsHW getPrePadding();

    /**
     *  \brief Set the padding that is applied at the end of the tensor.
     * 
     *  Negative padding results in trimming the edge by the specified amount
     * 
     *  @see getPostPadding
     *  */
    
    
    //!
    //!
    //!
    public native void setPostPadding(@ByVal DimsHW padding);

    /**
     *  \brief Set the padding that is applied at the end of the tensor.
     * 
     *  @see setPostPadding
     *  */
    public native @ByVal DimsHW getPostPadding();
}

/** \class IShuffleLayer
 * 
 *  \brief Layer type for shuffling data.
 * 
 *  This class shuffles data by applying in sequence: a transpose operation, a reshape operation
 *  and a second transpose operation. The dimension types of the output are those of the reshape dimension.
 *  */
@Namespace("nvinfer1") public static class Permutation extends Pointer {
    static { Loader.load(); }
    /** Default native constructor. */
    public Permutation() { super((Pointer)null); allocate(); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public Permutation(long size) { super((Pointer)null); allocateArray(size); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public Permutation(Pointer p) { super(p); }
    private native void allocate();
    private native void allocateArray(long size);
    @Override public Permutation position(long position) {
        return (Permutation)super.position(position);
    }

    /**
     *  The elements of the permutation.
     *  The permutation is applied as outputDimensionIndex = permutation.order[inputDimensionIndex], so to
     *  permute from CHW order to HWC order, the required permutation is [1, 2, 0], and to permute
     *  from HWC to CHW, the required permutation is [2, 0, 1].
     *  */
    public native int order(int i); public native Permutation order(int i, int order);
    @MemberGetter public native IntPointer order();
}

@Namespace("nvinfer1") public static class IShuffleLayer extends ILayer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IShuffleLayer(Pointer p) { super(p); }

    /**
     *  \brief Set the permutation applied by the first transpose operation.
     * 
     *  @param permutation The dimension permutation applied before the reshape.
     * 
     *  The default is the identity permutation.
     * 
     *  @see getFirstTranspose
     *  */
    
    
    //!
    //!
    //!
    //!
    public native void setFirstTranspose(@ByVal Permutation permutation);

    /**
     *  \brief Get the permutation applied by the first transpose operation.
     * 
     *  @return The dimension permutation applied before the reshape.
     * 
     *  @see setFirstTranspose
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    public native @ByVal Permutation getFirstTranspose();

    /**
     *  \brief Set the reshaped dimensions.
     * 
     *  @param dimensions The reshaped dimensions.
     * 
     *  Two special values can be used as dimensions.
     * 
     *  Value 0 copies the corresponding dimension from input. This special value
     *  can be used more than once in the dimensions. If number of reshape
     *  dimensions is less than input, 0s are resolved by aligning the most
     *  significant dimensions of input.
     * 
     *  Value -1 infers that particular dimension by looking at input and rest
     *  of the reshape dimensions. Note that only a maximum of one dimension is
     *  permitted to be specified as -1.
     * 
     *  The product of the new dimensions must be equal to the product of the old.
     *  */
    
    
    //!
    //!
    //!
    public native void setReshapeDimensions(@ByVal Dims dimensions);

    /**
     *  \brief Get the reshaped dimensions.
     * 
     *  @return The reshaped dimensions.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    public native @ByVal Dims getReshapeDimensions();

    /**
     *  \brief Set the permutation applied by the second transpose operation.
     * 
     *  @param permutation The dimension permutation applied after the reshape.
     * 
     *  The default is the identity permutation.
     * 
     *  The permutation is applied as outputDimensionIndex = permutation.order[inputDimensionIndex], so to
     *  permute from CHW order to HWC order, the required permutation is [1, 2, 0].
     * 
     *  @see getSecondTranspose
     *  */
    
    
    //!
    //!
    //!
    //!
    public native void setSecondTranspose(@ByVal Permutation permutation);

    /**
     *  \brief Get the permutation applied by the second transpose operation.
     * 
     *  @return The dimension permutation applied after the reshape.
     * 
     *  @see setSecondTranspose
     *  */
    public native @ByVal Permutation getSecondTranspose();
}

/**
 *  \enum TopKOperation
 * 
 *  \brief Enumerates the operations that may be performed by a TopK layer.
 *  */
@Namespace("nvinfer1") public enum TopKOperation {
    /** Maximum of the elements. */
    kMAX(0),
    /** Minimum of the elements. */
    kMIN(1);

    public final int value;
    private TopKOperation(int v) { this.value = v; }
    private TopKOperation(TopKOperation e) { this.value = e.value; }
    public TopKOperation intern() { for (TopKOperation e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}



/**
 *  \class ITopKLayer
 * 
 *  \brief Layer that represents a TopK reduction.
 *  */
@Namespace("nvinfer1") public static class ITopKLayer extends ILayer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ITopKLayer(Pointer p) { super(p); }

    /**
     *  \brief Set the operation for the layer.
     * 
     *  @see getOperation(), TopKOperation
     *  */
    
    
    //!
    //!
    //!
    public native void setOperation(TopKOperation op);
    public native void setOperation(@Cast("nvinfer1::TopKOperation") int op);

    /**
     *  \brief Get the operation for the layer.
     * 
     *  @see setOperation(), TopKOperation
     *  */
    
    
    //!
    //!
    //!
    //!
    public native TopKOperation getOperation();

    /**
     *  \brief Set the k value for the layer.
     * 
     *  Currently only values up to 25 are supported.
     * 
     *  @see getK()
     *  */
    
    
    //!
    //!
    //!
    public native void setK(int k);

    /**
     *  \brief Get the k value for the layer.
     * 
     *  @see setK()
     *  */
    
    
    //!
    //!
    //!
    public native int getK();

    /**
     *  \brief Set which axes to reduce for the layer.
     * 
     *  @see getReduceAxes()
     *  */
    
    
    //!
    //!
    //!
    public native void setReduceAxes(@Cast("uint32_t") int reduceAxes);

    /**
     *  \brief Get the axes to reduce for the layer.
     * 
     *  @see setReduceAxes()
     *  */
    public native @Cast("uint32_t") int getReduceAxes();
}

/**
 *  \class IMatrixMultiplyLayer
 * 
 *  \brief Layer that represents a Matrix Multiplication.
 * 
 *  Let A be getInput(0) and B be getInput(1).
 * 
 *  Tensors A and B must have equal rank, which must be at least 2.
 * 
 *  When A and B are matrices, computes op(A) * op(B), where:
 *      op(x)=x            if transpose == false
 *      op(x)=transpose(x) if transpose == true
 *  Transposition is of the last two dimensions.
 *  Inputs of higher rank are treated as collections of matrices.
 * 
 *  For a dimension that is not one of the last two dimensions:
 *  If the dimension is 1 for one of the tensors but not the other tensor,
 *  the former tensor is broadcast along that dimension to match the dimension of the latter tensor.
 *  */
@Namespace("nvinfer1") public static class IMatrixMultiplyLayer extends ILayer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IMatrixMultiplyLayer(Pointer p) { super(p); }

    /**
     *  \brief Set the transpose flag for an input tensor.
     *  @param index Input tensor number (0 or 1).
     *  @param val New transpose flag.
     *  @see getTranspose()
     *  */
    
    
    //!
    //!
    public native void setTranspose(int index, @Cast("bool") boolean val);

    /**
     *  \brief Get the transpose flag for an input tensor.
     *  @param index Input tensor number (0 or 1).
     *  @see setTranspose()
     *  */
    public native @Cast("bool") boolean getTranspose(int index);
}

/**
 *  \class IRaggedSoftMaxLayer
 * 
 *  \brief A RaggedSoftmax layer in a network definition.
 * 
 *  This layer takes a ZxS input tensor and an additional Zx1 bounds tensor
 *  holding the lengths of the Z sequences.
 * 
 *  This layer computes a softmax across each of the Z sequences.
 * 
 *  The output tensor is of the same size as the input tensor.
 *  */
@Namespace("nvinfer1") public static class IRaggedSoftMaxLayer extends ILayer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IRaggedSoftMaxLayer(Pointer p) { super(p); }

}

/** \class IIdentityLayer
 * 
 *  \brief A layer that represents the identity function.
 * 
 *  If tensor precision is being explicitly specified, it can be used to transform from one precision to another.
 *  */
@Namespace("nvinfer1") public static class IIdentityLayer extends ILayer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IIdentityLayer(Pointer p) { super(p); }

}

/** \class IConstantLayer
 * 
 *  \brief Layer that represents a constant value.
 *  */
@Namespace("nvinfer1") public static class IConstantLayer extends ILayer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IConstantLayer(Pointer p) { super(p); }

    /**
     *  \brief Set the weights for the layer.
     * 
     *  @see getWeights()
     *  */
    
    
    //!
    //!
    //!
    public native void setWeights(@ByVal Weights weights);

    /**
     *  \brief Get the weights for the layer.
     * 
     *  @see setWeights
     *  */
    
    
    //!
    //!
    //!
    //!
    public native @ByVal Weights getWeights();

    /**
     *  \brief Set the dimensions for the layer.
     * 
     *  @param dimensions The dimensions of the layer
     * 
     *  @see setDimensions
     *  */
    
    
    //!
    //!
    //!
    //!
    public native void setDimensions(@ByVal Dims dimensions);

    /**
     *  \brief Get the dimensions for the layer.
     * 
     *  @return the dimensions for the layer
     * 
     *  @see getDimensions
     *  */
    public native @ByVal Dims getDimensions();
}

/**
 *  \class INetworkDefinition
 * 
 *  \brief A network definition for input to the builder.
 *  */
@Namespace("nvinfer1") public static class INetworkDefinition extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public INetworkDefinition(Pointer p) { super(p); }

    /**
     *  \brief Add an input tensor to the network.
     * 
     *  The name of the input tensor is used to find the index into the buffer array for an engine built from the network.
     * 
     *  @param name The name of the tensor.
     *  @param type The type of the data held in the tensor.
     *  @param dimensions The dimensions of the tensor.
     * 
     *  Only DataType::kFLOAT, DataType::kHALF and DataType::kINT32 are valid input tensor types.
     *  The volume of the dimensions, including the maximum batch size, must be less than 2^30 elements.
     * 
     *  @see ITensor
     * 
     *  @return The new tensor or nullptr if there is an error.
     *  */
    
    
    //!
    //!
    //!
    public native ITensor addInput(String name, DataType type, @ByVal Dims dimensions);
    public native ITensor addInput(@Cast("const char*") BytePointer name, @Cast("nvinfer1::DataType") int type, @ByVal Dims dimensions);

    /**
     *  \brief Mark a tensor as a network output.
     * 
     *  @param tensor The tensor to mark as an output tensor.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native void markOutput(@ByRef ITensor tensor);

    /**
     *  \brief Add a convolution layer to the network.
     * 
     *  @param input The input tensor to the convolution.
     *  @param nbOutputMaps The number of output feature maps for the convolution.
     *  @param kernelSize The HW-dimensions of the convolution kernel.
     *  @param kernelWeights The kernel weights for the convolution.
     *  @param biasWeights The optional bias weights for the convolution.
     * 
     *  @see IConvolutionLayer
     * 
     *  @return The new convolution layer, or null if it could not be created.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native IConvolutionLayer addConvolution(@ByRef ITensor input, int nbOutputMaps, @ByVal DimsHW kernelSize, @ByVal Weights kernelWeights, @ByVal Weights biasWeights);

    /**
     *  \brief Add a fully connected layer to the network.
     * 
     *  @param input The input tensor to the layer.
     *  @param nbOutputs The number of outputs of the layer.
     *  @param kernelWeights The kernel weights for the convolution.
     *  @param biasWeights The optional bias weights for the convolution.
     * 
     *  @see IFullyConnectedLayer
     * 
     *  @return The new fully connected layer, or null if it could not be created.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native IFullyConnectedLayer addFullyConnected(@ByRef ITensor input, int nbOutputs, @ByVal Weights kernelWeights, @ByVal Weights biasWeights);

    /**
     *  \brief Add an activation layer to the network.
     * 
     *  @param input The input tensor to the layer.
     *  @param type The type of activation function to apply.
     * 
     *  @see IActivationLayer ActivationType
     * 
     *  @return The new activation layer, or null if it could not be created.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native IActivationLayer addActivation(@ByRef ITensor input, ActivationType type);
    public native IActivationLayer addActivation(@ByRef ITensor input, @Cast("nvinfer1::ActivationType") int type);

    /**
     *  \brief Add a pooling layer to the network.
     * 
     *  @param input The input tensor to the layer.
     *  @param type The type of pooling to apply.
     *  @param windowSize The size of the pooling window.
     * 
     *  @see IPoolingLayer PoolingType
     * 
     *  @return The new pooling layer, or null if it could not be created.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native IPoolingLayer addPooling(@ByRef ITensor input, PoolingType type, @ByVal DimsHW windowSize);
    public native IPoolingLayer addPooling(@ByRef ITensor input, @Cast("nvinfer1::PoolingType") int type, @ByVal DimsHW windowSize);

    /**
     *  \brief Add a LRN layer to the network.
     * 
     *  @param input The input tensor to the layer.
     *  @param window The size of the window.
     *  @param alpha The alpha value for the LRN computation.
     *  @param beta The beta value for the LRN computation.
     *  @param k The k value for the LRN computation.
     * 
     *  @see ILRNLayer
     * 
     *  @return The new LRN layer, or null if it could not be created.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    public native ILRNLayer addLRN(@ByRef ITensor input, int window, float alpha, float beta, float k);

    /**
     *  \brief Add a Scale layer to the network.
     * 
     *  @param input The input tensor to The layer. This tensor is required to have a minimum of 3 dimensions.
     *  @param mode The scaling mode.
     *  @param shift The shift value.
     *  @param scale The scale value.
     *  @param power The power value.
     * 
     *  If the weights are available, then the size of weights are dependent on the on the ScaleMode.
     *  For ::kUNIFORM, the number of weights is equal to 1.
     *  For ::kCHANNEL, the number of weights is equal to the channel dimension.
     *  For ::kELEMENTWISE, the number of weights is equal to the volume of the input.
     * 
     *  @see IScaleLayer
     * 
     *  @return The new Scale layer, or null if it could not be created.
     *  */
    
    
    //!
    //!
    //!
    //!
    public native IScaleLayer addScale(@ByRef ITensor input, ScaleMode mode, @ByVal Weights shift, @ByVal Weights scale, @ByVal Weights power);
    public native IScaleLayer addScale(@ByRef ITensor input, @Cast("nvinfer1::ScaleMode") int mode, @ByVal Weights shift, @ByVal Weights scale, @ByVal Weights power);

    /**
     *  \brief Add a SoftMax layer to the network.
     * 
     *  @see ISoftMaxLayer
     * 
     *  @return The new SoftMax layer, or null if it could not be created.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    public native ISoftMaxLayer addSoftMax(@ByRef ITensor input);

    /**
     *  \brief Add a concatenation layer to the network.
     * 
     *  @param inputs The input tensors to the layer.
     *  @param nbInputs The number of input tensors.
     * 
     *  @see IConcatenationLayer
     * 
     *  @return The new concatenation layer, or null if it could not be created.
     * 
     *  \warning All tensors must have the same dimensions for all dimensions except for channel.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native IConcatenationLayer addConcatenation(@Cast("nvinfer1::ITensor*const*") PointerPointer inputs, int nbInputs);
    public native IConcatenationLayer addConcatenation(@ByPtrPtr ITensor inputs, int nbInputs);

    /**
     *  \brief Add a deconvolution layer to the network.
     * 
     *  @param input The input tensor to the layer.
     *  @param nbOutputMaps The number of output feature maps.
     *  @param kernelSize The HW-dimensions of the convolution kernel.
     *  @param kernelWeights The kernel weights for the convolution.
     *  @param biasWeights The optional bias weights for the convolution.
     * 
     *  @see IDeconvolutionLayer
     * 
     *  @return The new deconvolution layer, or null if it could not be created.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    public native IDeconvolutionLayer addDeconvolution(@ByRef ITensor input, int nbOutputMaps, @ByVal DimsHW kernelSize, @ByVal Weights kernelWeights, @ByVal Weights biasWeights);

    /**
     *  \brief Add an elementwise layer to the network.
     * 
     *  @param input1 The first input tensor to the layer.
     *  @param input2 The second input tensor to the layer.
     *  @param op The binary operation that the layer applies.
     * 
     *  The input tensors must have the same number of dimensions.
     *  For each dimension, their lengths must match, or one of them must be one.
     *  In the latter case, the tensor is broadcast along that axis.
     * 
     *  The output tensor has the same number of dimensions as the inputs.
     *  For each dimension, its length is the maximum of the lengths of the
     *  corresponding input dimension.
     * 
     *  @see IElementWiseLayer
     * 
     *  @return The new elementwise layer, or null if it could not be created.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    public native IElementWiseLayer addElementWise(@ByRef ITensor input1, @ByRef ITensor input2, ElementWiseOperation op);
    public native IElementWiseLayer addElementWise(@ByRef ITensor input1, @ByRef ITensor input2, @Cast("nvinfer1::ElementWiseOperation") int op);

    /**
     *  \brief Add an \p layerCount deep RNN layer to the network with a
     *  sequence length of \p maxSeqLen and \p hiddenSize internal state per
     *  layer.
     * 
     *  @param inputs The input tensor to the layer.
     *  @param layerCount The number of layers in the RNN.
     *  @param hiddenSize The size of the internal hidden state for each layer.
     *  @param maxSeqLen The maximum length of the time sequence.
     *  @param op The type of RNN to execute.
     *  @param mode The input mode for the RNN.
     *  @param dir The direction to run the RNN.
     *  @param weights The weights for the weight matrix parameters of the RNN.
     *  @param bias The weights for the bias vectors parameters of the RNN.
     * 
     *  The input tensors must be of the type DataType::kFLOAT or DataType::kHALF.
     * 
     *  See IRNNLayer::setWeights() and IRNNLayer::setBias() for details on the required input
     *  format for \p weights and \p bias.
     * 
     *  The layout for the \p input tensor should be {@code {1, S_max, N, E}}, where:
     *    - {@code S_max} is the maximum allowed sequence length (number of RNN iterations)
     *    - {@code N} is the batch size
     *    - {@code E} specifies the embedding length (unless ::kSKIP is set, in which case it should match
     *      getHiddenSize()).
     * 
     *  The first output tensor is the output of the final RNN layer across all timesteps, with dimensions
     *  {@code {S_max, N, H}}:
     * 
     *    - {@code S_max} is the maximum allowed sequence length (number of RNN iterations)
     *    - {@code N} is the batch size
     *    - {@code H} is an output hidden state (equal to getHiddenSize() or 2x getHiddenSize())
     * 
     *  The second tensor is the final hidden state of the RNN across all layers, and if the RNN
     *  is an LSTM (i.e. getOperation() is ::kLSTM), then the third tensor is the final cell
     *  state of the RNN across all layers.  Both the second and third output tensors have dimensions
     *  {@code {L, N, H}}:
     * 
     *   - {@code L} is equal to getLayerCount() if getDirection is ::kUNIDIRECTION,
     *      and 2*getLayerCount() if getDirection is ::kBIDIRECTION.  In the bi-directional
     *      case, layer {@code l}'s final forward hidden state is stored in {@code L = 2*l}, and
     *      final backward hidden state is stored in {@code L = 2*l + 1}.
     *   - {@code N} is the batch size
     *   - {@code H} is getHiddenSize().
     * 
     *  Note that in bidirectional RNNs, the full "hidden state" for a layer {@code l}
     *  is the concatenation of its forward hidden state and its backward hidden
     *  state, and its size is 2*H.
     * 
     *  @deprecated IRNNLayer is superseded by IRNNv2Layer. Use addRNNv2() instead.
     * 
     *  @return The new RNN layer, or null if it could not be created.
     *  @see IRNNLayer
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native IRNNLayer addRNN(@ByRef ITensor inputs, int layerCount, @Cast("std::size_t") long hiddenSize, int maxSeqLen, RNNOperation op, RNNInputMode mode, RNNDirection dir, @ByVal Weights weights, @ByVal Weights bias);
    public native IRNNLayer addRNN(@ByRef ITensor inputs, int layerCount, @Cast("std::size_t") long hiddenSize, int maxSeqLen, @Cast("nvinfer1::RNNOperation") int op, @Cast("nvinfer1::RNNInputMode") int mode, @Cast("nvinfer1::RNNDirection") int dir, @ByVal Weights weights, @ByVal Weights bias);

    /**
     *  \brief Add a plugin layer to the network.
     * 
     *  @param inputs The input tensors to the layer.
     *  @param nbInputs The number of input tensors.
     *  @param plugin The layer plugin.
     * 
     *  @see IPluginLayer
     * 
     *  @return the new plugin layer, or null if it could not be created.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native IPluginLayer addPlugin(@Cast("nvinfer1::ITensor*const*") PointerPointer inputs, int nbInputs, @ByRef IPlugin plugin);
    public native IPluginLayer addPlugin(@ByPtrPtr ITensor inputs, int nbInputs, @ByRef IPlugin plugin);

    /**
     *  \brief Add a unary layer to the network.
     * 
     *  @param input The input tensor to the layer.
     *  @param operation The operation to apply.
     * 
     *  @see IUnaryLayer
     * 
     *  @return The new unary layer, or null if it could not be created
     *  */
    
    //!
    //!
    //!
    //!
    public native IUnaryLayer addUnary(@ByRef ITensor input, UnaryOperation operation);
    public native IUnaryLayer addUnary(@ByRef ITensor input, @Cast("nvinfer1::UnaryOperation") int operation);

    /** \brief Add a padding layer to the network.
     * 
     *  @param input The input tensor to the layer.
     *  @param prePadding The padding to apply to the start of the tensor.
     *  @param postPadding The padding to apply to the end of the tensor.
     * 
     *  @see IPaddingLayer
     * 
     *  @return the new padding layer, or null if it could not be created.
     *  */
    
    
    //!
    //!
    //!
    //!
    public native IPaddingLayer addPadding(@ByRef ITensor input, @ByVal DimsHW prePadding, @ByVal DimsHW postPadding);

    /**
     *  \brief Add a shuffle layer to the network.
     * 
     *  @param input The input tensor to the layer.
     * 
     *  @return The new shuffle layer, or null if it could not be created.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native IShuffleLayer addShuffle(@ByRef ITensor input);

    /**
     *  \brief Set the pooling output dimensions formula.
     * 
     *  @param formula The formula from computing the pooling output dimensions. If null is passed, the default formula is used.
     * 
     *  The default formula in each dimension is (inputDim + padding * 2 - kernelSize) / stride + 1.
     * 
     *  @see IOutputDimensionsFormula getPoolingOutputDimensionsFormula()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native void setPoolingOutputDimensionsFormula(IOutputDimensionsFormula formula);

    /**
     *  \brief Get the pooling output dimensions formula.
     * 
     *  @return The formula from computing the pooling output dimensions.
     * 
     *  @see IOutputDimensionsFormula setPoolingOutputDimensionsFormula()
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    public native @ByRef IOutputDimensionsFormula getPoolingOutputDimensionsFormula();

    /**
     *  \brief Set the convolution output dimensions formula.
     * 
     *  @deprecated This method does not currently work reliably and will be removed in a future release.
     * 
     *  @param formula The formula from computing the convolution output dimensions. If null is passed, the default formula is used.
     * 
     *  The default formula in each dimension is (inputDim + padding * 2 - kernelSize) / stride + 1.
     * 
     *  @see IOutputDimensionsFormula getConvolutionOutputDimensionsFormula()
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native void setConvolutionOutputDimensionsFormula(IOutputDimensionsFormula formula);

    /**
     *  \brief Get the convolution output dimensions formula.
     * 
     *  @deprecated This method does not currently work reliably and will be removed in a future release.
     * 
     *  @return The formula from computing the convolution output dimensions.
     * 
     *  @see IOutputDimensionsFormula setConvolutionOutputDimensionsFormula()
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    public native @ByRef IOutputDimensionsFormula getConvolutionOutputDimensionsFormula();

    /**
     *  \brief Set the deconvolution output dimensions formula.
     * 
     *  @deprecated This method does not currently work reliably and will be removed in a future release.
     * 
     *  @param formula The formula from computing the deconvolution output dimensions. If null is passed, the default formula is used.
     * 
     *  The default formula in each dimension is (inputDim - 1) * stride + kernelSize - 2 * padding.
     * 
     *  @see IOutputDimensionsFormula getDevonvolutionOutputDimensionsFormula()
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native void setDeconvolutionOutputDimensionsFormula(IOutputDimensionsFormula formula);

    /**
     *  \brief Get the deconvolution output dimensions formula.
     * 
     *  @return The formula from computing the deconvolution output dimensions.
     * 
     *  @deprecated This method does not currently work reliably and will be removed in a future release.
     * 
     *  @see IOutputDimensionsFormula setDeconvolutionOutputDimensionsFormula()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native @ByRef IOutputDimensionsFormula getDeconvolutionOutputDimensionsFormula();

    /**
     *  \brief Get the number of layers in the network.
     * 
     *  @return The number of layers in the network.
     * 
     *  @see getLayer()
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native int getNbLayers();

    /**
     *  \brief Get the layer specified by the given index.
     * 
     *  @param index The index of the layer.
     * 
     *  @return The layer, or null if the index is out of range.
     * 
     *  @see getNbLayers()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native ILayer getLayer(int index);

    /**
     *  \brief Get the number of inputs in the network.
     * 
     *  @return The number of inputs in the network.
     * 
     *  @see getInput()
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native int getNbInputs();

    /**
     *  \brief Get the input tensor specified by the given index.
     * 
     *  @param index The index of the input tensor.
     * 
     *  @return The input tensor, or null if the index is out of range.
     * 
     *  @see getNbInputs()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native ITensor getInput(int index); // adding inputs invalidates indexing here

    /**
     *  \brief Get the number of outputs in the network.
     * 
     *  @return The number of outputs in the network.
     * 
     *  @see getOutput()
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native int getNbOutputs();

    /**
     *  \brief Get the output tensor specified by the given index.
     * 
     *  @param index The index of the output tensor.
     * 
     *  @return The output tensor, or null if the index is out of range.
     * 
     *  @see getNbOutputs()
     *  */
    
    
    //!
    //!
    public native ITensor getOutput(int index); // adding outputs invalidates indexing here

    /**
     *  \brief Destroy this INetworkDefinition object.
     *  */
    public native void destroy();
    /**
     *  \brief Add a reduce layer to the network.
     * 
     *  @param input The input tensor to the layer.
     *  @param operation The reduction operation to perform.
     *  @param reduceAxes The reduction dimensions.
     *         Bit 0 of the uint32_t type corresponds to the non-batch dimension 0 boolean and so on.
     *         If a bit is set, then the corresponding dimension will be reduced.
     *         Let's say we have an NCHW tensor as input (three non-batch dimensions).
     *         Bit 0 corresponds to the C dimension boolean.
     *         Bit 1 corresponds to the H dimension boolean.
     *         Bit 2 corresponds to the W dimension boolean.
     *         Note that reduction is not permitted over the batch size dimension.
     *  @param keepDimensions The boolean that specifies whether or not to keep the reduced dimensions in the output of the layer.
     * 
     *  @see IReduceLayer
     * 
     *  @return The new reduce layer, or null if it could not be created.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    public native IReduceLayer addReduce(@ByRef ITensor input, ReduceOperation operation, @Cast("uint32_t") int reduceAxes, @Cast("bool") boolean keepDimensions);
    public native IReduceLayer addReduce(@ByRef ITensor input, @Cast("nvinfer1::ReduceOperation") int operation, @Cast("uint32_t") int reduceAxes, @Cast("bool") boolean keepDimensions);

    /**
     *  \brief Add a TopK layer to the network.
     * 
     *  The TopK layer has two outputs of the same dimensions. The first contains data values,
     *  the second contains index positions for the values. Output values are sorted, largest first
     *  for operation kMAX and smallest first for operation kMIN.
     * 
     *  Currently only values of K up to 1024 are supported.
     * 
     *  @param input The input tensor to the layer.
     * 
     *  @param op Operation to perform.
     * 
     *  @param k Number of elements to keep.
     * 
     *  @param reduceAxes The reduction dimensions.
     *         Bit 0 of the uint32_t type corresponds to the non-batch dimension 0 boolean and so on.
     *         If a bit is set, then the corresponding dimension will be reduced.
     *         Let's say we have an NCHW tensor as input (three non-batch dimensions).
     *         Bit 0 corresponds to the C dimension boolean.
     *         Bit 1 corresponds to the H dimension boolean.
     *         Bit 2 corresponds to the W dimension boolean.
     *         Note that TopK reduction is currently only permitted over one dimension.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native ITopKLayer addTopK(@ByRef ITensor input, TopKOperation op, int k, @Cast("uint32_t") int reduceAxes);
    public native ITopKLayer addTopK(@ByRef ITensor input, @Cast("nvinfer1::TopKOperation") int op, int k, @Cast("uint32_t") int reduceAxes);

    /**
     *  \brief Add a gather layer to the network.
     * 
     *  @param data The tensor to gather values from.
     *  @param indices The tensor to get indices from to populate the output tensor.
     *  @param axis The non-batch dimension axis in the data tensor to gather on.
     * 
     *  @see IGatherLayer
     * 
     *  @return The new gather layer, or null if it could not be created.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native IGatherLayer addGather(@ByRef ITensor data, @ByRef ITensor indices, int axis);

    /**
     *  \brief Add a RaggedSoftMax layer to the network.
     * 
     *  @param input The ZxS input tensor.
     *  @param bounds The Zx1 bounds tensor.
     * 
     *  @see IRaggedSoftMaxLayer
     * 
     *  @return The new RaggedSoftMax layer, or null if it could not be created.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native IRaggedSoftMaxLayer addRaggedSoftMax(@ByRef ITensor input, @ByRef ITensor bounds);

    /**
     *  \brief Add a MatrixMultiply layer to the network.
     * 
     *  @param input0 The first input tensor (commonly A).
     *  @param transpose0 If true, op(input0)=transpose(input0), else op(input0)=input0.
     *  @param input1 The second input tensor (commonly B).
     *  @param transpose1 If true, op(input1)=transpose(input1), else op(input1)=input1.
     * 
     *  @see IMatrixMultiplyLayer
     * 
     *  @return The new matrix multiply layer, or null if it could not be created.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native IMatrixMultiplyLayer addMatrixMultiply(@ByRef ITensor input0, @Cast("bool") boolean transpose0, @ByRef ITensor input1, @Cast("bool") boolean transpose1);

    /**
     *  \brief Add a constant layer to the network.
     * 
     *  @param dimensions The dimensions of the constant.
     *  @param weights The constant value, represented as weights.
     * 
     *  @see IConstantLayer
     * 
     *  @return The new constant layer, or null if it could not be created.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    public native IConstantLayer addConstant(@ByVal Dims dimensions, @ByVal Weights weights);

    /**
     *  \brief Add an \p layerCount deep RNN layer to the network with \p hiddenSize internal states that can
     *  take a batch with fixed or variable sequence lengths.
     * 
     *  @param input The input tensor to the layer (see below).
     *  @param layerCount The number of layers in the RNN.
     *  @param hiddenSize Size of the internal hidden state for each layer.
     *  @param maxSeqLen Maximum sequence length for the input.
     *  @param op The type of RNN to execute.
     * 
     *  By default, the layer is configured with RNNDirection::kUNIDIRECTION and RNNInputMode::kLINEAR.
     *  To change these settings, use IRNNv2Layer::setDirection() and IRNNv2Layer::setInputMode().
     * 
     *  %Weights and biases for the added layer should be set using
     *  IRNNv2Layer::setWeightsForGate() and IRNNv2Layer::setBiasForGate() prior
     *  to building an engine using this network.
     * 
     *  The input tensors must be of the type DataType::kFLOAT or DataType::kHALF.
     *  The layout of the weights is row major and must be the same datatype as the input tensor.
     *  \p weights contain 8 matrices and \p bias contains 8 vectors.
     * 
     *  See IRNNv2Layer::setWeightsForGate() and IRNNv2Layer::setBiasForGate() for details on the required input
     *  format for \p weights and \p bias.
     * 
     *  The \p input ITensor should contain zero or more index dimensions {@code {N1, ..., Np}}, followed by
     *  two dimensions, defined as follows:
     *    - {@code S_max} is the maximum allowed sequence length (number of RNN iterations)
     *    - {@code E} specifies the embedding length (unless ::kSKIP is set, in which case it should match
     *      getHiddenSize()).
     * 
     *  By default, all sequences in the input are assumed to be size \p maxSeqLen.  To provide explicit sequence
     *  lengths for each input sequence in the batch, use IRNNv2Layer::setSequenceLengths().
     * 
     *  The RNN layer outputs up to three tensors.
     * 
     *  The first output tensor is the output of the final RNN layer across all timesteps, with dimensions
     *  {@code {N1, ..., Np, S_max, H}}:
     * 
     *    - {@code N1..Np} are the index dimensions specified by the input tensor
     *    - {@code S_max} is the maximum allowed sequence length (number of RNN iterations)
     *    - {@code H} is an output hidden state (equal to getHiddenSize() or 2x getHiddenSize())
     * 
     *  The second tensor is the final hidden state of the RNN across all layers, and if the RNN
     *  is an LSTM (i.e. getOperation() is ::kLSTM), then the third tensor is the final cell state
     *  of the RNN across all layers.  Both the second and third output tensors have dimensions
     *  {@code {N1, ..., Np, L, H}}:
     * 
     *   - {@code N1..Np} are the index dimensions specified by the input tensor
     *   - {@code L} is the number of layers in the RNN, equal to getLayerCount()
     *   - {@code H} is the hidden state for each layer, equal to getHiddenSize() if getDirection is ::kUNIDIRECTION, and 2x getHiddenSize() otherwise.
     * 
     *  @return The new RNN layer, or null if it could not be created.
     *  @see IRNNv2Layer
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native IRNNv2Layer addRNNv2(@ByRef ITensor input, int layerCount, int hiddenSize, int maxSeqLen, RNNOperation op);
    public native IRNNv2Layer addRNNv2(@ByRef ITensor input, int layerCount, int hiddenSize, int maxSeqLen, @Cast("nvinfer1::RNNOperation") int op);

    /**
     *  \brief Add a plugin layer to the network using an IPluginExt interface.
     * 
     *  @param inputs The input tensors to the layer.
     *  @param nbInputs The number of input tensors.
     *  @param plugin The layer plugin.
     * 
     *  @return The new plugin layer, or null if it could not be created.
     * 
     *  @see IPluginLayer
     *  */
    
    
    //!
    //!
    //!
    //!
    public native IPluginLayer addPluginExt(@Cast("nvinfer1::ITensor*const*") PointerPointer inputs, int nbInputs, @ByRef IPluginExt plugin);
    public native IPluginLayer addPluginExt(@ByPtrPtr ITensor inputs, int nbInputs, @ByRef IPluginExt plugin);

    /**
     *  \brief Add an identity layer.
     * 
     *  @param input The input tensor to the layer.
     * 
     *  @return The new plugin layer, or null if it could not be created.
     *  */
    
    
    //!
    //!
    //!
    //!
    public native IIdentityLayer addIdentity(@ByRef ITensor input);

    /**
     *  \brief remove a tensor from the network definition.
     * 
     *  @param tensor the tensor to remove
     * 
     *  it is illegal to remove a tensor that is the input or output of a layer.
     *  if this method is called with such a tensor, a warning will be emitted on the log
     *  and the call will be ignored.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native void removeTensor(@ByRef ITensor tensor);

    /**
     *  \brief unmark a tensor as a network output.
     * 
     *  @param tensor The tensor to unmark as an output tensor.
     * 
     *  see markOutput()
     * 
     *  */
    public native void unmarkOutput(@ByRef ITensor tensor);
}

/**
 *  \class IProfiler
 * 
 *  \brief Application-implemented interface for profiling.
 * 
 *  When this class is added to an execution context, the profiler will be called once per layer for each invocation of execute().
 *  Note that enqueue() does not currently support profiling.
 * 
 *  The profiler will only be called after execution is complete. It has a small impact on execution time.
 *  */
@Namespace("nvinfer1") public static class IProfiler extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IProfiler(Pointer p) { super(p); }

    /**
     *  \brief Layer time reporting callback.
     * 
     *  @param layerName The name of the layer, set when constructing the network definition.
     *  @param ms The time in milliseconds to execute the layer.
     *  */
    @Virtual(true) public native void reportLayerTime(String layerName, float ms);
    
    /** Default native constructor. */
    public IProfiler() { super((Pointer)null); allocate(); }
    private native void allocate();
}

/**
 *  \class IExecutionContext
 * 
 *  \brief Context for executing inference using an engine.
 * 
 *  Multiple execution contexts may exist for one ICudaEngine instance, allowing the same
 *  engine to be used for the execution of multiple batches simultaneously.
 *  */
@Namespace("nvinfer1") public static class IExecutionContext extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IExecutionContext(Pointer p) { super(p); }

    /**
     *  \brief Synchronously execute inference on a batch.
     * 
     *  This method requires a array of input and output buffers. The mapping from tensor names to indices can be queried using ICudaEngine::getBindingIndex()
     *  @param batchSize The batch size. This is at most the value supplied when the engine was built.
     *  @param bindings An array of pointers to input and output buffers for the network.
     * 
     *  @return True if execution succeeded.
     * 
     *  @see ICudaEngine::getBindingIndex() ICudaEngine::getMaxBatchSize()
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native @Cast("bool") boolean execute(int batchSize, @Cast("void**") PointerPointer bindings);
    public native @Cast("bool") boolean execute(int batchSize, @Cast("void**") @ByPtrPtr Pointer bindings);

    /**
     *  \brief Asynchronously execute inference on a batch.
     * 
     *  This method requires a array of input and output buffers. The mapping from tensor names to indices can be queried using ICudaEngine::getBindingIndex()
     *  @param batchSize The batch size. This is at most the value supplied when the engine was built.
     *  @param bindings An array of pointers to input and output buffers for the network.
     *  @param stream A cuda stream on which the inference kernels will be enqueued
     *  @param inputConsumed An optional event which will be signaled when the input buffers can be refilled with new data
     * 
     *  @return True if the kernels were enqueued successfully.
     * 
     *  @see ICudaEngine::getBindingIndex() ICudaEngine::getMaxBatchSize()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native @Cast("bool") boolean enqueue(int batchSize, @Cast("void**") PointerPointer bindings, CUstream_st stream, @ByPtrPtr CUevent_st inputConsumed);
    public native @Cast("bool") boolean enqueue(int batchSize, @Cast("void**") @ByPtrPtr Pointer bindings, CUstream_st stream, @ByPtrPtr CUevent_st inputConsumed);

    /**
     *  \brief Set the debug sync flag.
     * 
     *  If this flag is set to true, the engine will log the successful execution for each kernel during execute(). It has no effect when using enqueue().
     * 
     *  @see getDebugSync()
     *  */
    
    
    //!
    //!
    //!
    public native void setDebugSync(@Cast("bool") boolean sync);

    /**
     *  \brief Get the debug sync flag.
     * 
     *  @see setDebugSync()
     *  */
    
    
    //!
    //!
    //!
    public native @Cast("bool") boolean getDebugSync();

    /**
     *  \brief Set the profiler.
     * 
     *  @see IProfiler getProfiler()
     *  */
    
    
    //!
    //!
    //!
    public native void setProfiler(IProfiler arg0);

    /**
     *  \brief Get the profiler.
     * 
     *  @see IProfiler setProfiler()
     *  */
    
    
    //!
    //!
    //!
    public native IProfiler getProfiler();

    /**
     *  \brief Get the associated engine.
     * 
     *  @see ICudaEngine
     *  */
    
    
    //!
    //!
    public native @Const @ByRef ICudaEngine getEngine();

    /**
     *  \brief Destroy this object.
     *  */
    public native void destroy();
    /**
     *  \brief Set the name of the execution context.
     * 
     *  This method copies the name string.
     * 
     *  @see getName()
     *  */
    
    
    //!
    //!
    //!
    public native void setName(String name);
    public native void setName(@Cast("const char*") BytePointer name);

    /**
     *  \brief Return the name of the execution context.
     * 
     *  @see setName()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native String getName();

    /**
     *  \brief set the device memory for use by this execution context.
     * 
     *  The memory must be aligned with cuda memory alignment property (using cudaGetDeviceProperties()), and its size must be at least that
     *  returned by getDeviceMemorySize(). If using enqueue() to run the network, The memory is in
     *  use from the invocation of enqueue() until network execution is complete. If using execute(),
     *  it is in use until execute() returns. Releasing or otherwise using the memory for other
     *  purposes during this time will result in undefined behavior.
     * 
     *  @see ICudaEngine::getDeviceMemorySize() ICudaEngine::createExecutionContextWithoutDeviceMemory()
     *  */
    public native void setDeviceMemory(Pointer memory);
}

/**
 *  \class ICudaEngine
 * 
 *  \brief An engine for executing inference on a built network.
 *  */
@Namespace("nvinfer1") public static class ICudaEngine extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ICudaEngine(Pointer p) { super(p); }

    /**
     *  \brief Get the number of binding indices.
     * 
     *  @see getBindingIndex();
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    public native int getNbBindings();

    /**
     *  \brief Retrieve the binding index for a named tensor.
     * 
     *  IExecutionContext::enqueue() and IExecutionContext::execute() require an array of buffers.
     * 
     *  Engine bindings map from tensor names to indices in this array.
     *  Binding indices are assigned at engine build time, and take values in the range [0 ... n-1] where n is the total number of inputs and outputs.
     * 
     *  @param name The tensor name.
     *  @return The binding index for the named tensor, or -1 if the name is not found.
     * 
     *  see getNbBindings() getBindingIndex()
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native int getBindingIndex(String name);
    public native int getBindingIndex(@Cast("const char*") BytePointer name);

    /**
     *  \brief Retrieve the name corresponding to a binding index.
     * 
     *  This is the reverse mapping to that provided by getBindingIndex().
     * 
     *  @param bindingIndex The binding index.
     *  @return The name corresponding to the index, or nullptr if the index is out of range.
     * 
     *  @see getBindingIndex()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native String getBindingName(int bindingIndex);

    /**
     *  \brief Determine whether a binding is an input binding.
     * 
     *  @param bindingIndex The binding index.
     *  @return True if the index corresponds to an input binding and the index is in range.
     * 
     *  @see getBindingIndex()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native @Cast("bool") boolean bindingIsInput(int bindingIndex);

    /**
     *  \brief Get the dimensions of a binding.
     * 
     *  @param bindingIndex The binding index.
     *  @return The dimensions of the binding if the index is in range, otherwise (0,0,0).
     * 
     *  @see getBindingIndex()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native @ByVal Dims getBindingDimensions(int bindingIndex);

    /**
     *  \brief Determine the required data type for a buffer from its binding index.
     * 
     *  @param bindingIndex The binding index.
     *  @return The type of the data in the buffer.
     * 
     *  @see getBindingIndex()
     *  */
    
    
    //!
    //!
    //!
    public native DataType getBindingDataType(int bindingIndex);

    /**
     *  \brief Get the maximum batch size which can be used for inference.
     * 
     *  @return The maximum batch size for this engine.
     *  */
    
    
    //!
    //!
    //!
    //!
    public native int getMaxBatchSize();

    /**
     *  \brief Get the number of layers in the network.
     * 
     *  The number of layers in the network is not necessarily the number in the original network definition, as layers may be combined or eliminated as the engine is
     *  optimized. This value can be useful when building per-layer tables, such as when aggregating profiling data over a number of executions.
     * 
     *  @return The number of layers in the network.
     *  */
    
    
    //!
    //!
    //!
    public native int getNbLayers();

    /**
     *  \brief Get the amount of workspace the engine uses.
     * 
     *  The workspace size will be no greater than the value provided to the builder when the engine was built, and will typically be smaller.
     *  Workspace will be allocated for each execution context.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native @Cast("std::size_t") long getWorkspaceSize();

    /**
     *  \brief Serialize the network to a stream.
     * 
     *  @return A IHostMemory object that contains the serialized engine.
     * 
     *  The network may be deserialized with IRuntime::deserializeCudaEngine()
     * 
     *  @see IRuntime::deserializeCudaEngine()
     *  */
    
    
    //!
    //!
    //!
    public native IHostMemory serialize();

    /**
     *  \brief Create an execution context.
     * 
     *  @see IExecutionContext.
     *  */
    
    
    //!
    //!
    public native IExecutionContext createExecutionContext();

    /**
     *  \brief Destroy this object;
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native void destroy();

    /**
     *  \brief Get location of binding
     * 
     *  This lets you know whether the binding should be a pointer to device or host memory.
     * 
     *  @see ITensor::setLocation() ITensor::getLocation()
     * 
     *  @param bindingIndex The binding index.
     *  @return The location of the bound tensor with given index.
     *  */
    public native TensorLocation getLocation(int bindingIndex);
    /**
     *  \brief create an execution context without any device memory allocated
     * 
     *  The memory for execution of this device context must be supplied by the application.
     * 
     *  @see getDeviceMemorySize() IExecutionContext::setDeviceMemory()
     *  */
    
    
    //!
    //!
    //!
    public native IExecutionContext createExecutionContextWithoutDeviceMemory();

    /**
     *  \brief Return the amount of device memory required by an execution context.
     * 
     *  @see IExecutionContext::setDeviceMemory()
     *  */
    public native @Cast("size_t") long getDeviceMemorySize();
}

/**
 *  enum CalibrationAlgoType
 * 
 *  \brief Version of calibration algorithm to use.
 *  */
@Namespace("nvinfer1") public enum CalibrationAlgoType {
    kLEGACY_CALIBRATION(0),
    kENTROPY_CALIBRATION(1);

    public final int value;
    private CalibrationAlgoType(int v) { this.value = v; }
    private CalibrationAlgoType(CalibrationAlgoType e) { this.value = e.value; }
    public CalibrationAlgoType intern() { for (CalibrationAlgoType e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}



/**
 *  \class IInt8Calibrator
 * 
 *  \brief Application-implemented interface for calibration.
 * 
 *  Calibration is a step performed by the builder when deciding suitable scale factors for 8-bit inference.
 * 
 *  It must also provide a method for retrieving representative images which the calibration process can use to examine
 *  the distribution of activations. It may optionally implement a method for caching the calibration result for reuse
 *  on subsequent runs.
 *  */
@Namespace("nvinfer1") public static class IInt8Calibrator extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IInt8Calibrator(Pointer p) { super(p); }

    /**
     *  \brief Get the batch size used for calibration batches.
     * 
     *  @return The batch size.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    public native int getBatchSize();

    /**
     *  \brief Get a batch of input for calibration.
     * 
     *  The batch size of the input must match the batch size returned by getBatchSize().
     * 
     *  @param bindings An array of pointers to device memory that must be set to the memory containing each network input data.
     *  @param names The names of the network input for each pointer in the binding array.
     *  @param nbBindings The number of pointers in the bindings array.
     *  @return False if there are no more batches for calibration.
     * 
     * 
     *  @see getBatchSize()
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native @Cast("bool") boolean getBatch(@Cast("void**") PointerPointer bindings, @Cast("const char**") PointerPointer names, int nbBindings);
    public native @Cast("bool") boolean getBatch(@Cast("void**") @ByPtrPtr Pointer bindings, @Cast("const char**") @ByPtrPtr BytePointer names, int nbBindings);
    public native @Cast("bool") boolean getBatch(@Cast("void**") @ByPtrPtr Pointer bindings, @Cast("const char**") @ByPtrPtr ByteBuffer names, int nbBindings);
    public native @Cast("bool") boolean getBatch(@Cast("void**") @ByPtrPtr Pointer bindings, @Cast("const char**") @ByPtrPtr byte[] names, int nbBindings); // get a pointer to the input batch

    /**
     *  \brief Load a calibration cache.
     * 
     *  Calibration is potentially expensive, so it can be useful to generate the calibration data once, then use it on subsequent builds
     *  of the network. The cache includes the regression cutoff and quantile values used to generate it, and will not be used if
     *  these do not batch the settings of the current calibrator. However, the network should also be recalibrated if its structure
     *  changes, or the input data set changes, and it is the responsibility of the application to ensure this.
     * 
     *  @param length The length of the cached data, that should be set by the called function. If there is no data, this should be zero.
     * 
     *  @return A pointer to the cache, or nullptr if there is no data.
     *  */
    
    
    //!
    //!
    //!
    //!
    public native @Const Pointer readCalibrationCache(@Cast("std::size_t*") @ByRef LongPointer length);
    public native @Const Pointer readCalibrationCache(@Cast("std::size_t*") @ByRef LongBuffer length);
    public native @Const Pointer readCalibrationCache(@Cast("std::size_t*") @ByRef long[] length);

    /**
     *  \brief Save a calibration cache.
     * 
     *  @param ptr A pointer to the data to cache.
     *  @param length The length in bytes of the data to cache.
     * 
     *  @see readCalibrationCache()
     *  */
    
    
    //!
    //!
    //!
    public native void writeCalibrationCache(@Const Pointer ptr, @Cast("std::size_t") long length);

    /**
     *  \brief Get the algorithm used by this calibrator.
     * 
     *  @return The algorithm used by the calibrator.
     *  */
    public native CalibrationAlgoType getAlgorithm();
}

/**
 *  Entropy calibrator. This is the preferred calibrator, as it is less complicated than the legacy calibrator and produces better results.
 *  */
@Namespace("nvinfer1") public static class IInt8EntropyCalibrator extends IInt8Calibrator {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IInt8EntropyCalibrator(Pointer p) { super(p); }

    /**
     *  Signal that this is the entropy calibrator.
     *  */
    public native CalibrationAlgoType getAlgorithm();
}

/**
 *  Legacy calibrator for compatibility with 2.0 EA. Will be removed in 2.2.
 *  @deprecated
 *  */
@Namespace("nvinfer1") public static class IInt8LegacyCalibrator extends IInt8Calibrator {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IInt8LegacyCalibrator(Pointer p) { super(p); }

    /**
     *  Signal that this is the legacy calibrator.
     *  */
    
    
    //!
    //!
    //!
    public native CalibrationAlgoType getAlgorithm();

    /**
     *  \brief The quantile (between 0 and 1) that will be used to select the region maximum when the quantile method is in use.
     * 
     *  See the user guide for more details on how the quantile is used.
     *  */
    
    
    //!
    //!
    //!
    public native double getQuantile();

    /**
     *  \brief The fraction (between 0 and 1) of the maximum used to define the regression cutoff when using regression to determine the region maximum.
     * 
     *  See the user guide for more details on how the regression cutoff is used
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native double getRegressionCutoff();

    /**
     *  \brief Load a histogram.
     * 
     *  Histogram generation is potentially expensive, so it can be useful to generate the histograms once, then use them when exploring
     *  the space of calibrations. The histograms should be regenerated if the network structure
     *  changes, or the input data set changes, and it is the responsibility of the application to ensure this.
     * 
     *  @param length The length of the cached data, that should be set by the called function. If there is no data, this should be zero.
     * 
     *  @return A pointer to the cache, or nullptr if there is no data.
     *  */
    
    
    //!
    //!
    //!
    //!
    public native @Const Pointer readHistogramCache(@Cast("std::size_t*") @ByRef LongPointer length);
    public native @Const Pointer readHistogramCache(@Cast("std::size_t*") @ByRef LongBuffer length);
    public native @Const Pointer readHistogramCache(@Cast("std::size_t*") @ByRef long[] length);

    /**
     *  \brief Save a histogram cache.
     * 
     *  @param ptr A pointer to the data to cache.
     *  @param length The length in bytes of the data to cache.
     * 
     *  @see readHistogramCache()
     *  */
    public native void writeHistogramCache(@Const Pointer ptr, @Cast("std::size_t") long length);
}

/**
 *  \class IGpuAllocator
 * 
 *  \brief Application-implemented class for controlling allocation on the GPU.
 *  */
@Namespace("nvinfer1") public static class IGpuAllocator extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IGpuAllocator(Pointer p) { super(p); }

    /**
     *  A callback implemented by the application to handle acquisition of GPU memory.
     * 
     *  @param size The size of the memory required.
     *  @param alignment The required alignment of memory. Alignment will zero
     *         or a power of 2 not exceeding the alignment guaranteed by cudaMalloc.
     *         Thus this allocator can be safely implemented with cudaMalloc/cudaFree.
     *         An alignment value of zero indicates any alignment is acceptable.
     *  @param flags Reserved for future use. In the current release, 0 will be passed.
     * 
     *  If an allocation request of size 0 is made, nullptr should be returned.
     * 
     *  If an allocation request cannot be satisfied, nullptr should be returned.
     *  */
    
    
    //!
    //!
    //!
    //!
    public native @Name("allocate") Pointer _allocate(@Cast("uint64_t") long size, @Cast("uint64_t") long alignment, @Cast("uint32_t") int flags);

    /**
     *  A callback implemented by the application to handle release of GPU memory.
     * 
     *  TensorRT may pass a nullptr to this function if it was previously returned by allocate().
     * 
     *  @param memory The acquired memory.
     *  */
    public native @Name("free") void _free(Pointer memory);
}

/**
 *  \class IBuilder
 * 
 *  \brief Builds an engine from a network definition.
 *  */
@Namespace("nvinfer1") public static class IBuilder extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IBuilder(Pointer p) { super(p); }

    /**
     *  \brief Create a network definition object.
     * 
     *  @see INetworkDefinition
     *  */
    
    
    //!
    //!
    //!
    //!
    public native INetworkDefinition createNetwork();

    /**
     *  \brief Set the maximum batch size.
     * 
     *  @param batchSize The maximum batch size which can be used at execution time, and also the batch size for which the engine will be optimized.
     * 
     *  @see getMaxBatchSize()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native void setMaxBatchSize(int batchSize);

    /**
     *  \brief Get the maximum batch size.
     * 
     *  @return The maximum batch size.
     * 
     *  @see setMaxBatchSize()
     *  @see getMaxDLABatchSize()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native int getMaxBatchSize();

    /**
     *  \brief Set the maximum workspace size.
     * 
     *  @param workspaceSize The maximum GPU temporary memory which the engine can use at execution time.
     * 
     *  @see getMaxWorkspaceSize()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native void setMaxWorkspaceSize(@Cast("std::size_t") long workspaceSize);

    /**
     *  \brief Get the maximum workspace size.
     * 
     *  @return The maximum workspace size.
     * 
     *  @see setMaxWorkspaceSize()
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    public native @Cast("std::size_t") long getMaxWorkspaceSize();

    /**
     *  \brief Set whether half2 mode is used.
     * 
     *  half2 mode is a paired-image mode that is significantly faster for batch sizes greater than one on platforms with fp16 support.
     * 
     *  @param mode Whether half2 mode is used.
     * 
     *  @see getHalf2Mode()
     * 
     *  @deprecated This function is superseded by setFp16Mode.
     *  */
    
    
    //!
    //!
    //!
    //!
    public native void setHalf2Mode(@Cast("bool") boolean mode);

    /**
     *  \brief Query whether half2 mode is used.
     * 
     *  @see setHalf2Mode()
     * 
     *  @deprecated This function is superseded by getFp16Mode.
     *  */
    
    
    //!
    //!
    //!
    public native @Cast("bool") boolean getHalf2Mode();

    /**
     *  \brief Set whether the builder should use debug synchronization.
     * 
     *  If this flag is true, the builder will synchronize after timing each layer, and report the layer name. It can be useful when diagnosing issues at build time.
     *  */
    
    
    //!
    //!
    //!
    public native void setDebugSync(@Cast("bool") boolean sync);

    /**
     *  \brief Query whether the builder will use debug synchronization.
     * 
     *  @see setDebugSync()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native @Cast("bool") boolean getDebugSync();

    /**
     *  \brief Set the number of minimization iterations used when timing layers.
     * 
     *  When timing layers, the builder minimizes over a set of average times for layer execution. This parameter controls the number of iterations
     *  used in minimization.
     * 
     *  @see getMinFindIterations()
     *  */
    
    
    //!
    //!
    //!
    public native void setMinFindIterations(int minFind);

    /**
     *  \brief Query the number of minimization iterations.
     * 
     *  @see setMinFindIterations()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native int getMinFindIterations();

    /**
     *  \brief Set the number of averaging iterations used when timing layers.
     * 
     *  When timing layers, the builder minimizes over a set of average times for layer execution. This parameter controls the number of iterations
     *  used in averaging.
     * 
     *  @see getAverageFindIterations()
     *  */
    
    
    //!
    //!
    //!
    public native void setAverageFindIterations(int avgFind);

    /**
     *  \brief Query the number of averaging iterations.
     * 
     *  @see setAverageFindIterations()
     *  */
    
    
    //!
    //!
    //!
    public native int getAverageFindIterations();

    /**
     *  \brief Build a CUDA engine from a network definition.
     * 
     *  @see INetworkDefinition ICudaEngine
     *  */
    
    
    //!
    //!
    public native ICudaEngine buildCudaEngine(@ByRef INetworkDefinition network);

    /**
     *  \brief Determine whether the platform has fast native fp16.
     *  */
    
    
    //!
    //!
    public native @Cast("bool") boolean platformHasFastFp16();

    /**
     *  \brief Determine whether the platform has fast native int8.
     *  */
    
    
    //!
    //!
    public native @Cast("bool") boolean platformHasFastInt8();

    /**
     *  \brief Destroy this object.
     *  */
    
    
    //!
    //!
    //!
    public native void destroy();

    /**
     *  \brief Set the maximum value for a region.
     * 
     *  Used for INT8 mode compression.
     *  */
    
    
    //!
    //!
    //!
    public native void setInt8Mode(@Cast("bool") boolean mode);

    /**
     *  \brief Query whether Int8 mode is used.
     * 
     *  @see setInt8Mode()
     *  */
    
    
    //!
    //!
    public native @Cast("bool") boolean getInt8Mode();

    /**
     *  \brief Set Int8 Calibration interface.
     *  */
    
    
    //!
    //!
    public native void setInt8Calibrator(IInt8Calibrator calibrator);

    /**
     *  \brief Set the device that this layer must execute on.
     *  @param DeviceType that this layer must execute on.
     *  If DeviceType is not set or is reset, TensorRT will use the default DeviceType set in the builder.
     *  @see getDeviceType()
     *  */
    
    
    //!
    //!
    public native void setDeviceType(ILayer layer, DeviceType deviceType);
    public native void setDeviceType(ILayer layer, @Cast("nvinfer1::DeviceType") int deviceType);

    /**
     *  \brief Get the device that this layer executes on.
     *  @return Returns DeviceType of the layer.
     *  */
    
    
    //!
    //!
    public native DeviceType getDeviceType(@Const ILayer layer);

    /**
     *  \brief whether the DeviceType has been explicitly set for this layer
     *  @return whether the DeviceType has been explicitly set
     *  @see setDeviceType() getDeviceType() resetDeviceType()
     *  */
    
    
    //!
    //!
    //!
    public native @Cast("bool") boolean isDeviceTypeSet(@Const ILayer layer);

    /**
     *  \brief reset the DeviceType for this layer
     * 
     *  @see setDeviceType() getDeviceType() isDeviceTypeSet()
     *  */
    
    
    //!
    //!
    public native void resetDeviceType(ILayer layer);

    /**
     *  \brief Checks if a layer can run on DLA.
     *  @return status true if the layer can on DLA else returns false.
     *  */
    
    
    //!
    //!
    public native @Cast("bool") boolean canRunOnDLA(@Const ILayer layer);

    /**
     *  \brief Sets the default DeviceType to be used by the builder. It ensures that all the layers that can run on this device will run on it, unless setDeviceType is used to override the default DeviceType for a layer.
     *  @see getDefaultDeviceType()
     *  */
    
    
    //!
    //!
    public native void setDefaultDeviceType(DeviceType deviceType);
    public native void setDefaultDeviceType(@Cast("nvinfer1::DeviceType") int deviceType);

    /**
     *  \brief Get the default DeviceType which was set by setDefaultDeviceType.
     *  */
    
    
    //!
    //!
    public native DeviceType getDefaultDeviceType();

    /**
     *  \brief Get the maximum batch size DLA can support.
     *  For any tensor the total volume of index dimensions combined(dimensions other than CHW) with the requested batch size should not exceed the value returned by this function.
     *  */
    
    
    //!
    //!
    public native int getMaxDLABatchSize(DeviceType deviceType);
    public native int getMaxDLABatchSize(@Cast("nvinfer1::DeviceType") int deviceType);

    /**
     *  \brief Sets the builder to use GPU if a layer that was supposed to run on DLA can not run on DLA.
     *  @param Allows fallback if setFallBackMode is true else disables fallback option.
     *  */
    
    
    //!
    //!
    public native void allowGPUFallback(@Cast("bool") boolean setFallBackMode);

    /**
     *  \brief Resets the builder state
     *  */
    public native void reset(@ByRef INetworkDefinition network);
    /**
     *  \brief Set the GPU allocator.
     *  @param allocator Set the GPU allocator to be used by the builder. All GPU memory acquired will use this allocator. If NULL is passed, the default allocator will be used.
     * 
     *  Default: uses cudaMalloc/cudaFree.
     * 
     *  \note This allocator will be passed to any engines created via the builder; thus the lifetime of the allocator must span the lifetime of those engines as
     *  well as that of the builder. If nullptr is passed, the default allocator will be used.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native void setGpuAllocator(IGpuAllocator allocator);

    /**
     *  \brief Set whether or not 16-bit kernels are permitted.
     * 
     *  During engine build fp16 kernels will also be tried when this mode is enabled.
     * 
     *  @param mode Whether 16-bit kernels are permitted.
     * 
     *  @see getFp16Mode()
     *  */
    
    
    //!
    //!
    //!
    public native void setFp16Mode(@Cast("bool") boolean mode);

    /**
     *  \brief Query whether 16-bit kernels are permitted.
     * 
     *  @see setFp16Mode()
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    public native @Cast("bool") boolean getFp16Mode();

    /**
     *  \brief Set whether or not type constraints are strict.
     * 
     *  When strict type constraints are in use, TensorRT will always choose a layer implementation that conforms to the type constraints
     *  specified, if one exists. If this flag is not set, a higher-precision implementation may be chosen if it results in higher performance.
     * 
     *  If no conformant layer exists, TensorRT will choose a non-conformant layer if available regardless of the setting of this flag.
     * 
     *  See the developer guide for the definition of strictness.
     * 
     *  @param mode Whether type constraints are strict
     * 
     *  @see getStrictTypeConstraints()
     *  */
    
    
    //!
    //!
    //!
    public native void setStrictTypeConstraints(@Cast("bool") boolean mode);

    /**
     *  \brief Query whether or not type constraints are strict.
     * 
     *  @see setStrictTypeConstraints()
     *  */
    public native @Cast("bool") boolean getStrictTypeConstraints();

}

/**
 *  \class IPluginFactory
 * 
 *  \brief Plugin factory for deserialization.
 *  */
@Namespace("nvinfer1") public static class IPluginFactory extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IPluginFactory(Pointer p) { super(p); }

    /**
     *  \brief Create a plugin from serialized data.
     * 
     *  Responsibility of destroying this plugin lies with the application.
     *  It can be done anytime after consumers of this plugin are destroyed.
     * 
     *  @param layerName The name of the layer.
     *  @param serialData The serialized data.
     *  @param serialLength The length of the serialized data.
     * 
     *  @return The plugin.
     * 
     *  @see IPlugin::serialize()
     *  */
    public native IPlugin createPlugin(String layerName, @Const Pointer serialData, @Cast("size_t") long serialLength);
    public native IPlugin createPlugin(@Cast("const char*") BytePointer layerName, @Const Pointer serialData, @Cast("size_t") long serialLength);
}

/**
 *  \class IRuntime
 * 
 *  \brief Allows a serialized engine to be deserialized.
 *  */
@Namespace("nvinfer1") public static class IRuntime extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IRuntime(Pointer p) { super(p); }

    /**
     *  \brief Deserialize an engine from a stream.
     * 
     *  @param blob The memory that holds the serialized engine.
     *  @param size The size of the memory.
     *  @param pluginFactory The plugin factory, if any plugins are used by the network, otherwise nullptr.
     * 
     *  @return The engine, or nullptr if it could not be deserialized.
     *  */
    
    
    //!
    //!
    public native ICudaEngine deserializeCudaEngine(@Const Pointer blob, @Cast("std::size_t") long size, IPluginFactory pluginFactory);

    /**
     *  \brief Destroy this object.
     *  */
    public native void destroy();
    /**
     *  \brief Set the GPU allocator.
     *  @param allocator Set the GPU allocator to be used by the runtime. All GPU memory acquired will use this allocator. If NULL is passed, the default allocator will be used.
     * 
     *  Default: uses cudaMalloc/cudaFree.
     * 
     *  If nullptr is passed, the default allocator will be used.
     *  */
    public native void setGpuAllocator(IGpuAllocator allocator);
}

/**
 *  \class ILogger
 * 
 *  \brief Application-implemented logging interface for the builder, engine and runtime.
 * 
 *  Note that although a logger is passed on creation to each instance of a IBuilder or IRuntime interface, the logger is internally considered a singleton, and thus
 *  multiple instances of IRuntime and/or IBuilder must all use the same logger.
 *  */
@Namespace("nvinfer1") public static class ILogger extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ILogger(Pointer p) { super(p); }

    /**
     *  \enum Severity
     * 
     *  The severity corresponding to a log message.
     *  */
    public enum Severity {
        /** An internal error has occurred. Execution is unrecoverable. */
        kINTERNAL_ERROR(0),
        /** An application error has occurred. */
        kERROR(1),
        /** An application error has been discovered, but TensorRT has recovered or fallen back to a default. */
        kWARNING(2),
        /** Informational messages. */
        kINFO(3);

        public final int value;
        private Severity(int v) { this.value = v; }
        private Severity(Severity e) { this.value = e.value; }
        public Severity intern() { for (Severity e : values()) if (e.value == value) return e; return this; }
        @Override public String toString() { return intern().name(); }
    }

    /**
     *  A callback implemented by the application to handle logging messages;
     * 
     *  @param severity The severity of the message.
     *  @param msg The log message, null terminated.
     *  */
    @Virtual(true) public native void log(Severity severity, String msg);
    
    /** Default native constructor. */
    public ILogger() { super((Pointer)null); allocate(); }
    private native void allocate();
}



 // namespace nvinfer1

/** Internal C entry point for creating IBuilder. */
public static native Pointer createInferBuilder_INTERNAL(Pointer logger, int version);
/** Internal C entry point for creating IRuntime.
<p>
//!
//! */
public static native Pointer createInferRuntime_INTERNAL(Pointer logger, int version);

/**
 *  \brief Return the logger object.
 *  */


//!
//!
//!
public static native ILogger getLogger();

/**
 *  \brief Return the library version number.
 * 
 *  The format is as for TENSORRT_VERSION: (TENSORRT_MAJOR * 1000) + (TENSORRT_MINOR * 100) + TENSOR_PATCH.
 *  */


//!
//!
public static native int getInferLibVersion();

/**
 *  \brief Return the plugin registry
 *  */
public static native IPluginRegistry getPluginRegistry();
/**
 *  \brief Create an instance of an IBuilder class.
 * 
 *  This class is the logging class for the builder.
 *  */


//!
//!
//!
@Namespace("nvinfer1") public static native IBuilder createInferBuilder(@ByRef ILogger logger);

/**
 *  \brief Create an instance of an IRuntime class.
 * 
 *  This class is the logging class for the runtime.
 *  */
@Namespace("nvinfer1") public static native IRuntime createInferRuntime(@ByRef ILogger logger);


/**
 *  \brief Register the plugin creator to the registry
 *  The static registry object will be instantiated when the plugin library is
 *  loaded. This static object will register all creators available in the
 *  library to the registry.
 *  */

// #define REGISTER_TENSORRT_PLUGIN(name) static PluginRegistrar<name> pluginRegistrar##name{}



// #endif


// Parsed from NvUtils.h

/*
 * Copyright 1993-2018 NVIDIA Corporation.  All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee.  Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE.  IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users.  These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item.  Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

// #ifndef NV_UTILS_H
// #define NV_UTILS_H

// #include "NvInfer.h"

    /**
     *  @param input The input weights to reshape.
     *  @param shape The shape of the weights.
     *  @param shapeOrder The order of the dimensions to process for the output.
     *  @param data The location where the output data is placed.
     *  @param nbDims The number of dimensions to process.
     * 
     *  \brief Reformat the input weights of the given shape based on the new
     *  order of dimensions.
     * 
     *  Take the weights specified by \p input with the dimensions specified by
     *  \p shape and re-order the weights based on the new dimensions specified
     *  by \p shapeOrder. The size of each dimension and the input data is not
     *  modified. The output volume pointed to by \p data must be the same as
     *  he \p input volume.
     * 
     *  Example usage:
     *  float *out = new float[N*C*H*W];
     *  Weights input{DataType::kFLOAT, {0 ... N*C*H*W-1}, N*C*H*W size};
     *  int order[4]{1, 0, 3, 2};
     *  int shape[4]{C, N, W, H};
     *  reshapeWeights(input, shape, order, out, 4);
     *  Weights reshaped{input.type, out, input.count};
     * 
     *  Input Matrix{3, 2, 3, 2}:
     *  { 0  1}, { 2  3}, { 4  5} <-- {0, 0, *, *}
     *  { 6  7}, { 8  9}, {10 11} <-- {0, 1, *, *}
     *  {12 13}, {14 15}, {16 17} <-- {1, 0, *, *}
     *  {18 19}, {20 21}, {22 23} <-- {1, 1, *, *}
     *  {24 25}, {26 27}, {28 29} <-- {2, 0, *, *}
     *  {30 31}, {32 33}, {34 35} <-- {2, 1, *, *}
     * 
     *  Output Matrix{2, 3, 2, 3}:
     *  { 0  2  4}, { 1  3  5} <-- {0, 0, *, *}
     *  {12 14 16}, {13 15 17} <-- {0, 1, *, *}
     *  {24 26 28}, {25 27 29} <-- {0, 2, *, *}
     *  { 6  8 10}, { 7  9 11} <-- {1, 0, *, *}
     *  {18 20 22}, {19 21 23} <-- {1, 1, *, *}
     *  {30 32 34}, {31 33 35} <-- {1, 2, *, *}
     * 
     *  @return True on success, false on failure.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    @Namespace("nvinfer1::utils") public static native @Cast("bool") boolean reshapeWeights(@Const @ByRef Weights input, @Const IntPointer shape, @Const IntPointer shapeOrder, Pointer data, int nbDims);
    @Namespace("nvinfer1::utils") public static native @Cast("bool") boolean reshapeWeights(@Const @ByRef Weights input, @Const IntBuffer shape, @Const IntBuffer shapeOrder, Pointer data, int nbDims);
    @Namespace("nvinfer1::utils") public static native @Cast("bool") boolean reshapeWeights(@Const @ByRef Weights input, @Const int[] shape, @Const int[] shapeOrder, Pointer data, int nbDims);

    /**
     *  @param input The input data to re-order.
     *  @param order The new order of the data sub-buffers.
     *  @param num The number of data sub-buffers to re-order.
     *  @param size The size of each data sub-buffer in bytes.
     * 
     *  \brief Takes an input stream and re-orders \p num chunks of the data
     *  given the \p size and \p order.
     * 
     *  In some frameworks, the ordering of the sub-buffers within a dimension
     *  is different than the way that TensorRT expects them.
     *  TensorRT expects the gate/bias sub-buffers for LSTM's to be in fico order.
     *  TensorFlow however formats the sub-buffers in icfo order.
     *  This helper function solves this in a generic fashion.
     * 
     *  Example usage output of reshapeWeights above:
     *  int indir[1]{1, 0}
     *  int stride = W*H;
     *  for (int x = 0, y = N*C; x < y; ++x)
     *  reorderSubBuffers(out + x * stride, indir, H, W);
     * 
     *  Input Matrix{2, 3, 2, 3}:
     *  { 0  2  4}, { 1  3  5} <-- {0, 0, *, *}
     *  {12 14 16}, {13 15 17} <-- {0, 1, *, *}
     *  {24 26 28}, {25 27 29} <-- {0, 2, *, *}
     *  { 6  8 10}, { 7  9 11} <-- {1, 0, *, *}
     *  {18 20 22}, {19 21 23} <-- {1, 1, *, *}
     *  {30 32 34}, {31 33 35} <-- {1, 2, *, *}
     * 
     *  Output Matrix{2, 3, 2, 3}:
     *  { 1  3  5}, { 0  2  4} <-- {0, 0, *, *}
     *  {13 15 17}, {12 14 16} <-- {0, 1, *, *}
     *  {25 27 29}, {24 26 28} <-- {0, 2, *, *}
     *  { 7  9 11}, { 6  8 10} <-- {1, 0, *, *}
     *  {19 21 23}, {18 20 22} <-- {1, 1, *, *}
     *  {31 33 35}, {30 32 34} <-- {1, 2, *, *}
     * 
     *  @return True on success, false on failure.
     * 
     *  @see reshapeWeights()
     *  */
    
    
    //!
    //!
    //!
    //!
    @Namespace("nvinfer1::utils") public static native @Cast("bool") boolean reorderSubBuffers(Pointer input, @Const IntPointer order, int num, int size);
    @Namespace("nvinfer1::utils") public static native @Cast("bool") boolean reorderSubBuffers(Pointer input, @Const IntBuffer order, int num, int size);
    @Namespace("nvinfer1::utils") public static native @Cast("bool") boolean reorderSubBuffers(Pointer input, @Const int[] order, int num, int size);

    /**
     *  @param input The input data to transpose.
     *  @param type The type of the data to transpose.
     *  @param num The number of data sub-buffers to transpose.
     *  @param height The size of the height dimension to transpose.
     *  @param width The size of the width dimension to transpose.
     * 
     *  \brief Transpose \p num sub-buffers of \p height * \p width.
     * 
     *  @return True on success, false on failure.
     *  */
    @Namespace("nvinfer1::utils") public static native @Cast("bool") boolean transposeSubBuffers(Pointer input, DataType type, int num, int height, int width);
    @Namespace("nvinfer1::utils") public static native @Cast("bool") boolean transposeSubBuffers(Pointer input, @Cast("nvinfer1::DataType") int type, int num, int height, int width);

 // utils namespace
 // nvinfer1 namespace
// #endif // NV_UTILS_H


}
