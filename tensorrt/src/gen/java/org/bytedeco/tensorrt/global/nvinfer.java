// Targeted by JavaCPP version 1.5.13-SNAPSHOT: DO NOT EDIT THIS FILE

package org.bytedeco.tensorrt.global;

import org.bytedeco.tensorrt.nvinfer.*;

import java.nio.*;
import org.bytedeco.javacpp.*;
import org.bytedeco.javacpp.annotation.*;

import static org.bytedeco.javacpp.presets.javacpp.*;
import org.bytedeco.cuda.cudart.*;
import static org.bytedeco.cuda.global.cudart.*;
import org.bytedeco.cuda.cublas.*;
import static org.bytedeco.cuda.global.cublas.*;
import org.bytedeco.cuda.cudnn.*;
import static org.bytedeco.cuda.global.cudnn.*;
import org.bytedeco.cuda.nvrtc.*;
import static org.bytedeco.cuda.global.nvrtc.*;

public class nvinfer extends org.bytedeco.tensorrt.presets.nvinfer {
    static { Loader.load(); }

// Parsed from NvInferVersion.h

/*
 * SPDX-FileCopyrightText: Copyright (c) 1993-2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
 * SPDX-License-Identifier: Apache-2.0
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/**
/** \file NvInferVersion.h
/**
/** Defines the TensorRT version
/** */
// #ifndef NV_INFER_VERSION_H
// #define NV_INFER_VERSION_H

public static final int TRT_MAJOR_ENTERPRISE = 10;
public static final int TRT_MINOR_ENTERPRISE = 14;
public static final int TRT_PATCH_ENTERPRISE = 1;
public static final int TRT_BUILD_ENTERPRISE = 48;
/** TensorRT major version. */
public static final int NV_TENSORRT_MAJOR = TRT_MAJOR_ENTERPRISE;
/** TensorRT minor version. */
public static final int NV_TENSORRT_MINOR = TRT_MINOR_ENTERPRISE;
/** TensorRT patch version. */
public static final int NV_TENSORRT_PATCH = TRT_PATCH_ENTERPRISE;
/** TensorRT build number. */
public static final int NV_TENSORRT_BUILD = TRT_BUILD_ENTERPRISE;

/** TensorRT LWS major version. */
public static final int NV_TENSORRT_LWS_MAJOR = 0;
/** TensorRT LWS minor version. */
public static final int NV_TENSORRT_LWS_MINOR = 0;
/** TensorRT LWS patch version. */
public static final int NV_TENSORRT_LWS_PATCH = 0;

/** An early access release */
public static final int NV_TENSORRT_RELEASE_TYPE_EARLY_ACCESS = 0;
/** A release candidate */
public static final int NV_TENSORRT_RELEASE_TYPE_RELEASE_CANDIDATE = 1;
/** A final release */
public static final int NV_TENSORRT_RELEASE_TYPE_GENERAL_AVAILABILITY = 2;

/** TensorRT release type */
public static final int NV_TENSORRT_RELEASE_TYPE = NV_TENSORRT_RELEASE_TYPE_GENERAL_AVAILABILITY;

// #endif // NV_INFER_VERSION_H


// Parsed from NvInferRuntimeBase.h

/*
 * SPDX-FileCopyrightText: Copyright (c) 1993-2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
 * SPDX-License-Identifier: Apache-2.0
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #ifndef NV_INFER_RUNTIME_BASE_H
// #define NV_INFER_RUNTIME_BASE_H

// #include "NvInferVersion.h"
// #include <cstddef>
// #include <cstdint>
// #include <cuda_runtime_api.h>

// Items that are marked as deprecated will be removed in a future release.
// #if __cplusplus >= 201402L
// #define TRT_DEPRECATED [[deprecated]]
// #define TRT_DEPRECATED_BECAUSE(REASON) [[deprecated(REASON)]]
// #define TRT_DEPRECATED_ENUM TRT_DEPRECATED
// #ifdef _MSC_VER
// #define TRT_DEPRECATED_API __declspec(dllexport)
// #else
// #define TRT_DEPRECATED_API [[deprecated]] __attribute__((visibility("default")))
// #endif
// #else
// #ifdef _MSC_VER
// #define TRT_DEPRECATED
// #define TRT_DEPRECATED_ENUM
// #define TRT_DEPRECATED_API __declspec(dllexport)
// #else
// #define TRT_DEPRECATED __attribute__((deprecated))
// #define TRT_DEPRECATED_ENUM
// #define TRT_DEPRECATED_API __attribute__((deprecated, visibility("default")))
// #endif
// #define TRT_DEPRECATED_BECAUSE(REASON) TRT_DEPRECATED
// #endif

/** A stand-in for {@code [[nodiscard]]} and {@code [[nodiscard(REASON)]]} that works with older compilers. */
// #if __cplusplus >= 201907L
// #define TRT_NODISCARD [[nodiscard]]
// #define TRT_NODISCARD_BECAUSE(REASON) [[nodiscard(REASON)]]
// #elif __cplusplus >= 201603L
// #define TRT_NODISCARD [[nodiscard]]
// #define TRT_NODISCARD_BECAUSE(REASON) [[nodiscard]]
// #else
// #define TRT_NODISCARD
// #define TRT_NODISCARD_BECAUSE(REASON)
// #endif

// Defines which symbols are exported
// #ifdef TENSORRT_BUILD_LIB
// #ifdef _MSC_VER
// #define TENSORRTAPI __declspec(dllexport)
// #else
// #define TENSORRTAPI __attribute__((visibility("default")))
// #endif
// #else
// #define TENSORRTAPI
// #endif

//!
//!
//!
//!
// #define TRTNOEXCEPT
/**
 *  \file NvInferRuntimeBase.h
 * 
 *  This file contains common definitions, data structures and interfaces shared between the standard and safe runtime.
 * 
 *  \warning Do not directly include this file. Instead include one of:
 *  * NvInferRuntime.h (for the standard runtime)
 *  * NvInferPluginUtils.h (for plugin utilities)
 *  */
// #if !defined(NV_INFER_INTERNAL_INCLUDE)
// #endif

/** Forward declare some CUDA types to avoid an include dependency. */
// Targeting ../nvinfer/cublasContext.java


// Targeting ../nvinfer/cudnnContext.java



/** Construct a single integer denoting TensorRT version.
 *  Usable in preprocessor expressions. */
// #define NV_TENSORRT_VERSION_INT(major, minor, patch) ((major) *10000L + (minor) *100L + (patch) *1L)

/** TensorRT version as a single integer.
 *  Usable in preprocessor expressions. */


//!
//!
//!
public static native @MemberGetter int NV_TENSORRT_VERSION();
public static final int NV_TENSORRT_VERSION = NV_TENSORRT_VERSION();

/**
 *  \namespace nvinfer1
 * 
 *  \brief The TensorRT API version 1 namespace.
 *  */
/** char_t is the type used by TensorRT to represent all valid characters. */

/** AsciiChar is the type used by TensorRT to represent valid ASCII characters.
 *  This type is widely used in automotive safety context. */

/** Forward declare IErrorRecorder for use in other interfaces. */
 // namespace v_1_0
/** Declaration of EnumMaxImpl struct to store maximum number of elements in an enumeration type. */
 // namespace impl

/** Maximum number of elements in an enumeration type. */


/**
 *  \enum DataType
 *  \brief The type of weights and tensors.
 *   The datatypes other than kBOOL, kINT32, and kINT64 are "activation datatypes,"
 *   as they often represent values corresponding to inference results.
 *  */
@Namespace("nvinfer1") public enum DataType {
    /** 32-bit floating point format. */
    kFLOAT(0),

    /** IEEE 16-bit floating-point format -- has a 5 bit exponent and 11 bit significand. */
    kHALF(1),

    /** Signed 8-bit integer representing a quantized floating-point value. */
    kINT8(2),

    /** Signed 32-bit integer format. */
    kINT32(3),

    /** 8-bit boolean. 0 = false, 1 = true, other values undefined. */
    kBOOL(4),

    /** Unsigned 8-bit integer format.
     *  Cannot be used to represent quantized floating-point values.
     *  Use the IdentityLayer to convert kUINT8 network-level inputs to {kFLOAT, kHALF} prior
     *  to use with other TensorRT layers, or to convert intermediate output
     *  before kUINT8 network-level outputs from {kFLOAT, kHALF} to kUINT8.
     *  kUINT8 conversions are only supported for {kFLOAT, kHALF}.
     *  kUINT8 to {kFLOAT, kHALF} conversion will convert the integer values
     *  to equivalent floating point values.
     *  {kFLOAT, kHALF} to kUINT8 conversion will convert the floating point values
     *  to integer values by truncating towards zero. This conversion has undefined behavior for
     *  floating point values outside the range [0.0F, 256.0F) after truncation.
     *  kUINT8 conversions are not supported for {kINT8, kINT32, kBOOL}. */
    kUINT8(5),

    /** Signed 8-bit floating point with
     *  1 sign bit, 4 exponent bits, 3 mantissa bits, and exponent-bias 7. */
    kFP8(6),

    /** Brain float -- has an 8 bit exponent and 8 bit significand. */
    kBF16(7),

    /** Signed 64-bit integer type. */
    kINT64(8),

    /** Signed 4-bit integer type. */
    kINT4(9),

    /** 4-bit floating point type
     *  1 bit sign, 2 bit exponent, 1 bit mantissa */
    kFP4(10),

    /** Unsigned representation of exponent-only 8-bit floating point type for quantization scales */
    kE8M0(11);

    public final int value;
    private DataType(int v) { this.value = v; }
    private DataType(DataType e) { this.value = e.value; }
    public DataType intern() { for (DataType e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}
/** Maximum number of elements in DataType enum. @see DataType */

// Targeting ../nvinfer/Dims64.java



/**
 *  Alias for Dims64.
 *  */



//!
//!
//!
// Targeting ../nvinfer/InterfaceInfo.java



/**
 *  \enum APILanguage
 * 
 *  \brief Programming language used in the implementation of a TRT interface
 *  */
@Namespace("nvinfer1") public enum APILanguage {
    kCPP(0),
    kPYTHON(1);

    public final int value;
    private APILanguage(int v) { this.value = v; }
    private APILanguage(APILanguage e) { this.value = e.value; }
    public APILanguage intern() { for (APILanguage e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}
/** Maximum number of elements in APILanguage enum. @see APILanguage */

// Targeting ../nvinfer/IVersionedInterface.java



/**
 *  \enum ErrorCode
 * 
 *  \brief Error codes that can be returned by TensorRT during execution.
 *  */
@Namespace("nvinfer1") public enum ErrorCode {
    /**
     *  Execution completed successfully.
     *  */
    

//!
//!
    kSUCCESS(0),

    /**
     *  An error that does not fall into any other category. This error is included for forward compatibility.
     *  */
    

//!
//!
    kUNSPECIFIED_ERROR(1),

    /**
     *  A non-recoverable TensorRT error occurred. TensorRT is in an invalid internal state when this error is
     *  emitted and any further calls to TensorRT will result in undefined behavior.
     *  */
    

//!
//!
    kINTERNAL_ERROR(2),

    /**
     *  An argument passed to the function is invalid in isolation.
     *  This is a violation of the API contract.
     *  */
    

//!
//!
    kINVALID_ARGUMENT(3),

    /**
     *  An error occurred when comparing the state of an argument relative to other arguments. For example, the
     *  dimensions for concat differ between two tensors outside of the channel dimension. This error is triggered
     *  when an argument is correct in isolation, but not relative to other arguments. This is to help to distinguish
     *  from the simple errors from the more complex errors.
     *  This is a violation of the API contract.
     *  */
    

//!
//!
    kINVALID_CONFIG(4),

    /**
     *  An error occurred when performing an allocation of memory on the host or the device.
     *  A memory allocation error is normally fatal, but in the case where the application provided its own memory
     *  allocation routine, it is possible to increase the pool of available memory and resume execution.
     *  */
    

//!
//!
    kFAILED_ALLOCATION(5),

    /**
     *  One, or more, of the components that TensorRT relies on did not initialize correctly.
     *  This is a system setup issue.
     *  */
    

//!
//!
    kFAILED_INITIALIZATION(6),

    /**
     *  An error occurred during execution that caused TensorRT to end prematurely, either an asynchronous error,
     *  user cancellation, or other execution errors reported by CUDA/DLA. In a dynamic system, the
     *  data can be thrown away and the next frame can be processed or execution can be retried.
     *  This is either an execution error or a memory error.
     *  */
    

//!
//!
    kFAILED_EXECUTION(7),

    /**
     *  An error occurred during execution that caused the data to become corrupted, but execution finished. Examples
     *  of this error are NaN squashing or integer overflow. In a dynamic system, the data can be thrown away and the
     *  next frame can be processed or execution can be retried.
     *  This is either a data corruption error, an input error, or a range error.
     *  This is not used in safety but may be used in standard.
     *  */
    

//!
//!
//!
    kFAILED_COMPUTATION(8),

    /**
     *  TensorRT was put into a bad state by incorrect sequence of function calls. An example of an invalid state is
     *  specifying a layer to be DLA only without GPU fallback, and that layer is not supported by DLA. This can occur
     *  in situations where a service is optimistically executing networks for multiple different configurations
     *  without checking proper error configurations, and instead throwing away bad configurations caught by TensorRT.
     *  This is a violation of the API contract, but can be recoverable.
     * 
     *  Example of a recovery:
     *  GPU fallback is disabled and conv layer with large filter(63x63) is specified to run on DLA. This will fail due
     *  to DLA not supporting the large kernel size. This can be recovered by either turning on GPU fallback
     *  or setting the layer to run on the GPU.
     *  */
    

//!
//!
    kINVALID_STATE(9),

    /**
     *  An error occurred due to the network not being supported on the device due to constraints of the hardware or
     *  system. An example is running an unsafe layer in a safety certified context, or a resource requirement for the
     *  current network is greater than the capabilities of the target device. The network is otherwise correct, but
     *  the network and hardware combination is problematic. This can be recoverable.
     *  Examples:
     *   * Scratch space requests larger than available device memory and can be recovered by increasing allowed
     *     workspace size.
     *   * Tensor size exceeds the maximum element count and can be recovered by reducing the maximum batch size.
     *  */
    kUNSUPPORTED_STATE(10);

    public final int value;
    private ErrorCode(int v) { this.value = v; }
    private ErrorCode(ErrorCode e) { this.value = e.value; }
    public ErrorCode intern() { for (ErrorCode e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}
/** Maximum number of elements in ErrorCode enum. @see ErrorCode */

// Targeting ../nvinfer/IErrorRecorder.java

 // class IErrorRecorder
 // namespace v_1_0

/**
 *  \class IErrorRecorder
 * 
 *  \brief Reference counted application-implemented error reporting interface for TensorRT objects.
 * 
 *  The error reporting mechanism is a user-defined object that interacts with the internal state of the object
 *  that it is assigned to in order to determine information about abnormalities in execution. The error recorder
 *  gets both an error enum that is more descriptive than pass/fail and also a string description that gives more
 *  detail on the exact failure modes. In the safety context, the error strings are all limited to 128 bytes
 *  or less in length, including the NULL terminator.
 * 
 *  The ErrorRecorder gets passed along to any class that is created from another class that has an ErrorRecorder
 *  assigned to it. For example, assigning an ErrorRecorder to an IBuilder allows all INetwork's, ILayer's, and
 *  ITensor's to use the same error recorder. For functions that have their own ErrorRecorder accessor functions.
 *  This allows registering a different error recorder or de-registering of the error recorder for that specific
 *  object.
 * 
 *  ErrorRecorder objects that are used in the safety runtime must define an implementation-dependent upper limit
 *  of errors whose information can be stored, and drop errors above this upper limit. The limit must fit in int32_t.
 *  The IErrorRecorder::hasOverflowed() method is used to signal that one or more errors have been dropped.
 * 
 *  The ErrorRecorder object implementation must be thread safe. All locking and synchronization is pushed to the
 *  interface implementation and TensorRT does not hold any synchronization primitives when calling the interface
 *  functions.
 * 
 *  The lifetime of the ErrorRecorder object must exceed the lifetime of all TensorRT objects that use it.
 *  */


//!
//!
//!

/**
 *  \enum TensorIOMode
 * 
 *  \brief Definition of tensor IO Mode.
 *  */
@Namespace("nvinfer1") public enum TensorIOMode {
    /** Tensor is not an input or output. */
    kNONE(0),

    /** Tensor is input to the engine. */
    kINPUT(1),

    /** Tensor is output by the engine. */
    kOUTPUT(2);

    public final int value;
    private TensorIOMode(int v) { this.value = v; }
    private TensorIOMode(TensorIOMode e) { this.value = e.value; }
    public TensorIOMode intern() { for (TensorIOMode e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}
/** Maximum number of elements in TensorIOMode enum. @see TensorIOMode */
 // namespace impl
 // namespace nvinfer1

/**
 *  \brief Return the library version number.
 * 
 *  The format is as for TENSORRT_VERSION: (MAJOR * 100 + MINOR) * 100 + PATCH
 *  */
public static native @NoException(true) int getInferLibVersion();

// #endif // NV_INFER_RUNTIME_BASE_H


// Parsed from NvInferRuntimeCommon.h

/*
 * SPDX-FileCopyrightText: Copyright (c) 1993-2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
 * SPDX-License-Identifier: Apache-2.0
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #ifndef NV_INFER_RUNTIME_COMMON_H


//!
//!
//!
//!
//!
// #define NV_INFER_RUNTIME_COMMON_H

/**
 *  \file NvInferRuntimeCommon.h
 * 
 *  This file provides the nvinfer1::IPluginRegistry interface, which will be moved to the NvInferRuntime.h header
 *  in a future release.
 * 
 *  \warning This file will be removed in a future release.
 * 
 *  \warning Do not directly include this file. Instead include NvInferRuntime.h
 *  */
public static final int NV_INFER_INTERNAL_INCLUDE = 1;
// #include "NvInferPluginBase.h"
// #undef NV_INFER_INTERNAL_INCLUDE
// #include "NvInferRuntimePlugin.h"
// Targeting ../nvinfer/IPluginRegistry.java



 // namespace nvinfer1

// #endif /* NV_INFER_RUNTIME_COMMON_H */


// Parsed from NvInferLegacyDims.h

/*
 * SPDX-FileCopyrightText: Copyright (c) 1993-2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
 * SPDX-License-Identifier: Apache-2.0
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #ifndef NV_INFER_LEGACY_DIMS_H
// #define NV_INFER_LEGACY_DIMS_H
// #include "NvInferRuntimeBase.h" // IWYU pragma: exports


//!
//!
//!

//!
//!
//!
// #undef NV_INFER_INTERNAL_INCLUDE

/**
 *  \file NvInferLegacyDims.h
 * 
 *  This file contains declarations of legacy dimensions types which use channel
 *  semantics in their names, and declarations on which those types rely.
 * 
 <p>
 * 
 *  \namespace nvinfer1
 * 
 *  \brief The TensorRT API version 1 namespace.
 *  */
// Targeting ../nvinfer/Dims2.java


// Targeting ../nvinfer/DimsHW.java


// Targeting ../nvinfer/Dims3.java


// Targeting ../nvinfer/Dims4.java



 // namespace nvinfer1

// #endif // NV_INFER_LEGCY_DIMS_H


// Parsed from NvInferRuntime.h

/*
 * SPDX-FileCopyrightText: Copyright (c) 1993-2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
 * SPDX-License-Identifier: Apache-2.0
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #ifndef NV_INFER_RUNTIME_H


//!
//!
//!
// #define NV_INFER_RUNTIME_H

/**
 *  \file NvInferRuntime.h
 * 
 *  This is the top-level API file for TensorRT extended runtime library.
 *  */

// #include "NvInferImpl.h" // IWYU pragma: export
// #include "NvInferPluginBase.h" // IWYU pragma: export
// #undef NV_INFER_INTERNAL_INCLUDE
// #include "NvInferRuntimeCommon.h"
// Targeting ../nvinfer/IPluginFactory.java


// Targeting ../nvinfer/INoCopy.java



/**
 *  \enum EngineCapability
 * 
 *  \brief List of supported engine capability flows.
 * 
 *  \details The EngineCapability determines the restrictions of a network during build time and what runtime
 *  it targets. When BuilderFlag::kSAFETY_SCOPE is not set (by default), EngineCapability::kSTANDARD does not provide
 *  any restrictions on functionality and the resulting serialized engine can be executed with TensorRT's standard
 *  runtime APIs in the nvinfer1 namespace. EngineCapability::kSAFETY provides a restricted subset of network
 *  operations that are safety certified and the resulting serialized engine can be executed with TensorRT's safe
 *  runtime APIs in the nvinfer1::safe namespace. EngineCapability::kDLA_STANDALONE provides a restricted subset of
 *  network operations that are DLA compatible and the resulting serialized engine can be executed using standalone
 *  DLA runtime APIs. See sampleCudla for an example of integrating cuDLA APIs with TensorRT APIs.
 *  */
@Namespace("nvinfer1") public enum EngineCapability {
    /**
     *  Standard: TensorRT flow without targeting the safety runtime.
     *  This flow supports both DeviceType::kGPU and DeviceType::kDLA.
     *  */
    

//!
//!
    kSTANDARD(0),

    /**
     *  Safety: TensorRT flow with restrictions targeting the safety runtime.
     *  See safety documentation for list of supported layers and formats.
     *  This flow supports only DeviceType::kGPU.
     * 
     *  This flag is only supported in NVIDIA Drive(R) products. */
    

//!
//!
    kSAFETY(1),

    /**
     *  DLA Standalone: TensorRT flow with restrictions targeting external, to TensorRT, DLA runtimes.
     *  See DLA documentation for list of supported layers and formats.
     *  This flow supports only DeviceType::kDLA.
     *  */
    kDLA_STANDALONE(2);

    public final int value;
    private EngineCapability(int v) { this.value = v; }
    private EngineCapability(EngineCapability e) { this.value = e.value; }
    public EngineCapability intern() { for (EngineCapability e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}
/** Maximum number of elements in EngineCapability enum. @see EngineCapability */

// Targeting ../nvinfer/Weights.java


// Targeting ../nvinfer/IHostMemory.java



/**
 *  \enum DimensionOperation
 * 
 *  \brief An operation on two IDimensionExpr, which represent integer expressions used in dimension computations.
 * 
 *  For example, given two IDimensionExpr x and y and an IExprBuilder& eb,
 *  eb.operation(DimensionOperation::kSUM, x, y) creates a representation of x+y.
 * 
 *  @see IDimensionExpr, IExprBuilder
 *  */
@Namespace("nvinfer1") public enum DimensionOperation {
    /** Sum of the two operands. */
    kSUM(0),
    /** Product of the two operands. */
    kPROD(1),
    /** Maximum of the two operands. */
    kMAX(2),
    /** Minimum of the two operands. */
    kMIN(3),
    /** Substract the second element from the first. */
    kSUB(4),
    /** 1 if operands are equal, 0 otherwise. */
    kEQUAL(5),
    /** 1 if first operand is less than second operand, 0 otherwise. */
    kLESS(6),
    /** Floor division of the first element by the second. */
    kFLOOR_DIV(7),
    /** Division rounding up */
    kCEIL_DIV(8);

    public final int value;
    private DimensionOperation(int v) { this.value = v; }
    private DimensionOperation(DimensionOperation e) { this.value = e.value; }
    public DimensionOperation intern() { for (DimensionOperation e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}

/** Maximum number of elements in DimensionOperation enum. @see DimensionOperation */


/**
 *  \enum TensorLocation
 * 
 *  \brief The location for tensor data storage, device or host.
 *  */
@Namespace("nvinfer1") public enum TensorLocation {
    /** Data stored on device. */
    kDEVICE(0),
    /** Data stored on host. */
    kHOST(1);

    public final int value;
    private TensorLocation(int v) { this.value = v; }
    private TensorLocation(TensorLocation e) { this.value = e.value; }
    public TensorLocation intern() { for (TensorLocation e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}
/** Maximum number of elements in TensorLocation enum. @see TensorLocation */

// Targeting ../nvinfer/IDimensionExpr.java


// Targeting ../nvinfer/IExprBuilder.java


// Targeting ../nvinfer/DimsExprs.java


// Targeting ../nvinfer/DynamicPluginTensorDesc.java


// Targeting ../nvinfer/IPluginV2DynamicExt.java


// Targeting ../nvinfer/IStreamReader.java


// Targeting ../nvinfer/IStreamWriter.java


 // namespace v_1_0

/**
 *  \class IStreamReader
 * 
 *  \brief Application-implemented class for reading data in a stream-based manner.
 * 
 *  \note To ensure compatibility of source code with future versions of TensorRT, use IStreamReader, not
 *        v_1_0::IStreamReader
 *  */


//!
//!
//!
//!

/**
 *  \class IStreamWriter
 * 
 *  \brief Application-implemented class for writing data in a stream-based manner.
 * 
 *  \note To ensure compatibility of source code with future versions of TensorRT, use IStreamWriter, not
 *        v_1_0::IStreamWriter
 *  */


//!
//!

/**
 *  \enum SeekPosition
 *  \brief Controls the seek mode of IStreamReaderV2.
 *  */
@Namespace("nvinfer1") public enum SeekPosition {
    /** From the beginning of the file. */
    kSET(0),

    /** From the current position of the file. */
    kCUR(1),

    /** From the tail of the file. */
    kEND(2);

    public final int value;
    private SeekPosition(int v) { this.value = v; }
    private SeekPosition(SeekPosition e) { this.value = e.value; }
    public SeekPosition intern() { for (SeekPosition e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}
// Targeting ../nvinfer/IStreamReaderV2.java


 // namespace v_1_0

/**
 *  \class IStreamReaderV2
 * 
 *  \brief Application-implemented class for reading data in a stream-based manner asynchronously. Intended for use with
 *  the GDS API for optimizing load times.
 * 
 *  \note To ensure compatibility of source code with future versions of TensorRT, use IStreamReaderV2, not
 *        v_1_0::IStreamReaderV2
 *  */


//!
//!
//!
//!
//!
//!
// Targeting ../nvinfer/IPluginResourceContext.java


// Targeting ../nvinfer/IPluginV3OneCore.java


// Targeting ../nvinfer/IPluginV3OneBuild.java


// Targeting ../nvinfer/IPluginV3OneRuntime.java


 // namespace v_1_0

 // namespace v_2_0

/**
 *  \class IPluginV3OneCore
 * 
 *  \brief A plugin capability interface that enables the core capability (PluginCapabilityType::kCORE).
 * 
 *  @see IPluginCapability
 *  @see PluginCapabilityType
 *  @see IPluginV3::getCapabilityInterface()
 *  */


//!
//!
//!
//!

/**
 *  \class IPluginV3OneBuild
 * 
 *  \brief A plugin capability interface that enables the build capability (PluginCapabilityType::kBUILD). Exposes
 *  methods that allow the expression of the build time properties and behavior of a plugin.
 * 
 *  @see IPluginCapability
 *  @see PluginCapabilityType
 *  @see IPluginV3::getCapabilityInterface()
 *  */


//!
//!
//!
//!

/**
 *  \class IPluginV3OneRuntime
 * 
 *  \brief A plugin capability interface that enables the runtime capability (PluginCapabilityType::kRUNTIME). Exposes
 *  methods that allow the expression of the runtime properties and behavior of a plugin.
 * 
 *  @see IPluginCapability
 *  @see PluginCapabilityType
 *  @see IPluginV3::getCapabilityInterface()
 *  */


//!
//!
//!
//!

/**
 *  \class IPluginV3OneBuildV2
 * 
 *  \brief A plugin capability interface that extends IPluginV3OneBuild by providing I/O aliasing functionality.
 * 
 *  @see IPluginV3OneBuild
 *  */
// Targeting ../nvinfer/IProfiler.java


 // namespace v_1_0

/**
 *  \class IProfiler
 * 
 *  \brief Application-implemented interface for profiling.
 * 
 *  When this class is added to an execution context, the profiler will be called once per layer for each invocation of
 *  executeV2()/enqueueV3().
 * 
 *  It is not recommended to run inference with profiler enabled when the inference execution time is critical since the
 *  profiler may affect execution time negatively.
 *  */


//!
//!
//!
//!

/**
 *  \enum WeightsRole
 * 
 *  \brief How a layer uses particular Weights.
 * 
 *  The power weights of an IScaleLayer are omitted.  Refitting those is not supported.
 *  */
@Namespace("nvinfer1") public enum WeightsRole {
    /** kernel for IConvolutionLayer or IDeconvolutionLayer */
    kKERNEL(0),
    /** bias for IConvolutionLayer or IDeconvolutionLayer */
    kBIAS(1),
    /** shift part of IScaleLayer */
    kSHIFT(2),
    /** scale part of IScaleLayer */
    kSCALE(3),
    /** weights for IConstantLayer */
    kCONSTANT(4),
    /** Any other weights role */
    kANY(5);

    public final int value;
    private WeightsRole(int v) { this.value = v; }
    private WeightsRole(WeightsRole e) { this.value = e.value; }
    public WeightsRole intern() { for (WeightsRole e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}

/** Maximum number of elements in WeightsRole enum. @see WeightsRole */


/**
 *  \enum DeviceType
 *  \brief The device that this layer/network will execute on.
 * 
 *  */
@Namespace("nvinfer1") public enum DeviceType {
    /** GPU Device */
    kGPU(0),
    /** DLA Core */
    kDLA(1);

    public final int value;
    private DeviceType(int v) { this.value = v; }
    private DeviceType(DeviceType e) { this.value = e.value; }
    public DeviceType intern() { for (DeviceType e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}

/** Maximum number of elements in DeviceType enum. @see DeviceType */


/**
 *  \enum TempfileControlFlag
 * 
 *  \brief Flags used to control TensorRT's behavior when creating executable temporary files.
 * 
 *  On some platforms the TensorRT runtime may need to create files in a temporary directory or use platform-specific
 *  APIs to create files in-memory to load temporary DLLs that implement runtime code. These flags allow the
 *  application to explicitly control TensorRT's use of these files. This will preclude the use of certain TensorRT
 *  APIs for deserializing and loading lean runtimes.
 *  */
@Namespace("nvinfer1") public enum TempfileControlFlag {
    /** Allow creating and loading files in-memory (or unnamed files). */
    
//!
    kALLOW_IN_MEMORY_FILES(0),

    /** Allow creating and loading named files in a temporary directory on the filesystem.
     * 
     *  @see IRuntime::setTemporaryDirectory() */
    kALLOW_TEMPORARY_FILES(1);

    public final int value;
    private TempfileControlFlag(int v) { this.value = v; }
    private TempfileControlFlag(TempfileControlFlag e) { this.value = e.value; }
    public TempfileControlFlag intern() { for (TempfileControlFlag e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}

/** Maximum number of elements in TempfileControlFlag enum. @see TempfileControlFlag */


/**
 *  \brief Represents a collection of one or more TempfileControlFlag values combined using bitwise-OR operations.
 * 
 *  @see TempfileControlFlag,
 *       IRuntime::setTempfileControlFlags(),
 *       IRuntime::getTempfileControlFlags() */


//!
//!
//!
//!
//!
//!
//!
//!
//!
//!

/**
 *  \enum TensorFormat
 * 
 *  \brief Format of the input/output tensors.
 * 
 *  This enum is used by both plugins and network I/O tensors.
 * 
 *  @see IPluginV2::supportsFormat(), safe::ICudaEngine::getBindingFormat()
 * 
 *  Many of the formats are **vector-major** or **vector-minor**. These formats specify
 *  a <em>vector dimension</em> and <em>scalars per vector</em>.
 *  For example, suppose that the tensor has has dimensions [M,N,C,H,W],
 *  the vector dimension is C and there are V scalars per vector.
 * 
 *  * A **vector-major** format splits the vectorized dimension into two axes in the
 *    memory layout. The vectorized dimension is replaced by an axis of length ceil(C/V)
 *    and a new dimension of length V is appended. For the example tensor, the memory layout
 *    is equivalent to an array with dimensions [M][N][ceil(C/V)][H][W][V].
 *    Tensor coordinate (m,n,c,h,w) maps to array location [m][n][c/V][h][w][c\%V].
 * 
 *  * A **vector-minor** format moves the vectorized dimension to become the last axis
 *    in the memory layout. For the example tensor, the memory layout is equivalent to an
 *    array with dimensions [M][N][H][W][ceil(C/V)*V]. Tensor coordinate (m,n,c,h,w) maps
 *    array location subscript [m][n][h][w][c].
 * 
 *  In interfaces that refer to "components per element", that's the value of V above.
 * 
 *  For more information about data formats, see the topic "Data Format Description" located in the
 *  TensorRT Developer Guide.
 *  https://docs.nvidia.com/deeplearning/tensorrt/latest/inference-library/advanced.html#i-o-formats
 *  */
@Namespace("nvinfer1") public enum TensorFormat {
    /** Memory layout is similar to an array in C or C++.
     *  The stride of each dimension is the product of the dimensions after it.
     *  The last dimension has unit stride.
     * 
     *  This format supports all TensorRT types.
     *  For DLA usage, the tensor sizes are limited to C,H,W in the range [1,8192]. */
    
//!
    kLINEAR(0),

    /** Vector-major format with two scalars per vector.
     *  Vector dimension is third to last.
     * 
     *  This format requires FP16 or BF16 and at least three dimensions. */
    kCHW2(1),

    /** Vector-minor format with eight scalars per vector.
     *  Vector dimension is third to last.
     *  This format requires FP16 or BF16 and at least three dimensions. */
    
//!
//!
//!
    kHWC8(2),

    /** Vector-major format with four scalars per vector.
     *  Vector dimension is third to last.
     * 
     *  This format requires INT8 and at least three dimensions.
     *  For INT8, the length of the vector dimension must be a build-time constant.
     * 
     *  Deprecated usage:
     * 
     *  If running on the DLA, this format can be used for acceleration
     *  with the caveat that C must be less than or equal to 4.
     *  If used as DLA input and the build option kGPU_FALLBACK is not specified,
     *  it needs to meet line stride requirement of DLA format. Column stride in
     *  bytes must be a multiple of 64 on Orin. */
    
//!
    kCHW4(3),

    /** Vector-major format with 16 scalars per vector.
     *  Vector dimension is third to last.
     * 
     *  This format is only supported by DLA and requires FP16 and at least three dimensions.
     *  This format maps to the native feature format for FP16,
     *  and the tensor sizes are limited to C,H,W in the range [1,8192]. */
    
//!
//!
    kCHW16(4),

    /** Vector-major format with 32 scalars per vector.
     *  Vector dimension is third to last.
     * 
     *  This format requires INT8, FP32, or FP16 and at least three dimensions.
     * 
     *  For DLA usage, this format maps to the native feature format for INT8,
     *  and the tensor sizes are limited to C,H,W in the range [1,8192]. */
    
//!
    kCHW32(5),

    /** Vector-minor format with eight scalars per vector.
     *  Vector dimension is fourth to last.
     * 
     *  This format requires FP16 or BF16 and at least four dimensions. */
    
//!
    kDHWC8(6),

    /** Vector-major format with 32 scalars per vector.
     *  Vector dimension is fourth to last.
     * 
     *  This format requires FP16 or INT8 and at least four dimensions. */
    
//!
    kCDHW32(7),

    /** Vector-minor format where channel dimension is third to last and unpadded.
     * 
     *  This format requires either FP32 or UINT8 and at least three dimensions. */
    
//!
    kHWC(8),

    /** DLA planar format. For a tensor with dimension {N, C, H, W}, the W axis
     *  always has unit stride. The stride for stepping along the H axis is
     *  rounded up to 64 bytes.
     * 
     *  The memory layout is equivalent to a C array with dimensions
     *  [N][C][H][roundUp(W, 64/elementSize)] where elementSize is
     *  2 for FP16 and 1 for Int8, with the tensor coordinates (n, c, h, w)
     *  mapping to array subscript [n][c][h][w]. */
    
//!
    kDLA_LINEAR(9),

    /** DLA image format. For a tensor with dimension {N, C, H, W} the C axis
     *  always has unit stride. The stride for stepping along the H axis is rounded up
     *  to 64 bytes on Orin. C can only be 1, 3 or 4.
     *  If C == 1, it will map to grayscale format.
     *  If C == 3 or C == 4, it will map to color image format. And if C == 3,
     *  the stride for stepping along the W axis needs to be padded to 4 in elements.
     * 
     *  When C is {1, 3, 4}, then C' is {1, 4, 4} respectively,
     *  the memory layout is equivalent to a C array with dimensions
     *  [N][H][roundUp(W, 64/C'/elementSize)][C'] on Orin
     *  where elementSize is 2 for FP16
     *  and 1 for Int8. The tensor coordinates (n, c, h, w) mapping to array
     *  subscript [n][h][w][c]. */
    
//!
    kDLA_HWC4(10),

    /** Vector-minor format with 16 scalars per vector.
     *  Vector dimension is third to last.
     * 
     *  This requires FP16, INT8 or FP8 and at least three dimensions. */
    
//!
    kHWC16(11),

    /** Vector-minor format with one scalar per vector.
     *  Vector dimension is fourth to last.
     * 
     *  This format requires FP32 and at least four dimensions. */
    kDHWC(12);

    public final int value;
    private TensorFormat(int v) { this.value = v; }
    private TensorFormat(TensorFormat e) { this.value = e.value; }
    public TensorFormat intern() { for (TensorFormat e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}
/** Maximum number of elements in TensorFormat enum. @see TensorFormat */
 // namespace impl

/**
 *  \enum AllocatorFlag
 * 
 *  \brief Allowed type of memory allocation.
 *  */
@Namespace("nvinfer1") public enum AllocatorFlag {
    /** TensorRT may call realloc() on this allocation. */
    kRESIZABLE(0);

    public final int value;
    private AllocatorFlag(int v) { this.value = v; }
    private AllocatorFlag(AllocatorFlag e) { this.value = e.value; }
    public AllocatorFlag intern() { for (AllocatorFlag e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}
/** Maximum number of elements in AllocatorFlag enum. @see AllocatorFlag */
 // namespace impl



//!
//!
//!
//!
//!
// Targeting ../nvinfer/ILogger.java


/** Maximum number of elements in ILogger::Severity enum. @see ILogger::Severity */

// Targeting ../nvinfer/IGpuAllocator.java



 // namespace v_1_0

/**
 *  \class IGpuAllocator
 * 
 *  \brief Application-implemented class for controlling allocation on the GPU.
 * 
 *  \warning The lifetime of an IGpuAllocator object must exceed that of all objects that use it.
 * 
 *  This class is intended as a base class for allocators that implement synchronous allocation.
 *  If you want the benefits of asynchronous allocation, you can do either of:
 * 
 *  * Derive your class from IGpuAllocator and override all four of its virtual methods
 *    for allocation/deallocation, including the two deprecated methods.
 * 
 *  * Derive your class from IGpuAsyncAllocator and override its two pure virtual
 *    methods for allocation/deallocation.
 * 
 *  The latter style is preferred because it does not tie code to deprecated methods.
 * 
 *  @see IGpuAsyncAllocator.
 *  */



//!
//!
//!
//!
// Targeting ../nvinfer/IRuntime.java


// Targeting ../nvinfer/IRefitter.java



/**
 *  \enum OptProfileSelector
 * 
 *  \brief When setting or querying optimization profile parameters (such as shape tensor inputs or dynamic dimensions),
 *         select whether we are interested in the minimum, optimum, or maximum values for these parameters.
 *         The minimum and maximum specify the permitted range that is supported at runtime, while the optimum value
 *         is used for the kernel selection. This should be the "typical" value that is expected to occur at runtime.
 * 
 *  @see IOptimizationProfile::setDimensions(), IOptimizationProfile::setShapeValuesV2(), IOptimizationProfile::setShapeValues()
 *  */
@Namespace("nvinfer1") public enum OptProfileSelector {
    /** This is used to set or get the minimum permitted value for dynamic dimensions etc. */
    kMIN(0),
    /** This is used to set or get the value that is used in the optimization (kernel selection). */
    kOPT(1),
    /** This is used to set or get the maximum permitted value for dynamic dimensions etc. */
    kMAX(2);

    public final int value;
    private OptProfileSelector(int v) { this.value = v; }
    private OptProfileSelector(OptProfileSelector e) { this.value = e.value; }
    public OptProfileSelector intern() { for (OptProfileSelector e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}

/**
 *  \brief Number of different values of OptProfileSelector enum.
 * 
 *  @see OptProfileSelector
 *  */

// Targeting ../nvinfer/IOptimizationProfile.java



/**
 *  \enum TacticSource
 * 
 *  \brief List of tactic sources for TensorRT.
 * 
 *  @see TacticSources, IBuilderConfig::setTacticSources(), IBuilderConfig::getTacticSources()
 *  */
@Namespace("nvinfer1") public enum TacticSource {
    /** cuBLAS tactics. Disabled by default.
     *  \note Disabling kCUBLAS will cause the cuBLAS handle passed to plugins in attachToContext to be null.
     *  @deprecated Deprecated in TensorRT 10.0. */
    kCUBLAS(0),

    /** cuBLAS LT tactics. Disabled by default.
     *  @deprecated Deprecated in TensorRT 9.0. */
    kCUBLAS_LT(1),

    /** cuDNN tactics. Disabled by default.
     *  \note Disabling kCUDNN will cause the cuDNN handle passed to plugins in attachToContext to be null.
     *  @deprecated Deprecated in TensorRT 10.0. */
    kCUDNN(2),

    /** Enables convolution tactics implemented with edge mask tables. These tactics tradeoff memory for performance by
     *  consuming additional memory space proportional to the input size.
     *  Enabled by default. */
    kEDGE_MASK_CONVOLUTIONS(3),

    /** Enables convolution tactics implemented with source-code JIT fusion. The engine building time may increase
     *  when this is enabled. Enabled by default. */
    kJIT_CONVOLUTIONS(4);

    public final int value;
    private TacticSource(int v) { this.value = v; }
    private TacticSource(TacticSource e) { this.value = e.value; }
    public TacticSource intern() { for (TacticSource e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}



/**
 *  \brief Represents a collection of one or more TacticSource values
 *  combine using bitwise-OR operations.
 * 
 *  @see IBuilderConfig::setTacticSources(), IBuilderConfig::getTacticSources()
 *  */


//!
//!
//!
//!

/**
 *  \enum ProfilingVerbosity
 * 
 *  \brief List of verbosity levels of layer information exposed in NVTX annotations and in IEngineInspector.
 * 
 *  @see IBuilderConfig::setProfilingVerbosity(),
 *       IBuilderConfig::getProfilingVerbosity(),
 *       IEngineInspector
 *  */
@Namespace("nvinfer1") public enum ProfilingVerbosity {
    /** Print only the layer names. This is the default setting. */
    kLAYER_NAMES_ONLY(0),
    /** Do not print any layer information. */
    kNONE(1),
    /** Print detailed layer information including layer names and layer parameters. */
    kDETAILED(2);

    public final int value;
    private ProfilingVerbosity(int v) { this.value = v; }
    private ProfilingVerbosity(ProfilingVerbosity e) { this.value = e.value; }
    public ProfilingVerbosity intern() { for (ProfilingVerbosity e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}

/** Maximum number of profile verbosity levels in ProfilingVerbosity enum. @see ProfilingVerbosity */


/**
 *  \brief Represents one or more SerializationFlag values using binary OR
 *  operations, e.g., 1U << SerializationFlag::kEXCLUDE_LEAN_RUNTIME
 * 
 *  @see ISerializationConfig::setFlags(), ISerializationConfig::getFlags()
 *  */


//!
//!
//!
//!

/**
 *  \enum SerializationFlag
 * 
 *  \brief List of valid flags that the engine can enable when serializing the bytes.
 * 
 *  @see ISerializationConfig::setFlags(), ISerializationConfig::getFlags()
 *  */
@Namespace("nvinfer1") public enum SerializationFlag {
    /** Exclude the weights that can be refitted. */
    kEXCLUDE_WEIGHTS(0),
    /** Exclude the lean runtime. */
    kEXCLUDE_LEAN_RUNTIME(1),
    /** Remain refittable if originally so. */
    kINCLUDE_REFIT(2);

    public final int value;
    private SerializationFlag(int v) { this.value = v; }
    private SerializationFlag(SerializationFlag e) { this.value = e.value; }
    public SerializationFlag intern() { for (SerializationFlag e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}

/** Maximum number of serialization flags in SerializationFlag enum. @see SerializationFlag */

// Targeting ../nvinfer/ISerializationConfig.java



/**
 *  \enum ExecutionContextAllocationStrategy
 * 
 *  \brief Different memory allocation behaviors for IExecutionContext.
 * 
 *  IExecutionContext requires a block of device memory for internal activation tensors during inference. The user can
 *  either let the execution context manage the memory in various ways or allocate the memory themselves.
 * 
 *  @see ICudaEngine::createExecutionContext()
 *  @see IExecutionContext::setDeviceMemory()
 *  */
@Namespace("nvinfer1") public enum ExecutionContextAllocationStrategy {
    /** Default static allocation with the maximum size across all profiles. */
    kSTATIC(0),
    /** Reallocate for a profile when it's selected. */
    kON_PROFILE_CHANGE(1),
    /** The user supplies custom allocation to the execution context. */
    kUSER_MANAGED(2);

    public final int value;
    private ExecutionContextAllocationStrategy(int v) { this.value = v; }
    private ExecutionContextAllocationStrategy(ExecutionContextAllocationStrategy e) { this.value = e.value; }
    public ExecutionContextAllocationStrategy intern() { for (ExecutionContextAllocationStrategy e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}

/**
 *  \brief Maximum number of memory allocation strategies in ExecutionContextAllocationStrategy enum.
 * 
 *  @see ExecutionContextAllocationStrategy
 *  */

// Targeting ../nvinfer/IRuntimeConfig.java

 // class IRuntimeConfig

/**
 *  \enum EngineStat
 * 
 *  \brief The kind of engine statistics that queried from the ICudaEngine.
 * 
 *  @see ICudaEngine::getEngineStat()
 *  @see BuilderFlag::kSTRIP_PLAN
 *  */
@Namespace("nvinfer1") public enum EngineStat {
    /** Return the total weight size in bytes. */
    kTOTAL_WEIGHTS_SIZE(0),

    /** Return the stripped weight size in bytes for engines built with BuilderFlag::kSTRIP_PLAN. */
    kSTRIPPED_WEIGHTS_SIZE(1);

    public final int value;
    private EngineStat(int v) { this.value = v; }
    private EngineStat(EngineStat e) { this.value = e.value; }
    public EngineStat intern() { for (EngineStat e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}

/**
 *  \brief Maximum number of engine statistic kinds in EngineStat enum.
 * 
 *  @see EngineStat
 *  */

// Targeting ../nvinfer/ICudaEngine.java


// Targeting ../nvinfer/IOutputAllocator.java


 // namespace v_1_0

/**
 *  \class IOutputAllocator
 * 
 *  \brief Callback from ExecutionContext::enqueueV3()
 * 
 *  @see IExecutionContext::enqueueV3()
 *  */
// Targeting ../nvinfer/IDebugListener.java


 // namespace v_1_0

/**
 *  \class IDebugListener
 * 
 *  \brief User-implemented callback for notification when value of a debug tensor is updated.
 *  */


//!
//!
//!
//!
// Targeting ../nvinfer/IExecutionContext.java

 // class IExecutionContext

/**
 *  \enum LayerInformationFormat
 * 
 *  \brief The format in which the IEngineInspector prints the layer information.
 * 
 *  @see IEngineInspector::getLayerInformation(), IEngineInspector::getEngineInformation()
 *  */
@Namespace("nvinfer1") public enum LayerInformationFormat {
    /** Print layer information in one line per layer. */
    kONELINE(0),
    /** Print layer information in JSON format. */
    kJSON(1);

    public final int value;
    private LayerInformationFormat(int v) { this.value = v; }
    private LayerInformationFormat(LayerInformationFormat e) { this.value = e.value; }
    public LayerInformationFormat intern() { for (LayerInformationFormat e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}

/** Maximum number of layer information formats in LayerInformationFormat enum.
 *  @see LayerInformationFormat */

// Targeting ../nvinfer/IEngineInspector.java

 // class IEngineInspector

 // namespace nvinfer1

/**
 *  Internal C entry point for creating IRuntime.
 *  \private
 *  */


//!
//!
public static native @NoException(true) Pointer createInferRuntime_INTERNAL(Pointer logger, int version);

/**
 *  Internal C entry point for creating IRefitter.
 *  \private
 *  */


//!
//!
public static native @NoException(true) Pointer createInferRefitter_INTERNAL(Pointer engine, Pointer logger, int version);

/**
 *  \brief Return the plugin registry
 *  */


//!
//!
public static native @NoException(true) IPluginRegistry getPluginRegistry();

/**
 *  \brief Return the logger object.
 *  \note the global logger is used only by standalone functions which have no associated builder, runtime
 *  or refitter.
 *  */
public static native @NoException(true) ILogger getLogger();
/**
 *  \brief Create an instance of an IRuntime class.
 * 
 *  @param logger The logging class for the runtime.
 *  */


//!
//!
//!
@Namespace("nvinfer1") public static native @NoException(true) IRuntime createInferRuntime(@ByRef ILogger logger);

/**
 *  \brief Create an instance of an IRefitter class.
 * 
 *  @param engine The engine class for the refitter.
 *  @param logger The logging class for the refitter.
 *  */
@Namespace("nvinfer1") public static native @NoException(true) IRefitter createInferRefitter(@ByRef ICudaEngine engine, @ByRef ILogger logger);

 // namespace

/**
 *  \brief Register the plugin creator to the registry
 *  The static registry object will be instantiated when the plugin library is
 *  loaded. This static object will register all creators available in the
 *  library to the registry.
 * 
 *  \warning Statically registering plugins should be avoided in the automotive
 *   safety context as the application developer should first register an error recorder
 *   with the plugin registry via IPluginRegistry::setErrorRecorder() before using
 *   IPluginRegistry::registerCreator() or other methods.
 *  */

 // namespace nvinfer1

// #define REGISTER_TENSORRT_PLUGIN(name)
//     static nvinfer1::PluginRegistrar<name> pluginRegistrar##name {}
// Targeting ../nvinfer/ILoggerFinder.java


// Targeting ../nvinfer/IGpuAsyncAllocator.java


// Targeting ../nvinfer/IPluginCreatorV3One.java



 // namespace v_1_0

/**
 *  \class IGpuAsyncAllocator
 * 
 *  \brief Application-implemented class for controlling asynchronous (stream ordered) memory allocation on the GPU.
 * 
 *  \warning The lifetime of an IGpuAsyncAllocator object must exceed that of all objects that use it.
 * 
 *  The advantage of deriving from IGpuAsyncAllocator instead of IGpuAllocator is that you only have
 *  to override two methods: allocateAsync() and deallocateAsync() to implement an allocator with
 *  asynchronous capability, whereas deriving from IGpuAllocator requires overriding four methods,
 *  including two deprecated methods.
 * 
 *  @see IGpuAllocator */


//!
//!
//!
//!

/**
 *  \class IPluginCreatorV3One
 * 
 *  \brief A plugin creator class capable of producing IPluginV3 objects
 * 
 *  @see IPluginV3
 *  @see IPluginRegistry
 *  */

 // namespace nvinfer1

/**
 *  \brief Return the library major version number.
 *  */

//!
//!
public static native @NoException(true) int getInferLibMajorVersion();
/**
 *  \brief Return the library minor version number.
 *  */

//!
//!
public static native @NoException(true) int getInferLibMinorVersion();
/**
 *  \brief Return the library patch version number.
 *  */

//!
//!
public static native @NoException(true) int getInferLibPatchVersion();
/**
 *  \brief Return the library build version number.
 *  */
public static native @NoException(true) int getInferLibBuildVersion();

// #endif // NV_INFER_RUNTIME_H


// Parsed from NvInfer.h

/*
 * SPDX-FileCopyrightText: Copyright (c) 1993-2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
 * SPDX-License-Identifier: Apache-2.0
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #ifndef NV_INFER_H
// #define NV_INFER_H

// #include "NvInferLegacyDims.h"


//!
//!
//!
//!
//!

//!
//!
//!

//!
//!
//!
// #include "NvInferRuntime.h" // IWYU pragma: export

/**
 *  \mainpage
 * 
 *  This is the API documentation for the NVIDIA TensorRT library. It provides information on individual
 *  functions, classes and methods. Use the index on the left to navigate the documentation.
 * 
 *  Please see the accompanying user guide and samples for higher-level information and general advice on
 *  using TensorRT.
 * 
 *  TensorRT Versioning follows Semantic Versioning Guidelines specified here: https://semver.org/
 * 
 <p>
 * 
 *  \file NvInfer.h
 * 
 *  This is the top-level API file for TensorRT.
 * 
 <p>
 * 
 *  \namespace nvinfer1
 * 
 *  \brief The TensorRT API version 1 namespace.
 *  */

/**
 *  \enum LayerType
 * 
 *  \brief The type values of layer classes.
 * 
 *  @see ILayer::getType()
 *  */
@Namespace("nvinfer1") public enum LayerType {
    /** Convolution layer. */
    kCONVOLUTION(0),
    /** Cast layer */
    kCAST(1),
    /** Activation layer. */
    kACTIVATION(2),
    /** Pooling layer. */
    kPOOLING(3),
    /** LRN layer. */
    kLRN(4),
    /** Scale layer. */
    kSCALE(5),
    /** SoftMax layer. */
    kSOFTMAX(6),
    /** Deconvolution layer. */
    kDECONVOLUTION(7),
    /** Concatenation layer. */
    kCONCATENATION(8),
    /** Elementwise layer. */
    kELEMENTWISE(9),
    /** Plugin layer. */
    kPLUGIN(10),
    /** UnaryOp operation Layer. */
    kUNARY(11),
    /** Padding layer. */
    kPADDING(12),
    /** Shuffle layer. */
    kSHUFFLE(13),
    /** Reduce layer. */
    kREDUCE(14),
    /** TopK layer. */
    kTOPK(15),
    /** Gather layer. */
    kGATHER(16),
    /** Matrix multiply layer. */
    kMATRIX_MULTIPLY(17),
    /** Ragged softmax layer. */
    kRAGGED_SOFTMAX(18),
    /** Constant layer. */
    kCONSTANT(19),
    /** Identity layer. */
    kIDENTITY(20),
    /** PluginV2 layer. */
    kPLUGIN_V2(21),
    /** Slice layer. */
    kSLICE(22),
    /** Shape layer. */
    kSHAPE(23),
    /** Parametric ReLU layer. */
    kPARAMETRIC_RELU(24),
    /** Resize Layer. */
    kRESIZE(25),
    /** Loop Trip limit layer */
    kTRIP_LIMIT(26),
    /** Loop Recurrence layer */
    kRECURRENCE(27),
    /** Loop Iterator layer */
    kITERATOR(28),
    /** Loop output layer */
    kLOOP_OUTPUT(29),
    /** Select layer. */
    kSELECT(30),
    /** Fill layer */
    kFILL(31),
    /** Quantize layer */
    kQUANTIZE(32),
    /** Dequantize layer */
    kDEQUANTIZE(33),
    /** Condition layer */
    kCONDITION(34),
    /** Conditional Input layer */
    kCONDITIONAL_INPUT(35),
    /** Conditional Output layer */
    kCONDITIONAL_OUTPUT(36),
    /** Scatter layer */
    kSCATTER(37),
    /** Einsum layer */
    kEINSUM(38),
    /** Assertion layer */
    kASSERTION(39),
    /** OneHot layer */
    kONE_HOT(40),
    /** NonZero layer */
    kNON_ZERO(41),
    /** Grid sample layer */
    kGRID_SAMPLE(42),
    /** NMS layer */
    kNMS(43),
    /** Reverse sequence layer */
    kREVERSE_SEQUENCE(44),
    /** Normalization layer */
    kNORMALIZATION(45),
    /** PluginV3 layer. */
    kPLUGIN_V3(46),
    /** Squeeze Layer. */
    kSQUEEZE(47),
    /** Unsqueeze Layer. */
    kUNSQUEEZE(48),
    /** Cumulative layer. */
    kCUMULATIVE(49),
    /** Dynamic Quantize layer. */
    kDYNAMIC_QUANTIZE(50),
    /** Attention Input. */
    kATTENTION_INPUT(51),
    /** Attention Output. */
    kATTENTION_OUTPUT(52);

    public final int value;
    private LayerType(int v) { this.value = v; }
    private LayerType(LayerType e) { this.value = e.value; }
    public LayerType intern() { for (LayerType e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}

/**
 *  Maximum number of elements in LayerType enum.
 * 
 *  @see LayerType
 *  */


/**
 *  \brief It is capable of representing one or more TensorFormat by binary OR
 *  operations, e.g., 1U << TensorFormat::kCHW4 | 1U << TensorFormat::kCHW32.
 * 
 *  @see ITensor::getAllowedFormats(), ITensor::setAllowedFormats(),
 *  */


//!
//!
//!

/**
 *  \enum ActivationType
 * 
 *  \brief Enumerates the types of activation to perform in an activation layer.
 *  */
@Namespace("nvinfer1") public enum ActivationType {
    /** Rectified linear activation. */
    kRELU(0),
    /** Sigmoid activation. */
    kSIGMOID(1),
    /** TanH activation. */
    kTANH(2),
    /** LeakyRelu activation: x>=0 ? x : alpha * x. */
    kLEAKY_RELU(3),
    /** Elu activation: x>=0 ? x : alpha * (exp(x) - 1). */
    kELU(4),
    /** Selu activation: x>0 ? beta * x : beta * (alpha*exp(x) - alpha) */
    kSELU(5),
    /** Softsign activation: x / (1+|x|) */
    kSOFTSIGN(6),
    /** Parametric softplus activation: alpha*log(exp(beta*x)+1) */
    kSOFTPLUS(7),
    /** Clip activation: max(alpha, min(beta, x)) */
    kCLIP(8),
    /** Hard sigmoid activation: max(0, min(1, alpha*x+beta)) */
    kHARD_SIGMOID(9),
    /** Scaled tanh activation: alpha*tanh(beta*x) */
    kSCALED_TANH(10),
    /** Thresholded ReLU activation: x>alpha ? x : 0 */
    kTHRESHOLDED_RELU(11),
    /** GELU erf activation: 0.5 * x * (1 + erf(sqrt(0.5) * x)) */
    kGELU_ERF(12),
    /** GELU tanh activation: 0.5 * x * (1 + tanh(sqrt(2/pi) * (0.044715F * pow(x, 3) + x))) */
    kGELU_TANH(13);

    public final int value;
    private ActivationType(int v) { this.value = v; }
    private ActivationType(ActivationType e) { this.value = e.value; }
    public ActivationType intern() { for (ActivationType e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}
/**
 *  Maximum number of elements in ActivationType enum.
 * 
 *  @see ActivationType
 *  */

// Targeting ../nvinfer/ITensor.java


// Targeting ../nvinfer/ILayer.java



/**
 *  \enum PaddingMode
 * 
 *  \brief Enumerates the modes of padding to perform in convolution, deconvolution and pooling layer,
 *  padding mode takes precedence if setPaddingMode() and setPrePadding() are also used.
 * 
 *  There are two padding styles, EXPLICIT and SAME with each style having two variants.
 *  The EXPLICIT style determine if the final sampling location is used or not.
 *  The SAME style determine if the asymmetry in the padding is on the pre or post padding.
 * 
 *  <pre>{@code
 *  Shorthand:
 *      I = dimensions of input image.
 *      B = prePadding, before the image data.
 *      A = postPadding, after the image data.
 *      P = delta between input and output
 *      S = stride
 *      F = filter
 *      O = output
 *      D = dilation
 *      M = I + B + A ; The image data plus any padding
 *      DK = 1 + D * (F - 1)
 *  }</pre>
 * 
 *  Formulas for Convolution:
 *      - EXPLICIT_ROUND_DOWN:
 *  <pre>{@code
 *          O = floor((M - DK) / S) + 1
 *  }</pre>
 *      - EXPLICIT_ROUND_UP:
 *  <pre>{@code
 *          O = ceil((M - DK) / S) + 1
 *  }</pre>
 *      - SAME_UPPER:
 *  <pre>{@code
 *          O = ceil(I / S)
 *          P = floor((I - 1) / S) * S + DK - I;
 *          B = floor(P / 2)
 *          A = P - B
 *  }</pre>
 *      - SAME_LOWER:
 *  <pre>{@code
 *          O = ceil(I / S)
 *          P = floor((I - 1) / S) * S + DK - I;
 *          A = floor(P / 2)
 *          B = P - A
 *  }</pre>
 * 
 *  Formulas for Deconvolution:
 *      - EXPLICIT_ROUND_DOWN:
 *      - EXPLICIT_ROUND_UP:
 *  <pre>{@code
 *          O = (I - 1) * S + DK - (B + A)
 *  }</pre>
 *      - SAME_UPPER:
 *  <pre>{@code
 *          O = min(I * S, (I - 1) * S + DK)
 *          P = max(DK - S, 0)
 *          B = floor(P / 2)
 *          A = P - B
 *  }</pre>
 *      - SAME_LOWER:
 *  <pre>{@code
 *          O = min(I * S, (I - 1) * S + DK)
 *          P = max(DK - S, 0)
 *          A = floor(P / 2)
 *          B = P - A
 *  }</pre>
 * 
 *  Formulas for Pooling:
 *      - EXPLICIT_ROUND_DOWN:
 *  <pre>{@code
 *          O = floor((M - F) / S) + 1
 *  }</pre>
 *      - EXPLICIT_ROUND_UP:
 *  <pre>{@code
 *          O = ceil((M - F) / S) + 1
 *  }</pre>
 *      - SAME_UPPER:
 *  <pre>{@code
 *          O = ceil(I / S)
 *          P = floor((I - 1) / S) * S + F - I;
 *          B = floor(P / 2)
 *          A = P - B
 *  }</pre>
 *      - SAME_LOWER:
 *  <pre>{@code
 *          O = ceil(I / S)
 *          P = floor((I - 1) / S) * S + F - I;
 *          A = floor(P / 2)
 *          B = P - A
 *  }</pre>
 * 
 *  Pooling Example 1:
 *  <pre>{@code
 *      Given I = {6, 6}, B = {3, 3}, A = {2, 2}, S = {2, 2}, F = {3, 3}. What is O?
 *      (B, A can be calculated for SAME_UPPER and SAME_LOWER mode)
 *  }</pre>
 * 
 *  - EXPLICIT_ROUND_DOWN:
 *  <pre>{@code
 *      Computation:
 *          M = {6, 6} + {3, 3} + {2, 2} ==> {11, 11}
 *          O ==> floor((M - F) / S) + 1
 *            ==> floor(({11, 11} - {3, 3}) / {2, 2}) + {1, 1}
 *            ==> floor({8, 8} / {2, 2}) + {1, 1}
 *            ==> {5, 5}
 *  }</pre>
 *  - EXPLICIT_ROUND_UP:
 *  <pre>{@code
 *      Computation:
 *          M = {6, 6} + {3, 3} + {2, 2} ==> {11, 11}
 *          O ==> ceil((M - F) / S) + 1
 *            ==> ceil(({11, 11} - {3, 3}) / {2, 2}) + {1, 1}
 *            ==> ceil({8, 8} / {2, 2}) + {1, 1}
 *            ==> {5, 5}
 *  }</pre>
 *      The sample points are {0, 2, 4, 6, 8} in each dimension.
 * 
 *  - SAME_UPPER:
 *  <pre>{@code
 *      Computation:
 *          I = {6, 6}
 *          S = {2, 2}
 *          O = ceil(I / S) = {3, 3}
 *          P = floor((I - 1) / S) * S + F - I
 *              ==> floor(({6, 6} - {1, 1}) / {2, 2}) * {2, 2} + {3, 3} - {6, 6}
 *              ==> {4, 4} + {3, 3} - {6, 6}
 *              ==> {1, 1}
 *          B = floor({1, 1} / {2, 2})
 *              ==> {0, 0}
 *          A = {1, 1} - {0, 0}
 *              ==> {1, 1}
 *  }</pre>
 *  - SAME_LOWER:
 *  <pre>{@code
 *      Computation:
 *          I = {6, 6}
 *          S = {2, 2}
 *          O = ceil(I / S) = {3, 3}
 *          P = floor((I - 1) / S) * S + F - I
 *            ==> {1, 1}
 *          A = floor({1, 1} / {2, 2})
 *            ==> {0, 0}
 *          B = {1, 1} - {0, 0}
 *            ==> {1, 1}
 *  }</pre>
 *      The sample pointers are {0, 2, 4} in each dimension.
 *      SAMPLE_UPPER has {O0, O1, O2, pad} in output in each dimension.
 *      SAMPLE_LOWER has {pad, O0, O1, O2} in output in each dimension.
 * 
 *  Pooling Example 2:
 *  <pre>{@code
 *      Given I = {6, 6}, B = {3, 3}, A = {3, 3}, S = {2, 2}, F = {3, 3}. What is O?
 *  }</pre>
 *  */
@Namespace("nvinfer1") public enum PaddingMode {
    /** Use explicit padding, rounding output size down. */
    kEXPLICIT_ROUND_DOWN(0),
    /** Use explicit padding, rounding output size up. */
    kEXPLICIT_ROUND_UP(1),
    /** Use SAME padding, with prePadding <= postPadding. */
    kSAME_UPPER(2),
    /** Use SAME padding, with prePadding >= postPadding. */
    kSAME_LOWER(3);

    public final int value;
    private PaddingMode(int v) { this.value = v; }
    private PaddingMode(PaddingMode e) { this.value = e.value; }
    public PaddingMode intern() { for (PaddingMode e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}
/**
 *  Maximum number of elements in PaddingMode enum.
 * 
 *  @see PaddingMode
 *  */

// Targeting ../nvinfer/IConvolutionLayer.java


// Targeting ../nvinfer/IActivationLayer.java



/**
 *  \enum PoolingType
 * 
 *  \brief The type of pooling to perform in a pooling layer.
 *  */
@Namespace("nvinfer1") public enum PoolingType {
    /** Maximum over elements */
    kMAX(0),
    /** Average over elements. If the tensor is padded, the count includes the padding */
    kAVERAGE(1),
    /** Blending between max and average pooling: (1-blendFactor)*maxPool + blendFactor*avgPool */
    kMAX_AVERAGE_BLEND(2);

    public final int value;
    private PoolingType(int v) { this.value = v; }
    private PoolingType(PoolingType e) { this.value = e.value; }
    public PoolingType intern() { for (PoolingType e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}
/**
 *  Maximum number of elements in PoolingType enum.
 * 
 *  @see PoolingType
 *  */

// Targeting ../nvinfer/IPoolingLayer.java


// Targeting ../nvinfer/ILRNLayer.java



/**
 *  \brief Controls how shift, scale and power are applied in a Scale layer.
 * 
 *  @see IScaleLayer
 *  */
@Namespace("nvinfer1") public enum ScaleMode {
    /** Identical coefficients across all elements of the tensor. */
    kUNIFORM(0),
    /** Per-channel coefficients. */
    kCHANNEL(1),
    /** Elementwise coefficients. */
    kELEMENTWISE(2);

    public final int value;
    private ScaleMode(int v) { this.value = v; }
    private ScaleMode(ScaleMode e) { this.value = e.value; }
    public ScaleMode intern() { for (ScaleMode e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}

/**
 *  Maximum number of elements in ScaleMode enum.
 * 
 *  @see ScaleMode
 *  */

// Targeting ../nvinfer/IScaleLayer.java


// Targeting ../nvinfer/ISoftMaxLayer.java


// Targeting ../nvinfer/IConcatenationLayer.java


// Targeting ../nvinfer/IDeconvolutionLayer.java



/**
 *  \enum ElementWiseOperation
 * 
 *  \brief Enumerates the binary operations that may be performed by an ElementWise layer.
 * 
 *  Operations kAND, kOR, and kXOR must have inputs of DataType::kBOOL.
 * 
 *  All other operations must have inputs of floating-point type, DataType::kINT8, DataType::kINT32, or
 *  DataType::kINT64.
 * 
 *  @see IElementWiseLayer
 *  */
@Namespace("nvinfer1") public enum ElementWiseOperation {
    /** Sum of the two elements. */
    kSUM(0),
    /** Product of the two elements. */
    kPROD(1),
    /** Maximum of the two elements. */
    kMAX(2),
    /** Minimum of the two elements. */
    kMIN(3),
    /** Subtract the second element from the first. */
    kSUB(4),
    /** Divide the first element by the second. */
    kDIV(5),
    /** The first element to the power of the second element. */
    kPOW(6),
    /** Floor division of the first element by the second. */
    kFLOOR_DIV(7),
    /** Logical AND of two elements. */
    kAND(8),
    /** Logical OR of two elements. */
    kOR(9),
    /** Logical XOR of two elements. */
    kXOR(10),
    /** Check if two elements are equal. */
    kEQUAL(11),
    /** Check if element in first tensor is greater than corresponding element in second tensor. */
    kGREATER(12),
    /** Check if element in first tensor is less than corresponding element in second tensor. */
    kLESS(13);

    public final int value;
    private ElementWiseOperation(int v) { this.value = v; }
    private ElementWiseOperation(ElementWiseOperation e) { this.value = e.value; }
    public ElementWiseOperation intern() { for (ElementWiseOperation e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}
/**
 *  Maximum number of elements in ElementWiseOperation enum.
 * 
 *  @see ElementWiseOperation
 *  */

// Targeting ../nvinfer/IElementWiseLayer.java



/**
 *  \brief Control form of IGatherLayer
 * 
 *  @see IGatherLayer
 *  */
@Namespace("nvinfer1") public enum GatherMode {
    /** Similar to ONNX Gather */
    kDEFAULT(0),
    /** Similar to ONNX GatherElements */
    kELEMENT(1),
    /** Similar to ONNX GatherND */
    kND(2);

    public final int value;
    private GatherMode(int v) { this.value = v; }
    private GatherMode(GatherMode e) { this.value = e.value; }
    public GatherMode intern() { for (GatherMode e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}

/**
 *  Maximum number of elements in GatherMode enum.
 * 
 *  @see GatherMode
 *  */

// Targeting ../nvinfer/IGatherLayer.java


// Targeting ../nvinfer/IPluginV2Layer.java


// Targeting ../nvinfer/IPluginV3Layer.java



/**
 *  \enum UnaryOperation
 * 
 *  \brief Enumerates the unary operations that may be performed by a Unary layer.
 * 
 *  Operations kNOT must have inputs of DataType::kBOOL.
 * 
 *  Operation kSIGN and kABS must have inputs of floating-point type, DataType::kINT8, DataType::kINT32 or
 *  DataType::kINT64.
 * 
 *  Operation kISINF must have inputs of floating-point type.
 * 
 *  All other operations must have inputs of floating-point type.
 * 
 *  @see IUnaryLayer
 *  */
@Namespace("nvinfer1") public enum UnaryOperation {
    /** Exponentiation. */
    kEXP(0),
    /** Log (base e). */
    kLOG(1),
    /** Square root. */
    kSQRT(2),
    /** Reciprocal. */
    kRECIP(3),
    /** Absolute value. */
    kABS(4),
    /** Negation. */
    kNEG(5),
    /** Sine. */
    kSIN(6),
    /** Cosine. */
    kCOS(7),
    /** Tangent. */
    kTAN(8),
    /** Hyperbolic sine. */
    kSINH(9),
    /** Hyperbolic cosine. */
    kCOSH(10),
    /** Inverse sine. */
    kASIN(11),
    /** Inverse cosine. */
    kACOS(12),
    /** Inverse tangent. */
    kATAN(13),
    /** Inverse hyperbolic sine. */
    kASINH(14),
    /** Inverse hyperbolic cosine. */
    kACOSH(15),
    /** Inverse hyperbolic tangent. */
    kATANH(16),
    /** Ceiling. */
    kCEIL(17),
    /** Floor. */
    kFLOOR(18),
    /** Gauss error function. */
    kERF(19),
    /** Logical NOT. */
    kNOT(20),
    /** Sign, If input > 0, output 1; if input < 0, output -1; if input == 0, output 0. */
    kSIGN(21),
    /** Round to nearest even for floating-point data type. */
    kROUND(22),
    /** Return true if input value equals +/- infinity for floating-point data type. */
    kISINF(23),
    /** Return true if input value is a NaN for floating-point data type. */
    kISNAN(24);

    public final int value;
    private UnaryOperation(int v) { this.value = v; }
    private UnaryOperation(UnaryOperation e) { this.value = e.value; }
    public UnaryOperation intern() { for (UnaryOperation e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}

/**
 *  Maximum number of elements in UnaryOperation enum.
 * 
 *  @see UnaryOperation
 *  */

// Targeting ../nvinfer/IUnaryLayer.java



/**
 *  \enum ReduceOperation
 * 
 *  \brief Enumerates the reduce operations that may be performed by a Reduce layer.
 * 
 *  The table shows the result of reducing across an empty volume of a given type.
 * 
 *  Operation | kFLOAT and kHALF  | kINT32  | kINT8
 *  --------- | ----------------- | ------- | -----
 *  kSUM      | 0                 | 0       | 0
 *  kPROD     | 1                 | 1       | 1
 *  kMAX      | negative infinity | INT_MIN | -128
 *  kMIN      | positive infinity | INT_MAX | 127
 *  kAVG      | NaN               | 0       | -128
 * 
 *  The current version of TensorRT usually performs reduction for kINT8 via kFLOAT or kHALF.
 *  The kINT8 values show the quantized representations of the floating-point values.
 *  */
@Namespace("nvinfer1") public enum ReduceOperation {
    kSUM(0),
    kPROD(1),
    kMAX(2),
    kMIN(3),
    kAVG(4);

    public final int value;
    private ReduceOperation(int v) { this.value = v; }
    private ReduceOperation(ReduceOperation e) { this.value = e.value; }
    public ReduceOperation intern() { for (ReduceOperation e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}

/**
 *  Maximum number of elements in ReduceOperation enum.
 * 
 *  @see ReduceOperation
 *  */

// Targeting ../nvinfer/IReduceLayer.java


// Targeting ../nvinfer/IPaddingLayer.java


// Targeting ../nvinfer/Permutation.java


// Targeting ../nvinfer/IShuffleLayer.java



/**
 *  \brief Controls how ISliceLayer and IGridSample handle out-of-bounds coordinates.
 * 
 *  @see ISliceLayer and IGridSample
 *  */
@Namespace("nvinfer1") public enum SampleMode {
    /** Fail with error when the coordinates are out of bounds. */
    kSTRICT_BOUNDS(0),
    /** Coordinates wrap around periodically. */
    kWRAP(1),
    /** Out of bounds indices are clamped to bounds. */
    kCLAMP(2),
    /** Use fill input value when coordinates are out of bounds. */
    kFILL(3),
    /** Coordinates reflect. The axis of reflection is the middle of the perimeter pixel and the
 *  reflections are repeated indefinitely within the padded regions. Repeats values for a single
 *  pixel and throws error for zero pixels. */
    kREFLECT(4);

    public final int value;
    private SampleMode(int v) { this.value = v; }
    private SampleMode(SampleMode e) { this.value = e.value; }
    public SampleMode intern() { for (SampleMode e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}

/**
 *  Maximum number of elements in SampleMode enum.
 * 
 *  @see SampleMode
 *  */

// Targeting ../nvinfer/ISliceLayer.java


// Targeting ../nvinfer/IShapeLayer.java



/**
 *  \enum TopKOperation
 * 
 *  \brief Enumerates the operations that may be performed by a TopK layer.
 *  */
@Namespace("nvinfer1") public enum TopKOperation {
    /** Maximum of the elements. */
    kMAX(0),
    /** Minimum of the elements. */
    kMIN(1);

    public final int value;
    private TopKOperation(int v) { this.value = v; }
    private TopKOperation(TopKOperation e) { this.value = e.value; }
    public TopKOperation intern() { for (TopKOperation e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}

/**
 *  Maximum number of elements in TopKOperation enum.
 * 
 *  @see TopKOperation
 *  */

// Targeting ../nvinfer/ITopKLayer.java



/**
 *  \enum MatrixOperation
 * 
 *  \brief Enumerates the operations that may be performed on a tensor
 *         by IMatrixMultiplyLayer before multiplication.
 *  */
@Namespace("nvinfer1") public enum MatrixOperation {
    /** Treat x as a matrix if it has two dimensions, or as a collection of
     *  matrices if x has more than two dimensions, where the last two dimensions
     *  are the matrix dimensions. x must have at least two dimensions. */
    kNONE(0),

    /** Like kNONE, but transpose the matrix dimensions. */
    
//!
//!
    kTRANSPOSE(1),

    /** Treat x as a vector if it has one dimension, or as a collection of
     *  vectors if x has more than one dimension. x must have at least one dimension.
     * 
     *  The first input tensor with dimensions [M,K] used with MatrixOperation::kVECTOR is equivalent to a tensor
     *  with dimensions [M, 1, K] with MatrixOperation::kNONE, i.e. is treated as M row vectors of length K,
     *  or dimensions [M, K, 1] with MatrixOperation::kTRANSPOSE.
     * 
     *  The second input tensor with dimensions [M,K] used with MatrixOperation::kVECTOR is equivalent to a tensor
     *  with dimensions [M, K, 1] with MatrixOperation::kNONE, i.e. is treated as M column vectors of length K,
     *  or dimensions [M, 1, K] with MatrixOperation::kTRANSPOSE. */
    kVECTOR(2);

    public final int value;
    private MatrixOperation(int v) { this.value = v; }
    private MatrixOperation(MatrixOperation e) { this.value = e.value; }
    public MatrixOperation intern() { for (MatrixOperation e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}

/**
 *  Maximum number of elements in MatrixOperation enum.
 * 
 *  @see DataType
 *  */

// Targeting ../nvinfer/IMatrixMultiplyLayer.java


// Targeting ../nvinfer/INonZeroLayer.java


// Targeting ../nvinfer/IRaggedSoftMaxLayer.java


// Targeting ../nvinfer/IIdentityLayer.java


// Targeting ../nvinfer/ICastLayer.java


// Targeting ../nvinfer/IConstantLayer.java


// Targeting ../nvinfer/IParametricReLULayer.java



/** \enum InterpolationMode
 * 
 *  \brief Enumerates various modes of interpolation
 * 
 *  */
@Namespace("nvinfer1") public enum InterpolationMode {
    /** ND (0 < N <= 8) nearest neighbor resizing. */
    kNEAREST(0),
    /** Supports linear (1D), bilinear (2D), and trilinear (3D) interpolation */
    kLINEAR(1),
    /** Supports bicubic (2D) interpolation */
    kCUBIC(2);

    public final int value;
    private InterpolationMode(int v) { this.value = v; }
    private InterpolationMode(InterpolationMode e) { this.value = e.value; }
    public InterpolationMode intern() { for (InterpolationMode e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}
/**
 *  Maximum number of elements in InterpolationMode enum.
 * 
 *  @see InterpolationMode
 *  */
 // namespace impl

/**
 *  \enum ResizeCoordinateTransformation
 * 
 *  \brief The resize coordinate transformation function.
 * 
 *  @see IResizeLayer::setCoordinateTransformation()
 *  */
@Namespace("nvinfer1") public enum ResizeCoordinateTransformation {
    /** Think of each value in the tensor as a unit volume, and the coordinate is a point inside this volume.
     *  The coordinate point is drawn as a star {@code (*)} in the below diagram, and multiple values range has a length.
     *  Define {@code x_origin} as the coordinate of axis x in the input tensor, {@code x_resized} as the coordinate of axis x in
     *  the output tensor, {@code length_origin} as length of the input tensor in axis x, and {@code length_resize} as length of the
     *  output tensor in axis x.
     * 
     *      |<--------------length---------->|
     *      |    0     |    1     |    2     |    3     |
     *      *          *          *          *
     * 
     *      x_origin = x_resized * (length_origin - 1) / (length_resize - 1)
     *  */
    
//!
//!
    kALIGN_CORNERS(0),

    /**     |<--------------length--------------------->|
     *      |    0     |    1     |    2     |    3     |
     *      *          *          *          *
     * 
     *      x_origin = x_resized * (length_origin / length_resize)
     *  */
    
//!
//!
    kASYMMETRIC(1),

    /**     |<--------------length--------------------->|
     *      |    0     |    1     |    2     |    3     |
     *           *          *          *          *
     * 
     *      x_origin = (x_resized + 0.5) * (length_origin / length_resize) - 0.5
     *  */
    kHALF_PIXEL(2);

    public final int value;
    private ResizeCoordinateTransformation(int v) { this.value = v; }
    private ResizeCoordinateTransformation(ResizeCoordinateTransformation e) { this.value = e.value; }
    public ResizeCoordinateTransformation intern() { for (ResizeCoordinateTransformation e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}
/**
 *  Maximum number of elements in ResizeCoordinateTransformation enum.
 * 
 *  @see ResizeCoordinateTransformation
 *  */
 // namespace impl

/**
 *  \enum ResizeSelector
 * 
 *  \brief The coordinate selector when resize to single pixel output.
 * 
 *  @see IResizeLayer::setSelectorForSinglePixel()
 *  */
@Namespace("nvinfer1") public enum ResizeSelector {
    /** Use formula to map the original index. */
    kFORMULA(0),

    /** Select the upper left pixel. */
    kUPPER(1);

    public final int value;
    private ResizeSelector(int v) { this.value = v; }
    private ResizeSelector(ResizeSelector e) { this.value = e.value; }
    public ResizeSelector intern() { for (ResizeSelector e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}
/**
 *  Maximum number of elements in ResizeSelector enum.
 * 
 *  @see ResizeSelector
 *  */
 // namespace impl

/**
 *  \enum ResizeRoundMode
 * 
 *  \brief The rounding mode for nearest neighbor resize.
 * 
 *  @see IResizeLayer::setNearestRounding()
 *  */
@Namespace("nvinfer1") public enum ResizeRoundMode {
    /** Round half up. */
    kHALF_UP(0),

    /** Round half down. */
    kHALF_DOWN(1),

    /** Round to floor. */
    kFLOOR(2),

    /** Round to ceil. */
    kCEIL(3);

    public final int value;
    private ResizeRoundMode(int v) { this.value = v; }
    private ResizeRoundMode(ResizeRoundMode e) { this.value = e.value; }
    public ResizeRoundMode intern() { for (ResizeRoundMode e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}
/**
 *  Maximum number of elements in ResizeRoundMode enum.
 * 
 *  @see ResizeRoundMode
 *  */

// Targeting ../nvinfer/IResizeLayer.java



/**
 *  \enum LoopOutput
 * 
 *  \brief Enum that describes kinds of loop outputs.
 *  */
@Namespace("nvinfer1") public enum LoopOutput {
    /** Output value is value of tensor for last iteration. */
    kLAST_VALUE(0),

    /** Output value is concatenation of values of tensor for each iteration, in forward order. */
    kCONCATENATE(1),

    /** Output value is concatenation of values of tensor for each iteration, in reverse order. */
    kREVERSE(2);

    public final int value;
    private LoopOutput(int v) { this.value = v; }
    private LoopOutput(LoopOutput e) { this.value = e.value; }
    public LoopOutput intern() { for (LoopOutput e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}

/**
 *  Maximum number of elements in LoopOutput enum.
 * 
 *  @see DataType
 *  */


/**
 *  \enum TripLimit
 * 
 *  \brief Enum that describes kinds of trip limits.
 *  */
@Namespace("nvinfer1") public enum TripLimit {

    /** Tensor is a scalar of type kINT32 or kINT64 that contains the trip count. */
    kCOUNT(0),
    /** Tensor is a scalar of type kBOOL. Loop terminates when value is false. */
    kWHILE(1);

    public final int value;
    private TripLimit(int v) { this.value = v; }
    private TripLimit(TripLimit e) { this.value = e.value; }
    public TripLimit intern() { for (TripLimit e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}

/**
 *  Maximum number of elements in TripLimit enum.
 * 
 *  @see DataType
 *  */

// Targeting ../nvinfer/ILoopBoundaryLayer.java


// Targeting ../nvinfer/IIfConditionalBoundaryLayer.java


// Targeting ../nvinfer/IConditionLayer.java


// Targeting ../nvinfer/IIfConditionalOutputLayer.java


// Targeting ../nvinfer/IIfConditionalInputLayer.java


// Targeting ../nvinfer/IIfConditional.java


// Targeting ../nvinfer/IRecurrenceLayer.java


// Targeting ../nvinfer/ILoopOutputLayer.java


// Targeting ../nvinfer/ITripLimitLayer.java


// Targeting ../nvinfer/IIteratorLayer.java


// Targeting ../nvinfer/ILoop.java


// Targeting ../nvinfer/ISelectLayer.java


// Targeting ../nvinfer/IAssertionLayer.java



/**
 *  \enum FillOperation
 * 
 *  \brief Enumerates the tensor fill operations that may performed by a fill layer.
 * 
 *  @see IFillLayer
 *  */
@Namespace("nvinfer1") public enum FillOperation {
    /** Compute each value via an affine function of its indices.
     *  For example, suppose the parameters for the IFillLayer are:
     * 
     *  * Dimensions = [3,4]
     *  * Alpha = 1
     *  * Beta = [100,10]
     * 
     *  Element [i,j] of the output is Alpha + Beta[0]*i + Beta[1]*j.
     *  Thus the output matrix is:
     * 
     *       1  11  21  31
     *     101 111 121 131
     *     201 211 221 231
     * 
     *  A static beta b is implicitly a 1D tensor, i.e. Beta = [b]. */
    kLINSPACE(0),

    /** Randomly draw values from a uniform distribution. */
    kRANDOM_UNIFORM(1),

    /** Randomly draw values from a normal distribution. */
    kRANDOM_NORMAL(2);

    public final int value;
    private FillOperation(int v) { this.value = v; }
    private FillOperation(FillOperation e) { this.value = e.value; }
    public FillOperation intern() { for (FillOperation e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}

/**
 *  Maximum number of elements in FillOperation enum.
 * 
 *  @see FillOperation
 *  */

// Targeting ../nvinfer/IFillLayer.java


// Targeting ../nvinfer/IQuantizeLayer.java


// Targeting ../nvinfer/IDequantizeLayer.java


// Targeting ../nvinfer/IDynamicQuantizeLayer.java


// Targeting ../nvinfer/IEinsumLayer.java



/**
 *  \enum ScatterMode
 * 
 *  \brief Control form of IScatterLayer
 * 
 *  @see IScatterLayer
 *  */
@Namespace("nvinfer1") public enum ScatterMode {
    /** Similar to ONNX ScatterElements */
    kELEMENT(0),
    /** Similar to ONNX ScatterND */
    kND(1);

    public final int value;
    private ScatterMode(int v) { this.value = v; }
    private ScatterMode(ScatterMode e) { this.value = e.value; }
    public ScatterMode intern() { for (ScatterMode e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}

/**
 *  Maximum number of elements in ScatterMode enum.
 * 
 *  @see ScatterMode
 *  */

// Targeting ../nvinfer/IScatterLayer.java


// Targeting ../nvinfer/IOneHotLayer.java


// Targeting ../nvinfer/IGridSampleLayer.java

 // class IGridSampleLayer

/**
 *  \enum BoundingBoxFormat
 * 
 *  \brief Representation of bounding box data used for the Boxes input tensor in INMSLayer
 * 
 *  @see INMSLayer
 *  */
@Namespace("nvinfer1") public enum BoundingBoxFormat {
    /** (x1, y1, x2, y2) where (x1, y1) and (x2, y2) are any pair of diagonal corners */
    kCORNER_PAIRS(0),
    /** (x_center, y_center, width, height) where (x_center, y_center) is the center point of the box */
    kCENTER_SIZES(1);

    public final int value;
    private BoundingBoxFormat(int v) { this.value = v; }
    private BoundingBoxFormat(BoundingBoxFormat e) { this.value = e.value; }
    public BoundingBoxFormat intern() { for (BoundingBoxFormat e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}

/**
 *  Maximum number of elements in BoundingBoxFormat enum.
 * 
 *  @see BoundingBoxFormat
 *  */

// Targeting ../nvinfer/INMSLayer.java


// Targeting ../nvinfer/IReverseSequenceLayer.java


// Targeting ../nvinfer/INormalizationLayer.java


// Targeting ../nvinfer/ISqueezeLayer.java


// Targeting ../nvinfer/IUnsqueezeLayer.java



/**
 *  \enum CumulativeOperation
 * 
 *  \brief Enumerates the cumulative operations that may be performed by a Cumulative layer.
 * 
 *  The table shows the initial value of each Cumulative operation.
 * 
 *  Operation | kFLOAT, kHALF, kBF16 | kINT32, kINT64 |
 *  --------- | -------------------- | -------------- |
 *  kSUM      | +0.0                 | 0              |
 *  */
@Namespace("nvinfer1") public enum CumulativeOperation {
    /** Calculate cumulative sum. */
    kSUM(0);

    public final int value;
    private CumulativeOperation(int v) { this.value = v; }
    private CumulativeOperation(CumulativeOperation e) { this.value = e.value; }
    public CumulativeOperation intern() { for (CumulativeOperation e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}

/**
 *  \brief Maximum number of elements in CumulativeOperation enum.
 * 
 *  @see CumulativeOperation
 *  */


// Targeting ../nvinfer/ICumulativeLayer.java



/**
 *  \enum AttentionNormalizationOp
 * 
 *  \brief Enumerates the operations that may be performed by the normalization in the attention subgraph.
 *  */
@Namespace("nvinfer1") public enum AttentionNormalizationOp {
    /** Apply no normalization on the attention scores. Must be used with decomposable=True on pre-Blackwell GPUs */
    kNONE
    (0),
    /** Apply softmax normalization on the attention scores on the {@code s_kv} dimension. */
    kSOFTMAX(1);

    public final int value;
    private AttentionNormalizationOp(int v) { this.value = v; }
    private AttentionNormalizationOp(AttentionNormalizationOp e) { this.value = e.value; }
    public AttentionNormalizationOp intern() { for (AttentionNormalizationOp e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}
/**
 *  Maximum number of elements in AttentionNormalizationOp enum.
 * 
 *  @see AttentionNormalizationOp
 *  */


// Targeting ../nvinfer/IAttentionBoundaryLayer.java


// Targeting ../nvinfer/IAttentionInputLayer.java


// Targeting ../nvinfer/IAttentionOutputLayer.java


// Targeting ../nvinfer/IAttention.java


// Targeting ../nvinfer/INetworkDefinition.java



/**
 *  \enum CalibrationAlgoType
 * 
 *  \brief Version of calibration algorithm to use.
 * 
 *  @deprecated Deprecated in TensorRT 10.1. Superseded by explicit quantization.
 *  */
@Namespace("nvinfer1") public enum CalibrationAlgoType {
    /** Legacy calibration */
    kLEGACY_CALIBRATION(0),
    /** Legacy entropy calibration */
    kENTROPY_CALIBRATION(1),
    /** Entropy calibration */
    kENTROPY_CALIBRATION_2(2),
    /** Minmax calibration */
    kMINMAX_CALIBRATION(3);

    public final int value;
    private CalibrationAlgoType(int v) { this.value = v; }
    private CalibrationAlgoType(CalibrationAlgoType e) { this.value = e.value; }
    public CalibrationAlgoType intern() { for (CalibrationAlgoType e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}

/**
 *  Maximum number of elements in CalibrationAlgoType enum.
 * 
 *  @see DataType
 *  */

// Targeting ../nvinfer/IInt8Calibrator.java


// Targeting ../nvinfer/IInt8EntropyCalibrator.java


 // namespace v_1_0

/**
 *  \class IInt8EntropyCalibrator
 * 
 *  \brief Entropy calibrator.
 * 
 *  This is the Legacy Entropy calibrator. It is less complicated than the legacy calibrator and
 *  produces better results.
 * 
 *  \note To ensure compatibility of source code with future versions of TensorRT, use IEntropyCalibrator, not
 *        v_1_0::IEntropyCalibrator
 * 
 *  @deprecated Deprecated in TensorRT 10.1. Superseded by explicit quantization.
 *  */
// Targeting ../nvinfer/IInt8EntropyCalibrator2.java


 // namespace v_1_0

/**
 *  \class IInt8EntropyCalibrator2
 * 
 *  \brief Entropy calibrator 2.
 * 
 *  This is the preferred calibrator. This is the required calibrator for DLA, as it supports per
 *  activation tensor scaling.
 * 
 *  \note To ensure compatibility of source code with future versions of TensorRT, use IEntropyCalibrator2, not
 *         v_1_0::IEntropyCalibrator2
 * 
 *  @deprecated Deprecated in TensorRT 10.1. Superseded by explicit quantization.
 *  */
// Targeting ../nvinfer/IInt8MinMaxCalibrator.java


 // namespace v_1_0

/**
 *  \class IInt8MinMaxCalibrator
 * 
 *  \brief MinMax Calibrator.
 * 
 *  It supports per activation tensor scaling.
 * 
 *  \note To ensure compatibility of source code with future versions of TensorRT, use IMinMaxCalibrator>, not
 *        v_1_0::IMinMaxCalibrator
 * 
 *  @deprecated Deprecated in TensorRT 10.1. Superseded by explicit quantization.
 *  */
// Targeting ../nvinfer/IInt8LegacyCalibrator.java


 // namespace v_1_0

/**
 *  \class IInt8LegacyCalibrator
 * 
 *  \brief Legacy calibrator.
 * 
 *  This calibrator requires user parameterization,
 *  and is provided as a fallback option if the other calibrators yield poor results.
 * 
 *  \note To ensure compatibility of source code with future versions of TensorRT, use ILegacyCalibrator, not
 *        v_1_0::ILegacyCalibrator
 * 
 *  @deprecated Deprecated in TensorRT 10.1. Superseded by explicit quantization.
 *  */


//!
//!
//!
//!
//!
// Targeting ../nvinfer/IAlgorithmIOInfo.java


// Targeting ../nvinfer/IAlgorithmVariant.java


// Targeting ../nvinfer/IAlgorithmContext.java


// Targeting ../nvinfer/IAlgorithm.java


// Targeting ../nvinfer/IAlgorithmSelector.java


 // namespace v_1_0

/**
 *  \class IAlgorithmSelector
 * 
 *  \brief Interface implemented by application for selecting and reporting algorithms of a layer provided by the
 *         builder.
 *  \note A layer in context of algorithm selection may be different from ILayer in INetworkDefinition.
 *        For example, an algorithm might be implementing a conglomeration of multiple ILayers in INetworkDefinition.
 *  \note To ensure compatibility of source code with future versions of TensorRT, use IAlgorithmSelector, not
 *        v_1_0::IAlgorithmSelector
 * 
 *  @deprecated Deprecated in TensorRT 10.8. Please use editable mode in ITimingCache instead.
 *  */


//!
//!
//!

/**
 *  \brief Represents one or more QuantizationFlag values using binary OR
 *  operations.
 * 
 *  @see IBuilderConfig::getQuantizationFlags(), IBuilderConfig::setQuantizationFlags()
 *  */


//!
//!
//!
//!
//!

/**
 *  \enum QuantizationFlag
 * 
 *  \brief List of valid flags for quantizing the network to int8
 * 
 *  @see IBuilderConfig::setQuantizationFlag(), IBuilderConfig::getQuantizationFlag()
 * 
 *  @deprecated Deprecated in TensorRT 10.1. Superseded by explicit quantization.
 *  */
@Namespace("nvinfer1") public enum QuantizationFlag {
    /** Run int8 calibration pass before layer fusion. Only valid for IInt8LegacyCalibrator and
     *  IInt8EntropyCalibrator. The builder always runs the int8 calibration pass before layer fusion for
     *  IInt8MinMaxCalibrator and IInt8EntropyCalibrator2. Disabled by default. */
    kCALIBRATE_BEFORE_FUSION(0);

    public final int value;
    private QuantizationFlag(int v) { this.value = v; }
    private QuantizationFlag(QuantizationFlag e) { this.value = e.value; }
    public QuantizationFlag intern() { for (QuantizationFlag e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}

/**
 *  Maximum number of quantization flags in QuantizationFlag enum.
 * 
 *  @see QuantizationFlag
 *  */


/**
 *  \enum RuntimePlatform
 * 
 *  \brief Describes the intended runtime platform (operating system and CPU architecture) for the execution of the
 *         TensorRT engine. TensorRT provides support for cross-platform engine compatibility when the target runtime
 *         platform is different from the build platform.
 * 
 *  \note The cross-platform engine will not be able to run on the host platform it was built on.
 * 
 *  \note When building a cross-platform engine that also requires version forward compatibility,
 *        kEXCLUDE_LEAN_RUNTIME must be set to exclude the target platform lean runtime.
 * 
 *  \note The cross-platform engine might have performance differences compared to the natively built engine on the
 *        target platform.
 * 
 *  @see IBuilderConfig::setRuntimePlatform(), IBuilderConfig::getRuntimePlatform()
 *  */
@Namespace("nvinfer1") public enum RuntimePlatform {
    /** No requirement for cross-platform compatibility. The engine constructed by TensorRT can only run on the
     *  identical platform it was built on. */
    kSAME_AS_BUILD(0),

    /** Designates the target platform for engine execution as Windows AMD64 system. Currently this flag can only be
     *  enabled when building engines on Linux AMD64 platforms. */
    kWINDOWS_AMD64(1);

    public final int value;
    private RuntimePlatform(int v) { this.value = v; }
    private RuntimePlatform(RuntimePlatform e) { this.value = e.value; }
    public RuntimePlatform intern() { for (RuntimePlatform e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}
/**
 *  Maximum number of elements in RuntimePlatform enum.
 * 
 *  @see RuntimePlatform
 *  */
 // namespace impl

/**
 *  \brief Represents one or more BuilderFlag values using binary OR
 *  operations, e.g., 1U << BuilderFlag::kFP16 | 1U << BuilderFlag::kDEBUG.
 * 
 *  @see IBuilderConfig::setFlags(), IBuilderConfig::getFlags()
 *  */


//!
//!
//!
//!

/**
 *  \enum BuilderFlag
 * 
 *  \brief List of valid modes that the builder can enable when creating an engine from a network definition.
 * 
 *  @see IBuilderConfig::setFlags(), IBuilderConfig::getFlags()
 *  */
@Namespace("nvinfer1") public enum BuilderFlag {
    /** Enable FP16 layer selection, with FP32 fallback.
     *  @deprecated Deprecated in TensorRT 10.12. Superseded by strong typing. */
    kFP16(0),

    /** Enable Int8 layer selection, with FP32 fallback with FP16 fallback if kFP16 also specified.
     *  @deprecated Deprecated in TensorRT 10.12. Superseded by strong typing. */
    kINT8(1),

    /** Enable debugging of layers via synchronizing after every layer. */
    kDEBUG(2),

    /** Enable layers marked to execute on GPU if layer cannot execute on DLA. */
    kGPU_FALLBACK(3),

    /** Enable building a refittable engine. */
    kREFIT(4),

    /** Disable reuse of timing information across identical layers. */
    kDISABLE_TIMING_CACHE(5),

    /** Allow (but not require) computations on tensors of type DataType::kFLOAT to use TF32.
     *  TF32 computes inner products by rounding the inputs to 10-bit mantissas before
     *  multiplying, but accumulates the sum using 23-bit mantissas. Enabled by default. */
    kTF32(6),

    /** Allow the builder to examine weights and use optimized functions when weights have suitable sparsity. */
    
//!
    kSPARSE_WEIGHTS(7),

    /** Change the allowed parameters in the EngineCapability::kSTANDARD flow to
     *  match the restrictions that EngineCapability::kSAFETY check against for DeviceType::kGPU
     *  and EngineCapability::kDLA_STANDALONE check against the DeviceType::kDLA case. This flag
     *  is forced to true if EngineCapability::kSAFETY at build time if it is unset.
     * 
     *  This flag is only supported in NVIDIA Drive(R) products. */
    kSAFETY_SCOPE(8),

    /** Require that layers execute in specified precisions. Build fails otherwise.
     *  @deprecated Deprecated in TensorRT 10.12. Superseded by strong typing. */
    kOBEY_PRECISION_CONSTRAINTS(9),

    /** Prefer that layers execute in specified precisions.
     *  Fall back (with warning) to another precision if build would otherwise fail.
     *  @deprecated Deprecated in TensorRT 10.12. Superseded by strong typing. */
    kPREFER_PRECISION_CONSTRAINTS(10),

    /** Require that no reformats be inserted between a layer and a network I/O tensor
     *  for which ITensor::setAllowedFormats was called.
     *  Build fails if a reformat is required for functional correctness.
     *  @deprecated Deprecated in TensorRT 10.7. Unneeded API. */
    kDIRECT_IO(11),

    /** Fail if IAlgorithmSelector::selectAlgorithms returns an empty set of algorithms.
     *  @deprecated Deprecated in TensorRT 10.10. Unneeded API due to IAlgorithmSelector deprecation. */
    
//!
    kREJECT_EMPTY_ALGORITHMS(12),

    /** Restrict to lean runtime operators to provide version forward compatibility
     *  for the plan.
     * 
     *  This flag is only supported by NVIDIA Volta and later GPUs.
     *  This flag is not supported in NVIDIA Drive(R) products. */
    
//!
    kVERSION_COMPATIBLE(13),

    /** Exclude lean runtime from the plan when version forward compatability is enabled.
     *  By default, this flag is unset, so the lean runtime will be included in the plan.
     * 
     *  If BuilderFlag::kVERSION_COMPATIBLE is not set then the value of this flag will be ignored. */
    
//!
//!
    kEXCLUDE_LEAN_RUNTIME(14),

    /** Enable plugins with FP8 input/output.
     * 
     *  This flag is not supported when HardwareCompatibilityLevel::kAMPERE_PLUS is enabled.
     * 
     *  @see HardwareCompatibilityLevel
     *  @deprecated Deprecated in TensorRT 10.12. Superseded by strong typing. */
    kFP8(15),

    /** Emit error when a tactic being timed is not present in the timing cache.
     *  This flag has an effect only when IBuilderConfig has an associated ITimingCache. */
    kERROR_ON_TIMING_CACHE_MISS(16),

    /** Enable DataType::kBF16 layer selection, with FP32 fallback.
     *  This flag is only supported by NVIDIA Ampere and later GPUs.
     *  @deprecated Deprecated in TensorRT 10.12. Superseded by strong typing. */
    kBF16(17),

    /** Disable caching of JIT-compilation results during engine build.
     *  By default, JIT-compiled code will be serialized as part of the timing cache, which may significantly increase
     *  the cache size. Setting this flag prevents the code from being serialized. This flag has an effect only when
     *  BuilderFlag::DISABLE_TIMING_CACHE is not set. */
    kDISABLE_COMPILATION_CACHE(18),

    /** Strip the refittable weights from the engine plan file. */
    kSTRIP_PLAN(19),

    /** @deprecated Deprecated in TensorRT 10.0. Superseded by kSTRIP_PLAN. */
    kWEIGHTLESS(kSTRIP_PLAN.value),

    /** Create a refittable engine under the assumption that the refit weights will be identical to those provided at
     *  build time. The resulting engine will have the same performance as a non-refittable one. All refittable weights
     *  can be refitted through the refit API, but if the refit weights are not identical to the build-time weights,
     *  behavior is undefined. When used alongside 'kSTRIP_PLAN', this flag will result in a small plan file for which
     *  weights are later supplied via refitting. This enables use of a single set of weights with different inference
     *  backends, or with TensorRT plans for multiple GPU architectures. */
    

//!
//!
//!
//!
//!
//!
//!
//!
    kREFIT_IDENTICAL(20),

    /**
     *  \brief Enable weight streaming for the current engine.
     * 
     *  Weight streaming from the host enables execution of models that do not fit
     *  in GPU memory by allowing TensorRT to intelligently stream network weights
     *  from the CPU DRAM. Please see ICudaEngine::getMinimumWeightStreamingBudget
     *  for the default memory budget when this flag is enabled.
     * 
     *  Enabling this feature changes the behavior of
     *  IRuntime::deserializeCudaEngine to allocate the entire network's weights
     *  on the CPU DRAM instead of GPU memory. Then,
     *  ICudaEngine::createExecutionContext will determine the optimal split of
     *  weights between the CPU and GPU and place weights accordingly.
     * 
     *  Future TensorRT versions may enable this flag by default.
     * 
     *  \warning Enabling this flag may marginally increase build time.
     * 
     *  \warning Enabling this feature will significantly increase the latency of
     *           ICudaEngine::createExecutionContext.
     * 
     *  @see IRuntime::deserializeCudaEngine,
     *       ICudaEngine::getMinimumWeightStreamingBudget,
     *       ICudaEngine::setWeightStreamingBudget
     *  */
    kWEIGHT_STREAMING(21),

    /** Enable plugins with INT4 input/output.
     *  @deprecated Deprecated in TensorRT 10.12. Superseded by strong typing. */
    kINT4(22),

    /** Enable building a refittable engine and provide fine-grained control. This allows
     *  control over which weights are refittable or not using INetworkDefinition::markWeightsRefittable and
     *  INetworkDefinition::unmarkWeightsRefittable. By default, all weights are non-refittable when this flag is
     *  enabled. This flag cannot be used together with kREFIT or kREFIT_IDENTICAL. */
    kREFIT_INDIVIDUAL(23),

    /**  Disable floating-point optimizations: 0*x => 0, x-x => 0, or x/x => 1. These identities are
     *   not true when x is a NaN or Inf, and thus might hide propagation or generation of NaNs. This flag is typically
     *   used in combination with kSPARSE_WEIGHTS.
     *   There are three valid sparsity configurations.
     *   1. Disable all sparsity. Both kSPARSE_WEIGHTS and kSTRICT_NANS are unset
     *   2. Enable sparsity only where it does not affect propagation/generation of NaNs. Both kSPARSE_WEIGHTS and
     *   kSTRICT_NANS are set
     *   3. Enable all sparsity. kSPARSE_WEIGHTS is set and kSTRICT_NANS is unset */
    kSTRICT_NANS(24),

    /** Enable memory monitor during build time. */
    kMONITOR_MEMORY(25),

    /** Enable plugins with FP4 input/output.
     *  @deprecated Deprecated in TensorRT 10.12. Superseded by strong typing. */
    kFP4(26),

    /** Enable editable timing cache. */
    kEDITABLE_TIMING_CACHE(27),

    /** Enable distributive independence.
     *  When BuilderFlag::kDISTRIBUTIVE_INDEPENDENCE is set and a layer documents axis i of an output as a distributive
     *  axis, then the layer behaves exactly as if each evaluation across axis i was done using identical operations.
     *  The definition of distributive axis is as follows:
     *  For IMatrixMultiplyLayer:
     *  All axes that are not one of the vector or matrix dimensions are distributive axes.
     *  For layers that perform reduction:
     *  All non-reduction axes are distributive axes.
     *  For layers that perform einsum:
     *  Let n be the leftmost reduction axis. The axes to the left of n are distributive axes. */
    kDISTRIBUTIVE_INDEPENDENCE(28),

// #if ENABLE_FEATURE_DISABLE_RUNTIME_ALLOCATION
    /** Build an engine that requires user allocation when creating an execution context.
     *  This means that runtime allocation will not be enabled even when the tensor dimensions
     *  exceed the limits for static allocation, and ensures that inference will support graph
     *  capture unless the network includes operations such as data-dependent dynamic shapes
     *  (INonZeroLayer, ITripLimitLayer, etc.) that require runtime allocation. If such operations
     *  are present, the engine build will fail with an error message. */
    kREQUIRE_USER_ALLOCATION(29);
// #endif // ENABLE_FEATURE_DISABLE_RUNTIME_ALLOCATION

    public final int value;
    private BuilderFlag(int v) { this.value = v; }
    private BuilderFlag(BuilderFlag e) { this.value = e.value; }
    public BuilderFlag intern() { for (BuilderFlag e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}

/**
 *  Maximum number of builder flags in BuilderFlag enum.
 * 
 *  @see BuilderFlag
 *  */

// Targeting ../nvinfer/TimingCacheKey.java


// Targeting ../nvinfer/TimingCacheValue.java



// Targeting ../nvinfer/ITimingCache.java



/**
 *  \enum MemoryPoolType
 * 
 *  \brief The type for memory pools used by TensorRT.
 * 
 *  @see IBuilderConfig::setMemoryPoolLimit, IBuilderConfig::getMemoryPoolLimit
 *  */
@Namespace("nvinfer1") public enum MemoryPoolType {
    /**
     *  kWORKSPACE is used by TensorRT to store intermediate buffers within an operation.
     *  This defaults to max device memory. Set to a smaller value to restrict tactics that use over the
     *  threshold en masse. For more targeted removal of tactics use the IAlgorithmSelector
     *  interface.
     *  */
    

//!
//!
    kWORKSPACE(0),

    /**
     *  kDLA_MANAGED_SRAM is a fast software managed RAM used by DLA to communicate within a layer.
     *  The size of this pool must be at least 4 KiB and must be a power of 2.
     *  This defaults to 1 MiB.
     *  Orin has capacity of 1 MiB per core.
     *  */
    

//!
//!
    kDLA_MANAGED_SRAM(1),

    /**
     *  kDLA_LOCAL_DRAM is host RAM used by DLA to share intermediate tensor data across operations.
     *  The size of this pool must be at least 4 KiB and must be a power of 2.
     *  This defaults to 1 GiB.
     *  */
    

//!
//!
    kDLA_LOCAL_DRAM(2),

    /**
     *  kDLA_GLOBAL_DRAM is host RAM used by DLA to store weights and metadata for execution.
     *  The size of this pool must be at least 4 KiB and must be a power of 2.
     *  This defaults to 512 MiB.
     *  */
    

//!
//!
    kDLA_GLOBAL_DRAM(3),

    /**
     *  kTACTIC_DRAM is the device DRAM used by the optimizer to
     *  run tactics. On embedded devices, where host and device memory are unified, this includes all host
     *  memory required by TensorRT to build the network up to the point of each memory allocation.
     *  This defaults to 75% of totalGlobalMem as reported by cudaGetDeviceProperties when
     *  cudaGetDeviceProperties.embedded is true, and 100% otherwise.
     *  */
    

//!
//!
//!
//!
    kTACTIC_DRAM(4),

    /**
     *  kTACTIC_SHARED_MEMORY defines the maximum sum of shared memory reserved by the driver and
     *  used for executing CUDA kernels. Adjust this value to restrict tactics that exceed the
     *  specified threshold en masse. The default value is device max capability. This value must
     *  be less than 1GiB.
     * 
     *  The driver reserved shared memory can be queried from cuDeviceGetAttribute(&reservedShmem,
     *  CU_DEVICE_ATTRIBUTE_RESERVED_SHARED_MEMORY_PER_BLOCK).
     * 
     *  Updating this flag will override the shared memory limit set by \ref HardwareCompatibilityLevel,
     *  which defaults to 48KiB - reservedShmem.
     *  */
    kTACTIC_SHARED_MEMORY(5);

    public final int value;
    private MemoryPoolType(int v) { this.value = v; }
    private MemoryPoolType(MemoryPoolType e) { this.value = e.value; }
    public MemoryPoolType intern() { for (MemoryPoolType e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}

/**
 *  Maximum number of memory pool types in the MemoryPoolType enum.
 * 
 *  @see MemoryPoolType
 *  */


/**
 *  \enum PreviewFeature
 * 
 *  \brief Define preview features
 * 
 *  Preview Features have been fully tested but are not yet as stable as other features in TensorRT.
 *  They are provided as opt-in features for at least one release.
 *  */
@Namespace("nvinfer1") public enum PreviewFeature {
    /**
     *  Allows optimization profiles to be shared across execution contexts.
     * 
     *  @deprecated Deprecated in TensorRT 10.0. The default value for this flag is on and can not be changed.
     *  */
    

//!
//!
    kPROFILE_SHARING_0806(0),

    /**
     *  Allows plugin I/O to be aliased when using IPluginV3OneBuildV2
     *  */
    

//!
//!
    kALIASED_PLUGIN_IO_10_03(1),

    /**
     *  Allows IExecutionContext::updateDeviceMemorySizeForShapes to resize runner internal activation memory.
     *  Using this feature can reduce runtime memory requirement when the actual input tensor shapes are smaller than
     *  the maximum input tensor dimensions.
     *  */
    kRUNTIME_ACTIVATION_RESIZE_10_10(2);

    public final int value;
    private PreviewFeature(int v) { this.value = v; }
    private PreviewFeature(PreviewFeature e) { this.value = e.value; }
    public PreviewFeature intern() { for (PreviewFeature e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}
/**
 *  Maximum number of elements in PreviewFeature enum.
 * 
 *  @see PreviewFeature
 *  */
 // namespace impl

/**
 *  \enum HardwareCompatibilityLevel
 * 
 *  \brief Describes requirements of compatibility with GPU architectures other than that of the GPU on which the engine
 *  was built.
 * 
 *  \warning Note that compatibility with future hardware depends on CUDA forward compatibility support.
 *  */
@Namespace("nvinfer1") public enum HardwareCompatibilityLevel {
    /** Do not require hardware compatibility with GPU architectures other than that of the GPU on which the engine was
     *  built. */
    
//!
//!
//!
    kNONE(0),

    /** Require that the engine is compatible with Ampere and newer GPUs. This will limit the combined usage of driver
     *  reserved and backend kernel max shared memory to 48KiB, may reduce the number of available tactics for each
     *  layer, and may prevent some fusions from occurring. Thus this can decrease the performance, especially for tf32
     *  models.
     *  This option will disable cuDNN, cuBLAS, and cuBLASLt as tactic sources.
     * 
     *  This option is only supported for engines built on NVIDIA Ampere and later GPUs.
     * 
     *  The driver reserved shared memory can be queried from cuDeviceGetAttribute(&reservedShmem,
     *  CU_DEVICE_ATTRIBUTE_RESERVED_SHARED_MEMORY_PER_BLOCK).
     *  */
    
//!
//!
//!
    kAMPERE_PLUS(1),

    /** Require that the engine is compatible with GPUs that have the same Compute Capability
     *  (https://developer.nvidia.com/cuda-gpus) as the one it was built on. This may decrease the performance compared
     *  to an engine with no compatibility.
     * 
     *  This option will disable cuDNN, cuBLAS, and cuBLASLt as tactic sources.
     * 
     *  This option is only supported for engines built on NVIDIA Turing and later GPUs.
     *  */
    kSAME_COMPUTE_CAPABILITY(2);

    public final int value;
    private HardwareCompatibilityLevel(int v) { this.value = v; }
    private HardwareCompatibilityLevel(HardwareCompatibilityLevel e) { this.value = e.value; }
    public HardwareCompatibilityLevel intern() { for (HardwareCompatibilityLevel e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}
/**
 *  Maximum number of elements in HardwareCompatibilityLevel enum.
 * 
 *  @see HardwareCompatibilityLevel
 *  */
 // namespace impl


/**
 *  \enum TilingOptimizationLevel
 * 
 *  \brief Define the optimization levels for Tiling
 * 
 *  TensorRT will try tiling optimization for on-chip caching if non-zero level is set.
 *  This level determines how much effort TensorRT would take to find a better solution for performance.
 *  */
@Namespace("nvinfer1") public enum TilingOptimizationLevel {
    /** Do not apply any tiling strategy. */
    kNONE(0),

    /** Use a fast algorithm and heuristic based strategy. Slightly increases engine build time. */
    kFAST(1),

    /** Increase search space and use a mixed heuristic/profiling strategy.
     *  Moderately increases engine build time. */
    kMODERATE(2),

    /** Increase search space even wider. Significantly increases engine build time. */
    kFULL(3);

    public final int value;
    private TilingOptimizationLevel(int v) { this.value = v; }
    private TilingOptimizationLevel(TilingOptimizationLevel e) { this.value = e.value; }
    public TilingOptimizationLevel intern() { for (TilingOptimizationLevel e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}
/**
 *  Maximum number of elements in TilingOptimizationLevel enum.
 * 
 *  @see TilingOptimizationLevel
 *  */

// Targeting ../nvinfer/IProgressMonitor.java

 // class IProgressMonitor
 // namespace v_1_0

/**
 *  \class IProgressMonitor
 * 
 *  \brief Application-implemented progress reporting interface for TensorRT.
 * 
 *  The IProgressMonitor is a user-defined object that TensorRT uses to report back when an internal algorithm has
 *  started or finished a phase to help provide feedback on the progress of the optimizer.
 * 
 *  The IProgressMonitor will trigger its start function when a phase is entered and will trigger its finish function
 *  when that phase is exited. Each phase consists of one or more steps. When each step is completed, the stepComplete
 *  function is triggered. This will allow an application using the builder to communicate progress relative to when the
 *  optimization step is expected to complete.
 * 
 *  The implementation of IProgressMonitor must be thread-safe so that it can be called from multiple internal threads.
 *  The lifetime of the IProgressMonitor must exceed the lifetime of all TensorRT objects that use it.
 * 
 *  \note To ensure compatibility of source code with future versions of TensorRT, use IProgressMonitor, not
 *        v_1_0::IProgressMonitor
 *  */


//!
//!
//!
//!
// Targeting ../nvinfer/IBuilderConfig.java



/**
 *  \brief Represents one or more NetworkDefinitionCreationFlag flags
 *  using binary OR operations.
 *   e.g., 1U << NetworkDefinitionCreationFlag::kSTRONGLY_TYPED
 * 
 *  @see IBuilder::createNetworkV2
 *  */


//!
//!
//!
//!

/**
 *  \enum NetworkDefinitionCreationFlag
 * 
 *  \brief List of immutable network properties expressed at network creation time.
 *  NetworkDefinitionCreationFlag is used with createNetworkV2() to specify immutable properties of the network.
 * 
 *  @see IBuilder::createNetworkV2
 *  */
@Namespace("nvinfer1") public enum NetworkDefinitionCreationFlag {
    /** Ignored because networks are always "explicit batch" in TensorRT 10.0.
     * 
     *  @deprecated Deprecated in TensorRT 10.0. */
    kEXPLICIT_BATCH(0),

    /** Mark the network to be strongly typed.
     *  Every tensor in the network has a data type defined in the network following only type inference rules and the
     *  inputs/operator annotations. Setting layer precision and layer output types is not allowed, and the network
     *  output types will be inferred based on the input types and the type inference rules. */
    kSTRONGLY_TYPED(1),
    /** If set, for a Python plugin with both AOT and JIT implementations, the JIT implementation will be used.
     *  Any plugin-specific JIT/AOT specification may override this.
     *  Cannot be used in conjunction with NetworkDefinitionCreationFlag::kPREFER_AOT_PYTHON_PLUGINS. */
    kPREFER_JIT_PYTHON_PLUGINS(2),

    /** If set, for a Python plugin with both AOT and JIT implementations, the AOT implementation will be used.
     *  Any plugin-specific JIT/AOT specification may override this.
     *  Cannot be used in conjunction with NetworkDefinitionCreationFlag::kPREFER_JIT_PYTHON_PLUGINS. */
    kPREFER_AOT_PYTHON_PLUGINS(3);

    public final int value;
    private NetworkDefinitionCreationFlag(int v) { this.value = v; }
    private NetworkDefinitionCreationFlag(NetworkDefinitionCreationFlag e) { this.value = e.value; }
    public NetworkDefinitionCreationFlag intern() { for (NetworkDefinitionCreationFlag e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}

/**
 *  Maximum number of elements in NetworkDefinitionCreationFlag enum.
 * 
 *  @see NetworkDefinitionCreationFlag
 *  */

// Targeting ../nvinfer/IBuilder.java



 // namespace nvinfer1

/**
 *  Internal C entry point for creating IBuilder.
 *  \private
 *  */
public static native @NoException(true) Pointer createInferBuilder_INTERNAL(Pointer logger, int version);

/**
 *  \brief Create an instance of an IBuilder class.
 * 
 *  @param logger The logging class for the builder.
 * 
 *  unnamed namespace avoids linkage surprises when linking objects built with different versions of this header.
 *  */
@Namespace("nvinfer1") public static native @NoException(true) IBuilder createInferBuilder(@ByRef ILogger logger);

 // namespace

/**
 *  \brief Return the plugin registry for building a Standard engine, or nullptr if no registry exists.
 * 
 *  Also return nullptr if the input argument is not EngineCapability::kSTANDARD.
 *  Engine capabilities EngineCapability::kSTANDARD and EngineCapability::kSAFETY have distinct plugin registries.
 *  Use IPluginRegistry::registerCreator from the registry to register plugins.
 *  Plugins registered in a registry associated with a specific engine capability are only available when
 *  building engines with that engine capability.
 * 
 *  There is no plugin registry for EngineCapability::kDLA_STANDALONE.
 *  */
@Namespace("nvinfer1") public static native @NoException(true) IPluginRegistry getBuilderPluginRegistry(
    EngineCapability capability);
@Namespace("nvinfer1") public static native @NoException(true) IPluginRegistry getBuilderPluginRegistry(
    @Cast("nvinfer1::EngineCapability") int capability);
// Targeting ../nvinfer/SafeIPluginRegistry.java


 // namespace safe

/**
 *  \brief Return the plugin registry for building a Safety engine, or nullptr if no registry exists.
 * 
 *  Also return nullptr if the input argument is not EngineCapability::kSAFETY.
 *  When building a Standard engine, use nvinfer1::getBuilderPluginRegistry().
 *  Use safe::IPluginRegistry::registerCreator from the registry to register plugins.
 *  */
@Namespace("nvinfer1") public static native @Deprecated @NoException(true) SafeIPluginRegistry getBuilderSafePluginRegistry(
    EngineCapability capability);
@Namespace("nvinfer1") public static native @Deprecated @NoException(true) SafeIPluginRegistry getBuilderSafePluginRegistry(
    @Cast("nvinfer1::EngineCapability") int capability);

 // namespace nvinfer1

// #endif // NV_INFER_H


// Parsed from NvInferImpl.h

/*
 * SPDX-FileCopyrightText: Copyright (c) 1993-2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
 * SPDX-License-Identifier: Apache-2.0
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #ifndef NV_INFER_IMPL_H
// #define NV_INFER_IMPL_H

// #include "NvInferLegacyDims.h"
// #include "NvInferRuntimeCommon.h"

// @cond SuppressDoxyWarnings
 // namespace v_1_0
 // namespace v_1_0
 // namespace v_1_0
 // namespace v_1_0
 // namespace v_1_0
// Targeting ../nvinfer/IPlugin.java


// Targeting ../nvinfer/IPluginExt.java


// Targeting ../nvinfer/IPluginLayer.java


 // namespace v_1_0
 // namespace v_1_0
 // namespace v_1_0
 // namespace v_1_0

/** enum class nvinfer1::ActivationType */
;
/** enum class nvinfer1::AttentionNormalizationOp */
;
/** enum class nvinfer1::BoundingBoxFormat */
;
/** enum class nvinfer1::BuilderFlag */
;
/** enum class nvinfer1::CalibrationAlgoType */
;
/** enum class nvinfer1::CumulativeOperation */
;
/** enum class nvinfer1::DeviceType */
;
/** enum class nvinfer1::DimensionOperation */
;
/** enum class nvinfer1::ElementWiseOperation */
;
/** enum class nvinfer1::EngineCapability */
;
/** enum class nvinfer1::FillOperation */
;
/** enum class nvinfer1::GatherMode */
;
/** enum class nvinfer1::LayerInformationFormat */
;
/** enum class nvinfer1::LayerType */
;
/** enum class nvinfer1::LoopOutput */
;
/** enum class nvinfer1::MatrixOperation */
;
/** enum class nvinfer1::MemoryPoolType */
;
/** enum class nvinfer1::NetworkDefinitionCreationFlag */
;
/** enum class nvinfer1::OptProfileSelector */
;
/** enum class nvinfer1::PaddingMode */
;
/** enum class nvinfer1::PoolingType */
;
/** enum class nvinfer1::ProfilingVerbosity */
;
/** enum class nvinfer1::QuantizationFlag */
;
/** enum class nvinfer1::ReduceOperation */
;
/** enum class nvinfer1::ResizeCoordinateTransformation */
;
/** enum class nvinfer1::InterpolationMode */
;
/** enum class nvinfer1::ResizeRoundMode */
;
/** enum class nvinfer1::ResizeSelector */
;
/** enum class nvinfer1::ScaleMode */
;
/** enum class nvinfer1::ScatterMode */
;
/** enum class nvinfer1::SampleMode */
;
/** enum class nvinfer1::SerializationFlag */
;
/** enum class nvinfer1::TensorIOMode */
;
/** enum class nvinfer1::TensorLocation */
;
/** enum class nvinfer1::TopKOperation */
;
/** enum class nvinfer1::TripLimit */
;
/** enum class nvinfer1::UnaryOperation */
;
/** enum class nvinfer1::WeightsRole */
;
/** enum class nvinfer1::PreviewFeature */
;
/** enum class nvinfer1::HardwareCompatibilityLevel */
;
/** enum class nvinfer1::ExecutionContextAllocationStrategy */
;
/** enum class nvinfer1::RuntimePlatform */
;
/** enum class nvinfer1::TilingOptimizationLevel */
;
/** enum class nvinfer1::EngineStat */
;


//!
//!
//!
// Targeting ../nvinfer/VRoot.java


// Targeting ../nvinfer/VHostMemory.java


// Targeting ../nvinfer/VDimensionExpr.java


// Targeting ../nvinfer/VExprBuilder.java


// Targeting ../nvinfer/VRuntime.java


// Targeting ../nvinfer/VRefitter.java


// Targeting ../nvinfer/VOptimizationProfile.java


// Targeting ../nvinfer/VCudaEngine.java


// Targeting ../nvinfer/VExecutionContext.java


// Targeting ../nvinfer/VEngineInspector.java


// Targeting ../nvinfer/VTensor.java


// Targeting ../nvinfer/VLayer.java


// Targeting ../nvinfer/VConvolutionLayer.java


// Targeting ../nvinfer/VActivationLayer.java


// Targeting ../nvinfer/VPoolingLayer.java


// Targeting ../nvinfer/VLRNLayer.java


// Targeting ../nvinfer/VScaleLayer.java


// Targeting ../nvinfer/VSoftMaxLayer.java


// Targeting ../nvinfer/VConcatenationLayer.java


// Targeting ../nvinfer/VDeconvolutionLayer.java


// Targeting ../nvinfer/VElementWiseLayer.java


// Targeting ../nvinfer/VGatherLayer.java


// Targeting ../nvinfer/VPluginLayer.java


// Targeting ../nvinfer/VPluginV2Layer.java


// Targeting ../nvinfer/VPluginV3Layer.java


// Targeting ../nvinfer/VUnaryLayer.java


// Targeting ../nvinfer/VReduceLayer.java


// Targeting ../nvinfer/VPaddingLayer.java


// Targeting ../nvinfer/VShuffleLayer.java


// Targeting ../nvinfer/VSliceLayer.java


// Targeting ../nvinfer/VShapeLayer.java


// Targeting ../nvinfer/VTopKLayer.java


// Targeting ../nvinfer/VMatrixMultiplyLayer.java


// Targeting ../nvinfer/VNonZeroLayer.java


// Targeting ../nvinfer/VRaggedSoftMaxLayer.java


// Targeting ../nvinfer/VIdentityLayer.java


// Targeting ../nvinfer/VCastLayer.java


// Targeting ../nvinfer/VConstantLayer.java


// Targeting ../nvinfer/VParametricReLULayer.java


// Targeting ../nvinfer/VResizeLayer.java


// Targeting ../nvinfer/VLoopBoundaryLayer.java


// Targeting ../nvinfer/VRecurrenceLayer.java


// Targeting ../nvinfer/VLoopOutputLayer.java


// Targeting ../nvinfer/VTripLimitLayer.java


// Targeting ../nvinfer/VIteratorLayer.java


// Targeting ../nvinfer/VLoop.java


// Targeting ../nvinfer/VConditionalBoundaryLayer.java


// Targeting ../nvinfer/VConditionLayer.java


// Targeting ../nvinfer/VConditionalInputLayer.java


// Targeting ../nvinfer/VConditionalOutputLayer.java


// Targeting ../nvinfer/VIfConditional.java


// Targeting ../nvinfer/VAttentionBoundaryLayer.java


// Targeting ../nvinfer/VAttentionInputLayer.java


// Targeting ../nvinfer/VAttentionOutputLayer.java


// Targeting ../nvinfer/VAttention.java


// Targeting ../nvinfer/VSelectLayer.java


// Targeting ../nvinfer/VAssertionLayer.java


// Targeting ../nvinfer/VFillLayer.java


// Targeting ../nvinfer/VQuantizeLayer.java


// Targeting ../nvinfer/VDequantizeLayer.java


// Targeting ../nvinfer/VDynamicQuantizeLayer.java


// Targeting ../nvinfer/VScatterLayer.java


// Targeting ../nvinfer/VEinsumLayer.java


// Targeting ../nvinfer/VOneHotLayer.java


// Targeting ../nvinfer/VGridSampleLayer.java


// Targeting ../nvinfer/VNMSLayer.java


// Targeting ../nvinfer/VReverseSequenceLayer.java


// Targeting ../nvinfer/VNormalizationLayer.java


// Targeting ../nvinfer/VSqueezeLayer.java


// Targeting ../nvinfer/VUnsqueezeLayer.java


// Targeting ../nvinfer/VCumulativeLayer.java


// Targeting ../nvinfer/VNetworkDefinition.java


// Targeting ../nvinfer/VAlgorithmIOInfo.java


// Targeting ../nvinfer/VAlgorithmVariant.java


// Targeting ../nvinfer/VAlgorithmContext.java


// Targeting ../nvinfer/VAlgorithm.java


// Targeting ../nvinfer/VTimingCache.java


// Targeting ../nvinfer/VBuilderConfig.java


// Targeting ../nvinfer/VSerializationConfig.java


// Targeting ../nvinfer/VBuilder.java


// Targeting ../nvinfer/VRuntimeConfig.java




 // namespace apiv
 // namespace nvinfer1

// @endcond

// #endif // NV_INFER_RUNTIME_IMPL_H


// Parsed from NvInferPluginBase.h

/*
 * SPDX-FileCopyrightText: Copyright (c) 2024-2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
 * SPDX-License-Identifier: Apache-2.0
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #ifndef NV_INFER_PLUGIN_BASE_H
// #define NV_INFER_PLUGIN_BASE_H

// #if !defined(NV_INFER_INTERNAL_INCLUDE)
// #endif
// #include "NvInferRuntimeBase.h" // IWYU pragma: exports
// #undef NV_INFER_INTERNAL_INCLUDE

/**
 *  \enum PluginFieldType
 * 
 *  \brief The possible field types for custom layer.
 *  */
@Namespace("nvinfer1") public enum PluginFieldType {
    /** FP16 field type. */
    kFLOAT16(0),
    /** FP32 field type. */
    kFLOAT32(1),
    /** FP64 field type. */
    kFLOAT64(2),
    /** INT8 field type. */
    kINT8(3),
    /** INT16 field type. */
    kINT16(4),
    /** INT32 field type. */
    kINT32(5),
    /** char field type. */
    kCHAR(6),
    /** nvinfer1::Dims field type. */
    kDIMS(7),
    /** Unknown field type. */
    kUNKNOWN(8),
    /** BF16 field type. */
    kBF16(9),
    /** INT64 field type. */
    kINT64(10),
    /** FP8 field type. */
    kFP8(11),
    /** INT4 field type. */
    kINT4(12),
    /** FP4 field type. */
    kFP4(13);

    public final int value;
    private PluginFieldType(int v) { this.value = v; }
    private PluginFieldType(PluginFieldType e) { this.value = e.value; }
    public PluginFieldType intern() { for (PluginFieldType e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}
// Targeting ../nvinfer/PluginField.java


// Targeting ../nvinfer/PluginFieldCollection.java



/**
 *  \enum TensorRTPhase
 * 
 *  \brief Indicates a phase of operation of TensorRT
 *  */
@Namespace("nvinfer1") public enum TensorRTPhase {
    /** Build phase of TensorRT */
    kBUILD(0),
    /** Execution phase of TensorRT */
    kRUNTIME(1);

    public final int value;
    private TensorRTPhase(int v) { this.value = v; }
    private TensorRTPhase(TensorRTPhase e) { this.value = e.value; }
    public TensorRTPhase intern() { for (TensorRTPhase e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}

/**
 *  \enum PluginCapabilityType
 * 
 *  \brief Enumerates the different capability types a IPluginV3 object may have
 *  */
@Namespace("nvinfer1") public enum PluginCapabilityType {
    /** Core capability. Every IPluginV3 object must have this. */
    kCORE(0),
    /** Build capability. IPluginV3 objects provided to TensorRT build phase must have this. */
    kBUILD(1),
    /** Runtime capability. IPluginV3 objects provided to TensorRT build and execution phases must have this. */
    kRUNTIME(2);

    public final int value;
    private PluginCapabilityType(int v) { this.value = v; }
    private PluginCapabilityType(PluginCapabilityType e) { this.value = e.value; }
    public PluginCapabilityType intern() { for (PluginCapabilityType e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}
// Targeting ../nvinfer/IPluginCapability.java


// Targeting ../nvinfer/IPluginResource.java


// Targeting ../nvinfer/IPluginCreatorInterface.java


// Targeting ../nvinfer/IPluginV3.java


 // namespace v_1_0

/**
 *  \class IPluginResource
 * 
 *  \brief Interface for plugins to define custom resources that could be shared through the plugin registry
 * 
 *  @see IPluginRegistry::acquirePluginResource
 *  @see IPluginRegistry::releasePluginResource
 *  */


//!
//!
//!
//!

/**
 *  \class IPluginCreatorInterface
 * 
 *  \brief Base class for all plugin creator versions.
 * 
 *  @see IPluginCreator and IPluginRegistry
 *  */


//!
//!
//!
//!
//!

/**
 *  \class IPluginV3
 * 
 *  \brief Plugin class for the V3 generation of user-implemented layers.
 * 
 *  IPluginV3 acts as a wrapper around the plugin capability interfaces that define the actual behavior of the plugin.
 * 
 *  @see IPluginCapability
 *  @see IPluginCreatorV3One
 *  @see IPluginRegistry
 *  */


//!
//!
//!
//!
//!
//!

/**
 *  \class IPluginCapability
 * 
 *  \brief Base class for plugin capability interfaces
 * 
 *   IPluginCapability represents a split in TensorRT V3 plugins to sub-objects that expose different types of
 *   capabilites a plugin may have, as opposed to a single interface which defines all capabilities and behaviors of a
 *   plugin.
 * 
 *  \warning Do not inherit from this class, as doing so will break forward-compatibility of the API and ABI.
 * 
 *  @see PluginCapabilityType
 *  */
 // namespace nvinfer1

// #endif /* NV_INFER_PLUGIN_BASE_H */


// Parsed from NvInferRuntimePlugin.h

/*
 * SPDX-FileCopyrightText: Copyright (c) 1993-2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
 * SPDX-License-Identifier: Apache-2.0
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #ifndef NV_INFER_RUNTIME_PLUGIN_H
// #define NV_INFER_RUNTIME_PLUGIN_H
// #include "NvInferPluginBase.h"


//!
//!
//!
//!

//!
//!
//!
// #undef NV_INFER_INTERNAL_INCLUDE

/**
 *  \file NvInferRuntimePlugin.h
 * 
 *  This file contains common definitions, data structures and interfaces that relate to plugins and are shared
 *  between the standard and safe runtime.
 * 
 *  \warning Do not directly include this file. Instead include NvInferRuntime.h
 * 
 <p>
 * 
 *  \namespace nvinfer1
 * 
 *  \brief The TensorRT API version 1 namespace.
 *  */

/** enum class nvinfer1::TensorFormat */
;
 // namespace v_1_0


//!
//!
//!

/**
 *  \brief PluginFormat is reserved for backward compatibility.
 * 
 *  @see IPluginV2::supportsFormat()
 *  */


//!
//!

/**
 *  \brief Bit at the plugin version to identify that it is a plugin.
 *  */


//!
//!
//!
//!
//!
@Namespace("nvinfer1") @MemberGetter public static native int kPLUGIN_VERSION_PYTHON_BIT();
public static final int kPLUGIN_VERSION_PYTHON_BIT = kPLUGIN_VERSION_PYTHON_BIT();
// Targeting ../nvinfer/PluginTensorDesc.java



/**
 *  \struct PluginVersion
 * 
 *  \brief Definition of plugin versions.
 * 
 *  Tag for plug-in versions.  Used in upper byte of getTensorRTVersion().
 * 
 *  @deprecated Deprecated in TensorRT 10.10. PluginVersion is used only in relation to IPluginV2-descendent plugin
 *  interfaces, which are all deprecated.
 *  */
@Namespace("nvinfer1") public enum PluginVersion {
    /** IPluginV2 */
    kV2((byte)(0)),
    /** IPluginV2Ext */
    kV2_EXT((byte)(1)),
    /** IPluginV2IOExt */
    kV2_IOEXT((byte)(2)),
    /** IPluginV2DynamicExt */
    kV2_DYNAMICEXT((byte)(3)),
    /** IPluginV2DynamicExt-based Python plugins */
    kV2_DYNAMICEXT_PYTHON((byte)(kPLUGIN_VERSION_PYTHON_BIT | 3));

    public final byte value;
    private PluginVersion(byte v) { this.value = v; }
    private PluginVersion(PluginVersion e) { this.value = e.value; }
    public PluginVersion intern() { for (PluginVersion e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}

/**
 *  \enum PluginCreatorVersion
 * 
 *  \brief Enum to identify version of the plugin creator.
 * 
 *  @deprecated Deprecated in TensorRT 10.10. PluginCreatorVersion is used only in relation to plugin creators based
 *  off IPluginCreator, which is deprecated.
 *  */
@Namespace("nvinfer1") public enum PluginCreatorVersion {
    /** IPluginCreator */
    kV1(0),
    /** IPluginCreator-based Python plugin creators */
    kV1_PYTHON(kPLUGIN_VERSION_PYTHON_BIT);

    public final int value;
    private PluginCreatorVersion(int v) { this.value = v; }
    private PluginCreatorVersion(PluginCreatorVersion e) { this.value = e.value; }
    public PluginCreatorVersion intern() { for (PluginCreatorVersion e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}
// Targeting ../nvinfer/IPluginV2.java


// Targeting ../nvinfer/IPluginV2Ext.java


// Targeting ../nvinfer/IPluginV2IOExt.java


// Targeting ../nvinfer/IPluginCreator.java


 // namespace v_1_0

/**
 *  \class IPluginCreator
 * 
 *  \brief Plugin creator class for user implemented layers.
 * 
 *  @see IPlugin and IPluginFactory
 * 
 *  @deprecated Deprecated in TensorRT 10.0. Please implement IPluginCreatorV3One
 *  along with IPluginV3 plugins instead.
 *  */

 // namespace nvinfer1

// #endif // NV_INFER_RUNTIME_PLUGIN_H


}
