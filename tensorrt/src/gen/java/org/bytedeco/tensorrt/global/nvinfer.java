// Targeted by JavaCPP version 1.5.4-SNAPSHOT: DO NOT EDIT THIS FILE

package org.bytedeco.tensorrt.global;

import org.bytedeco.tensorrt.nvinfer.*;

import java.nio.*;
import org.bytedeco.javacpp.*;
import org.bytedeco.javacpp.annotation.*;

import static org.bytedeco.javacpp.presets.javacpp.*;
import org.bytedeco.cuda.cudart.*;
import static org.bytedeco.cuda.global.cudart.*;
import org.bytedeco.cuda.cublas.*;
import static org.bytedeco.cuda.global.cublas.*;
import org.bytedeco.cuda.cudnn.*;
import static org.bytedeco.cuda.global.cudnn.*;
import org.bytedeco.cuda.nvrtc.*;
import static org.bytedeco.cuda.global.nvrtc.*;

public class nvinfer extends org.bytedeco.tensorrt.presets.nvinfer {
    static { Loader.load(); }

// Parsed from NvInferVersion.h

/*
 * Copyright 1993-2020 NVIDIA Corporation.  All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee.  Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE.  IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users.  These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item.  Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

 /**
 /** \file NvInferVersion.h
 /**
 /** Defines the TensorRT version
 /** */

// #ifndef NV_INFER_VERSION_H
// #define NV_INFER_VERSION_H

/** TensorRT major version. */
public static final int NV_TENSORRT_MAJOR = 7;
/** TensorRT minor version. */
public static final int NV_TENSORRT_MINOR = 1;
/** TensorRT patch version. */
public static final int NV_TENSORRT_PATCH = 3;
/** TensorRT build number. */
public static final int NV_TENSORRT_BUILD = 4;

/** Shared object library major version number. */
public static final int NV_TENSORRT_SONAME_MAJOR = 7;
/** Shared object library minor version number. */
public static final int NV_TENSORRT_SONAME_MINOR = 1;
/** Shared object library patch version number. */
public static final int NV_TENSORRT_SONAME_PATCH = 3;

// #endif // NV_INFER_VERSION_H


// Parsed from NvInferRuntimeCommon.h

/*
 * Copyright 1993-2020 NVIDIA Corporation.  All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee.  Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE.  IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users.  These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item.  Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

// #ifndef NV_INFER_RUNTIME_COMMON_H
// #define NV_INFER_RUNTIME_COMMON_H

// #include <cstddef>
// #include <cstdint>
// #include "NvInferVersion.h"

// #if __cplusplus >= 201103L
// #define _TENSORRT_FINAL final
// #define _TENSORRT_OVERRIDE override
// #else
// #define _TENSORRT_FINAL


/** Items that are marked as deprecated will be removed in a future release. */
// #define _TENSORRT_OVERRIDE
// #endif
// #if __cplusplus >= 201402L
// #define TRT_DEPRECATED [[deprecated]]
// #if __GNUC__ < 6
// #define TRT_DEPRECATED_ENUM
// #else
// #define TRT_DEPRECATED_ENUM TRT_DEPRECATED
// #endif
// #ifdef _MSC_VER
// #define TRT_DEPRECATED_API __declspec(dllexport)
// #else
// #define TRT_DEPRECATED_API [[deprecated]] __attribute__((visibility("default")))
// #endif
// #else
// #ifdef _MSC_VER
// #define TRT_DEPRECATED
// #define TRT_DEPRECATED_ENUM
// #define TRT_DEPRECATED_API __declspec(dllexport)
// #else
// #define TRT_DEPRECATED __attribute__((deprecated))
// #define TRT_DEPRECATED_ENUM


/** Defines which symbols are exported */
// #define TRT_DEPRECATED_API __attribute__((deprecated, visibility("default")))
// #endif
// #endif
// #ifdef TENSORRT_BUILD_LIB
// #ifdef _MSC_VER
// #define TENSORRTAPI __declspec(dllexport)
// #else
// #define TENSORRTAPI __attribute__((visibility("default")))
// #endif
// #else
// #define TENSORRTAPI
// #endif

//!
//!
//!
// #define TRTNOEXCEPT
// Targeting ../nvinfer/cublasContext.java


// Targeting ../nvinfer/cudnnContext.java


// Targeting ../nvinfer/CUstream_st.java


// Targeting ../nvinfer/CUevent_st.java





//!
//!
//!
@MemberGetter public static native int NV_TENSORRT_VERSION();
public static final int NV_TENSORRT_VERSION = NV_TENSORRT_VERSION(); // major, minor, patch

/**
 *  \namespace nvinfer1
 * 
 *  \brief The TensorRT API version 1 namespace.
 *  */

/**
 *  \enum ActivationType
 * 
 *  \brief Enumerates the types of activation to perform in an activation layer.
 *  */
@Namespace("nvinfer1") public enum ActivationType {
    /** Rectified linear activation. */
    kRELU(0),
    /** Sigmoid activation. */
    kSIGMOID(1),
    /** TanH activation. */
    kTANH(2),
    /** LeakyRelu activation: x>=0 ? x : alpha * x. */
    kLEAKY_RELU(3),
    /** Elu activation: x>=0 ? x : alpha * (exp(x) - 1). */
    kELU(4),
    /** Selu activation: x>0 ? beta * x : beta * (alpha*exp(x) - alpha) */
    kSELU(5),
    /** Softsign activation: x / (1+|x|) */
    kSOFTSIGN(6),
    /** Parametric softplus activation: alpha*log(exp(beta*x)+1) */
    kSOFTPLUS(7),
    /** Clip activation: max(alpha, min(beta, x)) */
    kCLIP(8),
    /** Hard sigmoid activation: max(0, min(1, alpha*x+beta)) */
    kHARD_SIGMOID(9),
    /** Scaled tanh activation: alpha*tanh(beta*x) */
    kSCALED_TANH(10),
    /** Thresholded ReLU activation: x>alpha ? x : 0 */
    kTHRESHOLDED_RELU(11);

    public final int value;
    private ActivationType(int v) { this.value = v; }
    private ActivationType(ActivationType e) { this.value = e.value; }
    public ActivationType intern() { for (ActivationType e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}





/**
 *  \enum DataType
 * 
 *  \brief The type of weights and tensors.
 *  */
@Namespace("nvinfer1") public enum DataType {
    /** 32-bit floating point format. */
    kFLOAT(0),

    /** IEEE 16-bit floating-point format. */
    kHALF(1),

    /** 8-bit integer representing a quantized floating-point value. */
    kINT8(2),

    /** Signed 32-bit integer format. */
    kINT32(3),

    /** 8-bit boolean. 0 = false, 1 = true, other values undefined. */
    kBOOL(4);

    public final int value;
    private DataType(int v) { this.value = v; }
    private DataType(DataType e) { this.value = e.value; }
    public DataType intern() { for (DataType e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}



/**
 *  \enum DimensionType
 *  \brief The type of data encoded across this dimension.
 *  */
@Namespace("nvinfer1") public enum DimensionType {
    /** Elements correspond to different spatial data. */
    kSPATIAL(0),
    /** Elements correspond to different channels. */
    kCHANNEL(1),
    /** Elements correspond to different batch index. */
    kINDEX(2),
    /** Elements correspond to different sequence values. */
    kSEQUENCE(3);

    public final int value;
    private DimensionType(int v) { this.value = v; }
    private DimensionType(DimensionType e) { this.value = e.value; }
    public DimensionType intern() { for (DimensionType e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}


// Targeting ../nvinfer/Dims.java



/**
 *  \brief It is capable of representing one or more TensorFormat by binary OR
 *  operations, e.g., 1U << TensorFormats::kCHW4 | 1U << TensorFormats::kCHW32.
 * 
 *  @see ITensor::getAllowedFormats(), ITensor::setAllowedFormats(),
 *  */


//!
//!
//!
//!
//!
//!

/**
 *  \enum TensorFormat
 * 
 *  \brief Format of the input/output tensors.
 * 
 *  This enum is extended to be used by both plugins and reformat-free network
 *  I/O tensors.
 * 
 *  @see IPluginExt::getPluginFormats(), safe::ICudaEngine::getBindingFormat()
 * 
 *  For more information about data formats, see the topic "Data Format Description" located in the
 *  TensorRT Developer Guide (https://docs.nvidia.com/deeplearning/sdk/tensorrt-developer-guide/index.html).
 *  */
@Namespace("nvinfer1") public enum TensorFormat {
    /** Row major linear format.
     *  For a tensor with dimensions {N, C, H, W} or {numbers, channels,
     *  columns, rows}, the dimensional index corresponds to {3, 2, 1, 0}
     *  and thus the order is W minor.
     * 
     *  For DLA usage, the tensor sizes are limited to C,H,W in the range [1,8192].
     *  */
    kLINEAR(0),
    /** Deprecated name of kLINEAR, provided for backwards compatibility */
    kNCHW(kLINEAR),

    /** Two wide channel vectorized row major format. This format is bound to
     *  FP16. It is only available for dimensions >= 3.
     *  For a tensor with dimensions {N, C, H, W},
     *  the memory layout is equivalent to a C array with dimensions
     *  [N][(C+1)/2][H][W][2], with the tensor coordinates (n, c, h, w)
     *  mapping to array subscript [n][c/2][h][w][c%2]. */
    kCHW2(1),
    /** Deprecated name of kCHW2, provided for backwards compatibility */
    kNC2HW2(kCHW2),

    /** Eight channel format where C is padded to a multiple of 8. This format
     *  is bound to FP16. It is only available for dimensions >= 3.
     *  For a tensor with dimensions {N, H, W, C},
     *  the memory layout is equivalent to the array with dimensions
     *  [N][H][W][(C+7)/8*8], with the tensor coordinates (n, h, w, c)
     *  mapping to array subscript [n][h][w][c]. */
    kHWC8(2),
    /** Deprecated name of kHWC8, provided for backwards compatibility */
    kNHWC8(kHWC8),

    /** Four wide channel vectorized row major format. This format is bound to
     *  INT8 or FP16. It is only available for dimensions >= 3.
     *  For INT8, the C dimension must be a build-time constant.
     *  For a tensor with dimensions {N, C, H, W},
     *  the memory layout is equivalent to a C array with dimensions
     *  [N][(C+3)/4][H][W][4], with the tensor coordinates (n, c, h, w)
     *  mapping to array subscript [n][c/4][h][w][c%4].
     *  If running on the DLA, this format can be used for acceleration
     *  with the caveat that C must equal 4. */
    
//!
//!
    kCHW4(3),

    /** Sixteen wide channel vectorized row major format. This format is bound
     *  to FP16. It is only available for dimensions >= 3.
     *  For a tensor with dimensions {N, C, H, W},
     *  the memory layout is equivalent to a C array with dimensions
     *  [N][(C+15)/16][H][W][16], with the tensor coordinates (n, c, h, w)
     *  mapping to array subscript [n][c/16][h][w][c%16].
     * 
     *  For DLA usage, this format maps to the native image format for FP16,
     *  and the tensor sizes are limited to C,H,W in the range [1,8192].
     *  */
    
//!
//!
    kCHW16(4),

    /** Thirty-two wide channel vectorized row major format. This format is
     *  only available for dimensions >= 3.
     *  For a tensor with dimensions {N, C, H, W},
     *  the memory layout is equivalent to a C array with dimensions
     *  [N][(C+31)/32][H][W][32], with the tensor coordinates (n, c, h, w)
     *  mapping to array subscript [n][c/32][h][w][c%32].
     * 
     *  For DLA usage, this format maps to the native image format for INT8,
     *  and the tensor sizes are limited to C,H,W in the range [1,8192].
     *  */
    kCHW32(5);

    public final int value;
    private TensorFormat(int v) { this.value = v; }
    private TensorFormat(TensorFormat e) { this.value = e.value; }
    public TensorFormat intern() { for (TensorFormat e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}

/**
 *  \brief PluginFormat is reserved for backward compatibility.
 * 
 *  @see IPluginExt::getPluginFormats()
 *  */


// Targeting ../nvinfer/PluginTensorDesc.java



/** \struct PluginVersion
 * 
 *  \brief Definition of plugin versions.
 * 
 *  Tag for plug-in versions.  Used in upper byte of getTensorRTVersion().
 *  */
@Namespace("nvinfer1") public enum PluginVersion {
    kV2((byte)0),            /** IPluginV2 */
    kV2_EXT((byte)1),        /** IPluginV2Ext */
    kV2_IOEXT((byte)2),      /** IPluginV2IOExt */
    kV2_DYNAMICEXT((byte)3);/** IPluginV2DynamicExt */

    public final byte value;
    private PluginVersion(byte v) { this.value = v; }
    private PluginVersion(PluginVersion e) { this.value = e.value; }
    public PluginVersion intern() { for (PluginVersion e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}
// Targeting ../nvinfer/IPluginV2.java


// Targeting ../nvinfer/IPluginV2Ext.java


// Targeting ../nvinfer/IPluginV2IOExt.java



/**
 *  \enum FieldType
 *  \brief The possible field types for custom layer.
 *  */

@Namespace("nvinfer1") public enum PluginFieldType {
    /** FP16 field type. */
    kFLOAT16(0),
    /** FP32 field type. */
    kFLOAT32(1),
    /** FP64 field type. */
    kFLOAT64(2),
    /** INT8 field type. */
    kINT8(3),
    /** INT16 field type. */
    kINT16(4),
    /** INT32 field type. */
    kINT32(5),
    /** char field type. */
    kCHAR(6),
    /** nvinfer1::Dims field type. */
    kDIMS(7),
    kUNKNOWN(8);

    public final int value;
    private PluginFieldType(int v) { this.value = v; }
    private PluginFieldType(PluginFieldType e) { this.value = e.value; }
    public PluginFieldType intern() { for (PluginFieldType e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}
// Targeting ../nvinfer/PluginField.java


// Targeting ../nvinfer/PluginFieldCollection.java


// Targeting ../nvinfer/IPluginCreator.java


// Targeting ../nvinfer/IPluginRegistry.java




/**
 *  \enum TensorLocation
 *  \brief The location for tensor data storage, device or host.
 *  */
@Namespace("nvinfer1") public enum TensorLocation {
    /** Data stored on device. */
    kDEVICE(0),
    /** Data stored on host. */
    kHOST(1);

    public final int value;
    private TensorLocation(int v) { this.value = v; }
    private TensorLocation(TensorLocation e) { this.value = e.value; }
    public TensorLocation intern() { for (TensorLocation e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}


// Targeting ../nvinfer/IGpuAllocator.java


// Targeting ../nvinfer/ILogger.java





/**
 *  \enum ErrorCode
 * 
 *  \brief Error codes that can be returned by TensorRT during execution.
 *  */
@Namespace("nvinfer1") public enum ErrorCode {
    /**
     *  Execution completed successfully.
     *  */
    

//!
//!
    kSUCCESS(0),

    /**
     *  An error that does not fall into any other category. This error is included for forward compatibility
     *  */
    

//!
//!
    kUNSPECIFIED_ERROR(1),

    /**
     *  A non-recoverable TensorRT error occurred.
     *  */
    

//!
//!
    kINTERNAL_ERROR(2),

    /**
     *  An argument passed to the function is invalid in isolation.
     *  This is a violation of the API contract
     *  */
    

//!
//!
    kINVALID_ARGUMENT(3),

    /**
     *  An error occurred when comparing the state of an argument relative to other arguments. For example, the
     *  dimensions for concat differ between two tensors outside of the channel dimension. This error is triggered
     *  when an argument is correct in isolation, but not relative to other arguments. This is to help to distinguish
     *  from the simple errors from the more complex errors.
     *  This is a violation of the API contract.
     *  */
    

//!
//!
    kINVALID_CONFIG(4),

    /**
     *  An error occurred when performing an allocation of memory on the host or the device.
     *  A memory allocation error is normally fatal, but in the case where the application provided its own memory
     *  allocation routine, it is possible to increase the pool of available memory and resume execution.
     *  */
    

//!
//!
    kFAILED_ALLOCATION(5),

    /**
     *  One, or more, of the components that TensorRT relies on did not initialize correctly.
     *  This is a system setup issue.
     *  */
    

//!
//!
    kFAILED_INITIALIZATION(6),

    /**
     *  An error occurred during execution that caused TensorRT to end prematurely, either an asynchronous error or
     *  other execution errors reported by CUDA/DLA. In a dynamic system, the
     *  data can be thrown away and the next frame can be processed or execution can be retried.
     *  This is either an execution error or a memory error.
     *  */
    

//!
//!
    kFAILED_EXECUTION(7),

    /**
     *  An error occurred during execution that caused the data to become corrupted, but execution finished. Examples
     *  of this error are NaN squashing or integer overflow. In a dynamic system, the data can be thrown away and the
     *  next frame can be processed or execution can be retried.
     *  This is either a data corruption error, an input error, or a range error.
     *  */
    

//!
//!
//!
    kFAILED_COMPUTATION(8),

    /**
     *  TensorRT was put into a bad state by incorrect sequence of function calls. An example of an invalid state is
     *  specifying a layer to be DLA only without GPU fallback, and that layer is not supported by DLA. This can occur
     *  in situations where a service is optimistically executing networks for multiple different configurations
     *  without checking proper error configurations, and instead throwing away bad configurations caught by TensorRT.
     *  This is a violation of the API contract, but can be recoverable.
     * 
     *  Example of a recovery:
     *  GPU fallback is disabled and conv layer with large filter(63x63) is specified to run on DLA. This will fail due
     *  to DLA not supporting the large kernel size. This can be recovered by either turning on GPU fallback
     *  or setting the layer to run on the GPU.
     *  */
    

//!
//!
    kINVALID_STATE(9),

    /**
     *  An error occurred due to the network not being supported on the device due to constraints of the hardware or
     *  system. An example is running a unsafe layer in a safety certified context, or a resource requirement for the
     *  current network is greater than the capabilities of the target device. The network is otherwise correct, but
     *  the network and hardware combination is problematic. This can be recoverable.
     *  Examples:
     *   * Scratch space requests larger than available device memory and can be recovered by increasing allowed
     *     workspace size.
     *   * Tensor size exceeds the maximum element count and can be recovered by reducing the maximum batch size.
     *  */
    kUNSUPPORTED_STATE(10);

    public final int value;
    private ErrorCode(int v) { this.value = v; }
    private ErrorCode(ErrorCode e) { this.value = e.value; }
    public ErrorCode intern() { for (ErrorCode e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}


// Targeting ../nvinfer/IErrorRecorder.java

 // class IErrorRecorder

 // namespace nvinfer1

/**
 *  Internal C entry point for creating safe::IRuntime.
 *  \private
 *  */


//!
//!
public static native Pointer createSafeInferRuntime_INTERNAL(Pointer logger, int version);

/**
 *  \brief Return the logger object.
 *  */


//!
//!
//!
public static native ILogger getLogger();

/**
 *  \brief Return the library version number.
 * 
 *  The format is as for TENSORRT_VERSION: (TENSORRT_MAJOR * 1000) + (TENSORRT_MINOR * 100) + TENSOR_PATCH.
 *  */


//!
//!
public static native int getInferLibVersion();

/**
 *  \brief Return the plugin registry
 *  */
public static native IPluginRegistry getPluginRegistry();

/**
 *  \brief Register the plugin creator to the registry
 *  The static registry object will be instantiated when the plugin library is
 *  loaded. This static object will register all creators available in the
 *  library to the registry.
 *  */

// #define REGISTER_TENSORRT_PLUGIN(name)
//     static nvinfer1::PluginRegistrar<name> pluginRegistrar##name {}

 // namespace nvinfer1

// #endif // NV_INFER_RUNTIME_COMMON_H


// Parsed from NvInferRuntime.h

/*
 * Copyright 1993-2020 NVIDIA Corporation.  All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee.  Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE.  IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users.  These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item.  Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

// #ifndef NV_INFER_RUNTIME_H


//!
//!
//!
// #define NV_INFER_RUNTIME_H

/**
 *  \file NvInferRuntime.h
 * 
 *  This is the top-level API file for TensorRT extended runtime library.
 *  */

// #include "NvInferRuntimeCommon.h"

/**
 *  \enum EngineCapability
 * 
 *  \brief List of supported engine capability flows.
 * 
 *  The EngineCapability determines the restrictions of a network during build time for what can be executed
 *  at runtime. EngineCapability::kDEFAULT does not provide any restrictions on functionality and the
 *  resulting serialized engine can be executed with TensorRT's standard runtime APIs in the nvinfer1 namespace.
 *  EngineCapabiltiy::kSAFE_GPU provides a restricted subset of network operations that are safety certified and
 *  the resulting serialized engine can be executed with TensorRT's safe runtime APIs in the nvinfer1::safe namespace.
 *  EngineCapability::kSAFE_DLA provides a restricted subset of network operations that are DLA compatible and
 *  the resulting serialized engine can be executed using NvMediaDLA's runtime APIs. See sampleNvmedia for an
 *  example of integrating NvMediaDLA APIs with TensorRT APIs.
 *  */
@Namespace("nvinfer1") public enum EngineCapability {
    /** Full capability, TensorRT mode without any restrictions using TensorRT nvinfer1 APIs. */
    kDEFAULT(0),
    /** Safety restricted capability, TensorRT flow that can only run on GPU devices via TensorRT nvinfer1::safe APIs. */
    kSAFE_GPU(1),
    /** Safety restricted capability, TensorRT flow that can only run on DLA devices via NvMediaDLA APIs. */
    kSAFE_DLA(2);

    public final int value;
    private EngineCapability(int v) { this.value = v; }
    private EngineCapability(EngineCapability e) { this.value = e.value; }
    public EngineCapability intern() { for (EngineCapability e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}


// Targeting ../nvinfer/Weights.java


// Targeting ../nvinfer/IHostMemory.java


// Targeting ../nvinfer/IPlugin.java


// Targeting ../nvinfer/IPluginExt.java



/**
 *  \enum DimensionOperation
 * 
 *  \brief An operation on two IDimensionExpr, which represent integer expressions used in dimension computations.
 * 
 *  For example, given two IDimensionExpr x and y and an IExprBuilder& eb,
 *  eb.operation(DimensionOperation::kSUM, x, y) creates a representation of x+y.
 * 
 *  @see IDimensionExpr, IExprBuilder
 *  */
@Namespace("nvinfer1") public enum DimensionOperation {
    /** Sum of the two operands. */
    kSUM(0),
    /** Product of the two operands. */
    kPROD(1),
    /** Maximum of the two operands. */
    kMAX(2),
    /** Minimum of the two operands. */
    kMIN(3),
    /** Substract the second element from the first. */
    kSUB(4),
    /** 1 if operands are equal, 0 otherwise. */
    kEQUAL(5),
    /** 1 if first operand is less than second operand, 0 otherwise. */
    kLESS(6),
    /** Floor division of the first element by the second. */
    kFLOOR_DIV(7),
    /** Division rounding up */
    kCEIL_DIV(8);

    public final int value;
    private DimensionOperation(int v) { this.value = v; }
    private DimensionOperation(DimensionOperation e) { this.value = e.value; }
    public DimensionOperation intern() { for (DimensionOperation e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}


// Targeting ../nvinfer/IDimensionExpr.java


// Targeting ../nvinfer/IExprBuilder.java


// Targeting ../nvinfer/DimsExprs.java


// Targeting ../nvinfer/DynamicPluginTensorDesc.java


// Targeting ../nvinfer/IPluginV2DynamicExt.java


// Targeting ../nvinfer/IProfiler.java



/**
 *  \enum WeightsRole
 *  \brief How a layer uses particular Weights.
 * 
 *  The power weights of an IScaleLayer are omitted.  Refitting those is not supported.
 *  */
@Namespace("nvinfer1") public enum WeightsRole {
    /** kernel for IConvolutionLayer, IDeconvolutionLayer, or IFullyConnectedLayer */
    kKERNEL(0),
    /** bias for IConvolutionLayer, IDeconvolutionLayer, or IFullyConnectedLayer */
    kBIAS(1),
    /** shift part of IScaleLayer */
    kSHIFT(2),
    /** scale part of IScaleLayer */
    kSCALE(3),
    /** weights for IConstantLayer */
    kCONSTANT(4);

    public final int value;
    private WeightsRole(int v) { this.value = v; }
    private WeightsRole(WeightsRole e) { this.value = e.value; }
    public WeightsRole intern() { for (WeightsRole e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}



/**
 *  \enum DeviceType
 *  \brief The device that this layer/network will execute on.
 * 
 *  */
@Namespace("nvinfer1") public enum DeviceType {
    /** GPU Device */
    kGPU(0),
    /** DLA Core */
    kDLA(1);

    public final int value;
    private DeviceType(int v) { this.value = v; }
    private DeviceType(DeviceType e) { this.value = e.value; }
    public DeviceType intern() { for (DeviceType e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}

// Targeting ../nvinfer/IRuntime.java


// Targeting ../nvinfer/IRefitter.java


// Targeting ../nvinfer/IPluginFactory.java



/**
 *  \enum OptProfileSelector
 * 
 *  \brief When setting or querying optimization profile parameters (such as shape tensor inputs or dynamic dimensions),
 *         select whether we are interested in the minimum, optimum, or maximum values for these parameters.
 *         The minimum and maximum specify the permitted range that is supported at runtime, while the optimum value
 *         is used for the kernel selection. This should be the "typical" value that is expected to occur at runtime.
 * 
 *  @see IOptimizationProfile::setDimensions(), IOptimizationProfile::setShapeValues()
 *  */
@Namespace("nvinfer1") public enum OptProfileSelector {
    /** This is used to set or get the minimum permitted value for dynamic dimensions etc. */
    kMIN(0),
    /** This is used to set or get the value that is used in the optimization (kernel selection). */
    kOPT(1),
    /** This is used to set or get the maximum permitted value for dynamic dimensions etc. */
    kMAX(2);

    public final int value;
    private OptProfileSelector(int v) { this.value = v; }
    private OptProfileSelector(OptProfileSelector e) { this.value = e.value; }
    public OptProfileSelector intern() { for (OptProfileSelector e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}


// Targeting ../nvinfer/IOptimizationProfile.java


// Targeting ../nvinfer/ICudaEngine.java


// Targeting ../nvinfer/IExecutionContext.java



/**
 *  Internal C entry point for creating IRuntime.
 *  \private
 *  */


//!
//!
public static native Pointer createInferRuntime_INTERNAL(Pointer logger, int version);

/**
 *  Internal C entry point for creating IRefitter.
 *  \private
 *  */
public static native Pointer createInferRefitter_INTERNAL(Pointer engine, Pointer logger, int version);
/**
 *  \brief Create an instance of an IRuntime class.
 * 
 *  This class is the logging class for the runtime.
 *  */


//!
//!
//!
@Namespace("nvinfer1") public static native IRuntime createInferRuntime(@ByRef ILogger logger);

/**
 *  \brief Create an instance of an IRefitter class.
 * 
 *  This class is the logging class for the refitter.
 *  */
@Namespace("nvinfer1") public static native IRefitter createInferRefitter(@ByRef ICudaEngine engine, @ByRef ILogger logger);



// #endif // NV_INFER_RUNTIME_H


// Parsed from NvInfer.h

/*
 * Copyright 1993-2020 NVIDIA Corporation.  All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee.  Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE.  IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users.  These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item.  Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

// #ifndef NV_INFER_H
// #define NV_INFER_H



//!
//!
//!
//!

//!
//!
//!

//!
//!
//!
// #include "NvInferRuntime.h"

/**
 *  \mainpage
 * 
 *  This is the API documentation for the NVIDIA TensorRT library. It provides information on individual
 *  functions, classes and methods. Use the index on the left to navigate the documentation.
 * 
 *  Please see the accompanying user guide and samples for higher-level information and general advice on
 *  using TensorRT. */
//
/** TensorRT Versioning follows Semantic Versioning Guidelines specified here: https://semver.org/
/**
<p>
/**
/** \file NvInfer.h
/**
/** This is the top-level API file for TensorRT.
/**
<p>
/**
/** \namespace nvinfer1
/**
/** \brief The TensorRT API version 1 namespace.
/** */
// Targeting ../nvinfer/Dims2.java


// Targeting ../nvinfer/DimsHW.java


// Targeting ../nvinfer/Dims3.java


// Targeting ../nvinfer/DimsCHW.java


// Targeting ../nvinfer/Dims4.java


// Targeting ../nvinfer/DimsNCHW.java



/**
 *  \enum LayerType
 * 
 *  \brief The type values of layer classes.
 * 
 *  @see ILayer::getType()
 *  */
@Namespace("nvinfer1") public enum LayerType {
    /** Convolution layer. */
    kCONVOLUTION(0),
    /** Fully connected layer. */
    kFULLY_CONNECTED(1),
    /** Activation layer. */
    kACTIVATION(2),
    /** Pooling layer. */
    kPOOLING(3),
    /** LRN layer. */
    kLRN(4),
    /** Scale layer. */
    kSCALE(5),
    /** SoftMax layer. */
    kSOFTMAX(6),
    /** Deconvolution layer. */
    kDECONVOLUTION(7),
    /** Concatenation layer. */
    kCONCATENATION(8),
    /** Elementwise layer. */
    kELEMENTWISE(9),
    /** Plugin layer. */
    kPLUGIN(10),
    /** RNN layer. */
    kRNN(11),
    /** UnaryOp operation Layer. */
    kUNARY(12),
    /** Padding layer. */
    kPADDING(13),
    /** Shuffle layer. */
    kSHUFFLE(14),
    /** Reduce layer. */
    kREDUCE(15),
    /** TopK layer. */
    kTOPK(16),
    /** Gather layer. */
    kGATHER(17),
    /** Matrix multiply layer. */
    kMATRIX_MULTIPLY(18),
    /** Ragged softmax layer. */
    kRAGGED_SOFTMAX(19),
    /** Constant layer. */
    kCONSTANT(20),
    /** RNNv2 layer. */
    kRNN_V2(21),
    /** Identity layer. */
    kIDENTITY(22),
    /** PluginV2 layer. */
    kPLUGIN_V2(23),
    /** Slice layer. */
    kSLICE(24),
    /** Shape layer. */
    kSHAPE(25),
    /** Parametric ReLU layer. */
    kPARAMETRIC_RELU(26),
    /** Resize Layer. */
    kRESIZE(27),
    /** Loop Trip limit layer */
    kTRIP_LIMIT(28),
    /** Loop Recurrence layer */
    kRECURRENCE(29),
    /** Loop Iterator layer */
    kITERATOR(30),
    /** Loop output layer */
    kLOOP_OUTPUT(31),
    /** Select layer. */
    kSELECT(32),
    /** Fill layer */
    kFILL(33);

    public final int value;
    private LayerType(int v) { this.value = v; }
    private LayerType(LayerType e) { this.value = e.value; }
    public LayerType intern() { for (LayerType e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}


// Targeting ../nvinfer/ITensor.java


// Targeting ../nvinfer/ILayer.java



/**
 *  \enum PaddingMode
 * 
 *  \brief Enumerates the modes of padding to perform in convolution, deconvolution and pooling layer,
 *  padding mode takes precedence if setPaddingMode() and setPrePadding() are also used.
 * 
 *  There are three padding styles, EXPLICIT, SAME, and CAFFE, with each style having two variants.
 *  The EXPLICIT and CAFFE styles determine if the final sampling location is used or not.
 *  The SAME style determine if the asymmetry in the padding is on the pre or post padding.
 * 
 *  <pre>{@code
 *  Shorthand:
 *      I = dimensions of input image.
 *      B = prePadding, before the image data. For deconvolution, prePadding is set before output.
 *      A = postPadding, after the image data. For deconvolution, postPadding is set after output.
 *      P = delta between input and output
 *      S = stride
 *      F = filter
 *      O = output
 *      D = dilation
 *      M = I + B + A ; The image data plus any padding
 *      DK = 1 + D * (F - 1)
 *  }</pre>
 * 
 *  Formulas for Convolution:
 *      - EXPLICIT_ROUND_DOWN:
 *  <pre>{@code
 *          O = floor((M - DK) / S) + 1
 *  }</pre>
 *      - CAFFE_ROUND_DOWN:
 *  <pre>{@code
 *          O = floor((I + B * 2 - DK) / S)
 *  }</pre>
 *      - EXPLICIT_ROUND_UP:
 *  <pre>{@code
 *          O = ceil((M - DK) / S) + 1
 *  }</pre>
 *      - CAFFE_ROUND_UP:
 *  <pre>{@code
 *          O = ceil((I + B * 2 - DK) / S)
 *  }</pre>
 *      - SAME_UPPER:
 *  <pre>{@code
 *          O = ceil(I / S)
 *          P = floor((I - 1) / S) * S + DK - I;
 *          B = floor(P / 2)
 *          A = P - B
 *  }</pre>
 *      - SAME_LOWER:
 *  <pre>{@code
 *          O = ceil(I / S)
 *          P = floor((I - 1) / S) * S + DK - I;
 *          A = floor(P / 2)
 *          B = P - A
 *  }</pre>
 * 
 *  Formulas for Deconvolution:
 *      - EXPLICIT_ROUND_DOWN:
 *      - CAFFE_ROUND_DOWN:
 *      - EXPLICIT_ROUND_UP:
 *      - CAFFE_ROUND_UP:
 *  <pre>{@code
 *          O = (I - 1) * S + DK - (B + A)
 *  }</pre>
 *      - SAME_UPPER:
 *  <pre>{@code
 *          O = min(I * S, (I - 1) * S + DK)
 *          P = max(DK - S, 0)
 *          B = floor(P / 2)
 *          A = P - B
 *  }</pre>
 *      - SAME_LOWER:
 *  <pre>{@code
 *          O = min(I * S, (I - 1) * S + DK)
 *          P = max(DK - S, 0)
 *          A = floor(P / 2)
 *          B = P - A
 *  }</pre>
 * 
 *  Formulas for Pooling:
 *      - EXPLICIT_ROUND_DOWN:
 *  <pre>{@code
 *          O = floor((M - F) / S) + 1
 *  }</pre>
 *      - EXPLICIT_ROUND_UP:
 *  <pre>{@code
 *          O = ceil((M - F) / S) + 1
 *  }</pre>
 *      - SAME_UPPER:
 *  <pre>{@code
 *          O = ceil(I / S)
 *          P = floor((I - 1) / S) * S + F - I;
 *          B = floor(P / 2)
 *          A = P - B
 *  }</pre>
 *      - SAME_LOWER:
 *  <pre>{@code
 *          O = ceil(I / S)
 *          P = floor((I - 1) / S) * S + F - I;
 *          A = floor(P / 2)
 *          B = P - A
 *  }</pre>
 *      - CAFFE_ROUND_DOWN:
 *  <pre>{@code
 *          EXPLICIT_ROUND_DOWN - ((EXPLICIT_ROUND_DOWN - 1) * S >= I + B)
 *  }</pre>
 *      - CAFFE_ROUND_UP:
 *  <pre>{@code
 *          EXPLICIT_ROUND_UP - ((EXPLICIT_ROUND_UP - 1) * S >= I + B)
 *  }</pre>
 * 
 *  Pooling Example 1:
 *  <pre>{@code
 *      Given I = {6, 6}, B = {3, 3}, A = {2, 2}, S = {2, 2}, F = {3, 3}. What is O?
 *      (B, A can be calculated for SAME_UPPER and SAME_LOWER mode)
 *  }</pre>
 * 
 *  - EXPLICIT_ROUND_DOWN:
 *  <pre>{@code
 *      Computation:
 *          M = {6, 6} + {3, 3} + {2, 2} ==> {11, 11}
 *          O ==> floor((M - F) / S) + 1
 *            ==> floor(({11, 11} - {3, 3}) / {2, 2}) + {1, 1}
 *            ==> floor({8, 8} / {2, 2}) + {1, 1}
 *            ==> {5, 5}
 *  }</pre>
 *  - EXPLICIT_ROUND_UP:
 *  <pre>{@code
 *      Computation:
 *          M = {6, 6} + {3, 3} + {2, 2} ==> {11, 11}
 *          O ==> ceil((M - F) / S) + 1
 *            ==> ceil(({11, 11} - {3, 3}) / {2, 2}) + {1, 1}
 *            ==> ceil({8, 8} / {2, 2}) + {1, 1}
 *            ==> {5, 5}
 *  }</pre>
 *      The sample points are {0, 2, 4, 6, 8} in each dimension.
 * 
 *  - SAME_UPPER:
 *  <pre>{@code
 *      Computation:
 *          I = {6, 6}
 *          S = {2, 2}
 *          O = ceil(I / S) = {3, 3}
 *          P = floor((I - 1) / S) * S + F - I
 *              ==> floor(({6, 6} - {1, 1}) / {2, 2}) * {2, 2} + {3, 3} - {6, 6}
 *              ==> {4, 4} + {3, 3} - {6, 6}
 *              ==> {1, 1}
 *          B = floor({1, 1} / {2, 2})
 *              ==> {0, 0}
 *          A = {1, 1} - {0, 0}
 *              ==> {1, 1}
 *  }</pre>
 *  - SAME_LOWER:
 *  <pre>{@code
 *      Computation:
 *          I = {6, 6}
 *          S = {2, 2}
 *          O = ceil(I / S) = {3, 3}
 *          P = floor((I - 1) / S) * S + F - I
 *            ==> {1, 1}
 *          A = floor({1, 1} / {2, 2})
 *            ==> {0, 0}
 *          B = {1, 1} - {0, 0}
 *            ==> {1, 1}
 *  }</pre>
 *      The sample pointers are {0, 2, 4} in each dimension.
 *      SAMPLE_UPPER has {O0, O1, O2, pad} in output in each dimension.
 *      SAMPLE_LOWER has {pad, O0, O1, O2} in output in each dimension.
 * 
 *  Pooling Example 2:
 *  <pre>{@code
 *      Given I = {6, 6}, B = {3, 3}, A = {3, 3}, S = {2, 2}, F = {3, 3}. What is O?
 *  }</pre>
 * 
 *  - CAFFE_ROUND_DOWN:
 *  <pre>{@code
 *      Computation:
 *          M = {6, 6} + {3, 3} + {3, 3} ==> {12, 12}
 *          EXPLICIT_ROUND_DOWN ==> floor((M - F) / S) + 1
 *                              ==> floor(({12, 12} - {3, 3}) / {2, 2}) + {1, 1}
 *                              ==> {5, 5}
 *          DIFF = (((EXPLICIT_ROUND_DOWN - 1) * S >= I + B) ? {1, 1} : {0, 0})
 *            ==> ({5, 5} - {1, 1}) * {2, 2} >= {6, 6} + {3, 3} ? {1, 1} : {0,0}
 *            ==> {0, 0}
 *          O ==> EXPLICIT_ROUND_DOWN - DIFF
 *            ==> {5, 5} - {0, 0}
 *            ==> {5, 5}
 *  }</pre>
 *  - CAFFE_ROUND_UP:
 *  <pre>{@code
 *      Computation:
 *          M = {6, 6} + {3, 3} + {3, 3} ==> {12, 12}
 *          EXPLICIT_ROUND_UP ==> ceil((M - F) / S) + 1
 *                            ==> ceil(({12, 12} - {3, 3}) / {2, 2}) + {1, 1}
 *                            ==> {6, 6}
 *          DIFF = (((EXPLICIT_ROUND_UP - 1) * S >= I + B) ? {1, 1} : {0, 0})
 *            ==> ({6, 6} - {1, 1}) * {2, 2} >= {6, 6} + {3, 3} ? {1, 1} : {0,0}
 *            ==> {1, 1}
 *          O ==> EXPLICIT_ROUND_UP - DIFF
 *            ==> {6, 6} - {1, 1}
 *            ==> {5, 5}
 *  }</pre>
 * 
 *  The sample points are {0, 2, 4, 6, 8} in each dimension. <br>
 *  CAFFE_ROUND_DOWN and CAFFE_ROUND_UP have two restrictions each on usage with pooling operations.
 *  This will cause getDimensions to return an empty dimension and also to reject the network
 *  at validation time. <br>
 *  For more information on original reference code, see
 *  https://github.com/BVLC/caffe/blob/master/src/caffe/layers/pooling_layer.cpp
 * 
 *  - Restriction 1:
 *  <pre>{@code
 *      CAFFE_ROUND_DOWN: B >= F is an error if (B - S) < F
 *      CAFFE_ROUND_UP: (B + S) >= (F + 1) is an error if B < (F + 1)
 *  }</pre>
 * 
 *  - Restriction 2:
 *  <pre>{@code
 *      CAFFE_ROUND_DOWN: (B - S) >= F is an error if B >= F
 *      CAFFE_ROUND_UP: B >= (F + 1) is an error if (B + S) >= (F + 1)
 *  }</pre>
 *  */
@Namespace("nvinfer1") public enum PaddingMode {
    /** Use explicit padding, rounding output size down. */
    kEXPLICIT_ROUND_DOWN(0),
    /** Use explicit padding, rounding output size up. */
    kEXPLICIT_ROUND_UP(1),
    /** Use SAME padding, with prePadding <= postPadding. */
    kSAME_UPPER(2),
    /** Use SAME padding, with prePadding >= postPadding. */
    kSAME_LOWER(3),
    /** Use CAFFE padding, rounding output size down, uses prePadding value. */
    kCAFFE_ROUND_DOWN(4),
    /** Use CAFFE padding, rounding output size up, uses prePadding value. */
    kCAFFE_ROUND_UP(5);

    public final int value;
    private PaddingMode(int v) { this.value = v; }
    private PaddingMode(PaddingMode e) { this.value = e.value; }
    public PaddingMode intern() { for (PaddingMode e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}


// Targeting ../nvinfer/IConvolutionLayer.java


// Targeting ../nvinfer/IFullyConnectedLayer.java


// Targeting ../nvinfer/IActivationLayer.java



/**
 *  \enum PoolingType
 * 
 *  \brief The type of pooling to perform in a pooling layer.
 *  */
@Namespace("nvinfer1") public enum PoolingType {
    kMAX(0),              // Maximum over elements
    kAVERAGE(1),          // Average over elements. If the tensor is padded, the count includes the padding
    kMAX_AVERAGE_BLEND(2);// Blending between max and average pooling: (1-blendFactor)*maxPool + blendFactor*avgPool

    public final int value;
    private PoolingType(int v) { this.value = v; }
    private PoolingType(PoolingType e) { this.value = e.value; }
    public PoolingType intern() { for (PoolingType e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}


// Targeting ../nvinfer/IPoolingLayer.java


// Targeting ../nvinfer/ILRNLayer.java



/**
 *  \brief Controls how shift, scale and power are applied in a Scale layer.
 * 
 *  @see IScaleLayer
 *  */
@Namespace("nvinfer1") public enum ScaleMode {
    /** Identical coefficients across all elements of the tensor. */
    kUNIFORM(0),
    /** Per-channel coefficients. */
    kCHANNEL(1),
    /** Elementwise coefficients. */
    kELEMENTWISE(2);

    public final int value;
    private ScaleMode(int v) { this.value = v; }
    private ScaleMode(ScaleMode e) { this.value = e.value; }
    public ScaleMode intern() { for (ScaleMode e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}


// Targeting ../nvinfer/IScaleLayer.java


// Targeting ../nvinfer/ISoftMaxLayer.java


// Targeting ../nvinfer/IConcatenationLayer.java


// Targeting ../nvinfer/IDeconvolutionLayer.java



/**
 *  \enum ElementWiseOperation
 * 
 *  \brief Enumerates the binary operations that may be performed by an ElementWise layer.
 * 
 *  @see IElementWiseLayer
 *  */
@Namespace("nvinfer1") public enum ElementWiseOperation {
    /** Sum of the two elements. */
    kSUM(0),
    /** Product of the two elements. */
    kPROD(1),
    /** Maximum of the two elements. */
    kMAX(2),
    /** Minimum of the two elements. */
    kMIN(3),
    /** Substract the second element from the first. */
    kSUB(4),
    /** Divide the first element by the second. */
    kDIV(5),
    /** The first element to the power of the second element. */
    kPOW(6),
    /** Floor division of the first element by the second. */
    kFLOOR_DIV(7),
    /** Logical AND of two elements. */
    kAND(8),
    /** Logical OR of two elements. */
    kOR(9),
    /** Logical XOR of two elements. */
    kXOR(10),
    /** Check if two elements are equal. */
    kEQUAL(11),
    /** Check if element in first tensor is greater than corresponding element in second tensor. */
    kGREATER(12),
    /** Check if element in first tensor is less than corresponding element in second tensor. */
    kLESS(13);

    public final int value;
    private ElementWiseOperation(int v) { this.value = v; }
    private ElementWiseOperation(ElementWiseOperation e) { this.value = e.value; }
    public ElementWiseOperation intern() { for (ElementWiseOperation e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}


// Targeting ../nvinfer/IElementWiseLayer.java


// Targeting ../nvinfer/IGatherLayer.java



/**
 *  \enum RNNOperation
 * 
 *  \brief Enumerates the RNN operations that may be performed by an RNN layer.
 * 
 *  __Equation definitions__
 * 
 *  In the equations below, we use the following naming convention:
 * 
 *  ~~~
 *  t := current time step
 * 
 *  i := input gate
 *  o := output gate
 *  f := forget gate
 *  z := update gate
 *  r := reset gate
 *  c := cell gate
 *  h := hidden gate
 * 
 *  g[t] denotes the output of gate g at timestep t, e.g.
 *  f[t] is the output of the forget gate f.
 * 
 *  X[t] := input tensor for timestep t
 *  C[t] := cell state for timestep t
 *  H[t] := hidden state for timestep t
 * 
 *  W[g] := W (input) parameter weight matrix for gate g
 *  R[g] := U (recurrent) parameter weight matrix for gate g
 *  Wb[g] := W (input) parameter bias vector for gate g
 *  Rb[g] := U (recurrent) parameter bias vector for gate g
 * 
 *  Unless otherwise specified, all operations apply pointwise
 *  to elements of each operand tensor.
 * 
 *  ReLU(X) := max(X, 0)
 *  tanh(X) := hyperbolic tangent of X
 *  sigmoid(X) := 1 / (1 + exp(-X))
 *  exp(X) := e^X
 * 
 *  A.B denotes matrix multiplication of A and B.
 *  A*B denotes pointwise multiplication of A and B.
 *  ~~~
 * 
 *  __Equations__
 * 
 *  Depending on the value of RNNOperation chosen, each sub-layer of the RNN
 *  layer will perform one of the following operations:
 * 
 *  ~~~
 *  ::kRELU
 * 
 *    H[t] := ReLU(W[i].X[t] + R[i].H[t-1] + Wb[i] + Rb[i])
 * 
 *  ::kTANH
 * 
 *    H[t] := tanh(W[i].X[t] + R[i].H[t-1] + Wb[i] + Rb[i])
 * 
 *  ::kLSTM
 * 
 *    i[t] := sigmoid(W[i].X[t] + R[i].H[t-1] + Wb[i] + Rb[i])
 *    f[t] := sigmoid(W[f].X[t] + R[f].H[t-1] + Wb[f] + Rb[f])
 *    o[t] := sigmoid(W[o].X[t] + R[o].H[t-1] + Wb[o] + Rb[o])
 *    c[t] :=    tanh(W[c].X[t] + R[c].H[t-1] + Wb[c] + Rb[c])
 * 
 *    C[t] := f[t]*C[t-1] + i[t]*c[t]
 *    H[t] := o[t]*tanh(C[t])
 * 
 *  ::kGRU
 * 
 *    z[t] := sigmoid(W[z].X[t] + R[z].H[t-1] + Wb[z] + Rb[z])
 *    r[t] := sigmoid(W[r].X[t] + R[r].H[t-1] + Wb[r] + Rb[r])
 *    h[t] := tanh(W[h].X[t] + r[t]*(R[h].H[t-1] + Rb[h]) + Wb[h])
 * 
 *    H[t] := (1 - z[t])*h[t] + z[t]*H[t-1]
 *  ~~~
 * 
 *  @see IRNNLayer, IRNNv2Layer
 *  */
@Namespace("nvinfer1") public enum RNNOperation {
    /** Single gate RNN w/ ReLU activation function. */
    kRELU(0),
    /** Single gate RNN w/ TANH activation function. */
    kTANH(1),
    /** Four-gate LSTM network w/o peephole connections. */
    kLSTM(2),
    /** Three-gate network consisting of Gated Recurrent Units. */
    kGRU(3);

    public final int value;
    private RNNOperation(int v) { this.value = v; }
    private RNNOperation(RNNOperation e) { this.value = e.value; }
    public RNNOperation intern() { for (RNNOperation e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}



/**
 *  \enum RNNDirection
 * 
 *  \brief Enumerates the RNN direction that may be performed by an RNN layer.
 * 
 *  @see IRNNLayer, IRNNv2Layer
 *  */
@Namespace("nvinfer1") public enum RNNDirection {
    /** Network iterations from first input to last input. */
    kUNIDIRECTION(0),
    /** Network iterates from first to last and vice versa and outputs concatenated. */
    kBIDIRECTION(1);

    public final int value;
    private RNNDirection(int v) { this.value = v; }
    private RNNDirection(RNNDirection e) { this.value = e.value; }
    public RNNDirection intern() { for (RNNDirection e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}



/**
 *  \enum RNNInputMode
 * 
 *  \brief Enumerates the RNN input modes that may occur with an RNN layer.
 * 
 *  If the RNN is configured with RNNInputMode::kLINEAR, then for each gate {@code g} in the first layer of the RNN,
 *  the input vector {@code X[t]} (length {@code E}) is left-multiplied by the gate's corresponding weight matrix {@code W[g]}
 *  (dimensions {@code HxE}) as usual, before being used to compute the gate output as described by \ref RNNOperation.
 * 
 *  If the RNN is configured with RNNInputMode::kSKIP, then this initial matrix multiplication is "skipped"
 *  and {@code W[g]} is conceptually an identity matrix.  In this case, the input vector {@code X[t]} must have length {@code H}
 *  (the size of the hidden state).
 * 
 *  @see IRNNLayer, IRNNv2Layer
 *  */
@Namespace("nvinfer1") public enum RNNInputMode {
    /** Perform the normal matrix multiplication in the first recurrent layer. */
    kLINEAR(0),
    /** No operation is performed on the first recurrent layer. */
    kSKIP(1);

    public final int value;
    private RNNInputMode(int v) { this.value = v; }
    private RNNInputMode(RNNInputMode e) { this.value = e.value; }
    public RNNInputMode intern() { for (RNNInputMode e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}


// Targeting ../nvinfer/IRNNLayer.java



/**
 *  \enum RNNGateType
 * 
 *  \brief Identifies an individual gate within an RNN cell.
 * 
 *  @see RNNOperation
 *  */
@Namespace("nvinfer1") public enum RNNGateType {
    /** Input gate  (i). */
    kINPUT(0),
    /** Output gate (o). */
    kOUTPUT(1),
    /** Forget gate (f). */
    kFORGET(2),
    /** Update gate (z). */
    kUPDATE(3),
    /** Reset gate  (r). */
    kRESET(4),
    /** Cell gate   (c). */
    kCELL(5),
    /** Hidden gate (h). */
    kHIDDEN(6);

    public final int value;
    private RNNGateType(int v) { this.value = v; }
    private RNNGateType(RNNGateType e) { this.value = e.value; }
    public RNNGateType intern() { for (RNNGateType e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}


// Targeting ../nvinfer/IRNNv2Layer.java


// Targeting ../nvinfer/IOutputDimensionsFormula.java


// Targeting ../nvinfer/IPluginLayer.java


// Targeting ../nvinfer/IPluginV2Layer.java



/**
 *  \enum UnaryOperation
 * 
 *  \brief Enumerates the unary operations that may be performed by a Unary layer.
 * 
 *  @see IUnaryLayer
 *  */
@Namespace("nvinfer1") public enum UnaryOperation {
    /** Exponentiation. */
    kEXP(0),
    /** Log (base e). */
    kLOG(1),
    /** Square root. */
    kSQRT(2),
    /** Reciprocal. */
    kRECIP(3),
    /** Absolute value. */
    kABS(4),
    /** Negation. */
    kNEG(5),
    /** Sine. */
    kSIN(6),
    /** Cosine. */
    kCOS(7),
    /** Tangent. */
    kTAN(8),
    /** Hyperbolic sine. */
    kSINH(9),
    /** Hyperbolic cosine. */
    kCOSH(10),
    /** Inverse sine. */
    kASIN(11),
    /** Inverse cosine. */
    kACOS(12),
    /** Inverse tangent. */
    kATAN(13),
    /** Inverse hyperbolic sine. */
    kASINH(14),
    /** Inverse hyperbolic cosine. */
    kACOSH(15),
    /** Inverse hyperbolic tangent. */
    kATANH(16),
    /** Ceiling. */
    kCEIL(17),
    /** Floor. */
    kFLOOR(18),
    /** Gauss error function. */
    kERF(19),
    /** Logical NOT. */
    kNOT(20);

    public final int value;
    private UnaryOperation(int v) { this.value = v; }
    private UnaryOperation(UnaryOperation e) { this.value = e.value; }
    public UnaryOperation intern() { for (UnaryOperation e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}


// Targeting ../nvinfer/IUnaryLayer.java



/**
 *  \enum ReduceOperation
 * 
 *  \brief Enumerates the reduce operations that may be performed by a Reduce layer.
 * 
 *  The table shows the result of reducing across an empty volume of a given type.
 * 
 *  Operation | kFLOAT and kHALF  | kINT32  | kINT8
 *  --------- | ----------------- | ------- | -----
 *  kSUM      | 0                 | 0       | 0
 *  kPROD     | 1                 | 1       | 1
 *  kMAX      | negative infinity | INT_MIN | -128
 *  kMIN      | positive infinity | INT_MAX | 127
 *  kAVG      | NaN               | 0       | -128
 * 
 *  The current version of TensorRT usually performs reduction for kINT8 via kFLOAT or kHALF.
 *  The kINT8 values show the quantized representations of the floating-point values.
 *  */
@Namespace("nvinfer1") public enum ReduceOperation {
    kSUM(0),
    kPROD(1),
    kMAX(2),
    kMIN(3),
    kAVG(4);

    public final int value;
    private ReduceOperation(int v) { this.value = v; }
    private ReduceOperation(ReduceOperation e) { this.value = e.value; }
    public ReduceOperation intern() { for (ReduceOperation e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}


// Targeting ../nvinfer/IReduceLayer.java


// Targeting ../nvinfer/IPaddingLayer.java


// Targeting ../nvinfer/Permutation.java


// Targeting ../nvinfer/IShuffleLayer.java



/**
 *  \brief Controls how ISliceLayer handles out of bounds coordinates.
 * 
 *  @see ISliceLayer
 *  */
@Namespace("nvinfer1") public enum SliceMode {
    /** Fail with error when the coordinates are out of bounds. This is the default. */
    kDEFAULT(0),
    /** Coordinates wrap around periodically. */
    kWRAP(1);

    public final int value;
    private SliceMode(int v) { this.value = v; }
    private SliceMode(SliceMode e) { this.value = e.value; }
    public SliceMode intern() { for (SliceMode e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}


// Targeting ../nvinfer/ISliceLayer.java


// Targeting ../nvinfer/IShapeLayer.java



/**
 *  \enum TopKOperation
 * 
 *  \brief Enumerates the operations that may be performed by a TopK layer.
 *  */
@Namespace("nvinfer1") public enum TopKOperation {
    /** Maximum of the elements. */
    kMAX(0),
    /** Minimum of the elements. */
    kMIN(1);

    public final int value;
    private TopKOperation(int v) { this.value = v; }
    private TopKOperation(TopKOperation e) { this.value = e.value; }
    public TopKOperation intern() { for (TopKOperation e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}


// Targeting ../nvinfer/ITopKLayer.java



/**
 *  \enum MatrixOperation
 * 
 *  \brief Enumerates the operations that may be performed on a tensor
 *         by IMatrixMultiplyLayer before multiplication.
 *  */
@Namespace("nvinfer1") public enum MatrixOperation {
    /** Treat x as a matrix if it has two dimensions, or as a collection of
     *  matrices if x has more than two dimensions, where the last two dimensions
     *  are the matrix dimensions.  x must have at least two dimensions. */
    kNONE(0),

    /** Like kNONE, but transpose the matrix dimensions. */
    
//!
    kTRANSPOSE(1),

    /** Treat x as a vector if it has one dimension, or as a collection of
     *  vectors if x has more than one dimension.  x must have at least one dimension.
     *  The first input tensor with dimensions [M,K] used with MatrixOperation::kVECTOR is equivalent to a tensor
     *  with dimensions [M, 1, K] with MatrixOperation::kNONE, i.e. is treated as M row vectors of length K.
     *  If MatrixOperation::kTRANSPOSE is specified, then the dimensions are [M, K, 1].
     * 
     *  The second input tensor with dimensions [M,K] used with MatrixOperation::kVECTOR is equivalent to a tensor
     *  with dimensions [M, K, 1] with MatrixOperation::kNONE, i.e. is treated as M column vectors of length K.
     *  If MatrixOperation::kTRANSPOSE is specified, then the dimensions are [M, 1, K]. */
    kVECTOR(2);

    public final int value;
    private MatrixOperation(int v) { this.value = v; }
    private MatrixOperation(MatrixOperation e) { this.value = e.value; }
    public MatrixOperation intern() { for (MatrixOperation e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}


// Targeting ../nvinfer/IMatrixMultiplyLayer.java


// Targeting ../nvinfer/IRaggedSoftMaxLayer.java


// Targeting ../nvinfer/IIdentityLayer.java


// Targeting ../nvinfer/IConstantLayer.java


// Targeting ../nvinfer/IParametricReLULayer.java



/** \enum ResizeMode
 * 
 *  \brief Enumerates various modes of resize in the resize layer.
 *         Resize mode set using setResizeMode().
 *  */
@Namespace("nvinfer1") public enum ResizeMode {
    kNEAREST(0), // ND (0 < N <= 8) nearest neighbor resizing.
    kLINEAR(1);  // Can handle linear (1D), bilinear (2D), and trilinear (3D) resizing.

    public final int value;
    private ResizeMode(int v) { this.value = v; }
    private ResizeMode(ResizeMode e) { this.value = e.value; }
    public ResizeMode intern() { for (ResizeMode e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}


// Targeting ../nvinfer/IResizeLayer.java



/** Enum that describes kinds of loop outputs. */
@Namespace("nvinfer1") public enum LoopOutput {
    /** Output value is value of tensor for last iteration. */
    kLAST_VALUE(0),

    /** Output value is concatenation of values of tensor for each iteration, in forward order. */
    kCONCATENATE(1),

    /** Output value is concatenation of values of tensor for each iteration, in reverse order. */
    kREVERSE(2);

    public final int value;
    private LoopOutput(int v) { this.value = v; }
    private LoopOutput(LoopOutput e) { this.value = e.value; }
    public LoopOutput intern() { for (LoopOutput e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}



/** Enum that describes kinds of trip limits. */
@Namespace("nvinfer1") public enum TripLimit {
    // Tensor is scalar of type kINT32 that contains the trip count.
    kCOUNT(0),

    // Tensor is a scalar of type kBOOL. Loop terminates when value is false.
    kWHILE(1);

    public final int value;
    private TripLimit(int v) { this.value = v; }
    private TripLimit(TripLimit e) { this.value = e.value; }
    public TripLimit intern() { for (TripLimit e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}


// Targeting ../nvinfer/ILoopBoundaryLayer.java


// Targeting ../nvinfer/IRecurrenceLayer.java


// Targeting ../nvinfer/ILoopOutputLayer.java


// Targeting ../nvinfer/ITripLimitLayer.java


// Targeting ../nvinfer/IIteratorLayer.java


// Targeting ../nvinfer/ILoop.java


// Targeting ../nvinfer/ISelectLayer.java



/**
 *  \enum FillOperation
 * 
 *  \brief Enumerates the tensor fill operations that may performed by a fill layer.
 * 
 *  @see IFillLayer
 *  */
@Namespace("nvinfer1") public enum FillOperation {
    /** Generate evenly spaced numbers over a specified interval. */
    kLINSPACE(0),
    /** Generate a tensor with random values drawn from a uniform distribution. */
    kRANDOM_UNIFORM(1);

    public final int value;
    private FillOperation(int v) { this.value = v; }
    private FillOperation(FillOperation e) { this.value = e.value; }
    public FillOperation intern() { for (FillOperation e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}


// Targeting ../nvinfer/IFillLayer.java


// Targeting ../nvinfer/INetworkDefinition.java



/**
 *  enum CalibrationAlgoType
 * 
 *  \brief Version of calibration algorithm to use.
 *  */
@Namespace("nvinfer1") public enum CalibrationAlgoType {
    kLEGACY_CALIBRATION(0),
    kENTROPY_CALIBRATION(1),
    kENTROPY_CALIBRATION_2(2),
    kMINMAX_CALIBRATION(3);

    public final int value;
    private CalibrationAlgoType(int v) { this.value = v; }
    private CalibrationAlgoType(CalibrationAlgoType e) { this.value = e.value; }
    public CalibrationAlgoType intern() { for (CalibrationAlgoType e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}


// Targeting ../nvinfer/IInt8Calibrator.java


// Targeting ../nvinfer/IInt8EntropyCalibrator.java


// Targeting ../nvinfer/IInt8EntropyCalibrator2.java


// Targeting ../nvinfer/IInt8MinMaxCalibrator.java


// Targeting ../nvinfer/IInt8LegacyCalibrator.java


// Targeting ../nvinfer/IAlgorithmIOInfo.java


// Targeting ../nvinfer/IAlgorithmVariant.java


// Targeting ../nvinfer/IAlgorithmContext.java


// Targeting ../nvinfer/IAlgorithm.java


// Targeting ../nvinfer/IAlgorithmSelector.java



/**
 *  \brief Represents a collection of one or more QuantizationFlag values using binary OR
 *  operations.
 * 
 *  @see IBuilderConfig::getQuantizationFlags(), IBuilderConfig::setQuantizationFlags()
 *  */


//!
//!
//!
//!

/**
 *  \enum QuantizationFlag
 * 
 *  \brief List of valid flags for quantizing the network to int8
 * 
 *  @see IBuilderConfig::setQuantizationFlag(), IBuilderConfig::getQuantizationFlag()
 *  */
@Namespace("nvinfer1") public enum QuantizationFlag {
    /** IInt8EntropyCalibrator. We always run int8 calibration pass before layer fusion for
     *  IInt8MinMaxCalibrator and IInt8EntropyCalibrator2. Disabled by default. */
    kCALIBRATE_BEFORE_FUSION(0);

    public final int value;
    private QuantizationFlag(int v) { this.value = v; }
    private QuantizationFlag(QuantizationFlag e) { this.value = e.value; }
    public QuantizationFlag intern() { for (QuantizationFlag e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}



/**
 *  \brief Represents a collection of one or more QuantizationFlag values using binary OR
 *  operations, e.g., 1U << BuilderFlag::kFP16 | 1U << BuilderFlag::kDEBUG.
 * 
 *  @see IBuilderConfig::getFlags(), ITensor::setFlags(),
 *  */


//!
//!
//!
//!

/**
 *  \enum BuilderFlag
 * 
 *  \brief List of valid modes that the builder can enable when creating an engine from a network definition.
 * 
 *  @see IBuilderConfig::setFlag(), IBuilderConfig::getFlag()
 *  */
@Namespace("nvinfer1") public enum BuilderFlag {
    /** Enable FP16 layer selection, with FP32 fallback. */
    kFP16(0),
    /** Enable Int8 layer selection, with FP32 fallback with FP16 fallback if kFP16 also specified. */
    kINT8(1),
    /** Enable debugging of layers via synchronizing after every layer. */
    kDEBUG(2),
    /** Enable layers marked to execute on GPU if layer cannot execute on DLA. */
    kGPU_FALLBACK(3),
    /** Enables strict type constraints. */
    kSTRICT_TYPES(4),
    /** Enable building a refittable engine. */
    kREFIT(5),
    /** Disable reuse of timing information across identical layers. */
    kDISABLE_TIMING_CACHE(6),

    /** Allow (but not require) computations on tensors of type DataType::kFLOAT to use TF32.
     *  TF32 computes inner products by rounding the inputs to 10-bit mantissas before
     *  multiplying, but accumulates the sum using 23-bit mantissas. Enabled by default. */
    kTF32(7);

    public final int value;
    private BuilderFlag(int v) { this.value = v; }
    private BuilderFlag(BuilderFlag e) { this.value = e.value; }
    public BuilderFlag intern() { for (BuilderFlag e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}



/**
 *  \enum ProfilingVerbosity
 * 
 *  \brief List of verbosity levels of layer information exposed in NVTX annotations.
 * 
 *  @see IBuilderConfig::setProfilingVerbosity(),
 *       IBuilderConfig::getProfilingVerbosity()
 *  */
@Namespace("nvinfer1") public enum ProfilingVerbosity {
   /** Register layer names in NVTX message field. */
   kDEFAULT(0),
   /** Turn off NVTX traces. */
   kNONE(1),
   /** Register layer names in NVTX message field and register layer detail in NVTX JSON payload field. */
   kVERBOSE(2);

    public final int value;
    private ProfilingVerbosity(int v) { this.value = v; }
    private ProfilingVerbosity(ProfilingVerbosity e) { this.value = e.value; }
    public ProfilingVerbosity intern() { for (ProfilingVerbosity e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}


// Targeting ../nvinfer/IBuilderConfig.java




/** \typedef NetworkDefinitionCreationFlags
 * 
 *  \brief This bitset is capable of representing one or more NetworkDefinitionCreationFlag flags
 *  constructed with binary OR operations.
 *   e.g., 1U << NetworkDefinitionCreationFlag::kEXPLICIT_BATCH
 * 
 *  @see IBuilder::createNetworkV2
 *  */

//!
//!
//!

/** \enum NetworkDefinitionCreationFlag
 * 
 *  \brief List of immutable network properties expressed at network creation time.
 *  NetworkDefinitionCreationFlag is used with createNetworkV2 to specify immutable properties of the network.
 *  The createNetwork() function always had an implicit batch dimension being specified by the
 *  maxBatchSize builder parameter. createNetworkV2 with kDEFAULT flag mimics that behaviour.
 * 
 *  @see IBuilder::createNetworkV2
 *  */
@Namespace("nvinfer1") public enum NetworkDefinitionCreationFlag {
    /** Dynamic shape support requires that the kEXPLICIT_BATCH flag is set.
     *  With dynamic shapes, any of the input dimensions can vary at run-time,
     *  and there are no implicit dimensions in the network specification. This is specified by using the
     *  wildcard dimension value -1. */
    /** Mark the network to be an explicit batch network */
    kEXPLICIT_BATCH(0),

    /** Setting the network to be an explicit precision network has the following implications:
     *  1) Precision of all input tensors to the network have to be specified with ITensor::setType() function
     *  2) Precision of all layer output tensors in the network have to be specified using ILayer::setOutputType()
     *  function
     *  3) The builder will not quantize the weights of any layer including those running in lower precision(INT8). It
     *  will
     *  simply cast the weights into the required precision.
     *  4) Dynamic ranges must not be provided to run the network in int8 mode. Dynamic ranges of each tensor in the
     *  explicit
     *  precision network is [-127,127].
     *  5) Quantizing and dequantizing activation values between higher (FP32) and lower (INT8) precision
     *  will be performed using explicit Scale layers with input/output precision set appropriately. */
    /** Mark the network to be an explicit precision network */
    kEXPLICIT_PRECISION(1);

    public final int value;
    private NetworkDefinitionCreationFlag(int v) { this.value = v; }
    private NetworkDefinitionCreationFlag(NetworkDefinitionCreationFlag e) { this.value = e.value; }
    public NetworkDefinitionCreationFlag intern() { for (NetworkDefinitionCreationFlag e : values()) if (e.value == value) return e; return this; }
    @Override public String toString() { return intern().name(); }
}

// Targeting ../nvinfer/IBuilder.java



 // namespace nvinfer1

/**
 *  Internal C entry point for creating IBuilder.
 *  \private
 *  */
public static native Pointer createInferBuilder_INTERNAL(Pointer logger, int version);
/**
 *  \brief Create an instance of an IBuilder class.
 * 
 *  This class is the logging class for the builder.
 * 
 *  unnamed namespace avoids linkage surprises when linking objects built with different versions of this header.
 *  */
@Namespace("nvinfer1") public static native IBuilder createInferBuilder(@ByRef ILogger logger);



// #endif


// Parsed from NvUtils.h

/*
 * Copyright 1993-2020 NVIDIA Corporation.  All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee.  Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE.  IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users.  These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item.  Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

// #ifndef NV_UTILS_H
// #define NV_UTILS_H



//!
//!
//!
// #include "NvInfer.h"

/**
 *  \file NvUtils.h
 * 
 *  This file includes various utility functions
 *  */

    /**
     *  @param input The input weights to reshape.
     *  @param shape The shape of the weights.
     *  @param shapeOrder The order of the dimensions to process for the output.
     *  @param data The location where the output data is placed.
     *  @param nbDims The number of dimensions to process.
     * 
     *  \brief Reformat the input weights of the given shape based on the new
     *  order of dimensions.
     * 
     *  Take the weights specified by \p input with the dimensions specified by
     *  \p shape and re-order the weights based on the new dimensions specified
     *  by \p shapeOrder. The size of each dimension and the input data is not
     *  modified. The output volume pointed to by \p data must be the same as
     *  he \p input volume.
     * 
     *  Example usage:
     *  float *out = new float[N*C*H*W];
     *  Weights input{DataType::kFLOAT, {0 ... N*C*H*W-1}, N*C*H*W size};
     *  int order[4]{1, 0, 3, 2};
     *  int shape[4]{C, N, W, H};
     *  reshapeWeights(input, shape, order, out, 4);
     *  Weights reshaped{input.type, out, input.count};
     * 
     *  Input Matrix{3, 2, 3, 2}:
     *  { 0  1}, { 2  3}, { 4  5} <-- {0, 0, *, *}
     *  { 6  7}, { 8  9}, {10 11} <-- {0, 1, *, *}
     *  {12 13}, {14 15}, {16 17} <-- {1, 0, *, *}
     *  {18 19}, {20 21}, {22 23} <-- {1, 1, *, *}
     *  {24 25}, {26 27}, {28 29} <-- {2, 0, *, *}
     *  {30 31}, {32 33}, {34 35} <-- {2, 1, *, *}
     * 
     *  Output Matrix{2, 3, 2, 3}:
     *  { 0  2  4}, { 1  3  5} <-- {0, 0, *, *}
     *  {12 14 16}, {13 15 17} <-- {0, 1, *, *}
     *  {24 26 28}, {25 27 29} <-- {0, 2, *, *}
     *  { 6  8 10}, { 7  9 11} <-- {1, 0, *, *}
     *  {18 20 22}, {19 21 23} <-- {1, 1, *, *}
     *  {30 32 34}, {31 33 35} <-- {1, 2, *, *}
     * 
     *  @return True on success, false on failure.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    @Namespace("nvinfer1::utils") public static native @Cast("bool") boolean reshapeWeights(@Const @ByRef Weights input, @Const IntPointer shape, @Const IntPointer shapeOrder, Pointer data, int nbDims);
    @Namespace("nvinfer1::utils") public static native @Cast("bool") boolean reshapeWeights(@Const @ByRef Weights input, @Const IntBuffer shape, @Const IntBuffer shapeOrder, Pointer data, int nbDims);
    @Namespace("nvinfer1::utils") public static native @Cast("bool") boolean reshapeWeights(@Const @ByRef Weights input, @Const int[] shape, @Const int[] shapeOrder, Pointer data, int nbDims);

    /**
     *  @param input The input data to re-order.
     *  @param order The new order of the data sub-buffers.
     *  @param num The number of data sub-buffers to re-order.
     *  @param size The size of each data sub-buffer in bytes.
     * 
     *  \brief Takes an input stream and re-orders \p num chunks of the data
     *  given the \p size and \p order.
     * 
     *  In some frameworks, the ordering of the sub-buffers within a dimension
     *  is different than the way that TensorRT expects them.
     *  TensorRT expects the gate/bias sub-buffers for LSTM's to be in fico order.
     *  TensorFlow however formats the sub-buffers in icfo order.
     *  This helper function solves this in a generic fashion.
     * 
     *  Example usage output of reshapeWeights above:
     *  int indir[1]{1, 0}
     *  int stride = W*H;
     *  for (int x = 0, y = N*C; x < y; ++x)
     *  reorderSubBuffers(out + x * stride, indir, H, W);
     * 
     *  Input Matrix{2, 3, 2, 3}:
     *  { 0  2  4}, { 1  3  5} <-- {0, 0, *, *}
     *  {12 14 16}, {13 15 17} <-- {0, 1, *, *}
     *  {24 26 28}, {25 27 29} <-- {0, 2, *, *}
     *  { 6  8 10}, { 7  9 11} <-- {1, 0, *, *}
     *  {18 20 22}, {19 21 23} <-- {1, 1, *, *}
     *  {30 32 34}, {31 33 35} <-- {1, 2, *, *}
     * 
     *  Output Matrix{2, 3, 2, 3}:
     *  { 1  3  5}, { 0  2  4} <-- {0, 0, *, *}
     *  {13 15 17}, {12 14 16} <-- {0, 1, *, *}
     *  {25 27 29}, {24 26 28} <-- {0, 2, *, *}
     *  { 7  9 11}, { 6  8 10} <-- {1, 0, *, *}
     *  {19 21 23}, {18 20 22} <-- {1, 1, *, *}
     *  {31 33 35}, {30 32 34} <-- {1, 2, *, *}
     * 
     *  @return True on success, false on failure.
     * 
     *  @see reshapeWeights()
     *  */
    
    
    //!
    //!
    //!
    //!
    @Namespace("nvinfer1::utils") public static native @Cast("bool") boolean reorderSubBuffers(Pointer input, @Const IntPointer order, int num, int size);
    @Namespace("nvinfer1::utils") public static native @Cast("bool") boolean reorderSubBuffers(Pointer input, @Const IntBuffer order, int num, int size);
    @Namespace("nvinfer1::utils") public static native @Cast("bool") boolean reorderSubBuffers(Pointer input, @Const int[] order, int num, int size);

    /**
     *  @param input The input data to transpose.
     *  @param type The type of the data to transpose.
     *  @param num The number of data sub-buffers to transpose.
     *  @param height The size of the height dimension to transpose.
     *  @param width The size of the width dimension to transpose.
     * 
     *  \brief Transpose \p num sub-buffers of \p height * \p width.
     * 
     *  @return True on success, false on failure.
     *  */
    @Namespace("nvinfer1::utils") public static native @Cast("bool") boolean transposeSubBuffers(Pointer input, DataType type, int num, int height, int width);
    @Namespace("nvinfer1::utils") public static native @Cast("bool") boolean transposeSubBuffers(Pointer input, @Cast("nvinfer1::DataType") int type, int num, int height, int width);

 // utils namespace
 // nvinfer1 namespace
// #endif // NV_UTILS_H


}
