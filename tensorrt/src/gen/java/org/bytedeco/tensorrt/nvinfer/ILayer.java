// Targeted by JavaCPP version 1.5-SNAPSHOT: DO NOT EDIT THIS FILE

package org.bytedeco.tensorrt.nvinfer;

import java.nio.*;
import org.bytedeco.javacpp.*;
import org.bytedeco.javacpp.annotation.*;

import org.bytedeco.cuda.cudart.*;
import static org.bytedeco.cuda.global.cudart.*;

import static org.bytedeco.tensorrt.global.nvinfer.*;


/**
 *  \class ILayer
 * 
 *  \brief Base class for all layer classes in a network definition.
 *  */
@Namespace("nvinfer1") @Properties(inherit = org.bytedeco.tensorrt.presets.nvinfer.class)
public class ILayer extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public ILayer(Pointer p) { super(p); }

    /**
     *  \brief Return the type of a layer.
     * 
     *  @see LayerType
     *  */
    
    
    //!
    //!
    //!
    //!
    public native LayerType getType();

    /**
     *  \brief Set the name of a layer.
     * 
     *  This method copies the name string.
     * 
     *  @see getName()
     *  */
    
    
    //!
    //!
    //!
    public native void setName(String name);
    public native void setName(@Cast("const char*") BytePointer name);

    /**
     *  \brief Return the name of a layer.
     * 
     <p>
     *  @see setName()
     *  */
    
    
    //!
    //!
    public native String getName();

    /**
     *  \brief Get the number of inputs of a layer.
     *  */
    
    
    //!
    //!
    //!
    //!
    public native int getNbInputs();

    /**
     *  \brief Get the layer input corresponding to the given index.
     * 
     *  @param index The index of the input tensor.
     * 
     *  @return The input tensor, or nullptr if the index is out of range.
     *  */
    
    
    //!
    //!
    public native ITensor getInput(int index);

    /**
     *  \brief Get the number of outputs of a layer.
     *  */
    
    
    //!
    //!
    //!
    public native int getNbOutputs();

    /**
     *  \brief Get the layer output corresponding to the given index.
     * 
     *  @return The indexed output tensor, or nullptr if the index is out of range.
     *  */
    
    
    //!
    //!
    //!
    //!
    public native ITensor getOutput(int index);

    /**
     *  \brief replace an input of this layer with a specific tensor
     * 
     *  Note that this method cannot change the number of inputs to a layer.  The index argument must be less
     *  than the value of getNbInputs()
     * 
     *  @param index the index of the input to modify.
     *  @param tensor the new input tensor
     *  */
    
    
    
    //!
    //!
    //!
    //!
    public native void setInput(int index, @ByRef ITensor tensor);


    /**
     *  \brief Set the computational precision of this layer
     * 
     *  setting the precision forces TensorRT to choose implementations which run at this precision. If precision is not set,
     *  TensorRT will select the computational precision based on performance considerations and the flags specified to the builder.
     * 
     *  @param precision the computational precision.
     * 
     *  @see getPrecision() precisionIsSet() resetPrecision() */

    
    
    //!
    //!
    //!
    public native void setPrecision(DataType dataType);
    public native void setPrecision(@Cast("nvinfer1::DataType") int dataType);

    /**
     *  \brief get the computational precision of this layer
     * 
     *  @return the computational precision
     * 
     *  @see setPrecision() precisionIsSet() resetPrecision() */

    
    
    //!
    //!
    //!
    public native DataType getPrecision();

    /**
     *  \brief whether the computational precision has been set for this layer
     * 
     *  @return whether the computational precision has been explicitly set
     * 
     *  @see setPrecision() getPrecision() resetPrecision() */

    
    
    //!
    //!
    public native @Cast("bool") boolean precisionIsSet();

    /**
     *  \brief reset the computational precision for this layer
     * 
     *  @see setPrecision() getPrecision() precisionIsSet() */

    
    
    //!
    //!
    //!
    //!
    public native void resetPrecision();

    /**
     *  \brief Set the output type of this layer
     * 
     *  setting the output type constrains TensorRT to choose implementations which generate output data with the given type.
     *  If it is not set, TensorRT will select the implementation based on performance considerations and the flags specified to the builder.
     * 
     *  @param index the index of the output to set
     *  @param dataType the type of the output
     * 
     *  @see getOutputType() outputTypeIsSet() resetOutputType() */

    
    
    //!
    //!
    //!
    public native void setOutputType(int index, DataType dataType);
    public native void setOutputType(int index, @Cast("nvinfer1::DataType") int dataType);

    /**
     *  \brief get the output type of this layer
     * 
     *  @param index the index of the output
     *  @return the output precision. If no precision has been set, DataType::kFLOAT will be returned
     * 
     *  @see getOutputType() outputTypeIsSet() resetOutputType() */

    
    
    //!
    //!
    //!
    public native DataType getOutputType(int index);

    /**
     *  \brief whether the output type has been set for this layer
     * 
     *  @param index the index of the output
     *  @return whether the output type has been explicitly set
     * 
     *  @see setOutputType() getOutputType() resetOutputType() */

    
    
    //!
    //!
    //!
    public native @Cast("bool") boolean outputTypeIsSet(int index);

    /**
     *  \brief reset the output type for this layer
     * 
     *  @param index the index of the output
     * 
     *  @see setOutputType() getOutputType() outputTypeIsSet() */

    public native void resetOutputType(int index);
}
