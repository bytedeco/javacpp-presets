// Targeted by JavaCPP version 1.5-SNAPSHOT: DO NOT EDIT THIS FILE

package org.bytedeco.tensorrt.nvinfer;

import java.nio.*;
import org.bytedeco.javacpp.*;
import org.bytedeco.javacpp.annotation.*;

import org.bytedeco.cuda.cudart.*;
import static org.bytedeco.cuda.global.cudart.*;

import static org.bytedeco.tensorrt.global.nvinfer.*;


/**
 *  \class INetworkDefinition
 * 
 *  \brief A network definition for input to the builder.
 *  */
@Namespace("nvinfer1") @Properties(inherit = org.bytedeco.tensorrt.presets.nvinfer.class)
public class INetworkDefinition extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public INetworkDefinition(Pointer p) { super(p); }

    /**
     *  \brief Add an input tensor to the network.
     * 
     *  The name of the input tensor is used to find the index into the buffer array for an engine built from the network.
     * 
     *  @param name The name of the tensor.
     *  @param type The type of the data held in the tensor.
     *  @param dimensions The dimensions of the tensor.
     * 
     *  Only DataType::kFLOAT, DataType::kHALF and DataType::kINT32 are valid input tensor types.
     *  The volume of the dimensions, including the maximum batch size, must be less than 2^30 elements.
     * 
     *  @see ITensor
     * 
     *  @return The new tensor or nullptr if there is an error.
     *  */
    
    
    //!
    //!
    //!
    public native ITensor addInput(String name, DataType type, @ByVal Dims dimensions);
    public native ITensor addInput(@Cast("const char*") BytePointer name, @Cast("nvinfer1::DataType") int type, @ByVal Dims dimensions);

    /**
     *  \brief Mark a tensor as a network output.
     * 
     *  @param tensor The tensor to mark as an output tensor.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native void markOutput(@ByRef ITensor tensor);

    /**
     *  \brief Add a convolution layer to the network.
     * 
     *  @param input The input tensor to the convolution.
     *  @param nbOutputMaps The number of output feature maps for the convolution.
     *  @param kernelSize The HW-dimensions of the convolution kernel.
     *  @param kernelWeights The kernel weights for the convolution.
     *  @param biasWeights The optional bias weights for the convolution.
     * 
     *  @see IConvolutionLayer
     * 
     *  @return The new convolution layer, or null if it could not be created.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native IConvolutionLayer addConvolution(@ByRef ITensor input, int nbOutputMaps, @ByVal DimsHW kernelSize, @ByVal Weights kernelWeights, @ByVal Weights biasWeights);

    /**
     *  \brief Add a fully connected layer to the network.
     * 
     *  @param input The input tensor to the layer.
     *  @param nbOutputs The number of outputs of the layer.
     *  @param kernelWeights The kernel weights for the convolution.
     *  @param biasWeights The optional bias weights for the convolution.
     * 
     *  @see IFullyConnectedLayer
     * 
     *  @return The new fully connected layer, or null if it could not be created.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native IFullyConnectedLayer addFullyConnected(@ByRef ITensor input, int nbOutputs, @ByVal Weights kernelWeights, @ByVal Weights biasWeights);

    /**
     *  \brief Add an activation layer to the network.
     * 
     *  @param input The input tensor to the layer.
     *  @param type The type of activation function to apply.
     * 
     *  @see IActivationLayer ActivationType
     * 
     *  @return The new activation layer, or null if it could not be created.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native IActivationLayer addActivation(@ByRef ITensor input, ActivationType type);
    public native IActivationLayer addActivation(@ByRef ITensor input, @Cast("nvinfer1::ActivationType") int type);

    /**
     *  \brief Add a pooling layer to the network.
     * 
     *  @param input The input tensor to the layer.
     *  @param type The type of pooling to apply.
     *  @param windowSize The size of the pooling window.
     * 
     *  @see IPoolingLayer PoolingType
     * 
     *  @return The new pooling layer, or null if it could not be created.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native IPoolingLayer addPooling(@ByRef ITensor input, PoolingType type, @ByVal DimsHW windowSize);
    public native IPoolingLayer addPooling(@ByRef ITensor input, @Cast("nvinfer1::PoolingType") int type, @ByVal DimsHW windowSize);

    /**
     *  \brief Add a LRN layer to the network.
     * 
     *  @param input The input tensor to the layer.
     *  @param window The size of the window.
     *  @param alpha The alpha value for the LRN computation.
     *  @param beta The beta value for the LRN computation.
     *  @param k The k value for the LRN computation.
     * 
     *  @see ILRNLayer
     * 
     *  @return The new LRN layer, or null if it could not be created.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    public native ILRNLayer addLRN(@ByRef ITensor input, int window, float alpha, float beta, float k);

    /**
     *  \brief Add a Scale layer to the network.
     * 
     *  @param input The input tensor to The layer. This tensor is required to have a minimum of 3 dimensions.
     *  @param mode The scaling mode.
     *  @param shift The shift value.
     *  @param scale The scale value.
     *  @param power The power value.
     * 
     *  If the weights are available, then the size of weights are dependent on the on the ScaleMode.
     *  For ::kUNIFORM, the number of weights is equal to 1.
     *  For ::kCHANNEL, the number of weights is equal to the channel dimension.
     *  For ::kELEMENTWISE, the number of weights is equal to the volume of the input.
     * 
     *  @see IScaleLayer
     * 
     *  @return The new Scale layer, or null if it could not be created.
     *  */
    
    
    //!
    //!
    //!
    //!
    public native IScaleLayer addScale(@ByRef ITensor input, ScaleMode mode, @ByVal Weights shift, @ByVal Weights scale, @ByVal Weights power);
    public native IScaleLayer addScale(@ByRef ITensor input, @Cast("nvinfer1::ScaleMode") int mode, @ByVal Weights shift, @ByVal Weights scale, @ByVal Weights power);

    /**
     *  \brief Add a SoftMax layer to the network.
     * 
     *  @see ISoftMaxLayer
     * 
     *  @return The new SoftMax layer, or null if it could not be created.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    public native ISoftMaxLayer addSoftMax(@ByRef ITensor input);

    /**
     *  \brief Add a concatenation layer to the network.
     * 
     *  @param inputs The input tensors to the layer.
     *  @param nbInputs The number of input tensors.
     * 
     *  @see IConcatenationLayer
     * 
     *  @return The new concatenation layer, or null if it could not be created.
     * 
     *  \warning All tensors must have the same dimensions for all dimensions except for channel.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native IConcatenationLayer addConcatenation(@Cast("nvinfer1::ITensor*const*") PointerPointer inputs, int nbInputs);
    public native IConcatenationLayer addConcatenation(@ByPtrPtr ITensor inputs, int nbInputs);

    /**
     *  \brief Add a deconvolution layer to the network.
     * 
     *  @param input The input tensor to the layer.
     *  @param nbOutputMaps The number of output feature maps.
     *  @param kernelSize The HW-dimensions of the convolution kernel.
     *  @param kernelWeights The kernel weights for the convolution.
     *  @param biasWeights The optional bias weights for the convolution.
     * 
     *  @see IDeconvolutionLayer
     * 
     *  @return The new deconvolution layer, or null if it could not be created.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    public native IDeconvolutionLayer addDeconvolution(@ByRef ITensor input, int nbOutputMaps, @ByVal DimsHW kernelSize, @ByVal Weights kernelWeights, @ByVal Weights biasWeights);

    /**
     *  \brief Add an elementwise layer to the network.
     * 
     *  @param input1 The first input tensor to the layer.
     *  @param input2 The second input tensor to the layer.
     *  @param op The binary operation that the layer applies.
     * 
     *  The input tensors must have the same number of dimensions.
     *  For each dimension, their lengths must match, or one of them must be one.
     *  In the latter case, the tensor is broadcast along that axis.
     * 
     *  The output tensor has the same number of dimensions as the inputs.
     *  For each dimension, its length is the maximum of the lengths of the
     *  corresponding input dimension.
     * 
     *  @see IElementWiseLayer
     * 
     *  @return The new elementwise layer, or null if it could not be created.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    public native IElementWiseLayer addElementWise(@ByRef ITensor input1, @ByRef ITensor input2, ElementWiseOperation op);
    public native IElementWiseLayer addElementWise(@ByRef ITensor input1, @ByRef ITensor input2, @Cast("nvinfer1::ElementWiseOperation") int op);

    /**
     *  \brief Add an \p layerCount deep RNN layer to the network with a
     *  sequence length of \p maxSeqLen and \p hiddenSize internal state per
     *  layer.
     * 
     *  @param inputs The input tensor to the layer.
     *  @param layerCount The number of layers in the RNN.
     *  @param hiddenSize The size of the internal hidden state for each layer.
     *  @param maxSeqLen The maximum length of the time sequence.
     *  @param op The type of RNN to execute.
     *  @param mode The input mode for the RNN.
     *  @param dir The direction to run the RNN.
     *  @param weights The weights for the weight matrix parameters of the RNN.
     *  @param bias The weights for the bias vectors parameters of the RNN.
     * 
     *  The input tensors must be of the type DataType::kFLOAT or DataType::kHALF.
     * 
     *  See IRNNLayer::setWeights() and IRNNLayer::setBias() for details on the required input
     *  format for \p weights and \p bias.
     * 
     *  The layout for the \p input tensor should be {@code {1, S_max, N, E}}, where:
     *    - {@code S_max} is the maximum allowed sequence length (number of RNN iterations)
     *    - {@code N} is the batch size
     *    - {@code E} specifies the embedding length (unless ::kSKIP is set, in which case it should match
     *      getHiddenSize()).
     * 
     *  The first output tensor is the output of the final RNN layer across all timesteps, with dimensions
     *  {@code {S_max, N, H}}:
     * 
     *    - {@code S_max} is the maximum allowed sequence length (number of RNN iterations)
     *    - {@code N} is the batch size
     *    - {@code H} is an output hidden state (equal to getHiddenSize() or 2x getHiddenSize())
     * 
     *  The second tensor is the final hidden state of the RNN across all layers, and if the RNN
     *  is an LSTM (i.e. getOperation() is ::kLSTM), then the third tensor is the final cell
     *  state of the RNN across all layers.  Both the second and third output tensors have dimensions
     *  {@code {L, N, H}}:
     * 
     *   - {@code L} is equal to getLayerCount() if getDirection is ::kUNIDIRECTION,
     *      and 2*getLayerCount() if getDirection is ::kBIDIRECTION.  In the bi-directional
     *      case, layer {@code l}'s final forward hidden state is stored in {@code L = 2*l}, and
     *      final backward hidden state is stored in {@code L = 2*l + 1}.
     *   - {@code N} is the batch size
     *   - {@code H} is getHiddenSize().
     * 
     *  Note that in bidirectional RNNs, the full "hidden state" for a layer {@code l}
     *  is the concatenation of its forward hidden state and its backward hidden
     *  state, and its size is 2*H.
     * 
     *  @deprecated IRNNLayer is superseded by IRNNv2Layer. Use addRNNv2() instead.
     * 
     *  @return The new RNN layer, or null if it could not be created.
     *  @see IRNNLayer
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native IRNNLayer addRNN(@ByRef ITensor inputs, int layerCount, @Cast("std::size_t") long hiddenSize, int maxSeqLen, RNNOperation op, RNNInputMode mode, RNNDirection dir, @ByVal Weights weights, @ByVal Weights bias);
    public native IRNNLayer addRNN(@ByRef ITensor inputs, int layerCount, @Cast("std::size_t") long hiddenSize, int maxSeqLen, @Cast("nvinfer1::RNNOperation") int op, @Cast("nvinfer1::RNNInputMode") int mode, @Cast("nvinfer1::RNNDirection") int dir, @ByVal Weights weights, @ByVal Weights bias);

    /**
     *  \brief Add a plugin layer to the network.
     * 
     *  @param inputs The input tensors to the layer.
     *  @param nbInputs The number of input tensors.
     *  @param plugin The layer plugin.
     * 
     *  @see IPluginLayer
     * 
     *  @return the new plugin layer, or null if it could not be created.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native IPluginLayer addPlugin(@Cast("nvinfer1::ITensor*const*") PointerPointer inputs, int nbInputs, @ByRef IPlugin plugin);
    public native IPluginLayer addPlugin(@ByPtrPtr ITensor inputs, int nbInputs, @ByRef IPlugin plugin);

    /**
     *  \brief Add a unary layer to the network.
     * 
     *  @param input The input tensor to the layer.
     *  @param operation The operation to apply.
     * 
     *  @see IUnaryLayer
     * 
     *  @return The new unary layer, or null if it could not be created
     *  */
    
    //!
    //!
    //!
    //!
    public native IUnaryLayer addUnary(@ByRef ITensor input, UnaryOperation operation);
    public native IUnaryLayer addUnary(@ByRef ITensor input, @Cast("nvinfer1::UnaryOperation") int operation);

    /** \brief Add a padding layer to the network.
     * 
     *  @param input The input tensor to the layer.
     *  @param prePadding The padding to apply to the start of the tensor.
     *  @param postPadding The padding to apply to the end of the tensor.
     * 
     *  @see IPaddingLayer
     * 
     *  @return the new padding layer, or null if it could not be created.
     *  */
    
    
    //!
    //!
    //!
    //!
    public native IPaddingLayer addPadding(@ByRef ITensor input, @ByVal DimsHW prePadding, @ByVal DimsHW postPadding);

    /**
     *  \brief Add a shuffle layer to the network.
     * 
     *  @param input The input tensor to the layer.
     * 
     *  @return The new shuffle layer, or null if it could not be created.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native IShuffleLayer addShuffle(@ByRef ITensor input);

    /**
     *  \brief Set the pooling output dimensions formula.
     * 
     *  @param formula The formula from computing the pooling output dimensions. If null is passed, the default formula is used.
     * 
     *  The default formula in each dimension is (inputDim + padding * 2 - kernelSize) / stride + 1.
     * 
     *  @see IOutputDimensionsFormula getPoolingOutputDimensionsFormula()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native void setPoolingOutputDimensionsFormula(IOutputDimensionsFormula formula);

    /**
     *  \brief Get the pooling output dimensions formula.
     * 
     *  @return The formula from computing the pooling output dimensions.
     * 
     *  @see IOutputDimensionsFormula setPoolingOutputDimensionsFormula()
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    public native @ByRef IOutputDimensionsFormula getPoolingOutputDimensionsFormula();

    /**
     *  \brief Set the convolution output dimensions formula.
     * 
     *  @deprecated This method does not currently work reliably and will be removed in a future release.
     * 
     *  @param formula The formula from computing the convolution output dimensions. If null is passed, the default formula is used.
     * 
     *  The default formula in each dimension is (inputDim + padding * 2 - kernelSize) / stride + 1.
     * 
     *  @see IOutputDimensionsFormula getConvolutionOutputDimensionsFormula()
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native void setConvolutionOutputDimensionsFormula(IOutputDimensionsFormula formula);

    /**
     *  \brief Get the convolution output dimensions formula.
     * 
     *  @deprecated This method does not currently work reliably and will be removed in a future release.
     * 
     *  @return The formula from computing the convolution output dimensions.
     * 
     *  @see IOutputDimensionsFormula setConvolutionOutputDimensionsFormula()
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    public native @ByRef IOutputDimensionsFormula getConvolutionOutputDimensionsFormula();

    /**
     *  \brief Set the deconvolution output dimensions formula.
     * 
     *  @deprecated This method does not currently work reliably and will be removed in a future release.
     * 
     *  @param formula The formula from computing the deconvolution output dimensions. If null is passed, the default formula is used.
     * 
     *  The default formula in each dimension is (inputDim - 1) * stride + kernelSize - 2 * padding.
     * 
     *  @see IOutputDimensionsFormula getDevonvolutionOutputDimensionsFormula()
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native void setDeconvolutionOutputDimensionsFormula(IOutputDimensionsFormula formula);

    /**
     *  \brief Get the deconvolution output dimensions formula.
     * 
     *  @return The formula from computing the deconvolution output dimensions.
     * 
     *  @deprecated This method does not currently work reliably and will be removed in a future release.
     * 
     *  @see IOutputDimensionsFormula setDeconvolutionOutputDimensionsFormula()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native @ByRef IOutputDimensionsFormula getDeconvolutionOutputDimensionsFormula();

    /**
     *  \brief Get the number of layers in the network.
     * 
     *  @return The number of layers in the network.
     * 
     *  @see getLayer()
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native int getNbLayers();

    /**
     *  \brief Get the layer specified by the given index.
     * 
     *  @param index The index of the layer.
     * 
     *  @return The layer, or null if the index is out of range.
     * 
     *  @see getNbLayers()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native ILayer getLayer(int index);

    /**
     *  \brief Get the number of inputs in the network.
     * 
     *  @return The number of inputs in the network.
     * 
     *  @see getInput()
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native int getNbInputs();

    /**
     *  \brief Get the input tensor specified by the given index.
     * 
     *  @param index The index of the input tensor.
     * 
     *  @return The input tensor, or null if the index is out of range.
     * 
     *  @see getNbInputs()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native ITensor getInput(int index); // adding inputs invalidates indexing here

    /**
     *  \brief Get the number of outputs in the network.
     * 
     *  @return The number of outputs in the network.
     * 
     *  @see getOutput()
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native int getNbOutputs();

    /**
     *  \brief Get the output tensor specified by the given index.
     * 
     *  @param index The index of the output tensor.
     * 
     *  @return The output tensor, or null if the index is out of range.
     * 
     *  @see getNbOutputs()
     *  */
    
    
    //!
    //!
    public native ITensor getOutput(int index); // adding outputs invalidates indexing here

    /**
     *  \brief Destroy this INetworkDefinition object.
     *  */
    public native void destroy();
    /**
     *  \brief Add a reduce layer to the network.
     * 
     *  @param input The input tensor to the layer.
     *  @param operation The reduction operation to perform.
     *  @param reduceAxes The reduction dimensions.
     *         Bit 0 of the uint32_t type corresponds to the non-batch dimension 0 boolean and so on.
     *         If a bit is set, then the corresponding dimension will be reduced.
     *         Let's say we have an NCHW tensor as input (three non-batch dimensions).
     *         Bit 0 corresponds to the C dimension boolean.
     *         Bit 1 corresponds to the H dimension boolean.
     *         Bit 2 corresponds to the W dimension boolean.
     *         Note that reduction is not permitted over the batch size dimension.
     *  @param keepDimensions The boolean that specifies whether or not to keep the reduced dimensions in the output of the layer.
     * 
     *  @see IReduceLayer
     * 
     *  @return The new reduce layer, or null if it could not be created.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    public native IReduceLayer addReduce(@ByRef ITensor input, ReduceOperation operation, @Cast("uint32_t") int reduceAxes, @Cast("bool") boolean keepDimensions);
    public native IReduceLayer addReduce(@ByRef ITensor input, @Cast("nvinfer1::ReduceOperation") int operation, @Cast("uint32_t") int reduceAxes, @Cast("bool") boolean keepDimensions);

    /**
     *  \brief Add a TopK layer to the network.
     * 
     *  The TopK layer has two outputs of the same dimensions. The first contains data values,
     *  the second contains index positions for the values. Output values are sorted, largest first
     *  for operation kMAX and smallest first for operation kMIN.
     * 
     *  Currently only values of K up to 1024 are supported.
     * 
     *  @param input The input tensor to the layer.
     * 
     *  @param op Operation to perform.
     * 
     *  @param k Number of elements to keep.
     * 
     *  @param reduceAxes The reduction dimensions.
     *         Bit 0 of the uint32_t type corresponds to the non-batch dimension 0 boolean and so on.
     *         If a bit is set, then the corresponding dimension will be reduced.
     *         Let's say we have an NCHW tensor as input (three non-batch dimensions).
     *         Bit 0 corresponds to the C dimension boolean.
     *         Bit 1 corresponds to the H dimension boolean.
     *         Bit 2 corresponds to the W dimension boolean.
     *         Note that TopK reduction is currently only permitted over one dimension.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native ITopKLayer addTopK(@ByRef ITensor input, TopKOperation op, int k, @Cast("uint32_t") int reduceAxes);
    public native ITopKLayer addTopK(@ByRef ITensor input, @Cast("nvinfer1::TopKOperation") int op, int k, @Cast("uint32_t") int reduceAxes);

    /**
     *  \brief Add a gather layer to the network.
     * 
     *  @param data The tensor to gather values from.
     *  @param indices The tensor to get indices from to populate the output tensor.
     *  @param axis The non-batch dimension axis in the data tensor to gather on.
     * 
     *  @see IGatherLayer
     * 
     *  @return The new gather layer, or null if it could not be created.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native IGatherLayer addGather(@ByRef ITensor data, @ByRef ITensor indices, int axis);

    /**
     *  \brief Add a RaggedSoftMax layer to the network.
     * 
     *  @param input The ZxS input tensor.
     *  @param bounds The Zx1 bounds tensor.
     * 
     *  @see IRaggedSoftMaxLayer
     * 
     *  @return The new RaggedSoftMax layer, or null if it could not be created.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native IRaggedSoftMaxLayer addRaggedSoftMax(@ByRef ITensor input, @ByRef ITensor bounds);

    /**
     *  \brief Add a MatrixMultiply layer to the network.
     * 
     *  @param input0 The first input tensor (commonly A).
     *  @param transpose0 If true, op(input0)=transpose(input0), else op(input0)=input0.
     *  @param input1 The second input tensor (commonly B).
     *  @param transpose1 If true, op(input1)=transpose(input1), else op(input1)=input1.
     * 
     *  @see IMatrixMultiplyLayer
     * 
     *  @return The new matrix multiply layer, or null if it could not be created.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native IMatrixMultiplyLayer addMatrixMultiply(@ByRef ITensor input0, @Cast("bool") boolean transpose0, @ByRef ITensor input1, @Cast("bool") boolean transpose1);

    /**
     *  \brief Add a constant layer to the network.
     * 
     *  @param dimensions The dimensions of the constant.
     *  @param weights The constant value, represented as weights.
     * 
     *  @see IConstantLayer
     * 
     *  @return The new constant layer, or null if it could not be created.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    public native IConstantLayer addConstant(@ByVal Dims dimensions, @ByVal Weights weights);

    /**
     *  \brief Add an \p layerCount deep RNN layer to the network with \p hiddenSize internal states that can
     *  take a batch with fixed or variable sequence lengths.
     * 
     *  @param input The input tensor to the layer (see below).
     *  @param layerCount The number of layers in the RNN.
     *  @param hiddenSize Size of the internal hidden state for each layer.
     *  @param maxSeqLen Maximum sequence length for the input.
     *  @param op The type of RNN to execute.
     * 
     *  By default, the layer is configured with RNNDirection::kUNIDIRECTION and RNNInputMode::kLINEAR.
     *  To change these settings, use IRNNv2Layer::setDirection() and IRNNv2Layer::setInputMode().
     * 
     *  %Weights and biases for the added layer should be set using
     *  IRNNv2Layer::setWeightsForGate() and IRNNv2Layer::setBiasForGate() prior
     *  to building an engine using this network.
     * 
     *  The input tensors must be of the type DataType::kFLOAT or DataType::kHALF.
     *  The layout of the weights is row major and must be the same datatype as the input tensor.
     *  \p weights contain 8 matrices and \p bias contains 8 vectors.
     * 
     *  See IRNNv2Layer::setWeightsForGate() and IRNNv2Layer::setBiasForGate() for details on the required input
     *  format for \p weights and \p bias.
     * 
     *  The \p input ITensor should contain zero or more index dimensions {@code {N1, ..., Np}}, followed by
     *  two dimensions, defined as follows:
     *    - {@code S_max} is the maximum allowed sequence length (number of RNN iterations)
     *    - {@code E} specifies the embedding length (unless ::kSKIP is set, in which case it should match
     *      getHiddenSize()).
     * 
     *  By default, all sequences in the input are assumed to be size \p maxSeqLen.  To provide explicit sequence
     *  lengths for each input sequence in the batch, use IRNNv2Layer::setSequenceLengths().
     * 
     *  The RNN layer outputs up to three tensors.
     * 
     *  The first output tensor is the output of the final RNN layer across all timesteps, with dimensions
     *  {@code {N1, ..., Np, S_max, H}}:
     * 
     *    - {@code N1..Np} are the index dimensions specified by the input tensor
     *    - {@code S_max} is the maximum allowed sequence length (number of RNN iterations)
     *    - {@code H} is an output hidden state (equal to getHiddenSize() or 2x getHiddenSize())
     * 
     *  The second tensor is the final hidden state of the RNN across all layers, and if the RNN
     *  is an LSTM (i.e. getOperation() is ::kLSTM), then the third tensor is the final cell state
     *  of the RNN across all layers.  Both the second and third output tensors have dimensions
     *  {@code {N1, ..., Np, L, H}}:
     * 
     *   - {@code N1..Np} are the index dimensions specified by the input tensor
     *   - {@code L} is the number of layers in the RNN, equal to getLayerCount()
     *   - {@code H} is the hidden state for each layer, equal to getHiddenSize() if getDirection is ::kUNIDIRECTION, and 2x getHiddenSize() otherwise.
     * 
     *  @return The new RNN layer, or null if it could not be created.
     *  @see IRNNv2Layer
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native IRNNv2Layer addRNNv2(@ByRef ITensor input, int layerCount, int hiddenSize, int maxSeqLen, RNNOperation op);
    public native IRNNv2Layer addRNNv2(@ByRef ITensor input, int layerCount, int hiddenSize, int maxSeqLen, @Cast("nvinfer1::RNNOperation") int op);

    /**
     *  \brief Add a plugin layer to the network using an IPluginExt interface.
     * 
     *  @param inputs The input tensors to the layer.
     *  @param nbInputs The number of input tensors.
     *  @param plugin The layer plugin.
     * 
     *  @return The new plugin layer, or null if it could not be created.
     * 
     *  @see IPluginLayer
     *  */
    
    
    //!
    //!
    //!
    //!
    public native IPluginLayer addPluginExt(@Cast("nvinfer1::ITensor*const*") PointerPointer inputs, int nbInputs, @ByRef IPluginExt plugin);
    public native IPluginLayer addPluginExt(@ByPtrPtr ITensor inputs, int nbInputs, @ByRef IPluginExt plugin);

    /**
     *  \brief Add an identity layer.
     * 
     *  @param input The input tensor to the layer.
     * 
     *  @return The new plugin layer, or null if it could not be created.
     *  */
    
    
    //!
    //!
    //!
    //!
    public native IIdentityLayer addIdentity(@ByRef ITensor input);

    /**
     *  \brief remove a tensor from the network definition.
     * 
     *  @param tensor the tensor to remove
     * 
     *  it is illegal to remove a tensor that is the input or output of a layer.
     *  if this method is called with such a tensor, a warning will be emitted on the log
     *  and the call will be ignored.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native void removeTensor(@ByRef ITensor tensor);

    /**
     *  \brief unmark a tensor as a network output.
     * 
     *  @param tensor The tensor to unmark as an output tensor.
     * 
     *  see markOutput()
     * 
     *  */
    public native void unmarkOutput(@ByRef ITensor tensor);
}
