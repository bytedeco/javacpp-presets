// Targeted by JavaCPP version 1.5.13-SNAPSHOT: DO NOT EDIT THIS FILE

package org.bytedeco.tensorrt.nvinfer;

import java.nio.*;
import org.bytedeco.javacpp.*;
import org.bytedeco.javacpp.annotation.*;

import static org.bytedeco.javacpp.presets.javacpp.*;
import org.bytedeco.cuda.cudart.*;
import static org.bytedeco.cuda.global.cudart.*;
import org.bytedeco.cuda.cublas.*;
import static org.bytedeco.cuda.global.cublas.*;
import org.bytedeco.cuda.cudnn.*;
import static org.bytedeco.cuda.global.cudnn.*;
import org.bytedeco.cuda.nvrtc.*;
import static org.bytedeco.cuda.global.nvrtc.*;

import static org.bytedeco.tensorrt.global.nvinfer.*;


/** DO NOT REFER TO namespace v_1_0 IN CODE. ALWAYS USE nvinfer1 INSTEAD.
 *  The name v_1_0 may change in future versions of TensorRT. */

@Namespace("nvinfer1::v_1_0") @Properties(inherit = org.bytedeco.tensorrt.presets.nvinfer.class)
public class IGpuAsyncAllocator extends IGpuAllocator {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IGpuAsyncAllocator(Pointer p) { super(p); }


    /**
     *  \brief A thread-safe callback implemented by the application to handle stream-ordered asynchronous
     *         acquisition of GPU memory.
     * 
     *  @param size The size of the memory block required (in bytes).
     *  @param alignment The required alignment of memory. Alignment will be zero
     *         or a power of 2 not exceeding the alignment guaranteed by cudaMalloc.
     *         Thus this allocator can be safely implemented with cudaMalloc/cudaFree.
     *         An alignment value of zero indicates any alignment is acceptable.
     *  @param flags Reserved for future use. In the current release, 0 will be passed.
     * 
     *  @param stream Specifies the cudastream for the asynchronous allocation. If nullptr or 0 is
     *         passed, the default stream will be used.
     * 
     *  @return If the allocation was successful, the start address of a device memory block of the requested size.
     *          If an allocation request of size 0 is made, nullptr must be returned.
     *          If an allocation request cannot be satisfied, nullptr must be returned.
     *          If a non-null address is returned, it is guaranteed to have the specified alignment.
     * 
     *  \note The implementation must guarantee thread safety for concurrent allocateAsync/deallocateAsync
     *  requests.
     * 
     *  \note The implementation is not required to be asynchronous. It is permitted to synchronize,
     *  albeit doing so will lose the performance advantage of asynchronous allocation.
     * 
     *  \u005Cusage
     *  - Allowed context for the API call
     *    - Thread-safe: Yes, this method is required to be thread-safe and may be called from multiple threads.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    public native @NoException(true) Pointer allocateAsync(@Cast("const uint64_t") long size, @Cast("const uint64_t") long alignment, @Cast("const nvinfer1::AllocatorFlags") int flags,
            CUstream_st arg3);

    /**
     *  \brief A thread-safe callback implemented by the application to handle stream-ordered asynchronous
     *  release of GPU memory.
     * 
     *  TensorRT may pass a nullptr to this function if it was previously returned by allocate().
     * 
     *  @param memory A memory address that was previously returned by an allocate() or reallocate() call of the same
     *  allocator object.
     * 
     *  @param stream Specifies the cudastream for the asynchronous deallocation. If nullptr or 0 is
     *         passed, the default stream will be used.
     * 
     *  @return True if the acquired memory is released successfully.
     * 
     *  \note The implementation must guarantee thread safety for concurrent allocateAsync/deallocateAsync
     *  requests.
     * 
     *  \note The implementation is not required to be asynchronous. It is permitted to synchronize,
     *  albeit doing so will lose the performance advantage of asynchronous deallocation.
     *  Either way, it is critical that it not actually free the memory until the current
     *  stream position is reached.
     * 
     *  \u005Cusage
     *  - Allowed context for the API call
     *    - Thread-safe: Yes, this method is required to be thread-safe and may be called from multiple threads. */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    public native @Cast("bool") @NoException(true) boolean deallocateAsync(Pointer memory, CUstream_st arg1);

    /**
     *  \brief A thread-safe callback implemented by the application to handle acquisition of GPU memory.
     * 
     *  @param size The size of the memory block required (in bytes).
     *  @param alignment The required alignment of memory. Alignment will be zero
     *         or a power of 2 not exceeding the alignment guaranteed by cudaMalloc.
     *         Thus this allocator can be safely implemented with cudaMalloc/cudaFree.
     *         An alignment value of zero indicates any alignment is acceptable.
     *  @param flags Reserved for future use. In the current release, 0 will be passed.
     * 
     *  @return If the allocation was successful, the start address of a device memory block of the requested size.
     *          If an allocation request of size 0 is made, nullptr must be returned.
     *          If an allocation request cannot be satisfied, nullptr must be returned.
     *          If a non-null address is returned, it is guaranteed to have the specified alignment.
     * 
     *  \note The implementation must guarantee thread safety for concurrent allocateAsync/deallocateAsync/reallocate
     *  requests.
     * 
     *  \u005Cusage
     *  - Allowed context for the API call
     *    - Thread-safe: Yes, this method is required to be thread-safe and may be called from multiple threads.
     *  @deprecated Deprecated in TensorRT 10.0. Superseded by allocateAsync
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    public native @Deprecated @Name("allocate") @NoException(true) Pointer _allocate(
            @Cast("const uint64_t") long size, @Cast("const uint64_t") long alignment, @Cast("const nvinfer1::AllocatorFlags") int flags);

    /**
     *  \brief A thread-safe callback implemented by the application to handle release of GPU memory.
     * 
     *  TensorRT may pass a nullptr to this function if it was previously returned by allocate().
     * 
     *  @param memory A memory address that was previously returned by an allocate() or reallocate() call of the same
     *  allocator object.
     * 
     *  @return True if the acquired memory is released successfully.
     * 
     *  \note The implementation must guarantee thread safety for concurrent allocate/reallocate/deallocate
     *  requests.
     * 
     *  \u005Cusage
     *  - Allowed context for the API call
     *    - Thread-safe: Yes, this method is required to be thread-safe and may be called from multiple threads.
     *  @deprecated Deprecated in TensorRT 10.0. Superseded by deallocateAsync
     *  */
    
    
    //!
    //!
    public native @Cast("bool") @Deprecated @Name("deallocate") @NoException(true) boolean _deallocate(Pointer memory);

    /**
     *  \brief Return version information associated with this interface. Applications must not override this method.
     *  */
    public native @ByVal @NoException(true) InterfaceInfo getInterfaceInfo();
}
