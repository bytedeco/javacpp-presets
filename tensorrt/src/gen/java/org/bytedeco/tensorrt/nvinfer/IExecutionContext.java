// Targeted by JavaCPP version 1.5.4-SNAPSHOT: DO NOT EDIT THIS FILE

package org.bytedeco.tensorrt.nvinfer;

import java.nio.*;
import org.bytedeco.javacpp.*;
import org.bytedeco.javacpp.annotation.*;

import static org.bytedeco.javacpp.presets.javacpp.*;
import org.bytedeco.cuda.cudart.*;
import static org.bytedeco.cuda.global.cudart.*;
import org.bytedeco.cuda.cublas.*;
import static org.bytedeco.cuda.global.cublas.*;
import org.bytedeco.cuda.cudnn.*;
import static org.bytedeco.cuda.global.cudnn.*;
import org.bytedeco.cuda.nvrtc.*;
import static org.bytedeco.cuda.global.nvrtc.*;

import static org.bytedeco.tensorrt.global.nvinfer.*;


/**
 *  \class IExecutionContext
 * 
 *  \brief Context for executing inference using an engine, with functionally unsafe features.
 * 
 *  Multiple execution contexts may exist for one ICudaEngine instance, allowing the same
 *  engine to be used for the execution of multiple batches simultaneously. If the engine supports
 *  dynamic shapes, each execution context in concurrent use must use a separate optimization profile.
 * 
 *  \warning Do not inherit from this class, as doing so will break forward-compatibility of the API and ABI. */
@Namespace("nvinfer1") @Properties(inherit = org.bytedeco.tensorrt.presets.nvinfer.class)
public class IExecutionContext extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IExecutionContext(Pointer p) { super(p); }

    /**
     *  \brief Synchronously execute inference on a batch.
     * 
     *  This method requires an array of input and output buffers. The mapping from tensor names to indices can be queried using ICudaEngine::getBindingIndex()
     *  @param batchSize The batch size. This is at most the value supplied when the engine was built.
     *  @param bindings An array of pointers to input and output buffers for the network.
     * 
     *  @return True if execution succeeded.
     * 
     *  @see ICudaEngine::getBindingIndex() ICudaEngine::getMaxBatchSize()
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native @Cast("bool") @NoException boolean execute(int batchSize, @Cast("void**") PointerPointer bindings);
    public native @Cast("bool") @NoException boolean execute(int batchSize, @Cast("void**") @ByPtrPtr Pointer bindings);

    /**
     *  \brief Asynchronously execute inference on a batch.
     * 
     *  This method requires an array of input and output buffers. The mapping from tensor names to indices can be queried using ICudaEngine::getBindingIndex()
     *  @param batchSize The batch size. This is at most the value supplied when the engine was built.
     *  @param bindings An array of pointers to input and output buffers for the network.
     *  @param stream A cuda stream on which the inference kernels will be enqueued
     *  @param inputConsumed An optional event which will be signaled when the input buffers can be refilled with new data
     * 
     *  @return True if the kernels were enqueued successfully.
     * 
     *  @see ICudaEngine::getBindingIndex() ICudaEngine::getMaxBatchSize()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native @Cast("bool") @NoException boolean enqueue(int batchSize, @Cast("void**") PointerPointer bindings, CUstream_st stream, @ByPtrPtr CUevent_st inputConsumed);
    public native @Cast("bool") @NoException boolean enqueue(int batchSize, @Cast("void**") @ByPtrPtr Pointer bindings, CUstream_st stream, @ByPtrPtr CUevent_st inputConsumed);

    /**
     *  \brief Set the debug sync flag.
     * 
     *  If this flag is set to true, the engine will log the successful execution for each kernel during execute(). It has no effect when using enqueue().
     * 
     *  @see getDebugSync()
     *  */
    
    
    //!
    //!
    //!
    public native @NoException void setDebugSync(@Cast("bool") boolean sync);

    /**
     *  \brief Get the debug sync flag.
     * 
     *  @see setDebugSync()
     *  */
    
    
    //!
    //!
    //!
    public native @Cast("bool") @NoException boolean getDebugSync();

    /**
     *  \brief Set the profiler.
     * 
     *  @see IProfiler getProfiler()
     *  */
    
    
    //!
    //!
    //!
    public native @NoException void setProfiler(IProfiler arg0);

    /**
     *  \brief Get the profiler.
     * 
     *  @see IProfiler setProfiler()
     *  */
    
    
    //!
    //!
    //!
    public native @NoException IProfiler getProfiler();

    /**
     *  \brief Get the associated engine.
     * 
     *  @see ICudaEngine
     *  */
    
    
    //!
    //!
    public native @Const @ByRef @NoException ICudaEngine getEngine();

    /**
     *  \brief Destroy this object.
     *  */
    public native @NoException void destroy();
    /**
     *  \brief Set the name of the execution context.
     * 
     *  This method copies the name string.
     * 
     *  @see getName()
     *  */
    
    
    //!
    //!
    //!
    public native @NoException void setName(String name);
    public native @NoException void setName(@Cast("const char*") BytePointer name);

    /**
     *  \brief Return the name of the execution context.
     * 
     *  @see setName()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native @NoException String getName();

    /**
     *  \brief Set the device memory for use by this execution context.
     * 
     *  The memory must be aligned with cuda memory alignment property (using cudaGetDeviceProperties()), and its size
     *  must be at least that returned by getDeviceMemorySize(). Setting memory to nullptr is acceptable if
     *  getDeviceMemorySize() returns 0. If using enqueue() to run the network, the memory is in use from the invocation
     *  of enqueue() until network execution is complete. If using execute(), it is in use until execute() returns.
     *  Releasing or otherwise using the memory for other purposes during this time will result in undefined behavior.
     * 
     *  @see ICudaEngine::getDeviceMemorySize() ICudaEngine::createExecutionContextWithoutDeviceMemory()
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    public native @NoException void setDeviceMemory(Pointer memory);

    /**
     *  \brief Return the strides of the buffer for the given binding.
     * 
     *  The strides are in units of elements, not components or bytes.
     *  For example, for TensorFormat::kHWC8, a stride of one spans 8 scalars.
     * 
     *  Note that strides can be different for different execution contexts
     *  with dynamic shapes.
     * 
     *  If the bindingIndex is invalid or there are dynamic dimensions that have not been
     *  set yet, returns Dims with Dims::nbDims = -1.
     * 
     *  @param bindingIndex The binding index.
     * 
     *  @see getBindingComponentsPerElement
     *  */
    public native @ByVal @NoException Dims getStrides(int bindingIndex);
    /**
     *  \brief Select an optimization profile for the current context.
     * 
     *  @param profileIndex Index of the profile. It must lie between 0 and
     *         getEngine().getNbOptimizationProfiles() - 1
     * 
     *  The selected profile will be used in subsequent calls to execute() or enqueue().
     * 
     *  If the associated CUDA engine has dynamic inputs, this method must be called at least once
     *  with a unique profileIndex before calling execute or enqueue (i.e. the profile index
     *  may not be in use by another execution context that has not been destroyed yet).
     *  For the first execution context that is created for an engine, setOptimizationProfile(0)
     *  is called implicitly.
     * 
     *  If the associated CUDA engine does not have inputs with dynamic shapes, this method need not be
     *  called, in which case the default profile index of 0 will be used (this is particularly
     *  the case for all safe engines).
     * 
     *  setOptimizationProfile() must be called before calling setBindingDimensions() and
     *  setInputShapeBinding() for all dynamic input tensors or input shape tensors, which in
     *  turn must be called before either execute() or enqueue().
     * 
     *  @return true if the call succeeded, else false (e.g. input out of range)
     * 
     *  @see ICudaEngine::getNbOptimizationProfiles() */
    
    
    //!
    //!
    //!
    public native @Cast("bool") @NoException boolean setOptimizationProfile(int profileIndex);

    /**
     *  \brief Get the index of the currently selected optimization profile.
     * 
     *  If the profile index has not been set yet (implicitly to 0 for the first execution context
     *  to be created, or explicitly for all subsequent contexts), an invalid value of -1 will be returned
     *  and all calls to enqueue() or execute() will fail until a valid profile index has been set.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    public native @NoException int getOptimizationProfile();

    /**
     *  \brief Set the dynamic dimensions of a binding
     * 
     *  Requires the engine to be built without an implicit batch dimension.
     *  The binding must be an input tensor, and all dimensions must be compatible with
     *  the network definition (i.e. only the wildcard dimension -1 can be replaced with a
     *  new dimension > 0). Furthermore, the dimensions must be in the valid range for the
     *  currently selected optimization profile, and the corresponding engine must not be
     *  safety-certified.
     * 
     *  This method will fail unless a valid optimization profile is defined for the current
     *  execution context (getOptimizationProfile() must not be -1).
     * 
     *  For all dynamic non-output bindings (which have at least one wildcard dimension of -1),
     *  this method needs to be called before either enqueue() or execute() may be called.
     *  This can be checked using the method allInputDimensionsSpecified().
     * 
     *  @return false if an error occurs (e.g. index out of range), else true
     * 
     *  @see ICudaEngine::getBindingIndex
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    public native @Cast("bool") @NoException boolean setBindingDimensions(int bindingIndex, @ByVal Dims dimensions);

    /**
     *  \brief Get the dynamic dimensions of a binding
     * 
     *  If the engine was built with an implicit batch dimension, same as ICudaEngine::getBindingDimensions.
     * 
     *  If setBindingDimensions() has been called on this binding (or if there are no
     *  dynamic dimensions), all dimensions will be positive. Otherwise, it is necessary to
     *  call setBindingDimensions() before enqueue() or execute() may be called.
     * 
     *  If the bindingIndex is out of range, an invalid Dims with nbDims == -1 is returned.
     *  The same invalid Dims will be returned if the engine was not built with an implicit
     *  batch dimension and if the execution context is not currently associated with a valid
     *  optimization profile (i.e. if getOptimizationProfile() returns -1).
     * 
     *  If ICudaEngine::bindingIsInput(bindingIndex) is false, then both
     *  allInputDimensionsSpecified() and allInputShapesSpecified() must be true
     *  before calling this method.
     * 
     *  @return Currently selected binding dimensions
     * 
     *  For backwards compatibility with earlier versions of TensorRT, a bindingIndex that does not belong
     *  to the current profile is corrected as described for ICudaEngine::getProfileDimensions.
     * 
     *  @see ICudaEngine::getProfileDimensions
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native @ByVal @NoException Dims getBindingDimensions(int bindingIndex);

    /**
     *  \brief Set values of input tensor required by shape calculations.
     * 
     *  @param bindingIndex index of an input tensor for which
     *         ICudaEngine::isShapeBinding(bindingIndex) and ICudaEngine::bindingIsInput(bindingIndex)
     *         are both true.
     * 
     *  @param data pointer to values of the input tensor.  The number of values should be
     *          the product of the dimensions returned by getBindingDimensions(bindingIndex).
     * 
     *  If ICudaEngine::isShapeBinding(bindingIndex) and ICudaEngine::bindingIsInput(bindingIndex)
     *  are both true, this method must be called before enqueue() or execute() may be called.
     *  This method will fail unless a valid optimization profile is defined for the current
     *  execution context (getOptimizationProfile() must not be -1).
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    public native @Cast("bool") @NoException boolean setInputShapeBinding(int bindingIndex, @Const IntPointer data);
    public native @Cast("bool") @NoException boolean setInputShapeBinding(int bindingIndex, @Const IntBuffer data);
    public native @Cast("bool") @NoException boolean setInputShapeBinding(int bindingIndex, @Const int[] data);

    /**
     *  \brief Get values of an input tensor required for shape calculations or an output tensor produced by shape calculations.
     * 
     *  @param bindingIndex index of an input or output tensor for which
     *         ICudaEngine::isShapeBinding(bindingIndex) is true.
     * 
     *  @param data pointer to where values will be written.  The number of values written is
     *         the product of the dimensions returned by getBindingDimensions(bindingIndex).
     * 
     *  If ICudaEngine::bindingIsInput(bindingIndex) is false, then both
     *  allInputDimensionsSpecified() and allInputShapesSpecified() must be true
     *  before calling this method. The method will also fail if no valid optimization profile
     *  has been set for the current execution context, i.e. if getOptimizationProfile() returns -1.
     * 
     *  @see isShapeBinding(bindingIndex)
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native @Cast("bool") @NoException boolean getShapeBinding(int bindingIndex, IntPointer data);
    public native @Cast("bool") @NoException boolean getShapeBinding(int bindingIndex, IntBuffer data);
    public native @Cast("bool") @NoException boolean getShapeBinding(int bindingIndex, int[] data);

    /**
     *  \brief Whether all dynamic dimensions of input tensors have been specified
     * 
     *  @return True if all dynamic dimensions of input tensors have been specified
     *          by calling setBindingDimensions().
     * 
     *  Trivially true if network has no dynamically shaped input tensors.
     * 
     *  @see setBindingDimensions(bindingIndex,dimensions)
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native @Cast("bool") @NoException boolean allInputDimensionsSpecified();

    /**
     *  \brief Whether all input shape bindings have been specified
     * 
     *  @return True if all input shape bindings have been specified by setInputShapeBinding().
     * 
     *  Trivially true if network has no input shape bindings.
     * 
     *  @see isShapeBinding(bindingIndex)
     *  */
    
    
    //!
    //!
    //!
    //!
    public native @Cast("bool") @NoException boolean allInputShapesSpecified();

    /**
     *  \brief Set the ErrorRecorder for this interface
     * 
     *  Assigns the ErrorRecorder to this interface. The ErrorRecorder will track all errors during execution.
     *  This function will call incRefCount of the registered ErrorRecorder at least once. Setting
     *  recorder to nullptr unregisters the recorder with the interface, resulting in a call to decRefCount if
     *  a recorder has been registered.
     * 
     *  @param recorder The error recorder to register with this interface. */
    //
    /** @see getErrorRecorder
    /** */
    
    
    //!
    //!
    //!
    //!
    //!
    public native @NoException void setErrorRecorder(IErrorRecorder recorder);

    /**
     *  \brief get the ErrorRecorder assigned to this interface.
     * 
     *  Retrieves the assigned error recorder object for the given class. A default error recorder does not exist,
     *  so a nullptr will be returned if setErrorRecorder has not been called.
     * 
     *  @return A pointer to the IErrorRecorder object that has been registered.
     * 
     *  @see setErrorRecorder
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native @NoException IErrorRecorder getErrorRecorder();

    /**
     *  \brief Synchronously execute inference a network.
     * 
     *  This method requires an array of input and output buffers. The mapping from tensor names to indices can be
     *  queried using ICudaEngine::getBindingIndex().
     *  This method only works for execution contexts built with full dimension networks.
     *  @param bindings An array of pointers to input and output buffers for the network.
     * 
     *  @return True if execution succeeded.
     * 
     *  @see ICudaEngine::getBindingIndex() ICudaEngine::getMaxBatchSize()
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    public native @Cast("bool") @NoException boolean executeV2(@Cast("void**") PointerPointer bindings);
    public native @Cast("bool") @NoException boolean executeV2(@Cast("void**") @ByPtrPtr Pointer bindings);

    /**
     *  \brief Asynchronously execute inference.
     * 
     *  This method requires an array of input and output buffers. The mapping from tensor names to indices can be
     *  queried using ICudaEngine::getBindingIndex().
     *  This method only works for execution contexts built with full dimension networks.
     *  @param bindings An array of pointers to input and output buffers for the network.
     *  @param stream A cuda stream on which the inference kernels will be enqueued
     *  @param inputConsumed An optional event which will be signaled when the input buffers can be refilled with new
     *  data
     * 
     *  @return True if the kernels were enqueued successfully.
     * 
     *  @see ICudaEngine::getBindingIndex() ICudaEngine::getMaxBatchSize()
     * 
     *  \note Calling enqueueV2() with a stream in CUDA graph capture mode has a known issue. If dynamic shapes are
     *        used, the first enqueueV2() call after a setInputShapeBinding() call will cause failure in stream capture
     *        due to resource allocation. Please call enqueueV2() once before capturing the graph.
     *  */
    public native @Cast("bool") @NoException boolean enqueueV2(@Cast("void**") PointerPointer bindings, CUstream_st stream, @ByPtrPtr CUevent_st inputConsumed);
    public native @Cast("bool") @NoException boolean enqueueV2(@Cast("void**") @ByPtrPtr Pointer bindings, CUstream_st stream, @ByPtrPtr CUevent_st inputConsumed);
}
