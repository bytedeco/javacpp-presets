// Targeted by JavaCPP version 1.5-SNAPSHOT: DO NOT EDIT THIS FILE

package org.bytedeco.tensorrt.nvinfer;

import java.nio.*;
import org.bytedeco.javacpp.*;
import org.bytedeco.javacpp.annotation.*;

import org.bytedeco.cuda.cudart.*;
import static org.bytedeco.cuda.global.cudart.*;

import static org.bytedeco.tensorrt.global.nvinfer.*;


/**
 *  \class IExecutionContext
 * 
 *  \brief Context for executing inference using an engine.
 * 
 *  Multiple execution contexts may exist for one ICudaEngine instance, allowing the same
 *  engine to be used for the execution of multiple batches simultaneously.
 *  */
@Namespace("nvinfer1") @Properties(inherit = org.bytedeco.tensorrt.presets.nvinfer.class)
public class IExecutionContext extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IExecutionContext(Pointer p) { super(p); }

    /**
     *  \brief Synchronously execute inference on a batch.
     * 
     *  This method requires a array of input and output buffers. The mapping from tensor names to indices can be queried using ICudaEngine::getBindingIndex()
     *  @param batchSize The batch size. This is at most the value supplied when the engine was built.
     *  @param bindings An array of pointers to input and output buffers for the network.
     * 
     *  @return True if execution succeeded.
     * 
     *  @see ICudaEngine::getBindingIndex() ICudaEngine::getMaxBatchSize()
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    public native @Cast("bool") boolean execute(int batchSize, @Cast("void**") PointerPointer bindings);
    public native @Cast("bool") boolean execute(int batchSize, @Cast("void**") @ByPtrPtr Pointer bindings);

    /**
     *  \brief Asynchronously execute inference on a batch.
     * 
     *  This method requires a array of input and output buffers. The mapping from tensor names to indices can be queried using ICudaEngine::getBindingIndex()
     *  @param batchSize The batch size. This is at most the value supplied when the engine was built.
     *  @param bindings An array of pointers to input and output buffers for the network.
     *  @param stream A cuda stream on which the inference kernels will be enqueued
     *  @param inputConsumed An optional event which will be signaled when the input buffers can be refilled with new data
     * 
     *  @return True if the kernels were enqueued successfully.
     * 
     *  @see ICudaEngine::getBindingIndex() ICudaEngine::getMaxBatchSize()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native @Cast("bool") boolean enqueue(int batchSize, @Cast("void**") PointerPointer bindings, CUstream_st stream, @ByPtrPtr CUevent_st inputConsumed);
    public native @Cast("bool") boolean enqueue(int batchSize, @Cast("void**") @ByPtrPtr Pointer bindings, CUstream_st stream, @ByPtrPtr CUevent_st inputConsumed);

    /**
     *  \brief Set the debug sync flag.
     * 
     *  If this flag is set to true, the engine will log the successful execution for each kernel during execute(). It has no effect when using enqueue().
     * 
     *  @see getDebugSync()
     *  */
    
    
    //!
    //!
    //!
    public native void setDebugSync(@Cast("bool") boolean sync);

    /**
     *  \brief Get the debug sync flag.
     * 
     *  @see setDebugSync()
     *  */
    
    
    //!
    //!
    //!
    public native @Cast("bool") boolean getDebugSync();

    /**
     *  \brief Set the profiler.
     * 
     *  @see IProfiler getProfiler()
     *  */
    
    
    //!
    //!
    //!
    public native void setProfiler(IProfiler arg0);

    /**
     *  \brief Get the profiler.
     * 
     *  @see IProfiler setProfiler()
     *  */
    
    
    //!
    //!
    //!
    public native IProfiler getProfiler();

    /**
     *  \brief Get the associated engine.
     * 
     *  @see ICudaEngine
     *  */
    
    
    //!
    //!
    public native @Const @ByRef ICudaEngine getEngine();

    /**
     *  \brief Destroy this object.
     *  */
    public native void destroy();
    /**
     *  \brief Set the name of the execution context.
     * 
     *  This method copies the name string.
     * 
     *  @see getName()
     *  */
    
    
    //!
    //!
    //!
    public native void setName(String name);
    public native void setName(@Cast("const char*") BytePointer name);

    /**
     *  \brief Return the name of the execution context.
     * 
     *  @see setName()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native String getName();

    /**
     *  \brief set the device memory for use by this execution context.
     * 
     *  The memory must be aligned with cuda memory alignment property (using cudaGetDeviceProperties()), and its size must be at least that
     *  returned by getDeviceMemorySize(). If using enqueue() to run the network, The memory is in
     *  use from the invocation of enqueue() until network execution is complete. If using execute(),
     *  it is in use until execute() returns. Releasing or otherwise using the memory for other
     *  purposes during this time will result in undefined behavior.
     * 
     *  @see ICudaEngine::getDeviceMemorySize() ICudaEngine::createExecutionContextWithoutDeviceMemory()
     *  */
    public native void setDeviceMemory(Pointer memory);
}
