// Targeted by JavaCPP version 1.5.13-SNAPSHOT: DO NOT EDIT THIS FILE

package org.bytedeco.tensorrt.nvinfer;

import java.nio.*;
import org.bytedeco.javacpp.*;
import org.bytedeco.javacpp.annotation.*;

import static org.bytedeco.javacpp.presets.javacpp.*;
import org.bytedeco.cuda.cudart.*;
import static org.bytedeco.cuda.global.cudart.*;
import org.bytedeco.cuda.cublas.*;
import static org.bytedeco.cuda.global.cublas.*;
import org.bytedeco.cuda.cudnn.*;
import static org.bytedeco.cuda.global.cudnn.*;
import org.bytedeco.cuda.nvrtc.*;
import static org.bytedeco.cuda.global.nvrtc.*;

import static org.bytedeco.tensorrt.global.nvinfer.*;


/**
 *  \class IDynamicQuantizeLayer
 * 
 *  \brief A network layer to perform dynamic quantization.
 * 
 *  This layer accepts a floating-point input tensor and computes the block scale factors needed to
 *  quantize the input's data. It outputs the quantized tensor as its first output and
 *  the scale factors as its second output.
 * 
 *  Use ILayer::setInput to add an input for the double-quantization scale factor.
 * 
 *  \note Only symmetric quantization is supported.
 *  \note The input tensor for this layer must not be a scalar.
 * 
 *  \warning Do not inherit from this class, as doing so will break forward-compatibility of the
 *  API and ABI.
 *  */
@Namespace("nvinfer1") @NoOffset @Properties(inherit = org.bytedeco.tensorrt.presets.nvinfer.class)
public class IDynamicQuantizeLayer extends ILayer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IDynamicQuantizeLayer(Pointer p) { super(p); }

    /**
     *  \brief Append or replace an input of this layer with a specific tensor
     * 
     *  @param index the index of the input to modify.
     *  @param tensor the new input tensor
     * 
     *  Input 0 is the input activation tensor.
     *  Input 1 is the double-quantization scale factor. This scale is used to quantize the
     *  dynamically computed high-precision scale factors that are used to quantize the
     *  activation data. Currently this input must be a positive scalar (a 0D tensor).
     *  */
    
    
    //!
    //!
    //!
    //!
    //!

    /**
     *  \brief Set DynamicQuantizeLayer's quantized output type.
     * 
     *  @param toType The data type of the quantized output tensor.
     * 
     *  Set the type of the dynamic quantization layer's quantized output.If the network is strongly typed, setToType
     *  must be used to set the output type, and use of setOutputType is an error. Otherwise, types passed to
     *  setOutputType and setToType must be the same.
     *  Valid values for \p toType are DataType::kFP4 (NVFP4 quantization) and DataType::kFP8 (MXFP8 quantization).
     * 
     *  @see NetworkDefinitionCreationFlag::kSTRONGLY_TYPED
     *  */
    
    
    //!
    //!
    //!
    //!
    public native @NoException(true) void setToType(DataType toType);
    public native @NoException(true) void setToType(@Cast("nvinfer1::DataType") int toType);

    /**
     *  \brief Return DynamicQuantizeLayer's quantized output type.
     * 
     *  @return toType parameter set during layer creation or by setToType().
     * 
     *  The return value is the type of the quantized output tensor.
     *  The default value is DataType::kFP4.
     *  */
    
    
    //!
    //!
    //!
    //!
    public native @NoException(true) DataType getToType();

    /**
     *  \brief Set the data type of the scale factors used to quantize the data.
     * 
     *  @param scaleType The scale factors data type.
     * 
     *  Set the scale-factors type.
     *  Valid values are DataType::kFP8 (NVFP4 quantization) and DataType::kE8M0 (MXFP8 quantization).
     *  */
    
    
    //!
    //!
    //!
    //!
    public native @NoException(true) void setScaleType(DataType scaleType);
    public native @NoException(true) void setScaleType(@Cast("nvinfer1::DataType") int scaleType);

    /**
     *  \brief Return the scale factors data type.
     * 
     *  @return scaleType parameter set during layer creation or by setScaleType().
     * 
     *  The return value is the type of the scale factors used to quantize the dynamic data.
     *  The default value is DataType::kFP8.
     *  */
    
    
    //!
    //!
    //!
    //!
    public native @NoException(true) DataType getScaleType();

    /**
     *  \brief Set the axis along which block quantization occurs.
     * 
     *  The axis must be the last dimension or second to last dimension.
     *  The input's shape along the axis must be constant.
     * 
     *  @see getAxis()
     *  */
    
    
    //!
    //!
    //!
    public native @NoException(true) void setAxis(int axis);

    /**
     *  \brief Get the axis along which blocking occurs.
     * 
     *  @see setAxis()
     *  */
    
    
    //!
    //!
    //!
    //!
    public native @NoException(true) int getAxis();

    /**
     *  \brief Set the size of the quantization block.
     * 
     *  Note: The block size must divide the input in the blocked axis without remainder.
     *  Valid values are 16 (NVFP4 quantization) and 32 (MXFP8 quantization).
     * 
     *  @see getBlockSize()
     *  */
    
    
    //!
    //!
    //!
    public native @NoException(true) void setBlockSize(int size);

    /**
     *  \brief Get the size of the quantization block.
     * 
     *  @see setBlockSize()
     *  */
    public native @NoException(true) int getBlockSize();
}
