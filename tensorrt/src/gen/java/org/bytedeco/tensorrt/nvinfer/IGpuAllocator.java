// Targeted by JavaCPP version 1.5.11-SNAPSHOT: DO NOT EDIT THIS FILE

package org.bytedeco.tensorrt.nvinfer;

import java.nio.*;
import org.bytedeco.javacpp.*;
import org.bytedeco.javacpp.annotation.*;

import static org.bytedeco.javacpp.presets.javacpp.*;
import org.bytedeco.cuda.cudart.*;
import static org.bytedeco.cuda.global.cudart.*;
import org.bytedeco.cuda.cublas.*;
import static org.bytedeco.cuda.global.cublas.*;
import org.bytedeco.cuda.cudnn.*;
import static org.bytedeco.cuda.global.cudnn.*;
import org.bytedeco.cuda.nvrtc.*;
import static org.bytedeco.cuda.global.nvrtc.*;

import static org.bytedeco.tensorrt.global.nvinfer.*;


/** DO NOT REFER TO namespace v_1_0 IN CODE. ALWAYS USE nvinfer1 INSTEAD.
 *  The name v_1_0 may change in future versions of TensoRT. */

@Namespace("nvinfer1::v_1_0") @Properties(inherit = org.bytedeco.tensorrt.presets.nvinfer.class)
public class IGpuAllocator extends IVersionedInterface {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public IGpuAllocator(Pointer p) { super(p); }

    /**
     *  \brief A thread-safe callback implemented by the application to handle acquisition of GPU memory.
     * 
     *  @param size The size of the memory block required (in bytes).
     *  @param alignment The required alignment of memory. Alignment will be zero
     *         or a power of 2 not exceeding the alignment guaranteed by cudaMalloc.
     *         Thus this allocator can be safely implemented with cudaMalloc/cudaFree.
     *         An alignment value of zero indicates any alignment is acceptable.
     *  @param flags Reserved for future use. In the current release, 0 will be passed.
     * 
     *  @return If the allocation was successful, the start address of a device memory block of the requested size.
     *  If an allocation request of size 0 is made, nullptr must be returned.
     *  If an allocation request cannot be satisfied, nullptr must be returned.
     *  If a non-null address is returned, it is guaranteed to have the specified alignment.
     * 
     *  \note The implementation must guarantee thread safety for concurrent allocate/reallocate/deallocate
     *  requests.
     * 
     *  \u005Cusage
     *  - Allowed context for the API call
     *    - Thread-safe: Yes, this method is required to be thread-safe and may be called from multiple threads.
     * 
     *  @deprecated Deprecated in TensorRT 10.0. Superseded by allocateAsync
     *  */
    public native @Deprecated @Name("allocate") @NoException(true) Pointer _allocate(
            @Cast("const uint64_t") long size, @Cast("const uint64_t") long alignment, @Cast("const nvinfer1::AllocatorFlags") int flags);

    /**
     *  \brief A thread-safe callback implemented by the application to resize an existing allocation.
     * 
     *  Only allocations which were allocated with AllocatorFlag::kRESIZABLE will be resized.
     * 
     *  Options are one of:
     *  * resize in place leaving min(oldSize, newSize) bytes unchanged and return the original address
     *  * move min(oldSize, newSize) bytes to a new location of sufficient size and return its address
     *  * return nullptr, to indicate that the request could not be fulfilled.
     * 
     *  If nullptr is returned, TensorRT will assume that resize() is not implemented, and that the
     *  allocation at baseAddr is still valid.
     * 
     *  This method is made available for use cases where delegating the resize
     *  strategy to the application provides an opportunity to improve memory management.
     *  One possible implementation is to allocate a large virtual device buffer and
     *  progressively commit physical memory with cuMemMap. CU_MEM_ALLOC_GRANULARITY_RECOMMENDED
     *  is suggested in this case.
     * 
     *  TensorRT may call realloc to increase the buffer by relatively small amounts.
     * 
     *  @param baseAddr the address of the original allocation, which will have been returned by previously calling
     *         allocate() or reallocate() on the same object.
     *  @param alignment The alignment used by the original allocation. This will be the same value that was previously
     *         passed to the allocate() or reallocate() call that returned baseAddr.
     *  @param newSize The new memory size required (in bytes).
     * 
     *  @return The address of the reallocated memory, or nullptr. If a non-null address is returned, it is
     *          guaranteed to have the specified alignment.
     * 
     *  \note The implementation must guarantee thread safety for concurrent allocate/reallocate/deallocate
     *  requests.
     * 
     *  \u005Cusage
     *  - Allowed context for the API call
     *    - Thread-safe: Yes, this method is required to be thread-safe and may be called from multiple threads.
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    public native @NoException(true) Pointer reallocate(Pointer arg0, @Cast("uint64_t") long arg1, @Cast("uint64_t") long arg2);

    /**
     *  \brief A thread-safe callback implemented by the application to handle release of GPU memory.
     * 
     *  TensorRT may pass a nullptr to this function if it was previously returned by allocate().
     * 
     *  @param memory A memory address that was previously returned by an allocate() or reallocate() call of the same
     *  allocator object.
     * 
     *  @return True if the acquired memory is released successfully.
     * 
     *  \note The implementation must guarantee thread safety for concurrent allocate/reallocate/deallocate
     *  requests.
     * 
     *  \u005Cusage
     *  - Allowed context for the API call
     *    - Thread-safe: Yes, this method is required to be thread-safe and may be called from multiple threads.
     *  @deprecated Deprecated in TensorRT 10.0. Superseded by deallocateAsync
     *  */
    
    
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    public native @Cast("bool") @Deprecated @Name("deallocate") @NoException(true) boolean _deallocate(Pointer memory);

    /**
     *  \brief A thread-safe callback implemented by the application to handle stream-ordered acquisition of GPU memory.
     * 
     *  The default behavior is to call method allocate(), which is synchronous and thus loses
     *  any performance benefits of asynchronous allocation. If you want the benefits of asynchronous
     *  allocation, see discussion of IGpuAsyncAllocator vs. IGpuAllocator in the documentation
     *  for nvinfer1::IGpuAllocator.
     * 
     *  @param size The size of the memory block required (in bytes).
     *  @param alignment The required alignment of memory. Alignment will be zero
     *         or a power of 2 not exceeding the alignment guaranteed by cudaMalloc.
     *         Thus this allocator can be safely implemented with cudaMalloc/cudaFree.
     *         An alignment value of zero indicates any alignment is acceptable.
     *  @param flags Reserved for future use. In the current release, 0 will be passed.
     *  @param stream specifies the cudaStream for asynchronous usage.
     * 
     *  @return If the allocation was successful, the start address of a device memory block of the requested size.
     *  If an allocation request of size 0 is made, nullptr must be returned.
     *  If an allocation request cannot be satisfied, nullptr must be returned.
     *  If a non-null address is returned, it is guaranteed to have the specified alignment.
     * 
     *  \note The implementation must guarantee thread safety for concurrent allocate/reallocate/deallocate
     *  requests.
     * 
     *  \u005Cusage
     *  - Allowed context for the API call
     *    - Thread-safe: Yes, this method is required to be thread-safe and may be called from multiple threads.
     *  */
    
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    //!
    public native @NoException(true) Pointer allocateAsync(
            @Cast("const uint64_t") long size, @Cast("const uint64_t") long alignment, @Cast("const nvinfer1::AllocatorFlags") int flags, CUstream_st arg3);
    /**
     *  \brief A thread-safe callback implemented by the application to handle stream-ordered release of GPU memory.
     * 
     *  The default behavior is to call method deallocate(), which is synchronous and thus loses
     *  any performance benefits of asynchronous deallocation. If you want the benefits of asynchronous
     *  deallocation, see discussion of IGpuAsyncAllocator vs. IGpuAllocator in the documentation
     *  for nvinfer1::IGpuAllocator.
     * 
     *  TensorRT may pass a nullptr to this function if it was previously returned by allocate().
     * 
     *  @param memory A memory address that was previously returned by an allocate() or reallocate() call of the same
     *  allocator object.
     *  @param stream specifies the cudaStream for asynchronous usage.
     * 
     *  @return True if the acquired memory is released successfully.
     * 
     *  \note The implementation must guarantee thread safety for concurrent allocate/reallocate/deallocate
     *  requests.
     * 
     *  \note The implementation is not required to be asynchronous. It is permitted to synchronize,
     *  albeit doing so will lose the performance advantage of asynchronous deallocation.
     *  Either way, it is critical that it not actually free the memory until the current
     *  stream position is reached.
     * 
     *  \u005Cusage
     *  - Allowed context for the API call
     *    - Thread-safe: Yes, this method is required to be thread-safe and may be called from multiple threads.
     *  */
    
    
    //!
    //!
    public native @Cast("bool") @NoException(true) boolean deallocateAsync(Pointer memory, CUstream_st arg1);

    /**
     *  \brief Return version information associated with this interface. Applications must not override this method.
     *  */
    public native @ByVal @NoException(true) InterfaceInfo getInterfaceInfo();
}
