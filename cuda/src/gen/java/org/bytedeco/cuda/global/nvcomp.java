// Targeted by JavaCPP version 1.5.13-SNAPSHOT: DO NOT EDIT THIS FILE

package org.bytedeco.cuda.global;

import org.bytedeco.cuda.nvcomp.*;

import java.nio.*;
import org.bytedeco.javacpp.*;
import org.bytedeco.javacpp.annotation.*;

import static org.bytedeco.javacpp.presets.javacpp.*;
import org.bytedeco.cuda.cudart.*;
import static org.bytedeco.cuda.global.cudart.*;

public class nvcomp extends org.bytedeco.cuda.presets.nvcomp {
    static { Loader.load(); }

// Parsed from <nvcomp/shared_types.h>

/*
 * SPDX-FileCopyrightText: Copyright (c) 2022-2025 NVIDIA CORPORATION & AFFILIATES.
 * All rights reserved. SPDX-License-Identifier: LicenseRef-NvidiaProprietary
 *
 * NVIDIA CORPORATION, its affiliates and licensors retain all intellectual
 * property and proprietary rights in and to this material, related
 * documentation and any modifications thereto. Any use, reproduction,
 * disclosure or distribution of this material and related documentation
 * without an express license agreement from NVIDIA CORPORATION or
 * its affiliates is strictly prohibited.
*/

// #ifndef NVCOMP_SHARED_TYPES_H
// #define NVCOMP_SHARED_TYPES_H

// #ifdef __cplusplus
// #include <cstddef>
// #include <cstdint>
// #else
// #include <stddef.h>
// #include <stdint.h>
// #endif // __cplusplus

/**
 * \brief nvCOMP return statuses.
 */
/** enum nvcompStatus_t */
public static final int
  nvcompSuccess = 0,
  nvcompErrorInvalidValue = 10,
  nvcompErrorNotSupported = 11,
  nvcompErrorCannotDecompress = 12,
  nvcompErrorBadChecksum = 13,
  nvcompErrorCannotVerifyChecksums = 14,
  nvcompErrorOutputBufferTooSmall = 15,
  nvcompErrorWrongHeaderLength = 16,
  nvcompErrorAlignment = 17,
  nvcompErrorChunkSizeTooLarge = 18,
  nvcompErrorCannotCompress = 19,
  nvcompErrorWrongInputLength = 20,
  nvcompErrorCudaError = 1000,
  nvcompErrorInternal = 10000;

/**
 * \brief Supported data types.
 */
/** enum nvcompType_t */
public static final int
  NVCOMP_TYPE_CHAR = 0,      // 1B
  NVCOMP_TYPE_UCHAR = 1,     // 1B
  NVCOMP_TYPE_SHORT = 2,     // 2B
  NVCOMP_TYPE_USHORT = 3,    // 2B
  NVCOMP_TYPE_INT = 4,       // 4B
  NVCOMP_TYPE_UINT = 5,      // 4B
  NVCOMP_TYPE_LONGLONG = 6,  // 8B
  NVCOMP_TYPE_ULONGLONG = 7, // 8B
  NVCOMP_TYPE_FLOAT16 = 9,   // 2B
  NVCOMP_TYPE_BITS = 0xff;    // 1b

/**
 * \brief Available decompression backend options
*/
/** enum nvcompDecompressBackend_t */
public static final int
  /** Let nvCOMP decide the best decompression backend internally, either
   *  hardware decompression or one of the CUDA implementations. */
  NVCOMP_DECOMPRESS_BACKEND_DEFAULT = 0,

  /** Decompress using the dedicated hardware decompression engine. */
  NVCOMP_DECOMPRESS_BACKEND_HARDWARE = 1,

  /** Decompress using the CUDA implementation. */
  NVCOMP_DECOMPRESS_BACKEND_CUDA = 2;
// Targeting ../nvcomp/nvcompProperties_t.java


// Targeting ../nvcomp/nvcompAlignmentRequirements_t.java



// #endif // NVCOMP_SHARED_TYPES_H


// Parsed from <nvcomp.h>

/*
 * SPDX-FileCopyrightText: Copyright (c) 2017-2025 NVIDIA CORPORATION & AFFILIATES.
 * All rights reserved. SPDX-License-Identifier: LicenseRef-NvidiaProprietary
 *
 * NVIDIA CORPORATION, its affiliates and licensors retain all intellectual
 * property and proprietary rights in and to this material, related
 * documentation and any modifications thereto. Any use, reproduction,
 * disclosure or distribution of this material and related documentation
 * without an express license agreement from NVIDIA CORPORATION or
 * its affiliates is strictly prohibited.
*/

// #pragma once

// #include <cuda_runtime.h>

// #include "nvcomp/shared_types.h"
// #include "nvcomp/version.h"
// #include "nvcomp_export.h"

// #ifdef __cplusplus
// #endif

/**
 * \brief Retrieve the nvCOMP library properties.
 *
 * @param properties [out] Retrieved nvCOMP properties in an nvcompProperties_t struct.
 *
 * @return nvcompErrorInvalidValue if properties is nullptr, nvcompSuccess otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompGetProperties(nvcompProperties_t properties);

// #ifdef __cplusplus
// #endif


// Parsed from <nvcomp/nvcompManager.hpp>

/*
 * SPDX-FileCopyrightText: Copyright (c) 2020-2025 NVIDIA CORPORATION & AFFILIATES.
 * All rights reserved. SPDX-License-Identifier: LicenseRef-NvidiaProprietary
 *
 * NVIDIA CORPORATION, its affiliates and licensors retain all intellectual
 * property and proprietary rights in and to this material, related
 * documentation and any modifications thereto. Any use, reproduction,
 * disclosure or distribution of this material and related documentation
 * without an express license agreement from NVIDIA CORPORATION or
 * its affiliates is strictly prohibited.
*/

// #pragma once

// #include <memory>
// #include <vector>
// #include <functional>

// #include "nvcomp.hpp"

/**
 * \brief Custom allocator function type that receives a size in bytes to allocate
 * in device-accessible memory.
 */

/**
 * \brief Custom deallocation function type that receives a memory pointer and size
 * in bytes to deallocate.
 */

/**
 * \brief Enumeration that defines how a buffer gets compressed by an nvCOMP manager.
 */
/** enum class nvcomp::BitstreamKind */
public static final int
  /** Each input buffer is chunked according to manager setting and compressed in parallel.
   *  Allows computation of checksums.
   *  Adds custom header with nvCOMP metadata at the beginning of the compressed data. */
  NVCOMP_NATIVE = 0,
  /** Compresses input data as is, just using underlying compression algorithm.
   *  Does not add header with nvCOMP metadata. */
  RAW = 1,
  /** Similar to RAW, but adds custom header with just uncompressed size at the beginning of the compressed data. */
  WITH_UNCOMPRESSED_SIZE = 2;

/**
 * \brief Enumeration that defines the checksum policy used by an nvCOMP manager.
 */
/** enum nvcomp::ChecksumPolicy */
public static final int
  /** During compression, do not compute checksums.
   *  During decompression, do not verify checksums. */
  NoComputeNoVerify = 0,

  /** During compression, compute checksums.
   *  During decompression, do not attempt to verify checksums. */
  ComputeAndNoVerify = 1,

  /** During compression, do not compute checksums.
   *  During decompression, verify checksums if they were included. */
  NoComputeAndVerifyIfPresent = 2,

  /** During compression, compute checksums.
   *  During decompression, verify checksums if they were included. */
  ComputeAndVerifyIfPresent = 3,

  /** During compression, compute checksums.
   *  During decompression, verify checksums.
   *  A runtime error will be thrown upon configure_decompression if
   *  checksums were not included in the compressed buffer. */
  ComputeAndVerify = 4;

// #ifndef DOXYGEN_SHOULD_SKIP_THIS

/**
 * \brief Internal memory pool used for compression / decompression configurations.
 */


// Targeting ../nvcomp/CompressionConfig.java


// Targeting ../nvcomp/DecompressionConfig.java


// Targeting ../nvcomp/nvcompManagerBase.java



// #ifndef DOXYGEN_SHOULD_SKIP_THIS

/**
 * \brief Internal nvcompManager base class for the high-level interface.
 */
// Targeting ../nvcomp/PimplManager.java



 // namespace detail

// #endif // DOXYGEN_SHOULD_SKIP_THIS

 // namespace nvcomp


// Parsed from <nvcomp/nvcompManagerFactory.hpp>

/*
 * SPDX-FileCopyrightText: Copyright (c) 2022-2025 NVIDIA CORPORATION & AFFILIATES.
 * All rights reserved. SPDX-License-Identifier: LicenseRef-NvidiaProprietary
 *
 * NVIDIA CORPORATION, its affiliates and licensors retain all intellectual
 * property and proprietary rights in and to this material, related
 * documentation and any modifications thereto. Any use, reproduction,
 * disclosure or distribution of this material and related documentation
 * without an express license agreement from NVIDIA CORPORATION or
 * its affiliates is strictly prohibited.
*/

// #pragma once

// #include "nvcompManager.hpp"
// #include "ans.hpp"
// #include "gdeflate.hpp"
// #include "lz4.hpp"
// #include "snappy.hpp"
// #include "bitcomp.hpp"
// #include "cascaded.hpp"
// #include "zstd.hpp"
// #include "deflate.hpp"
// #include "gzip.hpp"

/**
 * \brief Construct a ManagerBase from a given compressed buffer.
 *
 * \note This operation synchronizes the host with the stream.
 *
 * @param comp_buffer [in] The HLIF compressed buffer from which we intend to create the manager.
 * @param stream [in] The CUDA stream to perform the operation on.
 * @param checksum_policy [in] The checksum policy to use.
 * @param backend [in] The backend (CUDA / hardware decompress engine) to use.
 * @param use_de_sort [in] Whether to sort before hardware decompression for load balancing (for LZ4, Snappy, Deflate, and Gzip).
 *
 * @return The constructed manager instance.
 */
@Namespace("nvcomp") public static native @SharedPtr nvcompManagerBase create_manager(
    @Cast("const uint8_t*") BytePointer comp_buffer,
    CUstream_st stream/*=0*/,
    @Cast("nvcomp::ChecksumPolicy") int checksum_policy/*=nvcomp::NoComputeNoVerify*/,
    @Cast("nvcompDecompressBackend_t") int backend/*=NVCOMP_DECOMPRESS_BACKEND_DEFAULT*/,
    @Cast("bool") boolean use_de_sort/*=false*/);
@Namespace("nvcomp") public static native @SharedPtr nvcompManagerBase create_manager(
    @Cast("const uint8_t*") BytePointer comp_buffer);
@Namespace("nvcomp") public static native @SharedPtr nvcompManagerBase create_manager(
    @Cast("const uint8_t*") ByteBuffer comp_buffer,
    CUstream_st stream/*=0*/,
    @Cast("nvcomp::ChecksumPolicy") int checksum_policy/*=nvcomp::NoComputeNoVerify*/,
    @Cast("nvcompDecompressBackend_t") int backend/*=NVCOMP_DECOMPRESS_BACKEND_DEFAULT*/,
    @Cast("bool") boolean use_de_sort/*=false*/);
@Namespace("nvcomp") public static native @SharedPtr nvcompManagerBase create_manager(
    @Cast("const uint8_t*") ByteBuffer comp_buffer);
@Namespace("nvcomp") public static native @SharedPtr nvcompManagerBase create_manager(
    @Cast("const uint8_t*") byte[] comp_buffer,
    CUstream_st stream/*=0*/,
    @Cast("nvcomp::ChecksumPolicy") int checksum_policy/*=nvcomp::NoComputeNoVerify*/,
    @Cast("nvcompDecompressBackend_t") int backend/*=NVCOMP_DECOMPRESS_BACKEND_DEFAULT*/,
    @Cast("bool") boolean use_de_sort/*=false*/);
@Namespace("nvcomp") public static native @SharedPtr nvcompManagerBase create_manager(
    @Cast("const uint8_t*") byte[] comp_buffer);

 // namespace nvcomp


// Parsed from <nvcomp/ans.h>

/*
 * SPDX-FileCopyrightText: Copyright (c) 2017-2025 NVIDIA CORPORATION & AFFILIATES.
 * All rights reserved. SPDX-License-Identifier: LicenseRef-NvidiaProprietary
 *
 * NVIDIA CORPORATION, its affiliates and licensors retain all intellectual
 * property and proprietary rights in and to this material, related
 * documentation and any modifications thereto. Any use, reproduction,
 * disclosure or distribution of this material and related documentation
 * without an express license agreement from NVIDIA CORPORATION or
 * its affiliates is strictly prohibited.
*/

// #ifndef NVCOMP_ANS_H
// #define NVCOMP_ANS_H

// #include "nvcomp.h"

// #ifdef __cplusplus
// #endif

/**
 * \brief Available ANS types
 */
/** enum nvcompANSType_t */
public static final int
  nvcomp_rANS = 0;
// Targeting ../nvcomp/nvcompBatchedANSCompressOpts_t.java


// Targeting ../nvcomp/nvcompBatchedANSDecompressOpts_t.java



/**
 * \brief Default ANS compression options
 */
@MemberGetter public static native @Const @ByRef nvcompBatchedANSCompressOpts_t nvcompBatchedANSCompressDefaultOpts();

/**
 * \brief Default ANS decompression options
 */
@MemberGetter public static native @Const @ByRef nvcompBatchedANSDecompressOpts_t nvcompBatchedANSDecompressDefaultOpts();

/**
 * \brief The maximum supported uncompressed chunk size in bytes for the ANS compressor.
 */
@MemberGetter public static native @Cast("const size_t") long nvcompANSCompressionMaxAllowedChunkSize();
public static final long nvcompANSCompressionMaxAllowedChunkSize = nvcompANSCompressionMaxAllowedChunkSize();

/**
 * \brief The most restrictive of the minimum alignment requirements for void-type CUDA memory buffers
 * used for input, output, or temporary memory, passed to compression functions.
 *
 * \note In all cases, typed memory buffers must still be aligned to their type's size,
 * e.g., 4 bytes for {@code int}.
 */
@MemberGetter public static native @Cast("const size_t") long nvcompANSRequiredCompressionAlignment();
public static final long nvcompANSRequiredCompressionAlignment = nvcompANSRequiredCompressionAlignment();

/**
 * \brief Get the minimum buffer alignment requirements for compression.
 *
 * \note Providing buffers with alignments above the minimum requirements
 * (e.g., 16- or 32-byte alignment) may help improve performance.
 *
 * @param compress_opts [in] Compression options.
 * @param alignment_requirements [out] The minimum buffer alignment requirements
 * for compression.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedANSCompressGetRequiredAlignments(
    @ByVal nvcompBatchedANSCompressOpts_t compress_opts,
    nvcompAlignmentRequirements_t alignment_requirements);

/**
 * \brief Get the amount of temporary memory required on the GPU for compression
 * asynchronously.
 *
 * @param num_chunks [in] The number of chunks of memory in the batch.
 * @param max_uncompressed_chunk_bytes [in] The maximum size of a chunk in the
 * batch.
 * @param compress_opts [in] Compression options.
 * @param temp_bytes [out] The amount of GPU memory that will be temporarily
 * required during compression. The value is returned on the host side.
 * @param max_total_uncompressed_bytes [in] Upper bound on the total uncompressed
 * size of all chunks
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedANSCompressGetTempSizeAsync(
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedANSCompressOpts_t compress_opts,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes);

/**
 * \brief Get the amount of temporary memory required on the GPU for compression.
 * synchronously.
 *
 * @param device_uncompressed_chunk_ptrs [in] Array with size \p num_chunks of pointers
 * to the uncompressed data chunks. Both the pointers and the uncompressed data
 * should reside in device-accessible memory.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedANSCompressGetRequiredAlignments} when called with the same
 * \p compress_opts.
 * @param device_uncompressed_chunk_bytes [in] Array with size \p num_chunks of
 * sizes of the uncompressed chunks in bytes.
 * The sizes should reside in device-accessible memory.
 * @param num_chunks [in] The number of chunks of memory in the batch.
 * @param max_uncompressed_chunk_bytes [in] The maximum size of a chunk in the
 * batch.
 * @param compress_opts [in] Compression options.
 * @param temp_bytes [out] The amount of GPU memory that will be temporarily
 * required during compression. The value is returned on the host side.
 * @param max_total_uncompressed_bytes [in] Upper bound on the total uncompressed
 * size of all chunks
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedANSCompressGetTempSizeSync(
    @Cast("const void*const*const") PointerPointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedANSCompressOpts_t compress_opts,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedANSCompressGetTempSizeSync(
    @Cast("const void*const*const") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedANSCompressOpts_t compress_opts,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    CUstream_st stream);

/**
 * \brief Get the maximum size that a chunk of size at most max_uncompressed_chunk_bytes
 * could compress to. That is, the minimum amount of output memory required to be given
 * nvcompBatchedANSCompressAsync() for each chunk.
 *
 * @param max_uncompressed_chunk_bytes [in] The maximum size of a chunk before compression.
 * @param compress_opts [in] Compression options.
 * @param max_compressed_chunk_bytes [out] The maximum possible compressed size of the chunk.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedANSCompressGetMaxOutputChunkSize(
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedANSCompressOpts_t compress_opts,
    @Cast("size_t*") SizeTPointer max_compressed_chunk_bytes);

/**
 * \brief Perform batched asynchronous compression.
 *
 * \note Violating any of the conditions listed in the parameter descriptions
 * below may result in undefined behaviour.
 *
 * @param device_uncompressed_chunk_ptrs [in] Array with size \p num_chunks of pointers
 * to the uncompressed data chunks. Both the pointers and the uncompressed data
 * should reside in device-accessible memory.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedANSCompressGetRequiredAlignments} when called with the same
 * \p compress_opts.
 * @param device_uncompressed_chunk_bytes [in] Array with size \p num_chunks of
 * sizes of the uncompressed chunks in bytes.
 * The sizes should reside in device-accessible memory.
 * @param max_uncompressed_chunk_bytes [in] The size of the largest uncompressed chunk.
 * @param num_chunks [in] Number of chunks of data to compress.
 * @param device_temp_ptr [in] The temporary GPU workspace, could be NULL in case
 * temporary memory is not needed.
 * Must be aligned to the value in the {@code temp} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedANSCompressGetRequiredAlignments} when called with the same
 * \p compress_opts.
 * @param temp_bytes [in] The size of the temporary GPU memory pointed to by
 * {@code device_temp_ptr}.
 * @param device_compressed_chunk_ptrs [out] Array with size \p num_chunks of pointers
 * to the output compressed buffers. Both the pointers and the compressed
 * buffers should reside in device-accessible memory. Each compressed buffer
 * should be preallocated with the size given by
 * {@code nvcompBatchedANSCompressGetMaxOutputChunkSize}.
 * Each compressed buffer must be aligned to the value in the {@code output} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedANSCompressGetRequiredAlignments} when called with the same
 * \p compress_opts.
 * @param device_compressed_chunk_bytes [out] Array with size \p num_chunks,
 * to be filled with the compressed sizes of each chunk.
 * The buffer should be preallocated in device-accessible memory.
 * @param compress_opts [in] Compression options.
 * @param device_statuses [out] Array with size \p num_chunks of statuses in
 * device-accessible memory. This argument needs to be preallocated. For each
 * chunk, if the compression is successful, the status will be set to
 * {@code nvcompSuccess}, and an error code otherwise.
 * @param stream [in] The CUDA stream to operate on.
 * @return nvcompSuccess if successfully launched, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedANSCompressAsync(
    @Cast("const void*const*") PointerPointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") PointerPointer device_compressed_chunk_ptrs,
    @Cast("size_t*") SizeTPointer device_compressed_chunk_bytes,
    @ByVal nvcompBatchedANSCompressOpts_t compress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedANSCompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("size_t*") SizeTPointer device_compressed_chunk_bytes,
    @ByVal nvcompBatchedANSCompressOpts_t compress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedANSCompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("size_t*") SizeTPointer device_compressed_chunk_bytes,
    @ByVal nvcompBatchedANSCompressOpts_t compress_opts,
    @Cast("nvcompStatus_t*") IntBuffer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedANSCompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("size_t*") SizeTPointer device_compressed_chunk_bytes,
    @ByVal nvcompBatchedANSCompressOpts_t compress_opts,
    @Cast("nvcompStatus_t*") int[] device_statuses,
    CUstream_st stream);

/**
 * \brief The most restrictive of the minimum alignment requirements for void-type CUDA memory buffers
 * used for input, output, or temporary memory, passed to decompression functions.
 *
 * \note In all cases, typed memory buffers must still be aligned to their type's size,
 * e.g., 4 bytes for {@code int}.
 */
@MemberGetter public static native @Cast("const size_t") long nvcompANSRequiredDecompressionAlignment();
public static final long nvcompANSRequiredDecompressionAlignment = nvcompANSRequiredDecompressionAlignment();

/**
 * \brief Get the minimum buffer alignment requirements for decompression.
 *
 * \note Providing buffers with alignments above the minimum requirements
 * (e.g., 16- or 32-byte alignment) may help improve performance.
 *
 * @param decompress_opts [in] Decompression options.
 * @param alignment_requirements [out] The minimum buffer alignment requirements
 * for decompression.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedANSDecompressGetRequiredAlignments(
    @ByVal nvcompBatchedANSDecompressOpts_t decompress_opts,
    nvcompAlignmentRequirements_t alignment_requirements);

/**
 * \brief Get the amount of temporary memory required on the GPU for decompression
 * asynchronously.
 *
 * @param num_chunks [in] Number of chunks of data to be decompressed.
 * @param max_uncompressed_chunk_bytes [in] The size of the largest chunk in bytes
 * when uncompressed.
 * @param decompress_opts [in] Decompression options.
 * @param temp_bytes [out] The amount of GPU memory that will be temporarily required
 * during decompression. The value is returned on the host side.
 * @param max_total_uncompressed_bytes [in] The total decompressed size of all the chunks.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedANSDecompressGetTempSizeAsync(
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedANSDecompressOpts_t decompress_opts,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes);

/**
 * \brief Get the amount of temporary memory required on the GPU for decompression
 * synchronously.
 *
 * @param device_compressed_chunk_ptrs [in] Array with size \p num_chunks of pointers
 * in device-accessible memory to device-accessible compressed buffers.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedANSDecompressGetRequiredAlignments}.
 * @param device_compressed_chunk_bytes [in] Array with size \p num_chunks of sizes of
 * the compressed buffers in bytes. The sizes should reside in device-accessible memory.
 * @param num_chunks [in] Number of chunks of data to be decompressed.
 * @param max_uncompressed_chunk_bytes [in] The size of the largest chunk in bytes
 * when uncompressed.
 * @param temp_bytes [out] The amount of GPU memory that will be temporarily required
 * during decompression. The value is returned on the host side.
 * @param max_total_uncompressed_bytes [in]  The total decompressed size of all the chunks.
 * @param decompress_opts [in] Decompression options.
 * @param device_statuses [out] Array with size \p num_chunks of statuses in
 * device-accessible memory. This argument needs to be preallocated. For each
 * chunk, if the data can be parsed successfully, the status will be set to
 * {@code nvcompSuccess}, and an error code otherwise.
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedANSDecompressGetTempSizeSync(
    @Cast("const void*const*const") PointerPointer device_compressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    @ByVal nvcompBatchedANSDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedANSDecompressGetTempSizeSync(
    @Cast("const void*const*const") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    @ByVal nvcompBatchedANSDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedANSDecompressGetTempSizeSync(
    @Cast("const void*const*const") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    @ByVal nvcompBatchedANSDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntBuffer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedANSDecompressGetTempSizeSync(
    @Cast("const void*const*const") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    @ByVal nvcompBatchedANSDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") int[] device_statuses,
    CUstream_st stream);

/**
 * \brief Asynchronously compute the number of bytes of uncompressed data for
 * each compressed chunk.
 *
 * \note Violating any of the conditions listed in the parameter descriptions
 * below may result in undefined behaviour.
 *
 * @param device_compressed_chunk_ptrs [in] Array with size \p num_chunks of
 * pointers in device-accessible memory to compressed buffers.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedANSDecompressGetRequiredAlignments}.
 * @param device_compressed_chunk_bytes [in] Array with size \p num_chunks of sizes
 * of the compressed buffers in bytes. The sizes should reside in device-accessible memory.
 * @param device_uncompressed_chunk_bytes [out] Array with size \p num_chunks
 * to be filled with the sizes, in bytes, of each uncompressed data chunk.
 * If there is an error when retrieving the size of a chunk, the
 * uncompressed size of that chunk will be set to 0. This argument needs to
 * be preallocated in device-accessible memory.
 * @param num_chunks [in] Number of data chunks to compute sizes of.
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedANSGetDecompressSizeAsync(
    @Cast("const void*const*") PointerPointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedANSGetDecompressSizeAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    CUstream_st stream);

/**
 * \brief Perform batched asynchronous decompression.
 *
 * This function is used to decompress compressed buffers produced by
 * \ref nvcompBatchedANSCompressAsync .
 *
 * \note Violating any of the conditions listed in the parameter descriptions
 * below may result in undefined behaviour.
 *
 * @param device_compressed_chunk_ptrs [in] Array with size \p num_chunks of pointers
 * in device-accessible memory to device-accessible compressed buffers.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedANSDecompressGetRequiredAlignments}.
 * @param device_compressed_chunk_bytes [in] Array with size \p num_chunks of sizes of
 * the compressed buffers in bytes. The sizes should reside in device-accessible memory.
 * @param device_uncompressed_buffer_bytes [in] Array with size \p num_chunks of sizes,
 * in bytes, of the output buffers to be filled with uncompressed data for each chunk.
 * The sizes should reside in device-accessible memory. If a
 * size is not large enough to hold all decompressed data, the decompressor
 * will set the status in \p device_statuses corresponding to the
 * overflow chunk to {@code nvcompErrorCannotDecompress}.
 * @param device_uncompressed_chunk_bytes [out] Array with size \p num_chunks to
 * be filled with the actual number of bytes decompressed for every chunk.
 * This argument needs to be preallocated.
 * @param num_chunks [in] Number of chunks of data to decompress.
 * @param device_temp_ptr [in] The temporary GPU space, could be NULL in case temporary space is not needed.
 * Must be aligned to the value in the {@code temp} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedANSDecompressGetRequiredAlignments}.
 * @param temp_bytes [in] The size of the temporary GPU space.
 * @param device_uncompressed_chunk_ptrs [out] Array with size \p num_chunks of
 * pointers in device-accessible memory to decompressed data. Each uncompressed
 * buffer needs to be preallocated in device-accessible memory, have the size
 * specified by the corresponding entry in \p device_uncompressed_buffer_bytes,
 * and be aligned to the value in the {@code output} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedANSDecompressGetRequiredAlignments}.
 * @param decompress_opts [in] Decompression options.
 * @param device_statuses [out] Array with size \p num_chunks of statuses in
 * device-accessible memory. This argument needs to be preallocated. For each
 * chunk, if the decompression is successful, the status will be set to
 * {@code nvcompSuccess}. If the decompression is not successful, for example due to
 * the corrupted input or out-of-bound errors, the status will be set to
 * {@code nvcompErrorCannotDecompress}.
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successfully launched, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedANSDecompressAsync(
    @Cast("const void*const*") PointerPointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("const size_t*") SizeTPointer device_uncompressed_buffer_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") PointerPointer device_uncompressed_chunk_ptrs,
    @ByVal nvcompBatchedANSDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedANSDecompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("const size_t*") SizeTPointer device_uncompressed_buffer_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @ByVal nvcompBatchedANSDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedANSDecompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("const size_t*") SizeTPointer device_uncompressed_buffer_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @ByVal nvcompBatchedANSDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntBuffer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedANSDecompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("const size_t*") SizeTPointer device_uncompressed_buffer_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @ByVal nvcompBatchedANSDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") int[] device_statuses,
    CUstream_st stream);

// #ifdef __cplusplus
// #endif

// #endif // NVCOMP_ANS_H


// Parsed from <nvcomp/ans.hpp>

/*
 * SPDX-FileCopyrightText: Copyright (c) 2022-2025 NVIDIA CORPORATION & AFFILIATES.
 * All rights reserved. SPDX-License-Identifier: LicenseRef-NvidiaProprietary
 *
 * NVIDIA CORPORATION, its affiliates and licensors retain all intellectual
 * property and proprietary rights in and to this material, related
 * documentation and any modifications thereto. Any use, reproduction,
 * disclosure or distribution of this material and related documentation
 * without an express license agreement from NVIDIA CORPORATION or
 * its affiliates is strictly prohibited.
*/

// #pragma once

// #include "nvcompManager.hpp"
// #include "ans.h"
// Targeting ../nvcomp/ANSFormatSpecHeader.java


// Targeting ../nvcomp/ANSManager.java



 // namespace nvcomp


// Parsed from <nvcomp/bitcomp.h>

/*
 * SPDX-FileCopyrightText: Copyright (c) 2017-2025 NVIDIA CORPORATION & AFFILIATES.
 * All rights reserved. SPDX-License-Identifier: LicenseRef-NvidiaProprietary
 *
 * NVIDIA CORPORATION, its affiliates and licensors retain all intellectual
 * property and proprietary rights in and to this material, related
 * documentation and any modifications thereto. Any use, reproduction,
 * disclosure or distribution of this material and related documentation
 * without an express license agreement from NVIDIA CORPORATION or
 * its affiliates is strictly prohibited.
*/

// #ifndef NVCOMP_BITCOMP_H
// #define NVCOMP_BITCOMP_H

// #include "nvcomp.h"

// #ifdef __cplusplus
// Targeting ../nvcomp/nvcompBatchedBitcompCompressOpts_t.java


// Targeting ../nvcomp/nvcompBatchedBitcompDecompressOpts_t.java



/**
 * \brief Default Bitcomp compression options
 */
@MemberGetter public static native @Const @ByRef nvcompBatchedBitcompCompressOpts_t nvcompBatchedBitcompCompressDefaultOpts();

/**
 * \brief Default Bitcomp decompression options
 */
@MemberGetter public static native @Const @ByRef nvcompBatchedBitcompDecompressOpts_t nvcompBatchedBitcompDecompressDefaultOpts();

/**
 * \brief The maximum supported uncompressed chunk size in bytes for the Bitcomp compressor.
 */
@MemberGetter public static native @Cast("const size_t") long nvcompBitcompCompressionMaxAllowedChunkSize();
public static final long nvcompBitcompCompressionMaxAllowedChunkSize = nvcompBitcompCompressionMaxAllowedChunkSize();

/**
 * \brief The most restrictive of the minimum alignment requirements for void-type CUDA memory buffers
 * used for input, output, or temporary memory, passed to compression functions.
 *
 * \note In all cases, typed memory buffers must still be aligned to their type's size,
 * e.g., 4 bytes for {@code int}.
 */
@MemberGetter public static native @Cast("const size_t") long nvcompBitcompRequiredCompressionAlignment();
public static final long nvcompBitcompRequiredCompressionAlignment = nvcompBitcompRequiredCompressionAlignment();

/**
 * \brief Get the minimum buffer alignment requirements for compression.
 *
 * \note Providing buffers with alignments above the minimum requirements
 * (e.g., 16- or 32-byte alignment) may help improve performance.
 *
 * @param compress_opts [in] Compression options.
 * @param alignment_requirements [out] The minimum buffer alignment requirements
 * for compression.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedBitcompCompressGetRequiredAlignments(
    @ByVal nvcompBatchedBitcompCompressOpts_t compress_opts,
    nvcompAlignmentRequirements_t alignment_requirements);

/**
 * \brief Get the amount of temporary memory required on the GPU for compression
 * asynchronously.
 *
 * @param num_chunks [in] The number of chunks of memory in the batch.
 * @param max_uncompressed_chunk_bytes [in] The maximum size of a chunk in the
 * batch.
 * @param compress_opts [in] Compression options.
 * @param temp_bytes [out] The amount of GPU memory that will be temporarily
 * required during compression. The value is returned on the host side.
 * @param max_total_uncompressed_bytes [in] Upper bound on the total uncompressed
 * size of all chunks
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedBitcompCompressGetTempSizeAsync(
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedBitcompCompressOpts_t compress_opts,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes);

/**
 * \brief Get the amount of temporary memory required on the GPU for compression.
 * synchronously.
 *
 * @param device_uncompressed_chunk_ptrs [in] Array with size \p num_chunks of pointers
 * to the uncompressed data chunks. Both the pointers and the uncompressed data
 * should reside in device-accessible memory.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedBitcompCompressGetRequiredAlignments} when called with the same
 * \p compress_opts.
 * @param device_uncompressed_chunk_bytes [in] Array with size \p num_chunks of
 * sizes of the uncompressed chunks in bytes.
 * The sizes should reside in device-accessible memory.
 * @param num_chunks [in] The number of chunks of memory in the batch.
 * @param max_uncompressed_chunk_bytes [in] The maximum size of a chunk in the
 * batch.
 * @param compress_opts [in] Compression options.
 * @param temp_bytes [out] The amount of GPU memory that will be temporarily
 * required during compression. The value is returned on the host side.
 * @param max_total_uncompressed_bytes [in] Upper bound on the total uncompressed
 * size of all chunks
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedBitcompCompressGetTempSizeSync(
    @Cast("const void*const*const") PointerPointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedBitcompCompressOpts_t compress_opts,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedBitcompCompressGetTempSizeSync(
    @Cast("const void*const*const") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedBitcompCompressOpts_t compress_opts,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    CUstream_st stream);

/**
 * \brief Get the maximum size that a chunk of size at most max_uncompressed_chunk_bytes
 * could compress to. That is, the minimum amount of output memory required to be given
 * \ref nvcompBatchedBitcompCompressAsync for each chunk.
 *
 * @param max_uncompressed_chunk_bytes [in] The maximum size of a chunk before compression.
 * @param compress_opts [in] Compression options.
 * @param max_compressed_chunk_bytes [out] The maximum possible compressed size of the chunk.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedBitcompCompressGetMaxOutputChunkSize(
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedBitcompCompressOpts_t compress_opts,
    @Cast("size_t*") SizeTPointer max_compressed_chunk_bytes);

/**
 * \brief Perform batched asynchronous compression.
 *
 * \note Violating any of the conditions listed in the parameter descriptions
 * below may result in undefined behaviour.
 *
 * @param device_uncompressed_chunk_ptrs [in] Array with size \p num_chunks of pointers
 * to the uncompressed data chunks. Both the pointers and the uncompressed data
 * should reside in device-accessible memory.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedBitcompCompressGetRequiredAlignments} when called with the same
 * \p compress_opts.
 * @param device_uncompressed_chunk_bytes [in] Array with size \p num_chunks of
 * sizes of the uncompressed chunks in bytes.
 * The sizes should reside in device-accessible memory.
 * Each chunk size must be a multiple of the size of the data type specified by
 * compress_opts.data_type.
 * @param max_uncompressed_chunk_bytes [in] The maximum size of a chunk in the
 * batch. This parameter is currently unused.
 * Set it to either the actual value or zero.
 * @param num_chunks [in] Number of chunks of data to compress.
 * @param device_temp_ptr [in] This argument is not used.
 * @param temp_bytes [in] This argument is not used.
 * @param device_compressed_chunk_ptrs [out] Array with size \p num_chunks of pointers
 * to the output compressed buffers. Both the pointers and the compressed
 * buffers should reside in device-accessible memory. Each compressed buffer
 * should be preallocated with the size given by
 * {@code nvcompBatchedBitcompCompressGetMaxOutputChunkSize}.
 * Each compressed buffer must be aligned to the value in the {@code output} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedBitcompCompressGetRequiredAlignments} when called with the same
 * \p compress_opts.
 * @param device_compressed_chunk_bytes [out] Array with size \p num_chunks,
 * to be filled with the compressed sizes of each chunk.
 * The buffer should be preallocated in device-accessible memory.
 * @param compress_opts [in] Compression options. They must be valid.
 * @param device_statuses [out] Array with size \p num_chunks of statuses in
 * device-accessible memory. This argument needs to be preallocated. For each
 * chunk, if the compression is successful, the status will be set to
 * {@code nvcompSuccess}, and an error code otherwise.
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successfully launched, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedBitcompCompressAsync(
    @Cast("const void*const*") PointerPointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") PointerPointer device_compressed_chunk_ptrs,
    @Cast("size_t*") SizeTPointer device_compressed_chunk_bytes,
    @ByVal nvcompBatchedBitcompCompressOpts_t compress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedBitcompCompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("size_t*") SizeTPointer device_compressed_chunk_bytes,
    @ByVal nvcompBatchedBitcompCompressOpts_t compress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedBitcompCompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("size_t*") SizeTPointer device_compressed_chunk_bytes,
    @ByVal nvcompBatchedBitcompCompressOpts_t compress_opts,
    @Cast("nvcompStatus_t*") IntBuffer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedBitcompCompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("size_t*") SizeTPointer device_compressed_chunk_bytes,
    @ByVal nvcompBatchedBitcompCompressOpts_t compress_opts,
    @Cast("nvcompStatus_t*") int[] device_statuses,
    CUstream_st stream);

/**
 * \brief The most restrictive of the minimum alignment requirements for void-type CUDA memory buffers
 * used for input, output, or temporary memory, passed to decompression functions.
 *
 * \note In all cases, typed memory buffers must still be aligned to their type's size,
 * e.g., 4 bytes for {@code int}.
 */
@MemberGetter public static native @Cast("const size_t") long nvcompBitcompRequiredDecompressionAlignment();
public static final long nvcompBitcompRequiredDecompressionAlignment = nvcompBitcompRequiredDecompressionAlignment();

/**
 * \brief Get the minimum buffer alignment requirements for decompression.
 *
 * \note Providing buffers with alignments above the minimum requirements
 * (e.g., 16- or 32-byte alignment) may help improve performance.
 *
 * @param decompress_opts [in] Decompression options.
 * @param alignment_requirements [out] The minimum buffer alignment requirements
 * for decompression.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedBitcompDecompressGetRequiredAlignments(
    @ByVal nvcompBatchedBitcompDecompressOpts_t decompress_opts,
    nvcompAlignmentRequirements_t alignment_requirements);

/**
 * \brief Get the amount of temporary memory required on the GPU for decompression
 * asynchronously.
 *
 * @param num_chunks [in] Number of chunks of data to be decompressed.
 * @param max_uncompressed_chunk_bytes [in] The size of the largest chunk in bytes
 * when uncompressed.
 * @param decompress_opts [in] Decompression options.
 * @param temp_bytes [out] The amount of GPU memory that will be temporarily required
 * during decompression. The value is returned on the host side.
 * @param max_total_uncompressed_bytes [in]  The total decompressed size of all the chunks.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedBitcompDecompressGetTempSizeAsync(
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedBitcompDecompressOpts_t decompress_opts,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes);

/**
 * \brief Get the amount of temporary memory required on the GPU for decompression
 * synchronously.
 *
 * @param device_compressed_chunk_ptrs [in] Array with size \p num_chunks of pointers
 * in device-accessible memory to device-accessible compressed buffers.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedBitcompDecompressGetRequiredAlignments}.
 * @param device_compressed_chunk_bytes [in] Array with size \p num_chunks of sizes of
 * the compressed buffers in bytes. The sizes should reside in device-accessible memory.
 * @param num_chunks [in] Number of chunks of data to be decompressed.
 * @param max_uncompressed_chunk_bytes [in] The size of the largest chunk in bytes
 * when uncompressed.
 * @param temp_bytes [out] The amount of GPU memory that will be temporarily required
 * during decompression. The value is returned on the host side.
 * @param max_total_uncompressed_bytes [in]  The total decompressed size of all the chunks.
 * Unused in Bitcomp.
 * @param decompress_opts [in] Decompression options.
 * @param device_statuses [out] Array with size \p num_chunks of statuses in
 * device-accessible memory. This argument needs to be preallocated. For each
 * chunk, if the data can be parsed successfully, the status will be set to
 * {@code nvcompSuccess}, and an error code otherwise.
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedBitcompDecompressGetTempSizeSync(
    @Cast("const void*const*const") PointerPointer device_compressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    @ByVal nvcompBatchedBitcompDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedBitcompDecompressGetTempSizeSync(
    @Cast("const void*const*const") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    @ByVal nvcompBatchedBitcompDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedBitcompDecompressGetTempSizeSync(
    @Cast("const void*const*const") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    @ByVal nvcompBatchedBitcompDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntBuffer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedBitcompDecompressGetTempSizeSync(
    @Cast("const void*const*const") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    @ByVal nvcompBatchedBitcompDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") int[] device_statuses,
    CUstream_st stream);

/**
 * \brief Asynchronously compute the number of bytes of uncompressed data for
 * each compressed chunk.
 *
 * \note Violating any of the conditions listed in the parameter descriptions
 * below may result in undefined behaviour.
 *
 * @param device_compressed_chunk_ptrs [in] Array with size \p num_chunks of
 * pointers in device-accessible memory to compressed buffers.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedBitcompDecompressGetRequiredAlignments}.
 * @param device_compressed_chunk_bytes [in] This argument is not used.
 * @param device_uncompressed_chunk_bytes [out] Array with size \p num_chunks
 * to be filled with the sizes, in bytes, of each uncompressed data chunk.
 * If there is an error when retrieving the size of a chunk, the
 * uncompressed size of that chunk will be set to 0. This argument needs to
 * be preallocated in device-accessible memory.
 * @param num_chunks [in] Number of data chunks to compute sizes of.
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedBitcompGetDecompressSizeAsync(
    @Cast("const void*const*") PointerPointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedBitcompGetDecompressSizeAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    CUstream_st stream);

/**
 * \brief Perform batched asynchronous decompression.
 *
 * This function is used to decompress compressed buffers produced by
 * \ref nvcompBatchedBitcompCompressAsync . It can also decompress buffers
 * compressed with the native Bitcomp API.
 *
 * \note Violating any of the conditions listed in the parameter descriptions
 * below may result in undefined behaviour.
 *
 * \note The function is not completely asynchronous, as it needs to look
 * at the compressed data in order to create the proper bitcomp handle.
 * The stream is synchronized, the data is examined, then the asynchronous
 * decompression is launched.
 *
 * \note An asynchronous, faster version of batched Bitcomp asynchrnous decompression
 * is available, and can be launched via the HLIF manager.
 *
 * @param device_compressed_chunk_ptrs [in] Array with size \p num_chunks of pointers
 * in device-accessible memory to device-accessible compressed buffers.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedBitcompDecompressGetRequiredAlignments}.
 * @param device_compressed_chunk_bytes [in] This argument is not used.
 * @param device_uncompressed_buffer_bytes [in] Array with size \p num_chunks of sizes,
 * in bytes, of the output buffers to be filled with uncompressed data for each chunk.
 * The sizes should reside in device-accessible memory. If a
 * size is not large enough to hold all decompressed data, the decompressor
 * will set the status in \p device_statuses corresponding to the
 * overflow chunk to {@code nvcompErrorCannotDecompress}.
 * @param device_uncompressed_chunk_bytes [out] Array with size \p num_chunks to
 * be filled with the actual number of bytes decompressed for every chunk.
 * This argument needs to be preallocated.
 * @param num_chunks [in] Number of chunks of data to decompress.
 * @param device_temp_ptr [in] Temporary scratch memory.
 * @param temp_bytes [in] Size of temporary scratch memory.
 * @param device_uncompressed_chunk_ptrs [out] Array with size \p num_chunks of
 * pointers in device-accessible memory to decompressed data. Each uncompressed
 * buffer needs to be preallocated in device-accessible memory, have the size
 * specified by the corresponding entry in \p device_uncompressed_buffer_bytes,
 * and be aligned to the value in the {@code output} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedBitcompDecompressGetRequiredAlignments}.
 * @param decompress_opts [in] Decompression options.
 * @param device_statuses [out] Array with size \p num_chunks of statuses in
 * device-accessible memory. This argument needs to be preallocated. For each
 * chunk, if the decompression is successful, the status will be set to
 * {@code nvcompSuccess}. If the decompression is not successful, for example due to
 * the corrupted input or out-of-bound errors, the status will be set to
 * {@code nvcompErrorCannotDecompress}.
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successfully launched, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedBitcompDecompressAsync(
    @Cast("const void*const*") PointerPointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("const size_t*") SizeTPointer device_uncompressed_buffer_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") PointerPointer device_uncompressed_chunk_ptrs,
    @ByVal nvcompBatchedBitcompDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedBitcompDecompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("const size_t*") SizeTPointer device_uncompressed_buffer_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @ByVal nvcompBatchedBitcompDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedBitcompDecompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("const size_t*") SizeTPointer device_uncompressed_buffer_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @ByVal nvcompBatchedBitcompDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntBuffer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedBitcompDecompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("const size_t*") SizeTPointer device_uncompressed_buffer_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @ByVal nvcompBatchedBitcompDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") int[] device_statuses,
    CUstream_st stream);

// #ifdef __cplusplus
// #endif

// #endif // NVCOMP_BITCOMP_H


// Parsed from <nvcomp/bitcomp.hpp>

/*
 * SPDX-FileCopyrightText: Copyright (c) 2020-2025 NVIDIA CORPORATION & AFFILIATES.
 * All rights reserved. SPDX-License-Identifier: LicenseRef-NvidiaProprietary
 *
 * NVIDIA CORPORATION, its affiliates and licensors retain all intellectual
 * property and proprietary rights in and to this material, related
 * documentation and any modifications thereto. Any use, reproduction,
 * disclosure or distribution of this material and related documentation
 * without an express license agreement from NVIDIA CORPORATION or
 * its affiliates is strictly prohibited.
*/

// #pragma once

// #include "nvcompManager.hpp"
// #include "bitcomp.h"
// Targeting ../nvcomp/BitcompFormatSpecHeader.java


// Targeting ../nvcomp/BitcompManager.java



 // namespace nvcomp


// Parsed from <nvcomp/cascaded.h>

/*
 * SPDX-FileCopyrightText: Copyright (c) 2017-2025 NVIDIA CORPORATION & AFFILIATES.
 * All rights reserved. SPDX-License-Identifier: LicenseRef-NvidiaProprietary
 *
 * NVIDIA CORPORATION, its affiliates and licensors retain all intellectual
 * property and proprietary rights in and to this material, related
 * documentation and any modifications thereto. Any use, reproduction,
 * disclosure or distribution of this material and related documentation
 * without an express license agreement from NVIDIA CORPORATION or
 * its affiliates is strictly prohibited.
*/

// #ifndef NVCOMP_CASCADED_H
// #define NVCOMP_CASCADED_H

// #include "nvcomp.h"

// #ifdef __cplusplus
// Targeting ../nvcomp/nvcompBatchedCascadedCompressOpts_t.java


// Targeting ../nvcomp/nvcompBatchedCascadedDecompressOpts_t.java



/**
 * \brief Default Cascaded compression options
 */
@MemberGetter public static native @Const @ByRef nvcompBatchedCascadedCompressOpts_t nvcompBatchedCascadedCompressDefaultOpts();

/**
 * \brief Default Cascaded decompression options
 */
@MemberGetter public static native @Const @ByRef nvcompBatchedCascadedDecompressOpts_t nvcompBatchedCascadedDecompressDefaultOpts();

/**
 * \brief The maximum supported uncompressed chunk size in bytes for the Cascaded compressor.
 */
@MemberGetter public static native @Cast("const size_t") long nvcompCascadedCompressionMaxAllowedChunkSize();
public static final long nvcompCascadedCompressionMaxAllowedChunkSize = nvcompCascadedCompressionMaxAllowedChunkSize();

/**
 * \brief The most restrictive of the minimum alignment requirements for void-type CUDA memory buffers
 * used for input, output, or temporary memory, passed to compression functions.
 *
 * \note In all cases, typed memory buffers must still be aligned to their type's size,
 * e.g., 4 bytes for {@code int}.
 */
@MemberGetter public static native @Cast("const size_t") long nvcompCascadedRequiredCompressionAlignment();
public static final long nvcompCascadedRequiredCompressionAlignment = nvcompCascadedRequiredCompressionAlignment();

/**
 * \brief Get the minimum buffer alignment requirements for compression.
 *
 * \note Providing buffers with alignments above the minimum requirements
 * (e.g., 16- or 32-byte alignment) may help improve performance.
 *
 * @param compress_opts [in] Compression options.
 * @param alignment_requirements [out] The minimum buffer alignment requirements
 * for compression.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedCascadedCompressGetRequiredAlignments(
    @ByVal nvcompBatchedCascadedCompressOpts_t compress_opts,
    nvcompAlignmentRequirements_t alignment_requirements);

/**
 * \brief Get the amount of temporary memory required on the GPU for compression
 * asynchronously.
 *
 * @param num_chunks [in] The number of chunks of memory in the batch.
 * @param max_uncompressed_chunk_bytes [in] The maximum size of a chunk in the
 * batch.
 * @param compress_opts [in] Compression options.
 * @param temp_bytes [out] The amount of GPU memory that will be temporarily
 * required during compression. The value is returned on the host side.
 * @param max_total_uncompressed_bytes [in] Upper bound on the total uncompressed
 * size of all chunks
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedCascadedCompressGetTempSizeAsync(
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedCascadedCompressOpts_t compress_opts,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes);

/**
 * \brief Get the amount of temporary memory required on the GPU for compression.
 * synchronously.
 *
 * @param device_uncompressed_chunk_ptrs [in] Array with size \p num_chunks of pointers
 * to the uncompressed data chunks. Both the pointers and the uncompressed data
 * should reside in device-accessible memory.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedCascadedCompressGetRequiredAlignments} when called with the same
 * \p compress_opts.
 * @param device_uncompressed_chunk_bytes [in] Array with size \p num_chunks of
 * sizes of the uncompressed chunks in bytes.
 * The sizes should reside in device-accessible memory.
 * @param num_chunks [in] The number of chunks of memory in the batch.
 * @param max_uncompressed_chunk_bytes [in] The maximum size of a chunk in the
 * batch.
 * @param compress_opts [in] Compression options.
 * @param temp_bytes [out] The amount of GPU memory that will be temporarily
 * required during compression. The value is returned on the host side.
 * @param max_total_uncompressed_bytes [in] Upper bound on the total uncompressed
 * size of all chunks
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedCascadedCompressGetTempSizeSync(
    @Cast("const void*const*const") PointerPointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedCascadedCompressOpts_t compress_opts,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedCascadedCompressGetTempSizeSync(
    @Cast("const void*const*const") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedCascadedCompressOpts_t compress_opts,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    CUstream_st stream);

/**
 * \brief Get the maximum size that a chunk of size at most max_uncompressed_chunk_bytes
 * could compress to. That is, the minimum amount of output memory required to be given
 * \ref nvcompBatchedCascadedCompressAsync for each chunk.
 *
 * @param max_uncompressed_chunk_bytes [in] The maximum size of a chunk before compression.
 * @param compress_opts [in] The Cascaded compression options to use.
 * @param max_compressed_chunk_bytes [out] The maximum possible compressed size of the chunk.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedCascadedCompressGetMaxOutputChunkSize(
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedCascadedCompressOpts_t compress_opts,
    @Cast("size_t*") SizeTPointer max_compressed_chunk_bytes);

/**
 * \brief Perform batched asynchronous compression.
 *
 * \note The current implementation does not support uncompressed size larger
 * than 4,294,967,295 bytes (max uint32_t).
 *
 * \note Violating any of the conditions listed in the parameter descriptions
 * below may result in undefined behaviour.
 *
 * @param device_uncompressed_chunk_ptrs [in] Array with size \p num_chunks of pointers
 * to the uncompressed data chunks. Both the pointers and the uncompressed data
 * should reside in device-accessible memory.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedCascadedCompressGetRequiredAlignments} when called with the same
 * \p compress_opts.
 * @param device_uncompressed_chunk_bytes [in] Array with size \p num_chunks of
 * sizes of the uncompressed chunks in bytes.
 * The sizes should reside in device-accessible memory.
 * Each chunk size must be a multiple of the size of the data type specified by
 * compress_opts.type, else this may crash or produce invalid output.
 * @param max_uncompressed_chunk_bytes [in] The size of the largest uncompressed chunk.
 * This parameter is currently unused. Set it to either the actual value
 * or zero.
 * @param num_chunks [in] Number of chunks of data to compress.
 * @param device_temp_ptr [in] This argument is not used.
 * @param temp_bytes [in] This argument is not used.
 * @param device_compressed_chunk_ptrs [out] Array with size \p num_chunks of pointers
 * to the output compressed buffers. Both the pointers and the compressed
 * buffers should reside in device-accessible memory. Each compressed buffer
 * should be preallocated with the size given by
 * {@code nvcompBatchedCascadedCompressGetMaxOutputChunkSize}.
 * Each compressed buffer must be aligned to the value in the {@code output} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedCascadedCompressGetRequiredAlignments} when called with the same
 * \p compress_opts.
 * @param device_compressed_chunk_bytes [out] Array with size \p num_chunks,
 * to be filled with the compressed sizes of each chunk.
 * The buffer should be preallocated in device-accessible memory.
 * @param compress_opts [in] The cascaded format options. The format must be valid.
 * @param device_statuses [out] Array with size \p num_chunks of statuses in
 * device-accessible memory. This argument needs to be preallocated. For each
 * chunk, if the compression is successful, the status will be set to
 * {@code nvcompSuccess}, and an error code otherwise.
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successfully launched, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedCascadedCompressAsync(
    @Cast("const void*const*") PointerPointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") PointerPointer device_compressed_chunk_ptrs,
    @Cast("size_t*") SizeTPointer device_compressed_chunk_bytes,
    @ByVal nvcompBatchedCascadedCompressOpts_t compress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedCascadedCompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("size_t*") SizeTPointer device_compressed_chunk_bytes,
    @ByVal nvcompBatchedCascadedCompressOpts_t compress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedCascadedCompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("size_t*") SizeTPointer device_compressed_chunk_bytes,
    @ByVal nvcompBatchedCascadedCompressOpts_t compress_opts,
    @Cast("nvcompStatus_t*") IntBuffer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedCascadedCompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("size_t*") SizeTPointer device_compressed_chunk_bytes,
    @ByVal nvcompBatchedCascadedCompressOpts_t compress_opts,
    @Cast("nvcompStatus_t*") int[] device_statuses,
    CUstream_st stream);

/**
 * \brief The most restrictive of the minimum alignment requirements for void-type CUDA memory buffers
 * used for input, output, or temporary memory, passed to decompression functions.
 *
 * \note In all cases, typed memory buffers must still be aligned to their type's size,
 * e.g., 4 bytes for {@code int}.
 */
@MemberGetter public static native @Cast("const size_t") long nvcompCascadedRequiredDecompressionAlignment();
public static final long nvcompCascadedRequiredDecompressionAlignment = nvcompCascadedRequiredDecompressionAlignment();

/**
 * \brief Get the minimum buffer alignment requirements for decompression.
 *
 * \note Providing buffers with alignments above the minimum requirements
 * (e.g., 16- or 32-byte alignment) may help improve performance.
 *
 * @param decompress_opts [in] Decompression options.
 * @param alignment_requirements [out] The minimum buffer alignment requirements
 * for decompression.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedCascadedDecompressGetRequiredAlignments(
    @ByVal nvcompBatchedCascadedDecompressOpts_t decompress_opts,
    nvcompAlignmentRequirements_t alignment_requirements);

/**
 * \brief Get the amount of temporary memory required on the GPU for decompression
 * asynchronously.
 *
 * @param num_chunks [in] Number of chunks of data to be decompressed.
 * @param max_uncompressed_chunk_bytes [in] The size of the largest chunk in bytes
 * when uncompressed.
 * @param decompress_opts [in] Decompression options.
 * @param temp_bytes [out] The amount of GPU memory that will be temporarily required
 * during decompression. The value is returned on the host side.
 * @param max_total_uncompressed_bytes [in] The total decompressed size of all the chunks.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedCascadedDecompressGetTempSizeAsync(
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedCascadedDecompressOpts_t decompress_opts,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes);

/**
 * \brief Get the amount of temporary memory required on the GPU for decompression
 * synchronously.
 *
 * @param device_compressed_chunk_ptrs [in] Array with size \p num_chunks of pointers
 * in device-accessible memory to device-accessible compressed buffers.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedCascadedDecompressGetRequiredAlignments}.
 * @param device_compressed_chunk_bytes [in] Array with size \p num_chunks of sizes of
 * the compressed buffers in bytes. The sizes should reside in device-accessible memory.
 * @param num_chunks [in] Number of chunks of data to be decompressed.
 * @param max_uncompressed_chunk_bytes [in] The size of the largest chunk in bytes
 * when uncompressed.
 * @param temp_bytes [out] The amount of GPU memory that will be temporarily required
 * during decompression. The value is returned on the host side.
 * @param max_total_uncompressed_bytes [in]  The total decompressed size of all the chunks.
 * @param decompress_opts [in] Decompression options.
 * @param device_statuses [out] Array with size \p num_chunks of statuses in
 * device-accessible memory. This argument needs to be preallocated. For each
 * chunk, if the data can be parsed successfully, the status will be set to
 * {@code nvcompSuccess}, and an error code otherwise.
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedCascadedDecompressGetTempSizeSync(
    @Cast("const void*const*const") PointerPointer device_compressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    @ByVal nvcompBatchedCascadedDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedCascadedDecompressGetTempSizeSync(
    @Cast("const void*const*const") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    @ByVal nvcompBatchedCascadedDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedCascadedDecompressGetTempSizeSync(
    @Cast("const void*const*const") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    @ByVal nvcompBatchedCascadedDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntBuffer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedCascadedDecompressGetTempSizeSync(
    @Cast("const void*const*const") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    @ByVal nvcompBatchedCascadedDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") int[] device_statuses,
    CUstream_st stream);

/**
 * \brief Asynchronously compute the number of bytes of uncompressed data for
 * each compressed chunk.
 *
 * \note Violating any of the conditions listed in the parameter descriptions
 * below may result in undefined behaviour.
 *
 * @param device_compressed_chunk_ptrs [in] Array with size \p num_chunks of
 * pointers in device-accessible memory to compressed buffers.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedCascadedDecompressGetRequiredAlignments}.
 * @param device_compressed_chunk_bytes [in] Array with size \p num_chunks of sizes
 * of the compressed buffers in bytes. The sizes should reside in device-accessible memory.
 * @param device_uncompressed_chunk_bytes [out] Array with size \p num_chunks
 * to be filled with the sizes, in bytes, of each uncompressed data chunk.
 * If there is an error when retrieving the size of a chunk, the
 * uncompressed size of that chunk will be set to 0. This argument needs to
 * be preallocated in device-accessible memory.
 * @param num_chunks [in] Number of data chunks to compute sizes of.
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedCascadedGetDecompressSizeAsync(
    @Cast("const void*const*") PointerPointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedCascadedGetDecompressSizeAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    CUstream_st stream);

/**
 * \brief Perform batched asynchronous decompression.
 *
 * This function is used to decompress compressed buffers produced by
 * \ref nvcompBatchedCascadedCompressAsync.
 *
 * \note Violating any of the conditions listed in the parameter descriptions
 * below may result in undefined behaviour.
 *
 * @param device_compressed_chunk_ptrs [in] Array with size \p num_chunks of pointers
 * in device-accessible memory to device-accessible compressed buffers.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedCascadedDecompressGetRequiredAlignments}.
 * @param device_compressed_chunk_bytes [in] Array with size \p num_chunks of sizes of
 * the compressed buffers in bytes. The sizes should reside in device-accessible memory.
 * @param device_uncompressed_buffer_bytes [in] Array with size \p num_chunks of sizes,
 * in bytes, of the output buffers to be filled with uncompressed data for each chunk.
 * The sizes should reside in device-accessible memory. If a
 * size is not large enough to hold all decompressed data, the decompressor
 * will set the status in \p device_statuses corresponding to the
 * overflow chunk to {@code nvcompErrorCannotDecompress}.
 * @param device_uncompressed_chunk_bytes [out] Array with size \p num_chunks to
 * be filled with the actual number of bytes decompressed for every chunk.
 * This argument needs to be preallocated.
 * @param num_chunks [in] Number of chunks of data to decompress.
 * @param device_temp_ptr [in] This argument is not used.
 * @param temp_bytes [in] This argument is not used.
 * @param device_uncompressed_chunk_ptrs [out] Array with size \p num_chunks of
 * pointers in device-accessible memory to decompressed data. Each uncompressed
 * buffer needs to be preallocated in device-accessible memory, have the size
 * specified by the corresponding entry in \p device_uncompressed_buffer_bytes,
 * and be aligned to the value in the {@code output} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedCascadedDecompressGetRequiredAlignments}.
 * @param decompress_opts [in] Decompression options.
 * @param device_statuses [out] Array with size \p num_chunks of statuses in
 * device-accessible memory. This argument needs to be preallocated. For each
 * chunk, if the decompression is successful, the status will be set to
 * {@code nvcompSuccess}. If the decompression is not successful, for example due to
 * the corrupted input or out-of-bound errors, the status will be set to
 * {@code nvcompErrorCannotDecompress}.
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successfully launched, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedCascadedDecompressAsync(
    @Cast("const void*const*") PointerPointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("const size_t*") SizeTPointer device_uncompressed_buffer_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") PointerPointer device_uncompressed_chunk_ptrs,
    @ByVal nvcompBatchedCascadedDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedCascadedDecompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("const size_t*") SizeTPointer device_uncompressed_buffer_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @ByVal nvcompBatchedCascadedDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedCascadedDecompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("const size_t*") SizeTPointer device_uncompressed_buffer_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @ByVal nvcompBatchedCascadedDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntBuffer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedCascadedDecompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("const size_t*") SizeTPointer device_uncompressed_buffer_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @ByVal nvcompBatchedCascadedDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") int[] device_statuses,
    CUstream_st stream);

// #ifdef __cplusplus
// #endif

// #endif // NVCOMP_CASCADED_H


// Parsed from <nvcomp/crc32.h>

/*
 * SPDX-FileCopyrightText: Copyright (c) 2017-2025 NVIDIA CORPORATION & AFFILIATES.
 * All rights reserved. SPDX-License-Identifier: LicenseRef-NvidiaProprietary
 *
 * NVIDIA CORPORATION, its affiliates and licensors retain all intellectual
 * property and proprietary rights in and to this material, related
 * documentation and any modifications thereto. Any use, reproduction,
 * disclosure or distribution of this material and related documentation
 * without an express license agreement from NVIDIA CORPORATION or
 * its affiliates is strictly prohibited.
*/

// #ifndef NVCOMP_CRC32_H
// #define NVCOMP_CRC32_H

// #include "nvcomp.h"

// #ifndef __cplusplus
// #include <stdbool.h>
// #endif

// #ifdef __cplusplus
// Targeting ../nvcomp/nvcompCRC32Spec_t.java



/**
 * \brief Standard CRC32 (aka CRC-32/PKZIP) model preset.
 */
@MemberGetter public static native @Const @ByRef nvcompCRC32Spec_t nvcompCRC32();
/**
 * \brief CRC32-C (aka CRC-32/ISCSI) model preset.
 */
@MemberGetter public static native @Const @ByRef nvcompCRC32Spec_t nvcompCRC32_C();
/**
 * \brief CRC32-D (aka CRC-32/BASE91-D) model preset.
 */
@MemberGetter public static native @Const @ByRef nvcompCRC32Spec_t nvcompCRC32_D();
/**
 * \brief CRC32-Q (aka CRC-32/AIXM) model preset.
 */
@MemberGetter public static native @Const @ByRef nvcompCRC32Spec_t nvcompCRC32_Q();
/**
 * \brief CRC-32/MEF model preset.
 */
@MemberGetter public static native @Const @ByRef nvcompCRC32Spec_t nvcompCRC32_MEF();
/**
 * \brief CRC-32/XFER model preset.
 */
@MemberGetter public static native @Const @ByRef nvcompCRC32Spec_t nvcompCRC32_XFER();
/**
 * \brief CRC-32/BZIP2 (aka CRC-32/AAL-5) model preset.
 */
@MemberGetter public static native @Const @ByRef nvcompCRC32Spec_t nvcompCRC32_BZIP2();
/**
 * \brief CRC-32/POSIX (aka CRC-32/CKSUM) model preset.
 */
@MemberGetter public static native @Const @ByRef nvcompCRC32Spec_t nvcompCRC32_POSIX();
/**
 * \brief CRC-32/JAMCRC model preset.
 */
@MemberGetter public static native @Const @ByRef nvcompCRC32Spec_t nvcompCRC32_JAMCRC();
/**
 * \brief CRC-32/MPEG-2 model preset.
 */
@MemberGetter public static native @Const @ByRef nvcompCRC32Spec_t nvcompCRC32_MPEG_2();
/**
 * \brief CRC-32/AUTOSAR model preset.
 */
@MemberGetter public static native @Const @ByRef nvcompCRC32Spec_t nvcompCRC32_AUTOSAR();
/**
 * \brief CRC-32/CD-ROM-EDC model preset.
 */
@MemberGetter public static native @Const @ByRef nvcompCRC32Spec_t nvcompCRC32_CD_ROM_EDC();

/**
 * \brief Enumeration of kernel kinds for CRC32 computation.
 */
/** enum nvcompCRC32KernelKind_t */
public static final int
  /**
   * \brief Let each warp process its own chunk of input data.
   */
  nvcompCRC32WarpKernel = 0,
  /**
   * \brief Let one or more blocks process each chunk of input data.
   */
  nvcompCRC32BlockKernel = 1;
// Targeting ../nvcomp/nvcompCRC32KernelConf_t.java


// Targeting ../nvcomp/nvcompBatchedCRC32Opts_t.java



/**
 * \brief Enumeration specifying segment types for streaming CRC32 computation.
 */
/** enum nvcompCRC32SegmentKind_t */
public static final int
  /**
   * \brief Single segment (complete message).
   */
  nvcompCRC32OnlySegment = 0,
  /**
   * \brief First segment of a message that may be followed by further segments.
   */
  nvcompCRC32FirstSegment = 1,
  /**
   * \brief Non-first segment of a message that may be followed by further segments.
   */
  nvcompCRC32MidSegment = 2,
  /**
   * \brief Last segment of a message.
   *
   * If the segment is also the first segment, \ref nvcompCRC32OnlySegment
   * should be used instead.
   *
   * This enumerator can also be used to retroactively mark the last processed
   * segment as the last segment of a message. For details, see \ref
   * nvcompBatchedCRC32Async.
   */
  nvcompCRC32LastSegment = 3;

/**
 * \brief Perform CRC32 checksum calculation asynchronously.
 *
 * All pointers must point to device-accessible locations.
 *
 * This function supports streaming CRC32 computation, where the input data
 * might not be visible all at once but only in individual segments. This is
 * controlled by the \p segment_kind parameter. See \ref
 * nvcompCRC32SegmentKind_t for details. If the input data nevertheless is
 * visible all at once,
 * \ref nvcompCRC32OnlySegment should be passed as \p segment_kind. If a segment
 * is processed as if it may be followed by further segments, but it
 * subsequently turns out to have been the last segment, the CRC32 calculation
 * can be finalized by passing a null pointer as \p device_input_chunk_ptrs and
 * \ref nvcompCRC32LastSegment as \p segment_kind.
 *
 * \note The length of a chunk is allowed to be zero. Length-zero chunks may be
 * useful in situations where the number of segments is message-dependent. Rather
 * than having to perform potentially complicated input and output permutations,
 * the missing chunks can be represented as length-zero chunks.
 *
 * @param device_input_chunk_ptrs [in] Array with size \p num_chunks of pointers
 * to the input data chunks. Both the pointers and the input data should reside
 * in device-accessible memory. The data chunks do not have any alignment
 * requirements.
 * @param device_input_chunk_bytes [in] Array with size \p num_chunks of sizes of
 * the input chunks in bytes. The sizes should reside in device-accessible
 * memory.
 * @param num_chunks [in] The number of chunks to compute checksums of.
 * @param device_crc [out] 32_ptr Array with size \p num_chunks on the GPU to be
 * filled with the CRC32 checksum of each chunk.
 * @param opts [in] The CRC32 options.
 * @param segment_kind [in] The \ref nvcompCRC32SegmentKind_t to use.
 * @param device_statuses [out] Array with size \p num_chunks of statuses in
 * device-accessible memory. For each chunk the status will be set to
 * {@code nvcompSuccess} if the CRC32 calculation is successful, or an error code
 * otherwise. Can be NULL if desired, in which case error status is not
 * reported.
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successfully launched, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedCRC32Async(
    @Cast("const void*const*") PointerPointer device_input_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_input_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("uint32_t*") IntPointer device_crc32_ptr,
    @ByVal nvcompBatchedCRC32Opts_t opts,
    @Cast("nvcompCRC32SegmentKind_t") int segment_kind,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedCRC32Async(
    @Cast("const void*const*") @ByPtrPtr Pointer device_input_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_input_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("uint32_t*") IntPointer device_crc32_ptr,
    @ByVal nvcompBatchedCRC32Opts_t opts,
    @Cast("nvcompCRC32SegmentKind_t") int segment_kind,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedCRC32Async(
    @Cast("const void*const*") @ByPtrPtr Pointer device_input_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_input_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("uint32_t*") IntBuffer device_crc32_ptr,
    @ByVal nvcompBatchedCRC32Opts_t opts,
    @Cast("nvcompCRC32SegmentKind_t") int segment_kind,
    @Cast("nvcompStatus_t*") IntBuffer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedCRC32Async(
    @Cast("const void*const*") @ByPtrPtr Pointer device_input_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_input_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("uint32_t*") int[] device_crc32_ptr,
    @ByVal nvcompBatchedCRC32Opts_t opts,
    @Cast("nvcompCRC32SegmentKind_t") int segment_kind,
    @Cast("nvcompStatus_t*") int[] device_statuses,
    CUstream_st stream);

/**
 * \brief Value to pass as \p device_input_chunk_bytes to \ref
 * nvcompBatchedCRC32GetHeuristicConf when specifying the maximum input chunk
 * size in \p max_input_chunk_bytes.
 * 
 * Equal to a null pointer.
 */
@MemberGetter public static native @Cast("const size_t*") SizeTPointer nvcompCRC32IgnoredInputChunkBytes();

/**
 * \brief Value to pass as \p max_input_chunk_bytes to \ref
 * nvcompBatchedCRC32GetHeuristicConf to indicate that max input chunk bytes
 * should be deduced from \p device_input_chunk_bytes.
 * 
 * Equal to 0.
 */
@MemberGetter public static native @Cast("const size_t") long nvcompCRC32DeducedMaxInputChunkBytes();
public static final long nvcompCRC32DeducedMaxInputChunkBytes = nvcompCRC32DeducedMaxInputChunkBytes();

/**
 * \brief Heuristically determine a performant kernel configuration for CRC32
 * computation based on input data characteristics.
 *
 * This function is particularly useful when all chunks are of a similar size,
 * both within and across \ref nvcompBatchedCRC32Async calls. If, in addition,
 * the number of chunks is the same or similar across \ref
 * nvcompBatchedCRC32Async calls, reusing the configuration obtained from this
 * function for all \ref nvcompBatchedCRC32Async calls should work well.
 *
 * The result depends on the GPU model, the number of chunks, and the maximum
 * input chunk size. The latter can be passed directly in \p
 * max_input_chunk_bytes or can be deduced from \p device_input_chunk_bytes.
 * When directly specifying \p max_input_chunk_bytes, \p
 * device_input_chunk_bytes should be passed as \ref
 * nvcompCRC32IgnoredInputChunkBytes or a null pointer. When deducing \p
 * max_input_chunk_bytes from \p device_input_chunk_bytes, \p
 * max_input_chunk_bytes should be set to \ref
 * nvcompCRC32DeducedMaxInputChunkBytes or 0.
 *
 * This function is always synchronous with respect to the host. When directly
 * passing the maximum input chunk size in \p max_input_chunk_bytes, no
 * synchronization with the device happens and \p stream is ignored. When
 * deducing \p max_input_chunk_bytes from \p device_input_chunk_bytes, the
 * function synchronizes with \p stream. On devices that do not support
 * stream-ordered memory allocation, the function synchronizes with the entire
 * device in this case.
 * 
 * @param device_input_chunk_bytes [in] Array with size \p num_chunks of sizes of
 * the input chunks in bytes, residing in device-accessible memory, or \ref
 * nvcompCRC32IgnoredInputChunkBytes if \p max_input_chunk_bytes is directly
 * specified. In the former case, the data chunks do not have any alignment
 * requirements.
 * @param num_chunks [in] The number of chunks to compute checksums of.
 * @param kernel_conf [out] Pointer to the kernel configuration to be filled.
 * @param max_input_chunk_bytes [in] Maximum input chunk size in bytes, or \ref
 * nvcompCRC32DeducedMaxInputChunkBytes to deduce from \p device_input_chunk_bytes.
 * @param stream [in] The CUDA stream to operate on. Ignored if \p
 * max_input_chunk_bytes is directly specified.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedCRC32GetHeuristicConf(
    @Cast("const size_t*") SizeTPointer device_input_chunk_bytes,
    @Cast("size_t") long num_chunks,
    nvcompCRC32KernelConf_t kernel_conf,
    @Cast("size_t") long max_input_chunk_bytes,
    CUstream_st stream);

/**
 * \brief Explicitly search for the optimal CRC32 kernel configuration by
 * benchmarking.
 *
 * In most cases, \ref nvcompBatchedCRC32GetHeuristicConf should provide a
 * sufficiently performant kernel configuration using much less time and fewer
 * resources. When performance is of paramount importance, this function can be
 * used to explicitly search for the optimal kernel configuration. Note that
 * this only makes sense when processing a large number of batches and the
 * number and length of chunks are very similar across batches so that the same
 * kernel configuration can be used.
 * 
 * This function is always synchronous with respect to the host and synchronizes
 * with \p stream. On devices that do not support stream-ordered memory
 * allocation, the function synchronizes with the entire device.
 *
 * @param device_input_chunk_ptrs [in] Array with size \p num_chunks of pointers
 * to the input data chunks in device-accessible memory. The data chunks do not
 * have any alignment requirements.
 * @param device_input_chunk_bytes [in] Array with size \p num_chunks of sizes of
 * the input chunks in bytes, residing in device-accessible memory.
 * @param num_chunks [in] The number of chunks to use for benchmarking.
 * @param device_crc [out] 32_ptr Array with size \p num_chunks on the GPU to be
 * used for benchmark outputs.
 * @param spec [in] The CRC32 specification to use for benchmarking.
 * @param kernel_conf [out] Pointer to the kernel configuration to be filled with
 * optimal settings.
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedCRC32SearchConf(
    @Cast("const void*const*") PointerPointer device_input_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_input_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("uint32_t*") IntPointer device_crc32_ptr,
    @ByVal nvcompCRC32Spec_t spec,
    nvcompCRC32KernelConf_t kernel_conf,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedCRC32SearchConf(
    @Cast("const void*const*") @ByPtrPtr Pointer device_input_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_input_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("uint32_t*") IntPointer device_crc32_ptr,
    @ByVal nvcompCRC32Spec_t spec,
    nvcompCRC32KernelConf_t kernel_conf,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedCRC32SearchConf(
    @Cast("const void*const*") @ByPtrPtr Pointer device_input_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_input_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("uint32_t*") IntBuffer device_crc32_ptr,
    @ByVal nvcompCRC32Spec_t spec,
    nvcompCRC32KernelConf_t kernel_conf,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedCRC32SearchConf(
    @Cast("const void*const*") @ByPtrPtr Pointer device_input_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_input_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("uint32_t*") int[] device_crc32_ptr,
    @ByVal nvcompCRC32Spec_t spec,
    nvcompCRC32KernelConf_t kernel_conf,
    CUstream_st stream);

// #ifdef __cplusplus
// #endif
// #endif // NVCOMP_CRC32_H


// Parsed from <nvcomp/deflate.h>

/*
 * SPDX-FileCopyrightText: Copyright (c) 2017-2025 NVIDIA CORPORATION & AFFILIATES.
 * All rights reserved. SPDX-License-Identifier: LicenseRef-NvidiaProprietary
 *
 * NVIDIA CORPORATION, its affiliates and licensors retain all intellectual
 * property and proprietary rights in and to this material, related
 * documentation and any modifications thereto. Any use, reproduction,
 * disclosure or distribution of this material and related documentation
 * without an express license agreement from NVIDIA CORPORATION or
 * its affiliates is strictly prohibited.
*/

// #ifndef NVCOMP_DEFLATE_H
// #define NVCOMP_DEFLATE_H

// #include "nvcomp.h"

// #ifdef __cplusplus
// Targeting ../nvcomp/nvcompBatchedDeflateCompressOpts_t.java


// Targeting ../nvcomp/nvcompBatchedDeflateDecompressOpts_t.java



/**
 * \brief Default Deflate compression options
 */
@MemberGetter public static native @Const @ByRef nvcompBatchedDeflateCompressOpts_t nvcompBatchedDeflateCompressDefaultOpts();

/**
 * \brief Default Deflate decompression options
 */
@MemberGetter public static native @Const @ByRef nvcompBatchedDeflateDecompressOpts_t nvcompBatchedDeflateDecompressDefaultOpts();

/**
 * \brief The maximum supported uncompressed chunk size in bytes for the Deflate compressor.
 *
 * \note Although chunk sizes up to 2GB are theoretically possible, compression
 * with large chunks may be very slow or use large amounts of temporary memory,
 * so caution is advised when using chunk sizes above 64KB.
 */
@MemberGetter public static native @Cast("const size_t") long nvcompDeflateCompressionMaxAllowedChunkSize();
public static final long nvcompDeflateCompressionMaxAllowedChunkSize = nvcompDeflateCompressionMaxAllowedChunkSize();

/**
 * \brief The most restrictive of the minimum alignment requirements for void-type CUDA memory buffers
 * used for input, output, or temporary memory, passed to compression functions.
 *
 * \note In all cases, typed memory buffers must still be aligned to their type's size,
 * e.g., 4 bytes for {@code int}.
 */
@MemberGetter public static native @Cast("const size_t") long nvcompDeflateRequiredCompressionAlignment();
public static final long nvcompDeflateRequiredCompressionAlignment = nvcompDeflateRequiredCompressionAlignment();

/**
 * \brief Get the minimum buffer alignment requirements for compression.
 *
 * \note Providing buffers with alignments above the minimum requirements
 * (e.g., 16- or 32-byte alignment) may help improve performance.
 *
 * @param compress_opts [in] Compression options.
 * @param alignment_requirements [out] The minimum buffer alignment requirements
 * for compression.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedDeflateCompressGetRequiredAlignments(
    @ByVal nvcompBatchedDeflateCompressOpts_t compress_opts,
    nvcompAlignmentRequirements_t alignment_requirements);

/**
 * \brief Get the amount of temporary memory required on the GPU for compression
 * asynchronously.
 *
 * @param num_chunks [in] The number of chunks of memory in the batch.
 * @param max_uncompressed_chunk_bytes [in] The maximum size of a chunk in the
 * batch.
 * @param compress_opts [in] Compression options.
 * @param temp_bytes [out] The amount of GPU memory that will be temporarily
 * required during compression. The value is returned on the host side.
 * @param max_total_uncompressed_bytes [in] Upper bound on the total uncompressed
 * size of all chunks
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedDeflateCompressGetTempSizeAsync(
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedDeflateCompressOpts_t compress_opts,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes);

/**
 * \brief Get the amount of temporary memory required on the GPU for compression.
 * synchronously.
 *
 * @param device_uncompressed_chunk_ptrs [in] Array with size \p num_chunks of pointers
 * to the uncompressed data chunks. Both the pointers and the uncompressed data
 * should reside in device-accessible memory.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedDeflateCompressGetRequiredAlignments} when called with the same
 * \p compress_opts.
 * @param device_uncompressed_chunk_bytes [in] Array with size \p num_chunks of
 * sizes of the uncompressed chunks in bytes.
 * The sizes should reside in device-accessible memory.
 * @param num_chunks [in] The number of chunks of memory in the batch.
 * @param max_uncompressed_chunk_bytes [in] The maximum size of a chunk in the
 * batch.
 * @param compress_opts [in] Compression options.
 * @param temp_bytes [out] The amount of GPU memory that will be temporarily
 * required during compression. The value is returned on the host side.
 * @param max_total_uncompressed_bytes [in] Upper bound on the total uncompressed
 * size of all chunks
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedDeflateCompressGetTempSizeSync(
    @Cast("const void*const*const") PointerPointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedDeflateCompressOpts_t compress_opts,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedDeflateCompressGetTempSizeSync(
    @Cast("const void*const*const") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedDeflateCompressOpts_t compress_opts,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    CUstream_st stream);

/**
 * \brief Get the maximum size that a chunk of size at most max_uncompressed_chunk_bytes
 * could compress to. That is, the minimum amount of output memory required to be given
 * \ref nvcompBatchedDeflateCompressAsync for each chunk.
 *
 * \note For best performance, a chunk size of 65536 bytes is recommended.
 *
 * @param max_uncompressed_chunk_bytes [in] The maximum size of a chunk before compression.
 * @param compress_opts [in] The Deflate compression options to use.
 * @param max_compressed_chunk_bytes [out] The maximum possible compressed size of the chunk.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedDeflateCompressGetMaxOutputChunkSize(
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedDeflateCompressOpts_t compress_opts,
    @Cast("size_t*") SizeTPointer max_compressed_chunk_bytes);

/**
 * \brief Perform batched asynchronous compression.
 *
 * \note For best performance, a chunk size of 65536 bytes is recommended.
 * Violating any of the conditions listed in the parameter descriptions
 * below may result in undefined behaviour.
 *
 * @param device_uncompressed_chunk_ptrs [in] Array with size \p num_chunks of pointers
 * to the uncompressed data chunks. Both the pointers and the uncompressed data
 * should reside in device-accessible memory.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedDeflateCompressGetRequiredAlignments} when called with the same
 * \p compress_opts.
 * @param device_uncompressed_chunk_bytes [in] Array with size \p num_chunks of
 * sizes of the uncompressed chunks in bytes.
 * The sizes should reside in device-accessible memory.
 * Chunk sizes must not exceed 65536 bytes. For best performance, a chunk size
 * of 65536 bytes is recommended.
 * @param max_uncompressed_chunk_bytes [in] The size of the largest uncompressed chunk.
 * @param num_chunks [in] Number of chunks of data to compress.
 * @param device_temp_ptr [in] The temporary GPU workspace.
 * Must be aligned to the value in the {@code temp} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedDeflateCompressGetRequiredAlignments} when called with the same
 * \p compress_opts.
 * @param temp_bytes [in] The size of the temporary GPU memory pointed to by
 * {@code device_temp_ptr}.
 * @param device_compressed_chunk_ptrs [out] Array with size \p num_chunks of pointers
 * to the output compressed buffers. Both the pointers and the compressed
 * buffers should reside in device-accessible memory. Each compressed buffer
 * should be preallocated with the size given by
 * {@code nvcompBatchedDeflateCompressGetMaxOutputChunkSize}.
 * Each compressed buffer must be aligned to the value in the {@code output} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedDeflateCompressGetRequiredAlignments} when called with the same
 * \p compress_opts.
 * @param device_compressed_chunk_bytes [out] Array with size \p num_chunks,
 * to be filled with the compressed sizes of each chunk.
 * The buffer should be preallocated in device-accessible memory.
 * @param compress_opts [in] The Deflate compression options to use.
 * @param device_statuses [out] Array with size \p num_chunks of statuses in
 * device-accessible memory. This argument needs to be preallocated. For each
 * chunk, if the compression is successful, the status will be set to
 * {@code nvcompSuccess}, and an error code otherwise.
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successfully launched, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedDeflateCompressAsync(
    @Cast("const void*const*") PointerPointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") PointerPointer device_compressed_chunk_ptrs,
    @Cast("size_t*") SizeTPointer device_compressed_chunk_bytes,
    @ByVal nvcompBatchedDeflateCompressOpts_t compress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedDeflateCompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("size_t*") SizeTPointer device_compressed_chunk_bytes,
    @ByVal nvcompBatchedDeflateCompressOpts_t compress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedDeflateCompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("size_t*") SizeTPointer device_compressed_chunk_bytes,
    @ByVal nvcompBatchedDeflateCompressOpts_t compress_opts,
    @Cast("nvcompStatus_t*") IntBuffer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedDeflateCompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("size_t*") SizeTPointer device_compressed_chunk_bytes,
    @ByVal nvcompBatchedDeflateCompressOpts_t compress_opts,
    @Cast("nvcompStatus_t*") int[] device_statuses,
    CUstream_st stream);

/**
 * \brief The most restrictive of the minimum alignment requirements for void-type CUDA memory buffers
 * used for input, output, or temporary memory, passed to decompression functions.
 *
 * \note In all cases, typed memory buffers must still be aligned to their type's size,
 * e.g., 4 bytes for {@code int}.
 */
@MemberGetter public static native @Cast("const size_t") long nvcompDeflateRequiredDecompressionAlignment();
public static final long nvcompDeflateRequiredDecompressionAlignment = nvcompDeflateRequiredDecompressionAlignment();

/**
 * \brief Get the minimum buffer alignment requirements for decompression.
 *
 * \note Providing buffers with alignments above the minimum requirements
 * (e.g., 16- or 32-byte alignment) may help improve performance.
 *
 * @param decompress_opts [in] Decompression options.
 * @param alignment_requirements [out] The minimum buffer alignment requirements
 * for decompression.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedDeflateDecompressGetRequiredAlignments(
    @ByVal nvcompBatchedDeflateDecompressOpts_t decompress_opts,
    nvcompAlignmentRequirements_t alignment_requirements);

/**
 * \brief Get the amount of temporary memory required on the GPU for decompression
 * asynchronously.
 *
 * @param num_chunks [in] Number of chunks of data to be decompressed.
 * @param max_uncompressed_chunk_bytes [in] The size of the largest chunk in bytes
 * when uncompressed.
 * @param decompress_opts [in] Decompression options.
 * @param temp_bytes [out] The amount of GPU memory that will be temporarily required
 * during decompression. The value is returned on the host side.
 * @param max_total_uncompressed_bytes [in] The total decompressed size of all the chunks.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedDeflateDecompressGetTempSizeAsync(
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedDeflateDecompressOpts_t decompress_opts,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes);

/**
 * \brief Get the amount of temporary memory required on the GPU for decompression
 * synchronously.
 *
 * @param device_compressed_chunk_ptrs [in] Array with size \p num_chunks of pointers
 * in device-accessible memory to device-accessible compressed buffers.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedDeflateDecompressGetRequiredAlignments}.
 * @param device_compressed_chunk_bytes [in] Array with size \p num_chunks of sizes of
 * the compressed buffers in bytes. The sizes should reside in device-accessible memory.
 * @param num_chunks [in] Number of chunks of data to be decompressed.
 * @param max_uncompressed_chunk_bytes [in] The size of the largest chunk in bytes
 * when uncompressed.
 * @param temp_bytes [out] The amount of GPU memory that will be temporarily required
 * during decompression. The value is returned on the host side.
 * @param max_total_uncompressed_bytes [in]  The total decompressed size of all the chunks.
 * @param decompress_opts [in] Decompression options.
 * @param device_statuses [out] Array with size \p num_chunks of statuses in
 * device-accessible memory. This argument needs to be preallocated. For each
 * chunk, if the data can be parsed successfully, the status will be set to
 * {@code nvcompSuccess}, and an error code otherwise.
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedDeflateDecompressGetTempSizeSync(
    @Cast("const void*const*const") PointerPointer device_compressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    @ByVal nvcompBatchedDeflateDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedDeflateDecompressGetTempSizeSync(
    @Cast("const void*const*const") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    @ByVal nvcompBatchedDeflateDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedDeflateDecompressGetTempSizeSync(
    @Cast("const void*const*const") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    @ByVal nvcompBatchedDeflateDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntBuffer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedDeflateDecompressGetTempSizeSync(
    @Cast("const void*const*const") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    @ByVal nvcompBatchedDeflateDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") int[] device_statuses,
    CUstream_st stream);

/**
 * \brief Asynchronously compute the number of bytes of uncompressed data for
 * each compressed chunk.
 *
 * This is needed when we do not know the expected output size.
 *
 * \note If the stream is corrupt, the calculated sizes will be invalid.
 *
 * \note Violating any of the conditions listed in the parameter descriptions
 * below may result in undefined behaviour.
 *
 * @param device_compressed_chunk_ptrs [in] Array with size \p num_chunks of
 * pointers in device-accessible memory to compressed buffers.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedDeflateDecompressGetRequiredAlignments}.
 * @param device_compressed_chunk_bytes [in] Array with size \p num_chunks of sizes
 * of the compressed buffers in bytes. The sizes should reside in device-accessible memory.
 * @param device_uncompressed_chunk_bytes [out] Array with size \p num_chunks
 * to be filled with the sizes, in bytes, of each uncompressed data chunk.
 * @param num_chunks [in] Number of data chunks to compute sizes of.
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedDeflateGetDecompressSizeAsync(
    @Cast("const void*const*") PointerPointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedDeflateGetDecompressSizeAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    CUstream_st stream);

/**
 * \brief Perform batched asynchronous decompression.
 *
 * \note Violating any of the conditions listed in the parameter descriptions
 * below may result in undefined behaviour.
 *
 * @param device_compressed_chunk_ptrs [in] Array with size \p num_chunks of pointers
 * in device-accessible memory to device-accessible compressed buffers.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedDeflateDecompressGetRequiredAlignments}.
 * @param device_compressed_chunk_bytes [in] Array with size \p num_chunks of sizes of
 * the compressed buffers in bytes. The sizes should reside in device-accessible memory.
 * @param device_uncompressed_buffer_bytes [in] Array with size \p num_chunks of sizes,
 * in bytes, of the output buffers to be filled with uncompressed data for each chunk.
 * The sizes should reside in device-accessible memory. If a
 * size is not large enough to hold all decompressed data, the decompressor
 * will set the status in \p device_statuses corresponding to the
 * overflow chunk to {@code nvcompErrorCannotDecompress}.
 * @param device_uncompressed_chunk_bytes [out] Array with size \p num_chunks to
 * be filled with the actual number of bytes decompressed for every chunk.
 * This argument needs to be preallocated.
 * When {@code NVCOMP_DECOMPRESS_BACKEND_HARDWARE} is specified in \p decompress_opts.backend,
 * this parameter is required. For {@code NVCOMP_DECOMPRESS_BACKEND_CUDA}, it is optional
 * and may be set to NULL if reporting the actual sizes is not necessary.
 * @param num_chunks [in] Number of chunks of data to decompress.
 * @param device_temp_ptr [in] The temporary GPU space.
 * Must be aligned to the value in the {@code temp} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedDeflateDecompressGetRequiredAlignments}.
 * @param temp_bytes [in] The size of the temporary GPU space.
 * @param device_uncompressed_chunk_ptrs [out] Array with size \p num_chunks of
 * pointers in device-accessible memory to decompressed data. Each uncompressed
 * buffer needs to be preallocated in device-accessible memory, have the size
 * specified by the corresponding entry in \p device_uncompressed_buffer_bytes,
 * and be aligned to the value in the {@code output} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedDeflateDecompressGetRequiredAlignments}.
 * @param decompress_opts [in] Decompression options.
 * @param device_statuses [out] Array with size \p num_chunks of statuses in
 * device-accessible memory. This argument needs to be preallocated. For each
 * chunk, if the decompression is successful, the status will be set to
 * {@code nvcompSuccess}. If the decompression is not successful, for example due to
 * the corrupted input or out-of-bound errors, the status will be set to
 * {@code nvcompErrorCannotDecompress}.
 * Can be NULL if desired, in which case error status is not reported.
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successfully launched, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedDeflateDecompressAsync(
    @Cast("const void*const*") PointerPointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("const size_t*") SizeTPointer device_uncompressed_buffer_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") PointerPointer device_uncompressed_chunk_ptrs,
    @ByVal nvcompBatchedDeflateDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedDeflateDecompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("const size_t*") SizeTPointer device_uncompressed_buffer_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @ByVal nvcompBatchedDeflateDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedDeflateDecompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("const size_t*") SizeTPointer device_uncompressed_buffer_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @ByVal nvcompBatchedDeflateDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntBuffer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedDeflateDecompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("const size_t*") SizeTPointer device_uncompressed_buffer_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @ByVal nvcompBatchedDeflateDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") int[] device_statuses,
    CUstream_st stream);

// #ifdef __cplusplus
// #endif

// #endif // NVCOMP_DEFLATE_H


// Parsed from <nvcomp/deflate.hpp>

/*
 * SPDX-FileCopyrightText: Copyright (c) 2020-2025 NVIDIA CORPORATION & AFFILIATES.
 * All rights reserved. SPDX-License-Identifier: LicenseRef-NvidiaProprietary
 *
 * NVIDIA CORPORATION, its affiliates and licensors retain all intellectual
 * property and proprietary rights in and to this material, related
 * documentation and any modifications thereto. Any use, reproduction,
 * disclosure or distribution of this material and related documentation
 * without an express license agreement from NVIDIA CORPORATION or
 * its affiliates is strictly prohibited.
*/

// #pragma once

// #include "nvcompManager.hpp"
// #include "deflate.h"
// Targeting ../nvcomp/DeflateFormatSpecHeader.java


// Targeting ../nvcomp/DeflateManager.java



 // namespace nvcomp


// Parsed from <nvcomp/gdeflate.h>

/*
 * SPDX-FileCopyrightText: Copyright (c) 2017-2025 NVIDIA CORPORATION & AFFILIATES.
 * All rights reserved. SPDX-License-Identifier: LicenseRef-NvidiaProprietary
 *
 * NVIDIA CORPORATION, its affiliates and licensors retain all intellectual
 * property and proprietary rights in and to this material, related
 * documentation and any modifications thereto. Any use, reproduction,
 * disclosure or distribution of this material and related documentation
 * without an express license agreement from NVIDIA CORPORATION or
 * its affiliates is strictly prohibited.
*/

// #ifndef NVCOMP_GDEFLATE_H
// #define NVCOMP_GDEFLATE_H

// #include "nvcomp.h"

// #ifdef __cplusplus
// Targeting ../nvcomp/nvcompBatchedGdeflateCompressOpts_t.java


// Targeting ../nvcomp/nvcompBatchedGdeflateDecompressOpts_t.java



/**
 * \brief Default Gdeflate compression options
 */
@MemberGetter public static native @Const @ByRef nvcompBatchedGdeflateCompressOpts_t nvcompBatchedGdeflateCompressDefaultOpts();

/**
 * \brief Default Gdeflate decompression options
 */
@MemberGetter public static native @Const @ByRef nvcompBatchedGdeflateDecompressOpts_t nvcompBatchedGdeflateDecompressDefaultOpts();

/**
 * \brief The maximum supported uncompressed chunk size in bytes for the Gdeflate compressor.
 *
 * \note Although chunk sizes up to 2GB are theoretically possible, compression
 * with large chunks may be very slow or use large amounts of temporary memory,
 * so caution is advised when using chunk sizes above 64KB.
 */
@MemberGetter public static native @Cast("const size_t") long nvcompGdeflateCompressionMaxAllowedChunkSize();
public static final long nvcompGdeflateCompressionMaxAllowedChunkSize = nvcompGdeflateCompressionMaxAllowedChunkSize();

/**
 * \brief The most restrictive of the minimum alignment requirements for void-type CUDA memory buffers
 * used for input, output, or temporary memory, passed to compression functions.
 *
 * \note In all cases, typed memory buffers must still be aligned to their type's size,
 * e.g., 4 bytes for {@code int}.
 */
@MemberGetter public static native @Cast("const size_t") long nvcompGdeflateRequiredCompressionAlignment();
public static final long nvcompGdeflateRequiredCompressionAlignment = nvcompGdeflateRequiredCompressionAlignment();

/**
 * \brief Get the minimum buffer alignment requirements for compression.
 *
 * \note Providing buffers with alignments above the minimum requirements
 * (e.g., 16- or 32-byte alignment) may help improve performance.
 *
 * @param compress_opts [in] Compression options.
 * @param alignment_requirements [out] The minimum buffer alignment requirements
 * for compression.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedGdeflateCompressGetRequiredAlignments(
    @ByVal nvcompBatchedGdeflateCompressOpts_t compress_opts,
    nvcompAlignmentRequirements_t alignment_requirements);

/**
 * \brief Get the amount of temporary memory required on the GPU for compression
 * asynchronously.
 *
 * \note For best performance, a chunk size of 65536 bytes is recommended.
 *
 * @param num_chunks [in] The number of chunks of memory in the batch.
 * @param max_uncompressed_chunk_bytes [in] The maximum size of a chunk in the
 * batch.
 * @param compress_opts [in] Compression options.
 * @param temp_bytes [out] The amount of GPU memory that will be temporarily
 * required during compression. The value is returned on the host side.
 * @param max_total_uncompressed_bytes [in] Upper bound on the total uncompressed
 * size of all chunks
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedGdeflateCompressGetTempSizeAsync(
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedGdeflateCompressOpts_t compress_opts,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes);

/**
 * \brief Get the amount of temporary memory required on the GPU for compression.
 * synchronously.
 *
 * \note For best performance, a chunk size of 65536 bytes is recommended.
 *
 * @param device_uncompressed_chunk_ptrs [in] Array with size \p num_chunks of pointers
 * to the uncompressed data chunks. Both the pointers and the uncompressed data
 * should reside in device-accessible memory.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedGdeflateCompressGetRequiredAlignments} when called with the same
 * \p compress_opts.
 * @param device_uncompressed_chunk_bytes [in] Array with size \p num_chunks of
 * sizes of the uncompressed chunks in bytes.
 * The sizes should reside in device-accessible memory.
 * @param num_chunks [in] The number of chunks of memory in the batch.
 * @param max_uncompressed_chunk_bytes [in] The maximum size of a chunk in the
 * batch.
 * @param compress_opts [in] Compression options.
 * @param temp_bytes [out] The amount of GPU memory that will be temporarily
 * required during compression. The value is returned on the host side.
 * @param max_total_uncompressed_bytes [in] Upper bound on the total uncompressed
 * size of all chunks
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedGdeflateCompressGetTempSizeSync(
    @Cast("const void*const*const") PointerPointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedGdeflateCompressOpts_t compress_opts,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedGdeflateCompressGetTempSizeSync(
    @Cast("const void*const*const") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedGdeflateCompressOpts_t compress_opts,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    CUstream_st stream);

/**
 * \brief Get the maximum size that a chunk of size at most max_uncompressed_chunk_bytes
 * could compress to. That is, the minimum amount of output memory required to be given
 * \ref nvcompBatchedGdeflateCompressAsync for each chunk.
 *
 * \note For best performance, a chunk size of 65536 bytes is recommended.
 *
 * @param max_uncompressed_chunk_bytes [in] The maximum size of a chunk before compression.
 * @param compress_opts [in] The GDeflate compression options to use.
 * @param max_compressed_chunk_bytes [out] The maximum possible compressed size of the chunk.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedGdeflateCompressGetMaxOutputChunkSize(
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedGdeflateCompressOpts_t compress_opts,
    @Cast("size_t*") SizeTPointer max_compressed_chunk_bytes);

/**
 * \brief Perform batched asynchronous compression.
 *
 * \note For best performance, a chunk size of 65536 bytes is recommended.
 * Violating any of the conditions listed in the parameter descriptions
 * below may result in undefined behaviour.
 *
 * @param device_uncompressed_chunk_ptrs [in] Array with size \p num_chunks of pointers
 * to the uncompressed data chunks. Both the pointers and the uncompressed data
 * should reside in device-accessible memory.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedGdeflateCompressGetRequiredAlignments} when called with the same
 * \p compress_opts.
 * @param device_uncompressed_chunk_bytes [in] Array with size \p num_chunks of
 * sizes of the uncompressed chunks in bytes.
 * The sizes should reside in device-accessible memory.
 * Chunk sizes must not exceed 65536 bytes. For best performance, a chunk size
 * of 65536 bytes is recommended.
 * @param max_uncompressed_chunk_bytes [in] The size of the largest uncompressed chunk.
 * @param num_chunks [in] Number of chunks of data to compress.
 * @param device_temp_ptr [in] The temporary GPU workspace.
 * Must be aligned to the value in the {@code temp} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedGdeflateCompressGetRequiredAlignments} when called with the same
 * \p compress_opts.
 * @param temp_bytes [in] The size of the temporary GPU memory pointed to by
 * {@code device_temp_ptr}.
 * @param device_compressed_chunk_ptrs [out] Array with size \p num_chunks of pointers
 * to the output compressed buffers. Both the pointers and the compressed
 * buffers should reside in device-accessible memory. Each compressed buffer
 * should be preallocated with the size given by
 * {@code nvcompBatchedGdeflateCompressGetMaxOutputChunkSize}.
 * Each compressed buffer must be aligned to the value in the {@code output} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedGdeflateCompressGetRequiredAlignments} when called with the same
 * \p compress_opts.
 * @param device_compressed_chunk_bytes [out] Array with size \p num_chunks,
 * to be filled with the compressed sizes of each chunk.
 * The buffer should be preallocated in device-accessible memory.
 * @param compress_opts [in] The GDeflate compression options to use.
 * @param device_statuses [out] Array with size \p num_chunks of statuses in
 * device-accessible memory. This argument needs to be preallocated. For each
 * chunk, if the compression is successful, the status will be set to
 * {@code nvcompSuccess}, and an error code otherwise.
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successfully launched, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedGdeflateCompressAsync(
    @Cast("const void*const*") PointerPointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") PointerPointer device_compressed_chunk_ptrs,
    @Cast("size_t*") SizeTPointer device_compressed_chunk_bytes,
    @ByVal nvcompBatchedGdeflateCompressOpts_t compress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedGdeflateCompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("size_t*") SizeTPointer device_compressed_chunk_bytes,
    @ByVal nvcompBatchedGdeflateCompressOpts_t compress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedGdeflateCompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("size_t*") SizeTPointer device_compressed_chunk_bytes,
    @ByVal nvcompBatchedGdeflateCompressOpts_t compress_opts,
    @Cast("nvcompStatus_t*") IntBuffer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedGdeflateCompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("size_t*") SizeTPointer device_compressed_chunk_bytes,
    @ByVal nvcompBatchedGdeflateCompressOpts_t compress_opts,
    @Cast("nvcompStatus_t*") int[] device_statuses,
    CUstream_st stream);

/**
 * \brief The most restrictive of the minimum alignment requirements for void-type CUDA memory buffers
 * used for input, output, or temporary memory, passed to decompression functions.
 *
 * \note In all cases, typed memory buffers must still be aligned to their type's size,
 * e.g., 4 bytes for {@code int}.
 */
@MemberGetter public static native @Cast("const size_t") long nvcompGdeflateRequiredDecompressionAlignment();
public static final long nvcompGdeflateRequiredDecompressionAlignment = nvcompGdeflateRequiredDecompressionAlignment();

/**
 * \brief Get the minimum buffer alignment requirements for decompression.
 *
 * \note Providing buffers with alignments above the minimum requirements
 * (e.g., 16- or 32-byte alignment) may help improve performance.
 *
 * @param decompress_opts [in] Decompression options.
 * @param alignment_requirements [out] The minimum buffer alignment requirements
 * for decompression.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedGdeflateDecompressGetRequiredAlignments(
    @ByVal nvcompBatchedGdeflateDecompressOpts_t decompress_opts,
    nvcompAlignmentRequirements_t alignment_requirements);

/**
 * \brief Get the amount of temporary memory required on the GPU for decompression
 * asynchronously.
 *
 * @param num_chunks [in] Number of chunks of data to be decompressed.
 * @param max_uncompressed_chunk_bytes [in] The size of the largest chunk in bytes
 * when uncompressed.
 * @param decompress_opts [in] Decompression options.
 * @param temp_bytes [out] The amount of GPU memory that will be temporarily required
 * during decompression. The value is returned on the host side.
 * @param max_total_uncompressed_bytes [in] The total decompressed size of all the chunks.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedGdeflateDecompressGetTempSizeAsync(
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedGdeflateDecompressOpts_t decompress_opts,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes);

/**
 * \brief Get the amount of temporary memory required on the GPU for decompression
 * synchronously.
 *
 * @param device_compressed_chunk_ptrs [in] Array with size \p num_chunks of pointers
 * in device-accessible memory to device-accessible compressed buffers.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedGdeflateDecompressGetRequiredAlignments}.
 * @param device_compressed_chunk_bytes [in] Array with size \p num_chunks of sizes of
 * the compressed buffers in bytes. The sizes should reside in device-accessible memory.
 * @param num_chunks [in] Number of chunks of data to be decompressed.
 * @param max_uncompressed_chunk_bytes [in] The size of the largest chunk in bytes
 * when uncompressed.
 * @param temp_bytes [out] The amount of GPU memory that will be temporarily required
 * during decompression. The value is returned on the host side.
 * @param max_total_uncompressed_bytes [in]  The total decompressed size of all the chunks.
 * @param decompress_opts [in] Decompression options.
 * @param device_statuses [out] Array with size \p num_chunks of statuses in
 * device-accessible memory. This argument needs to be preallocated. For each
 * chunk, if the data can be parsed successfully, the status will be set to
 * {@code nvcompSuccess}, and an error code otherwise.
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedGdeflateDecompressGetTempSizeSync(
    @Cast("const void*const*const") PointerPointer device_compressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    @ByVal nvcompBatchedGdeflateDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedGdeflateDecompressGetTempSizeSync(
    @Cast("const void*const*const") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    @ByVal nvcompBatchedGdeflateDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedGdeflateDecompressGetTempSizeSync(
    @Cast("const void*const*const") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    @ByVal nvcompBatchedGdeflateDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntBuffer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedGdeflateDecompressGetTempSizeSync(
    @Cast("const void*const*const") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    @ByVal nvcompBatchedGdeflateDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") int[] device_statuses,
    CUstream_st stream);

/**
 * \brief Asynchronously compute the number of bytes of uncompressed data for
 * each compressed chunk.
 *
 * This is needed when we do not know the expected output size.
 *
 * \note If the stream is corrupt, the calculated sizes will be invalid.
 *
 * \note Violating any of the conditions listed in the parameter descriptions
 * below may result in undefined behaviour.
 *
 * @param device_compressed_chunk_ptrs [in] Array with size \p num_chunks of
 * pointers in device-accessible memory to compressed buffers.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedGdeflateDecompressGetRequiredAlignments}.
 * @param device_compressed_chunk_bytes [in] Array with size \p num_chunks of sizes
 * of the compressed buffers in bytes. The sizes should reside in device-accessible memory.
 * @param device_uncompressed_chunk_bytes [out] Array with size \p num_chunks
 * to be filled with the sizes, in bytes, of each uncompressed data chunk.
 * @param num_chunks [in] Number of data chunks to compute sizes of.
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedGdeflateGetDecompressSizeAsync(
    @Cast("const void*const*") PointerPointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedGdeflateGetDecompressSizeAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    CUstream_st stream);

/**
 * \brief Perform batched asynchronous decompression.
 *
 * \note Violating any of the conditions listed in the parameter descriptions
 * below may result in undefined behaviour.
 *
 * \note In the case where a chunk of compressed data is not a valid GDeflate
 * stream, 0 will be written for the size of the invalid chunk and
 * nvcompStatusCannotDecompress will be flagged for that chunk.
 *
 * @param device_compressed_chunk_ptrs [in] Array with size \p num_chunks of pointers
 * in device-accessible memory to device-accessible compressed buffers.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedGdeflateDecompressGetRequiredAlignments}.
 * @param device_compressed_chunk_bytes [in] Array with size \p num_chunks of sizes of
 * the compressed buffers in bytes. The sizes should reside in device-accessible memory.
 * @param device_uncompressed_buffer_bytes [in] Array with size \p num_chunks of sizes,
 * in bytes, of the output buffers to be filled with uncompressed data for each chunk.
 * The sizes should reside in device-accessible memory. If a
 * size is not large enough to hold all decompressed data, the decompressor
 * will set the status in \p device_statuses corresponding to the
 * overflow chunk to {@code nvcompErrorCannotDecompress}.
 * @param device_uncompressed_chunk_bytes [out] Array with size \p num_chunks to
 * be filled with the actual number of bytes decompressed for every chunk.
 * This argument needs to be preallocated, but can be NULL if desired,
 * in which case the actual sizes are not reported.
 * @param num_chunks [in] Number of chunks of data to decompress.
 * @param device_temp_ptr [in] The temporary GPU space.
 * Must be aligned to the value in the {@code temp} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedGdeflateDecompressGetRequiredAlignments}.
 * @param temp_bytes [in] The size of the temporary GPU space.
 * @param device_uncompressed_chunk_ptrs [out] Array with size \p num_chunks of
 * pointers in device-accessible memory to decompressed data. Each uncompressed
 * buffer needs to be preallocated in device-accessible memory, have the size
 * specified by the corresponding entry in \p device_uncompressed_buffer_bytes,
 * and be aligned to the value in the {@code output} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedGdeflateDecompressGetRequiredAlignments}.
 * @param decompress_opts [in] Decompression options.
 * @param device_statuses [out] Array with size \p num_chunks of statuses in
 * device-accessible memory. This argument needs to be preallocated. For each
 * chunk, if the decompression is successful, the status will be set to
 * {@code nvcompSuccess}. If the decompression is not successful, for example due to
 * the corrupted input or out-of-bound errors, the status will be set to
 * {@code nvcompErrorCannotDecompress}.
 * Can be NULL if desired, in which case error status is not reported.
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successfully launched, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedGdeflateDecompressAsync(
    @Cast("const void*const*") PointerPointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("const size_t*") SizeTPointer device_uncompressed_buffer_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") PointerPointer device_uncompressed_chunk_ptrs,
    @ByVal nvcompBatchedGdeflateDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedGdeflateDecompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("const size_t*") SizeTPointer device_uncompressed_buffer_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @ByVal nvcompBatchedGdeflateDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedGdeflateDecompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("const size_t*") SizeTPointer device_uncompressed_buffer_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @ByVal nvcompBatchedGdeflateDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntBuffer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedGdeflateDecompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("const size_t*") SizeTPointer device_uncompressed_buffer_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @ByVal nvcompBatchedGdeflateDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") int[] device_statuses,
    CUstream_st stream);

// #ifdef __cplusplus
// #endif

// #endif // NVCOMP_GDEFLATE_H


// Parsed from <nvcomp/gdeflate.hpp>

/*
 * SPDX-FileCopyrightText: Copyright (c) 2022-2025 NVIDIA CORPORATION & AFFILIATES.
 * All rights reserved. SPDX-License-Identifier: LicenseRef-NvidiaProprietary
 *
 * NVIDIA CORPORATION, its affiliates and licensors retain all intellectual
 * property and proprietary rights in and to this material, related
 * documentation and any modifications thereto. Any use, reproduction,
 * disclosure or distribution of this material and related documentation
 * without an express license agreement from NVIDIA CORPORATION or
 * its affiliates is strictly prohibited.
*/

// #pragma once

// #include "nvcompManager.hpp"
// #include "gdeflate.h"
// Targeting ../nvcomp/GdeflateFormatSpecHeader.java


// Targeting ../nvcomp/GdeflateManager.java



 // namespace nvcomp


// Parsed from <nvcomp/gzip.h>

/*
 * SPDX-FileCopyrightText: Copyright (c) 2017-2025 NVIDIA CORPORATION & AFFILIATES.
 * All rights reserved. SPDX-License-Identifier: LicenseRef-NvidiaProprietary
 *
 * NVIDIA CORPORATION, its affiliates and licensors retain all intellectual
 * property and proprietary rights in and to this material, related
 * documentation and any modifications thereto. Any use, reproduction,
 * disclosure or distribution of this material and related documentation
 * without an express license agreement from NVIDIA CORPORATION or
 * its affiliates is strictly prohibited.
*/

// #ifndef NVCOMP_GZIP_H
// #define NVCOMP_GZIP_H

// #include "nvcomp.h"

// #ifdef __cplusplus
// Targeting ../nvcomp/nvcompBatchedGzipCompressOpts_t.java



/**
 * \brief Gzip decompression CUDA algorithm options for the low-level API
 */
/** enum nvcompBatchedGzipDecompressAlgorithm_t */
public static final int
  NVCOMP_GZIP_DECOMPRESS_ALGORITHM_NAIVE = 0,
  NVCOMP_GZIP_DECOMPRESS_ALGORITHM_LOOKAHEAD = 1;
// Targeting ../nvcomp/nvcompBatchedGzipDecompressOpts_t.java



/**
 * \brief Default Gzip compression options
 */
@MemberGetter public static native @Const @ByRef nvcompBatchedGzipCompressOpts_t nvcompBatchedGzipCompressDefaultOpts();

/**
 * \brief Default Gzip decompression options
 */
@MemberGetter public static native @Const @ByRef nvcompBatchedGzipDecompressOpts_t nvcompBatchedGzipDecompressDefaultOpts();

/**
 * \brief Get the amount of temporary memory required on the GPU for compression
 * asynchronously.
 *
 * \note For best performance, a chunk size of 65536 bytes is recommended.
 *
 * @param num_chunks [in] The number of chunks of memory in the batch.
 * @param max_uncompressed_chunk_bytes [in] The maximum size of a chunk in the
 * batch.
 * @param compress_opts [in] Compression options.
 * @param temp_bytes [out] The amount of GPU memory that will be temporarily
 * required during compression. The value is returned on the host side.
 * @param max_total_uncompressed_bytes [in] Upper bound on the total uncompressed
 * size of all chunks
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedGzipCompressGetTempSizeAsync(
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedGzipCompressOpts_t compress_opts,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes);

/**
 * \brief Get the amount of temporary memory required on the GPU for compression.
 * synchronously.
 *
 * @param device_uncompressed_chunk_ptrs [in] Array with size \p num_chunks of pointers
 * to the uncompressed data chunks. Both the pointers and the uncompressed data
 * should reside in device-accessible memory.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedGzipCompressGetRequiredAlignments} when called with the same
 * \p compress_opts.
 * @param device_uncompressed_chunk_bytes [in] Array with size \p num_chunks of
 * sizes of the uncompressed chunks in bytes.
 * The sizes should reside in device-accessible memory.
 * @param num_chunks [in] The number of chunks of memory in the batch.
 * @param max_uncompressed_chunk_bytes [in] The maximum size of a chunk in the
 * batch.
 * @param compress_opts [in] Compression options.
 * @param temp_bytes [out] The amount of GPU memory that will be temporarily
 * required during compression. The value is returned on the host side.
 * @param max_total_uncompressed_bytes [in] Upper bound on the total uncompressed
 * size of all chunks
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedGzipCompressGetTempSizeSync(
    @Cast("const void*const*const") PointerPointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedGzipCompressOpts_t compress_opts,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedGzipCompressGetTempSizeSync(
    @Cast("const void*const*const") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedGzipCompressOpts_t compress_opts,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    CUstream_st stream);

/**
 * \brief Get the maximum size that a chunk of size at most max_uncompressed_chunk_bytes
 * could compress to. That is, the minimum amount of output memory required to be given
 * \ref nvcompBatchedGzipCompressAsync for each chunk.
 *
 * \note For best performance, a chunk size of 65536 bytes is recommended.
 *
 * @param max_uncompressed_chunk_bytes [in] The maximum size of a chunk before compression.
 * @param compress_opts [in] The Gzip compression options to use.
 * @param max_compressed_chunk_bytes [out] The maximum possible compressed size of the chunk.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */


/**
 * \brief Perform batched asynchronous compression.
 *
 * \note For best performance, a chunk size of 65536 bytes is recommended.
 * Violating any of the conditions listed in the parameter descriptions
 * below may result in undefined behaviour.
 *
 * @param device_uncompressed_chunk_ptrs [in] Array with size \p num_chunks of pointers
 * to the uncompressed data chunks. Both the pointers and the uncompressed data
 * should reside in device-accessible memory.
 * @param device_uncompressed_chunk_bytes [in] Array with size \p num_chunks of
 * sizes of the uncompressed chunks in bytes.
 * The sizes should reside in device-accessible memory.
 * @param max_uncompressed_chunk_bytes [in] The size of the largest uncompressed chunk.
 * @param num_chunks [in] Number of chunks of data to compress.
 * @param device_temp_ptr [in] The temporary GPU workspace.
 * @param temp_bytes [in] The size of the temporary GPU memory pointed to by
 * {@code device_temp_ptr}.
 * @param device_compressed_chunk_ptrs [out] Array with size \p num_chunks of pointers
 * to the output compressed buffers. Both the pointers and the compressed
 * buffers should reside in device-accessible memory. Each compressed buffer
 * should be preallocated with the size given by
 * {@code nvcompBatchedGzipCompressGetMaxOutputChunkSize}.
 * @param device_compressed_chunk_bytes [out] Array with size \p num_chunks,
 * to be filled with the compressed sizes of each chunk.
 * The buffer should be preallocated in device-accessible memory.
 * @param compress_opts [in] The Gzip compression options to use.
 * @param device_statuses [out] Array with size \p num_chunks of statuses in
 * device-accessible memory. This argument needs to be preallocated. For each
 * chunk, if the compression is successful, the status will be set to
 * {@code nvcompSuccess}, and an error code otherwise.
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successfully launched, and an error code otherwise.
 */


/**
 * \brief The most restrictive of the minimum alignment requirements for void-type CUDA memory buffers
 * used for input, output, or temporary memory, passed to decompression functions.
 *
 * \note In all cases, typed memory buffers must still be aligned to their type's size,
 * e.g., 4 bytes for {@code int}.
 */
@MemberGetter public static native @Cast("const size_t") long nvcompGzipRequiredDecompressionAlignment();
public static final long nvcompGzipRequiredDecompressionAlignment = nvcompGzipRequiredDecompressionAlignment();

/**
 * \brief Get the minimum buffer alignment requirements for decompression.
 *
 * \note Providing buffers with alignments above the minimum requirements
 * (e.g., 16- or 32-byte alignment) may help improve performance.
 *
 * @param decompress_opts [in] Decompression options.
 * @param alignment_requirements [out] The minimum buffer alignment requirements
 * for decompression.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedGzipDecompressGetRequiredAlignments(
    @ByVal nvcompBatchedGzipDecompressOpts_t decompress_opts,
    nvcompAlignmentRequirements_t alignment_requirements);

/**
 * \brief Get the amount of temporary memory required on the GPU for decompression
 * asynchronously.
 *
 * @param num_chunks [in] Number of chunks of data to be decompressed.
 * @param max_uncompressed_chunk_bytes [in] The size of the largest chunk in bytes
 * when uncompressed.
 * @param decompress_opts [in] Decompression options.
 * @param temp_bytes [out] The amount of GPU memory that will be temporarily required
 * during decompression. The value is returned on the host side.
 * @param max_total_uncompressed_bytes [in] The total decompressed size of all the chunks.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedGzipDecompressGetTempSizeAsync(
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedGzipDecompressOpts_t decompress_opts,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes);

/**
 * \brief Get the amount of temporary memory required on the GPU for decompression
 * synchronously.
 *
 * @param device_compressed_chunk_ptrs [in] Array with size \p num_chunks of pointers
 * in device-accessible memory to device-accessible compressed buffers.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedGzipDecompressGetRequiredAlignments}.
 * @param device_compressed_chunk_bytes [in] Array with size \p num_chunks of sizes of
 * the compressed buffers in bytes. The sizes should reside in device-accessible memory.
 * @param num_chunks [in] Number of chunks of data to be decompressed.
 * @param max_uncompressed_chunk_bytes [in] The size of the largest chunk in bytes
 * when uncompressed.
 * @param temp_bytes [out] The amount of GPU memory that will be temporarily required
 * during decompression. The value is returned on the host side.
 * @param max_total_uncompressed_bytes [in]  The total decompressed size of all the chunks.
 * @param decompress_opts [in] Decompression options.
 * @param device_statuses [out] Array with size \p num_chunks of statuses in
 * device-accessible memory. This argument needs to be preallocated. For each
 * chunk, if the data can be parsed successfully, the status will be set to
 * {@code nvcompSuccess}, and an error code otherwise.
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedGzipDecompressGetTempSizeSync(
    @Cast("const void*const*const") PointerPointer device_compressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    @ByVal nvcompBatchedGzipDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedGzipDecompressGetTempSizeSync(
    @Cast("const void*const*const") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    @ByVal nvcompBatchedGzipDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedGzipDecompressGetTempSizeSync(
    @Cast("const void*const*const") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    @ByVal nvcompBatchedGzipDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntBuffer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedGzipDecompressGetTempSizeSync(
    @Cast("const void*const*const") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    @ByVal nvcompBatchedGzipDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") int[] device_statuses,
    CUstream_st stream);

/**
 * \brief Asynchronously compute the number of bytes of uncompressed data for
 * each compressed chunk.
 *
 * This is needed when we do not know the expected output size.
 *
 * \note If the stream is corrupt, the calculated sizes will be invalid.
 *
 * \note Violating any of the conditions listed in the parameter descriptions
 * below may result in undefined behaviour.
 *
 * @param device_compressed_chunk_ptrs [in] Array with size \p num_chunks of
 * pointers in device-accessible memory to compressed buffers.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedGzipDecompressGetRequiredAlignments}.
 * @param device_compressed_chunk_bytes [in] Array with size \p num_chunks of sizes
 * of the compressed buffers in bytes. The sizes should reside in device-accessible memory.
 * @param device_uncompressed_chunk_bytes [out] Array with size \p num_chunks
 * to be filled with the sizes, in bytes, of each uncompressed data chunk.
 * @param num_chunks [in] Number of data chunks to compute sizes of.
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedGzipGetDecompressSizeAsync(
    @Cast("const void*const*") PointerPointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedGzipGetDecompressSizeAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    CUstream_st stream);

/**
 * \brief Perform batched asynchronous decompression.
 *
 * \note Violating any of the conditions listed in the parameter descriptions
 * below may result in undefined behaviour.
 *
 * @param device_compressed_chunk_ptrs [in] Array with size \p num_chunks of pointers
 * in device-accessible memory to device-accessible compressed buffers.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedGzipDecompressGetRequiredAlignments}.
 * @param device_compressed_chunk_bytes [in] Array with size \p num_chunks of sizes of
 * the compressed buffers in bytes. The sizes should reside in device-accessible memory.
 * @param device_uncompressed_buffer_bytes [in] Array with size \p num_chunks of sizes,
 * in bytes, of the output buffers to be filled with uncompressed data for each chunk.
 * The sizes should reside in device-accessible memory. If a
 * size is not large enough to hold all decompressed data, the decompressor
 * will set the status in \p device_statuses corresponding to the
 * overflow chunk to {@code nvcompErrorCannotDecompress}.
 * @param device_uncompressed_chunk_bytes [out] Array with size \p num_chunks to
 * be filled with the actual number of bytes decompressed for every chunk.
 * This argument needs to be preallocated.
 * When {@code NVCOMP_DECOMPRESS_BACKEND_HARDWARE} is specified in \p decompress_opts.backend,
 * this parameter is required. For {@code NVCOMP_DECOMPRESS_BACKEND_CUDA}, it is optional
 * and may be set to NULL if reporting the actual sizes is not necessary.
 * @param num_chunks [in] Number of chunks of data to decompress.
 * @param device_temp_ptr [in] The temporary GPU space.
 * Must be aligned to the value in the {@code temp} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedGzipDecompressGetRequiredAlignments}.
 * @param temp_bytes [in] The size of the temporary GPU space.
 * @param device_uncompressed_chunk_ptrs [out] Array with size \p num_chunks of
 * pointers in device-accessible memory to decompressed data. Each uncompressed
 * buffer needs to be preallocated in device-accessible memory, have the size
 * specified by the corresponding entry in \p device_uncompressed_buffer_bytes,
 * and be aligned to the value in the {@code output} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedGzipDecompressGetRequiredAlignments}.
 * @param decompress_opts [in] Decompression options.
 * @param device_statuses [out] Array with size \p num_chunks of statuses in
 * device-accessible memory. This argument needs to be preallocated. For each
 * chunk, if the decompression is successful, the status will be set to
 * {@code nvcompSuccess}. If the decompression is not successful, for example due to
 * the corrupted input or out-of-bound errors, the status will be set to
 * {@code nvcompErrorCannotDecompress}.
 * Can be NULL if desired, in which case error status is not reported.
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successfully launched, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedGzipDecompressAsync(
    @Cast("const void*const*") PointerPointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("const size_t*") SizeTPointer device_uncompressed_buffer_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") PointerPointer device_uncompressed_chunk_ptrs,
    @ByVal nvcompBatchedGzipDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedGzipDecompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("const size_t*") SizeTPointer device_uncompressed_buffer_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @ByVal nvcompBatchedGzipDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedGzipDecompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("const size_t*") SizeTPointer device_uncompressed_buffer_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @ByVal nvcompBatchedGzipDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntBuffer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedGzipDecompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("const size_t*") SizeTPointer device_uncompressed_buffer_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @ByVal nvcompBatchedGzipDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") int[] device_statuses,
    CUstream_st stream);

// #ifdef __cplusplus
// #endif

// #endif // NVCOMP_GZIP_H


// Parsed from <nvcomp/lz4.h>

/*
 * SPDX-FileCopyrightText: Copyright (c) 2017-2025 NVIDIA CORPORATION & AFFILIATES.
 * All rights reserved. SPDX-License-Identifier: LicenseRef-NvidiaProprietary
 *
 * NVIDIA CORPORATION, its affiliates and licensors retain all intellectual
 * property and proprietary rights in and to this material, related
 * documentation and any modifications thereto. Any use, reproduction,
 * disclosure or distribution of this material and related documentation
 * without an express license agreement from NVIDIA CORPORATION or
 * its affiliates is strictly prohibited.
*/

// #ifndef NVCOMP_LZ4_H
// #define NVCOMP_LZ4_H

// #include "nvcomp.h"

// #ifdef __cplusplus
// Targeting ../nvcomp/nvcompBatchedLZ4CompressOpts_t.java


// Targeting ../nvcomp/nvcompBatchedLZ4DecompressOpts_t.java



/**
 * \brief Default LZ4 compression options
 */
@MemberGetter public static native @Const @ByRef nvcompBatchedLZ4CompressOpts_t nvcompBatchedLZ4CompressDefaultOpts();

/**
 * \brief Default LZ4 decompression options
 */
@MemberGetter public static native @Const @ByRef nvcompBatchedLZ4DecompressOpts_t nvcompBatchedLZ4DecompressDefaultOpts();

/**
 * \brief The maximum supported uncompressed chunk size in bytes for the LZ4 compressor.
 */
@MemberGetter public static native @Cast("const size_t") long nvcompLZ4CompressionMaxAllowedChunkSize();
public static final long nvcompLZ4CompressionMaxAllowedChunkSize = nvcompLZ4CompressionMaxAllowedChunkSize();

/**
 * \brief The most restrictive of the minimum alignment requirements for void-type CUDA memory buffers
 * used for input, output, or temporary memory, passed to compression functions.
 *
 * \note In all cases, typed memory buffers must still be aligned to their type's size,
 * e.g., 4 bytes for {@code int}.
 */
@MemberGetter public static native @Cast("const size_t") long nvcompLZ4RequiredCompressionAlignment();
public static final long nvcompLZ4RequiredCompressionAlignment = nvcompLZ4RequiredCompressionAlignment();

/**
 * \brief Get the minimum buffer alignment requirements for compression.
 *
 * \note Providing buffers with alignments above the minimum requirements
 * (e.g., 16- or 32-byte alignment) may help improve performance.
 *
 * @param compress_opts [in] Compression options.
 * @param alignment_requirements [out] The minimum buffer alignment requirements
 * for compression.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedLZ4CompressGetRequiredAlignments(
    @ByVal nvcompBatchedLZ4CompressOpts_t compress_opts,
    nvcompAlignmentRequirements_t alignment_requirements);

/**
 * \brief Get the amount of temporary memory required on the GPU for compression
 * asynchronously.
 *
 * \note For best performance, a chunk size of 65536 bytes is recommended.
 *
 * @param num_chunks [in] The number of chunks of memory in the batch.
 * @param max_uncompressed_chunk_bytes [in] The maximum size of a chunk in the
 * batch.
 * @param compress_opts [in] Compression options.
 * @param temp_bytes [out] The amount of GPU memory that will be temporarily
 * required during compression. The value is returned on the host side.
 * @param max_total_uncompressed_bytes [in] Upper bound on the total uncompressed
 * size of all chunks
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedLZ4CompressGetTempSizeAsync(
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedLZ4CompressOpts_t compress_opts,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes);

/**
 * \brief Get the amount of temporary memory required on the GPU for compression.
 * synchronously.
 *
 * @param device_uncompressed_chunk_ptrs [in] Array with size \p num_chunks of pointers
 * to the uncompressed data chunks. Both the pointers and the uncompressed data
 * should reside in device-accessible memory.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedLZ4CompressGetRequiredAlignments} when called with the same
 * \p compress_opts.
 * @param device_uncompressed_chunk_bytes [in] Array with size \p num_chunks of
 * sizes of the uncompressed chunks in bytes.
 * The sizes should reside in device-accessible memory.
 * @param num_chunks [in] The number of chunks of memory in the batch.
 * @param max_uncompressed_chunk_bytes [in] The maximum size of a chunk in the
 * batch.
 * @param compress_opts [in] Compression options.
 * @param temp_bytes [out] The amount of GPU memory that will be temporarily
 * required during compression. The value is returned on the host side.
 * @param max_total_uncompressed_bytes [in] Upper bound on the total uncompressed
 * size of all chunks
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedLZ4CompressGetTempSizeSync(
    @Cast("const void*const*const") PointerPointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedLZ4CompressOpts_t compress_opts,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedLZ4CompressGetTempSizeSync(
    @Cast("const void*const*const") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedLZ4CompressOpts_t compress_opts,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    CUstream_st stream);

/**
 * \brief Get the maximum size that a chunk of size at most max_uncompressed_chunk_bytes
 * could compress to. That is, the minimum amount of output memory required to be given
 * \ref nvcompBatchedLZ4CompressAsync for each chunk.
 *
 * \note For best performance, a chunk size of 65536 bytes is recommended.
 *
 * @param max_uncompressed_chunk_bytes [in] The maximum size of a chunk before compression.
 * @param compress_opts [in] The LZ4 compression options to use.
 * @param max_compressed_chunk_bytes [out] The maximum possible compressed size of the chunk.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedLZ4CompressGetMaxOutputChunkSize(
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedLZ4CompressOpts_t compress_opts,
    @Cast("size_t*") SizeTPointer max_compressed_chunk_bytes);

/**
 * \brief Perform batched asynchronous compression.
 *
 * \note For best performance, a chunk size of 65536 bytes is recommended.
 * Violating any of the conditions listed in the parameter descriptions
 * below may result in undefined behaviour.
 *
 * @param device_uncompressed_chunk_ptrs [in] Array with size \p num_chunks of pointers
 * to the uncompressed data chunks. Both the pointers and the uncompressed data
 * should reside in device-accessible memory.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedLZ4CompressGetRequiredAlignments} when called with the same
 * \p compress_opts.
 * @param device_uncompressed_chunk_bytes [in] Array with size \p num_chunks of
 * sizes of the uncompressed chunks in bytes.
 * The sizes should reside in device-accessible memory.
 * Each chunk size must be a multiple of the size of the data type specified by
 * compress_opts.data_type.
 * Chunk sizes must not exceed 16777216 bytes. For best performance, a chunk size
 * of 65536 bytes is recommended.
 * @param max_uncompressed_chunk_bytes [in] The size of the largest uncompressed chunk.
 * @param num_chunks [in] Number of chunks of data to compress.
 * @param device_temp_ptr [in] The temporary GPU workspace.
 * Must be aligned to the value in the {@code temp} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedLZ4CompressGetRequiredAlignments} when called with the same
 * \p compress_opts.
 * @param temp_bytes [in] The size of the temporary GPU memory pointed to by
 * {@code device_temp_ptr}.
 * @param device_compressed_chunk_ptrs [out] Array with size \p num_chunks of pointers
 * to the output compressed buffers. Both the pointers and the compressed
 * buffers should reside in device-accessible memory. Each compressed buffer
 * should be preallocated with the size given by
 * {@code nvcompBatchedLZ4CompressGetMaxOutputChunkSize}.
 * Each compressed buffer must be aligned to the value in the {@code output} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedLZ4CompressGetRequiredAlignments} when called with the same
 * \p compress_opts.
 * @param device_compressed_chunk_bytes [out] Array with size \p num_chunks,
 * to be filled with the compressed sizes of each chunk.
 * The buffer should be preallocated in device-accessible memory.
 * @param compress_opts [in] The LZ4 compression options to use.
 * @param device_statuses [out] Array with size \p num_chunks of statuses in
 * device-accessible memory. This argument needs to be preallocated. For each
 * chunk, if the compression is successful, the status will be set to
 * {@code nvcompSuccess}, and an error code otherwise.
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successfully launched, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedLZ4CompressAsync(
    @Cast("const void*const*") PointerPointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") PointerPointer device_compressed_chunk_ptrs,
    @Cast("size_t*") SizeTPointer device_compressed_chunk_bytes,
    @ByVal nvcompBatchedLZ4CompressOpts_t compress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedLZ4CompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("size_t*") SizeTPointer device_compressed_chunk_bytes,
    @ByVal nvcompBatchedLZ4CompressOpts_t compress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedLZ4CompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("size_t*") SizeTPointer device_compressed_chunk_bytes,
    @ByVal nvcompBatchedLZ4CompressOpts_t compress_opts,
    @Cast("nvcompStatus_t*") IntBuffer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedLZ4CompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("size_t*") SizeTPointer device_compressed_chunk_bytes,
    @ByVal nvcompBatchedLZ4CompressOpts_t compress_opts,
    @Cast("nvcompStatus_t*") int[] device_statuses,
    CUstream_st stream);

/**
 * \brief The most restrictive of the minimum alignment requirements for void-type CUDA memory buffers
 * used for input, output, or temporary memory, passed to decompression functions.
 *
 * \note In all cases, typed memory buffers must still be aligned to their type's size,
 * e.g., 4 bytes for {@code int}.
 */
@MemberGetter public static native @Cast("const size_t") long nvcompLZ4RequiredDecompressionAlignment();
public static final long nvcompLZ4RequiredDecompressionAlignment = nvcompLZ4RequiredDecompressionAlignment();

/**
 * \brief Get the minimum buffer alignment requirements for decompression.
 *
 * \note Providing buffers with alignments above the minimum requirements
 * (e.g., 16- or 32-byte alignment) may help improve performance.
 *
 * @param decompress_opts [in] Decompression options.
 * @param alignment_requirements [out] The minimum buffer alignment requirements
 * for decompression.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedLZ4DecompressGetRequiredAlignments(
    @ByVal nvcompBatchedLZ4DecompressOpts_t decompress_opts,
    nvcompAlignmentRequirements_t alignment_requirements);

/**
 * \brief Get the amount of temporary memory required on the GPU for decompression
 * asynchronously.
 *
 * @param num_chunks [in] Number of chunks of data to be decompressed.
 * @param max_uncompressed_chunk_bytes [in] The size of the largest chunk in bytes
 * when uncompressed.
 * @param decompress_opts [in] Decompression options.
 * @param temp_bytes [out] The amount of GPU memory that will be temporarily required
 * during decompression. The value is returned on the host side.
 * @param max_total_uncompressed_bytes [in] The total decompressed size of all the chunks.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedLZ4DecompressGetTempSizeAsync(
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedLZ4DecompressOpts_t decompress_opts,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes);

/**
 * \brief Get the amount of temporary memory required on the GPU for decompression
 * synchronously.
 *
 * @param device_compressed_chunk_ptrs [in] Array with size \p num_chunks of pointers
 * in device-accessible memory to device-accessible compressed buffers.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedLZ4DecompressGetRequiredAlignments}.
 * @param device_compressed_chunk_bytes [in] Array with size \p num_chunks of sizes of
 * the compressed buffers in bytes. The sizes should reside in device-accessible memory.
 * @param num_chunks [in] Number of chunks of data to be decompressed.
 * @param max_uncompressed_chunk_bytes [in] The size of the largest chunk in bytes
 * when uncompressed.
 * @param temp_bytes [out] The amount of GPU memory that will be temporarily required
 * during decompression. The value is returned on the host side.
 * @param max_total_uncompressed_bytes [in]  The total decompressed size of all the chunks.
 * @param decompress_opts [in] Decompression options.
 * @param device_statuses [out] Array with size \p num_chunks of statuses in
 * device-accessible memory. This argument needs to be preallocated. For each
 * chunk, if the data can be parsed successfully, the status will be set to
 * {@code nvcompSuccess}, and an error code otherwise.
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedLZ4DecompressGetTempSizeSync(
    @Cast("const void*const*const") PointerPointer device_compressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    @ByVal nvcompBatchedLZ4DecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedLZ4DecompressGetTempSizeSync(
    @Cast("const void*const*const") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    @ByVal nvcompBatchedLZ4DecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedLZ4DecompressGetTempSizeSync(
    @Cast("const void*const*const") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    @ByVal nvcompBatchedLZ4DecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntBuffer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedLZ4DecompressGetTempSizeSync(
    @Cast("const void*const*const") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    @ByVal nvcompBatchedLZ4DecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") int[] device_statuses,
    CUstream_st stream);

/**
 * \brief Asynchronously compute the number of bytes of uncompressed data for
 * each compressed chunk.
 *
 * This is needed when we do not know the expected output size.
 *
 * \note If the stream is corrupt, the calculated sizes will be invalid.
 *
 * \note Violating any of the conditions listed in the parameter descriptions
 * below may result in undefined behaviour.
 *
 * @param device_compressed_chunk_ptrs [in] Array with size \p num_chunks of
 * pointers in device-accessible memory to compressed buffers.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedLZ4DecompressGetRequiredAlignments}.
 * @param device_compressed_chunk_bytes [in] Array with size \p num_chunks of sizes
 * of the compressed buffers in bytes. The sizes should reside in device-accessible memory.
 * @param device_uncompressed_chunk_bytes [out] Array with size \p num_chunks
 * to be filled with the sizes, in bytes, of each uncompressed data chunk.
 * This argument needs to be preallocated in device-accessible memory.
 * @param num_chunks [in] Number of data chunks to compute sizes of.
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedLZ4GetDecompressSizeAsync(
    @Cast("const void*const*") PointerPointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedLZ4GetDecompressSizeAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    CUstream_st stream);

/**
 * \brief Perform batched asynchronous decompression.
 *
 * \note Violating any of the conditions listed in the parameter descriptions
 * below may result in undefined behaviour.
 *
 * @param device_compressed_chunk_ptrs [in] Array with size \p num_chunks of pointers
 * in device-accessible memory to device-accessible compressed buffers.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedLZ4DecompressGetRequiredAlignments}.
 * @param device_compressed_chunk_bytes [in] Array with size \p num_chunks of sizes of
 * the compressed buffers in bytes. The sizes should reside in device-accessible memory.
 * @param device_uncompressed_buffer_bytes [in] Array with size \p num_chunks of sizes,
 * in bytes, of the output buffers to be filled with uncompressed data for each chunk.
 * The sizes should reside in device-accessible memory. If a
 * size is not large enough to hold all decompressed data, the decompressor
 * will set the status in \p device_statuses corresponding to the
 * overflow chunk to {@code nvcompErrorCannotDecompress}.
 * @param device_uncompressed_chunk_bytes [out] Array with size \p num_chunks to
 * be filled with the actual number of bytes decompressed for every chunk.
 * This argument needs to be preallocated.
 * When {@code NVCOMP_DECOMPRESS_BACKEND_HARDWARE} is specified in \p decompress_opts.backend,
 * this parameter is required. For {@code NVCOMP_DECOMPRESS_BACKEND_CUDA}, it is optional
 * and may be set to NULL if reporting the actual sizes is not necessary.
 * @param num_chunks [in] Number of chunks of data to decompress.
 * @param device_temp_ptr [in] The temporary GPU space.
 * Must be aligned to the value in the {@code temp} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedLZ4DecompressGetRequiredAlignments}.
 * @param temp_bytes [in] The size of the temporary GPU space.
 * @param device_uncompressed_chunk_ptrs [out] Array with size \p num_chunks of
 * pointers in device-accessible memory to decompressed data. Each uncompressed
 * buffer needs to be preallocated in device-accessible memory, have the size
 * specified by the corresponding entry in \p device_uncompressed_buffer_bytes,
 * and be aligned to the value in the {@code output} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedLZ4DecompressGetRequiredAlignments}.
 * @param decompress_opts [in] Decompression options.
 * @param device_statuses [out] Array with size \p num_chunks of statuses in
 * device-accessible memory. This argument needs to be preallocated. For each
 * chunk, if the decompression is successful, the status will be set to
 * {@code nvcompSuccess}. If the decompression is not successful, for example due to
 * the corrupted input or out-of-bound errors, the status will be set to
 * {@code nvcompErrorCannotDecompress}.
 * Can be NULL if desired, in which case error status is not reported.
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successfully launched, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedLZ4DecompressAsync(
    @Cast("const void*const*") PointerPointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("const size_t*") SizeTPointer device_uncompressed_buffer_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") PointerPointer device_uncompressed_chunk_ptrs,
    @ByVal nvcompBatchedLZ4DecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedLZ4DecompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("const size_t*") SizeTPointer device_uncompressed_buffer_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @ByVal nvcompBatchedLZ4DecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedLZ4DecompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("const size_t*") SizeTPointer device_uncompressed_buffer_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @ByVal nvcompBatchedLZ4DecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntBuffer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedLZ4DecompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("const size_t*") SizeTPointer device_uncompressed_buffer_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @ByVal nvcompBatchedLZ4DecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") int[] device_statuses,
    CUstream_st stream);

// #ifdef __cplusplus
// #endif

// #endif // NVCOMP_LZ4_H


// Parsed from <nvcomp/lz4.hpp>

/*
 * SPDX-FileCopyrightText: Copyright (c) 2022-2025 NVIDIA CORPORATION & AFFILIATES.
 * All rights reserved. SPDX-License-Identifier: LicenseRef-NvidiaProprietary
 *
 * NVIDIA CORPORATION, its affiliates and licensors retain all intellectual
 * property and proprietary rights in and to this material, related
 * documentation and any modifications thereto. Any use, reproduction,
 * disclosure or distribution of this material and related documentation
 * without an express license agreement from NVIDIA CORPORATION or
 * its affiliates is strictly prohibited.
*/

// #pragma once

// #include "nvcompManager.hpp"
// #include "lz4.h"
// Targeting ../nvcomp/LZ4FormatSpecHeader.java


// Targeting ../nvcomp/LZ4Manager.java



 // namespace nvcomp


// Parsed from <nvcomp/snappy.h>

/*
 * SPDX-FileCopyrightText: Copyright (c) 2017-2025 NVIDIA CORPORATION & AFFILIATES.
 * All rights reserved. SPDX-License-Identifier: LicenseRef-NvidiaProprietary
 *
 * NVIDIA CORPORATION, its affiliates and licensors retain all intellectual
 * property and proprietary rights in and to this material, related
 * documentation and any modifications thereto. Any use, reproduction,
 * disclosure or distribution of this material and related documentation
 * without an express license agreement from NVIDIA CORPORATION or
 * its affiliates is strictly prohibited.
*/

// #ifndef NVCOMP_SNAPPY_H
// #define NVCOMP_SNAPPY_H

// #include "nvcomp.h"

// #ifdef __cplusplus
// Targeting ../nvcomp/nvcompBatchedSnappyCompressOpts_t.java


// Targeting ../nvcomp/nvcompBatchedSnappyDecompressOpts_t.java



/**
 * \brief Default Snappy compression options
 */
@MemberGetter public static native @Const @ByRef nvcompBatchedSnappyCompressOpts_t nvcompBatchedSnappyCompressDefaultOpts();

/**
 * \brief Default Snappy decompression options
 */
@MemberGetter public static native @Const @ByRef nvcompBatchedSnappyDecompressOpts_t nvcompBatchedSnappyDecompressDefaultOpts();

/**
 * \brief The maximum supported uncompressed chunk size in bytes for the Snappy compressor.
 */
@MemberGetter public static native @Cast("const size_t") long nvcompSnappyCompressionMaxAllowedChunkSize();
public static final long nvcompSnappyCompressionMaxAllowedChunkSize = nvcompSnappyCompressionMaxAllowedChunkSize();

/**
 * \brief The maximum supported compressed chunk size in bytes for the Snappy decompressor.
 */
@MemberGetter public static native @Cast("const size_t") long nvcompSnappyDecompressionMaxAllowedChunkSize();
public static final long nvcompSnappyDecompressionMaxAllowedChunkSize = nvcompSnappyDecompressionMaxAllowedChunkSize();

/**
 * \brief The most restrictive of the minimum alignment requirements for void-type CUDA memory buffers
 * used for input, output, or temporary memory, passed to compression functions.
 *
 * \note In all cases, typed memory buffers must still be aligned to their type's size,
 * e.g., 4 bytes for {@code int}.
 */
@MemberGetter public static native @Cast("const size_t") long nvcompSnappyRequiredCompressionAlignment();
public static final long nvcompSnappyRequiredCompressionAlignment = nvcompSnappyRequiredCompressionAlignment();

/**
 * \brief Get the minimum buffer alignment requirements for compression.
 *
 * \note Providing buffers with alignments above the minimum requirements
 * (e.g., 16- or 32-byte alignment) may help improve performance.
 *
 * @param compress_opts [in] Compression options.
 * @param alignment_requirements [out] The minimum buffer alignment requirements
 * for compression.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedSnappyCompressGetRequiredAlignments(
    @ByVal nvcompBatchedSnappyCompressOpts_t compress_opts,
    nvcompAlignmentRequirements_t alignment_requirements);

/**
 * \brief Get the amount of temporary memory required on the GPU for compression
 * asynchronously.
 *
 * @param num_chunks [in] The number of chunks of memory in the batch.
 * @param max_uncompressed_chunk_bytes [in] The maximum size of a chunk in the
 * batch.
 * @param compress_opts [in] Compression options.
 * @param temp_bytes [out] The amount of GPU memory that will be temporarily
 * required during compression. The value is returned on the host side.
 * @param max_total_uncompressed_bytes [in] Upper bound on the total uncompressed
 * size of all chunks
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedSnappyCompressGetTempSizeAsync(
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedSnappyCompressOpts_t compress_opts,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes);

/**
 * \brief Get the amount of temporary memory required on the GPU for compression.
 * synchronously.
 *
 * @param device_uncompressed_chunk_ptrs [in] Array with size \p num_chunks of pointers
 * to the uncompressed data chunks. Both the pointers and the uncompressed data
 * should reside in device-accessible memory.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedSnappyCompressGetRequiredAlignments} when called with the same
 * \p compress_opts.
 * @param device_uncompressed_chunk_bytes [in] Array with size \p num_chunks of
 * sizes of the uncompressed chunks in bytes.
 * The sizes should reside in device-accessible memory.
 * @param num_chunks [in] The number of chunks of memory in the batch.
 * @param max_uncompressed_chunk_bytes [in] The maximum size of a chunk in the
 * batch.
 * @param compress_opts [in] Compression options.
 * @param temp_bytes [out] The amount of GPU memory that will be temporarily
 * required during compression. The value is returned on the host side.
 * @param max_total_uncompressed_bytes [in] Upper bound on the total uncompressed
 * size of all chunks
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedSnappyCompressGetTempSizeSync(
    @Cast("const void*const*const") PointerPointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedSnappyCompressOpts_t compress_opts,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedSnappyCompressGetTempSizeSync(
    @Cast("const void*const*const") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedSnappyCompressOpts_t compress_opts,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    CUstream_st stream);

/**
 * \brief Get the maximum size that a chunk of size at most max_uncompressed_chunk_bytes
 * could compress to. That is, the minimum amount of output memory required to be given
 * \ref nvcompBatchedSnappyCompressAsync for each chunk.
 *
 * @param max_uncompressed_chunk_bytes [in] The maximum size of a chunk before compression.
 * @param compress_opts [in] Snappy compression options.
 * @param max_compressed_chunk_bytes [out] The maximum possible compressed size of the chunk.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedSnappyCompressGetMaxOutputChunkSize(
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedSnappyCompressOpts_t compress_opts,
    @Cast("size_t*") SizeTPointer max_compressed_chunk_bytes);

/**
 * \brief Perform batched asynchronous compression.
 *
 * \note Violating any of the conditions listed in the parameter descriptions
 * below may result in undefined behaviour.
 *
 * @param device_uncompressed_chunk_ptrs [in] Array with size \p num_chunks of pointers
 * to the uncompressed data chunks. Both the pointers and the uncompressed data
 * should reside in device-accessible memory.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedSnappyCompressGetRequiredAlignments} when called with the same
 * \p compress_opts.
 * @param device_uncompressed_chunk_bytes [in] Array with size \p num_chunks of
 * sizes of the uncompressed chunks in bytes.
 * The sizes should reside in device-accessible memory.
 * @param max_uncompressed_chunk_bytes [in] The size of the largest uncompressed chunk.
 * This parameter is currently unused. Set it to either the actual value
 * or zero.
 * @param num_chunks [in] Number of chunks of data to compress.
 * @param device_temp_ptr [in] The temporary GPU workspace, could be NULL in case
 * temporary memory is not needed.
 * Must be aligned to the value in the {@code temp} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedSnappyCompressGetRequiredAlignments} when called with the same
 * \p compress_opts.
 * @param temp_bytes [in] The size of the temporary GPU memory pointed to by
 * {@code device_temp_ptr}.
 * @param device_compressed_chunk_ptrs [out] Array with size \p num_chunks of pointers
 * to the output compressed buffers. Both the pointers and the compressed
 * buffers should reside in device-accessible memory. Each compressed buffer
 * should be preallocated with the size given by
 * {@code nvcompBatchedSnappyCompressGetMaxOutputChunkSize}.
 * Each compressed buffer must be aligned to the value in the {@code output} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedSnappyCompressGetRequiredAlignments} when called with the same
 * \p compress_opts.
 * @param device_compressed_chunk_bytes [out] Array with size \p num_chunks,
 * to be filled with the compressed sizes of each chunk.
 * The buffer should be preallocated in device-accessible memory.
 * @param compress_opts [in] Snappy compression options.
 * @param device_statuses [out] Array with size \p num_chunks of statuses in
 * device-accessible memory. This argument needs to be preallocated. For each
 * chunk, if the compression is successful, the status will be set to
 * {@code nvcompSuccess}, and an error code otherwise.
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successfully launched, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedSnappyCompressAsync(
    @Cast("const void*const*") PointerPointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") PointerPointer device_compressed_chunk_ptrs,
    @Cast("size_t*") SizeTPointer device_compressed_chunk_bytes,
    @ByVal nvcompBatchedSnappyCompressOpts_t compress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedSnappyCompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("size_t*") SizeTPointer device_compressed_chunk_bytes,
    @ByVal nvcompBatchedSnappyCompressOpts_t compress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedSnappyCompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("size_t*") SizeTPointer device_compressed_chunk_bytes,
    @ByVal nvcompBatchedSnappyCompressOpts_t compress_opts,
    @Cast("nvcompStatus_t*") IntBuffer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedSnappyCompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("size_t*") SizeTPointer device_compressed_chunk_bytes,
    @ByVal nvcompBatchedSnappyCompressOpts_t compress_opts,
    @Cast("nvcompStatus_t*") int[] device_statuses,
    CUstream_st stream);

/**
 * \brief The most restrictive of the minimum alignment requirements for void-type CUDA memory buffers
 * used for input, output, or temporary memory, passed to decompression functions.
 *
 * \note In all cases, typed memory buffers must still be aligned to their type's size,
 * e.g., 4 bytes for {@code int}.
 */
@MemberGetter public static native @Cast("const size_t") long nvcompSnappyRequiredDecompressionAlignment();
public static final long nvcompSnappyRequiredDecompressionAlignment = nvcompSnappyRequiredDecompressionAlignment();

/**
 * \brief Get the minimum buffer alignment requirements for decompression.
 *
 * \note Providing buffers with alignments above the minimum requirements
 * (e.g., 16- or 32-byte alignment) may help improve performance.
 *
 * @param decompress_opts [in] Decompression options.
 * @param alignment_requirements [out] The minimum buffer alignment requirements
 * for decompression.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedSnappyDecompressGetRequiredAlignments(
    @ByVal nvcompBatchedSnappyDecompressOpts_t decompress_opts,
    nvcompAlignmentRequirements_t alignment_requirements);

/**
 * \brief Get the amount of temporary memory required on the GPU for decompression
 * asynchronously.
 *
 * @param num_chunks [in] Number of chunks of data to be decompressed.
 * @param max_uncompressed_chunk_bytes [in] The size of the largest chunk in bytes
 * when uncompressed.
 * @param decompress_opts [in] Decompression options.
 * @param temp_bytes [out] The amount of GPU memory that will be temporarily required
 * during decompression. The value is returned on the host side.
 * @param max_total_uncompressed_bytes [in] The total decompressed size of all the chunks.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedSnappyDecompressGetTempSizeAsync(
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedSnappyDecompressOpts_t decompress_opts,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes);

/**
 * \brief Get the amount of temporary memory required on the GPU for decompression
 * synchronously.
 *
 * @param device_compressed_chunk_ptrs [in] Array with size \p num_chunks of pointers
 * in device-accessible memory to device-accessible compressed buffers.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedSnappyDecompressGetRequiredAlignments}.
 * @param device_compressed_chunk_bytes [in] Array with size \p num_chunks of sizes of
 * the compressed buffers in bytes. The sizes should reside in device-accessible memory.
 * @param num_chunks [in] Number of chunks of data to be decompressed.
 * @param max_uncompressed_chunk_bytes [in] The size of the largest chunk in bytes
 * when uncompressed.
 * @param temp_bytes [out] The amount of GPU memory that will be temporarily required
 * during decompression. The value is returned on the host side.
 * @param max_total_uncompressed_bytes [in]  The total decompressed size of all the chunks.
 * @param decompress_opts [in] Decompression options.
 * @param device_statuses [out] Array with size \p num_chunks of statuses in
 * device-accessible memory. This argument needs to be preallocated. For each
 * chunk, if the data can be parsed successfully, the status will be set to
 * {@code nvcompSuccess}, and an error code otherwise.
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedSnappyDecompressGetTempSizeSync(
    @Cast("const void*const*const") PointerPointer device_compressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    @ByVal nvcompBatchedSnappyDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedSnappyDecompressGetTempSizeSync(
    @Cast("const void*const*const") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    @ByVal nvcompBatchedSnappyDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedSnappyDecompressGetTempSizeSync(
    @Cast("const void*const*const") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    @ByVal nvcompBatchedSnappyDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntBuffer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedSnappyDecompressGetTempSizeSync(
    @Cast("const void*const*const") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    @ByVal nvcompBatchedSnappyDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") int[] device_statuses,
    CUstream_st stream);

/**
 * \brief Asynchronously compute the number of bytes of uncompressed data for
 * each compressed chunk.
 *
 * \note Violating any of the conditions listed in the parameter descriptions
 * below may result in undefined behaviour.
 *
 * @param device_compressed_chunk_ptrs [in] Array with size \p num_chunks of
 * pointers in device-accessible memory to compressed buffers.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedSnappyDecompressGetRequiredAlignments}.
 * @param device_compressed_chunk_bytes [in] Array with size \p num_chunks of sizes
 * of the compressed buffers in bytes. The sizes should reside in device-accessible memory.
 * @param device_uncompressed_chunk_bytes [out] Array with size \p num_chunks
 * to be filled with the sizes, in bytes, of each uncompressed data chunk.
 * If there is an error when retrieving the size of a chunk, the
 * uncompressed size of that chunk will be set to 0. This argument needs to
 * be preallocated in device-accessible memory.
 * @param num_chunks [in] Number of data chunks to compute sizes of.
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedSnappyGetDecompressSizeAsync(
    @Cast("const void*const*") PointerPointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedSnappyGetDecompressSizeAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    CUstream_st stream);

/**
 * \brief Perform batched asynchronous decompression.
 *
 * \note Violating any of the conditions listed in the parameter descriptions
 * below may result in undefined behaviour.
 *
 * @param device_compressed_chunk_ptrs [in] Array with size \p num_chunks of pointers
 * in device-accessible memory to device-accessible compressed buffers.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedSnappyDecompressGetRequiredAlignments}.
 * @param device_compressed_chunk_bytes [in] Array with size \p num_chunks of sizes of
 * the compressed buffers in bytes. The sizes should reside in device-accessible memory.
 * @param device_uncompressed_buffer_bytes [in] Array with size \p num_chunks of sizes,
 * in bytes, of the output buffers to be filled with uncompressed data for each chunk.
 * The sizes should reside in device-accessible memory. If a
 * size is not large enough to hold all decompressed data, the decompressor
 * will set the status in \p device_statuses corresponding to the
 * overflow chunk to {@code nvcompErrorCannotDecompress}.
 * @param device_uncompressed_chunk_bytes [out] Array with size \p num_chunks to
 * be filled with the actual number of bytes decompressed for every chunk.
 * This argument needs to be preallocated.
 * When {@code NVCOMP_DECOMPRESS_BACKEND_HARDWARE} is specified in \p decompress_opts.backend,
 * this parameter is required. For {@code NVCOMP_DECOMPRESS_BACKEND_CUDA}, it is optional
 * and may be set to NULL if reporting the actual sizes is not necessary.
 * @param num_chunks [in] Number of chunks of data to decompress.
 * @param device_temp_ptr [in] The temporary GPU space, could be NULL in case temporary space is not needed.
 * Must be aligned to the value in the {@code temp} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedSnappyDecompressGetRequiredAlignments}.
 * @param temp_bytes [in] The size of the temporary GPU space.
 * @param device_uncompressed_chunk_ptrs [out] Array with size \p num_chunks of
 * pointers in device-accessible memory to decompressed data. Each uncompressed
 * buffer needs to be preallocated in device-accessible memory, have the size
 * specified by the corresponding entry in \p device_uncompressed_buffer_bytes,
 * and be aligned to the value in the {@code output} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedSnappyDecompressGetRequiredAlignments}.
 * @param decompress_opts [in] Decompression options.
 * @param device_statuses [out] Array with size \p num_chunks of statuses in
 * device-accessible memory. This argument needs to be preallocated. For each
 * chunk, if the decompression is successful, the status will be set to
 * {@code nvcompSuccess}. If the decompression is not successful, for example due to
 * the corrupted input or out-of-bound errors, the status will be set to
 * {@code nvcompErrorCannotDecompress}.
 * Can be NULL if desired, in which case error status is not reported.
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successfully launched, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedSnappyDecompressAsync(
    @Cast("const void*const*") PointerPointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("const size_t*") SizeTPointer device_uncompressed_buffer_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") PointerPointer device_uncompressed_chunk_ptrs,
    @ByVal nvcompBatchedSnappyDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedSnappyDecompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("const size_t*") SizeTPointer device_uncompressed_buffer_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @ByVal nvcompBatchedSnappyDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedSnappyDecompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("const size_t*") SizeTPointer device_uncompressed_buffer_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @ByVal nvcompBatchedSnappyDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntBuffer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedSnappyDecompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("const size_t*") SizeTPointer device_uncompressed_buffer_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @ByVal nvcompBatchedSnappyDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") int[] device_statuses,
    CUstream_st stream);

// #ifdef __cplusplus
// #endif

// #endif // NVCOMP_SNAPPY_H


// Parsed from <nvcomp/snappy.hpp>

/*
 * SPDX-FileCopyrightText: Copyright (c) 2022-2025 NVIDIA CORPORATION & AFFILIATES.
 * All rights reserved. SPDX-License-Identifier: LicenseRef-NvidiaProprietary
 *
 * NVIDIA CORPORATION, its affiliates and licensors retain all intellectual
 * property and proprietary rights in and to this material, related
 * documentation and any modifications thereto. Any use, reproduction,
 * disclosure or distribution of this material and related documentation
 * without an express license agreement from NVIDIA CORPORATION or
 * its affiliates is strictly prohibited.
*/

// #pragma once

// #include "nvcompManager.hpp"
// #include "snappy.h"
// Targeting ../nvcomp/SnappyFormatSpecHeader.java


// Targeting ../nvcomp/SnappyManager.java



 // namespace nvcomp


// Parsed from <nvcomp/zstd.h>

/*
 * SPDX-FileCopyrightText: Copyright (c) 2022-2025 NVIDIA CORPORATION & AFFILIATES.
 * All rights reserved. SPDX-License-Identifier: LicenseRef-NvidiaProprietary
 *
 * NVIDIA CORPORATION, its affiliates and licensors retain all intellectual
 * property and proprietary rights in and to this material, related
 * documentation and any modifications thereto. Any use, reproduction,
 * disclosure or distribution of this material and related documentation
 * without an express license agreement from NVIDIA CORPORATION or
 * its affiliates is strictly prohibited.
*/

// #ifndef NVCOMP_ZSTD_H
// #define NVCOMP_ZSTD_H

// #include "nvcomp.h"

// #ifdef __cplusplus
// Targeting ../nvcomp/nvcompBatchedZstdCompressOpts_t.java


// Targeting ../nvcomp/nvcompBatchedZstdDecompressOpts_t.java



/**
 * \brief Default Zstd compression options
 */
@MemberGetter public static native @Const @ByRef nvcompBatchedZstdCompressOpts_t nvcompBatchedZstdCompressDefaultOpts();

/**
 * \brief Default Zstd decompression options
 */
@MemberGetter public static native @Const @ByRef nvcompBatchedZstdDecompressOpts_t nvcompBatchedZstdDecompressDefaultOpts();

/**
 * \brief The maximum supported uncompressed chunk size in bytes for the Zstd compressor.
 */
@MemberGetter public static native @Cast("const size_t") long nvcompZstdCompressionMaxAllowedChunkSize();
public static final long nvcompZstdCompressionMaxAllowedChunkSize = nvcompZstdCompressionMaxAllowedChunkSize();

/**
 * \brief The most restrictive of the minimum alignment requirements for void-type CUDA memory buffers
 * used for input, output, or temporary memory, passed to compression functions.
 *
 * \note In all cases, typed memory buffers must still be aligned to their type's size,
 * e.g., 4 bytes for {@code int}.
 */
@MemberGetter public static native @Cast("const size_t") long nvcompZstdRequiredCompressionAlignment();
public static final long nvcompZstdRequiredCompressionAlignment = nvcompZstdRequiredCompressionAlignment();

/**
 * \brief Get the minimum buffer alignment requirements for compression.
 *
 * \note Providing buffers with alignments above the minimum requirements
 * (e.g., 16- or 32-byte alignment) may help improve performance.
 *
 * @param compress_opts [in] Compression options.
 * @param alignment_requirements [out] The minimum buffer alignment requirements
 * for compression.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedZstdCompressGetRequiredAlignments(
    @ByVal nvcompBatchedZstdCompressOpts_t compress_opts,
    nvcompAlignmentRequirements_t alignment_requirements);

/**
 * \brief Get the amount of temporary memory required on the GPU for compression
 * asynchronously.
 *
 * \note For best performance, a chunk size of 65536 bytes is recommended.
 *
 * @param num_chunks [in] The number of chunks of memory in the batch.
 * @param max_uncompressed_chunk_bytes [in] The maximum size of a chunk in the
 * batch.
 * @param compress_opts [in] Compression options.
 * @param temp_bytes [out] The amount of GPU memory that will be temporarily
 * required during compression. The value is returned on the host side.
 * @param max_total_uncompressed_bytes [in] Upper bound on the total uncompressed
 * size of all chunks
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedZstdCompressGetTempSizeAsync(
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedZstdCompressOpts_t compress_opts,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes);

/**
 * \brief Get the amount of temporary memory required on the GPU for compression.
 * synchronously.
 *
 * \note For best performance, a chunk size of 65536 bytes is recommended.
 *
 * @param device_uncompressed_chunk_ptrs [in] Array with size \p num_chunks of pointers
 * to the uncompressed data chunks. Both the pointers and the uncompressed data
 * should reside in device-accessible memory.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedZstdCompressGetRequiredAlignments} when called with the same
 * \p compress_opts.
 * @param device_uncompressed_chunk_bytes [in] Array with size \p num_chunks of
 * sizes of the uncompressed chunks in bytes.
 * The sizes should reside in device-accessible memory.
 * @param num_chunks [in] The number of chunks of memory in the batch.
 * @param max_uncompressed_chunk_bytes [in] The maximum size of a chunk in the
 * batch.
 * @param compress_opts [in] Compression options.
 * @param temp_bytes [out] The amount of GPU memory that will be temporarily
 * required during compression. The value is returned on the host side.
 * @param max_total_uncompressed_bytes [in] Upper bound on the total uncompressed
 * size of all chunks
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedZstdCompressGetTempSizeSync(
    @Cast("const void*const*const") PointerPointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedZstdCompressOpts_t compress_opts,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedZstdCompressGetTempSizeSync(
    @Cast("const void*const*const") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedZstdCompressOpts_t compress_opts,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    CUstream_st stream);

/**
 * \brief Get the maximum size that a chunk of size at most max_uncompressed_chunk_bytes
 * could compress to. That is, the minimum amount of output memory required to be given
 * \ref nvcompBatchedZstdCompressAsync for each chunk.
 *
 * \note For best performance, a chunk size of 65536 bytes is recommended.
 *
 * @param max_uncompressed_chunk_bytes [in] The maximum size of a chunk before compression.
 * @param compress_opts [in] The Zstd compression options to use. Currently empty.
 * @param max_compressed_chunk_bytes [out] The maximum possible compressed size of the chunk.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedZstdCompressGetMaxOutputChunkSize(
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedZstdCompressOpts_t compress_opts,
    @Cast("size_t*") SizeTPointer max_compressed_chunk_bytes);

/**
 * \brief Perform batched asynchronous compression.
 *
 * \note For best performance, a chunk size of 65536 bytes is recommended.
 * Violating any of the conditions listed in the parameter descriptions
 * below may result in undefined behaviour.
 *
 * @param device_uncompressed_chunk_ptrs [in] Array with size \p num_chunks of pointers
 * to the uncompressed data chunks. Both the pointers and the uncompressed data
 * should reside in device-accessible memory.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedZstdCompressGetRequiredAlignments} when called with the same
 * \p compress_opts.
 * @param device_uncompressed_chunk_bytes [in] Array with size \p num_chunks of
 * sizes of the uncompressed chunks in bytes.
 * The sizes should reside in device-accessible memory.
 * Chunk sizes must not exceed 16 MB. For best performance, a chunk size of
 * 64 KB is recommended.
 * @param max_uncompressed_chunk_bytes [in] The size of the largest uncompressed chunk.
 * @param num_chunks [in] Number of chunks of data to compress.
 * @param device_temp_ptr [in] The temporary GPU workspace, could be NULL in case
 * temporary memory is not needed.
 * Must be aligned to the value in the {@code temp} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedZstdCompressGetRequiredAlignments} when called with the same
 * \p compress_opts.
 * @param temp_bytes [in] The size of the temporary GPU memory pointed to by
 * {@code device_temp_ptr}.
 * @param device_compressed_chunk_ptrs [out] Array with size \p num_chunks of pointers
 * to the output compressed buffers. Both the pointers and the compressed
 * buffers should reside in device-accessible memory. Each compressed buffer
 * should be preallocated with the size given by
 * {@code nvcompBatchedZstdCompressGetMaxOutputChunkSize}.
 * Each compressed buffer must be aligned to the value in the {@code output} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedZstdCompressGetRequiredAlignments} when called with the same
 * \p compress_opts.
 * @param device_compressed_chunk_bytes [out] Array with size \p num_chunks,
 * to be filled with the compressed sizes of each chunk.
 * The buffer should be preallocated in device-accessible memory.
 * @param compress_opts [in] The Zstd compression options to use. Currently empty.
 * @param device_statuses [out] Array with size \p num_chunks of statuses in
 * device-accessible memory. This argument needs to be preallocated. For each
 * chunk, if the compression is successful, the status will be set to
 * {@code nvcompSuccess}, and an error code otherwise.
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successfully launched, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedZstdCompressAsync(
    @Cast("const void*const*") PointerPointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") PointerPointer device_compressed_chunk_ptrs,
    @Cast("size_t*") SizeTPointer device_compressed_chunk_bytes,
    @ByVal nvcompBatchedZstdCompressOpts_t compress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedZstdCompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("size_t*") SizeTPointer device_compressed_chunk_bytes,
    @ByVal nvcompBatchedZstdCompressOpts_t compress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedZstdCompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("size_t*") SizeTPointer device_compressed_chunk_bytes,
    @ByVal nvcompBatchedZstdCompressOpts_t compress_opts,
    @Cast("nvcompStatus_t*") IntBuffer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedZstdCompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("size_t*") SizeTPointer device_compressed_chunk_bytes,
    @ByVal nvcompBatchedZstdCompressOpts_t compress_opts,
    @Cast("nvcompStatus_t*") int[] device_statuses,
    CUstream_st stream);

/**
 * \brief The most restrictive of the minimum alignment requirements for void-type CUDA memory buffers
 * used for input, output, or temporary memory, passed to decompression functions.
 *
 * \note In all cases, typed memory buffers must still be aligned to their type's size,
 * e.g., 4 bytes for {@code int}.
 */
@MemberGetter public static native @Cast("const size_t") long nvcompZstdRequiredDecompressionAlignment();
public static final long nvcompZstdRequiredDecompressionAlignment = nvcompZstdRequiredDecompressionAlignment();

/**
 * \brief Get the minimum buffer alignment requirements for decompression.
 *
 * \note Providing buffers with alignments above the minimum requirements
 * (e.g., 16- or 32-byte alignment) may help improve performance.
 *
 * @param decompress_opts [in] Decompression options.
 * @param alignment_requirements [out] The minimum buffer alignment requirements
 * for decompression.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedZstdDecompressGetRequiredAlignments(
    @ByVal nvcompBatchedZstdDecompressOpts_t decompress_opts,
    nvcompAlignmentRequirements_t alignment_requirements);

/**
 * \brief Get the amount of temporary memory required on the GPU for decompression
 * asynchronously.
 *
 * @param num_chunks [in] Number of chunks of data to be decompressed.
 * @param max_uncompressed_chunk_bytes [in] The size of the largest chunk in bytes
 * when uncompressed.
 * @param decompress_opts [in] Decompression options.
 * @param temp_bytes [out] The amount of GPU memory that will be temporarily required
 * during decompression. The value is returned on the host side.
 * @param max_total_uncompressed_bytes [in] The total decompressed size of all the chunks.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedZstdDecompressGetTempSizeAsync(
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @ByVal nvcompBatchedZstdDecompressOpts_t decompress_opts,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes);

/**
 * \brief Get the amount of temporary memory required on the GPU for decompression
 * synchronously.
 *
 * @param device_compressed_chunk_ptrs [in] Array with size \p num_chunks of pointers
 * in device-accessible memory to device-accessible compressed buffers.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedZstdDecompressGetRequiredAlignments}.
 * @param device_compressed_chunk_bytes [in] Array with size \p num_chunks of sizes of
 * the compressed buffers in bytes. The sizes should reside in device-accessible memory.
 * @param num_chunks [in] Number of chunks of data to be decompressed.
 * @param max_uncompressed_chunk_bytes [in] The size of the largest chunk in bytes
 * when uncompressed.
 * @param temp_bytes [out] The amount of GPU memory that will be temporarily required
 * during decompression. The value is returned on the host side.
 * @param max_total_uncompressed_bytes [in]  The total decompressed size of all the chunks.
 * @param decompress_opts [in] Decompression options.
 * @param device_statuses [out] Array with size \p num_chunks of statuses in
 * device-accessible memory. This argument needs to be preallocated. For each
 * chunk, if the data can be parsed successfully, the status will be set to
 * {@code nvcompSuccess}, and an error code otherwise.
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedZstdDecompressGetTempSizeSync(
    @Cast("const void*const*const") PointerPointer device_compressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    @ByVal nvcompBatchedZstdDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedZstdDecompressGetTempSizeSync(
    @Cast("const void*const*const") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    @ByVal nvcompBatchedZstdDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedZstdDecompressGetTempSizeSync(
    @Cast("const void*const*const") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    @ByVal nvcompBatchedZstdDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntBuffer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedZstdDecompressGetTempSizeSync(
    @Cast("const void*const*const") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*const") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    @Cast("size_t") long max_uncompressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer temp_bytes,
    @Cast("size_t") long max_total_uncompressed_bytes,
    @ByVal nvcompBatchedZstdDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") int[] device_statuses,
    CUstream_st stream);

/**
 * \brief Asynchronously compute the number of bytes of uncompressed data for
 * each compressed chunk.
 *
 * \note Violating any of the conditions listed in the parameter descriptions
 * below may result in undefined behaviour.
 *
 * @param device_compressed_chunk_ptrs [in] Array with size \p num_chunks of
 * pointers in device-accessible memory to compressed buffers.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedZstdDecompressGetRequiredAlignments}.
 * @param device_compressed_chunk_bytes [in] Array with size \p num_chunks of sizes
 * of the compressed buffers in bytes. The sizes should reside in device-accessible memory.
 * @param device_uncompressed_chunk_bytes [out] Array with size \p num_chunks
 * to be filled with the sizes, in bytes, of each uncompressed data chunk.
 * If there is an error when retrieving the size of a chunk, the
 * uncompressed size of that chunk will be set to 0. This argument needs to
 * be preallocated in device-accessible memory.
 * @param num_chunks [in] Number of data chunks to compute sizes of.
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successful, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedZstdGetDecompressSizeAsync(
    @Cast("const void*const*") PointerPointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedZstdGetDecompressSizeAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    CUstream_st stream);

/**
 * \brief Perform batched asynchronous decompression.
 *
 * \note Violating any of the conditions listed in the parameter descriptions
 * below may result in undefined behaviour.
 *
 * @param device_compressed_chunk_ptrs [in] Array with size \p num_chunks of pointers
 * in device-accessible memory to device-accessible compressed buffers.
 * Each chunk must be aligned to the value in the {@code input} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedZstdDecompressGetRequiredAlignments}.
 * @param device_compressed_chunk_bytes [in] Array with size \p num_chunks of sizes of
 * the compressed buffers in bytes. The sizes should reside in device-accessible memory.
 * @param device_uncompressed_buffer_bytes [in] Array with size \p num_chunks of sizes,
 * in bytes, of the output buffers to be filled with uncompressed data for each chunk.
 * The sizes should reside in device-accessible memory. If a
 * size is not large enough to hold all decompressed data, the decompressor
 * will set the status in \p device_statuses corresponding to the
 * overflow chunk to {@code nvcompErrorCannotDecompress}.
 * @param device_uncompressed_chunk_bytes [out] Array with size \p num_chunks to
 * be filled with the actual number of bytes decompressed for every chunk.
 * @param num_chunks [in] Number of chunks of data to decompress.
 * @param device_temp_ptr [in] The temporary GPU space, could be NULL in case temporary space is not needed.
  * Must be aligned to the value in the {@code temp} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedZstdDecompressGetRequiredAlignments}.
 * @param temp_bytes [in] The size of the temporary GPU space.
 * @param device_uncompressed_chunk_ptrs [out] Array with size \p num_chunks of
 * pointers in device-accessible memory to decompressed data. Each uncompressed
 * buffer needs to be preallocated in device-accessible memory, have the size
 * specified by the corresponding entry in \p device_uncompressed_buffer_bytes,
 * and be aligned to the value in the {@code output} member of the
 * \ref nvcompAlignmentRequirements_t object output by
 * {@code nvcompBatchedZstdDecompressGetRequiredAlignments}.
 * @param decompress_opts [in] Decompression options.
 * @param device_statuses [out] Array with size \p num_chunks of statuses in
 * device-accessible memory. This argument needs to be preallocated. For each
 * chunk, if the decompression is successful, the status will be set to
 * {@code nvcompSuccess}. If the decompression is not successful, for example due to
 * the corrupted input or out-of-bound errors, the status will be set to
 * {@code nvcompErrorCannotDecompress}.
 * @param stream [in] The CUDA stream to operate on.
 *
 * @return nvcompSuccess if successfully launched, and an error code otherwise.
 */
public static native @Cast("nvcompStatus_t") int nvcompBatchedZstdDecompressAsync(
    @Cast("const void*const*") PointerPointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("const size_t*") SizeTPointer device_uncompressed_buffer_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") PointerPointer device_uncompressed_chunk_ptrs,
    @ByVal nvcompBatchedZstdDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedZstdDecompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("const size_t*") SizeTPointer device_uncompressed_buffer_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @ByVal nvcompBatchedZstdDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntPointer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedZstdDecompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("const size_t*") SizeTPointer device_uncompressed_buffer_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @ByVal nvcompBatchedZstdDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") IntBuffer device_statuses,
    CUstream_st stream);
public static native @Cast("nvcompStatus_t") int nvcompBatchedZstdDecompressAsync(
    @Cast("const void*const*") @ByPtrPtr Pointer device_compressed_chunk_ptrs,
    @Cast("const size_t*") SizeTPointer device_compressed_chunk_bytes,
    @Cast("const size_t*") SizeTPointer device_uncompressed_buffer_bytes,
    @Cast("size_t*") SizeTPointer device_uncompressed_chunk_bytes,
    @Cast("size_t") long num_chunks,
    Pointer device_temp_ptr,
    @Cast("size_t") long temp_bytes,
    @Cast("void*const*") @ByPtrPtr Pointer device_uncompressed_chunk_ptrs,
    @ByVal nvcompBatchedZstdDecompressOpts_t decompress_opts,
    @Cast("nvcompStatus_t*") int[] device_statuses,
    CUstream_st stream);

// #ifdef __cplusplus
// #endif

// #endif // NVCOMP_ZSTD_H


// Parsed from <nvcomp/zstd.hpp>

/*
 * SPDX-FileCopyrightText: Copyright (c) 2023-2025 NVIDIA CORPORATION & AFFILIATES.
 * All rights reserved. SPDX-License-Identifier: LicenseRef-NvidiaProprietary
 *
 * NVIDIA CORPORATION, its affiliates and licensors retain all intellectual
 * property and proprietary rights in and to this material, related
 * documentation and any modifications thereto. Any use, reproduction,
 * disclosure or distribution of this material and related documentation
 * without an express license agreement from NVIDIA CORPORATION or
 * its affiliates is strictly prohibited.
*/

// #pragma once

// #include "nvcompManager.hpp"
// #include "zstd.h"
// Targeting ../nvcomp/ZstdFormatSpecHeader.java


// Targeting ../nvcomp/ZstdManager.java



 // namespace nvcomp


}
