// Targeted by JavaCPP version 1.5.12-SNAPSHOT: DO NOT EDIT THIS FILE

package org.bytedeco.tensorflowlite;

import java.nio.*;
import org.bytedeco.javacpp.*;
import org.bytedeco.javacpp.annotation.*;

import static org.bytedeco.tensorflowlite.global.tensorflowlite.*;


/** {@code TfLiteRegistration} defines the implementation of an operation
 *  (a built-in op, custom op, or custom delegate kernel).
 * 
 *  It is a struct containing "methods" (C function pointers) that will be
 *  invoked by the TF Lite runtime to evaluate instances of the operation.
 * 
 *  See also {@code TfLiteOperator} which is a more ABI-stable equivalent. */
@Properties(inherit = org.bytedeco.tensorflowlite.presets.tensorflowlite.class)
public class TfLiteRegistration extends Pointer {
    static { Loader.load(); }
    /** Default native constructor. */
    public TfLiteRegistration() { super((Pointer)null); allocate(); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public TfLiteRegistration(long size) { super((Pointer)null); allocateArray(size); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public TfLiteRegistration(Pointer p) { super(p); }
    private native void allocate();
    private native void allocateArray(long size);
    @Override public TfLiteRegistration position(long position) {
        return (TfLiteRegistration)super.position(position);
    }
    @Override public TfLiteRegistration getPointer(long i) {
        return new TfLiteRegistration((Pointer)this).offsetAddress(i);
    }

  /** Initializes the op from serialized data.
   *  Called only *once* for the lifetime of the op, so any one-time allocations
   *  should be made here (unless they depend on tensor sizes).
   * 
   *  * If a built-in op:
   *        * {@code buffer} is the op's params data (TfLiteLSTMParams*).
   *        * {@code length} is zero.
   *  * If custom op:
   *        * {@code buffer} is the op's {@code custom_options}.
   *        * {@code length} is the size of the buffer.
   * 
   *  Returns a type-punned (i.e. void*) opaque data (e.g. a primitive pointer
   *  or an instance of a struct).
   * 
   *  The returned pointer will be stored with the node in the {@code user_data}
   *  field, accessible within prepare and invoke functions below.
   * 
   *  NOTE: if the data is already in the desired format, simply implement this
   *  function to return {@code nullptr} and implement the free function to be a
   *  no-op. */
  public static class Init_TfLiteContext_BytePointer_long extends FunctionPointer {
      static { Loader.load(); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public    Init_TfLiteContext_BytePointer_long(Pointer p) { super(p); }
      protected Init_TfLiteContext_BytePointer_long() { allocate(); }
      private native void allocate();
      public native Pointer call(TfLiteContext context, @Cast("const char*") BytePointer buffer, @Cast("size_t") long length);
  }
  public native Init_TfLiteContext_BytePointer_long init(); public native TfLiteRegistration init(Init_TfLiteContext_BytePointer_long setter);

  /** The pointer {@code buffer} is the data previously returned by an init
   *  invocation. */
  public static class Free_TfLiteContext_Pointer extends FunctionPointer {
      static { Loader.load(); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public    Free_TfLiteContext_Pointer(Pointer p) { super(p); }
      protected Free_TfLiteContext_Pointer() { allocate(); }
      private native void allocate();
      public native void call(TfLiteContext context, Pointer buffer);
  }
  
  ///
  public native @Name("free") Free_TfLiteContext_Pointer _free(); public native TfLiteRegistration _free(Free_TfLiteContext_Pointer setter);

  /** prepare is called when the inputs this node depends on have been resized.
   *  {@code context->ResizeTensor()} can be called to request output tensors to be
   *  resized.
   *  Can be called multiple times for the lifetime of the op.
   * 
   *  Returns {@code kTfLiteOk} on success. */
  public static class Prepare_TfLiteContext_TfLiteNode extends FunctionPointer {
      static { Loader.load(); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public    Prepare_TfLiteContext_TfLiteNode(Pointer p) { super(p); }
      protected Prepare_TfLiteContext_TfLiteNode() { allocate(); }
      private native void allocate();
      public native @Cast("TfLiteStatus") int call(TfLiteContext context, TfLiteNode node);
  }
  
  ///
  public native Prepare_TfLiteContext_TfLiteNode prepare(); public native TfLiteRegistration prepare(Prepare_TfLiteContext_TfLiteNode setter);

  /** Execute the node (should read {@code node->inputs} and output to
   *  {@code node->outputs}).
   * 
   *  Returns {@code kTfLiteOk} on success. */
  public static class Invoke_TfLiteContext_TfLiteNode extends FunctionPointer {
      static { Loader.load(); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public    Invoke_TfLiteContext_TfLiteNode(Pointer p) { super(p); }
      protected Invoke_TfLiteContext_TfLiteNode() { allocate(); }
      private native void allocate();
      public native @Cast("TfLiteStatus") int call(TfLiteContext context, TfLiteNode node);
  }
  public native Invoke_TfLiteContext_TfLiteNode invoke(); public native TfLiteRegistration invoke(Invoke_TfLiteContext_TfLiteNode setter);

  /** {@code profiling_string} is called during summarization of profiling information
   *  in order to group executions together. Providing a value here will cause a
   *  given op to appear multiple times is the profiling report. This is
   *  particularly useful for custom ops that can perform significantly
   *  different calculations depending on their {@code user-data}. */
  public static class Profiling_string_TfLiteContext_TfLiteNode extends FunctionPointer {
      static { Loader.load(); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public    Profiling_string_TfLiteContext_TfLiteNode(Pointer p) { super(p); }
      protected Profiling_string_TfLiteContext_TfLiteNode() { allocate(); }
      private native void allocate();
      public native @Cast("const char*") BytePointer call(@Const TfLiteContext context,
                                    @Const TfLiteNode node);
  }
  
  ///
  public native Profiling_string_TfLiteContext_TfLiteNode profiling_string(); public native TfLiteRegistration profiling_string(Profiling_string_TfLiteContext_TfLiteNode setter);

  /** Builtin codes. If this kernel refers to a builtin this is the code
   *  of the builtin. This is so we can do marshaling to other frameworks like
   *  NN API.
   * 
   *  Note: It is the responsibility of the registration binder to set this
   *  properly. */
  
  ///
  ///
  public native int builtin_code(); public native TfLiteRegistration builtin_code(int setter);

  /** Custom op name. If the op is a builtin, this will be {@code null}.
   * 
   *  Note: It is the responsibility of the registration binder to set this
   *  properly.
   * 
   *  WARNING: This is an experimental interface that is subject to change. */
  public native @Cast("const char*") BytePointer custom_name(); public native TfLiteRegistration custom_name(BytePointer setter);

  /** The version of the op.
   *  Note: It is the responsibility of the registration binder to set this
   *  properly. */
  public native int version(); public native TfLiteRegistration version(int setter);

  /** The external (i.e. ABI-stable) version of {@code TfLiteRegistration}.
   *  Since we can't use internal types (such as {@code TfLiteContext}) for C API to
   *  maintain ABI stability.  C API user will provide {@code TfLiteOperator} to
   *  implement custom ops.  We keep it inside of {@code TfLiteRegistration} and use
   *  it to route callbacks properly. */
  
  ///
  public native TfLiteOperator registration_external(); public native TfLiteRegistration registration_external(TfLiteOperator setter);

  /** Retrieves asynchronous kernel.
   * 
   *  If the {@code async_kernel} field is nullptr, it means the operation described
   *  by this TfLiteRegistration object does not support asynchronous execution.
   *  Otherwise, the function that the field points to should only be called for
   *  delegate kernel nodes, i.e. {@code node} should be a delegate kernel node
   *  created by applying a delegate. If the function returns nullptr, that
   *  means that the underlying delegate does not support asynchronous execution
   *  for this {@code node}. */

  /** Indicates if an operator's output may safely overwrite its inputs.
   *  See the comments in {@code TfLiteInPlaceOp}. */
  public native @Cast("uint64_t") long inplace_operator(); public native TfLiteRegistration inplace_operator(long setter);
}
