// Targeted by JavaCPP version 1.4.4-SNAPSHOT: DO NOT EDIT THIS FILE

package org.bytedeco.javacpp;

import java.nio.*;
import org.bytedeco.javacpp.*;
import org.bytedeco.javacpp.annotation.*;

import static org.bytedeco.javacpp.mklml.*;

public class mkldnn extends org.bytedeco.javacpp.presets.mkldnn {
    static { Loader.load(); }

@Name("std::vector<mkldnn_primitive_desc_t>") public static class mkldnn_primitive_desc_vector extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public mkldnn_primitive_desc_vector(Pointer p) { super(p); }
    public mkldnn_primitive_desc_vector(mkldnn_primitive_desc value) { this(1); put(0, value); }
    public mkldnn_primitive_desc_vector(mkldnn_primitive_desc ... array) { this(array.length); put(array); }
    public mkldnn_primitive_desc_vector()       { allocate();  }
    public mkldnn_primitive_desc_vector(long n) { allocate(n); }
    private native void allocate();
    private native void allocate(@Cast("size_t") long n);
    public native @Name("operator=") @ByRef mkldnn_primitive_desc_vector put(@ByRef mkldnn_primitive_desc_vector x);

    public boolean empty() { return size() == 0; }
    public native long size();
    public void clear() { resize(0); }
    public native void resize(@Cast("size_t") long n);

    @Index(function = "at") public native mkldnn_primitive_desc get(@Cast("size_t") long i);
    public native mkldnn_primitive_desc_vector put(@Cast("size_t") long i, mkldnn_primitive_desc value);

    public native @ByVal Iterator insert(@ByVal Iterator pos, mkldnn_primitive_desc value);
    public native @ByVal Iterator erase(@ByVal Iterator pos);
    public native @ByVal Iterator begin();
    public native @ByVal Iterator end();
    @NoOffset @Name("iterator") public static class Iterator extends Pointer {
        public Iterator(Pointer p) { super(p); }
        public Iterator() { }

        public native @Name("operator++") @ByRef Iterator increment();
        public native @Name("operator==") boolean equals(@ByRef Iterator it);
        public native @Name("operator*") mkldnn_primitive_desc get();
    }

    public mkldnn_primitive_desc[] get() {
        mkldnn_primitive_desc[] array = new mkldnn_primitive_desc[size() < Integer.MAX_VALUE ? (int)size() : Integer.MAX_VALUE];
        for (int i = 0; i < array.length; i++) {
            array[i] = get(i);
        }
        return array;
    }
    @Override public String toString() {
        return java.util.Arrays.toString(get());
    }

    public mkldnn_primitive_desc pop_back() {
        long size = size();
        mkldnn_primitive_desc value = get(size - 1);
        resize(size - 1);
        return value;
    }
    public mkldnn_primitive_desc_vector push_back(mkldnn_primitive_desc value) {
        long size = size();
        resize(size + 1);
        return put(size, value);
    }
    public mkldnn_primitive_desc_vector put(mkldnn_primitive_desc value) {
        if (size() != 1) { resize(1); }
        return put(0, value);
    }
    public mkldnn_primitive_desc_vector put(mkldnn_primitive_desc ... array) {
        if (size() != array.length) { resize(array.length); }
        for (int i = 0; i < array.length; i++) {
            put(i, array[i]);
        }
        return this;
    }
}

@Name("std::vector<mkldnn::primitive>") public static class primitive_vector extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public primitive_vector(Pointer p) { super(p); }
    public primitive_vector(primitive value) { this(1); put(0, value); }
    public primitive_vector(primitive ... array) { this(array.length); put(array); }
    public primitive_vector()       { allocate();  }
    public primitive_vector(long n) { allocate(n); }
    private native void allocate();
    private native void allocate(@Cast("size_t") long n);
    public native @Name("operator=") @ByRef primitive_vector put(@ByRef primitive_vector x);

    public boolean empty() { return size() == 0; }
    public native long size();
    public void clear() { resize(0); }
    public native void resize(@Cast("size_t") long n);

    @Index(function = "at") public native @ByRef primitive get(@Cast("size_t") long i);
    public native primitive_vector put(@Cast("size_t") long i, primitive value);

    public native @ByVal Iterator insert(@ByVal Iterator pos, @ByRef primitive value);
    public native @ByVal Iterator erase(@ByVal Iterator pos);
    public native @ByVal Iterator begin();
    public native @ByVal Iterator end();
    @NoOffset @Name("iterator") public static class Iterator extends Pointer {
        public Iterator(Pointer p) { super(p); }
        public Iterator() { }

        public native @Name("operator++") @ByRef Iterator increment();
        public native @Name("operator==") boolean equals(@ByRef Iterator it);
        public native @Name("operator*") @ByRef @Const primitive get();
    }

    public primitive[] get() {
        primitive[] array = new primitive[size() < Integer.MAX_VALUE ? (int)size() : Integer.MAX_VALUE];
        for (int i = 0; i < array.length; i++) {
            array[i] = get(i);
        }
        return array;
    }
    @Override public String toString() {
        return java.util.Arrays.toString(get());
    }

    public primitive pop_back() {
        long size = size();
        primitive value = get(size - 1);
        resize(size - 1);
        return value;
    }
    public primitive_vector push_back(primitive value) {
        long size = size();
        resize(size + 1);
        return put(size, value);
    }
    public primitive_vector put(primitive value) {
        if (size() != 1) { resize(1); }
        return put(0, value);
    }
    public primitive_vector put(primitive ... array) {
        if (size() != array.length) { resize(array.length); }
        for (int i = 0; i < array.length; i++) {
            put(i, array[i]);
        }
        return this;
    }
}

@Name("std::vector<mkldnn::memory::primitive_desc>") public static class memory_primitive_desc_vector extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public memory_primitive_desc_vector(Pointer p) { super(p); }
    public memory_primitive_desc_vector(memory.primitive_desc value) { this(1); put(0, value); }
    public memory_primitive_desc_vector(memory.primitive_desc ... array) { this(array.length); put(array); }
    public memory_primitive_desc_vector()       { allocate();  }
    public memory_primitive_desc_vector(long n) { allocate(n); }
    private native void allocate();
    private native void allocate(@Cast("size_t") long n);
    public native @Name("operator=") @ByRef memory_primitive_desc_vector put(@ByRef memory_primitive_desc_vector x);

    public boolean empty() { return size() == 0; }
    public native long size();
    public void clear() { resize(0); }
    public native void resize(@Cast("size_t") long n);

    @Index(function = "at") public native @ByRef memory.primitive_desc get(@Cast("size_t") long i);
    public native memory_primitive_desc_vector put(@Cast("size_t") long i, memory.primitive_desc value);

    public native @ByVal Iterator insert(@ByVal Iterator pos, @ByRef memory.primitive_desc value);
    public native @ByVal Iterator erase(@ByVal Iterator pos);
    public native @ByVal Iterator begin();
    public native @ByVal Iterator end();
    @NoOffset @Name("iterator") public static class Iterator extends Pointer {
        public Iterator(Pointer p) { super(p); }
        public Iterator() { }

        public native @Name("operator++") @ByRef Iterator increment();
        public native @Name("operator==") boolean equals(@ByRef Iterator it);
        public native @Name("operator*") @ByRef @Const memory.primitive_desc get();
    }

    public memory.primitive_desc[] get() {
        memory.primitive_desc[] array = new memory.primitive_desc[size() < Integer.MAX_VALUE ? (int)size() : Integer.MAX_VALUE];
        for (int i = 0; i < array.length; i++) {
            array[i] = get(i);
        }
        return array;
    }
    @Override public String toString() {
        return java.util.Arrays.toString(get());
    }

    public memory.primitive_desc pop_back() {
        long size = size();
        memory.primitive_desc value = get(size - 1);
        resize(size - 1);
        return value;
    }
    public memory_primitive_desc_vector push_back(memory.primitive_desc value) {
        long size = size();
        resize(size + 1);
        return put(size, value);
    }
    public memory_primitive_desc_vector put(memory.primitive_desc value) {
        if (size() != 1) { resize(1); }
        return put(0, value);
    }
    public memory_primitive_desc_vector put(memory.primitive_desc ... array) {
        if (size() != array.length) { resize(array.length); }
        for (int i = 0; i < array.length; i++) {
            put(i, array[i]);
        }
        return this;
    }
}

// Parsed from mkldnn_types.h

/*******************************************************************************
* Copyright 2016-2018 Intel Corporation
*
* Licensed under the Apache License, Version 2.0 (the "License");
* you may not use this file except in compliance with the License.
* You may obtain a copy of the License at
*
*     http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
* See the License for the specific language governing permissions and
* limitations under the License.
*******************************************************************************/

// #ifndef MKLDNN_TYPES_H
// #define MKLDNN_TYPES_H

// #ifdef __cplusplus
// #endif

// #ifndef DOXYGEN_SHOULD_SKIP_THIS
// #endif

/** \addtogroup c_api C API
 *  \{
 *
 *  \addtogroup c_api_types Types
 *  \{
 *
 *  \addtogroup c_api_types_generic Generic
 *  \{ */

/** Status values returned by Intel(R) MKL-DNN functions. */
/** enum mkldnn_status_t */
public static final int
    /** The operation was successful */
    mkldnn_success = 0,
    /** The operation failed due to an out-of-memory condition */
    mkldnn_out_of_memory = 1,
    /** The operation failed and should be retried */
    mkldnn_try_again = 2,
    /** The operation failed because of incorrect function arguments  */
    mkldnn_invalid_arguments = 3,
    /** The operation failed because a primitive was not ready for execution */
    mkldnn_not_ready = 4,
    /** The operation failed because requested functionality is not implemented
     */
    mkldnn_unimplemented = 5,
    /** Primitive iterator passed over last primitive descriptor */
    mkldnn_iterator_ends = 6,
    /** Primitive or engine failed on execution */
    mkldnn_runtime_error = 7,
    /** Queried element is not required for given primitive */
    mkldnn_not_required = 8;

/** Data type specification */
/** enum mkldnn_data_type_t */
public static final int
    /** Undefined data type, used for empty memory descriptors. */
    mkldnn_data_type_undef = 0,
    /** 32-bit/single-precision floating point. */
    mkldnn_f32 = 1,
    /** 32-bit signed integer. */
    mkldnn_s32 = 2,
    /** 16-bit signed integer. */
    mkldnn_s16 = 4,
    /** 8-bit signed integer. */
    mkldnn_s8 = 5,
    /** 8-bit unsigned integer. */
    mkldnn_u8 = 6;

/** Rounding mode */
/** enum mkldnn_round_mode_t */
public static final int
    /** Round nearest */
    mkldnn_round_nearest = 1,
    /** Round down */
    mkldnn_round_down = 2;

/** Memory format specification.
 *
 * Intel MKL-DNN formats describe physical data layout. The physical layout
 * is described as a sequence of the dimensions as they are laid out in the
 * memory (from the outer-most to the inner-most). Note that this order
 * doesn't affect the logical order of the dimensions that is kept in the
 * {@code dims} field of mkldnn_memory_desc_t structure. The logical order of the
 * dimensions is specified by the type of tensor.
 *
 * For example, CNN 5D tensor always has its logical dimensions in order
 * {@code (batch, channels, depth, height, width)}, while physical layout might
 * be #mkldnn_ncdhw or #mkldnn_ndhwc:
 *
 * ~~~cpp
 * int batch = 2, channels = 16, depth = 13, height = 13, width = 13;
 *
 * int ndims = 5; // 5D tensor
 * mkldnn_dims_t dims = {batch, channels, depth, height, width};
 *
 * mkldnn_memory_desc_t data_in_ncdhw;
 * mkldnn_memory_desc_init(&data_in_ncdhw, 5, dims, mlkdnn_ncdhw);
 *
 * // note that in both cases dims passed are the same
 * mkldnn_memory_desc_t data_in_ndhwc;
 * mkldnn_memory_desc_init(&data_in_ndhwc, 5, dims, mlkdnn_ndhwc);
 * ~~~
 *
 * The following notation for memory format names:
 *  - \c 'n' denotes the mini-batch dimension
 *  - \c 'c' denotes a channels dimension
 *  - When there are multiple channel dimensions (for example, in convolution
 *    weights tensor), \c 'i' and \c 'o' denote dimensions of input and output
 *    channels
 *  - \c 'd', \c 'h', and \c 'w' denote spatial depth, height, and width
 *    respectively
 *  - Upper-case letters indicate that the data is laid out in blocks
 *    for a particular dimension. In such cases, the format name contains both
 *    upper- and lower-case letters for that dimension with lower-case letter
 *    preceded by the block size. For example: \c 'mkldnn_nChw8c' describes a
 *    format where the outermost dimension is mini-batch, followed by the
 *    channel block number, followed by the spatial height and width, and
 *    finally followed by 8-element channel blocks.
 *
 * \note
 *    Channel designations can be different. For example: both the \c
 *    'mkldnn_nc' and \c 'mkldnn_io' formats can be used to describe a 2D
 *    tensor.
 *
 * \sa \ref understanding_memory_formats
 */
/** enum mkldnn_memory_format_t */
public static final int
    /** Undefined memory format, used for empty memory descriptors. */
    mkldnn_format_undef = 0,
    /** Unspecified format. The primitive selects a format
     * automatically. */
    mkldnn_any = 1,
    /** A tensor in a generic format described by the stride and blocking
     * values in each dimension. See #mkldnn_blocking_desc_t for more
     * information. */
    mkldnn_blocked = 2,
    /** 1D data tensor. */
    mkldnn_x = 3,
    /** 2D data tensor. */
    mkldnn_nc = 4,
    /** 3D data tensor with the physical layout \c ncw.
     * Logical dimensions come in the order: (n, c, w) */
    mkldnn_ncw = 5,
    /** 3D data tensor with the physical layout \c nwc.
     * Logical dimensions come in the order: (n, c, w) */
    mkldnn_nwc = 6,
    /** 4D data tensor with the physical layout \c nchw, used in Caffe.
     * Logical dimensions come in the order: (n, c, h, w) */
    mkldnn_nchw = 7,
    /** 4D data tensor with the physical layout \c nhwc, used in TensorFlow.
     * Logical dimensions come in the order: (n, c, h, w) */
    mkldnn_nhwc = 8,
    /** 4D data tensor with the physical layout \c chwn, used in Neon.
     * Logical dimensions come in the order: (n, c, h, w) */
    mkldnn_chwn = 9,
    /** 5D data tensor with the physical layout \c ncdhw.
     * Logical dimensions come in the order: (n, c, d, h, w) */
    mkldnn_ncdhw = 10,
    /** 5D data tensor with the physical layout \c ndhwc, used in TensorFlow.
     * Logical dimensions come in the order: (n, c, d, h, w) */
    mkldnn_ndhwc = 11,
    /** 2D weights tensor with physical layout \c oi.
     * Logical dimensions come in the order: (o, i) */
    mkldnn_oi = 12,
    /** 2D weights tensor with physical layout \c io.
     * Logical dimensions come in the order: (o, i) */
    mkldnn_io = 13,
    /** 3D weights tensor with physical layout \c oiw.
     * Logical dimensions come in the order: (o, i, w) */
    mkldnn_oiw = 14,
    /** 3D weights tensor with physical layout \c wio.
     * Logical dimensions come in the order: (o, i, w) */
    mkldnn_wio = 15,
    /** 4D weights tensor with physical layout \c oihw, used in Caffe.
     * Logical dimensions come in the order: (o, i, h, w) */
    mkldnn_oihw = 16,
    /** 4D weights tensor with physical layout \c hwio, used in TensorFlow.
     * Logical dimensions come in the order: (o, i, h, w) */
    mkldnn_hwio = 17,
    /** 4D weights tensor with physical layout \c ihwo.
     * Logical dimensions come in the order: (o, i, h, w) */
    mkldnn_ihwo = 18,
    /** 5D weights tensor with physical layout \c iodhw, used in Caffe.
     * Logical dimensions come in the order: (o, i, d, h, w) */
    mkldnn_oidhw = 19,
    /** 5D weights tensor with physical layout \c dhwio, used in TensorFlow.
     * Logical dimensions come in the order: (o, i, d, h, w) */
    mkldnn_dhwio = 20,
    /** 4D grouped weights tensor with the physical layout \c goiw.
     * Logical dimensions come in the order: (g, o, i, w) */
    mkldnn_goiw = 21,
    /** 5D grouped weights tensor with the physical layout \c goihw,
     * used in Caffe.
     * Logical dimensions come in the order: (g, o, i, h, w) */
    mkldnn_goihw = 22,
    /** 5D grouped weights tensor with the physical layout \c hwigo,
     * used in TensorFlow.
     * Logical dimensions come in the order: (g, o, i, h, w) */
    mkldnn_hwigo = 23,
    /** 6D grouped weights tensor with the physical layout \c goidhw,
     * used in Caffe.
     * Logical dimensions come in the order: (g, o, i, d, h, w) */
    mkldnn_goidhw = 24,
    /** 3D RNN data tensor in the format (batch, seq_length, input channels). */
    mkldnn_ntc = 25,
    /** 3D RNN data tensor in the format (seq_length, batch, input channels). */
    mkldnn_tnc = 26,
    /** 5D RNN states tensor in the format (num_layers, num_directions,
     * num_states, batch, state channels). */
    mkldnn_ldsnc = 27,
    /** 5D RNN weights tensor in the format (num_layers, num_directions,
     *  input_channels, num_gates, output_channels).
     *
     *  - For LSTM cells, the gates order is input, forget, candidate
     *    and output gate.
     *  - For GRU cells, the gates order is update, reset and output gate. */
    mkldnn_ldigo = 28,
    /** 5D RNN weights tensor in the format (num_layers, num_directions,
     * num_gates, output_channels, input_channels).
     *
     *  - For LSTM cells, the gates order is input, forget, candidate
     *    and output gate.
     *  - For GRU cells, the gates order is update, reset and output gate. */
    mkldnn_ldgoi = 29,
    /** 4D RNN bias tensor in the format (num_layers, num_directions,
     * num_gates, output_channels).
     *
     *  - For LSTM cells, the gates order is input, forget, candidate
     *    and output gate.
     * - For GRU cells, the gates order is update, reset and output gate. */
    mkldnn_ldgo = 30,

    /* Opaque data types, are not to be used explicitly */

    /* data */
    mkldnn_nCw8c = 31,
    mkldnn_nCw16c = 32,
    mkldnn_nChw8c = 33,
    mkldnn_nChw16c = 34,
    mkldnn_nCdhw8c = 35,
    mkldnn_nCdhw16c = 36,

    /* weights, 3D */
    mkldnn_Owi8o = 37,
    mkldnn_OIw8i8o = 38,
    mkldnn_OIw8o8i = 39,
    mkldnn_OIw16i16o = 40,
    mkldnn_OIw16o16i = 41,
    mkldnn_Oiw16o = 42,
    mkldnn_Owi16o = 43,
    mkldnn_OIw8i16o2i = 44,
    mkldnn_OIw8o16i2o = 45,
    mkldnn_IOw16o16i = 46,

    /* weights, 4D */
    /** weights format with additional buffer
     * size equal to the number of output channels
     * and containing the values:
     * O[i:0,OC] = -128 * SUM(j:0,IC;h:0,H;w:0,W)(weights(i,j,h,w))*/
    mkldnn_hwio_s8s8 = 47,
    mkldnn_oIhw8i = 48,
    mkldnn_oIhw16i = 49,
    mkldnn_OIhw8i8o = 50,
    mkldnn_OIhw16i16o = 51,
    mkldnn_OIhw4i16o4i = 52,
    /** blocked weights format with additional buffer
     * with size equal to the number of output channels
     * and containing the values:
     * O[i:0,OC] = -128 * SUM(j:0,IC;h:0,H;w:0,W)(weights(i,j,h,w))*/
    mkldnn_OIhw4i16o4i_s8s8 = 53,
    mkldnn_OIhw8i16o2i = 54,
    mkldnn_OIhw8o16i2o = 55,
    mkldnn_OIhw8o8i = 56,
    mkldnn_OIhw16o16i = 57,
    mkldnn_IOhw16o16i = 58,
    mkldnn_Oihw8o = 59,
    mkldnn_Oihw16o = 60,
    mkldnn_Ohwi8o = 61,
    mkldnn_Ohwi16o = 62,
    mkldnn_OhIw16o4i = 63,

    /* weights, 5D */
    mkldnn_oIdhw8i = 64,
    mkldnn_oIdhw16i = 65,
    mkldnn_OIdhw8i8o = 66,
    mkldnn_OIdhw8o8i = 67,
    mkldnn_Odhwi8o = 68,
    mkldnn_OIdhw16i16o = 69,
    mkldnn_OIdhw16o16i = 70,
    mkldnn_Oidhw16o = 71,
    mkldnn_Odhwi16o = 72,
    mkldnn_OIdhw8i16o2i = 73,

    /* weights w/ groups, 4D */
    mkldnn_gOwi8o = 74,
    mkldnn_gOIw8o8i = 75,
    mkldnn_gOIw8i8o = 76,
    mkldnn_gOIw16i16o = 77,
    mkldnn_gOIw16o16i = 78,
    mkldnn_gOiw16o = 79,
    mkldnn_gOwi16o = 80,
    mkldnn_gOIw8i16o2i = 81,
    mkldnn_gOIw8o16i2o = 82,
    mkldnn_gIOw16o16i = 83,

    /* weights w/ groups, 5D */
    /** weights format with additional buffer
     * size equal to the number of output channels
     * multiplied by number of groups and containing the values:
     * O[i:0,G*OC] = -128 * SUM(j:0,IC;h:0,H;w:0,W)(weights(i,j,h,w))*/
    mkldnn_hwigo_s8s8 = 84,
    mkldnn_gOIhw8i8o = 85,
    mkldnn_gOIhw16i16o = 86,
    mkldnn_gOIhw4i16o4i = 87,
    /** blocked weights format with additional buffer
     * with size equal to the number of output channels
     * multiplied by number of groups and containing the values:
     * O[i:0,G*OC] = -128 * SUM(j:0,IC;h:0,H;w:0,W)(weights(i,j,h,w))*/
    mkldnn_gOIhw4i16o4i_s8s8 = 88,
    mkldnn_gOIhw8i16o2i = 89,
    mkldnn_gOIhw8o16i2o = 90,
    mkldnn_gOIhw8o8i = 91,
    mkldnn_gOIhw16o16i = 92,
    mkldnn_gIOhw16o16i = 93,
    mkldnn_gOihw8o = 94,
    mkldnn_gOihw16o = 95,
    mkldnn_gOhwi8o = 96,
    mkldnn_gOhwi16o = 97,
    mkldnn_Goihw8g = 98,
    mkldnn_Goihw16g = 99,
    mkldnn_gOhIw16o4i = 100,

    /* weights w/ groups, 6D */
    mkldnn_gOIdhw8i8o = 101,
    mkldnn_gOIdhw8o8i = 102,
    mkldnn_gOdhwi8o = 103,
    mkldnn_gOIdhw8i16o2i = 104,
    mkldnn_gOIdhw16i16o = 105,
    mkldnn_gOIdhw16o16i = 106,
    mkldnn_gOidhw16o = 107,
    mkldnn_gOdhwi16o = 108,

    mkldnn_wino_fmt = 109,

    /* RNN packed weights */
    mkldnn_ldigo_p = 110,
    mkldnn_ldgoi_p = 111,

    /** Just a sentinel, not real memory format. Must be changed after new
     * format is added. */
    mkldnn_format_last = 112;

/** Kinds of padding. Define how to interpret the data in padding regions. */
/** enum mkldnn_padding_kind_t */
public static final int
    /** The data in padding regions is zero. */
    mkldnn_padding_zero = 0;

/** Kinds of propagation. */
/** enum mkldnn_prop_kind_t */
public static final int
    /* TODO: suggest renames */
    /** Undefined propagation type. */
    mkldnn_prop_kind_undef = 0,
    /** Forward data propagation (training mode). In this mode primitives
     * perform computations necessary for subsequent backward propagation. */
    mkldnn_forward_training = 64,
    /** Forward data propagation (inference mode). In this mode primitives only
     * perform computations that are necessary for inference and omit
     * computations that are only necessary for backward propagation. */
    mkldnn_forward_inference = 96,
    /** Forward data propagation (alias for \c mkldnn_forward_inference) */
    mkldnn_forward_scoring = mkldnn_forward_inference,
   /** Forward data propagation (alias for \c mkldnn_forward_training) */
    mkldnn_forward = mkldnn_forward_training,
    /** Backward propagation (with respect to all parameters */
    mkldnn_backward = 128,
    /** Backward data propagation */
    mkldnn_backward_data = 160,
    /** Backward weights propagation */
    mkldnn_backward_weights = 192,
    /** Backward bias propagation */
    mkldnn_backward_bias = 193;

/** Kinds of primitives. Used to implement a way to extend the library with new
 * primitives without changing the ABI. */
/** enum mkldnn_primitive_kind_t */
public static final int
    /** Undefined primitive (XXX: why do we have it?). */
    mkldnn_undefined_primitive = 0,
    /** A memory primitive. */
    mkldnn_memory = 1,
    /** A view primitive. */
    mkldnn_view = 2,
    /** A reorder primitive.*/
    mkldnn_reorder = 3,
    /** A shuffle primitive.*/
    mkldnn_shuffle = 4,
    /** A (out-of-place) concat primitive. */
    mkldnn_concat = 5,
    /** A (in-place) concat primitive. */
    mkldnn_concat_inplace = 6,
    /** A sum primitive. */
    mkldnn_sum = 7,
    /** A convolution primitive. */
    mkldnn_convolution = 8,
    /** A deconvolution primitive. */
    mkldnn_deconvolution = 9,
    /** An element-wise primitive. */
    mkldnn_eltwise = 10,
    /** A ReLU primitive. @deprecated */
    mkldnn_relu = mkldnn_eltwise,
    /** A Softmax primitive. */
    mkldnn_softmax = mkldnn_eltwise + 1,
    /** A pooling primitive. */
    mkldnn_pooling = mkldnn_eltwise + 2,
    /** An LRN primitive. */
    mkldnn_lrn = mkldnn_eltwise + 3,
    /** An batch normalization primitive. */
    mkldnn_batch_normalization = mkldnn_eltwise + 4,
    /** An inner product primitive. */
    mkldnn_inner_product = mkldnn_eltwise + 5,
    /** A convolution primitive merged with ReLU. @deprecated */
    mkldnn_convolution_relu = mkldnn_eltwise + 6,
    /** A rnn primitive. */
    mkldnn_rnn = mkldnn_eltwise + 7;

/** Kinds of algorithms. */
/** enum mkldnn_alg_kind_t */
public static final int
    mkldnn_alg_kind_undef = 0,
    /** Direct convolution */
    mkldnn_convolution_direct = 1,
    /** Winograd convolution */
    mkldnn_convolution_winograd = 2,
    /** Eltwise: ReLU */
    mkldnn_eltwise_relu = 8,
    /** Eltwise: hyperbolic tangent non-linearity (tanh) */
    mkldnn_eltwise_tanh = 9,
    /** Eltwise: parametric exponential linear unit (elu) */
    mkldnn_eltwise_elu = 10,
    /** Eltwise: square */
    mkldnn_eltwise_square = 11,
    /** Eltwise: abs */
    mkldnn_eltwise_abs = 12,
    /** Eltwise: square root */
    mkldnn_eltwise_sqrt = 13,
    /** Eltwise: linear */
    mkldnn_eltwise_linear = 14,
    /** Eltwise: bounded_relu */
    mkldnn_eltwise_bounded_relu = 15,
    /** Eltwise: soft_relu */
    mkldnn_eltwise_soft_relu = 16,
    /** Eltwise: logistic */
    mkldnn_eltwise_logistic = 17,
    /** Max pooling */
    mkldnn_pooling_max = 34,
    /** Average pooling include padding */
    mkldnn_pooling_avg_include_padding = 40,
    /** Average pooling exclude padding */
    mkldnn_pooling_avg_exclude_padding = 41,
    mkldnn_pooling_avg = mkldnn_pooling_avg_exclude_padding,
    /** Local response normalization (LRN) across multiple channels */
    mkldnn_lrn_across_channels = 65,
    /** LRN within a single channel */
    mkldnn_lrn_within_channel = 66,
    /** Direct deconvolution */
    mkldnn_deconvolution_direct = 71,
    /** Winograd deconvolution */
    mkldnn_deconvolution_winograd = 72,
    /** RNN cell */
    mkldnn_vanilla_rnn = 80,
    /** LSTM cell */
    mkldnn_vanilla_lstm = 81,
    /** GRU cell */
    mkldnn_vanilla_gru = 82,
    /** GRU cell with linear before reset
     *
     * Modification of original GRU cell. Differs from #mkldnn_vanilla_gru
     * in how the new memory gate is calculated:
     * \f[ c_t = tanh(W_c*x_t + b_{c_h} + r_t*(U_c*h_{t-1}+b_{c_h})) \f]
     * Primitive expects 4 biases on input:
     * \f$[b_{u}, b_{r}, b_{c_x}, b_{c_h}]\f$
     * */
    mkldnn_gru_linear_before_reset = 83;

/** Flags for batch-normalization primititve. */
/** enum mkldnn_batch_normalization_flag_t */
public static final int
    /** Use global statistics
     *
     * If specified
     *  - on forward propagation use mean and variance provided by user (input)
     *  - on backward propagation reduces the amount of computations, since
     *    mean and variance are considered as constants
     *
     *  If not specified:
     *   - on forward propagation mean and variance are computed and stored in
     *     output
     *   - on backward propagation compute full derivative wrt to data
     */
    mkldnn_use_global_stats = 0x1,
    /** Use scale and shift parameters
     *
     * If specified:
     *  - on forward propagation use scale and shift (aka scale and bias) for
     *    the batch normalization results
     *  - on backward propagation (for prop_kind == #mkldnn_backward) compute
     *    diff wrt to scale and shift (hence one extra output used)
     *
     * If no specified:
     *  - on backward propagation prop_kind == #mkldnn_backward_data has the
     *    same behavior as prop_kind == #mkldnn_backward
     */
    mkldnn_use_scaleshift = 0x2,
    /** Omit statistics
     *
     * @deprecated use #mkldnn_use_global_stats instead
     *
     * For time being had an affect on backward propagation only which allowed
     * skipping some computations (the same semantics as
     * #mkldnn_use_global_stats)
     */
    mkldnn_omit_stats = mkldnn_use_global_stats,
    /** Fuse with ReLU
     *
     * If specified:
     *  - on inference this option behaves the same as if the primitive were
     *    fused with ReLU via post ops API
     *  - on training primitive requires workspace (required to be able to
     *    perform backward pass)
     */
    mkldnn_fuse_bn_relu = 0x4;

/** \} */

/** \addtogroup c_api_types_memory Auxiliary types for memory description
 *  \{ */

/** Maximum number of dimensions a tensor can have. Only restricts the amount
 * of space used for the tensor description. Individual computational
 * primitives may support only tensors of certain dimensions. */
public static final int TENSOR_MAX_DIMS = 12;

/** A type to describe tensor dimensions. */
/** A type to describe strides within a tensor. */

/** Generic description of blocked data layout for most memory formats.
 *
 * \sa \ref understanding_memory_formats */
public static class mkldnn_blocking_desc_t extends Pointer {
    static { Loader.load(); }
    /** Default native constructor. */
    public mkldnn_blocking_desc_t() { super((Pointer)null); allocate(); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public mkldnn_blocking_desc_t(long size) { super((Pointer)null); allocateArray(size); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public mkldnn_blocking_desc_t(Pointer p) { super(p); }
    private native void allocate();
    private native void allocateArray(long size);
    @Override public mkldnn_blocking_desc_t position(long position) {
        return (mkldnn_blocking_desc_t)super.position(position);
    }

    /** Block size for each of the dimensions. */
    @MemberGetter public native @Const IntPointer block_dims();
    /** strides[0]: stride between the first elements of adjacent blocks.
     * \n strides[1]: strides between elements in the same block. */
    @MemberGetter public native @Const CLongPointer strides(int i);
    @MemberGetter public native @Cast("const long**") PointerPointer strides();
    /** Size of the data including padding in each dimension. */
    @MemberGetter public native @Const IntPointer padding_dims();
    /** Per-dimension offset from the padding to actual data, the top-level
     * tensor with offsets applied must lie within the padding area. */
    @MemberGetter public native @Const IntPointer offset_padding_to_data();
    /** Offset from memory origin to the current block, non-zero only in
     * a description of a memory sub-block. */
    public native @Cast("ptrdiff_t") long offset_padding(); public native mkldnn_blocking_desc_t offset_padding(long offset_padding);
}

/** enum mkldnn_wino_memory_format_t */
public static final int
    /** Undefined memory format, used for empty memory descriptors. */
    mkldnn_wino_undef = 0,
    /** Tensors of weights for 2x3 winograd convolutions. */
    mkldnn_wino_wei_aaOIoi = 1,
    mkldnn_wino_wei_aaOio = 2,
    mkldnn_wino_wei_aaOBiOo = 3,
    /** Tensor of weights for 4x3 convolution. */
    mkldnn_wino_wei_OBaaIBOIio = 4;

/** Description of tensor of weights for winograd 2x3 convolution. */
public static class mkldnn_wino_desc_t extends Pointer {
    static { Loader.load(); }
    /** Default native constructor. */
    public mkldnn_wino_desc_t() { super((Pointer)null); allocate(); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public mkldnn_wino_desc_t(long size) { super((Pointer)null); allocateArray(size); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public mkldnn_wino_desc_t(Pointer p) { super(p); }
    private native void allocate();
    private native void allocateArray(long size);
    @Override public mkldnn_wino_desc_t position(long position) {
        return (mkldnn_wino_desc_t)super.position(position);
    }

    public native @Cast("mkldnn_wino_memory_format_t") int wino_format(); public native mkldnn_wino_desc_t wino_format(int wino_format);
    public native int r(); public native mkldnn_wino_desc_t r(int r);
    public native int alpha(); public native mkldnn_wino_desc_t alpha(int alpha);
    public native int ic(); public native mkldnn_wino_desc_t ic(int ic);
    public native int oc(); public native mkldnn_wino_desc_t oc(int oc);
    public native int ic_block(); public native mkldnn_wino_desc_t ic_block(int ic_block);
    public native int oc_block(); public native mkldnn_wino_desc_t oc_block(int oc_block);
    public native int ic2_block(); public native mkldnn_wino_desc_t ic2_block(int ic2_block);
    public native int oc2_block(); public native mkldnn_wino_desc_t oc2_block(int oc2_block);
    public native float adj_scale(); public native mkldnn_wino_desc_t adj_scale(float adj_scale);
    public native @Cast("size_t") long size(); public native mkldnn_wino_desc_t size(long size);
}

/** \addtogroup c_api_types_op_descs Operation descriptors
 *  \{*/

/** A pointer to any of the operation descriptors. */
@Namespace @Name("void") @Opaque public static class mkldnn_op_desc_t extends Pointer {
    /** Empty constructor. Calls {@code super((Pointer)null)}. */
    public mkldnn_op_desc_t() { super((Pointer)null); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public mkldnn_op_desc_t(Pointer p) { super(p); }
}
/** A pointer to any of the operation descriptors (constant variant). */
@Namespace @Name("void") @Opaque public static class const_mkldnn_op_desc_t extends Pointer {
    /** Empty constructor. Calls {@code super((Pointer)null)}. */
    public const_mkldnn_op_desc_t() { super((Pointer)null); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public const_mkldnn_op_desc_t(Pointer p) { super(p); }
}

/** Memory descriptor. The description is based on a number of dimensions,
 * dimensions themselves, plus information about elements type and memory
 * format. Additionally, contains format-specific descriptions of the data
 * layout. */
public static class mkldnn_memory_desc_t extends Pointer {
    static { Loader.load(); }
    /** Default native constructor. */
    public mkldnn_memory_desc_t() { super((Pointer)null); allocate(); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public mkldnn_memory_desc_t(long size) { super((Pointer)null); allocateArray(size); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public mkldnn_memory_desc_t(Pointer p) { super(p); }
    private native void allocate();
    private native void allocateArray(long size);
    @Override public mkldnn_memory_desc_t position(long position) {
        return (mkldnn_memory_desc_t)super.position(position);
    }

    /** The kind of primitive. Used for self identifying the primitive
     * descriptor. Must be #mkldnn_memory. */
    public native @Cast("mkldnn_primitive_kind_t") int primitive_kind(); public native mkldnn_memory_desc_t primitive_kind(int primitive_kind);
    /** Number of dimensions */
    public native int ndims(); public native mkldnn_memory_desc_t ndims(int ndims);
    /** Dimensions in the following order:
     * - CNN data tensors: mini-batch, channel, spatial
     *   (<code>{N, C, [[D,] H,] W}</code>)
     * - CNN weight tensors: group (optional), output channel, input channel,
     *   spatial (<code>{[G,] O, I, [[D,] H,] W}</code>)
     * - RNN data tensors: time, mini-batch, channels (<code>{T, N, C}</code>)
     *   or layers, directions, states, mini-batch, channels (<code>{L, D, S, N, C}</code>)
     * - RNN weight tensor: layers, directions, input channel, gates, output channels
     *   (<code>{L, D, I, G, O}</code>).
     *
     * \note
     *    The order of dimensions does not depend on the memory format, so
     *    no matter whether the data is laid in #mkldnn_nchw or #mkldnn_nhwc
     *    the dims for 4D CN data tensor would be <code>{N, C, H, W}</code>
     */
    @MemberGetter public native @Const IntPointer dims();
    /** Data type of the tensor elements. */
    public native @Cast("mkldnn_data_type_t") int data_type(); public native mkldnn_memory_desc_t data_type(int data_type);
    /** Memory format. */
    public native @Cast("mkldnn_memory_format_t") int format(); public native mkldnn_memory_desc_t format(int format);
        /** Description of the data layout for memory formats that use
         * blocking. */
        @Name("layout_desc.blocking") public native @ByRef mkldnn_blocking_desc_t layout_desc_blocking(); public native mkldnn_memory_desc_t layout_desc_blocking(mkldnn_blocking_desc_t layout_desc_blocking);
        /** Tensor of weights for integer 8bit winograd convolution. */
        @Name("layout_desc.wino_desc") public native @ByRef mkldnn_wino_desc_t layout_desc_wino_desc(); public native mkldnn_memory_desc_t layout_desc_wino_desc(mkldnn_wino_desc_t layout_desc_wino_desc);
        /* ... other descriptions possible */
}

/** \} */

/** A descriptor of a convolution operation. */
public static class mkldnn_convolution_desc_t extends Pointer {
    static { Loader.load(); }
    /** Default native constructor. */
    public mkldnn_convolution_desc_t() { super((Pointer)null); allocate(); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public mkldnn_convolution_desc_t(long size) { super((Pointer)null); allocateArray(size); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public mkldnn_convolution_desc_t(Pointer p) { super(p); }
    private native void allocate();
    private native void allocateArray(long size);
    @Override public mkldnn_convolution_desc_t position(long position) {
        return (mkldnn_convolution_desc_t)super.position(position);
    }

    /** The kind of primitive. Used for self identifying the primitive
     * descriptor. Must be #mkldnn_convolution. */
    public native @Cast("mkldnn_primitive_kind_t") int primitive_kind(); public native mkldnn_convolution_desc_t primitive_kind(int primitive_kind);
    /** The kind of propagation. Possible values: #mkldnn_forward_training,
     * #mkldnn_forward_inference, #mkldnn_backward_data,
     * #mkldnn_backward_weights, and #mkldnn_backward_bias. */
    public native @Cast("mkldnn_prop_kind_t") int prop_kind(); public native mkldnn_convolution_desc_t prop_kind(int prop_kind);
    /** The kind of the convolution algorithm. Possible values:
     * #mkldnn_convolution_direct. */
    public native @Cast("mkldnn_alg_kind_t") int alg_kind(); public native mkldnn_convolution_desc_t alg_kind(int alg_kind);
    /** Source memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t src_desc(); public native mkldnn_convolution_desc_t src_desc(mkldnn_memory_desc_t src_desc);
    /** Source gradient memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t diff_src_desc(); public native mkldnn_convolution_desc_t diff_src_desc(mkldnn_memory_desc_t diff_src_desc);
    /** Weights memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t weights_desc(); public native mkldnn_convolution_desc_t weights_desc(mkldnn_memory_desc_t weights_desc);
    /** Weights gradient memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t diff_weights_desc(); public native mkldnn_convolution_desc_t diff_weights_desc(mkldnn_memory_desc_t diff_weights_desc);
    /** Bias memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t bias_desc(); public native mkldnn_convolution_desc_t bias_desc(mkldnn_memory_desc_t bias_desc);
    /** Bias gradient memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t diff_bias_desc(); public native mkldnn_convolution_desc_t diff_bias_desc(mkldnn_memory_desc_t diff_bias_desc);
    /** Destination memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t dst_desc(); public native mkldnn_convolution_desc_t dst_desc(mkldnn_memory_desc_t dst_desc);
    /** Destination gradient memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t diff_dst_desc(); public native mkldnn_convolution_desc_t diff_dst_desc(mkldnn_memory_desc_t diff_dst_desc);
    /** Convolution strides in each spatial dimension. */
    @MemberGetter public native @Const IntPointer strides();
    /** Convolution dilates in each spatial dimension. */
    @MemberGetter public native @Const IntPointer dilates();
    /** Padding in each spatial dimension. padding[0] is a padding in the
     * beginning (\p padding_l), padding[1] is a padding in the end (\p
     * padding_r). */
    @MemberGetter public native @Const IntPointer padding(int i);
    @MemberGetter public native @Cast("const int**") PointerPointer padding();
    /** The kind of padding to use. */
    public native @Cast("mkldnn_padding_kind_t") int padding_kind(); public native mkldnn_convolution_desc_t padding_kind(int padding_kind);
    /** The accumulator data type. Initialized automatically. */
    public native @Cast("mkldnn_data_type_t") int accum_data_type(); public native mkldnn_convolution_desc_t accum_data_type(int accum_data_type);
}

/** A descriptor of a deconvolution operation. */

/** A descriptor of a shuffle operation. */
public static class mkldnn_shuffle_desc_t extends Pointer {
    static { Loader.load(); }
    /** Default native constructor. */
    public mkldnn_shuffle_desc_t() { super((Pointer)null); allocate(); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public mkldnn_shuffle_desc_t(long size) { super((Pointer)null); allocateArray(size); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public mkldnn_shuffle_desc_t(Pointer p) { super(p); }
    private native void allocate();
    private native void allocateArray(long size);
    @Override public mkldnn_shuffle_desc_t position(long position) {
        return (mkldnn_shuffle_desc_t)super.position(position);
    }

    /** The kind of primitive. Used for self identifying the primitive
     * descriptor. Must be #mkldnn_convolution. */
    public native @Cast("mkldnn_primitive_kind_t") int primitive_kind(); public native mkldnn_shuffle_desc_t primitive_kind(int primitive_kind);
    /** The kind of propagation. Possible values: #mkldnn_forward_training,
     * #mkldnn_forward_inference, #mkldnn_backward_data*/
    public native @Cast("mkldnn_prop_kind_t") int prop_kind(); public native mkldnn_shuffle_desc_t prop_kind(int prop_kind);
    /** Source and destination memory descriptor.
     *  and source and destination gradient memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t data_desc(); public native mkldnn_shuffle_desc_t data_desc(mkldnn_memory_desc_t data_desc);
    /** axis for shuffling. */
    public native int axis(); public native mkldnn_shuffle_desc_t axis(int axis);
    /** number of groups in group convolution */
    public native int group_size(); public native mkldnn_shuffle_desc_t group_size(int group_size);
}

/** A descriptor of a element-wise operation. */
public static class mkldnn_eltwise_desc_t extends Pointer {
    static { Loader.load(); }
    /** Default native constructor. */
    public mkldnn_eltwise_desc_t() { super((Pointer)null); allocate(); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public mkldnn_eltwise_desc_t(long size) { super((Pointer)null); allocateArray(size); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public mkldnn_eltwise_desc_t(Pointer p) { super(p); }
    private native void allocate();
    private native void allocateArray(long size);
    @Override public mkldnn_eltwise_desc_t position(long position) {
        return (mkldnn_eltwise_desc_t)super.position(position);
    }

    /** The kind of primitive. Used for self identifying the primitive
     * descriptor. Must be #mkldnn_eltwise. */
    public native @Cast("mkldnn_primitive_kind_t") int primitive_kind(); public native mkldnn_eltwise_desc_t primitive_kind(int primitive_kind);
    /** The kind of propagation. Possible values: #mkldnn_forward_training,
     * #mkldnn_forward_inference, #mkldnn_backward, and #mkldnn_backward_data.
     */
    public native @Cast("mkldnn_prop_kind_t") int prop_kind(); public native mkldnn_eltwise_desc_t prop_kind(int prop_kind);
    /** The kind of eltwise algorithm. Possible values: #mkldnn_eltwise_relu,
     * #mkldnn_eltwise_tanh, #mkldnn_eltwise_elu, #mkldnn_eltwise_square,
     * #mkldnn_eltwise_abs, #mkldnn_eltwise_sqrt, #mkldnn_eltwise_linear,
     * #mkldnn_eltwise_bounded_relu, #mkldnn_eltwise_soft_relu,
     * #mkldnn_eltwise_logistic. */
    public native @Cast("mkldnn_alg_kind_t") int alg_kind(); public native mkldnn_eltwise_desc_t alg_kind(int alg_kind);
    /** Source and destination memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t data_desc(); public native mkldnn_eltwise_desc_t data_desc(mkldnn_memory_desc_t data_desc);
    /** Source and destination gradient memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t diff_data_desc(); public native mkldnn_eltwise_desc_t diff_data_desc(mkldnn_memory_desc_t diff_data_desc);
    /** Algorithm specific parameter.
     * Accordance table:
     *  - #mkldnn_eltwise_relu: \p alpha -- negative slope, \p beta ignored
     *  - #mkldnn_eltwise_tanh: \p alpha and \p beta ignored
     *  - #mkldnn_eltwise_elu: \p alpha -- negative slope, \p beta ignored
     *  - #mkldnn_eltwise_square: \p alpha and \p beta ignored
     *  - #mkldnn_eltwise_abs: \p alpha and \p beta ignored
     *  - #mkldnn_eltwise_sqrt: \p alpha and \p beta ignored
     *  - #mkldnn_eltwise_linear: \p alpha -- scale, \p beta -- shift
     *  - #mkldnn_eltwise_bounded_relu: \p alpha -- upper bound, \p beta ignored
     *  - #mkldnn_eltwise_soft_relu: \p alpha and \p beta ignored
     *  - #mkldnn_eltwise_logistic: \p alpha and \p beta ignored
     */
    public native float alpha(); public native mkldnn_eltwise_desc_t alpha(float alpha);
    public native float beta(); public native mkldnn_eltwise_desc_t beta(float beta);
    /** ReLU scaling factor for negative values.
     * @deprecated : use alpha instead
     * \warning: read-only value */
    public native float negative_slope(); public native mkldnn_eltwise_desc_t negative_slope(float negative_slope);
}

/* @deprecated: use mkldnn_eltwise_desc_t */

/** A descriptor of a Softmax operation. */
public static class mkldnn_softmax_desc_t extends Pointer {
    static { Loader.load(); }
    /** Default native constructor. */
    public mkldnn_softmax_desc_t() { super((Pointer)null); allocate(); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public mkldnn_softmax_desc_t(long size) { super((Pointer)null); allocateArray(size); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public mkldnn_softmax_desc_t(Pointer p) { super(p); }
    private native void allocate();
    private native void allocateArray(long size);
    @Override public mkldnn_softmax_desc_t position(long position) {
        return (mkldnn_softmax_desc_t)super.position(position);
    }

    /** The kind of primitive. Used for self identifying the primitive
    * descriptor. Must be #mkldnn_softmax. */
    public native @Cast("mkldnn_primitive_kind_t") int primitive_kind(); public native mkldnn_softmax_desc_t primitive_kind(int primitive_kind);
    /** The kind of propagation. Possible values: #mkldnn_forward_training,
     * #mkldnn_forward_inference. */
    public native @Cast("mkldnn_prop_kind_t") int prop_kind(); public native mkldnn_softmax_desc_t prop_kind(int prop_kind);
    /** Source and destination memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t data_desc(); public native mkldnn_softmax_desc_t data_desc(mkldnn_memory_desc_t data_desc);
    /** Source and Destination of gradient memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t diff_desc(); public native mkldnn_softmax_desc_t diff_desc(mkldnn_memory_desc_t diff_desc);
    /** The axis along which to perform the softmax. */
    public native int softmax_axis(); public native mkldnn_softmax_desc_t softmax_axis(int softmax_axis);
}

/** A descriptor of a pooling operation. */
public static class mkldnn_pooling_desc_t extends Pointer {
    static { Loader.load(); }
    /** Default native constructor. */
    public mkldnn_pooling_desc_t() { super((Pointer)null); allocate(); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public mkldnn_pooling_desc_t(long size) { super((Pointer)null); allocateArray(size); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public mkldnn_pooling_desc_t(Pointer p) { super(p); }
    private native void allocate();
    private native void allocateArray(long size);
    @Override public mkldnn_pooling_desc_t position(long position) {
        return (mkldnn_pooling_desc_t)super.position(position);
    }

    /** The kind of primitive. Used for self identifying the primitive
     * descriptor. Must be #mkldnn_pooling. */
    public native @Cast("mkldnn_primitive_kind_t") int primitive_kind(); public native mkldnn_pooling_desc_t primitive_kind(int primitive_kind);
    /** The kind of propagation. Possible values: #mkldnn_forward_training,
     * #mkldnn_forward_inference, #mkldnn_backward, and #mkldnn_backward_data.
     */
    public native @Cast("mkldnn_prop_kind_t") int prop_kind(); public native mkldnn_pooling_desc_t prop_kind(int prop_kind);
    /** The kind of pooling algorithm. Possible values: #mkldnn_pooling_max,
     * #mkldnn_pooling_avg. */
    public native @Cast("mkldnn_alg_kind_t") int alg_kind(); public native mkldnn_pooling_desc_t alg_kind(int alg_kind);
    /** Source memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t src_desc(); public native mkldnn_pooling_desc_t src_desc(mkldnn_memory_desc_t src_desc);
    /** Source gradient memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t diff_src_desc(); public native mkldnn_pooling_desc_t diff_src_desc(mkldnn_memory_desc_t diff_src_desc);
    /** Destination memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t dst_desc(); public native mkldnn_pooling_desc_t dst_desc(mkldnn_memory_desc_t dst_desc);
    /** Destination gradient memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t diff_dst_desc(); public native mkldnn_pooling_desc_t diff_dst_desc(mkldnn_memory_desc_t diff_dst_desc);
    /** Pooling kernel strides for spatial dimensions. */
    @MemberGetter public native @Const IntPointer strides();
    /** Pooling kernel spatial dimensions. */
    @MemberGetter public native @Const IntPointer kernel();
    /** Padding in each spatial dimension. padding[0] is a padding in the
     * beginning (\p padding_l), padding[1] is a padding in the end (\p
     * padding_r). */
    @MemberGetter public native @Const IntPointer padding(int i);
    @MemberGetter public native @Cast("const int**") PointerPointer padding();
    /** The kind of padding to use. */
    public native @Cast("mkldnn_padding_kind_t") int padding_kind(); public native mkldnn_pooling_desc_t padding_kind(int padding_kind);
    /** The accumulator data type. Initialized automatically. */
    public native @Cast("mkldnn_data_type_t") int accum_data_type(); public native mkldnn_pooling_desc_t accum_data_type(int accum_data_type);
}

/** A descriptor of a Local Response Normalization (LRN) operation. */
public static class mkldnn_lrn_desc_t extends Pointer {
    static { Loader.load(); }
    /** Default native constructor. */
    public mkldnn_lrn_desc_t() { super((Pointer)null); allocate(); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public mkldnn_lrn_desc_t(long size) { super((Pointer)null); allocateArray(size); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public mkldnn_lrn_desc_t(Pointer p) { super(p); }
    private native void allocate();
    private native void allocateArray(long size);
    @Override public mkldnn_lrn_desc_t position(long position) {
        return (mkldnn_lrn_desc_t)super.position(position);
    }

    /** The kind of primitive. Used for self identifying the primitive
     * descriptor. Must be #mkldnn_lrn. */
    public native @Cast("mkldnn_primitive_kind_t") int primitive_kind(); public native mkldnn_lrn_desc_t primitive_kind(int primitive_kind);
    /** The kind of propagation. Possible values: #mkldnn_forward_training,
     * #mkldnn_forward_inference, #mkldnn_backward, and #mkldnn_backward_data.
     */
    public native @Cast("mkldnn_prop_kind_t") int prop_kind(); public native mkldnn_lrn_desc_t prop_kind(int prop_kind);
    /** LRN algorithm. Possible values #mkldnn_lrn_within_channel or
     * #mkldnn_lrn_across_channels. */
    public native @Cast("mkldnn_alg_kind_t") int alg_kind(); public native mkldnn_lrn_desc_t alg_kind(int alg_kind);
    /** Source and destination memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t data_desc(); public native mkldnn_lrn_desc_t data_desc(mkldnn_memory_desc_t data_desc);
    /** Source and destination gradient memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t diff_data_desc(); public native mkldnn_lrn_desc_t diff_data_desc(mkldnn_memory_desc_t diff_data_desc);
    /** The number of channels to sum over (for cross-channel LRN) or the side
     * length of the square region to sum over (for within-channel LRN). */
    public native int local_size(); public native mkldnn_lrn_desc_t local_size(int local_size);
    /** LRN alpha parameter. */
    public native float lrn_alpha(); public native mkldnn_lrn_desc_t lrn_alpha(float lrn_alpha);
    /** LRN beta parameter. */
    public native float lrn_beta(); public native mkldnn_lrn_desc_t lrn_beta(float lrn_beta);
    /** LRN k parameter. */
    public native float lrn_k(); public native mkldnn_lrn_desc_t lrn_k(float lrn_k);
}

/** A descriptor of a Batch Normalization operation. */
public static class mkldnn_batch_normalization_desc_t extends Pointer {
    static { Loader.load(); }
    /** Default native constructor. */
    public mkldnn_batch_normalization_desc_t() { super((Pointer)null); allocate(); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public mkldnn_batch_normalization_desc_t(long size) { super((Pointer)null); allocateArray(size); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public mkldnn_batch_normalization_desc_t(Pointer p) { super(p); }
    private native void allocate();
    private native void allocateArray(long size);
    @Override public mkldnn_batch_normalization_desc_t position(long position) {
        return (mkldnn_batch_normalization_desc_t)super.position(position);
    }

    /** The kind of primitive. Used for self identifying the primitive
     * descriptor. Must be #mkldnn_batch_normalization. */
    public native @Cast("mkldnn_primitive_kind_t") int primitive_kind(); public native mkldnn_batch_normalization_desc_t primitive_kind(int primitive_kind);
    /** The kind of propagation. Possible values: #mkldnn_forward_training,
     * #mkldnn_forward_inference, #mkldnn_backward, and #mkldnn_backward_data.
     */
    public native @Cast("mkldnn_prop_kind_t") int prop_kind(); public native mkldnn_batch_normalization_desc_t prop_kind(int prop_kind);
    /** Source and destination memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t data_desc(); public native mkldnn_batch_normalization_desc_t data_desc(mkldnn_memory_desc_t data_desc);
    /** Source and destination gradient memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t diff_data_desc(); public native mkldnn_batch_normalization_desc_t diff_data_desc(mkldnn_memory_desc_t diff_data_desc);
    /** Scale and shift data and gradient memory descriptors.
     *
     * Scaleshift memory descriptor uses 2D #mkldnn_nc format[2,Channels]. 1-st
     * dimension contains gamma parameter, 2-nd dimension contains beta
     * parameter. */
    public native @ByRef mkldnn_memory_desc_t data_scaleshift_desc(); public native mkldnn_batch_normalization_desc_t data_scaleshift_desc(mkldnn_memory_desc_t data_scaleshift_desc);
    public native @ByRef mkldnn_memory_desc_t diff_data_scaleshift_desc(); public native mkldnn_batch_normalization_desc_t diff_data_scaleshift_desc(mkldnn_memory_desc_t diff_data_scaleshift_desc);
    /** Mean and variance data memory descriptors.
     *
     * Mean and variance memory descriptors use 1D #mkldnn_x format[Channels].
     */
    public native @ByRef mkldnn_memory_desc_t mean_desc(); public native mkldnn_batch_normalization_desc_t mean_desc(mkldnn_memory_desc_t mean_desc);
    public native @ByRef mkldnn_memory_desc_t variance_desc(); public native mkldnn_batch_normalization_desc_t variance_desc(mkldnn_memory_desc_t variance_desc);
    /** Batch normalization epsilon parameter. */
    public native float batch_norm_epsilon(); public native mkldnn_batch_normalization_desc_t batch_norm_epsilon(float batch_norm_epsilon);
    public native @Cast("unsigned") int flags(); public native mkldnn_batch_normalization_desc_t flags(int flags);
}

/** A descriptor of an inner product operation. */
public static class mkldnn_inner_product_desc_t extends Pointer {
    static { Loader.load(); }
    /** Default native constructor. */
    public mkldnn_inner_product_desc_t() { super((Pointer)null); allocate(); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public mkldnn_inner_product_desc_t(long size) { super((Pointer)null); allocateArray(size); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public mkldnn_inner_product_desc_t(Pointer p) { super(p); }
    private native void allocate();
    private native void allocateArray(long size);
    @Override public mkldnn_inner_product_desc_t position(long position) {
        return (mkldnn_inner_product_desc_t)super.position(position);
    }

    /** The kind of primitive. Used for self identifying the primitive
     * descriptor. Must be #mkldnn_inner_product. */
    public native @Cast("mkldnn_primitive_kind_t") int primitive_kind(); public native mkldnn_inner_product_desc_t primitive_kind(int primitive_kind);
    /** The kind of propagation. Possible values: #mkldnn_forward_training,
     * #mkldnn_forward_inference, #mkldnn_backward_data,
     * #mkldnn_backward_weights, and #mkldnn_backward_bias. */
    public native @Cast("mkldnn_prop_kind_t") int prop_kind(); public native mkldnn_inner_product_desc_t prop_kind(int prop_kind);
    /** Source memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t src_desc(); public native mkldnn_inner_product_desc_t src_desc(mkldnn_memory_desc_t src_desc);
    /** Source gradient memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t diff_src_desc(); public native mkldnn_inner_product_desc_t diff_src_desc(mkldnn_memory_desc_t diff_src_desc);
    /** Weights memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t weights_desc(); public native mkldnn_inner_product_desc_t weights_desc(mkldnn_memory_desc_t weights_desc);
    /** Weights gradient memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t diff_weights_desc(); public native mkldnn_inner_product_desc_t diff_weights_desc(mkldnn_memory_desc_t diff_weights_desc);
    /** Bias memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t bias_desc(); public native mkldnn_inner_product_desc_t bias_desc(mkldnn_memory_desc_t bias_desc);
    /** Bias gradient memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t diff_bias_desc(); public native mkldnn_inner_product_desc_t diff_bias_desc(mkldnn_memory_desc_t diff_bias_desc);
    /** Destination memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t dst_desc(); public native mkldnn_inner_product_desc_t dst_desc(mkldnn_memory_desc_t dst_desc);
    /** Destination gradient memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t diff_dst_desc(); public native mkldnn_inner_product_desc_t diff_dst_desc(mkldnn_memory_desc_t diff_dst_desc);
    /** The accumulator data type. Initialized automatically. */
    public native @Cast("mkldnn_data_type_t") int accum_data_type(); public native mkldnn_inner_product_desc_t accum_data_type(int accum_data_type);
}

/** A descriptor of a convolution followed by relu operation. */
public static class mkldnn_convolution_relu_desc_t extends Pointer {
    static { Loader.load(); }
    /** Default native constructor. */
    public mkldnn_convolution_relu_desc_t() { super((Pointer)null); allocate(); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public mkldnn_convolution_relu_desc_t(long size) { super((Pointer)null); allocateArray(size); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public mkldnn_convolution_relu_desc_t(Pointer p) { super(p); }
    private native void allocate();
    private native void allocateArray(long size);
    @Override public mkldnn_convolution_relu_desc_t position(long position) {
        return (mkldnn_convolution_relu_desc_t)super.position(position);
    }

    /** The kind of primitive. Used for self identifying the primitive
     * descriptor. Must be #mkldnn_convolution_relu. */
    public native @Cast("mkldnn_primitive_kind_t") int primitive_kind(); public native mkldnn_convolution_relu_desc_t primitive_kind(int primitive_kind);
    /** A descriptor of a convolution operation. */
    public native @ByRef mkldnn_convolution_desc_t convolution_desc(); public native mkldnn_convolution_relu_desc_t convolution_desc(mkldnn_convolution_desc_t convolution_desc);
    /** Scaling factor for negative values, stored as float-precision but
     * interpreted in a way specific to the data type in each implementation */
    public native float negative_slope(); public native mkldnn_convolution_relu_desc_t negative_slope(float negative_slope);
}

/** Flags for RNN cell. */
/** enum mkldnn_rnn_cell_flags_t */
public static final int
    mkldnn_rnn_cell_with_relu = 0x1,
    mkldnn_rnn_cell_with_clipping = 0x2;

public static class mkldnn_rnn_cell_desc_t extends Pointer {
    static { Loader.load(); }
    /** Default native constructor. */
    public mkldnn_rnn_cell_desc_t() { super((Pointer)null); allocate(); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public mkldnn_rnn_cell_desc_t(long size) { super((Pointer)null); allocateArray(size); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public mkldnn_rnn_cell_desc_t(Pointer p) { super(p); }
    private native void allocate();
    private native void allocateArray(long size);
    @Override public mkldnn_rnn_cell_desc_t position(long position) {
        return (mkldnn_rnn_cell_desc_t)super.position(position);
    }

    /** RNN cell kind. Must be one of #mkldnn_vanilla_rnn,
     * #mkldnn_vanilla_lstm, #mkldnn_vanilla_gru
     * or #mkldnn_gru_linear_before_reset. */
    public native @Cast("mkldnn_alg_kind_t") int cell_kind(); public native mkldnn_rnn_cell_desc_t cell_kind(int cell_kind);
    /** Activation function used. Must be one of #mkldnn_eltwise_relu,
     * #mkldnn_eltwise_tanh. */
    public native @Cast("mkldnn_alg_kind_t") int activation_kind(); public native mkldnn_rnn_cell_desc_t activation_kind(int activation_kind);
    /** RNN cell flags */
    public native @Cast("unsigned int") int flags(); public native mkldnn_rnn_cell_desc_t flags(int flags);
    /** alpha is a negative slope parameter (used only if
     * (flags & #mkldnn_rnn_cell_with_relu) != 0) */
    public native float alpha(); public native mkldnn_rnn_cell_desc_t alpha(float alpha);
    /** clipping parameter (used only if
     * (flags & #mkldnn_rnn_cell_with_clipping) != 0) */
    public native float clipping(); public native mkldnn_rnn_cell_desc_t clipping(float clipping);
}

/** A direction of RNN primitive execution */
/** enum mkldnn_rnn_direction_t */
public static final int
    /* Unidirectional execution of RNN primitive from left to right. */
    mkldnn_unidirectional_left2right = 0,
    /* Unidirectional execution of RNN primitive from right to left. */
    mkldnn_unidirectional_right2left = 1,
    /* Bidirectional execution of RNN primitive with concatenation of the
     * results. */
    mkldnn_bidirectional_concat = 2,
    /* Bidirectional execution of RNN primitive with summation of the
     * results. */
    mkldnn_bidirectional_sum = 3,
    mkldnn_unidirectional = mkldnn_unidirectional_left2right;

/** A descriptor for an rnn operation */
public static class mkldnn_rnn_desc_t extends Pointer {
    static { Loader.load(); }
    /** Default native constructor. */
    public mkldnn_rnn_desc_t() { super((Pointer)null); allocate(); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public mkldnn_rnn_desc_t(long size) { super((Pointer)null); allocateArray(size); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public mkldnn_rnn_desc_t(Pointer p) { super(p); }
    private native void allocate();
    private native void allocateArray(long size);
    @Override public mkldnn_rnn_desc_t position(long position) {
        return (mkldnn_rnn_desc_t)super.position(position);
    }

    /** The kind of primitive. Used for self identifying the primitive
     * descriptor. Must be #mkldnn_rnn. */
    public native @Cast("mkldnn_primitive_kind_t") int primitive_kind(); public native mkldnn_rnn_desc_t primitive_kind(int primitive_kind);
    /** The kind of propagation. Possible values: #mkldnn_forward_training,
     * #mkldnn_forward_inference, #mkldnn_backward. */
    public native @Cast("mkldnn_prop_kind_t") int prop_kind(); public native mkldnn_rnn_desc_t prop_kind(int prop_kind);
    /** The RNN cell desc. */
    public native @ByRef mkldnn_rnn_cell_desc_t cell_desc(); public native mkldnn_rnn_desc_t cell_desc(mkldnn_rnn_cell_desc_t cell_desc);
    /** The direction of RNN primitive execution. */
    public native @Cast("mkldnn_rnn_direction_t") int direction(); public native mkldnn_rnn_desc_t direction(int direction);
    /** Source layer memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t src_layer_desc(); public native mkldnn_rnn_desc_t src_layer_desc(mkldnn_memory_desc_t src_layer_desc);
    /** Source iteration memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t src_iter_desc(); public native mkldnn_rnn_desc_t src_iter_desc(mkldnn_memory_desc_t src_iter_desc);
    /** Weights layer memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t weights_layer_desc(); public native mkldnn_rnn_desc_t weights_layer_desc(mkldnn_memory_desc_t weights_layer_desc);
    /** Weights iteration memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t weights_iter_desc(); public native mkldnn_rnn_desc_t weights_iter_desc(mkldnn_memory_desc_t weights_iter_desc);
    /** Bias memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t bias_desc(); public native mkldnn_rnn_desc_t bias_desc(mkldnn_memory_desc_t bias_desc);
    /** Destination layer memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t dst_layer_desc(); public native mkldnn_rnn_desc_t dst_layer_desc(mkldnn_memory_desc_t dst_layer_desc);
    /** Destination iter memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t dst_iter_desc(); public native mkldnn_rnn_desc_t dst_iter_desc(mkldnn_memory_desc_t dst_iter_desc);
    /** Source gradient layer memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t diff_src_layer_desc(); public native mkldnn_rnn_desc_t diff_src_layer_desc(mkldnn_memory_desc_t diff_src_layer_desc);
    /** Source gradient iter memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t diff_src_iter_desc(); public native mkldnn_rnn_desc_t diff_src_iter_desc(mkldnn_memory_desc_t diff_src_iter_desc);
    /** Weights gradient layer memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t diff_weights_layer_desc(); public native mkldnn_rnn_desc_t diff_weights_layer_desc(mkldnn_memory_desc_t diff_weights_layer_desc);
    /** Weights gradient iter memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t diff_weights_iter_desc(); public native mkldnn_rnn_desc_t diff_weights_iter_desc(mkldnn_memory_desc_t diff_weights_iter_desc);
    /** Bias gradient memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t diff_bias_desc(); public native mkldnn_rnn_desc_t diff_bias_desc(mkldnn_memory_desc_t diff_bias_desc);
    /** Destination gradient layer memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t diff_dst_layer_desc(); public native mkldnn_rnn_desc_t diff_dst_layer_desc(mkldnn_memory_desc_t diff_dst_layer_desc);
    /** Destination gradient iteration memory descriptor. */
    public native @ByRef mkldnn_memory_desc_t diff_dst_iter_desc(); public native mkldnn_rnn_desc_t diff_dst_iter_desc(mkldnn_memory_desc_t diff_dst_iter_desc);
}

/** \} */

/** \addtogroup c_api_engine_types Engine
 * \{ */

/** \brief Kinds of engines. */
/** enum mkldnn_engine_kind_t */
public static final int
    /** An unspecified engine. */
    mkldnn_any_engine = 0,
    /** CPU engine. */
    mkldnn_cpu = 1;

/** \struct mkldnn_engine
 * \brief An opaque structure to describe an engine. */
@Opaque public static class mkldnn_engine extends Pointer {
    /** Empty constructor. Calls {@code super((Pointer)null)}. */
    public mkldnn_engine() { super((Pointer)null); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public mkldnn_engine(Pointer p) { super(p); }
}
/** \brief An engine handle. */
// #if 0
// #endif

/** \} */

/** \addtogroup c_api_primitive_desc_iterators Primitive descriptor iterators
 * \{ */

/** \struct mkldnn_primitive_desc_iterator
 * \brief An opaque structure to describe a primitive descriptor iterator . */
@Opaque public static class mkldnn_primitive_desc_iterator extends Pointer {
    /** Empty constructor. Calls {@code super((Pointer)null)}. */
    public mkldnn_primitive_desc_iterator() { super((Pointer)null); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public mkldnn_primitive_desc_iterator(Pointer p) { super(p); }
}

/** \brief A primitive descriptor iterator handle. */

/** \brief A constant primitive descriptor iterator handle. */

/** \} */

/** \addtogroup c_api_primitive_descs Primitive descriptors
 * \{ */

/** \struct mkldnn_primitive_desc
 * \brief An opaque structure to describe a primitive descriptor . */
@Opaque public static class mkldnn_primitive_desc extends Pointer {
    /** Empty constructor. Calls {@code super((Pointer)null)}. */
    public mkldnn_primitive_desc() { super((Pointer)null); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public mkldnn_primitive_desc(Pointer p) { super(p); }
}

/** \brief A primitive descriptor handle. */

/** \brief A constant primitive descriptor handle. */

/** \} */

/** \addtogroup c_api_primitive_attr Primitive descriptor attributes
 * \{ */

/** \struct mkldnn_primitive_attr
 * \brief An opaque structure for primitive descriptor attributes.
 *
 * Attributes may contain:
 *  - rounding mode for integer based primitives (like convolution, reorders)
 *  - output scales (to scale the result prior to storing it to the memory)
 */
@Opaque public static class mkldnn_primitive_attr extends Pointer {
    /** Empty constructor. Calls {@code super((Pointer)null)}. */
    public mkldnn_primitive_attr() { super((Pointer)null); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public mkldnn_primitive_attr(Pointer p) { super(p); }
}

/** \brief A primitive descriptor attributes handle that controls primitive
 * behavior. */

/** \brief A constant primitive descriptor attributes handle. */

/** \struct mkldnn_post_ops
 * \brief An opaque structure for a chain of post operations.
 *
 * mkldnn_post_ops can be used to perform some (trivial) operations like
 * accumulation or eltwise after certain primitives like convolution.
 *
 * Post operations might be combined together, making a chain of post
 * operations. For instance one can configure convolution followed by
 * accumulation followed by eltwise (relu). This might be especially beneficial
 * for residual learning blocks.
 *
 * \warning
 *      Of course not all the combinations are supported, so user should handle
 *      error accordingly.
 *
 * Supported post operations:
 *  - accumulation (base primitive: convolution)
 *  - eltwise (base primitive: convolution)
 */
@Opaque public static class mkldnn_post_ops extends Pointer {
    /** Empty constructor. Calls {@code super((Pointer)null)}. */
    public mkldnn_post_ops() { super((Pointer)null); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public mkldnn_post_ops(Pointer p) { super(p); }
}

/** \brief A post operation chain handle. */

/** \brief A constant post operation chain handle. */

/** \} */

/** \addtogroup c_api_types_primitive Primitive
 * \{ */

/** \struct mkldnn_primitive
 * An opaque structure to describe a primitive. */
@Opaque public static class mkldnn_primitive extends Pointer {
    /** Empty constructor. Calls {@code super((Pointer)null)}. */
    public mkldnn_primitive() { super((Pointer)null); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public mkldnn_primitive(Pointer p) { super(p); }
}
/** A primitive handle. */
/** A constant primitive handle. */

/** A wrapper structure to specify a particular output of a primitive. */
public static class mkldnn_primitive_at_t extends Pointer {
    static { Loader.load(); }
    /** Default native constructor. */
    public mkldnn_primitive_at_t() { super((Pointer)null); allocate(); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public mkldnn_primitive_at_t(long size) { super((Pointer)null); allocateArray(size); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public mkldnn_primitive_at_t(Pointer p) { super(p); }
    private native void allocate();
    private native void allocateArray(long size);
    @Override public mkldnn_primitive_at_t position(long position) {
        return (mkldnn_primitive_at_t)super.position(position);
    }

    /** Primitive to specify the output for. */
    public native @Const mkldnn_primitive primitive(); public native mkldnn_primitive_at_t primitive(mkldnn_primitive primitive);
    /** Desired output index. */
    public native @Cast("size_t") long output_index(); public native mkldnn_primitive_at_t output_index(long output_index);
}

/** \} */

/** \addtogroup c_api_types_query Queries
 * \{ */

/** Primitive descriptor query specification
 *
 * For generic function mkldnn_primitive_desc_query() the type of result must
 * be agreed with queried argument. The correspondence table:
 *      Query                        | type of result
 *      --------------------------------------------------------------
 *      #mkldnn_query_engine         | mkldnn_engine_t *
 *      #mkldnn_query_primitive_kind | mkldnn_primitive_kind_t *
 *      *_s32                        | int *
 *      *_s64                        | ptrdiff_t *
 *      *_f64                        | double *
 *      *_str                        | const char **
 *      #mkldnn_query_op_d           | const_mkldnn_op_desc_t *
 *      *_md                         | const mkldnn_memory_desc_t **
 *      *_${op}_d                    | const mkldnn_${op}_desc_t **
 *      *_pd                         | const_mkldnn_primitive_desc_t *
 *
 * \note
 *     Rule of thumb: all opaque types and structures are returned by
 *     reference. All numbers are returned by value.
 *
 * \warning
 *     All returned references point to constant objects and valid only during
 *     the lifetime of queried primitive descriptor. Returned objects must not
 *     be destroyed by user. If there is a need to keep the object longer than
 *     a lifetime of queried primitive descriptor use
 *     mkldnn_primitive_desc_clone() to make a copy. */
/** enum mkldnn_query_t */
public static final int
    /** no query */
    mkldnn_query_undef = 0,

    /** execution engine */
    mkldnn_query_engine = 1,
    /** primitive kind */
    mkldnn_query_primitive_kind = 2,

    /** number of inputs expected */
    mkldnn_query_num_of_inputs_s32 = 3,
    /** number of outputs expected */
    mkldnn_query_num_of_outputs_s32 = 4,

    /** runtime estimation (seconds) */
    mkldnn_query_time_estimate_f64 = 5,
    /** memory consumption -- extra
                                           (scratch) memory, additional to all
                                           inputs and outputs memory (bytes) */
    mkldnn_query_memory_consumption_s64 = 6,

    /** implementation name */
    mkldnn_query_impl_info_str = 7,

    /* memory and op descriptor section */
    /** stub */
    mkldnn_query_some_d = 64,
    /** op descriptor */
    mkldnn_query_op_d = 65,
    /** memory descriptor for memory and view */
    mkldnn_query_memory_d = 66,
    /** convolution descriptor */
    mkldnn_query_convolution_d = 67,
    /** deconvolution descriptor */
    mkldnn_query_deconvolution_d = 68,
    /** shuffle descriptor */
    mkldnn_query_shuffle_d = 69,
    /** eltwise descriptor */
    mkldnn_query_eltwise_d = 70,
    /** @deprecated */
    mkldnn_query_relu_d = mkldnn_query_eltwise_d,
    /** softmax descriptor */
    mkldnn_query_softmax_d = mkldnn_query_eltwise_d + 1,
    /** pooling descriptor */
    mkldnn_query_pooling_d = mkldnn_query_eltwise_d + 2,
    /** lrn descriptor */
    mkldnn_query_lrn_d = mkldnn_query_eltwise_d + 3,
    /** batch normalization descriptor */
    mkldnn_query_batch_normalization_d = mkldnn_query_eltwise_d + 4,
    /** inner product descriptor */
    mkldnn_query_inner_product_d = mkldnn_query_eltwise_d + 5,
    /** @deprecated */
    mkldnn_query_convolution_relu_d = mkldnn_query_eltwise_d + 6,
    /** rnn descriptor */
    mkldnn_query_rnn_d = mkldnn_query_eltwise_d + 7,

    /* (memory) primitive descriptor section */
    /** stub */
    mkldnn_query_some_pd = 128,
    /** input memory primitive desc */
    mkldnn_query_input_pd = 129,
    /** output memory primitive desc */
    mkldnn_query_output_pd = 130,
    /** source memory primitive desc */
    mkldnn_query_src_pd = 131,
    /** source gradient memory primitive desc */
    mkldnn_query_diff_src_pd = 132,
    /** weights memory primitive descriptor desc */
    mkldnn_query_weights_pd = 133,
    /** weights grad. memory primitive desc */
    mkldnn_query_diff_weights_pd = 134,
    /** destination memory primitive desc */
    mkldnn_query_dst_pd = 135,
    /** destination grad. memory primitive desc */
    mkldnn_query_diff_dst_pd = 136,
    /** workspace memory primitive desc */
    mkldnn_query_workspace_pd = 137;

/** \} */

/** \addtogroup c_api_types_stream Execution stream
 * \{ */

/** \brief Kinds of streams. */
/** enum mkldnn_stream_kind_t */
public static final int
    /** An unspecified engine. */
    mkldnn_any_stream = 0,
    /** Eager stream. */
    mkldnn_eager = 1,
    /** Lazy stream. */
    mkldnn_lazy = 2;

/** \struct mkldnn_stream
 * An opaque structure to describe an execution stream. */
@Opaque public static class mkldnn_stream extends Pointer {
    /** Empty constructor. Calls {@code super((Pointer)null)}. */
    public mkldnn_stream() { super((Pointer)null); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public mkldnn_stream(Pointer p) { super(p); }
}
/** An execution stream handle. */
/** A constant execution stream handle. */

/** \} */
/** \} */
/** \} */

// #ifdef __cplusplus
// #endif


// #endif


// Parsed from mkldnn.h

/*******************************************************************************
* Copyright 2016-2018 Intel Corporation
*
* Licensed under the Apache License, Version 2.0 (the "License");
* you may not use this file except in compliance with the License.
* You may obtain a copy of the License at
*
*     http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
* See the License for the specific language governing permissions and
* limitations under the License.
*******************************************************************************/

// #ifndef MKLDNN_H
// #define MKLDNN_H

// #ifndef DOXYGEN_SHOULD_SKIP_THIS
// #endif /* DOXYGEN_SHOULD_SKIP_THIS */

// #ifdef __cplusplus
// #endif

/** \addtogroup c_api C API
 * \{ */

/** \addtogroup c_api_primitive Primitive operations
 * \{ */

/** \addtogroup c_api_primitive_common Common primitive operations
 * \{ */

/** Creates a primitive descriptor \p iterator for given \p op_desc, \p engine,
 * and optionally a hint primitive descriptor from forward propagation
 * (required for backward propagation). Pass \c NULL for forward propagation.
 */
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_desc_iterator_create(
        @ByPtrPtr mkldnn_primitive_desc_iterator iterator,
        const_mkldnn_op_desc_t op_desc, mkldnn_engine engine,
        @Const mkldnn_primitive_desc hint_forward_primitive_desc);
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_desc_iterator_create(
        @Cast("mkldnn_primitive_desc_iterator_t*") PointerPointer iterator,
        const_mkldnn_op_desc_t op_desc, mkldnn_engine engine,
        @Const mkldnn_primitive_desc hint_forward_primitive_desc);

/** Creates a primitive descriptor \p iterator for given \p op_desc, \p attr,
 * \p engine, and optionally a hint primitive descriptor from forward
 * propagation (required for backward propagation). Pass \c NULL for forward
 * propagation.
 */
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_desc_iterator_create_v2(
        @ByPtrPtr mkldnn_primitive_desc_iterator iterator,
        const_mkldnn_op_desc_t op_desc, @Const mkldnn_primitive_attr attr,
        mkldnn_engine engine,
        @Const mkldnn_primitive_desc hint_forward_primitive_desc);
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_desc_iterator_create_v2(
        @Cast("mkldnn_primitive_desc_iterator_t*") PointerPointer iterator,
        const_mkldnn_op_desc_t op_desc, @Const mkldnn_primitive_attr attr,
        mkldnn_engine engine,
        @Const mkldnn_primitive_desc hint_forward_primitive_desc);

/** Iterates over primitive descriptors. Returns #mkldnn_iterator_ends if no
 * more primitive descriptors are available */
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_desc_iterator_next(
        mkldnn_primitive_desc_iterator iterator);

/** Fetches current primitive descriptor.
 *
 * \note
 *     fetched primitive descriptor should be deleted by user using
 *     mkldnn_primitive_desc_destroy() once becomes unneeded */
public static native mkldnn_primitive_desc mkldnn_primitive_desc_iterator_fetch(
        @Const mkldnn_primitive_desc_iterator iterator);

/** Deletes a primitive descriptor \p iterator */
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_desc_iterator_destroy(
        mkldnn_primitive_desc_iterator iterator);

/** Creates a \p primitive_desc using \p op_desc, \p engine, and optionally a
 * hint primitive descriptor from forward propagation. The call is equivalent
 * to create a primitive descriptor iterator, instantly fetch a primitive_desc
 * and destroy the iterator. */
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_desc_create(
        @ByPtrPtr mkldnn_primitive_desc primitive_desc,
        const_mkldnn_op_desc_t op_desc, mkldnn_engine engine,
        @Const mkldnn_primitive_desc hint_forward_primitive_desc);
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_desc_create(
        @Cast("mkldnn_primitive_desc_t*") PointerPointer primitive_desc,
        const_mkldnn_op_desc_t op_desc, mkldnn_engine engine,
        @Const mkldnn_primitive_desc hint_forward_primitive_desc);

/** Creates a \p primitive_desc using \p op_desc, \p attr, \p engine, and
 * optionally a hint primitive descriptor from forward propagation. The call is
 * equivalent to create a primitive descriptor iterator, instantly fetch a \p
 * primitive_desc and destroy the iterator. */
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_desc_create_v2(
        @ByPtrPtr mkldnn_primitive_desc primitive_desc,
        const_mkldnn_op_desc_t op_desc, @Const mkldnn_primitive_attr attr,
        mkldnn_engine engine,
        @Const mkldnn_primitive_desc hint_forward_primitive_desc);
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_desc_create_v2(
        @Cast("mkldnn_primitive_desc_t*") PointerPointer primitive_desc,
        const_mkldnn_op_desc_t op_desc, @Const mkldnn_primitive_attr attr,
        mkldnn_engine engine,
        @Const mkldnn_primitive_desc hint_forward_primitive_desc);

/** Makes a copy of a \p primitive_desc. */
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_desc_clone(
        @ByPtrPtr mkldnn_primitive_desc primitive_desc,
        @Const mkldnn_primitive_desc existing_primitive_desc);
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_desc_clone(
        @Cast("mkldnn_primitive_desc_t*") PointerPointer primitive_desc,
        @Const mkldnn_primitive_desc existing_primitive_desc);

/** Returns a constant reference to the attribute of a \p primitive_desc.
 *
 * \warning
 *      User should not destroy obtained \p attr
 *
 * \warning
 *      The lifetime of an \p attr is same as \p primitive_desc, so it is
 *      illegal to use the \p attr once \p primitive_desc is destroyed */
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_desc_get_attr(
        @Const mkldnn_primitive_desc primitive_desc,
        @Const @ByPtrPtr mkldnn_primitive_attr attr);
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_desc_get_attr(
        @Const mkldnn_primitive_desc primitive_desc,
        @Cast("const_mkldnn_primitive_attr_t*") PointerPointer attr);

/** Deletes a \p primitive_desc. */
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_desc_destroy(
        mkldnn_primitive_desc primitive_desc);

/** Queries primitive descriptor
 *
 * One of the most typical use cases is to query a convolution primitive
 * descriptor created with source, weights and destination formats equal
 * to #mkldnn_any about the corresponding memory primitive descriptors
 * (\p what equals #mkldnn_query_src_pd, #mkldnn_query_weights_pd, and
 * #mkldnn_query_dst_pd respectively) to be able to prepare memory and
 * create reorders if required.
 *
 * Another quite typical use case is to query an operation primitive
 * descriptor for a workspace (\p what equals #mkldnn_query_workspace_pd).
 * Returned status #mkldnn_not_required indicates that workspace is
 * not required.
 *
 * Few other possibilities:
 *  - query a memory primitive descriptor for the underlying memory
 *    descriptor (#mkldnn_query_memory_d)
 *  - query an operation primitive descriptor for the underlying operation
 *    descriptor (#mkldnn_query_convolution_d, #mkldnn_query_eltwise_d,
 *    #mkldnn_query_rnn_d, etc)
 *  - query an operation primitive descriptor for the implementation
 *    information string (#mkldnn_query_impl_info_str)
 *  - query an operation primitive descriptor for the number of inputs and
 *    outputs (#mkldnn_query_num_of_inputs_s32 and
 *    #mkldnn_query_num_of_outputs_s32 respectively)
 *
 * \sa mkldnn_query_t for more options
 */
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_desc_query(
        @Const mkldnn_primitive_desc primitive_desc, @Cast("mkldnn_query_t") int what,
        int index, Pointer result);

/** Queries primitive descriptor for memory descriptor
 *
 * @return NULL in case of any error (in particular if queried entity is
 * not of type mkldnn_memory_desc_t).
 *
 * This is just a specialized version of mkldnn_primitive_desc_query
 * used for convenience.
 */
public static native @Const mkldnn_memory_desc_t mkldnn_primitive_desc_query_memory_d(
        @Const mkldnn_primitive_desc primitive_desc);

/** Queries primitive descriptor for primitive descriptor
 *
 * @return NULL in case of any error (in particular if queried entity is
 * not of type const_mkldnn_primitive_desc_t).
 *
 * This is just a specialized version of mkldnn_primitive_desc_query
 * used for convenience.
 *
 * Example: query an operation primitive descriptor for a workspace
 *         (\p what equals #mkldnn_query_workspace_pd). Returned
 *         NULL indicates the primitive does not require a workspace.
 *         Otherwise a user should prepare the workspace and pass it
 *         to the corresponding primitive.
 */
public static native @Const mkldnn_primitive_desc mkldnn_primitive_desc_query_pd(
        @Const mkldnn_primitive_desc primitive_desc, @Cast("mkldnn_query_t") int what,
        int index);

/** Queries primitive descriptor for signed 32bit int
 *
 * @return 0 in case of any error (in particular if queried entity is
 * not of type int32_t). Note that 0 might also be the actual returned
 * value.
 *
 * This is just a specialized version of mkldnn_primitive_desc_query
 * used for convenience.
 */
public static native int mkldnn_primitive_desc_query_s32(
        @Const mkldnn_primitive_desc primitive_desc, @Cast("mkldnn_query_t") int what,
        int index);

/** Creates a \p primitive using a \p primitive_desc descriptor and arrays of
 * \p inputs and \p outputs. */
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_create(
        @ByPtrPtr mkldnn_primitive primitive,
        @Const mkldnn_primitive_desc primitive_desc,
        @Const mkldnn_primitive_at_t inputs,
        @Const @ByPtrPtr mkldnn_primitive outputs);
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_create(
        @Cast("mkldnn_primitive_t*") PointerPointer primitive,
        @Const mkldnn_primitive_desc primitive_desc,
        @Const mkldnn_primitive_at_t inputs,
        @Cast("const_mkldnn_primitive_t*") PointerPointer outputs);

/** Retrieves a reference to the \p primitive_desc descriptor of given \p
 * primitive.
 *
 * \warning
 *     Returned object must not be destroyed by user. 'const' qualifier of the
 *     returned object prevents such attempts. */
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_get_primitive_desc(
        @Const mkldnn_primitive primitive,
        @Const @ByPtrPtr mkldnn_primitive_desc primitive_desc);
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_get_primitive_desc(
        @Const mkldnn_primitive primitive,
        @Cast("const_mkldnn_primitive_desc_t*") PointerPointer primitive_desc);

/** For a \p primitive, returns \p input at the \p index position. */
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_get_input_at(
        @Const mkldnn_primitive primitive, @Cast("size_t") long index,
        mkldnn_primitive_at_t input);

/** For a \p primitive, returns \p output at the \p index position. */
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_get_output(
        @Const mkldnn_primitive primitive, @Cast("size_t") long index,
        @Const @ByPtrPtr mkldnn_primitive output);
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_get_output(
        @Const mkldnn_primitive primitive, @Cast("size_t") long index,
        @Cast("const_mkldnn_primitive_t*") PointerPointer output);

/** Deletes a \p primitive. */
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_destroy(
        mkldnn_primitive primitive);

/** Creates an #mkldnn_primitive_at_t structure from a \p primitive and \p
 * output_index. This function only fills in the data structure
 * and does not check whether parameters are correct. The actual error checking
 * is done when the resulting #mkldnn_primitive_at structure is passed to a
 * primitive creation function. */
public static native @ByVal mkldnn_primitive_at_t mkldnn_primitive_at(
        @Const mkldnn_primitive primitive, @Cast("size_t") long output_index);

/** \} */

/** \addtogroup c_api_attributes Attributes
 * An extension for controlling primitive behavior.
 * \{ */

/** Creates an empty (default) \p attr attribute. All the parameters set to
 * default values.
 *
 * An empty attribute is used in primitive descriptor creating whenever it is
 * not passed explicitly, e.g. in mkldnn_primitive_desc_create.
 */
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_attr_create(
        @ByPtrPtr mkldnn_primitive_attr attr);
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_attr_create(
        @Cast("mkldnn_primitive_attr_t*") PointerPointer attr);

/** Makes a copy of an \p existing_attr. */
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_attr_clone(
        @ByPtrPtr mkldnn_primitive_attr attr,
        @Const mkldnn_primitive_attr existing_attr);
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_attr_clone(
        @Cast("mkldnn_primitive_attr_t*") PointerPointer attr,
        @Const mkldnn_primitive_attr existing_attr);

/** Deletes an \p attr. */
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_attr_destroy(
        mkldnn_primitive_attr attr);

/** Returns integer output rounding mode \p round_mode for a given \p attr,
 * previously set by mkldnn_primitive_attr_set_int_output_round_mode. */
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_attr_get_int_output_round_mode(
        @Const mkldnn_primitive_attr attr, @Cast("mkldnn_round_mode_t*") IntPointer round_mode);
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_attr_get_int_output_round_mode(
        @Const mkldnn_primitive_attr attr, @Cast("mkldnn_round_mode_t*") IntBuffer round_mode);
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_attr_get_int_output_round_mode(
        @Const mkldnn_primitive_attr attr, @Cast("mkldnn_round_mode_t*") int[] round_mode);

/** Sets output rounding mode \p round_mode for integer operations for a given
 * \p attr.
 *
 * The default value is #mkldnn_round_nearest.
 */
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_attr_set_int_output_round_mode(
        mkldnn_primitive_attr attr, @Cast("mkldnn_round_mode_t") int round_mode);

/** Returns \p count, correspondence scale \p mask, and pointer to a constant
 * floating point array of output \p scales for given \p attr, previously set
 * by mkldnn_primitive_attr_set_output_scales.
 *
 * \warning
 *      \p scales array points to the internal \p attr field, so user should
 *      not modify/destroy \p scales.
 *
 * \warning
 *      The lifetime of \p scales is same as \p attr it belongs to, so it is
 *      illegal to use the \p scales after \p attr is destroyed
 */
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_attr_get_output_scales(
        @Const mkldnn_primitive_attr attr, IntPointer count, IntPointer mask,
        @Cast("const float**") PointerPointer scales);
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_attr_get_output_scales(
        @Const mkldnn_primitive_attr attr, IntPointer count, IntPointer mask,
        @Const @ByPtrPtr FloatPointer scales);
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_attr_get_output_scales(
        @Const mkldnn_primitive_attr attr, IntBuffer count, IntBuffer mask,
        @Const @ByPtrPtr FloatBuffer scales);
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_attr_get_output_scales(
        @Const mkldnn_primitive_attr attr, int[] count, int[] mask,
        @Const @ByPtrPtr float[] scales);

/** Sets output \p scales for primitive operations. The number of elements \p
 * count and correspondence scale \p mask are stored for future use.
 *
 * The \p mask argument defines correspondence between output tensor dimensions
 * and the \p scales array. Set i-th bit of \p mask to 1 to use dedicated
 * scaling factor for each slice of the output tensor over i-th dimension. Set
 * \p mask to 0 to use common scaling factor for the whole output tensor.
 *
 * \note
 *      The dimension order is always native and does not depend on the actual
 *      layout used. Examples:
 *       - 2D dimensional data the order of dimensions is always: (n, c)
 *       - 4D dimensional data the order is always: (n, c, h, w)
 *       - 5D dimensional weights the order is always: (g, oc, ic, kh, kw)
 *
 * Example usage:
 * <pre>{@code
 *      int mb = 32, oc = 32, oh = 14, ow = 14; // convolution output params
 *      float scales[oc] = { ... }; // unique output scales per output channel
 *      int oc_dim = 1; // mb_dim = 0, channel_dim = 1, height_dim = 2, ...
 *
 *      mkldnn_convolution_desc_t cd; // create & configure convolution op_desc
 *
 *      mkldnn_primitive_attr_t attr;
 *      mkldnn_primitive_attr_create(&attr);  // create default attributes
 *      mkldnn_primitive_attr_set_output_scales(attr, oc, 1 << oc_dim, scales);
 *
 *      mkldnn_primitive_desc_t cpd;
 *      mkldnn_primitive_desc_create_v2(&cpd, &cd, attr, NULL);
 * }</pre>
 *
 * \note
 *      There is no way to check that \p count corresponds to \p mask until an
 *      actual primitive descriptor is created, so it is user's responsibility
 *      to set proper values. The following formula must be hold:
 *
 *      \f[count = \prod\limits_{d \in mask} output.dims[d]\f]
 */
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_attr_set_output_scales(
        mkldnn_primitive_attr attr, int count, int mask,
        @Const FloatPointer scales);
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_attr_set_output_scales(
        mkldnn_primitive_attr attr, int count, int mask,
        @Const FloatBuffer scales);
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_attr_set_output_scales(
        mkldnn_primitive_attr attr, int count, int mask,
        @Const float[] scales);

/** Returns \p post_ops for given attr.
 *
 * \warning
 *      \p post_ops points to the internal \p attr field, so user should not
 *      modify/destroy \p post_ops. Also the lifetime of \p post_ops is the
 *      same as \p attr it belongs to, so it is illegal to use \p post_ops once
 *      \p attr is destroyed.
 */
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_attr_get_post_ops(
        @Const mkldnn_primitive_attr attr, @Const @ByPtrPtr mkldnn_post_ops post_ops);
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_attr_get_post_ops(
        @Const mkldnn_primitive_attr attr, @Cast("const_mkldnn_post_ops_t*") PointerPointer post_ops);

/** Sets configured \p post_ops to an attribute \p attr for future use (when
 * primitive descriptor is being created.
 *
 * \note
 *      At this point of time there is no way to check whether primitive
 *      descriptor does or does not support given sequence of post operations.
 *      That means that user should handle an error that might happen at
 *      mkldnn_primitive_desc_create call.
 */
public static native @Cast("mkldnn_status_t") int mkldnn_primitive_attr_set_post_ops(
        mkldnn_primitive_attr attr, @Const mkldnn_post_ops post_ops);

/** \addtogroup c_api_attributes_post_ops Sequence of post operations
 * An extension for performing extra operations after base operation.
 * \{ */

/** Creates an empty sequence of post operations \p post_ops. */
public static native @Cast("mkldnn_status_t") int mkldnn_post_ops_create(@ByPtrPtr mkldnn_post_ops post_ops);
public static native @Cast("mkldnn_status_t") int mkldnn_post_ops_create(@Cast("mkldnn_post_ops_t*") PointerPointer post_ops);

/** Deletes a \p post_ops sequence. */
public static native @Cast("mkldnn_status_t") int mkldnn_post_ops_destroy(mkldnn_post_ops post_ops);

/** Returns the \p length of post operations for given \p post_ops. */
public static native int mkldnn_post_ops_len(@Const mkldnn_post_ops post_ops);

/** Returns the type of post operation with index \p index in given
 * \p post_ops. In case of error returns #mkldnn_undefined_primitive. */
public static native @Cast("mkldnn_primitive_kind_t") int mkldnn_post_ops_get_kind(
        @Const mkldnn_post_ops post_ops, int index);

/** Appends accumulation (sum) post operation to the \p post_ops. Prior to
 * accumulating the result the previous value would be multiplied by \p scale.
 *
 * The kind of this post operation is #mkldnn_sum.
 *
 * This feature might improve performance for the cases like residual learning
 * blocks, where the result of convolution is accumulated to the previously
 * computed activations. Scale parameter \p scale might be extremely for the
 * integer-based computations, when the result and previous activations have
 * different logical scaling factors.
 *
 * In the simplest case when the accumulation is the only post operation, the
 * computations would be:
 * dst[] <- scale * dst[] + op(...) // instead of dst[] <- op(...)
 *
 * \note
 *      This post op (as well as all the others) disregards the original layout
 *      of dst, i.e. the layout of the original dst is expected to be the same
 *      as the layout of stored dst.
 */
public static native @Cast("mkldnn_status_t") int mkldnn_post_ops_append_sum(
        mkldnn_post_ops post_ops, float scale);

/** Gets the parameters of the accumulation (sum) post operation with index
 * \p index in the sequence of \p post_ops.
 *
 * \note
 *      If index \p index would not correspond to the accumulation post
 *      operation, the function return #mkldnn_invalid_arguments.
 */
public static native @Cast("mkldnn_status_t") int mkldnn_post_ops_get_params_sum(
        @Const mkldnn_post_ops post_ops, int index, FloatPointer scale);
public static native @Cast("mkldnn_status_t") int mkldnn_post_ops_get_params_sum(
        @Const mkldnn_post_ops post_ops, int index, FloatBuffer scale);
public static native @Cast("mkldnn_status_t") int mkldnn_post_ops_get_params_sum(
        @Const mkldnn_post_ops post_ops, int index, float[] scale);

/** Appends eltwise post operation to the \p post_ops with given parameters
 * \p kind, \p alpha and \p beta (\sa mkldnn_eltwise_forward_desc_init and
 * mkldnn_eltwise_desc_t).
 *
 * The kind of this post operation is #mkldnn_eltwise.
 *
 * In the simplest case when the eltwise is the only post operation, the
 * computations would be:
 * dst[] <- scale * eltwise_op ( op(...) ) // instead of dst[] <- op(...)
 * where eltwise_op is configured with given parameters.
 */
public static native @Cast("mkldnn_status_t") int mkldnn_post_ops_append_eltwise(
        mkldnn_post_ops post_ops, float scale, @Cast("mkldnn_alg_kind_t") int alg,
        float alpha, float beta);

/** Gets the eltwise parameters of the post operation with index \p index in
 * the sequence of \p post_ops.
 */
public static native @Cast("mkldnn_status_t") int mkldnn_post_ops_get_params_eltwise(
        @Const mkldnn_post_ops post_ops, int index, FloatPointer scale,
        @Cast("mkldnn_alg_kind_t*") IntPointer alg, FloatPointer alpha, FloatPointer beta);
public static native @Cast("mkldnn_status_t") int mkldnn_post_ops_get_params_eltwise(
        @Const mkldnn_post_ops post_ops, int index, FloatBuffer scale,
        @Cast("mkldnn_alg_kind_t*") IntBuffer alg, FloatBuffer alpha, FloatBuffer beta);
public static native @Cast("mkldnn_status_t") int mkldnn_post_ops_get_params_eltwise(
        @Const mkldnn_post_ops post_ops, int index, float[] scale,
        @Cast("mkldnn_alg_kind_t*") int[] alg, float[] alpha, float[] beta);

/** \} */

/** \} */

/** \addtogroup c_api_memory Memory
 * A primitive to describe and store data.
 *
 * The library supports various data types and formats. Memory hierarchy
 * consists of three levels of abstraction:
 * 1. **Memory descriptor** -- engine agnostic logical description of data
 *      (number of dimensions, dimensions themselves and data type), and
 *      optionally the format/layout that describes the physical representation
 *      of data in memory. If the format/layout is not known yet one can pass
 *      #mkldnn_any. This approach is used to allow compute intensive
 *      primitives to specify the most appropriate layout on their own with
 *      users required to reorder the data if the incoming layout doesn't match
 *      the primitive's selection. Memory descriptor can be created with
 *      mkldnn_memory_desc_init() function or by directly filling the
 *      mkldnn_memory_desc_t structure. The later requires deep knowledge of
 *      how the physical data representation is mapped to the structure. The
 *      \ref understanding_memory_formats topic should shed some light on that.
 * 2. **Memory primitive descriptor** -- logical description of data that is
 *      fully defined, i.e. cannot contain #mkldnn_any as a format. It also
 *      has the engine specified. A memory primitive descriptor is created by
 *      calling mkldnn_memory_primitive_desc_create() with two arguments: an
 *      mkldnn_memory_desc_t and an mkldnn_engine_t. It has the same type as
 *      other primitive descriptors and can be:
 *      - queried to return the underlying memory descriptor using
 *        mkldnn_primitive_desc_query() and
 *        mkldnn_primitive_desc_query_memory_d().
 *      - compared with another memory primitive descriptor using
 *        mkldnn_memory_primitive_desc_equal(). This is especially useful when
 *        checking whether a primitive requires reorder from user's data layout
 *        to the primitive's one.
 *      - queried to return the size of the data using
 *        mkldnn_memory_primitive_desc_get_size(). As described in
 *        \ref understanding_memory_formats the size of data sometimes cannot
 *        be computed as a product of dimensions times the size of data type.
 *        So users are encouraged to use this function to have better code
 *        portability.
 * 3. **Memory primitive** or simply **memory** -- a pseudo-primitive that is
 *      defined by a memory primitive descriptor and a handle to the data
 *      itself (in case of CPU engine the handle is simply a pointer {@code void*}).
 *      The data handle can be queried using mkldnn_memory_get_data_handle()
 *      and be set using mkldnn_memory_set_data_handle(). The latter function
 *      always sets the memory in the padding region to zero which is the
 *      invariant maintained by all the primitives in Intel MKL-DNN. See
 *      \ref understanding_memory_formats for more details.
 *      A memory primitive can be created using mkldnn_primitive_create() with
 *      empty inputs and outputs. In this case, the memory primitive's data
 *      handle needs to be set manually using mkldnn_memory_set_data_handle().
 *
 * Along with ordinary memory with all dimensions being positive, Intel
 * MKL-DNN supports *zero-volume* memory with one or more dimensions set to
 * zero. This is to support NumPy\* convention.
 * If a *zero-volume* memory is passed to a primitive, the primitive would
 * not perform any computations on this memory. For example:
 *  - Convolution with {@code (0 batch, 3 input channels, 13 height, 13 width)}
 *    source and {@code (16 output channels, 3 inputs, channel, 3 height, 3 width)}
 *    weights would produce {@code (0 batch, 16 ouput channels, 11 height, 11 width)}
 *    destination (assuming strides are {@code 1} and paddings are zero) and perform
 *    zero multiply-add operations.
 *  - Concatenation of 3 memories of shapes {@code (3, 4, 13, 13)}, {@code (3, 0, 13, 13)},
 *    and {@code (3, 1, 13, 13)} along the second axis would produce the output of
 *    the shape {@code (3, 5, 13, 13)}, effectively ignoring the second input
 *    (however if user created a concatenation primitive descriptor with 3
 *    inputs they should also provide all 3 memories to the concatenation
 *    primitive, including the one with zero second dimension).
 *  - However, Intel MKL-DNN would return an error when attempting to create a
 *    convolution with *zero-volume* memory passed for weights because such
 *    convolution is not well-defined:
 *    ~~~
 *    dst(1, 16, 11, 11) <-- src(1, 0, 13, 13) (*) wei(16, 0, 3, 3)
 *    ~~~
 *    Should the values in the destination be zeroes or just not accessed at
 *    all? Moreover, backward pass w.r.t. weights in such cases is not
 *    well-defined as well.
 *
 *  Data handle of *zero-volume* memory is never accessed and hence can be
 *  unset (NULL in case of CPU engine).
 *
 * \sa \ref understanding_memory_formats
 * \{ */

/** Initializes a \p memory_desc memory descriptor using \p ndims, \p dims, \p
 * data_type, and data \p format. \p format can be #mkldnn_any, which means
 * that specific data layouts are not permitted. */
public static native @Cast("mkldnn_status_t") int mkldnn_memory_desc_init(
        mkldnn_memory_desc_t memory_desc, int ndims, @Const IntPointer dims,
        @Cast("mkldnn_data_type_t") int data_type, @Cast("mkldnn_memory_format_t") int format);
public static native @Cast("mkldnn_status_t") int mkldnn_memory_desc_init(
        mkldnn_memory_desc_t memory_desc, int ndims, @Const IntBuffer dims,
        @Cast("mkldnn_data_type_t") int data_type, @Cast("mkldnn_memory_format_t") int format);
public static native @Cast("mkldnn_status_t") int mkldnn_memory_desc_init(
        mkldnn_memory_desc_t memory_desc, int ndims, @Const int[] dims,
        @Cast("mkldnn_data_type_t") int data_type, @Cast("mkldnn_memory_format_t") int format);

/** Creates a \p memory_primitive_desc memory primitive descriptor using \p
 * memory_desc and \p engine. \p memory_desc cannot be uncertain, that is,
 * initialized with #mkldnn_any. */
public static native @Cast("mkldnn_status_t") int mkldnn_memory_primitive_desc_create(
        @ByPtrPtr mkldnn_primitive_desc memory_primitive_desc,
        @Const mkldnn_memory_desc_t memory_desc, mkldnn_engine engine);
public static native @Cast("mkldnn_status_t") int mkldnn_memory_primitive_desc_create(
        @Cast("mkldnn_primitive_desc_t*") PointerPointer memory_primitive_desc,
        @Const mkldnn_memory_desc_t memory_desc, mkldnn_engine engine);

/** Creates a \p view_primitive_desc for a given \p memory_primitive_desc, with
 * \p dims sizes and \p offset offsets. May fail if layout used does not allow
 * obtain desired view. In this case consider using extract primitive */
public static native @Cast("mkldnn_status_t") int mkldnn_view_primitive_desc_create(
        @ByPtrPtr mkldnn_primitive_desc view_primitive_desc,
        @Const mkldnn_primitive_desc memory_primitive_desc,
        @Const IntPointer dims, @Const IntPointer offsets);
public static native @Cast("mkldnn_status_t") int mkldnn_view_primitive_desc_create(
        @Cast("mkldnn_primitive_desc_t*") PointerPointer view_primitive_desc,
        @Const mkldnn_primitive_desc memory_primitive_desc,
        @Const IntBuffer dims, @Const IntBuffer offsets);
public static native @Cast("mkldnn_status_t") int mkldnn_view_primitive_desc_create(
        @ByPtrPtr mkldnn_primitive_desc view_primitive_desc,
        @Const mkldnn_primitive_desc memory_primitive_desc,
        @Const int[] dims, @Const int[] offsets);
public static native @Cast("mkldnn_status_t") int mkldnn_view_primitive_desc_create(
        @Cast("mkldnn_primitive_desc_t*") PointerPointer view_primitive_desc,
        @Const mkldnn_primitive_desc memory_primitive_desc,
        @Const IntPointer dims, @Const IntPointer offsets);
public static native @Cast("mkldnn_status_t") int mkldnn_view_primitive_desc_create(
        @ByPtrPtr mkldnn_primitive_desc view_primitive_desc,
        @Const mkldnn_primitive_desc memory_primitive_desc,
        @Const IntBuffer dims, @Const IntBuffer offsets);
public static native @Cast("mkldnn_status_t") int mkldnn_view_primitive_desc_create(
        @Cast("mkldnn_primitive_desc_t*") PointerPointer view_primitive_desc,
        @Const mkldnn_primitive_desc memory_primitive_desc,
        @Const int[] dims, @Const int[] offsets);

/** Compares two descriptors of memory primitives.
 * @return 1 if the descriptors are the same.
 * @return 0 if the descriptors are different.
 *
 * Use this function to identify whether a reorder is required for the memory
 * primitives. \p lhs and \p rhs must be either memory or view primitive
 * descriptors. */
public static native int mkldnn_memory_primitive_desc_equal(
        @Const mkldnn_primitive_desc lhs,
        @Const mkldnn_primitive_desc rhs);

/** Returns the size (in bytes) that is required for given \p
 * memory_primitive_desc */
/* XXX: view? */
public static native @Cast("size_t") long mkldnn_memory_primitive_desc_get_size(
        @Const mkldnn_primitive_desc memory_primitive_desc);

/** For a \p memory primitive, returns the data \p handle. For the CPU engine,
 * the data handle is a pointer to the actual data. */
/* XXX: view? */
public static native @Cast("mkldnn_status_t") int mkldnn_memory_get_data_handle(
        @Const mkldnn_primitive memory, @Cast("void**") PointerPointer handle);
public static native @Cast("mkldnn_status_t") int mkldnn_memory_get_data_handle(
        @Const mkldnn_primitive memory, @Cast("void**") @ByPtrPtr Pointer handle);

/** For a \p memory primitive, sets the data \p handle. */
public static native @Cast("mkldnn_status_t") int mkldnn_memory_set_data_handle(
        mkldnn_primitive memory, Pointer handle);

/** \} */

/** \addtogroup c_api_reorder Reorder
 * A primitive to copy data between memory formats.
 * \{ */

/** Initializes a \p reorder_primitive_desc using descriptors of \p input and
 * \p output memory primitives.
 *
 * Order of inputs:
 *  - input (#mkldnn_query_input_pd, 0)
 *
 * Order of outputs:
 *  - output (#mkldnn_query_output_pd, 0)
 */
public static native @Cast("mkldnn_status_t") int mkldnn_reorder_primitive_desc_create(
        @ByPtrPtr mkldnn_primitive_desc reorder_primitive_desc,
        @Const mkldnn_primitive_desc input,
        @Const mkldnn_primitive_desc output);
public static native @Cast("mkldnn_status_t") int mkldnn_reorder_primitive_desc_create(
        @Cast("mkldnn_primitive_desc_t*") PointerPointer reorder_primitive_desc,
        @Const mkldnn_primitive_desc input,
        @Const mkldnn_primitive_desc output);

/** Initializes a \p reorder_primitive_desc using an \p attr attribute and
 * descriptors of \p input and \p output memory primitives.
 *
 * Order of inputs:
 *  - input (#mkldnn_query_input_pd, 0)
 *
 * Order of outputs:
 *  - output (#mkldnn_query_output_pd, 0)
 */
public static native @Cast("mkldnn_status_t") int mkldnn_reorder_primitive_desc_create_v2(
        @ByPtrPtr mkldnn_primitive_desc reorder_primitive_desc,
        @Const mkldnn_primitive_desc input,
        @Const mkldnn_primitive_desc output,
        @Const mkldnn_primitive_attr attr);
public static native @Cast("mkldnn_status_t") int mkldnn_reorder_primitive_desc_create_v2(
        @Cast("mkldnn_primitive_desc_t*") PointerPointer reorder_primitive_desc,
        @Const mkldnn_primitive_desc input,
        @Const mkldnn_primitive_desc output,
        @Const mkldnn_primitive_attr attr);

/** \} */

/** \addtogroup c_api_concat Concat
 * A primitive to concatenate data by arbitrary dimension
 * \{ */

/** Creates out-of-place \p concat_primitive_desc for concatenation of \p n
 * inputs by \p concat_dimension with resulting \p output_desc memory
 * descriptor. \p output_desc can be NULL or be specified with #mkldnn_any
 * format -- in this case appropriate memory format would be chosen
 * automatically.
 *
 * Order of inputs:
 *  - input 0 (#mkldnn_query_input_pd, 0)
 *  - input 1 (#mkldnn_query_input_pd, 1)
 *  - ...
 *  - input \p n - 1 (#mkldnn_query_input_pd, \p n - 1)
 *
 * Order of outputs:
 *  - output (#mkldnn_query_output_pd, 0)
 */
public static native @Cast("mkldnn_status_t") int mkldnn_concat_primitive_desc_create(
        @ByPtrPtr mkldnn_primitive_desc concat_primitive_desc,
        @Const mkldnn_memory_desc_t output_desc, int n, int concat_dimension,
        @Const @ByPtrPtr mkldnn_primitive_desc input_pds);
public static native @Cast("mkldnn_status_t") int mkldnn_concat_primitive_desc_create(
        @Cast("mkldnn_primitive_desc_t*") PointerPointer concat_primitive_desc,
        @Const mkldnn_memory_desc_t output_desc, int n, int concat_dimension,
        @Cast("const_mkldnn_primitive_desc_t*") PointerPointer input_pds);

// #if 0
// #endif

/** \} */

/** \addtogroup c_api_sum Sum
 * A primitive to sum data
 * \{ */

/** Creates out-of-place \p sum_primitive_desc for sum of \p n
 * inputs multiplied by scale with resulting \p output_desc memory
 * descriptor. \p output_desc can be NULL or be specified with #mkldnn_any
 * format -- in this case appropriate memory format would be chosen
 * automatically.
 *
 * Order of inputs:
 *  - input 0 (#mkldnn_query_input_pd, 0)
 *  - input 1 (#mkldnn_query_input_pd, 1)
 *  - ...
 *  - input \p n - 1 (#mkldnn_query_input_pd, \p n - 1)
 *
 * Order of outputs:
 *  - output (#mkldnn_query_output_pd, 0)
 */
public static native @Cast("mkldnn_status_t") int mkldnn_sum_primitive_desc_create(
        @ByPtrPtr mkldnn_primitive_desc sum_primitive_desc,
        @Const mkldnn_memory_desc_t output_desc, int n, @Const FloatPointer scales,
        @Const @ByPtrPtr mkldnn_primitive_desc input_pds);
public static native @Cast("mkldnn_status_t") int mkldnn_sum_primitive_desc_create(
        @Cast("mkldnn_primitive_desc_t*") PointerPointer sum_primitive_desc,
        @Const mkldnn_memory_desc_t output_desc, int n, @Const FloatBuffer scales,
        @Cast("const_mkldnn_primitive_desc_t*") PointerPointer input_pds);
public static native @Cast("mkldnn_status_t") int mkldnn_sum_primitive_desc_create(
        @ByPtrPtr mkldnn_primitive_desc sum_primitive_desc,
        @Const mkldnn_memory_desc_t output_desc, int n, @Const float[] scales,
        @Const @ByPtrPtr mkldnn_primitive_desc input_pds);
public static native @Cast("mkldnn_status_t") int mkldnn_sum_primitive_desc_create(
        @Cast("mkldnn_primitive_desc_t*") PointerPointer sum_primitive_desc,
        @Const mkldnn_memory_desc_t output_desc, int n, @Const FloatPointer scales,
        @Cast("const_mkldnn_primitive_desc_t*") PointerPointer input_pds);
public static native @Cast("mkldnn_status_t") int mkldnn_sum_primitive_desc_create(
        @ByPtrPtr mkldnn_primitive_desc sum_primitive_desc,
        @Const mkldnn_memory_desc_t output_desc, int n, @Const FloatBuffer scales,
        @Const @ByPtrPtr mkldnn_primitive_desc input_pds);
public static native @Cast("mkldnn_status_t") int mkldnn_sum_primitive_desc_create(
        @Cast("mkldnn_primitive_desc_t*") PointerPointer sum_primitive_desc,
        @Const mkldnn_memory_desc_t output_desc, int n, @Const float[] scales,
        @Cast("const_mkldnn_primitive_desc_t*") PointerPointer input_pds);

/** \} */

/** \addtogroup c_api_convolution Convolution
 * A primitive to compute convolution using different algorithms.
 *
 * \f[dst[n][oc][oh][ow]  =
 *     \sum_{kw=0}^{KW}\sum_{kh=0}^{KH}\sum_{ic=0}^{IC}
 *     src[n][ic][oh \cdot s_h - p_l[0] + kh][ow \cdot s_w - p_r[1] + kw]
 *     \cdot weights[g][oc][ic][kh][kw]
 *     + bias[g][oc],\f]
 *
 * where size of output spatial domain is given by
 * \f$ OH = \left\lfloor{\frac{IH - KH + p_l[0] + p_r[0]}{s_h}}
 *          \right\rfloor + 1\f$,
 * \f$ OW = \left\lfloor{\frac{IW - KW + p_l[1] + p_r[1]}{s_w}}
 *          \right\rfloor + 1\f$,
 *
 * and summation is carried over input channels \f$ic\f$ in
 * group \f$g\f$, and \f$s_h, s_w\f$ are \p strides and
 * \f$p_l, p_r\f$ are \p padding_l and \p padding_r.
 * \{ */

/** Initializes a convolution descriptor \p conv_desc for forward propagation
 * using \p prop_kind (possible values are #mkldnn_forward_training or
 * #mkldnn_forward_inference), \p alg_kind, memory descriptors, \p strides, \p
 * padding_l, \p padding_r, and \p padding_kind. In order to create a
 * convolution without bias, \p bias_desc should be either \c NULL or point to
 * a descriptor with memory format equals to #mkldnn_format_undef.
 *
 * \note if \p padding_r is \c NULL, the padding is supposed to be symmetric
 *
 * \note memory descriptors are allowed to be initialized with #mkldnn_any
 * value of \p format_kind.
 *
 * Order of inputs:
 *  - src (#mkldnn_query_src_pd, 0)
 *  - weights (#mkldnn_query_weights_pd, 0)
 *  - bias (#mkldnn_query_weights_pd, 1), if created with bias
 *
 * Order of outputs:
 *  - dst (#mkldnn_query_dst_pd, 0)
 */
public static native @Cast("mkldnn_status_t") int mkldnn_convolution_forward_desc_init(
        mkldnn_convolution_desc_t conv_desc, @Cast("mkldnn_prop_kind_t") int prop_kind,
        @Cast("mkldnn_alg_kind_t") int alg_kind, @Const mkldnn_memory_desc_t src_desc,
        @Const mkldnn_memory_desc_t weights_desc,
        @Const mkldnn_memory_desc_t bias_desc,
        @Const mkldnn_memory_desc_t dst_desc, @Const IntPointer strides,
        @Const IntPointer padding_l, @Const IntPointer padding_r,
        @Cast("mkldnn_padding_kind_t") int padding_kind);
public static native @Cast("mkldnn_status_t") int mkldnn_convolution_forward_desc_init(
        mkldnn_convolution_desc_t conv_desc, @Cast("mkldnn_prop_kind_t") int prop_kind,
        @Cast("mkldnn_alg_kind_t") int alg_kind, @Const mkldnn_memory_desc_t src_desc,
        @Const mkldnn_memory_desc_t weights_desc,
        @Const mkldnn_memory_desc_t bias_desc,
        @Const mkldnn_memory_desc_t dst_desc, @Const IntBuffer strides,
        @Const IntBuffer padding_l, @Const IntBuffer padding_r,
        @Cast("mkldnn_padding_kind_t") int padding_kind);
public static native @Cast("mkldnn_status_t") int mkldnn_convolution_forward_desc_init(
        mkldnn_convolution_desc_t conv_desc, @Cast("mkldnn_prop_kind_t") int prop_kind,
        @Cast("mkldnn_alg_kind_t") int alg_kind, @Const mkldnn_memory_desc_t src_desc,
        @Const mkldnn_memory_desc_t weights_desc,
        @Const mkldnn_memory_desc_t bias_desc,
        @Const mkldnn_memory_desc_t dst_desc, @Const int[] strides,
        @Const int[] padding_l, @Const int[] padding_r,
        @Cast("mkldnn_padding_kind_t") int padding_kind);

/** Initializes a dilated convolution descriptor \p conv_desc for forward
 * propagation using \p prop_kind (possible values are #mkldnn_forward_training
 * or #mkldnn_forward_inference), \p alg_kind, memory descriptors, \p strides,
 * \p dilates, \p padding_l, \p padding_r, and \p padding_kind.
 * In order to create a dilated convolution without bias, \p bias_desc
 * should be either \c NULL or point to a descriptor with memory format equals
 * to #mkldnn_format_undef.
 *
 * \note if \p padding_r is \c NULL, the padding is supposed to be symmetric
 *
 * \note memory descriptors are allowed to be initialized with #mkldnn_any
 * value of \p format_kind.
 *
 * Order of inputs:
 *  - src (#mkldnn_query_src_pd, 0)
 *  - weights (#mkldnn_query_weights_pd, 0)
 *  - bias (#mkldnn_query_weights_pd, 1), if created with bias
 *
 * Order of outputs:
 *  - dst (#mkldnn_query_dst_pd, 0)
 */
public static native @Cast("mkldnn_status_t") int mkldnn_dilated_convolution_forward_desc_init(
        mkldnn_convolution_desc_t conv_desc, @Cast("mkldnn_prop_kind_t") int prop_kind,
        @Cast("mkldnn_alg_kind_t") int alg_kind, @Const mkldnn_memory_desc_t src_desc,
        @Const mkldnn_memory_desc_t weights_desc,
        @Const mkldnn_memory_desc_t bias_desc,
        @Const mkldnn_memory_desc_t dst_desc, @Const IntPointer strides,
        @Const IntPointer dilates, @Const IntPointer padding_l,
        @Const IntPointer padding_r, @Cast("mkldnn_padding_kind_t") int padding_kind);
public static native @Cast("mkldnn_status_t") int mkldnn_dilated_convolution_forward_desc_init(
        mkldnn_convolution_desc_t conv_desc, @Cast("mkldnn_prop_kind_t") int prop_kind,
        @Cast("mkldnn_alg_kind_t") int alg_kind, @Const mkldnn_memory_desc_t src_desc,
        @Const mkldnn_memory_desc_t weights_desc,
        @Const mkldnn_memory_desc_t bias_desc,
        @Const mkldnn_memory_desc_t dst_desc, @Const IntBuffer strides,
        @Const IntBuffer dilates, @Const IntBuffer padding_l,
        @Const IntBuffer padding_r, @Cast("mkldnn_padding_kind_t") int padding_kind);
public static native @Cast("mkldnn_status_t") int mkldnn_dilated_convolution_forward_desc_init(
        mkldnn_convolution_desc_t conv_desc, @Cast("mkldnn_prop_kind_t") int prop_kind,
        @Cast("mkldnn_alg_kind_t") int alg_kind, @Const mkldnn_memory_desc_t src_desc,
        @Const mkldnn_memory_desc_t weights_desc,
        @Const mkldnn_memory_desc_t bias_desc,
        @Const mkldnn_memory_desc_t dst_desc, @Const int[] strides,
        @Const int[] dilates, @Const int[] padding_l,
        @Const int[] padding_r, @Cast("mkldnn_padding_kind_t") int padding_kind);

/** Initializes a convolution descriptor \p conv_desc for backward propagation
 * with respect to data using \p alg_kind, memory descriptors, \p strides, \p
 * padding_l, \p padding_r, and \p padding_kind.
 *
 * \note memory descriptors are allowed to be initialized with #mkldnn_any
 * value of \p format_kind.
 *
 * Order of inputs:
 *  - diff_dst (#mkldnn_query_diff_dst_pd, 0)
 *  - weights (#mkldnn_query_weights_pd, 0)
 *
 * Order of outputs:
 *  - diff_src (#mkldnn_query_diff_src_pd, 0)
 */
public static native @Cast("mkldnn_status_t") int mkldnn_convolution_backward_data_desc_init(
        mkldnn_convolution_desc_t conv_desc, @Cast("mkldnn_alg_kind_t") int alg_kind,
        @Const mkldnn_memory_desc_t diff_src_desc,
        @Const mkldnn_memory_desc_t weights_desc,
        @Const mkldnn_memory_desc_t diff_dst_desc, @Const IntPointer strides,
        @Const IntPointer padding_l, @Const IntPointer padding_r,
        @Cast("mkldnn_padding_kind_t") int padding_kind);
public static native @Cast("mkldnn_status_t") int mkldnn_convolution_backward_data_desc_init(
        mkldnn_convolution_desc_t conv_desc, @Cast("mkldnn_alg_kind_t") int alg_kind,
        @Const mkldnn_memory_desc_t diff_src_desc,
        @Const mkldnn_memory_desc_t weights_desc,
        @Const mkldnn_memory_desc_t diff_dst_desc, @Const IntBuffer strides,
        @Const IntBuffer padding_l, @Const IntBuffer padding_r,
        @Cast("mkldnn_padding_kind_t") int padding_kind);
public static native @Cast("mkldnn_status_t") int mkldnn_convolution_backward_data_desc_init(
        mkldnn_convolution_desc_t conv_desc, @Cast("mkldnn_alg_kind_t") int alg_kind,
        @Const mkldnn_memory_desc_t diff_src_desc,
        @Const mkldnn_memory_desc_t weights_desc,
        @Const mkldnn_memory_desc_t diff_dst_desc, @Const int[] strides,
        @Const int[] padding_l, @Const int[] padding_r,
        @Cast("mkldnn_padding_kind_t") int padding_kind);

/** Initializes a dilated convolution descriptor \p conv_desc for backward
 * propagation with respect to data using \p alg_kind, memory descriptors, \p
 * strides, \p dilates \p padding_l, \p padding_r, and \p padding_kind.
 *
 * \note memory descriptors are allowed to be initialized with #mkldnn_any
 * value of \p format_kind.
 *
 * Order of inputs:
 *  - diff_dst (#mkldnn_query_diff_dst_pd, 0)
 *  - weights (#mkldnn_query_weights_pd, 0)
 *
 * Order of outputs:
 *  - diff_src (#mkldnn_query_diff_src_pd, 0)
 */
public static native @Cast("mkldnn_status_t") int mkldnn_dilated_convolution_backward_data_desc_init(
        mkldnn_convolution_desc_t conv_desc, @Cast("mkldnn_alg_kind_t") int alg_kind,
        @Const mkldnn_memory_desc_t diff_src_desc,
        @Const mkldnn_memory_desc_t weights_desc,
        @Const mkldnn_memory_desc_t diff_dst_desc, @Const IntPointer strides,
        @Const IntPointer dilates, @Const IntPointer padding_l,
        @Const IntPointer padding_r, @Cast("mkldnn_padding_kind_t") int padding_kind);
public static native @Cast("mkldnn_status_t") int mkldnn_dilated_convolution_backward_data_desc_init(
        mkldnn_convolution_desc_t conv_desc, @Cast("mkldnn_alg_kind_t") int alg_kind,
        @Const mkldnn_memory_desc_t diff_src_desc,
        @Const mkldnn_memory_desc_t weights_desc,
        @Const mkldnn_memory_desc_t diff_dst_desc, @Const IntBuffer strides,
        @Const IntBuffer dilates, @Const IntBuffer padding_l,
        @Const IntBuffer padding_r, @Cast("mkldnn_padding_kind_t") int padding_kind);
public static native @Cast("mkldnn_status_t") int mkldnn_dilated_convolution_backward_data_desc_init(
        mkldnn_convolution_desc_t conv_desc, @Cast("mkldnn_alg_kind_t") int alg_kind,
        @Const mkldnn_memory_desc_t diff_src_desc,
        @Const mkldnn_memory_desc_t weights_desc,
        @Const mkldnn_memory_desc_t diff_dst_desc, @Const int[] strides,
        @Const int[] dilates, @Const int[] padding_l,
        @Const int[] padding_r, @Cast("mkldnn_padding_kind_t") int padding_kind);

/** Initializes a convolution descriptor \p conv_desc for backward propagation
 * with respect to weights using \p alg_kind, memory descriptors, \p strides,
 * \p padding_l, \p padding_r, and \p padding_kind.
 *
 * \note memory descriptors are allowed to be initialized with #mkldnn_any
 * value of \p format_kind.
 *
 * Order of inputs:
 *  - src (#mkldnn_query_src_pd, 0)
 *  - diff_dst (#mkldnn_query_diff_dst_pd, 0)
 *
 * Order of outputs:
 *  - diff_weights (#mkldnn_query_diff_weights_pd, 0)
 *  - diff_bias (#mkldnn_query_diff_weights_pd, 1), if created with bias
 */
public static native @Cast("mkldnn_status_t") int mkldnn_convolution_backward_weights_desc_init(
        mkldnn_convolution_desc_t conv_desc, @Cast("mkldnn_alg_kind_t") int alg_kind,
        @Const mkldnn_memory_desc_t src_desc,
        @Const mkldnn_memory_desc_t diff_weights_desc,
        @Const mkldnn_memory_desc_t diff_bias_desc,
        @Const mkldnn_memory_desc_t diff_dst_desc, @Const IntPointer strides,
        @Const IntPointer padding_l, @Const IntPointer padding_r,
        @Cast("mkldnn_padding_kind_t") int padding_kind);
public static native @Cast("mkldnn_status_t") int mkldnn_convolution_backward_weights_desc_init(
        mkldnn_convolution_desc_t conv_desc, @Cast("mkldnn_alg_kind_t") int alg_kind,
        @Const mkldnn_memory_desc_t src_desc,
        @Const mkldnn_memory_desc_t diff_weights_desc,
        @Const mkldnn_memory_desc_t diff_bias_desc,
        @Const mkldnn_memory_desc_t diff_dst_desc, @Const IntBuffer strides,
        @Const IntBuffer padding_l, @Const IntBuffer padding_r,
        @Cast("mkldnn_padding_kind_t") int padding_kind);
public static native @Cast("mkldnn_status_t") int mkldnn_convolution_backward_weights_desc_init(
        mkldnn_convolution_desc_t conv_desc, @Cast("mkldnn_alg_kind_t") int alg_kind,
        @Const mkldnn_memory_desc_t src_desc,
        @Const mkldnn_memory_desc_t diff_weights_desc,
        @Const mkldnn_memory_desc_t diff_bias_desc,
        @Const mkldnn_memory_desc_t diff_dst_desc, @Const int[] strides,
        @Const int[] padding_l, @Const int[] padding_r,
        @Cast("mkldnn_padding_kind_t") int padding_kind);

/** Initializes a convolution descriptor \p conv_desc for backward propagation
 * with respect to weights using \p alg_kind, memory descriptors, \p strides,
 * \p dilates \p padding_l, \p padding_r, and \p padding_kind.
 *
 * \note memory descriptors are allowed to be initialized with #mkldnn_any
 * value of \p format_kind.
 *
 * Order of inputs:
 *  - src (#mkldnn_query_src_pd, 0)
 *  - diff_dst (#mkldnn_query_diff_dst_pd, 0)
 *
 * Order of outputs:
 *  - diff_weights (#mkldnn_query_diff_weights_pd, 0)
 *  - diff_bias (#mkldnn_query_diff_weights_pd, 1), if created with bias
 */
public static native @Cast("mkldnn_status_t") int mkldnn_dilated_convolution_backward_weights_desc_init(
        mkldnn_convolution_desc_t conv_desc, @Cast("mkldnn_alg_kind_t") int alg_kind,
        @Const mkldnn_memory_desc_t src_desc,
        @Const mkldnn_memory_desc_t diff_weights_desc,
        @Const mkldnn_memory_desc_t diff_bias_desc,
        @Const mkldnn_memory_desc_t diff_dst_desc, @Const IntPointer strides,
        @Const IntPointer dilates, @Const IntPointer padding_l,
        @Const IntPointer padding_r, @Cast("mkldnn_padding_kind_t") int padding_kind);
public static native @Cast("mkldnn_status_t") int mkldnn_dilated_convolution_backward_weights_desc_init(
        mkldnn_convolution_desc_t conv_desc, @Cast("mkldnn_alg_kind_t") int alg_kind,
        @Const mkldnn_memory_desc_t src_desc,
        @Const mkldnn_memory_desc_t diff_weights_desc,
        @Const mkldnn_memory_desc_t diff_bias_desc,
        @Const mkldnn_memory_desc_t diff_dst_desc, @Const IntBuffer strides,
        @Const IntBuffer dilates, @Const IntBuffer padding_l,
        @Const IntBuffer padding_r, @Cast("mkldnn_padding_kind_t") int padding_kind);
public static native @Cast("mkldnn_status_t") int mkldnn_dilated_convolution_backward_weights_desc_init(
        mkldnn_convolution_desc_t conv_desc, @Cast("mkldnn_alg_kind_t") int alg_kind,
        @Const mkldnn_memory_desc_t src_desc,
        @Const mkldnn_memory_desc_t diff_weights_desc,
        @Const mkldnn_memory_desc_t diff_bias_desc,
        @Const mkldnn_memory_desc_t diff_dst_desc, @Const int[] strides,
        @Const int[] dilates, @Const int[] padding_l,
        @Const int[] padding_r, @Cast("mkldnn_padding_kind_t") int padding_kind);

/** \} */

/** \addtogroup c_api_deconvolution Deconvolution
 * A primitive to compute deconvolution using different algorithms.
 *
 * \{ */


/** Initializes a deconvolution descriptor \p deconv_desc for forward propagation
 * using \p prop_kind (possible values are #mkldnn_forward_training or
 * #mkldnn_forward_inference), \p alg_kind, memory descriptors, \p strides, \p
 * padding_l, \p padding_r, and \p padding_kind. In order to create a
 * deconvolution without bias, \p bias_desc should be either \c NULL or point to
 * a descriptor with memory format equals to #mkldnn_format_undef.
 *
 * \note if \p padding_r is \c NULL, the padding is supposed to be symmetric
 *
 * \note memory descriptors are allowed to be initialized with #mkldnn_any
 * value of \p format_kind.
 *
 * Order of inputs:
 *  - src (#mkldnn_query_src_pd, 0)
 *  - weights (#mkldnn_query_weights_pd, 0)
 *  - bias (#mkldnn_query_weights_pd, 1), if created with bias
 *
 * Order of outputs:
 *  - dst (#mkldnn_query_dst_pd, 0)
 */
public static native @Cast("mkldnn_status_t") int mkldnn_deconvolution_forward_desc_init(
        @Cast("mkldnn_deconvolution_desc_t*") mkldnn_convolution_desc_t conv_desc, @Cast("mkldnn_prop_kind_t") int prop_kind,
        @Cast("mkldnn_alg_kind_t") int alg_kind, @Const mkldnn_memory_desc_t src_desc,
        @Const mkldnn_memory_desc_t weights_desc,
        @Const mkldnn_memory_desc_t bias_desc,
        @Const mkldnn_memory_desc_t dst_desc, @Const IntPointer strides,
        @Const IntPointer padding_l, @Const IntPointer padding_r,
        @Cast("mkldnn_padding_kind_t") int padding_kind);
public static native @Cast("mkldnn_status_t") int mkldnn_deconvolution_forward_desc_init(
        @Cast("mkldnn_deconvolution_desc_t*") mkldnn_convolution_desc_t conv_desc, @Cast("mkldnn_prop_kind_t") int prop_kind,
        @Cast("mkldnn_alg_kind_t") int alg_kind, @Const mkldnn_memory_desc_t src_desc,
        @Const mkldnn_memory_desc_t weights_desc,
        @Const mkldnn_memory_desc_t bias_desc,
        @Const mkldnn_memory_desc_t dst_desc, @Const IntBuffer strides,
        @Const IntBuffer padding_l, @Const IntBuffer padding_r,
        @Cast("mkldnn_padding_kind_t") int padding_kind);
public static native @Cast("mkldnn_status_t") int mkldnn_deconvolution_forward_desc_init(
        @Cast("mkldnn_deconvolution_desc_t*") mkldnn_convolution_desc_t conv_desc, @Cast("mkldnn_prop_kind_t") int prop_kind,
        @Cast("mkldnn_alg_kind_t") int alg_kind, @Const mkldnn_memory_desc_t src_desc,
        @Const mkldnn_memory_desc_t weights_desc,
        @Const mkldnn_memory_desc_t bias_desc,
        @Const mkldnn_memory_desc_t dst_desc, @Const int[] strides,
        @Const int[] padding_l, @Const int[] padding_r,
        @Cast("mkldnn_padding_kind_t") int padding_kind);

/** Initializes a dilated deconvolution descriptor \p deconv_desc for forward
 * propagation using \p prop_kind (possible values are #mkldnn_forward_training
 * or #mkldnn_forward_inference), \p alg_kind, memory descriptors, \p strides,
 * \p dilates, \p padding_l, \p padding_r, and \p padding_kind. In order to
 * create a dilated deconvolution without bias, \p bias_desc should be either
 * \c NULL or point to a descriptor with memory format equals to
 * #mkldnn_format_undef.
 *
 * \note if \p padding_r is \c NULL, the padding is supposed to be symmetric
 *
 * \note memory descriptors are allowed to be initialized with #mkldnn_any
 * value of \p format_kind.
 *
 * Order of inputs:
 *  - src (#mkldnn_query_src_pd, 0)
 *  - weights (#mkldnn_query_weights_pd, 0)
 *  - bias (#mkldnn_query_weights_pd, 1), if created with bias
 *
 * Order of outputs:
 *  - dst (#mkldnn_query_dst_pd, 0)
 */
public static native @Cast("mkldnn_status_t") int mkldnn_dilated_deconvolution_forward_desc_init(
        @Cast("mkldnn_deconvolution_desc_t*") mkldnn_convolution_desc_t conv_desc, @Cast("mkldnn_prop_kind_t") int prop_kind,
        @Cast("mkldnn_alg_kind_t") int alg_kind, @Const mkldnn_memory_desc_t src_desc,
        @Const mkldnn_memory_desc_t weights_desc,
        @Const mkldnn_memory_desc_t bias_desc,
        @Const mkldnn_memory_desc_t dst_desc, @Const IntPointer strides,
        @Const IntPointer dilates, @Const IntPointer padding_l,
        @Const IntPointer padding_r, @Cast("mkldnn_padding_kind_t") int padding_kind);
public static native @Cast("mkldnn_status_t") int mkldnn_dilated_deconvolution_forward_desc_init(
        @Cast("mkldnn_deconvolution_desc_t*") mkldnn_convolution_desc_t conv_desc, @Cast("mkldnn_prop_kind_t") int prop_kind,
        @Cast("mkldnn_alg_kind_t") int alg_kind, @Const mkldnn_memory_desc_t src_desc,
        @Const mkldnn_memory_desc_t weights_desc,
        @Const mkldnn_memory_desc_t bias_desc,
        @Const mkldnn_memory_desc_t dst_desc, @Const IntBuffer strides,
        @Const IntBuffer dilates, @Const IntBuffer padding_l,
        @Const IntBuffer padding_r, @Cast("mkldnn_padding_kind_t") int padding_kind);
public static native @Cast("mkldnn_status_t") int mkldnn_dilated_deconvolution_forward_desc_init(
        @Cast("mkldnn_deconvolution_desc_t*") mkldnn_convolution_desc_t conv_desc, @Cast("mkldnn_prop_kind_t") int prop_kind,
        @Cast("mkldnn_alg_kind_t") int alg_kind, @Const mkldnn_memory_desc_t src_desc,
        @Const mkldnn_memory_desc_t weights_desc,
        @Const mkldnn_memory_desc_t bias_desc,
        @Const mkldnn_memory_desc_t dst_desc, @Const int[] strides,
        @Const int[] dilates, @Const int[] padding_l,
        @Const int[] padding_r, @Cast("mkldnn_padding_kind_t") int padding_kind);

/** Initializes a deconvolution descriptor \p conv_desc for backward propagation
 * with respect to data using \p alg_kind, memory descriptors, \p strides, \p
 * padding_l, \p padding_r, and \p padding_kind.
 *
 * \note memory descriptors are allowed to be initialized with #mkldnn_any
 * value of \p format_kind.
 *
 * Order of inputs:
 *  - diff_dst (#mkldnn_query_diff_dst_pd, 0)
 *  - weights (#mkldnn_query_weights_pd, 0)
 *
 * Order of outputs:
 *  - diff_src (#mkldnn_query_diff_src_pd, 0)
 */
public static native @Cast("mkldnn_status_t") int mkldnn_deconvolution_backward_data_desc_init(
        @Cast("mkldnn_deconvolution_desc_t*") mkldnn_convolution_desc_t conv_desc, @Cast("mkldnn_alg_kind_t") int alg_kind,
        @Const mkldnn_memory_desc_t diff_src_desc,
        @Const mkldnn_memory_desc_t weights_desc,
        @Const mkldnn_memory_desc_t diff_dst_desc, @Const IntPointer strides,
        @Const IntPointer padding_l, @Const IntPointer padding_r,
        @Cast("mkldnn_padding_kind_t") int padding_kind);
public static native @Cast("mkldnn_status_t") int mkldnn_deconvolution_backward_data_desc_init(
        @Cast("mkldnn_deconvolution_desc_t*") mkldnn_convolution_desc_t conv_desc, @Cast("mkldnn_alg_kind_t") int alg_kind,
        @Const mkldnn_memory_desc_t diff_src_desc,
        @Const mkldnn_memory_desc_t weights_desc,
        @Const mkldnn_memory_desc_t diff_dst_desc, @Const IntBuffer strides,
        @Const IntBuffer padding_l, @Const IntBuffer padding_r,
        @Cast("mkldnn_padding_kind_t") int padding_kind);
public static native @Cast("mkldnn_status_t") int mkldnn_deconvolution_backward_data_desc_init(
        @Cast("mkldnn_deconvolution_desc_t*") mkldnn_convolution_desc_t conv_desc, @Cast("mkldnn_alg_kind_t") int alg_kind,
        @Const mkldnn_memory_desc_t diff_src_desc,
        @Const mkldnn_memory_desc_t weights_desc,
        @Const mkldnn_memory_desc_t diff_dst_desc, @Const int[] strides,
        @Const int[] padding_l, @Const int[] padding_r,
        @Cast("mkldnn_padding_kind_t") int padding_kind);

/** Initializes a dilated deconvolution descriptor \p conv_desc for backward
 * propagation with respect to data using \p alg_kind, memory descriptors, \p
 * strides, \p dilates, \p padding_l, \p padding_r, and \p padding_kind.
 *
 * \note memory descriptors are allowed to be initialized with #mkldnn_any
 * value of \p format_kind.
 *
 * Order of inputs:
 *  - diff_dst (#mkldnn_query_diff_dst_pd, 0)
 *  - weights (#mkldnn_query_weights_pd, 0)
 *
 * Order of outputs:
 *  - diff_src (#mkldnn_query_diff_src_pd, 0)
 */
public static native @Cast("mkldnn_status_t") int mkldnn_dilated_deconvolution_backward_data_desc_init(
        @Cast("mkldnn_deconvolution_desc_t*") mkldnn_convolution_desc_t conv_desc, @Cast("mkldnn_alg_kind_t") int alg_kind,
        @Const mkldnn_memory_desc_t diff_src_desc,
        @Const mkldnn_memory_desc_t weights_desc,
        @Const mkldnn_memory_desc_t diff_dst_desc, @Const IntPointer strides,
        @Const IntPointer dilates, @Const IntPointer padding_l,
        @Const IntPointer padding_r, @Cast("mkldnn_padding_kind_t") int padding_kind);
public static native @Cast("mkldnn_status_t") int mkldnn_dilated_deconvolution_backward_data_desc_init(
        @Cast("mkldnn_deconvolution_desc_t*") mkldnn_convolution_desc_t conv_desc, @Cast("mkldnn_alg_kind_t") int alg_kind,
        @Const mkldnn_memory_desc_t diff_src_desc,
        @Const mkldnn_memory_desc_t weights_desc,
        @Const mkldnn_memory_desc_t diff_dst_desc, @Const IntBuffer strides,
        @Const IntBuffer dilates, @Const IntBuffer padding_l,
        @Const IntBuffer padding_r, @Cast("mkldnn_padding_kind_t") int padding_kind);
public static native @Cast("mkldnn_status_t") int mkldnn_dilated_deconvolution_backward_data_desc_init(
        @Cast("mkldnn_deconvolution_desc_t*") mkldnn_convolution_desc_t conv_desc, @Cast("mkldnn_alg_kind_t") int alg_kind,
        @Const mkldnn_memory_desc_t diff_src_desc,
        @Const mkldnn_memory_desc_t weights_desc,
        @Const mkldnn_memory_desc_t diff_dst_desc, @Const int[] strides,
        @Const int[] dilates, @Const int[] padding_l,
        @Const int[] padding_r, @Cast("mkldnn_padding_kind_t") int padding_kind);

/** Initializes a deconvolution descriptor \p conv_desc for backward propagation
 * with respect to weights using \p alg_kind, memory descriptors, \p strides,
 * \p padding_l, \p padding_r, and \p padding_kind.
 *
 * \note memory descriptors are allowed to be initialized with #mkldnn_any
 * value of \p format_kind.
 *
 * Order of inputs:
 *  - src (#mkldnn_query_src_pd, 0)
 *  - diff_dst (#mkldnn_query_diff_dst_pd, 0)
 *
 * Order of outputs:
 *  - diff_weights (#mkldnn_query_diff_weights_pd, 0)
 *  - diff_bias (#mkldnn_query_diff_weights_pd, 1), if created with bias
 */
public static native @Cast("mkldnn_status_t") int mkldnn_deconvolution_backward_weights_desc_init(
        @Cast("mkldnn_deconvolution_desc_t*") mkldnn_convolution_desc_t conv_desc, @Cast("mkldnn_alg_kind_t") int alg_kind,
        @Const mkldnn_memory_desc_t src_desc,
        @Const mkldnn_memory_desc_t diff_weights_desc,
        @Const mkldnn_memory_desc_t diff_bias_desc,
        @Const mkldnn_memory_desc_t diff_dst_desc, @Const IntPointer strides,
        @Const IntPointer padding_l, @Const IntPointer padding_r,
        @Cast("mkldnn_padding_kind_t") int padding_kind);
public static native @Cast("mkldnn_status_t") int mkldnn_deconvolution_backward_weights_desc_init(
        @Cast("mkldnn_deconvolution_desc_t*") mkldnn_convolution_desc_t conv_desc, @Cast("mkldnn_alg_kind_t") int alg_kind,
        @Const mkldnn_memory_desc_t src_desc,
        @Const mkldnn_memory_desc_t diff_weights_desc,
        @Const mkldnn_memory_desc_t diff_bias_desc,
        @Const mkldnn_memory_desc_t diff_dst_desc, @Const IntBuffer strides,
        @Const IntBuffer padding_l, @Const IntBuffer padding_r,
        @Cast("mkldnn_padding_kind_t") int padding_kind);
public static native @Cast("mkldnn_status_t") int mkldnn_deconvolution_backward_weights_desc_init(
        @Cast("mkldnn_deconvolution_desc_t*") mkldnn_convolution_desc_t conv_desc, @Cast("mkldnn_alg_kind_t") int alg_kind,
        @Const mkldnn_memory_desc_t src_desc,
        @Const mkldnn_memory_desc_t diff_weights_desc,
        @Const mkldnn_memory_desc_t diff_bias_desc,
        @Const mkldnn_memory_desc_t diff_dst_desc, @Const int[] strides,
        @Const int[] padding_l, @Const int[] padding_r,
        @Cast("mkldnn_padding_kind_t") int padding_kind);

/** Initializes a dilated deconvolution descriptor \p conv_desc for backward
 * propagation with respect to weights using \p alg_kind, memory descriptors,
 * \p strides, \p dilates, \p padding_l, \p padding_r, and \p padding_kind.
 *
 * \note memory descriptors are allowed to be initialized with #mkldnn_any
 * value of \p format_kind.
 *
 * Order of inputs:
 *  - src (#mkldnn_query_src_pd, 0)
 *  - diff_dst (#mkldnn_query_diff_dst_pd, 0)
 *
 * Order of outputs:
 *  - diff_weights (#mkldnn_query_diff_weights_pd, 0)
 *  - diff_bias (#mkldnn_query_diff_weights_pd, 1), if created with bias
 */
public static native @Cast("mkldnn_status_t") int mkldnn_dilated_deconvolution_backward_weights_desc_init(
        @Cast("mkldnn_deconvolution_desc_t*") mkldnn_convolution_desc_t conv_desc, @Cast("mkldnn_alg_kind_t") int alg_kind,
        @Const mkldnn_memory_desc_t src_desc,
        @Const mkldnn_memory_desc_t diff_weights_desc,
        @Const mkldnn_memory_desc_t diff_bias_desc,
        @Const mkldnn_memory_desc_t diff_dst_desc, @Const IntPointer strides,
        @Const IntPointer dilates, @Const IntPointer padding_l,
        @Const IntPointer padding_r, @Cast("mkldnn_padding_kind_t") int padding_kind);
public static native @Cast("mkldnn_status_t") int mkldnn_dilated_deconvolution_backward_weights_desc_init(
        @Cast("mkldnn_deconvolution_desc_t*") mkldnn_convolution_desc_t conv_desc, @Cast("mkldnn_alg_kind_t") int alg_kind,
        @Const mkldnn_memory_desc_t src_desc,
        @Const mkldnn_memory_desc_t diff_weights_desc,
        @Const mkldnn_memory_desc_t diff_bias_desc,
        @Const mkldnn_memory_desc_t diff_dst_desc, @Const IntBuffer strides,
        @Const IntBuffer dilates, @Const IntBuffer padding_l,
        @Const IntBuffer padding_r, @Cast("mkldnn_padding_kind_t") int padding_kind);
public static native @Cast("mkldnn_status_t") int mkldnn_dilated_deconvolution_backward_weights_desc_init(
        @Cast("mkldnn_deconvolution_desc_t*") mkldnn_convolution_desc_t conv_desc, @Cast("mkldnn_alg_kind_t") int alg_kind,
        @Const mkldnn_memory_desc_t src_desc,
        @Const mkldnn_memory_desc_t diff_weights_desc,
        @Const mkldnn_memory_desc_t diff_bias_desc,
        @Const mkldnn_memory_desc_t diff_dst_desc, @Const int[] strides,
        @Const int[] dilates, @Const int[] padding_l,
        @Const int[] padding_r, @Cast("mkldnn_padding_kind_t") int padding_kind);

/** \} */

/** \addtogroup c_api_shuffle Shuffle
 * A primitive to shuffle data along the axis.
 * \{ */

/** Initializes a \p shuffle_desc for forward propagation using \p prop_kind,
 * \p memory descriptor \p data_desc, \p axis and \p group
 * number.
 *
 * Order of inputs:
 *  - src (#mkldnn_query_src_pd, 0)
 *
 * Order of outputs:
 *  - dst (#mkldnn_query_dst_pd, 0)
 *
 */
public static native @Cast("mkldnn_status_t") int mkldnn_shuffle_forward_desc_init(
        mkldnn_shuffle_desc_t shuffle_desc, @Cast("mkldnn_prop_kind_t") int prop_kind,
        @Const mkldnn_memory_desc_t data_desc, int axis, int group_size);

/** Initializes a \p shuffle_desc for backward propagation using \p memory
 * descriptor \p diff_data_desc, \p axis and \p group number.
 *
 *
 * Order of inputs:
 *  - diff_dst (#mkldnn_query_diff_dst_pd, 0)
 *
 * Order of outputs:
 *  - diff_src (#mkldnn_query_diff_src_pd, 0)
 *
 */
public static native @Cast("mkldnn_status_t") int mkldnn_shuffle_backward_desc_init(
        mkldnn_shuffle_desc_t shuffle_desc,
        @Const mkldnn_memory_desc_t diff_data_desc, int axis, int group_size);

/** \} */

/** \addtogroup c_api_eltwise Eltwise
 * A primitive to compute element wise operations like parametric rectifier
 * linear unit (ReLU).
 *
 * Both forward and backward passes support in-place operation, i.e. src
 * and dst point to the same memory for forward, and diff_dst and diff_src
 * point to the same memory for backward pass.
 *
 * \warning Since for backward pass original src is required, in-place forward
 * pass in general cannot be applied during training. However for some kinds of
 * element wise operations (namely ReLU with alpha parameter equals 0) dst and
 * src can be interchangeable for the backward pass, which allows performing
 * in-place forward even for training.
 *
 * \{ */

/** Initializes a \p eltwise_desc for forward propagation using \p prop_kind
 * (possible values are #mkldnn_forward_training or #mkldnn_forward_inference),
 * \p alg_kind algorithm, memory descriptor \p data_desc, and \p alpha,
 * \p beta parameters.
 *
 * \sa mkldnn_eltwise_desc_t for details
 *
 * Order of inputs:
 *  - src (#mkldnn_query_src_pd, 0)
 *
 * Order of outputs:
 *  - dst (#mkldnn_query_dst_pd, 0)
 */
public static native @Cast("mkldnn_status_t") int mkldnn_eltwise_forward_desc_init(
        mkldnn_eltwise_desc_t eltwise_desc, @Cast("mkldnn_prop_kind_t") int prop_kind,
        @Cast("mkldnn_alg_kind_t") int alg_kind, @Const mkldnn_memory_desc_t data_desc,
        float alpha, float beta);

/** Initializes a \p eltwise_desc for backward propagation using \p alg_kind
 * algorithm memory descriptors \p diff_data_desc and \p data_desc, and
 * \p alpha, \p beta parameters.
 *
 * \sa mkldnn_eltwise_desc_t for details
 *
 * Order of inputs:
 *  - src (#mkldnn_query_src_pd, 0)
 *  - diff_dst (#mkldnn_query_diff_dst_pd, 0)
 *
 * Order of outputs:
 *  - diff_src (#mkldnn_query_diff_src_pd, 0)
 */
public static native @Cast("mkldnn_status_t") int mkldnn_eltwise_backward_desc_init(
        mkldnn_eltwise_desc_t eltwise_desc, @Cast("mkldnn_alg_kind_t") int alg_kind,
        @Const mkldnn_memory_desc_t diff_data_desc,
        @Const mkldnn_memory_desc_t data_desc, float alpha, float beta);

/** \} */

/** \addtogroup c_api_relu ReLU (deprecated, use Eltwise instead)
 * A primitive to compute a parametric rectifier linear unit (ReLU).
 *
 * \f[dst[n][c][h][w] = \max(src[n][c][h][w], 0) +
 *                      \min(src[n][c][h][w], 0) \cdot negative\_slope\f]
 * \{ */

/** Initializes a \p relu_desc for forward propagation using \p prop_kind
 * (possible values are #mkldnn_forward_training or #mkldnn_forward_inference),
 * \p negative_slope and memory descriptor \p data_desc.
 *
 * @deprecated use mkldnn_eltwise_forward_desc_init() instead, with \p alpha
 * equals \p negative_slope
 *
 * Order of inputs:
 *  - src (#mkldnn_query_src_pd, 0)
 *
 * Order of outputs:
 *  - dst (#mkldnn_query_dst_pd, 0)
 */
public static native @Cast("mkldnn_status_t") @Deprecated int mkldnn_relu_forward_desc_init(
        @Cast("mkldnn_relu_desc_t*") mkldnn_eltwise_desc_t relu_desc, @Cast("mkldnn_prop_kind_t") int prop_kind,
        @Const mkldnn_memory_desc_t data_desc, float negative_slope);

/** Initializes a \p relu_desc for backward propagation using \p negative_slope
 * and memory descriptors \p diff_data_desc and \p data_desc.
 *
 * @deprecated use mkldnn_eltwise_backward_desc_init() instead, with \p alpha
 * equals \p negative_slope
 *
 * Order of inputs:
 *  - src (#mkldnn_query_src_pd, 0)
 *  - diff_dst (#mkldnn_query_diff_dst_pd, 0)
 *
 * Order of outputs:
 *  - diff_src (#mkldnn_query_diff_src_pd, 0)
 */
public static native @Cast("mkldnn_status_t") @Deprecated int mkldnn_relu_backward_desc_init(
        @Cast("mkldnn_relu_desc_t*") mkldnn_eltwise_desc_t relu_desc,
        @Const mkldnn_memory_desc_t diff_data_desc,
        @Const mkldnn_memory_desc_t data_desc, float negative_slope);

/** \} */

/** \addtogroup c_api_softmax Softmax
 * A primitive to perform softmax.
 *
 * \f[dst[u][c][in] =
 *    \frac{\exp(src[ou][c][in]) - \max\limits_{c}(src[ou][c][in])}
 *    {\sum\limits_{c}\{\exp(src[ou][c][in])
 *    - \max\limits_{c}(src[ou][c][in])\}},\f]
 *
 * where \f$ou, iu\f$ are outer and inner sizes repectively, defined
 * by \p data_desc.dims and \p softmax_axis.
 * \{ */

/** Initializes a \p softmax_desc for forward propagation using \p prop_kind
 * (possible value are #mkldnn_forward_training or #mkldnn_forward_inference)
 * and memory descriptor \p data_desc.
 *
 * Order of inputs:
 *  - src (#mkldnn_query_src_pd, 0)
 *
 * Order of outputs:
 *  - dst (#mkldnn_query_dst_pd, 0)
 */
public static native @Cast("mkldnn_status_t") int mkldnn_softmax_forward_desc_init(
        mkldnn_softmax_desc_t softmax_desc, @Cast("mkldnn_prop_kind_t") int prop_kind,
        @Const mkldnn_memory_desc_t data_desc, int softmax_axis);

/** Initializes a \p softmax_desc for backward propagation using memory
 * descriptors \p diff_desc and \p data_desc.
 *
 * Order of inputs:
 *  - dst (#mkldnn_query_dst_pd, 0)
 *  - diff_dst (#mkldnn_query_diff_dst_pd, 0)
 *
 * Order of outputs:
 *  - diff_src (#mkldnn_query_diff_src_pd, 0)
 */
public static native @Cast("mkldnn_status_t") int mkldnn_softmax_backward_desc_init(
        mkldnn_softmax_desc_t softmax_desc,
        @Const mkldnn_memory_desc_t diff_desc,
        @Const mkldnn_memory_desc_t data_desc, int softmax_axis);

/** \} */

/** \addtogroup c_api_pooling Pooling
 * A primitive to perform max or average pooling.
 *
 * Max pooling:
 * \f[dst[n][oc][oh][ow] =
 *     \max\limits_{kw,kh}
 *     (src[n][ic][oh \cdot s_h - p_l[0] + kh][ow \cdot s_w - p_r[1] + kw]),\f]
 *
 * Average pooling:
 * \f[dst[n][oc][oh][ow] =
 *     \frac{1}{KW \cdot KH}\sum\limits_{kw,kh}
 *     src[n][ic][oh \cdot s_h - p_l[0] + kh][ow \cdot s_w - p_r[1] + kw],\f]
 *
 * where \f$p_l, p_r\f$ are \p padding_l and \p padding_r
 * respectively and output spatial dimensions are calculated
 * similarly as done in convolution.
 *
 * During training max pooling requires workspace on forward
 * (#mkldnn_forward_training) and backward (#mkldnn_backward) passes to
 * save indices where maximum was found. Workspace layout is opaque and
 * the indices cannot be restored from it. However one can use backward
 * pooling to perform up-sampling (used in some detection topologies).
 *
 * \{ */

/** Initializes a pooling descriptor \p pool_desc for forward propagation using
 * \p prop_kind (possible values are #mkldnn_forward_training or
 * #mkldnn_forward_inference), \p alg_kind, memory descriptors, and pooling
 * parameters in spatial domain: \p strides, \p kernel sizes, \p padding_l, \p
 * padding_r, and \p padding_kind.
 *
 * \note if \p padding_r is \c NULL, the padding is supposed to be symmetric
 *
 * Order of inputs:
 *  - src (#mkldnn_query_src_pd, 0)
 *
 * Order of outputs:
 *  - dst (#mkldnn_query_dst_pd, 0)
 *  - workspace (#mkldnn_query_workspace_pd, 0),
 *      if \p alg_kind = #mkldnn_pooling_max and
 *      \p prop_kind = #mkldnn_forward_training
 */
public static native @Cast("mkldnn_status_t") int mkldnn_pooling_forward_desc_init(
        mkldnn_pooling_desc_t pool_desc, @Cast("mkldnn_prop_kind_t") int prop_kind,
        @Cast("mkldnn_alg_kind_t") int alg_kind, @Const mkldnn_memory_desc_t src_desc,
        @Const mkldnn_memory_desc_t dst_desc, @Const IntPointer strides,
        @Const IntPointer kernel, @Const IntPointer padding_l,
        @Const IntPointer padding_r, @Cast("mkldnn_padding_kind_t") int padding_kind);
public static native @Cast("mkldnn_status_t") int mkldnn_pooling_forward_desc_init(
        mkldnn_pooling_desc_t pool_desc, @Cast("mkldnn_prop_kind_t") int prop_kind,
        @Cast("mkldnn_alg_kind_t") int alg_kind, @Const mkldnn_memory_desc_t src_desc,
        @Const mkldnn_memory_desc_t dst_desc, @Const IntBuffer strides,
        @Const IntBuffer kernel, @Const IntBuffer padding_l,
        @Const IntBuffer padding_r, @Cast("mkldnn_padding_kind_t") int padding_kind);
public static native @Cast("mkldnn_status_t") int mkldnn_pooling_forward_desc_init(
        mkldnn_pooling_desc_t pool_desc, @Cast("mkldnn_prop_kind_t") int prop_kind,
        @Cast("mkldnn_alg_kind_t") int alg_kind, @Const mkldnn_memory_desc_t src_desc,
        @Const mkldnn_memory_desc_t dst_desc, @Const int[] strides,
        @Const int[] kernel, @Const int[] padding_l,
        @Const int[] padding_r, @Cast("mkldnn_padding_kind_t") int padding_kind);

/** Initializes a pooling descriptor \p pool_desc for backward propagation
 * using \p alg_kind, memory descriptors, and pooling parameters in spatial
 * domain: \p strides, \p kernel sizes, \p padding_l, \p padding_r, and \p
 * padding_kind.
 *
 * \note if \p padding_r is \c NULL, the padding is supposed to be symmetric
 *
 * Order of inputs:
 *  - diff_dst (#mkldnn_query_diff_dst_pd, 0)
 *  - workspace (#mkldnn_query_workspace_pd, 0),
 *      if \p alg_kind = #mkldnn_pooling_max
 *
 * Order of outputs:
 *  - diff_src (#mkldnn_query_diff_src_pd, 0)
 */
public static native @Cast("mkldnn_status_t") int mkldnn_pooling_backward_desc_init(
        mkldnn_pooling_desc_t pool_desc, @Cast("mkldnn_alg_kind_t") int alg_kind,
        @Const mkldnn_memory_desc_t diff_src_desc,
        @Const mkldnn_memory_desc_t diff_dst_desc, @Const IntPointer strides,
        @Const IntPointer kernel, @Const IntPointer padding_l,
        @Const IntPointer padding_r, @Cast("mkldnn_padding_kind_t") int padding_kind);
public static native @Cast("mkldnn_status_t") int mkldnn_pooling_backward_desc_init(
        mkldnn_pooling_desc_t pool_desc, @Cast("mkldnn_alg_kind_t") int alg_kind,
        @Const mkldnn_memory_desc_t diff_src_desc,
        @Const mkldnn_memory_desc_t diff_dst_desc, @Const IntBuffer strides,
        @Const IntBuffer kernel, @Const IntBuffer padding_l,
        @Const IntBuffer padding_r, @Cast("mkldnn_padding_kind_t") int padding_kind);
public static native @Cast("mkldnn_status_t") int mkldnn_pooling_backward_desc_init(
        mkldnn_pooling_desc_t pool_desc, @Cast("mkldnn_alg_kind_t") int alg_kind,
        @Const mkldnn_memory_desc_t diff_src_desc,
        @Const mkldnn_memory_desc_t diff_dst_desc, @Const int[] strides,
        @Const int[] kernel, @Const int[] padding_l,
        @Const int[] padding_r, @Cast("mkldnn_padding_kind_t") int padding_kind);

/** \} */

/** \addtogroup c_api_lrn LRN
 * A primitive to perform local response normalization (LRN) across or within
 * channels.
 *
 * LRN accross channels:
 * \f[dst[n][c][h][w] = \left\{k + \frac{\alpha}{n_{l}}
 *                      \sum\limits_{i=-(n_{l}-1)/2}^{(n_{l}+1)/2}
 *                      (src[n][c+i][h][w])^2\right\}^{-\beta}
 *                      src[n][c][h][w],\f]
 *
 * LRN within channels:
 * \f[dst[n][c][h][w] = \left\{k + \frac{\alpha}{n_{l}}
 *                      \sum\limits_{i=-(n_{l}-1)/2}^{(n_{l}+1)/2}
 *                      (src[n][c][h+i][w+i])^2\right\}^{-\beta}
 *                      src[n][c][h][w],\f]
 *
 * where \f$n_{l}\f$ is the \p local_size.
 *
 * During training LRN might or might not require workspace on forward
 * (#mkldnn_forward_training) and backward (#mkldnn_backward) passes. The
 * behavior is implementation specific. Optimized implementations typically
 * require workspace and use it to save some intermediate results from the
 * forward pass that accelerate computations on the backward pass.
 *
 * To check whether workspace is required one should query the LRN primitive
 * descriptor for the workspace (#mkldnn_query_workspace_pd). Success would
 * indicate the workspace is required and its description would be returned.
 * \sa mkldnn_primitive_desc_query and mkldnn_primitive_desc_query_pd
 *
 * \{ */

/** Initializes an \p lrn_desc for forward propagation using \p prop_kind
 * (possible values are #mkldnn_forward_training or #mkldnn_forward_inference),
 * \p alg_kind, memory descriptor \p data_desc, and regularization
 * parameters \p local_size, \p alpha, \p beta, and \p k.
 *
 * Order of inputs:
 *  - src (#mkldnn_query_src_pd, 0)
 *
 * Order of outputs:
 *  - dst (#mkldnn_query_dst_pd, 0)
 *  - workspace (#mkldnn_query_workspace_pd, 0),
 *      if the underlying implementation requires
 */
public static native @Cast("mkldnn_status_t") int mkldnn_lrn_forward_desc_init(
        mkldnn_lrn_desc_t lrn_desc, @Cast("mkldnn_prop_kind_t") int prop_kind,
        @Cast("mkldnn_alg_kind_t") int alg_kind, @Const mkldnn_memory_desc_t data_desc,
        int local_size, float alpha, float beta, float k);

/** Initializes an \p lrn_desc for backward propagation using \p alg_kind,
 * memory descriptors \p data_desc, and \p diff_data_desc, and regularization
 * parameters \p local_size, \p alpha, \p beta, and \p k.
 *
 * Order of inputs:
 *  - src (#mkldnn_query_src_pd, 0)
 *  - diff_dst (#mkldnn_query_diff_dst_pd, 0)
 *  - workspace (#mkldnn_query_workspace_pd, 0),
 *      if the underlying implementation requires
 *
 * Order of outputs:
 *  - diff_src (#mkldnn_query_diff_src_pd, 0)
 */
public static native @Cast("mkldnn_status_t") int mkldnn_lrn_backward_desc_init(
        mkldnn_lrn_desc_t lrn_desc, @Cast("mkldnn_alg_kind_t") int alg_kind,
        @Const mkldnn_memory_desc_t diff_data_desc,
        @Const mkldnn_memory_desc_t data_desc, int local_size, float alpha,
        float beta, float k);

/** \} */

/** \addtogroup c_api_batch_normalization Batch Normalization
 * A primitive to perform batch normalization.
 *
 * \f[dst[n][c][h][w] = \gamma[c] \frac{src[n][c][h][w] - \mu[c]}
 *                      {\sqrt{\sigma[c] + eps}} + \beta[c],\f]
 *
 * where \f$\gamma[c], \beta[c]\f$ are weights and bias for a channel and,
 *
 * \f$\mu[c] = \frac{1}{NHW} \sum\limits_{whn} src[n][c][h][w]\f$,
 * \f$\sigma[c] = \frac{1}{NHW} \sum\limits_{whn}
 *                              (src[n][c][h][w] - \mu[c])^2\f$,
 *
 * and eps is a constant to improve numerical stability.
 *
 * Both forward and backward passes support in-place operation, i.e. src
 * and dst point to the same memory for forward, and diff_dst and diff_src
 * point to the same memory for backward pass.
 *
 * Batch normalization supports different flavors controlled by
 * mkldnn_batch_normalization_desc_t. For example batch normalization can
 * compute the mean and variance on its own or can take them as inputs.
 * It can either perform scaling and shifting using gamma and beta parameters
 * or not. Optionally it can also perform a fused ReLU, which in case of
 * training would also require a workspace.
 *
 * \sa mkldnn_batch_normalization_desc_t
 * \{ */

/** Initializes a batch normalization descriptor \p bnrm_desc for forward
 * propagation using \p prop_kind, (possible values are
 * #mkldnn_forward_training or #mkldnn_forward_inference), memory descriptor
 * \p data_desc, normalization parameter \p epsilon and \p flags set using bit
 * flags of type mkldnn_batch_normalization_desc_t.
 *
 * Order of inputs:
 *  - src (#mkldnn_query_src_pd, 0)
 *  - mean (#mkldnn_query_src_pd, 1),
 *      if #mkldnn_use_global_stats bit-flags is set in \p flags
 *  - variance (#mkldnn_query_src_pd, 2),
 *      if #mkldnn_use_global_stats bit-flags is set in \p flags
 *  - scale_and_shift (#mkldnn_query_weights_pd, 0),
 *      if #mkldnn_use_scaleshift bit-flags is set in \p flags
 *
 * Order of outputs:
 *  - dst (#mkldnn_query_dst_pd, 0)
 *  - mean (#mkldnn_query_dst_pd, 1),
 *      if #mkldnn_use_global_stats bit-flags is not set in \p flags
 *      \p prop_kind = #mkldnn_forward_training
 *  - variance (#mkldnn_query_dst_pd, 2),
 *      if #mkldnn_use_global_stats bit-flags is not set in \p flags
 *      and \p prop_kind = #mkldnn_forward_training
 *  - workspace (#mkldnn_query_workspace_pd, 0),
 *      if #mkldnn_fuse_bn_relu bit-flags is set in \p flags
 *      and \p prop_kind = #mkldnn_forward_training
 *
 * \note in-place operation is supported,
 *       i.e. dst points to the same memory as src.
 *
 * \sa mkldnn_batch_normalization_desc_t
 */
public static native @Cast("mkldnn_status_t") int mkldnn_batch_normalization_forward_desc_init(
        mkldnn_batch_normalization_desc_t bnrm_desc,
        @Cast("mkldnn_prop_kind_t") int prop_kind, @Const mkldnn_memory_desc_t data_desc,
        float epsilon, @Cast("unsigned") int flags);

/** Initializes a batch normalization descriptor \p bnrm_desc for backward
 * propagation with respect to data and scale-shift parameters using memory
 * descriptors \p data_desc and \p diff_data_desc, and normalization parameter
 * \p epsilon and \p flags set using bit flags of type
 * mkldnn_batch_normalization_desc_t.
 *
 * Order of inputs:
 *  - src (#mkldnn_query_src_pd, 0)
 *  - mean (#mkldnn_query_src_pd, 1)
 *  - variance (#mkldnn_query_src_pd, 2)
 *  - diff_dst (#mkldnn_query_diff_dst_pd, 0)
 *  - scale_and_shift (#mkldnn_query_weights_pd, 0),
 *      if #mkldnn_use_scaleshift bit-flags is set in \p flags
 *  - workspace (#mkldnn_query_workspace_pd, 0),
 *      if #mkldnn_fuse_bn_relu bit-flags is set in \p flags
 *
 * Order of outputs:
 *  - diff_src (#mkldnn_query_diff_src_pd, 0)
 *  - diff_scale_and_shift (#mkldnn_query_diff_weights_pd, 0),
 *      if #mkldnn_use_scaleshift bit-flags is set in \p flags
 *      and \p prop_kind = #mkldnn_backward
 *
 * \note in-place operation is supported,
 *       i.e. diff_src points to the same memory as diff_dst.
 *
 * \sa mkldnn_batch_normalization_desc_t
 */
public static native @Cast("mkldnn_status_t") int mkldnn_batch_normalization_backward_desc_init(
        mkldnn_batch_normalization_desc_t bnrm_desc,
        @Cast("mkldnn_prop_kind_t") int prop_kind,
        @Const mkldnn_memory_desc_t diff_data_desc,
        @Const mkldnn_memory_desc_t data_desc,
        float epsilon, @Cast("unsigned") int flags);

/** \} */

/** \addtogroup c_api_inner_product Inner product
 * A primitive to compute an inner product.
 *
 * Inner product layer is also known as fully connected layer.
 * with spatial dimension:
 *
 * \f[dst[n][oc] = \sum\limits_{ic, kh, kw}
 *                 src[n][ic][kh][kw] \cdot weights[oc][ic][kh][kw]
 *                 + bias[oc]\f]
 * \{ */

/** Initializes an inner product descriptor \p ip_desc for forward propagation
 * using \p prop_kind (possible values are #mkldnn_forward_training or
 * #mkldnn_forward_inference) and memory descriptors. In order to create an
 * inner product without bias, \p bias_desc should be either \c NULL or a
 * pointer to descriptor with memory format equals to #mkldnn_format_undef.
 *
 * \note
 *     memory descriptors are allowed to be initialized with #mkldnn_any value
 *     of \p format_kind.
 *
 * Order of inputs:
 *  - src (#mkldnn_query_src_pd, 0)
 *  - weights (#mkldnn_query_weights_pd, 0)
 *  - bias (#mkldnn_query_weights_pd, 1), if created with bias
 *
 * Order of outputs:
 *  - dst (#mkldnn_query_dst_pd, 0)
 */
public static native @Cast("mkldnn_status_t") int mkldnn_inner_product_forward_desc_init(
        mkldnn_inner_product_desc_t ip_desc, @Cast("mkldnn_prop_kind_t") int prop_kind,
        @Const mkldnn_memory_desc_t src_desc,
        @Const mkldnn_memory_desc_t weights_desc,
        @Const mkldnn_memory_desc_t bias_desc,
        @Const mkldnn_memory_desc_t dst_desc);

/** Initializes an inner product descriptor \p ip_desc for backward propagation
 * with respect to data using memory descriptors.
 *
 * \note
 *     memory descriptors are allowed to be initialized with #mkldnn_any value
 *     of \p format_kind.
 *
 * Order of inputs:
 *  - diff_dst (#mkldnn_query_diff_dst_pd, 0)
 *  - weights (#mkldnn_query_weights_pd, 0)
 *
 * Order of outputs:
 *  - diff_src (#mkldnn_query_diff_src_pd, 0)
 */
public static native @Cast("mkldnn_status_t") int mkldnn_inner_product_backward_data_desc_init(
        mkldnn_inner_product_desc_t ip_desc,
        @Const mkldnn_memory_desc_t diff_src_desc,
        @Const mkldnn_memory_desc_t weights_desc,
        @Const mkldnn_memory_desc_t diff_dst_desc);

/** Initializes an inner product descriptor \p ip_desc for backward propagation
 * with respect to weights using memory descriptors.
 *
 * \note
 *     memory descriptors are allowed to be initialized with #mkldnn_any value
 *     of \p format_kind.
 *
 * Order of inputs:
 *  - src (#mkldnn_query_src_pd, 0)
 *  - diff_dst (#mkldnn_query_diff_dst_pd, 0)
 *
 * Order of outputs:
 *  - diff_weights (#mkldnn_query_diff_weights_pd, 0)
 *  - diff_bias (#mkldnn_query_diff_weights_pd, 1), if created with bias
 */
public static native @Cast("mkldnn_status_t") int mkldnn_inner_product_backward_weights_desc_init(
        mkldnn_inner_product_desc_t ip_desc,
        @Const mkldnn_memory_desc_t src_desc,
        @Const mkldnn_memory_desc_t diff_weights_desc,
        @Const mkldnn_memory_desc_t diff_bias_desc,
        @Const mkldnn_memory_desc_t diff_dst_desc);

/** \} */

/** \addtogroup c_api_convolution_relu Convolution followed by ReLU (deprecated)
 * A merged primitive to compute a convolution followed by relu.
 * \{ */

/** Initializes a merged convolution-relu descriptor \p conv_relu_desc for
 * forward propagation (supported inference mode only) using convolution
 * descriptor \p conv_desc and ReLU parameter \p negative slope.
 *
 * @deprecated use mkldnn_convolution_desc_init with
 * mkldnn_post_ops_append_eltwise to append ReLU
 *
 * Order of inputs:
 *  - src (#mkldnn_query_src_pd, 0)
 *  - weights (#mkldnn_query_weights_pd, 0)
 *  - bias (#mkldnn_query_weights_pd, 1),
 *      if convolution is created with bias
 *
 * Order of outputs:
 *  - dst (#mkldnn_query_dst_pd, 0)
 */
public static native @Cast("mkldnn_status_t") int mkldnn_convolution_relu_desc_init(
        mkldnn_convolution_relu_desc_t conv_relu_desc,
        @Const mkldnn_convolution_desc_t conv_desc, float negative_slope);

/** \} */

/** \addtogroup c_api_rnn RNN
 * A primitive to compute common recurrent layer.
 * \todo add additional description for the group
 * \{ */

/**
 * Initializes a recurrent cell descriptor \p rnn_cell_desc
 * using \p rnn_cell_desc, \p kind (possible values are
 *  #mkldnn_vanilla_rnn, #mkldnn_vanilla_lstm, #mkldnn_vanilla_gru,
 *  #mkldnn_gru_linear_before_reset),
 *  \p f (possible values are #mkldnn_eltwise_relu,
 *   #mkldnn_eltwise_tanh), \p flags, \p alpha, and \p clipping.
 */
public static native @Cast("mkldnn_status_t") int mkldnn_rnn_cell_desc_init(
        mkldnn_rnn_cell_desc_t rnn_cell_desc,
        @Cast("mkldnn_alg_kind_t") int kind, @Cast("mkldnn_alg_kind_t") int f,
        @Cast("unsigned int") int flags, float alpha, float clipping);

/** Returns the number of gates of a particular \p rnn_cell_desc. */
public static native int mkldnn_rnn_cell_get_gates_count(
        @Const mkldnn_rnn_cell_desc_t rnn_cell_desc);

/** Returns the number of states of a particular \p rnn_cell_desc. */
public static native int mkldnn_rnn_cell_get_states_count(
        @Const mkldnn_rnn_cell_desc_t rnn_cell_desc);

/** Initializes a rnn descriptor \p rnn_desc for forward propagation
 * using \p prop_kind, \p rnn_cell_desc, \p direction, and memory descriptors.
 * \note if \p prop_kind equals #mkldnn_forward_training, you need to query a
 * workspace memory descriptor before creating the primitive.
 *
 * \p src_iter_desc, \p bias_desc, and \p dst_iter_desc are allowed to be
 * either NULL or point to a zero memory descriptor that would indicate
 * RNN primitive should not use them.
 *
 * \note all memory descriptors except \p src_iter_desc are allowed to be
 * initialized with #mkldnn_any value of \p format_kind.
 *
 * Order of inputs:
 *  - src_layer (#mkldnn_query_src_pd, 0)
 *  - src_iter (#mkldnn_query_src_pd, 1), if used
 *  - weights_layer (#mkldnn_query_weights_pd, 0)
 *  - weights_iter (#mkldnn_query_weights_pd, 1)
 *  - bias (#mkldnn_query_weights_pd, 2), if used
 *
 * Order of outputs:
 *  - dst_layer (#mkldnn_query_dst_pd, 0)
 *  - dst_iter (#mkldnn_query_dst_pd, 1), if used
 *  - workspace (#mkldnn_query_workspace_pd, 0),
 *      if \p prop_kind equals #mkldnn_forward_training
 */
public static native @Cast("mkldnn_status_t") int mkldnn_rnn_forward_desc_init(
        mkldnn_rnn_desc_t rnn_desc, @Cast("mkldnn_prop_kind_t") int prop_kind,
        @Const mkldnn_rnn_cell_desc_t rnn_cell_desc,
        @Cast("const mkldnn_rnn_direction_t") int direction,
        @Const mkldnn_memory_desc_t src_layer_desc,
        @Const mkldnn_memory_desc_t src_iter_desc,
        @Const mkldnn_memory_desc_t weights_layer_desc,
        @Const mkldnn_memory_desc_t weights_iter_desc,
        @Const mkldnn_memory_desc_t bias_desc,
        @Const mkldnn_memory_desc_t dst_layer_desc,
        @Const mkldnn_memory_desc_t dst_iter_desc);

/** Initializes a rnn descriptor \p rnn_desc for backward propagation
 * using \p prop_kind, \p rnn_cell_desc, \p direction, and memory descriptors.
 * \note all memory descriptors are allowed to be initialized with
 * #mkldnn_any value of \p format_kind.
 *
 * \p src_iter_desc (simultaneously with \p diff_src_iter_desc),
 * \p bias_desc (simultaneously with \p diff_bias_desc), and
 * \p dst_iter_desc (simultaneously with \p diff_src_iter_desc) are allowed
 * to be either NULL or point to a zero memory descriptor that would indicate
 * RNN primitive should not use them.
 *
 * Order of inputs:
 *  - src_layer (#mkldnn_query_src_pd, 0)
 *  - src_iter (#mkldnn_query_src_pd, 1), if used
 *  - weights_layer (#mkldnn_query_weights_pd, 0)
 *  - weights_iter (#mkldnn_query_weights_pd, 1)
 *  - bias (#mkldnn_query_weights_pd, 2), if used
 *  - dst_layer (#mkldnn_query_dst_pd, 0)
 *  - dst_iter (#mkldnn_query_dst_pd, 1), if used
 *  - diff_dst_layer (#mkldnn_query_diff_dst_pd, 0)
 *  - diff_dst_iter (#mkldnn_query_diff_dst_pd, 1), if used
 *  - workspace (#mkldnn_query_workspace_pd, 0)
 *
 * Order of outputs:
 *  - diff_src_layer (#mkldnn_query_diff_src_pd, 0)
 *  - diff_src_iter (#mkldnn_query_diff_src_pd, 1), if used
 *  - diff_weights_layer (#mkldnn_query_diff_weights_pd, 0)
 *  - diff_weights_iter (#mkldnn_query_diff_weights_pd, 1)
 *  - diff_bias (#mkldnn_query_diff_weights_pd, 2), if used
 */
public static native @Cast("mkldnn_status_t") int mkldnn_rnn_backward_desc_init(
        mkldnn_rnn_desc_t rnn_desc, @Cast("mkldnn_prop_kind_t") int prop_kind,
        @Const mkldnn_rnn_cell_desc_t rnn_cell_desc,
        @Cast("const mkldnn_rnn_direction_t") int direction,
        @Const mkldnn_memory_desc_t src_layer_desc,
        @Const mkldnn_memory_desc_t src_iter_desc,
        @Const mkldnn_memory_desc_t weights_layer_desc,
        @Const mkldnn_memory_desc_t weights_iter_desc,
        @Const mkldnn_memory_desc_t bias_desc,
        @Const mkldnn_memory_desc_t dst_layer_desc,
        @Const mkldnn_memory_desc_t dst_iter_desc,
        @Const mkldnn_memory_desc_t diff_src_layer_desc,
        @Const mkldnn_memory_desc_t diff_src_iter_desc,
        @Const mkldnn_memory_desc_t diff_weights_layer_desc,
        @Const mkldnn_memory_desc_t diff_weights_iter_desc,
        @Const mkldnn_memory_desc_t diff_bias_desc,
        @Const mkldnn_memory_desc_t diff_dst_layer,
        @Const mkldnn_memory_desc_t diff_dst_iter_desc);

/** \} */

/** \} */

/** \addtogroup c_api_engine Engine operations
 * \{ */

/** Returns the number of engines of a particular \p kind. */
public static native @Cast("size_t") long mkldnn_engine_get_count(@Cast("mkldnn_engine_kind_t") int kind);

/** Creates an \p engine of particular \p kind and \p index. */
public static native @Cast("mkldnn_status_t") int mkldnn_engine_create(@ByPtrPtr mkldnn_engine engine,
        @Cast("mkldnn_engine_kind_t") int kind, @Cast("size_t") long index);
public static native @Cast("mkldnn_status_t") int mkldnn_engine_create(@Cast("mkldnn_engine_t*") PointerPointer engine,
        @Cast("mkldnn_engine_kind_t") int kind, @Cast("size_t") long index);

/** Returns the kind of an \p engine. */
public static native @Cast("mkldnn_status_t") int mkldnn_engine_get_kind(mkldnn_engine engine,
        @Cast("mkldnn_engine_kind_t*") IntPointer kind);
public static native @Cast("mkldnn_status_t") int mkldnn_engine_get_kind(mkldnn_engine engine,
        @Cast("mkldnn_engine_kind_t*") IntBuffer kind);
public static native @Cast("mkldnn_status_t") int mkldnn_engine_get_kind(mkldnn_engine engine,
        @Cast("mkldnn_engine_kind_t*") int[] kind);

/** Destroys an \p engine. */
public static native @Cast("mkldnn_status_t") int mkldnn_engine_destroy(mkldnn_engine engine);

/** \} */

/** \addtogroup c_api_stream Execution stream operations
 * \{ */

/** Creates an execution \p stream of \p stream_kind. */
public static native @Cast("mkldnn_status_t") int mkldnn_stream_create(@ByPtrPtr mkldnn_stream stream,
        @Cast("mkldnn_stream_kind_t") int stream_kind);
public static native @Cast("mkldnn_status_t") int mkldnn_stream_create(@Cast("mkldnn_stream_t*") PointerPointer stream,
        @Cast("mkldnn_stream_kind_t") int stream_kind);

/** Submits \p primitives to an execution \p stream. The number of primitives
 * is \p n.  All or none of the primitives can be lazy. In case of an error,
 * returns the offending \p error_primitive if it is not \c NULL. */
public static native @Cast("mkldnn_status_t") int mkldnn_stream_submit(mkldnn_stream stream,
        @Cast("size_t") long n, @ByPtrPtr mkldnn_primitive primitives,
        @ByPtrPtr mkldnn_primitive error_primitive);
public static native @Cast("mkldnn_status_t") int mkldnn_stream_submit(mkldnn_stream stream,
        @Cast("size_t") long n, @Cast("mkldnn_primitive_t*") PointerPointer primitives,
        @Cast("mkldnn_primitive_t*") PointerPointer error_primitive);

/** Waits for all primitives in the execution \p stream to finish. Returns
 * immediately if \p block is zero. In case of an error, returns
 * the offending \p error_primitive if it is not \c NULL. */
public static native @Cast("mkldnn_status_t") int mkldnn_stream_wait(mkldnn_stream stream,
        int block, @ByPtrPtr mkldnn_primitive error_primitive);
public static native @Cast("mkldnn_status_t") int mkldnn_stream_wait(mkldnn_stream stream,
        int block, @Cast("mkldnn_primitive_t*") PointerPointer error_primitive);

/** Reruns all the primitives within the \p stream. In case of an error,
 * returns the offending \p error_primitive if it is not \c NULL. */
public static native @Cast("mkldnn_status_t") int mkldnn_stream_rerun(mkldnn_stream stream,
        @ByPtrPtr mkldnn_primitive error_primitive);
public static native @Cast("mkldnn_status_t") int mkldnn_stream_rerun(mkldnn_stream stream,
        @Cast("mkldnn_primitive_t*") PointerPointer error_primitive);

/** Destroys an execution \p stream. */
public static native @Cast("mkldnn_status_t") int mkldnn_stream_destroy(mkldnn_stream stream);

/** \} */

/** \addtogroup c_api_service Service functions
 * \{ */

/** Sets verbosity level (print information to stdout).
 * Possible levels are:
 *  - 0 -- no verbose output
 *  - 1 -- primitive information at execution
 *  - 2 -- primitive information at creation and execution
 *
 * \note
 *     Dumping information might affect performance */
public static native @Cast("mkldnn_status_t") int mkldnn_verbose_set(int level);

/** \} */

/** \addtogroup c_api_blas BLAS functions
 * \{ */

/** SGEMM performs matrix-matrix multiplication operation
 * C := alpha*op( A )*op( B ) + beta*C,
 * where  op( X ) is one of
 * op( X ) = X or op( X ) = X**T,
 * alpha and beta are scalars, and A, B and C are matrices, with op( A )
 * an m by k matrix, op( B ) a k by n matrix and C an m by n matrix.
 * \note
 *      API is different compared to standard BLAS routine
 *      as it returns mkldnn_status_t for error handling.
 *      XERBLA is not supported: no error message will be printed
 *      in case of incorrect parameters */
public static native @Cast("mkldnn_status_t") int mkldnn_sgemm(@Cast("const char*") BytePointer transa, @Cast("const char*") BytePointer transb,
        @Const IntPointer M, @Const IntPointer N, @Const IntPointer K,
        @Const FloatPointer alpha, @Const FloatPointer A, @Const IntPointer lda,
        @Const FloatPointer B, @Const IntPointer ldb,
        @Const FloatPointer beta, FloatPointer C, @Const IntPointer ldc);
public static native @Cast("mkldnn_status_t") int mkldnn_sgemm(String transa, String transb,
        @Const IntBuffer M, @Const IntBuffer N, @Const IntBuffer K,
        @Const FloatBuffer alpha, @Const FloatBuffer A, @Const IntBuffer lda,
        @Const FloatBuffer B, @Const IntBuffer ldb,
        @Const FloatBuffer beta, FloatBuffer C, @Const IntBuffer ldc);
public static native @Cast("mkldnn_status_t") int mkldnn_sgemm(@Cast("const char*") BytePointer transa, @Cast("const char*") BytePointer transb,
        @Const int[] M, @Const int[] N, @Const int[] K,
        @Const float[] alpha, @Const float[] A, @Const int[] lda,
        @Const float[] B, @Const int[] ldb,
        @Const float[] beta, float[] C, @Const int[] ldc);
public static native @Cast("mkldnn_status_t") int mkldnn_sgemm(String transa, String transb,
        @Const IntPointer M, @Const IntPointer N, @Const IntPointer K,
        @Const FloatPointer alpha, @Const FloatPointer A, @Const IntPointer lda,
        @Const FloatPointer B, @Const IntPointer ldb,
        @Const FloatPointer beta, FloatPointer C, @Const IntPointer ldc);
public static native @Cast("mkldnn_status_t") int mkldnn_sgemm(@Cast("const char*") BytePointer transa, @Cast("const char*") BytePointer transb,
        @Const IntBuffer M, @Const IntBuffer N, @Const IntBuffer K,
        @Const FloatBuffer alpha, @Const FloatBuffer A, @Const IntBuffer lda,
        @Const FloatBuffer B, @Const IntBuffer ldb,
        @Const FloatBuffer beta, FloatBuffer C, @Const IntBuffer ldc);
public static native @Cast("mkldnn_status_t") int mkldnn_sgemm(String transa, String transb,
        @Const int[] M, @Const int[] N, @Const int[] K,
        @Const float[] alpha, @Const float[] A, @Const int[] lda,
        @Const float[] B, @Const int[] ldb,
        @Const float[] beta, float[] C, @Const int[] ldc);

/** gemm_s8u8s32 and gemm_s8s8s32 perform matrix-matrix multiplication operation
 * and add the result to a scalar-matrix product. To get the final result,
 * a vector is added to each row or column of the output matrix.
 * The operation is defined as:
 * C := alpha*(op(A) + A_offset) * (op(B) + B_offset) + beta*C + C_offset
 * where op( X ) = X or op( X ) = X**T,
 * A_offset is an m-by-k matrix with every element equal to the value oa,
 * B_offset is an k-by-n matrix with every element equal to the value ob,
 * C_offset is an m-by-n matrix defined by the oc array, size len:
 * if offsetc = F: len must be at least 1
 * if offsetc = C: len must be at least max(1, m)
 * if offsetc = R: len must be at least max(1, n)
 * alpha and beta are scalars, and A, B and C are matrices, with op( A )
 * an m-by-k matrix, op( B ) a k-by-n matrix and C an m-by-n matrix.
 * \note
 *      API is different compared to standard BLAS routine
 *      as it returns mkldnn_status_t for error handling.
 *      XERBLA is not supported: no error message will be printed
 *      in case of incorrect parameters */
public static native @Cast("mkldnn_status_t") int mkldnn_gemm_s8u8s32(@Cast("const char*") BytePointer transa,
        @Cast("const char*") BytePointer transb, @Cast("const char*") BytePointer offsetc, @Const IntPointer M, @Const IntPointer N,
        @Const IntPointer K, @Const FloatPointer alpha, @Const BytePointer A, @Const IntPointer lda,
        @Const BytePointer ao, @Cast("const uint8_t*") BytePointer B, @Const IntPointer ldb, @Const BytePointer bo,
        @Const FloatPointer beta, IntPointer c, @Const IntPointer ldc, @Const IntPointer co);
public static native @Cast("mkldnn_status_t") int mkldnn_gemm_s8u8s32(String transa,
        String transb, String offsetc, @Const IntBuffer M, @Const IntBuffer N,
        @Const IntBuffer K, @Const FloatBuffer alpha, @Const ByteBuffer A, @Const IntBuffer lda,
        @Const ByteBuffer ao, @Cast("const uint8_t*") ByteBuffer B, @Const IntBuffer ldb, @Const ByteBuffer bo,
        @Const FloatBuffer beta, IntBuffer c, @Const IntBuffer ldc, @Const IntBuffer co);
public static native @Cast("mkldnn_status_t") int mkldnn_gemm_s8u8s32(@Cast("const char*") BytePointer transa,
        @Cast("const char*") BytePointer transb, @Cast("const char*") BytePointer offsetc, @Const int[] M, @Const int[] N,
        @Const int[] K, @Const float[] alpha, @Const byte[] A, @Const int[] lda,
        @Const byte[] ao, @Cast("const uint8_t*") byte[] B, @Const int[] ldb, @Const byte[] bo,
        @Const float[] beta, int[] c, @Const int[] ldc, @Const int[] co);
public static native @Cast("mkldnn_status_t") int mkldnn_gemm_s8u8s32(String transa,
        String transb, String offsetc, @Const IntPointer M, @Const IntPointer N,
        @Const IntPointer K, @Const FloatPointer alpha, @Const BytePointer A, @Const IntPointer lda,
        @Const BytePointer ao, @Cast("const uint8_t*") BytePointer B, @Const IntPointer ldb, @Const BytePointer bo,
        @Const FloatPointer beta, IntPointer c, @Const IntPointer ldc, @Const IntPointer co);
public static native @Cast("mkldnn_status_t") int mkldnn_gemm_s8u8s32(@Cast("const char*") BytePointer transa,
        @Cast("const char*") BytePointer transb, @Cast("const char*") BytePointer offsetc, @Const IntBuffer M, @Const IntBuffer N,
        @Const IntBuffer K, @Const FloatBuffer alpha, @Const ByteBuffer A, @Const IntBuffer lda,
        @Const ByteBuffer ao, @Cast("const uint8_t*") ByteBuffer B, @Const IntBuffer ldb, @Const ByteBuffer bo,
        @Const FloatBuffer beta, IntBuffer c, @Const IntBuffer ldc, @Const IntBuffer co);
public static native @Cast("mkldnn_status_t") int mkldnn_gemm_s8u8s32(String transa,
        String transb, String offsetc, @Const int[] M, @Const int[] N,
        @Const int[] K, @Const float[] alpha, @Const byte[] A, @Const int[] lda,
        @Const byte[] ao, @Cast("const uint8_t*") byte[] B, @Const int[] ldb, @Const byte[] bo,
        @Const float[] beta, int[] c, @Const int[] ldc, @Const int[] co);

public static native @Cast("mkldnn_status_t") int mkldnn_gemm_s8s8s32(@Cast("const char*") BytePointer transa,
        @Cast("const char*") BytePointer transb, @Cast("const char*") BytePointer offsetc, @Const IntPointer M, @Const IntPointer N,
        @Const IntPointer K, @Const FloatPointer alpha, @Const BytePointer A, @Const IntPointer lda,
        @Const BytePointer ao, @Const BytePointer B, @Const IntPointer ldb, @Const BytePointer bo,
        @Const FloatPointer beta, IntPointer c, @Const IntPointer ldc, @Const IntPointer co);
public static native @Cast("mkldnn_status_t") int mkldnn_gemm_s8s8s32(String transa,
        String transb, String offsetc, @Const IntBuffer M, @Const IntBuffer N,
        @Const IntBuffer K, @Const FloatBuffer alpha, @Const ByteBuffer A, @Const IntBuffer lda,
        @Const ByteBuffer ao, @Const ByteBuffer B, @Const IntBuffer ldb, @Const ByteBuffer bo,
        @Const FloatBuffer beta, IntBuffer c, @Const IntBuffer ldc, @Const IntBuffer co);
public static native @Cast("mkldnn_status_t") int mkldnn_gemm_s8s8s32(@Cast("const char*") BytePointer transa,
        @Cast("const char*") BytePointer transb, @Cast("const char*") BytePointer offsetc, @Const int[] M, @Const int[] N,
        @Const int[] K, @Const float[] alpha, @Const byte[] A, @Const int[] lda,
        @Const byte[] ao, @Const byte[] B, @Const int[] ldb, @Const byte[] bo,
        @Const float[] beta, int[] c, @Const int[] ldc, @Const int[] co);
public static native @Cast("mkldnn_status_t") int mkldnn_gemm_s8s8s32(String transa,
        String transb, String offsetc, @Const IntPointer M, @Const IntPointer N,
        @Const IntPointer K, @Const FloatPointer alpha, @Const BytePointer A, @Const IntPointer lda,
        @Const BytePointer ao, @Const BytePointer B, @Const IntPointer ldb, @Const BytePointer bo,
        @Const FloatPointer beta, IntPointer c, @Const IntPointer ldc, @Const IntPointer co);
public static native @Cast("mkldnn_status_t") int mkldnn_gemm_s8s8s32(@Cast("const char*") BytePointer transa,
        @Cast("const char*") BytePointer transb, @Cast("const char*") BytePointer offsetc, @Const IntBuffer M, @Const IntBuffer N,
        @Const IntBuffer K, @Const FloatBuffer alpha, @Const ByteBuffer A, @Const IntBuffer lda,
        @Const ByteBuffer ao, @Const ByteBuffer B, @Const IntBuffer ldb, @Const ByteBuffer bo,
        @Const FloatBuffer beta, IntBuffer c, @Const IntBuffer ldc, @Const IntBuffer co);
public static native @Cast("mkldnn_status_t") int mkldnn_gemm_s8s8s32(String transa,
        String transb, String offsetc, @Const int[] M, @Const int[] N,
        @Const int[] K, @Const float[] alpha, @Const byte[] A, @Const int[] lda,
        @Const byte[] ao, @Const byte[] B, @Const int[] ldb, @Const byte[] bo,
        @Const float[] beta, int[] c, @Const int[] ldc, @Const int[] co);
/** \} */

/** \} */

// #ifdef __cplusplus
// #endif

// #endif


// Parsed from mkldnn.hpp

/*******************************************************************************
* Copyright 2016-2018 Intel Corporation
*
* Licensed under the Apache License, Version 2.0 (the "License");
* you may not use this file except in compliance with the License.
* You may obtain a copy of the License at
*
*     http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
* See the License for the specific language governing permissions and
* limitations under the License.
*******************************************************************************/

// #ifndef MKLDNN_HPP
// #define MKLDNN_HPP

// #ifndef DOXYGEN_SHOULD_SKIP_THIS
// #endif

/** \addtogroup cpp_api C++ API
 *  \{
 <p>
 *  \addtogroup cpp_api_utils Utils
 *  \{
 <p>
 *  A class that provides the destructor for an Intel(R) MKL-DNN C handle */

/** A class for wrapping an Intel(R) MKL-DNN handle. It is used as the base
 *  class for primitive (#mkldnn_primitive_t), engine (#mkldnn_engine_t), and
 *  stream (#mkldnn_stream_t) handles. An object of the #mkldnn::handle class
 *  can be passed by value. This class enables wrapping:
 *   - Newly constructed handles.
 *     \n In this case, the constructed handle uses reference counting provided
 *     by \p std::shared_ptr with a proper deleter function specified through
 *     the \p handle_traits class.
 *   - Pre-existing handles returned by the Intel(R) MKL-DNN C API (for
 *     example, through #mkldnn_primitive_get_output()).
 *     \n In this case, an Intel(R) MKL-DNN C API handle is wrapped without a
 *     deleter because it is assumed that the handle wrapper for the original
 *     object deletes the handle (this model is similar to \p std::weak_ptr). */
@Name("mkldnn::handle<mkldnn_engine_t>") @NoOffset public static class mkldnn_engine_handle extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public mkldnn_engine_handle(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public mkldnn_engine_handle(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public mkldnn_engine_handle position(long position) {
        return (mkldnn_engine_handle)super.position(position);
    }

    /** Constructs a C handle wrapper.
     *  @param t The C handle to wrap.
     *  @param weak A flag to specify whether to construct a weak wrapper. */
    public mkldnn_engine_handle(mkldnn_engine t/*=0*/, @Cast("bool") boolean weak/*=false*/) { super((Pointer)null); allocate(t, weak); }
    private native void allocate(mkldnn_engine t/*=0*/, @Cast("bool") boolean weak/*=false*/);
    public mkldnn_engine_handle() { super((Pointer)null); allocate(); }
    private native void allocate();

    public mkldnn_engine_handle(@Const @ByRef mkldnn_engine_handle other) { super((Pointer)null); allocate(other); }
    private native void allocate(@Const @ByRef mkldnn_engine_handle other);
    public native @ByRef @Name("operator =") mkldnn_engine_handle put(@Const @ByRef mkldnn_engine_handle other);
    /** Resets the value of a C handle.
     *  @param t The new value of the C handle.
     *  @param weak A flag to specify whether the wrapper should be weak. */
    public native void reset(mkldnn_engine t, @Cast("bool") boolean weak/*=false*/);
    public native void reset(mkldnn_engine t);

    /** Returns the value of the underlying C handle. */
    public native mkldnn_engine get();

    public native @Cast("bool") @Name("operator ==") boolean equals(@Const @ByRef mkldnn_engine_handle other);
    public native @Cast("bool") @Name("operator !=") boolean notEquals(@Const @ByRef mkldnn_engine_handle other);
}
@Name("mkldnn::handle<mkldnn_primitive_desc_t>") @NoOffset public static class mkldnn_primitive_desc_handle extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public mkldnn_primitive_desc_handle(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public mkldnn_primitive_desc_handle(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public mkldnn_primitive_desc_handle position(long position) {
        return (mkldnn_primitive_desc_handle)super.position(position);
    }

    /** Constructs a C handle wrapper.
     *  @param t The C handle to wrap.
     *  @param weak A flag to specify whether to construct a weak wrapper. */
    public mkldnn_primitive_desc_handle(mkldnn_primitive_desc t/*=0*/, @Cast("bool") boolean weak/*=false*/) { super((Pointer)null); allocate(t, weak); }
    private native void allocate(mkldnn_primitive_desc t/*=0*/, @Cast("bool") boolean weak/*=false*/);
    public mkldnn_primitive_desc_handle() { super((Pointer)null); allocate(); }
    private native void allocate();

    public mkldnn_primitive_desc_handle(@Const @ByRef mkldnn_primitive_desc_handle other) { super((Pointer)null); allocate(other); }
    private native void allocate(@Const @ByRef mkldnn_primitive_desc_handle other);
    public native @ByRef @Name("operator =") mkldnn_primitive_desc_handle put(@Const @ByRef mkldnn_primitive_desc_handle other);
    /** Resets the value of a C handle.
     *  @param t The new value of the C handle.
     *  @param weak A flag to specify whether the wrapper should be weak. */
    public native void reset(mkldnn_primitive_desc t, @Cast("bool") boolean weak/*=false*/);
    public native void reset(mkldnn_primitive_desc t);

    /** Returns the value of the underlying C handle. */
    public native mkldnn_primitive_desc get();

    public native @Cast("bool") @Name("operator ==") boolean equals(@Const @ByRef mkldnn_primitive_desc_handle other);
    public native @Cast("bool") @Name("operator !=") boolean notEquals(@Const @ByRef mkldnn_primitive_desc_handle other);
}
@Name("mkldnn::handle<mkldnn_primitive_attr_t>") @NoOffset public static class mkldnn_primitive_attr_handle extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public mkldnn_primitive_attr_handle(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public mkldnn_primitive_attr_handle(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public mkldnn_primitive_attr_handle position(long position) {
        return (mkldnn_primitive_attr_handle)super.position(position);
    }

    /** Constructs a C handle wrapper.
     *  @param t The C handle to wrap.
     *  @param weak A flag to specify whether to construct a weak wrapper. */
    public mkldnn_primitive_attr_handle(mkldnn_primitive_attr t/*=0*/, @Cast("bool") boolean weak/*=false*/) { super((Pointer)null); allocate(t, weak); }
    private native void allocate(mkldnn_primitive_attr t/*=0*/, @Cast("bool") boolean weak/*=false*/);
    public mkldnn_primitive_attr_handle() { super((Pointer)null); allocate(); }
    private native void allocate();

    public mkldnn_primitive_attr_handle(@Const @ByRef mkldnn_primitive_attr_handle other) { super((Pointer)null); allocate(other); }
    private native void allocate(@Const @ByRef mkldnn_primitive_attr_handle other);
    public native @ByRef @Name("operator =") mkldnn_primitive_attr_handle put(@Const @ByRef mkldnn_primitive_attr_handle other);
    /** Resets the value of a C handle.
     *  @param t The new value of the C handle.
     *  @param weak A flag to specify whether the wrapper should be weak. */
    public native void reset(mkldnn_primitive_attr t, @Cast("bool") boolean weak/*=false*/);
    public native void reset(mkldnn_primitive_attr t);

    /** Returns the value of the underlying C handle. */
    public native mkldnn_primitive_attr get();

    public native @Cast("bool") @Name("operator ==") boolean equals(@Const @ByRef mkldnn_primitive_attr_handle other);
    public native @Cast("bool") @Name("operator !=") boolean notEquals(@Const @ByRef mkldnn_primitive_attr_handle other);
}
@Name("mkldnn::handle<mkldnn_post_ops_t>") @NoOffset public static class mkldnn_post_ops_handle extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public mkldnn_post_ops_handle(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public mkldnn_post_ops_handle(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public mkldnn_post_ops_handle position(long position) {
        return (mkldnn_post_ops_handle)super.position(position);
    }

    /** Constructs a C handle wrapper.
     *  @param t The C handle to wrap.
     *  @param weak A flag to specify whether to construct a weak wrapper. */
    public mkldnn_post_ops_handle(mkldnn_post_ops t/*=0*/, @Cast("bool") boolean weak/*=false*/) { super((Pointer)null); allocate(t, weak); }
    private native void allocate(mkldnn_post_ops t/*=0*/, @Cast("bool") boolean weak/*=false*/);
    public mkldnn_post_ops_handle() { super((Pointer)null); allocate(); }
    private native void allocate();

    public mkldnn_post_ops_handle(@Const @ByRef mkldnn_post_ops_handle other) { super((Pointer)null); allocate(other); }
    private native void allocate(@Const @ByRef mkldnn_post_ops_handle other);
    public native @ByRef @Name("operator =") mkldnn_post_ops_handle put(@Const @ByRef mkldnn_post_ops_handle other);
    /** Resets the value of a C handle.
     *  @param t The new value of the C handle.
     *  @param weak A flag to specify whether the wrapper should be weak. */
    public native void reset(mkldnn_post_ops t, @Cast("bool") boolean weak/*=false*/);
    public native void reset(mkldnn_post_ops t);

    /** Returns the value of the underlying C handle. */
    public native mkldnn_post_ops get();

    public native @Cast("bool") @Name("operator ==") boolean equals(@Const @ByRef mkldnn_post_ops_handle other);
    public native @Cast("bool") @Name("operator !=") boolean notEquals(@Const @ByRef mkldnn_post_ops_handle other);
}
@Name("mkldnn::handle<mkldnn_primitive_t>") @NoOffset public static class mkldnn_primitive_handle extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public mkldnn_primitive_handle(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public mkldnn_primitive_handle(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public mkldnn_primitive_handle position(long position) {
        return (mkldnn_primitive_handle)super.position(position);
    }

    /** Constructs a C handle wrapper.
     *  @param t The C handle to wrap.
     *  @param weak A flag to specify whether to construct a weak wrapper. */
    public mkldnn_primitive_handle(mkldnn_primitive t/*=0*/, @Cast("bool") boolean weak/*=false*/) { super((Pointer)null); allocate(t, weak); }
    private native void allocate(mkldnn_primitive t/*=0*/, @Cast("bool") boolean weak/*=false*/);
    public mkldnn_primitive_handle() { super((Pointer)null); allocate(); }
    private native void allocate();

    public mkldnn_primitive_handle(@Const @ByRef mkldnn_primitive_handle other) { super((Pointer)null); allocate(other); }
    private native void allocate(@Const @ByRef mkldnn_primitive_handle other);
    public native @ByRef @Name("operator =") mkldnn_primitive_handle put(@Const @ByRef mkldnn_primitive_handle other);
    /** Resets the value of a C handle.
     *  @param t The new value of the C handle.
     *  @param weak A flag to specify whether the wrapper should be weak. */
    public native void reset(mkldnn_primitive t, @Cast("bool") boolean weak/*=false*/);
    public native void reset(mkldnn_primitive t);

    /** Returns the value of the underlying C handle. */
    public native mkldnn_primitive get();

    public native @Cast("bool") @Name("operator ==") boolean equals(@Const @ByRef mkldnn_primitive_handle other);
    public native @Cast("bool") @Name("operator !=") boolean notEquals(@Const @ByRef mkldnn_primitive_handle other);
}
@Name("mkldnn::handle<mkldnn_stream_t>") @NoOffset public static class mkldnn_stream_handle extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public mkldnn_stream_handle(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public mkldnn_stream_handle(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public mkldnn_stream_handle position(long position) {
        return (mkldnn_stream_handle)super.position(position);
    }

    /** Constructs a C handle wrapper.
     *  @param t The C handle to wrap.
     *  @param weak A flag to specify whether to construct a weak wrapper. */
    public mkldnn_stream_handle(mkldnn_stream t/*=0*/, @Cast("bool") boolean weak/*=false*/) { super((Pointer)null); allocate(t, weak); }
    private native void allocate(mkldnn_stream t/*=0*/, @Cast("bool") boolean weak/*=false*/);
    public mkldnn_stream_handle() { super((Pointer)null); allocate(); }
    private native void allocate();

    public mkldnn_stream_handle(@Const @ByRef mkldnn_stream_handle other) { super((Pointer)null); allocate(other); }
    private native void allocate(@Const @ByRef mkldnn_stream_handle other);
    public native @ByRef @Name("operator =") mkldnn_stream_handle put(@Const @ByRef mkldnn_stream_handle other);
    /** Resets the value of a C handle.
     *  @param t The new value of the C handle.
     *  @param weak A flag to specify whether the wrapper should be weak. */
    public native void reset(mkldnn_stream t, @Cast("bool") boolean weak/*=false*/);
    public native void reset(mkldnn_stream t);

    /** Returns the value of the underlying C handle. */
    public native mkldnn_stream get();

    public native @Cast("bool") @Name("operator ==") boolean equals(@Const @ByRef mkldnn_stream_handle other);
    public native @Cast("bool") @Name("operator !=") boolean notEquals(@Const @ByRef mkldnn_stream_handle other);
}

// #ifndef DOXYGEN_SHOULD_SKIP_THIS
// #endif

/** Base class for all computational primitives. */
@Namespace("mkldnn") public static class primitive extends mkldnn_primitive_handle {
    static { Loader.load(); }
    /** Default native constructor. */
    public primitive() { super((Pointer)null); allocate(); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public primitive(long size) { super((Pointer)null); allocateArray(size); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public primitive(Pointer p) { super(p); }
    private native void allocate();
    private native void allocateArray(long size);
    @Override public primitive position(long position) {
        return (primitive)super.position(position);
    }

    /** A proxy to C primitive kind enum */
    /** enum class mkldnn::primitive::kind */
    public static final int
        undefined_primitive = mkldnn_undefined_primitive,
        memory = mkldnn_memory,
        view = mkldnn_view,
        reorder = mkldnn_reorder,
        concat = mkldnn_concat,
        concat_inplace = mkldnn_concat_inplace,
        sum = mkldnn_sum,
        convolution = mkldnn_convolution,
        deconvolution = mkldnn_deconvolution,
        shuffle = mkldnn_shuffle,
        eltwise = mkldnn_eltwise,
        relu = mkldnn_relu,
        softmax = mkldnn_softmax,
        pooling = mkldnn_pooling,
        lrn = mkldnn_lrn,
        batch_normalization = mkldnn_batch_normalization,
        inner_product = mkldnn_inner_product,
        convolution_relu = mkldnn_convolution_relu,
        rnn = mkldnn_rnn;

    /** A wrapper structure to specify a particular output of a primitive. */
    @NoOffset public static class at extends Pointer {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public at(Pointer p) { super(p); }
    
        /** The underlying C API structure. */
        
        ///
        public native @ByRef mkldnn_primitive_at_t data(); public native at data(mkldnn_primitive_at_t data);
        /** Constructs a wrapper specifying \p aprimitive output with index \p
         *  at.
         * 
         *  @param aprimitive The target primitive.
         *  @param at The output index. */

        public at(@Const @ByRef primitive aprimitive, @Cast("size_t") long at/*=0*/) { super((Pointer)null); allocate(aprimitive, at); }
        private native void allocate(@Const @ByRef primitive aprimitive, @Cast("size_t") long at/*=0*/);
        public at(@Const @ByRef primitive aprimitive) { super((Pointer)null); allocate(aprimitive); }
        private native void allocate(@Const @ByRef primitive aprimitive);
        /** Returns the specified output. */
        public native @ByVal @Name("operator mkldnn::primitive") primitive asPrimitive();
    }

    /** Returns the descriptor of the underlying C API primitive */
    public native @Name("get_primitive_desc") @Const mkldnn_primitive_desc get_mkldnn_primitive_desc();
    // TODO: use the C++ API wrapper structure.
}


///
@Namespace("mkldnn") public static native @Cast("mkldnn_primitive_kind_t") int convert_to_c(@Cast("mkldnn::primitive::kind") int akind);
/** Intel(R) MKL-DNN exception class.
 * 
 *  This class captures the status returned by the failed C API function, error
 *  message, and, optionally, handle of the primitive that caused the error. */
@Namespace("mkldnn") @NoOffset public static class error extends Pointer {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public error(Pointer p) { super(p); }

    public native @Cast("mkldnn_status_t") int status(); public native error status(int status);
    public native @StdString BytePointer message(); public native error message(BytePointer message);
    
    ///
    public native @ByRef primitive error_primitive(); public native error error_primitive(primitive error_primitive);

    /** Constructs an error instance.
     * 
     *  @param astatus The error status returned by the C API.
     *  @param amessage The error message.
     *  @param aerror_primitive (optional) A C handle of the primitive that
     *                          caused the error. */

    
    ///
    public error(@Cast("mkldnn_status_t") int astatus, @StdString BytePointer amessage,
                mkldnn_primitive aerror_primitive/*=0*/) { super((Pointer)null); allocate(astatus, amessage, aerror_primitive); }
    private native void allocate(@Cast("mkldnn_status_t") int astatus, @StdString BytePointer amessage,
                mkldnn_primitive aerror_primitive/*=0*/);
    public error(@Cast("mkldnn_status_t") int astatus, @StdString BytePointer amessage) { super((Pointer)null); allocate(astatus, amessage); }
    private native void allocate(@Cast("mkldnn_status_t") int astatus, @StdString BytePointer amessage);
    public error(@Cast("mkldnn_status_t") int astatus, @StdString String amessage,
                mkldnn_primitive aerror_primitive/*=0*/) { super((Pointer)null); allocate(astatus, amessage, aerror_primitive); }
    private native void allocate(@Cast("mkldnn_status_t") int astatus, @StdString String amessage,
                mkldnn_primitive aerror_primitive/*=0*/);
    public error(@Cast("mkldnn_status_t") int astatus, @StdString String amessage) { super((Pointer)null); allocate(astatus, amessage); }
    private native void allocate(@Cast("mkldnn_status_t") int astatus, @StdString String amessage);

    /** A convenience function for wrapping calls to the C API. Checks the
     *  return status and throws an #error in case of failure.
     * 
     *  @param status The error status returned by the C API.
     *  @param message The error message.
     *  @param error_primitive (optional) A C handle of the primitive that
     *                         caused the error. */

    public static native void wrap_c_api(@Cast("mkldnn_status_t") int status,
                @StdString BytePointer message,
                @ByPtrPtr mkldnn_primitive error_primitive/*=0*/);
    public static native void wrap_c_api(@Cast("mkldnn_status_t") int status,
                @StdString BytePointer message);
    public static native void wrap_c_api(@Cast("mkldnn_status_t") int status,
                @StdString String message,
                @Cast("mkldnn_primitive_t*") PointerPointer error_primitive/*=0*/);
    public static native void wrap_c_api(@Cast("mkldnn_status_t") int status,
                @StdString String message);
}




/** \}
 <p>
 *  \addtogroup cpp_api_enums Common data types and enumerations
 *  A proxy to \ref c_api_types in \ref c_api.
 * 
 *  \{ */

/** enum mkldnn::round_mode */
public static final int
    round_nearest = mkldnn_round_nearest,
    round_down = mkldnn_round_down;

/** enum mkldnn::padding_kind */
public static final int
    zero = mkldnn_padding_zero;

/** enum mkldnn::prop_kind */
public static final int
    forward_training = mkldnn_forward_training,
    forward_scoring = mkldnn_forward_scoring,
    forward_inference = mkldnn_forward_inference,
    forward = mkldnn_forward,
    backward = mkldnn_backward,
    backward_data = mkldnn_backward_data,
    backward_weights = mkldnn_backward_weights,
    backward_bias = mkldnn_backward_bias;

/** enum mkldnn::algorithm */
public static final int
    algorithm_undef = mkldnn_alg_kind_undef,
    convolution_direct = mkldnn_convolution_direct,
    convolution_winograd = mkldnn_convolution_winograd,
    deconvolution_direct = mkldnn_deconvolution_direct,
    deconvolution_winograd = mkldnn_deconvolution_winograd,
    eltwise_relu = mkldnn_eltwise_relu,
    eltwise_tanh = mkldnn_eltwise_tanh,
    eltwise_elu = mkldnn_eltwise_elu,
    eltwise_square = mkldnn_eltwise_square,
    eltwise_abs = mkldnn_eltwise_abs,
    eltwise_sqrt = mkldnn_eltwise_sqrt,
    eltwise_linear = mkldnn_eltwise_linear,
    eltwise_bounded_relu = mkldnn_eltwise_bounded_relu,
    eltwise_soft_relu = mkldnn_eltwise_soft_relu,
    eltwise_logistic = mkldnn_eltwise_logistic,
    lrn_across_channels = mkldnn_lrn_across_channels,
    lrn_within_channel  = mkldnn_lrn_within_channel,
    pooling_max = mkldnn_pooling_max,
    pooling_avg = mkldnn_pooling_avg,
    pooling_avg_include_padding = mkldnn_pooling_avg_include_padding,
    pooling_avg_exclude_padding = mkldnn_pooling_avg_exclude_padding,
    vanilla_rnn = mkldnn_vanilla_rnn,
    vanilla_lstm = mkldnn_vanilla_lstm,
    vanilla_gru = mkldnn_vanilla_gru,
    gru_linear_before_reset = mkldnn_gru_linear_before_reset;

/** enum mkldnn::batch_normalization_flag */
public static final int
    use_global_stats = mkldnn_use_global_stats,
    use_scale_shift = mkldnn_use_scaleshift,
    omit_stats = mkldnn_omit_stats,
    fuse_bn_relu = mkldnn_fuse_bn_relu;

/** enum mkldnn::rnn_direction */
public static final int
    unidirectional_left2right = mkldnn_unidirectional_left2right,
    unidirectional_right2left = mkldnn_unidirectional_right2left,
    unidirectional = mkldnn_unidirectional,
    bidirectional_concat = mkldnn_bidirectional_concat,
    bidirectional_sum = mkldnn_bidirectional_sum;

/** enum mkldnn::query */
public static final int
    undef = mkldnn_query_undef,

    eengine = mkldnn_query_engine,
    primitive_kind = mkldnn_query_primitive_kind,

    num_of_inputs_s32 = mkldnn_query_num_of_inputs_s32,
    num_of_outputs_s32 = mkldnn_query_num_of_outputs_s32,

    time_estimate_f64 = mkldnn_query_time_estimate_f64,
    memory_consumption_s64 = mkldnn_query_memory_consumption_s64,

    impl_info_str = mkldnn_query_impl_info_str,

    op_d = mkldnn_query_op_d,
    memory_d = mkldnn_query_memory_d,
    convolution_d = mkldnn_query_convolution_d,
    deconvolution_d = mkldnn_query_deconvolution_d,
    shuffle_d = mkldnn_query_shuffle_d,
    eltwise_d = mkldnn_query_eltwise_d,
    relu_d = mkldnn_query_relu_d,
    softmax_d = mkldnn_query_softmax_d,
    pooling_d = mkldnn_query_pooling_d,
    lrn_d = mkldnn_query_lrn_d,
    batch_normalization_d = mkldnn_query_batch_normalization_d,
    inner_product_d = mkldnn_query_inner_product_d,
    convolution_relu_d = mkldnn_query_convolution_relu_d,
    rnn_d = mkldnn_query_rnn_d,

    input_pd = mkldnn_query_input_pd,
    output_pd = mkldnn_query_output_pd,
    src_pd = mkldnn_query_src_pd,
    diff_src_pd = mkldnn_query_diff_src_pd,
    weights_pd = mkldnn_query_weights_pd,
    diff_weights_pd = mkldnn_query_diff_weights_pd,
    dst_pd = mkldnn_query_dst_pd,
    diff_dst_pd = mkldnn_query_diff_dst_pd,
    workspace_pd = mkldnn_query_workspace_pd;

/** \}
 <p>
 *  \addtogroup cpp_api_attr Attributes
 *  An extension for controlling primitive behavior.
 * 
 *  \sa \ref c_api_attributes in \ref c_api
 *  \{ */

// #ifndef DOXYGEN_SHOULD_SKIP_THIS
// #endif

@Namespace("mkldnn") public static class post_ops extends mkldnn_post_ops_handle {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public post_ops(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public post_ops(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public post_ops position(long position) {
        return (post_ops)super.position(position);
    }

    public post_ops() { super((Pointer)null); allocate(); }
    private native void allocate();

    public native int len();

    public native @Cast("mkldnn::primitive::kind") int kind(int index);

    public native void append_sum(float scale/*=1.*/);
    public native void append_sum();

    public native void get_params_sum(int index, @ByRef FloatPointer scale);
    public native void get_params_sum(int index, @ByRef FloatBuffer scale);
    public native void get_params_sum(int index, @ByRef float[] scale);

    public native void append_eltwise(float scale, @Cast("mkldnn::algorithm") int alg, float alpha,
                float beta);

    public native void get_params_eltwise(int index, @ByRef FloatPointer scale, @Cast("mkldnn::algorithm*") @ByRef IntPointer alg,
                @ByRef FloatPointer alpha, @ByRef FloatPointer beta);
    public native void get_params_eltwise(int index, @ByRef FloatBuffer scale, @Cast("mkldnn::algorithm*") @ByRef IntBuffer alg,
                @ByRef FloatBuffer alpha, @ByRef FloatBuffer beta);
    public native void get_params_eltwise(int index, @ByRef float[] scale, @Cast("mkldnn::algorithm*") @ByRef int[] alg,
                @ByRef float[] alpha, @ByRef float[] beta);
}

// #ifndef DOXYGEN_SHOULD_SKIP_THIS
// #endif

@Namespace("mkldnn") public static class primitive_attr extends mkldnn_primitive_attr_handle {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public primitive_attr(Pointer p) { super(p); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public primitive_attr(long size) { super((Pointer)null); allocateArray(size); }
    private native void allocateArray(long size);
    @Override public primitive_attr position(long position) {
        return (primitive_attr)super.position(position);
    }

    public primitive_attr() { super((Pointer)null); allocate(); }
    private native void allocate();

    public native @Cast("mkldnn::round_mode") int get_int_output_round_mode();

    public native void set_int_output_round_mode(@Cast("mkldnn::round_mode") int mode);

    public native void get_output_scales(@ByRef IntPointer mask, @StdVector FloatPointer scales);
    public native void get_output_scales(@ByRef IntBuffer mask, @StdVector FloatBuffer scales);
    public native void get_output_scales(@ByRef int[] mask, @StdVector float[] scales);

    public native void set_output_scales(int mask, @StdVector FloatPointer scales);
    public native void set_output_scales(int mask, @StdVector FloatBuffer scales);
    public native void set_output_scales(int mask, @StdVector float[] scales);

    public native @Const @ByVal post_ops get_post_ops();

    public native void set_post_ops(@ByVal post_ops ops);
}

/** \}
 <p>
 *  \addtogroup cpp_api_engine Engine
 *  Engine operations
 * 
 *  \sa \ref c_api_engine in \ref c_api
 *  \{ */

// #ifndef DOXYGEN_SHOULD_SKIP_THIS
// #endif

/** An execution engine. */
@Namespace("mkldnn") public static class engine extends mkldnn_engine_handle {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public engine(Pointer p) { super(p); }

    // gcc bug??? using handle::handle;

    /** Kinds of engines */
    /** enum mkldnn::engine::kind */
    public static final int
        /** An unspecified engine */
        any = mkldnn_any_engine,
        /** CPU engine */
        cpu = mkldnn_cpu;

    /** Returns the number of engines of a certain kind.
     * 
     *  @param akind The kind of engines to count. */

    
    ///
    public static native @Cast("size_t") long get_count(@Cast("mkldnn::engine::kind") int akind);

    /** Constructs an engine.
     * 
     *  @param akind The kind of engine to construct.
     *  @param index The index of the engine. Must be less than the value
     *               returned by #get_count() for this particular kind of engine. */

    public engine(@Cast("mkldnn::engine::kind") int akind, @Cast("size_t") long index) { super((Pointer)null); allocate(akind, index); }
    private native void allocate(@Cast("mkldnn::engine::kind") int akind, @Cast("size_t") long index);

    public engine(mkldnn_engine aengine) { super((Pointer)null); allocate(aengine); }
    private native void allocate(mkldnn_engine aengine);

    public engine(@Const @ByRef mkldnn_primitive_desc_handle pd) { super((Pointer)null); allocate(pd); }
    private native void allocate(@Const @ByRef mkldnn_primitive_desc_handle pd);
}

/** \}
 <p>
 *  \addtogroup cpp_api_memory_related Memory and memory related operations
 *  \{
 <p>
 *  \addtogroup cpp_api_memory Memory
 *  A primitive to describe and store data.
 * 
 *  For more information please refer to \ref c_api_memory in \ref c_api
 *  \{
 <p>
 *  Memory primitive that describes the data. */
@Namespace("mkldnn") @NoOffset public static class memory extends primitive {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public memory(Pointer p) { super(p); }


    /** Data type specification. See #mkldnn_data_type_t for a detailed
     *  description. */
    /** enum mkldnn::memory::data_type */
    public static final int
        data_undef = mkldnn_data_type_undef,
        f32 = mkldnn_f32,
        s32 = mkldnn_s32,
        s16 = mkldnn_s16,
        s8 = mkldnn_s8,
        u8 = mkldnn_u8;

    /** Memory format specification. See #mkldnn_memory_format_t
     *  for a detailed description. */
    /** enum mkldnn::memory::format */
    public static final int
        format_undef = mkldnn_format_undef,
        any = mkldnn_any,
        blocked = mkldnn_blocked,
        x = mkldnn_x,
        nc = mkldnn_nc,
        ncw = mkldnn_ncw,
        nwc = mkldnn_nwc,
        nCw16c = mkldnn_nCw16c,
        nchw = mkldnn_nchw,
        nhwc = mkldnn_nhwc,
        chwn = mkldnn_chwn,
        nCw8c = mkldnn_nCw8c,
        nChw8c = mkldnn_nChw8c,
        nChw16c = mkldnn_nChw16c,
        ncdhw = mkldnn_ncdhw,
        ndhwc = mkldnn_ndhwc,
        nCdhw8c = mkldnn_nCdhw8c,
        nCdhw16c = mkldnn_nCdhw16c,
        oi = mkldnn_oi,
        io = mkldnn_io,
        oiw = mkldnn_oiw,
        wio = mkldnn_wio,
        Owi8o = mkldnn_Owi8o,
        OIw8o8i = mkldnn_OIw8o8i,
        OIw8i8o = mkldnn_OIw8i8o,
        OIw16i16o = mkldnn_OIw16i16o,
        OIw16o16i = mkldnn_OIw16o16i,
        Oiw16o = mkldnn_Oiw16o,
        Owi16o = mkldnn_Owi16o,
        OIw8i16o2i = mkldnn_OIw8i16o2i,
        OIw8o16i2o = mkldnn_OIw8o16i2o,
        IOw16o16i = mkldnn_IOw16o16i,
        oihw = mkldnn_oihw,
        ihwo = mkldnn_ihwo,
        hwio = mkldnn_hwio,
        hwio_s8s8 = mkldnn_hwio_s8s8,
        dhwio = mkldnn_dhwio,
        oidhw = mkldnn_oidhw,
        OIdhw8i8o = mkldnn_OIdhw8i8o,
        OIdhw8o8i = mkldnn_OIdhw8o8i,
        Odhwi8o = mkldnn_Odhwi8o,
        OIdhw16i16o = mkldnn_OIdhw16i16o,
        OIdhw16o16i = mkldnn_OIdhw16o16i,
        Oidhw16o = mkldnn_Oidhw16o,
        Odhwi16o = mkldnn_Odhwi16o,
        oIhw8i = mkldnn_oIhw8i,
        oIhw16i = mkldnn_oIhw16i,
        oIdhw8i = mkldnn_oIdhw8i,
        oIdhw16i = mkldnn_oIdhw16i,
        OIhw8i8o = mkldnn_OIhw8i8o,
        OIhw16i16o = mkldnn_OIhw16i16o,
        OIhw8o8i = mkldnn_OIhw8o8i,
        OIhw16o16i = mkldnn_OIhw16o16i,
        IOhw16o16i = mkldnn_IOhw16o16i,
        OIhw8i16o2i = mkldnn_OIhw8i16o2i,
        OIdhw8i16o2i = mkldnn_OIdhw8i16o2i,
        OIhw8o16i2o = mkldnn_OIhw8o16i2o,
        OIhw4i16o4i = mkldnn_OIhw4i16o4i,
        OIhw4i16o4i_s8s8 = mkldnn_OIhw4i16o4i_s8s8,
        Oihw8o = mkldnn_Oihw8o,
        Oihw16o = mkldnn_Oihw16o,
        Ohwi8o = mkldnn_Ohwi8o,
        Ohwi16o = mkldnn_Ohwi16o,
        OhIw16o4i = mkldnn_OhIw16o4i,
        goiw = mkldnn_goiw,
        gOwi8o = mkldnn_gOwi8o,
        gOIw8o8i = mkldnn_gOIw8o8i,
        gOIw8i8o = mkldnn_gOIw8i8o,
        gOIw16i16o = mkldnn_gOIw16i16o,
        gOIw16o16i = mkldnn_gOIw16o16i,
        gOiw16o = mkldnn_gOiw16o,
        gOwi16o = mkldnn_gOwi16o,
        gOIw8i16o2i = mkldnn_gOIw8i16o2i,
        gIOw16o16i = mkldnn_gIOw16o16i,
        gOIw8o16i2o = mkldnn_gOIw8o16i2o,
        goihw = mkldnn_goihw,
        hwigo = mkldnn_hwigo,
        hwigo_s8s8 = mkldnn_hwigo_s8s8,
        gOIdhw8i8o = mkldnn_gOIdhw8i8o,
        gOIdhw8o8i = mkldnn_gOIdhw8o8i,
        gOdhwi8o = mkldnn_gOdhwi8o,
        gOIhw8i8o = mkldnn_gOIhw8i8o,
        gOIhw16i16o = mkldnn_gOIhw16i16o,
        gOIhw8i16o2i = mkldnn_gOIhw8i16o2i,
        gOIdhw8i16o2i = mkldnn_gOIdhw8i16o2i,
        gOIhw8o16i2o = mkldnn_gOIhw8o16i2o,
        gOIhw4i16o4i = mkldnn_gOIhw4i16o4i,
        gOIhw4i16o4i_s8s8 = mkldnn_gOIhw4i16o4i_s8s8,
        gOihw8o = mkldnn_gOihw8o,
        gOihw16o = mkldnn_gOihw16o,
        gOhwi8o = mkldnn_gOhwi8o,
        gOhwi16o = mkldnn_gOhwi16o,
        Goihw8g = mkldnn_Goihw8g,
        Goihw16g = mkldnn_Goihw16g,
        gOIhw8o8i = mkldnn_gOIhw8o8i,
        gOIhw16o16i = mkldnn_gOIhw16o16i,
        gIOhw16o16i = mkldnn_gIOhw16o16i,
        gOhIw16o4i = mkldnn_gOhIw16o4i,
        goidhw = mkldnn_goidhw,
        gOIdhw16i16o = mkldnn_gOIdhw16i16o,
        gOIdhw16o16i = mkldnn_gOIdhw16o16i,
        gOidhw16o = mkldnn_gOidhw16o,
        gOdhwi16o = mkldnn_gOdhwi16o,
        ntc = mkldnn_ntc,
        tnc = mkldnn_tnc,
        ldsnc = mkldnn_ldsnc,
        ldigo = mkldnn_ldigo,
        ldigo_p = mkldnn_ldigo_p,
        ldgoi = mkldnn_ldgoi,
        ldgoi_p = mkldnn_ldgoi_p,
        ldgo = mkldnn_ldgo,
        wino_fmt = mkldnn_wino_fmt,
        format_last = mkldnn_format_last;

    /** A memory descriptor. */
    @NoOffset public static class desc extends Pointer {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public desc(Pointer p) { super(p); }
    
        /** The underlying C API data structure. */
        
        ///
        public native @ByRef mkldnn_memory_desc_t data(); public native desc data(mkldnn_memory_desc_t data);

        /** Constructs a memory descriptor.
         * 
         *  @param adims Data dimensions
         *  @param adata_type Data precision/type.
         *  @param aformat Data layout format. */
        
        ///
        public desc(@StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer adims, @Cast("mkldnn::memory::data_type") int adata_type,
                        @Cast("mkldnn::memory::format") int aformat) { super((Pointer)null); allocate(adims, adata_type, aformat); }
        private native void allocate(@StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer adims, @Cast("mkldnn::memory::data_type") int adata_type,
                        @Cast("mkldnn::memory::format") int aformat);
        public desc(@StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer adims, @Cast("mkldnn::memory::data_type") int adata_type,
                        @Cast("mkldnn::memory::format") int aformat) { super((Pointer)null); allocate(adims, adata_type, aformat); }
        private native void allocate(@StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer adims, @Cast("mkldnn::memory::data_type") int adata_type,
                        @Cast("mkldnn::memory::format") int aformat);
        public desc(@StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] adims, @Cast("mkldnn::memory::data_type") int adata_type,
                        @Cast("mkldnn::memory::format") int aformat) { super((Pointer)null); allocate(adims, adata_type, aformat); }
        private native void allocate(@StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] adims, @Cast("mkldnn::memory::data_type") int adata_type,
                        @Cast("mkldnn::memory::format") int aformat);

        /** Constructs a memory descriptor from a C API data structure.
         * 
         *  @param adata A C API #mkldnn_memory_desc_t structure. */
        public desc(@Const @ByRef mkldnn_memory_desc_t adata) { super((Pointer)null); allocate(adata); }
        private native void allocate(@Const @ByRef mkldnn_memory_desc_t adata);
    }

    /** A memory primitive descriptor. */
    public static class primitive_desc extends mkldnn_primitive_desc_handle {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public primitive_desc(Pointer p) { super(p); }
        /** Native array allocator. Access with {@link Pointer#position(long)}. */
        public primitive_desc(long size) { super((Pointer)null); allocateArray(size); }
        private native void allocateArray(long size);
        @Override public primitive_desc position(long position) {
            return (primitive_desc)super.position(position);
        }
    

        // TODO: make private
        public primitive_desc() { super((Pointer)null); allocate(); }
        private native void allocate();

        /** Constructs a memory primitive descriptor. */
        public primitive_desc(@Const @ByRef desc adesc, @Const @ByRef engine aengine) { super((Pointer)null); allocate(adesc, aengine); }
        private native void allocate(@Const @ByRef desc adesc, @Const @ByRef engine aengine);

        /** Returns the memory primitive descriptor. */
        public native @ByVal desc desc();

        /** Returns the number of bytes required to allocate the memory described
         *  including the padding area. */
        public native @Cast("size_t") long get_size();

        public native @Cast("bool") @Name("operator ==") boolean equals(@Const @ByRef primitive_desc other);

        public native @Cast("bool") @Name("operator !=") boolean notEquals(@Const @ByRef primitive_desc other);

        public native @ByVal engine get_engine();
    }

    /** Constructs a memory primitive from a generic primitive.
     * 
     *  @param aprimitive The primitive to treat as memory. */
    
    ///
    public memory(@Const @ByRef primitive aprimitive) { super((Pointer)null); allocate(aprimitive); }
    private native void allocate(@Const @ByRef primitive aprimitive);
    /** Constructs a memory primitive.
     * 
     *  @param adesc Memory primitive descriptor. */
    public memory(@Const @ByRef primitive_desc adesc) { super((Pointer)null); allocate(adesc); }
    private native void allocate(@Const @ByRef primitive_desc adesc);

    public memory(@Const @ByRef primitive_desc adesc, Pointer ahandle) { super((Pointer)null); allocate(adesc, ahandle); }
    private native void allocate(@Const @ByRef primitive_desc adesc, Pointer ahandle);

    /** Returns the descriptor of the memory primitive. */
    public native @ByVal primitive_desc get_primitive_desc();

    /** Returns a handle of the data contained in the memory primitive. On
     *  the CPU engine, this is a pointer to the allocated memory. */
    public native Pointer get_data_handle();

    public native void set_data_handle(Pointer handle);

    // Must go away or be private:
    public static native @Cast("mkldnn_data_type_t") int convert_to_c(@Cast("mkldnn::memory::data_type") int adata_type);
}

@Namespace("mkldnn") public static native @ByVal memory.desc zero_md();

@Namespace("mkldnn") public static native @ByVal memory null_memory(@ByVal engine eng);

@Namespace("mkldnn") public static native void check_num_parameters(@Const mkldnn_primitive_desc aprimitive_desc, int n_inputs, int n_outputs,
    @StdString BytePointer prim_name);
@Namespace("mkldnn") public static native void check_num_parameters(@Const mkldnn_primitive_desc aprimitive_desc, int n_inputs, int n_outputs,
    @StdString String prim_name);


@Namespace("mkldnn") public static native @Cast("bool") boolean is_null_memory(@Const mkldnn_primitive aprimitive);

@Namespace("mkldnn") public static native @Cast("bool") @Name("operator ==") boolean equals(@Cast("mkldnn_data_type_t") int a, @Cast("mkldnn::memory::data_type") int b);
@Namespace("mkldnn") public static native @Cast("bool") @Name("operator !=") boolean notEquals(@Cast("mkldnn_data_type_t") int a, @Cast("mkldnn::memory::data_type") int b);

/** \}
 <p>
 *  \addtogroup cpp_api_reorder Reorder
 *  A primitive to copy data between memory formats.
 * 
 *  \sa \ref c_api_reorder in \ref c_api
 *  \{ */

@Namespace("mkldnn") public static class reorder extends primitive {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public reorder(Pointer p) { super(p); }

    public static class primitive_desc extends mkldnn_primitive_desc_handle {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public primitive_desc(Pointer p) { super(p); }
    
        public primitive_desc(@Const @ByRef memory.primitive_desc input,
                               @Const @ByRef memory.primitive_desc output) { super((Pointer)null); allocate(input, output); }
        private native void allocate(@Const @ByRef memory.primitive_desc input,
                               @Const @ByRef memory.primitive_desc output);

        public primitive_desc(@Const @ByRef memory.primitive_desc input,
                        @Const @ByRef memory.primitive_desc output,
                        @Const @ByRef primitive_attr aattr) { super((Pointer)null); allocate(input, output, aattr); }
        private native void allocate(@Const @ByRef memory.primitive_desc input,
                        @Const @ByRef memory.primitive_desc output,
                        @Const @ByRef primitive_attr aattr);

        public native @ByVal engine get_engine();
    }

    public reorder(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at input, @Const @ByRef memory output) { super((Pointer)null); allocate(aprimitive_desc, input, output); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at input, @Const @ByRef memory output);

    public reorder(@Const @ByRef primitive.at input, @Const @ByRef memory output) { super((Pointer)null); allocate(input, output); }
    private native void allocate(@Const @ByRef primitive.at input, @Const @ByRef memory output);
}

/** \}
 <p>
 *  \addtogroup cpp_api_view View
 *  A primitive to view on a memory.
 * 
 *  \sa mkldnn_view_primitive_desc_create in \ref c_api
 *  \{ */

@Namespace("mkldnn") public static class view extends primitive {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public view(Pointer p) { super(p); }

    public static class primitive_desc extends mkldnn_primitive_desc_handle {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public primitive_desc(Pointer p) { super(p); }
    
        public primitive_desc(@Const @ByRef memory.primitive_desc input, @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer dims,
                        @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer offsets) { super((Pointer)null); allocate(input, dims, offsets); }
        private native void allocate(@Const @ByRef memory.primitive_desc input, @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer dims,
                        @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer offsets);
        public primitive_desc(@Const @ByRef memory.primitive_desc input, @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer dims,
                        @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer offsets) { super((Pointer)null); allocate(input, dims, offsets); }
        private native void allocate(@Const @ByRef memory.primitive_desc input, @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer dims,
                        @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer offsets);
        public primitive_desc(@Const @ByRef memory.primitive_desc input, @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] dims,
                        @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] offsets) { super((Pointer)null); allocate(input, dims, offsets); }
        private native void allocate(@Const @ByRef memory.primitive_desc input, @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] dims,
                        @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] offsets);

        public native @ByVal memory.primitive_desc dst_primitive_desc();

        public native @ByVal engine get_engine();
    }

    public view(@Const @ByRef primitive_desc view_pd, @ByVal primitive.at input) { super((Pointer)null); allocate(view_pd, input); }
    private native void allocate(@Const @ByRef primitive_desc view_pd, @ByVal primitive.at input);

    public view(@ByVal memory input, @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer dims, @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer offsets) { super((Pointer)null); allocate(input, dims, offsets); }
    private native void allocate(@ByVal memory input, @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer dims, @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer offsets);
    public view(@ByVal memory input, @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer dims, @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer offsets) { super((Pointer)null); allocate(input, dims, offsets); }
    private native void allocate(@ByVal memory input, @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer dims, @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer offsets);
    public view(@ByVal memory input, @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] dims, @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] offsets) { super((Pointer)null); allocate(input, dims, offsets); }
    private native void allocate(@ByVal memory input, @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] dims, @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] offsets);
}

/** \}
 <p>
 *  \addtogroup cpp_api_concat Concat
 *  A primitive to concatenate data by arbitrary dimension
 * 
 *  \sa \ref c_api_concat in \ref c_api
 *  \{ */

@Namespace("mkldnn") public static class concat extends primitive {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public concat(Pointer p) { super(p); }

    public static class primitive_desc extends mkldnn_primitive_desc_handle {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public primitive_desc(Pointer p) { super(p); }
    
        public native @ByVal @Cast("std::vector<const_mkldnn_primitive_desc_t>*") mkldnn_primitive_desc_vector cpp_to_c(
                        @ByVal memory_primitive_desc_vector inputs);

        public primitive_desc(@Const @ByRef memory.desc output, int concat_dimension,
                        @ByVal memory_primitive_desc_vector inputs) { super((Pointer)null); allocate(output, concat_dimension, inputs); }
        private native void allocate(@Const @ByRef memory.desc output, int concat_dimension,
                        @ByVal memory_primitive_desc_vector inputs);

        public primitive_desc(int concat_dimension,
                        @ByVal memory_primitive_desc_vector inputs) { super((Pointer)null); allocate(concat_dimension, inputs); }
        private native void allocate(int concat_dimension,
                        @ByVal memory_primitive_desc_vector inputs);

        public native @ByVal memory.primitive_desc dst_primitive_desc();

        public native @ByVal engine get_engine();
    }

    public concat(@Const @ByRef primitive_desc concat_pd,
                @StdVector primitive.at inputs, @Const @ByRef memory output) { super((Pointer)null); allocate(concat_pd, inputs, output); }
    private native void allocate(@Const @ByRef primitive_desc concat_pd,
                @StdVector primitive.at inputs, @Const @ByRef memory output);
}

/** \}
 <p>
 *  \addtogroup cpp_api_sum Sum
 *  A primitive to sum data
 * 
 *  \sa \ref c_api_sum in \ref c_api
 *  \{ */

@Namespace("mkldnn") public static class sum extends primitive {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public sum(Pointer p) { super(p); }

    public static class primitive_desc extends mkldnn_primitive_desc_handle {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public primitive_desc(Pointer p) { super(p); }
    
        public native @ByVal @Cast("std::vector<const_mkldnn_primitive_desc_t>*") mkldnn_primitive_desc_vector cpp_to_c(
                        @ByVal memory_primitive_desc_vector inputs);

        public primitive_desc(@Const @ByRef memory.desc output,
                        @StdVector FloatPointer scales,
                        @ByVal memory_primitive_desc_vector inputs) { super((Pointer)null); allocate(output, scales, inputs); }
        private native void allocate(@Const @ByRef memory.desc output,
                        @StdVector FloatPointer scales,
                        @ByVal memory_primitive_desc_vector inputs);
        public primitive_desc(@Const @ByRef memory.desc output,
                        @StdVector FloatBuffer scales,
                        @ByVal memory_primitive_desc_vector inputs) { super((Pointer)null); allocate(output, scales, inputs); }
        private native void allocate(@Const @ByRef memory.desc output,
                        @StdVector FloatBuffer scales,
                        @ByVal memory_primitive_desc_vector inputs);
        public primitive_desc(@Const @ByRef memory.desc output,
                        @StdVector float[] scales,
                        @ByVal memory_primitive_desc_vector inputs) { super((Pointer)null); allocate(output, scales, inputs); }
        private native void allocate(@Const @ByRef memory.desc output,
                        @StdVector float[] scales,
                        @ByVal memory_primitive_desc_vector inputs);

        public primitive_desc(@StdVector FloatPointer scales,
                        @ByVal memory_primitive_desc_vector inputs) { super((Pointer)null); allocate(scales, inputs); }
        private native void allocate(@StdVector FloatPointer scales,
                        @ByVal memory_primitive_desc_vector inputs);
        public primitive_desc(@StdVector FloatBuffer scales,
                        @ByVal memory_primitive_desc_vector inputs) { super((Pointer)null); allocate(scales, inputs); }
        private native void allocate(@StdVector FloatBuffer scales,
                        @ByVal memory_primitive_desc_vector inputs);
        public primitive_desc(@StdVector float[] scales,
                        @ByVal memory_primitive_desc_vector inputs) { super((Pointer)null); allocate(scales, inputs); }
        private native void allocate(@StdVector float[] scales,
                        @ByVal memory_primitive_desc_vector inputs);

        /** @deprecated : api backwards compatibility for double scales type */
        public primitive_desc(@Const @ByRef memory.desc output, @StdVector DoublePointer scale,
                        @ByVal memory_primitive_desc_vector inputs) { super((Pointer)null); allocate(output, scale, inputs); }
        private native @Deprecated void allocate(@Const @ByRef memory.desc output, @StdVector DoublePointer scale,
                        @ByVal memory_primitive_desc_vector inputs);
        public primitive_desc(@Const @ByRef memory.desc output, @StdVector DoubleBuffer scale,
                        @ByVal memory_primitive_desc_vector inputs) { super((Pointer)null); allocate(output, scale, inputs); }
        private native @Deprecated void allocate(@Const @ByRef memory.desc output, @StdVector DoubleBuffer scale,
                        @ByVal memory_primitive_desc_vector inputs);
        public primitive_desc(@Const @ByRef memory.desc output, @StdVector double[] scale,
                        @ByVal memory_primitive_desc_vector inputs) { super((Pointer)null); allocate(output, scale, inputs); }
        private native @Deprecated void allocate(@Const @ByRef memory.desc output, @StdVector double[] scale,
                        @ByVal memory_primitive_desc_vector inputs);

        /** @deprecated : api backwards compatibility for double scales type */
        public primitive_desc(@StdVector DoublePointer scale,
                        @ByVal memory_primitive_desc_vector inputs) { super((Pointer)null); allocate(scale, inputs); }
        private native @Deprecated void allocate(@StdVector DoublePointer scale,
                        @ByVal memory_primitive_desc_vector inputs);
        public primitive_desc(@StdVector DoubleBuffer scale,
                        @ByVal memory_primitive_desc_vector inputs) { super((Pointer)null); allocate(scale, inputs); }
        private native @Deprecated void allocate(@StdVector DoubleBuffer scale,
                        @ByVal memory_primitive_desc_vector inputs);
        public primitive_desc(@StdVector double[] scale,
                        @ByVal memory_primitive_desc_vector inputs) { super((Pointer)null); allocate(scale, inputs); }
        private native @Deprecated void allocate(@StdVector double[] scale,
                        @ByVal memory_primitive_desc_vector inputs);

        public native @ByVal memory.primitive_desc dst_primitive_desc();

        public native @ByVal engine get_engine();
    }

    public sum(@Const @ByRef primitive_desc sum_pd,
                @StdVector primitive.at inputs, @Const @ByRef memory output) { super((Pointer)null); allocate(sum_pd, inputs, output); }
    private native void allocate(@Const @ByRef primitive_desc sum_pd,
                @StdVector primitive.at inputs, @Const @ByRef memory output);
}

/** \}
 <p>
 *  \}
 <p>
 *  \addtogroup cpp_api_primitives Primitives
 *  \{
 <p>
 *  \addtogroup cpp_api_primitive_descriptors Primitive descriptors
 *  \{
 <p>
 *  A base class for all primitive descriptors */
@Name("mkldnn::primitive_desc") @NoOffset public static class primitive_desc extends mkldnn_primitive_desc_handle {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public primitive_desc(Pointer p) { super(p); }

    public primitive_desc(const_mkldnn_op_desc_t desc, @Const primitive_attr attr,
                @Const @ByRef engine e, @Const mkldnn_primitive_desc hint_fwd_pd) { super((Pointer)null); allocate(desc, attr, e, hint_fwd_pd); }
    private native void allocate(const_mkldnn_op_desc_t desc, @Const primitive_attr attr,
                @Const @ByRef engine e, @Const mkldnn_primitive_desc hint_fwd_pd);

    public native @ByVal engine get_engine();

    public native @ByVal primitive_attr get_primitive_attr();

    /** Returns implementation name */
    
    ///
    public native @Cast("const char*") BytePointer impl_info_str();

    /** Advances the next implementation for the given op descriptor
     * 
     *  Returns:
     *  - \c true on success
     *  - \c false if the last implementation reached, and
     *    the primitive descriptor itself is kept unchanged */
    public native @Cast("bool") boolean next_impl();

    /** Queries and returns requested memory primitive descriptor */
    public native @ByVal memory.primitive_desc query_mpd(@Cast("mkldnn::query") int what, int idx/*=0*/);
    public native @ByVal memory.primitive_desc query_mpd(@Cast("mkldnn::query") int what);

    // register specialized queries, e.g. src_primitive_desc()
// #   define REG_QUERY_MPD(name, what, idx)
//     memory::primitive_desc name ## _primitive_desc() const
//     { return query_mpd(what ## _pd, idx); }
}

/** \}
 <p>
 *  \addtogroup cpp_api_convolution Convolution
 *  A primitive to compute convolution using different algorithms.
 * 
 *  \sa \ref c_api_convolution in \ref c_api
 *  \{ */

@Namespace("mkldnn") public static class convolution_forward extends primitive {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public convolution_forward(Pointer p) { super(p); }

    @NoOffset public static class desc extends Pointer {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public desc(Pointer p) { super(p); }
    
        public native @ByRef mkldnn_convolution_desc_t data(); public native desc data(mkldnn_convolution_desc_t data);
        public desc(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc bias_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aprop_kind, aalgorithm, src_desc, weights_desc, bias_desc, dst_desc, strides, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc bias_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc bias_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aprop_kind, aalgorithm, src_desc, weights_desc, bias_desc, dst_desc, strides, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc bias_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc bias_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aprop_kind, aalgorithm, src_desc, weights_desc, bias_desc, dst_desc, strides, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc bias_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aprop_kind, aalgorithm, src_desc, weights_desc, dst_desc, strides, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aprop_kind, aalgorithm, src_desc, weights_desc, dst_desc, strides, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aprop_kind, aalgorithm, src_desc, weights_desc, dst_desc, strides, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc bias_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aprop_kind, aalgorithm, src_desc, weights_desc, bias_desc, dst_desc, strides, dilates, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc bias_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc bias_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aprop_kind, aalgorithm, src_desc, weights_desc, bias_desc, dst_desc, strides, dilates, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc bias_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc bias_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aprop_kind, aalgorithm, src_desc, weights_desc, bias_desc, dst_desc, strides, dilates, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc bias_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aprop_kind, aalgorithm, src_desc, weights_desc, dst_desc, strides, dilates, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aprop_kind, aalgorithm, src_desc, weights_desc, dst_desc, strides, dilates, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aprop_kind, aalgorithm, src_desc, weights_desc, dst_desc, strides, dilates, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
    }

    public static class primitive_desc extends mkldnn.primitive_desc {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public primitive_desc(Pointer p) { super(p); }
    
        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef engine e) { super((Pointer)null); allocate(desc, e); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef engine e);

        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e) { super((Pointer)null); allocate(desc, attr, e); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e);

        public native @ByVal memory.primitive_desc src_primitive_desc();
        public native @ByVal memory.primitive_desc weights_primitive_desc();
        public native @ByVal memory.primitive_desc bias_primitive_desc();
        public native @ByVal memory.primitive_desc dst_primitive_desc();
    }

    public convolution_forward(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at weights,
                @Const @ByRef primitive.at bias, @Const @ByRef memory dst) { super((Pointer)null); allocate(aprimitive_desc, src, weights, bias, dst); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at weights,
                @Const @ByRef primitive.at bias, @Const @ByRef memory dst);

    public convolution_forward(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at weights,
                @Const @ByRef memory dst) { super((Pointer)null); allocate(aprimitive_desc, src, weights, dst); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at weights,
                @Const @ByRef memory dst);
}

@Namespace("mkldnn") public static class convolution_backward_data extends primitive {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public convolution_backward_data(Pointer p) { super(p); }

    @NoOffset public static class desc extends Pointer {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public desc(Pointer p) { super(p); }
    
        public native @ByRef mkldnn_convolution_desc_t data(); public native desc data(mkldnn_convolution_desc_t data);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc diff_src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aalgorithm, diff_src_desc, weights_desc, diff_dst_desc, strides, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc diff_src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc diff_src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aalgorithm, diff_src_desc, weights_desc, diff_dst_desc, strides, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc diff_src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc diff_src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aalgorithm, diff_src_desc, weights_desc, diff_dst_desc, strides, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc diff_src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc diff_src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aalgorithm, diff_src_desc, weights_desc, diff_dst_desc, strides, dilates, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc diff_src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc diff_src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aalgorithm, diff_src_desc, weights_desc, diff_dst_desc, strides, dilates, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc diff_src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc diff_src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aalgorithm, diff_src_desc, weights_desc, diff_dst_desc, strides, dilates, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc diff_src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
    }

    public static class primitive_desc extends mkldnn.primitive_desc {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public primitive_desc(Pointer p) { super(p); }
    
        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef engine e,
                        @Const @ByRef convolution_forward.primitive_desc hint_fwd_pd) { super((Pointer)null); allocate(desc, e, hint_fwd_pd); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef engine e,
                        @Const @ByRef convolution_forward.primitive_desc hint_fwd_pd);

        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e,
                        @Const @ByRef convolution_forward.primitive_desc hint_fwd_pd) { super((Pointer)null); allocate(desc, attr, e, hint_fwd_pd); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e,
                        @Const @ByRef convolution_forward.primitive_desc hint_fwd_pd);

        public native @ByVal memory.primitive_desc diff_src_primitive_desc();
        public native @ByVal memory.primitive_desc weights_primitive_desc();
        public native @ByVal memory.primitive_desc diff_dst_primitive_desc();
    }

    public convolution_backward_data(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at diff_dst, @Const @ByRef primitive.at weights,
                @Const @ByRef memory diff_src) { super((Pointer)null); allocate(aprimitive_desc, diff_dst, weights, diff_src); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at diff_dst, @Const @ByRef primitive.at weights,
                @Const @ByRef memory diff_src);
}

@Namespace("mkldnn") public static class convolution_backward_weights extends primitive {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public convolution_backward_weights(Pointer p) { super(p); }

    @NoOffset public static class desc extends Pointer {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public desc(Pointer p) { super(p); }
    
        public native @ByRef mkldnn_convolution_desc_t data(); public native desc data(mkldnn_convolution_desc_t data);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_bias_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aalgorithm, src_desc, diff_weights_desc, diff_bias_desc, diff_dst_desc, strides, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_bias_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_bias_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aalgorithm, src_desc, diff_weights_desc, diff_bias_desc, diff_dst_desc, strides, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_bias_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_bias_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aalgorithm, src_desc, diff_weights_desc, diff_bias_desc, diff_dst_desc, strides, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_bias_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aalgorithm, src_desc, diff_weights_desc, diff_dst_desc, strides, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aalgorithm, src_desc, diff_weights_desc, diff_dst_desc, strides, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aalgorithm, src_desc, diff_weights_desc, diff_dst_desc, strides, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_bias_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aalgorithm, src_desc, diff_weights_desc, diff_bias_desc, diff_dst_desc, strides, dilates, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_bias_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_bias_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aalgorithm, src_desc, diff_weights_desc, diff_bias_desc, diff_dst_desc, strides, dilates, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_bias_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_bias_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aalgorithm, src_desc, diff_weights_desc, diff_bias_desc, diff_dst_desc, strides, dilates, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_bias_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aalgorithm, src_desc, diff_weights_desc, diff_dst_desc, strides, dilates, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aalgorithm, src_desc, diff_weights_desc, diff_dst_desc, strides, dilates, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aalgorithm, src_desc, diff_weights_desc, diff_dst_desc, strides, dilates, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);

    }

    public static class primitive_desc extends mkldnn.primitive_desc {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public primitive_desc(Pointer p) { super(p); }
    
        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef engine e,
                        @Const @ByRef convolution_forward.primitive_desc hint_fwd_pd) { super((Pointer)null); allocate(desc, e, hint_fwd_pd); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef engine e,
                        @Const @ByRef convolution_forward.primitive_desc hint_fwd_pd);

        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e,
                        @Const @ByRef convolution_forward.primitive_desc hint_fwd_pd) { super((Pointer)null); allocate(desc, attr, e, hint_fwd_pd); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e,
                        @Const @ByRef convolution_forward.primitive_desc hint_fwd_pd);

        public native @ByVal memory.primitive_desc src_primitive_desc();
        public native @ByVal memory.primitive_desc diff_weights_primitive_desc();
        public native @ByVal memory.primitive_desc diff_bias_primitive_desc();
        public native @ByVal memory.primitive_desc diff_dst_primitive_desc();
    }

    public convolution_backward_weights(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at diff_dst,
                @Const @ByRef memory diff_weights, @Const @ByRef memory diff_bias) { super((Pointer)null); allocate(aprimitive_desc, src, diff_dst, diff_weights, diff_bias); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at diff_dst,
                @Const @ByRef memory diff_weights, @Const @ByRef memory diff_bias);
    public convolution_backward_weights(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at diff_dst,
                @Const @ByRef memory diff_weights) { super((Pointer)null); allocate(aprimitive_desc, src, diff_dst, diff_weights); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at diff_dst,
                @Const @ByRef memory diff_weights);
}

/** A merged convolution-relu primitive for inference mode only
 * 
 *  @deprecated consider using convolution_forward with post_ops
 *  (e.g. post_ops::append_eltwise(1.f, #eltwise_relu, negative_slope, 0.f) */
@Namespace("mkldnn") public static class convolution_relu_forward extends primitive {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public convolution_relu_forward(Pointer p) { super(p); }

    @NoOffset public static class desc extends Pointer {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public desc(Pointer p) { super(p); }
    
        public native @ByRef mkldnn_convolution_relu_desc_t data(); public native desc data(mkldnn_convolution_relu_desc_t data);

        public desc(@Const @ByVal convolution_forward.desc conv_desc,
                        float negative_slope) { super((Pointer)null); allocate(conv_desc, negative_slope); }
        private native void allocate(@Const @ByVal convolution_forward.desc conv_desc,
                        float negative_slope);
    }

    public static class primitive_desc extends mkldnn.primitive_desc {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public primitive_desc(Pointer p) { super(p); }
    
        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef engine e) { super((Pointer)null); allocate(desc, e); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef engine e);

        public native @ByVal memory.primitive_desc src_primitive_desc();
        public native @ByVal memory.primitive_desc weights_primitive_desc();
        public native @ByVal memory.primitive_desc bias_primitive_desc();
        public native @ByVal memory.primitive_desc dst_primitive_desc();
    }

    /** @deprecated consider using convolution_forward + post_ops */
    public convolution_relu_forward(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at weights,
                @Const @ByRef primitive.at bias, @Const @ByRef memory dst) { super((Pointer)null); allocate(aprimitive_desc, src, weights, bias, dst); }
    private native @Deprecated void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at weights,
                @Const @ByRef primitive.at bias, @Const @ByRef memory dst);

    /** @deprecated consider using convolution_forward + post_ops */
    public convolution_relu_forward(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at weights,
                @Const @ByRef memory dst) { super((Pointer)null); allocate(aprimitive_desc, src, weights, dst); }
    private native @Deprecated void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at weights,
                @Const @ByRef memory dst);
}

/** \} */
//
/** \addtogroup cpp_api_deconvolution Deconvolution
/** A primitive to compute deconvolution using different algorithms.
/**
/** \sa \ref c_api_deconvolution in \ref c_api
/** \{ */

@Namespace("mkldnn") public static class deconvolution_forward extends primitive {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public deconvolution_forward(Pointer p) { super(p); }

    @NoOffset public static class desc extends Pointer {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public desc(Pointer p) { super(p); }
    
        public native @ByRef @Cast("mkldnn_deconvolution_desc_t*") mkldnn_convolution_desc_t data(); public native desc data(mkldnn_convolution_desc_t data);
        public desc(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc bias_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aprop_kind, aalgorithm, src_desc, weights_desc, bias_desc, dst_desc, strides, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc bias_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc bias_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aprop_kind, aalgorithm, src_desc, weights_desc, bias_desc, dst_desc, strides, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc bias_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc bias_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aprop_kind, aalgorithm, src_desc, weights_desc, bias_desc, dst_desc, strides, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc bias_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aprop_kind, aalgorithm, src_desc, weights_desc, dst_desc, strides, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aprop_kind, aalgorithm, src_desc, weights_desc, dst_desc, strides, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aprop_kind, aalgorithm, src_desc, weights_desc, dst_desc, strides, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc bias_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aprop_kind, aalgorithm, src_desc, weights_desc, bias_desc, dst_desc, strides, dilates, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc bias_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc bias_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aprop_kind, aalgorithm, src_desc, weights_desc, bias_desc, dst_desc, strides, dilates, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc bias_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc bias_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aprop_kind, aalgorithm, src_desc, weights_desc, bias_desc, dst_desc, strides, dilates, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc bias_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aprop_kind, aalgorithm, src_desc, weights_desc, dst_desc, strides, dilates, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aprop_kind, aalgorithm, src_desc, weights_desc, dst_desc, strides, dilates, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aprop_kind, aalgorithm, src_desc, weights_desc, dst_desc, strides, dilates, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
    }

    public static class primitive_desc extends mkldnn.primitive_desc {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public primitive_desc(Pointer p) { super(p); }
    
        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef engine e) { super((Pointer)null); allocate(desc, e); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef engine e);

        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e) { super((Pointer)null); allocate(desc, attr, e); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e);

        public native @ByVal memory.primitive_desc src_primitive_desc();
        public native @ByVal memory.primitive_desc weights_primitive_desc();
        public native @ByVal memory.primitive_desc bias_primitive_desc();
        public native @ByVal memory.primitive_desc dst_primitive_desc();
    }

    public deconvolution_forward(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at weights,
                @Const @ByRef primitive.at bias, @Const @ByRef memory dst) { super((Pointer)null); allocate(aprimitive_desc, src, weights, bias, dst); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at weights,
                @Const @ByRef primitive.at bias, @Const @ByRef memory dst);

    public deconvolution_forward(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at weights,
                @Const @ByRef memory dst) { super((Pointer)null); allocate(aprimitive_desc, src, weights, dst); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at weights,
                @Const @ByRef memory dst);
}

@Namespace("mkldnn") public static class deconvolution_backward_data extends primitive {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public deconvolution_backward_data(Pointer p) { super(p); }

    @NoOffset public static class desc extends Pointer {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public desc(Pointer p) { super(p); }
    
        public native @ByRef @Cast("mkldnn_deconvolution_desc_t*") mkldnn_convolution_desc_t data(); public native desc data(mkldnn_convolution_desc_t data);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc diff_src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aalgorithm, diff_src_desc, weights_desc, diff_dst_desc, strides, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc diff_src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc diff_src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aalgorithm, diff_src_desc, weights_desc, diff_dst_desc, strides, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc diff_src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc diff_src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aalgorithm, diff_src_desc, weights_desc, diff_dst_desc, strides, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc diff_src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc diff_src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aalgorithm, diff_src_desc, weights_desc, diff_dst_desc, strides, dilates, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc diff_src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc diff_src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aalgorithm, diff_src_desc, weights_desc, diff_dst_desc, strides, dilates, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc diff_src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc diff_src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aalgorithm, diff_src_desc, weights_desc, diff_dst_desc, strides, dilates, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc diff_src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
    }

    public static class primitive_desc extends mkldnn.primitive_desc {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public primitive_desc(Pointer p) { super(p); }
    
        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef engine e,
                        @Const @ByRef deconvolution_forward.primitive_desc hint_fwd_pd) { super((Pointer)null); allocate(desc, e, hint_fwd_pd); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef engine e,
                        @Const @ByRef deconvolution_forward.primitive_desc hint_fwd_pd);

        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e,
                        @Const @ByRef deconvolution_forward.primitive_desc hint_fwd_pd) { super((Pointer)null); allocate(desc, attr, e, hint_fwd_pd); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e,
                        @Const @ByRef deconvolution_forward.primitive_desc hint_fwd_pd);

        public native @ByVal memory.primitive_desc diff_src_primitive_desc();
        public native @ByVal memory.primitive_desc weights_primitive_desc();
        public native @ByVal memory.primitive_desc diff_dst_primitive_desc();
    }

    public deconvolution_backward_data(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at diff_dst, @Const @ByRef primitive.at weights,
                @Const @ByRef memory diff_src) { super((Pointer)null); allocate(aprimitive_desc, diff_dst, weights, diff_src); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at diff_dst, @Const @ByRef primitive.at weights,
                @Const @ByRef memory diff_src);
}

@Namespace("mkldnn") public static class deconvolution_backward_weights extends primitive {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public deconvolution_backward_weights(Pointer p) { super(p); }

    @NoOffset public static class desc extends Pointer {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public desc(Pointer p) { super(p); }
    
        public native @ByRef @Cast("mkldnn_deconvolution_desc_t*") mkldnn_convolution_desc_t data(); public native desc data(mkldnn_convolution_desc_t data);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_bias_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aalgorithm, src_desc, diff_weights_desc, diff_bias_desc, diff_dst_desc, strides, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_bias_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_bias_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aalgorithm, src_desc, diff_weights_desc, diff_bias_desc, diff_dst_desc, strides, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_bias_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_bias_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aalgorithm, src_desc, diff_weights_desc, diff_bias_desc, diff_dst_desc, strides, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_bias_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aalgorithm, src_desc, diff_weights_desc, diff_dst_desc, strides, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aalgorithm, src_desc, diff_weights_desc, diff_dst_desc, strides, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aalgorithm, src_desc, diff_weights_desc, diff_dst_desc, strides, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_bias_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aalgorithm, src_desc, diff_weights_desc, diff_bias_desc, diff_dst_desc, strides, dilates, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_bias_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_bias_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aalgorithm, src_desc, diff_weights_desc, diff_bias_desc, diff_dst_desc, strides, dilates, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_bias_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_bias_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aalgorithm, src_desc, diff_weights_desc, diff_bias_desc, diff_dst_desc, strides, dilates, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_bias_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aalgorithm, src_desc, diff_weights_desc, diff_dst_desc, strides, dilates, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aalgorithm, src_desc, diff_weights_desc, diff_dst_desc, strides, dilates, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aalgorithm, src_desc, diff_weights_desc, diff_dst_desc, strides, dilates, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] dilates,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
    }

    public static class primitive_desc extends mkldnn.primitive_desc {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public primitive_desc(Pointer p) { super(p); }
    
        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef engine e,
                        @Const @ByRef deconvolution_forward.primitive_desc hint_fwd_pd) { super((Pointer)null); allocate(desc, e, hint_fwd_pd); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef engine e,
                        @Const @ByRef deconvolution_forward.primitive_desc hint_fwd_pd);

        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e,
                        @Const @ByRef deconvolution_forward.primitive_desc hint_fwd_pd) { super((Pointer)null); allocate(desc, attr, e, hint_fwd_pd); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e,
                        @Const @ByRef deconvolution_forward.primitive_desc hint_fwd_pd);

        public native @ByVal memory.primitive_desc src_primitive_desc();
        public native @ByVal memory.primitive_desc diff_weights_primitive_desc();
        public native @ByVal memory.primitive_desc diff_bias_primitive_desc();
        public native @ByVal memory.primitive_desc diff_dst_primitive_desc();
    }

    public deconvolution_backward_weights(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at diff_dst,
                @Const @ByRef memory diff_weights, @Const @ByRef memory diff_bias) { super((Pointer)null); allocate(aprimitive_desc, src, diff_dst, diff_weights, diff_bias); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at diff_dst,
                @Const @ByRef memory diff_weights, @Const @ByRef memory diff_bias);
    public deconvolution_backward_weights(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at diff_dst,
                @Const @ByRef memory diff_weights) { super((Pointer)null); allocate(aprimitive_desc, src, diff_dst, diff_weights); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at diff_dst,
                @Const @ByRef memory diff_weights);
}

/** \}
 <p>
 *  \addtogroup cpp_api_lrn LRN
 *  A primitive to perform local response normalization (LRN) across or within
 *  channels.
 * 
 *  \sa \ref c_api_lrn in \ref c_api
 *  \{ */

@Namespace("mkldnn") public static class lrn_forward extends primitive {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public lrn_forward(Pointer p) { super(p); }

    @NoOffset public static class desc extends Pointer {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public desc(Pointer p) { super(p); }
    
        public native @ByRef mkldnn_lrn_desc_t data(); public native desc data(mkldnn_lrn_desc_t data);
        public desc(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                    @Const @ByRef memory.desc src_desc,
                    int local_size, float alpha, float beta, float k) { super((Pointer)null); allocate(aprop_kind, aalgorithm, src_desc, local_size, alpha, beta, k); }
        private native void allocate(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                    @Const @ByRef memory.desc src_desc,
                    int local_size, float alpha, float beta, float k);
        public desc(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                    @Const @ByRef memory.desc src_desc,
                    int local_size, float alpha, float beta) { super((Pointer)null); allocate(aprop_kind, aalgorithm, src_desc, local_size, alpha, beta); }
        private native void allocate(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                    @Const @ByRef memory.desc src_desc,
                    int local_size, float alpha, float beta);
    }

    public static class primitive_desc extends mkldnn.primitive_desc {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public primitive_desc(Pointer p) { super(p); }
    
        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef engine e) { super((Pointer)null); allocate(desc, e); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef engine e);

        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e) { super((Pointer)null); allocate(desc, attr, e); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e);

        public native @ByVal memory.primitive_desc src_primitive_desc();
        public native @ByVal memory.primitive_desc dst_primitive_desc();
        public native @ByVal memory.primitive_desc workspace_primitive_desc();
    }

    public lrn_forward(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef memory workspace,
                @Const @ByRef memory dst) { super((Pointer)null); allocate(aprimitive_desc, src, workspace, dst); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef memory workspace,
                @Const @ByRef memory dst);

    public lrn_forward(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef memory dst) { super((Pointer)null); allocate(aprimitive_desc, src, dst); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef memory dst);
}

@Namespace("mkldnn") public static class lrn_backward extends primitive {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public lrn_backward(Pointer p) { super(p); }

    @NoOffset public static class desc extends Pointer {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public desc(Pointer p) { super(p); }
    
        public native @ByRef mkldnn_lrn_desc_t data(); public native desc data(mkldnn_lrn_desc_t data);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                    @Const @ByRef memory.desc data_desc,
                    @Const @ByRef memory.desc diff_data_desc,
                    int local_size, float alpha, float beta, float k) { super((Pointer)null); allocate(aalgorithm, data_desc, diff_data_desc, local_size, alpha, beta, k); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                    @Const @ByRef memory.desc data_desc,
                    @Const @ByRef memory.desc diff_data_desc,
                    int local_size, float alpha, float beta, float k);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                    @Const @ByRef memory.desc data_desc,
                    @Const @ByRef memory.desc diff_data_desc,
                    int local_size, float alpha, float beta) { super((Pointer)null); allocate(aalgorithm, data_desc, diff_data_desc, local_size, alpha, beta); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                    @Const @ByRef memory.desc data_desc,
                    @Const @ByRef memory.desc diff_data_desc,
                    int local_size, float alpha, float beta);
    }

    public static class primitive_desc extends mkldnn.primitive_desc {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public primitive_desc(Pointer p) { super(p); }
    
        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef engine e,
                        @Const @ByRef lrn_forward.primitive_desc hint_fwd_pd) { super((Pointer)null); allocate(desc, e, hint_fwd_pd); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef engine e,
                        @Const @ByRef lrn_forward.primitive_desc hint_fwd_pd);

        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e,
                        @Const @ByRef lrn_forward.primitive_desc hint_fwd_pd) { super((Pointer)null); allocate(desc, attr, e, hint_fwd_pd); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e,
                        @Const @ByRef lrn_forward.primitive_desc hint_fwd_pd);

        public native @ByVal memory.primitive_desc diff_src_primitive_desc();
        public native @ByVal memory.primitive_desc diff_dst_primitive_desc();
        public native @ByVal memory.primitive_desc workspace_primitive_desc();
    }

    public lrn_backward(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at diff_dst,
                @Const @ByRef primitive.at workspace, @Const @ByRef memory diff_src) { super((Pointer)null); allocate(aprimitive_desc, src, diff_dst, workspace, diff_src); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at diff_dst,
                @Const @ByRef primitive.at workspace, @Const @ByRef memory diff_src);

    public lrn_backward(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at diff_dst,
                @Const @ByRef memory diff_src) { super((Pointer)null); allocate(aprimitive_desc, src, diff_dst, diff_src); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at diff_dst,
                @Const @ByRef memory diff_src);
}

/** \}
 <p>
 *  \addtogroup cpp_api_pooling Pooling
 *  A primitive to perform max or average pooling.
 * 
 *  \sa \ref c_api_pooling in \ref c_api
 *  \{ */

@Namespace("mkldnn") public static class pooling_forward extends primitive {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public pooling_forward(Pointer p) { super(p); }

    @NoOffset public static class desc extends Pointer {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public desc(Pointer p) { super(p); }
    
        public native @ByRef mkldnn_pooling_desc_t data(); public native desc data(mkldnn_pooling_desc_t data);
        public desc(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer kernel,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aprop_kind, aalgorithm, src_desc, dst_desc, strides, kernel, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer kernel,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer kernel,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aprop_kind, aalgorithm, src_desc, dst_desc, strides, kernel, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer kernel,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] kernel,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aprop_kind, aalgorithm, src_desc, dst_desc, strides, kernel, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] kernel,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByVal int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
    }

    public static class primitive_desc extends mkldnn.primitive_desc {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public primitive_desc(Pointer p) { super(p); }
    
        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef engine e) { super((Pointer)null); allocate(desc, e); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef engine e);

        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e) { super((Pointer)null); allocate(desc, attr, e); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e);

        public native @ByVal memory.primitive_desc src_primitive_desc();
        public native @ByVal memory.primitive_desc dst_primitive_desc();
        public native @ByVal memory.primitive_desc workspace_primitive_desc();
    }

    public pooling_forward(@Const @ByRef primitive_desc aprimitive_desc, @Const @ByRef primitive.at src,
                @Const @ByRef memory dst) { super((Pointer)null); allocate(aprimitive_desc, src, dst); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc, @Const @ByRef primitive.at src,
                @Const @ByRef memory dst);

    public pooling_forward(@Const @ByRef primitive_desc aprimitive_desc, @Const @ByRef primitive.at src,
                @Const @ByRef memory dst, @Const @ByRef memory workspace) { super((Pointer)null); allocate(aprimitive_desc, src, dst, workspace); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc, @Const @ByRef primitive.at src,
                @Const @ByRef memory dst, @Const @ByRef memory workspace);
}

@Namespace("mkldnn") public static class pooling_backward extends primitive {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public pooling_backward(Pointer p) { super(p); }

    @NoOffset public static class desc extends Pointer {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public desc(Pointer p) { super(p); }
    
        public native @ByRef mkldnn_pooling_desc_t data(); public native desc data(mkldnn_pooling_desc_t data);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc diff_src_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByRef IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByRef IntPointer kernel,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByRef IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByRef IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aalgorithm, diff_src_desc, diff_dst_desc, strides, kernel, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc diff_src_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByRef IntPointer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByRef IntPointer kernel,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByRef IntPointer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByRef IntPointer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc diff_src_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByRef IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByRef IntBuffer kernel,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByRef IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByRef IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aalgorithm, diff_src_desc, diff_dst_desc, strides, kernel, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc diff_src_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByRef IntBuffer strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByRef IntBuffer kernel,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByRef IntBuffer padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByRef IntBuffer padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
        public desc(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc diff_src_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByRef int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByRef int[] kernel,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByRef int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByRef int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind) { super((Pointer)null); allocate(aalgorithm, diff_src_desc, diff_dst_desc, strides, kernel, padding_l, padding_r, apadding_kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int aalgorithm,
                        @Const @ByRef memory.desc diff_src_desc,
                        @Const @ByRef memory.desc diff_dst_desc,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByRef int[] strides,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByRef int[] kernel,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByRef int[] padding_l,
                        @Const @StdVector("std::remove_extent<mkldnn_dims_t>::type") @ByRef int[] padding_r,
                        @Cast("const mkldnn::padding_kind") int apadding_kind);
    }

    public static class primitive_desc extends mkldnn.primitive_desc {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public primitive_desc(Pointer p) { super(p); }
    
        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef engine e,
                        @Const @ByRef pooling_forward.primitive_desc hint_fwd_pd) { super((Pointer)null); allocate(desc, e, hint_fwd_pd); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef engine e,
                        @Const @ByRef pooling_forward.primitive_desc hint_fwd_pd);

        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e,
                        @Const @ByRef pooling_forward.primitive_desc hint_fwd_pd) { super((Pointer)null); allocate(desc, attr, e, hint_fwd_pd); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e,
                        @Const @ByRef pooling_forward.primitive_desc hint_fwd_pd);

        public native @ByVal memory.primitive_desc diff_src_primitive_desc();
        public native @ByVal memory.primitive_desc diff_dst_primitive_desc();
        public native @ByVal memory.primitive_desc workspace_primitive_desc();
    }

    public pooling_backward(@Const @ByRef primitive_desc aprimitive_desc, @Const @ByRef primitive.at diff_dst,
                @Const @ByRef memory diff_src) { super((Pointer)null); allocate(aprimitive_desc, diff_dst, diff_src); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc, @Const @ByRef primitive.at diff_dst,
                @Const @ByRef memory diff_src);

    public pooling_backward(@Const @ByRef primitive_desc aprimitive_desc, @Const @ByRef primitive.at diff_dst,
                @Const @ByRef primitive.at workspace, @Const @ByRef memory diff_src) { super((Pointer)null); allocate(aprimitive_desc, diff_dst, workspace, diff_src); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc, @Const @ByRef primitive.at diff_dst,
                @Const @ByRef primitive.at workspace, @Const @ByRef memory diff_src);
}

/** \}
 <p>
 *  \addtogroup cpp_api_eltwise Eltwise
 *  A primitive to compute element wise operations like parametric rectifier
 *  linear unit (ReLU).
 * 
 *  \sa \ref c_api_eltwise in \ref c_api
 *  \{ */

@Namespace("mkldnn") public static class eltwise_forward extends primitive {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public eltwise_forward(Pointer p) { super(p); }

    @NoOffset public static class desc extends Pointer {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public desc(Pointer p) { super(p); }
    
        public native @ByRef mkldnn_eltwise_desc_t data(); public native desc data(mkldnn_eltwise_desc_t data);
        public desc(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int alg_kind,
                        @Const @ByRef memory.desc src_desc, float alpha/*=0*/, float beta/*=0*/) { super((Pointer)null); allocate(aprop_kind, alg_kind, src_desc, alpha, beta); }
        private native void allocate(@Cast("mkldnn::prop_kind") int aprop_kind, @Cast("mkldnn::algorithm") int alg_kind,
                        @Const @ByRef memory.desc src_desc, float alpha/*=0*/, float beta/*=0*/);

        /** @deprecated : api backward compatibility for relu */
        public desc(@Cast("mkldnn::prop_kind") int aprop_kind, @Const @ByRef memory.desc src_desc,
                        float negative_slope) { super((Pointer)null); allocate(aprop_kind, src_desc, negative_slope); }
        private native @Deprecated void allocate(@Cast("mkldnn::prop_kind") int aprop_kind, @Const @ByRef memory.desc src_desc,
                        float negative_slope);
    }

    public static class primitive_desc extends mkldnn.primitive_desc {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public primitive_desc(Pointer p) { super(p); }
    
        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef engine e) { super((Pointer)null); allocate(desc, e); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef engine e);

        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e) { super((Pointer)null); allocate(desc, attr, e); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e);

        public native @ByVal memory.primitive_desc src_primitive_desc();
        public native @ByVal memory.primitive_desc dst_primitive_desc();
    }

    public eltwise_forward(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef memory dst) { super((Pointer)null); allocate(aprimitive_desc, src, dst); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef memory dst);
}

@Namespace("mkldnn") public static class eltwise_backward extends primitive {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public eltwise_backward(Pointer p) { super(p); }

    @NoOffset public static class desc extends Pointer {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public desc(Pointer p) { super(p); }
    
        public native @ByRef mkldnn_eltwise_desc_t data(); public native desc data(mkldnn_eltwise_desc_t data);

        public desc(@Cast("mkldnn::algorithm") int alg_kind, @Const @ByRef memory.desc diff_data_desc,
                        @Const @ByRef memory.desc data_desc, float alpha/*=0*/, float beta/*=0*/) { super((Pointer)null); allocate(alg_kind, diff_data_desc, data_desc, alpha, beta); }
        private native void allocate(@Cast("mkldnn::algorithm") int alg_kind, @Const @ByRef memory.desc diff_data_desc,
                        @Const @ByRef memory.desc data_desc, float alpha/*=0*/, float beta/*=0*/);

        /** @deprecated : api backward compatibility for relu */
        public desc(@Const @ByRef memory.desc diff_data_desc, @Const @ByRef memory.desc data_desc,
                    float negative_slope) { super((Pointer)null); allocate(diff_data_desc, data_desc, negative_slope); }
        private native @Deprecated void allocate(@Const @ByRef memory.desc diff_data_desc, @Const @ByRef memory.desc data_desc,
                    float negative_slope);
    }

    public static class primitive_desc extends mkldnn.primitive_desc {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public primitive_desc(Pointer p) { super(p); }
    
        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef engine e,
                        @Const @ByRef eltwise_forward.primitive_desc hint_fwd_pd) { super((Pointer)null); allocate(desc, e, hint_fwd_pd); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef engine e,
                        @Const @ByRef eltwise_forward.primitive_desc hint_fwd_pd);

        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e,
                        @Const @ByRef eltwise_forward.primitive_desc hint_fwd_pd) { super((Pointer)null); allocate(desc, attr, e, hint_fwd_pd); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e,
                        @Const @ByRef eltwise_forward.primitive_desc hint_fwd_pd);

        public native @ByVal memory.primitive_desc src_primitive_desc();
        public native @ByVal memory.primitive_desc diff_src_primitive_desc();
        public native @ByVal memory.primitive_desc diff_dst_primitive_desc();
    }

    public eltwise_backward(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at diff_dst,
                @Const @ByRef memory diff_src) { super((Pointer)null); allocate(aprimitive_desc, src, diff_dst, diff_src); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at diff_dst,
                @Const @ByRef memory diff_src);
}


///

/** \}
 <p>
 *  \addtogroup cpp_api_softmax Softmax
 *  A primitive to perform softmax.
 * 
 *  \sa \ref c_api_softmax in \ref c_api
 *  \{ */

@Namespace("mkldnn") public static class softmax_forward extends primitive {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public softmax_forward(Pointer p) { super(p); }

    @NoOffset public static class desc extends Pointer {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public desc(Pointer p) { super(p); }
    
        public native @ByRef mkldnn_softmax_desc_t data(); public native desc data(mkldnn_softmax_desc_t data);
        public desc(@Cast("mkldnn::prop_kind") int aprop_kind, @Const @ByRef memory.desc data_desc,
                     int softmax_axis) { super((Pointer)null); allocate(aprop_kind, data_desc, softmax_axis); }
        private native void allocate(@Cast("mkldnn::prop_kind") int aprop_kind, @Const @ByRef memory.desc data_desc,
                     int softmax_axis);
    }

    public static class primitive_desc extends mkldnn.primitive_desc {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public primitive_desc(Pointer p) { super(p); }
    
        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef engine e) { super((Pointer)null); allocate(desc, e); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef engine e);

        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e) { super((Pointer)null); allocate(desc, attr, e); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e);

        public native @ByVal memory.primitive_desc src_primitive_desc();
        public native @ByVal memory.primitive_desc dst_primitive_desc();
    }

    public softmax_forward(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef memory dst) { super((Pointer)null); allocate(aprimitive_desc, src, dst); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef memory dst);
}

@Namespace("mkldnn") public static class softmax_backward extends primitive {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public softmax_backward(Pointer p) { super(p); }

    @NoOffset public static class desc extends Pointer {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public desc(Pointer p) { super(p); }
    
        public native @ByRef mkldnn_softmax_desc_t data(); public native desc data(mkldnn_softmax_desc_t data);
        public desc(@Const @ByRef memory.desc diff_desc, @Const @ByRef memory.desc data_desc,
                        int softmax_axis) { super((Pointer)null); allocate(diff_desc, data_desc, softmax_axis); }
        private native void allocate(@Const @ByRef memory.desc diff_desc, @Const @ByRef memory.desc data_desc,
                        int softmax_axis);
    }

    public static class primitive_desc extends mkldnn.primitive_desc {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public primitive_desc(Pointer p) { super(p); }
    
        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef engine e,
                        @Const @ByRef softmax_forward.primitive_desc hint_fwd_pd) { super((Pointer)null); allocate(desc, e, hint_fwd_pd); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef engine e,
                        @Const @ByRef softmax_forward.primitive_desc hint_fwd_pd);

        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e,
                        @Const @ByRef softmax_forward.primitive_desc hint_fwd_pd) { super((Pointer)null); allocate(desc, attr, e, hint_fwd_pd); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e,
                        @Const @ByRef softmax_forward.primitive_desc hint_fwd_pd);

        public native @ByVal memory.primitive_desc dst_primitive_desc();
        public native @ByVal memory.primitive_desc diff_src_primitive_desc();
        public native @ByVal memory.primitive_desc diff_dst_primitive_desc();
        public native @ByVal memory.primitive_desc workspace_primitive_desc();
    }

    public softmax_backward(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at dst, @Const @ByRef primitive.at diff_dst,
                @Const @ByRef memory diff_src) { super((Pointer)null); allocate(aprimitive_desc, dst, diff_dst, diff_src); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at dst, @Const @ByRef primitive.at diff_dst,
                @Const @ByRef memory diff_src);
}

/** \}
 <p>
 *  \addtogroup cpp_api_batch_norm Batch normalization
 *  A primitive to perform batch normalization.
 * 
 *  \sa \ref c_api_batch_normalization in \ref c_api
 *  \{ */

@Namespace("mkldnn") public static class batch_normalization_forward extends primitive {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public batch_normalization_forward(Pointer p) { super(p); }

    @NoOffset public static class desc extends Pointer {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public desc(Pointer p) { super(p); }
    
        public native @ByRef mkldnn_batch_normalization_desc_t data(); public native desc data(mkldnn_batch_normalization_desc_t data);
        public desc(@Cast("mkldnn::prop_kind") int aprop_kind, @Const @ByRef memory.desc src_desc, float epsilon,
                        @Cast("unsigned") int flags) { super((Pointer)null); allocate(aprop_kind, src_desc, epsilon, flags); }
        private native void allocate(@Cast("mkldnn::prop_kind") int aprop_kind, @Const @ByRef memory.desc src_desc, float epsilon,
                        @Cast("unsigned") int flags);
    }

    public static class primitive_desc extends mkldnn.primitive_desc {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public primitive_desc(Pointer p) { super(p); }
    
        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef engine e) { super((Pointer)null); allocate(desc, e); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef engine e);

        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e) { super((Pointer)null); allocate(desc, attr, e); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e);

        public native @ByVal memory.primitive_desc src_primitive_desc();
        public native @ByVal memory.primitive_desc weights_primitive_desc();
        public native @ByVal memory.primitive_desc dst_primitive_desc();
        public native @ByVal memory.primitive_desc workspace_primitive_desc();

        public native @ByVal memory.primitive_desc mean_primitive_desc();
        public native @ByVal memory.primitive_desc variance_primitive_desc();
    }

    public batch_normalization_forward(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at mean,
                @Const @ByRef primitive.at variance, @Const @ByRef primitive.at weights,
                @Const @ByRef memory dst) { super((Pointer)null); allocate(aprimitive_desc, src, mean, variance, weights, dst); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at mean,
                @Const @ByRef primitive.at variance, @Const @ByRef primitive.at weights,
                @Const @ByRef memory dst);

    public batch_normalization_forward(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at mean,
                @Const @ByRef primitive.at variance, @Const @ByRef memory dst) { super((Pointer)null); allocate(aprimitive_desc, src, mean, variance, dst); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at mean,
                @Const @ByRef primitive.at variance, @Const @ByRef memory dst);

    /** \warning batch_normalization_forward has 2 constructors with very
     *           similar signatures:
     *            - (pd, src, weights, dst, mean, variance) // 2 in, 3 out
     *            - (pd, src, dst, mean, variance, workspace) // 1 in, 4 out
     *           The only way to distinguish between those is to explicitly
     *           cast all input parameters to their type, i.e. to
     *           const primitive:at &. */
    public batch_normalization_forward(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at weights,
                @Const @ByRef memory dst, @Const @ByRef memory mean, @Const @ByRef memory variance) { super((Pointer)null); allocate(aprimitive_desc, src, weights, dst, mean, variance); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at weights,
                @Const @ByRef memory dst, @Const @ByRef memory mean, @Const @ByRef memory variance);

    public batch_normalization_forward(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at weights,
                @Const @ByRef memory dst, @Const @ByRef memory mean, @Const @ByRef memory variance,
                @Const @ByRef memory workspace) { super((Pointer)null); allocate(aprimitive_desc, src, weights, dst, mean, variance, workspace); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at weights,
                @Const @ByRef memory dst, @Const @ByRef memory mean, @Const @ByRef memory variance,
                @Const @ByRef memory workspace);

    public batch_normalization_forward(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef memory dst, @Const @ByRef memory mean,
                @Const @ByRef memory variance) { super((Pointer)null); allocate(aprimitive_desc, src, dst, mean, variance); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef memory dst, @Const @ByRef memory mean,
                @Const @ByRef memory variance);

    /** \warning batch_normalization_forward has 2 constructors with very
     *           similar signatures:
     *            - (pd, src, weights, dst, mean, variance) // 2 in, 3 out
     *            - (pd, src, dst, mean, variance, workspace) // 1 in, 4 out
     *           The only way to distinguish between those is to explicitly
     *           cast all input parameters to their type, i.e. to
     *           const primitive:at &.
     *  \note to make users' experience a little bit better this constructor
     *        checks if whether parameters match corresponding primitive
     *        descriptor, and if they are not -- call the other (proper)
     *        constructor. Yeah, this is still very ugly... */
    public batch_normalization_forward(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef memory dst, @Const @ByRef memory mean,
                @Const @ByRef memory variance, @Const @ByRef memory workspace) { super((Pointer)null); allocate(aprimitive_desc, src, dst, mean, variance, workspace); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef memory dst, @Const @ByRef memory mean,
                @Const @ByRef memory variance, @Const @ByRef memory workspace);

    public batch_normalization_forward(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at weights,
                @Const @ByRef memory dst) { super((Pointer)null); allocate(aprimitive_desc, src, weights, dst); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at weights,
                @Const @ByRef memory dst);

    public batch_normalization_forward(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef memory dst) { super((Pointer)null); allocate(aprimitive_desc, src, dst); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef memory dst);
}

@Namespace("mkldnn") public static class batch_normalization_backward extends primitive {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public batch_normalization_backward(Pointer p) { super(p); }

    @NoOffset public static class desc extends Pointer {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public desc(Pointer p) { super(p); }
    
        public native @ByRef mkldnn_batch_normalization_desc_t data(); public native desc data(mkldnn_batch_normalization_desc_t data);
        public desc(@Cast("mkldnn::prop_kind") int aprop_kind, @Const @ByRef memory.desc diff_data_desc,
                        @Const @ByRef memory.desc data_desc, float epsilon, @Cast("unsigned") int flags) { super((Pointer)null); allocate(aprop_kind, diff_data_desc, data_desc, epsilon, flags); }
        private native void allocate(@Cast("mkldnn::prop_kind") int aprop_kind, @Const @ByRef memory.desc diff_data_desc,
                        @Const @ByRef memory.desc data_desc, float epsilon, @Cast("unsigned") int flags);
    }

    public static class primitive_desc extends mkldnn.primitive_desc {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public primitive_desc(Pointer p) { super(p); }
    
        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef engine e,
                        @Const @ByRef batch_normalization_forward.primitive_desc hint_fwd_pd) { super((Pointer)null); allocate(desc, e, hint_fwd_pd); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef engine e,
                        @Const @ByRef batch_normalization_forward.primitive_desc hint_fwd_pd);

        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e,
                        @Const @ByRef batch_normalization_forward.primitive_desc hint_fwd_pd) { super((Pointer)null); allocate(desc, attr, e, hint_fwd_pd); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e,
                        @Const @ByRef batch_normalization_forward.primitive_desc hint_fwd_pd);

        public native @ByVal memory.primitive_desc src_primitive_desc();
        public native @ByVal memory.primitive_desc mean_primitive_desc();
        public native @ByVal memory.primitive_desc variance_primitive_desc();
        public native @ByVal memory.primitive_desc weights_primitive_desc();
        public native @ByVal memory.primitive_desc dst_primitive_desc();
        public native @ByVal memory.primitive_desc diff_dst_primitive_desc();
        public native @ByVal memory.primitive_desc workspace_primitive_desc();

        public native @ByVal memory.primitive_desc diff_src_primitive_desc();
        public native @ByVal memory.primitive_desc diff_weights_primitive_desc();
    }

    // Prop_kind == backward
    public batch_normalization_backward(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at mean,
                @Const @ByRef primitive.at variance, @Const @ByRef primitive.at diff_dst,
                @Const @ByRef primitive.at weights, @Const @ByRef memory diff_src,
                @Const @ByRef memory diff_weights) { super((Pointer)null); allocate(aprimitive_desc, src, mean, variance, diff_dst, weights, diff_src, diff_weights); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at mean,
                @Const @ByRef primitive.at variance, @Const @ByRef primitive.at diff_dst,
                @Const @ByRef primitive.at weights, @Const @ByRef memory diff_src,
                @Const @ByRef memory diff_weights);

    // Prop_kind == backward (+ws)
    public batch_normalization_backward(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at mean,
                @Const @ByRef primitive.at variance, @Const @ByRef primitive.at diff_dst,
                @Const @ByRef primitive.at weights, @Const @ByRef primitive.at workspace,
                @Const @ByRef memory diff_src, @Const @ByRef memory diff_weights) { super((Pointer)null); allocate(aprimitive_desc, src, mean, variance, diff_dst, weights, workspace, diff_src, diff_weights); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at mean,
                @Const @ByRef primitive.at variance, @Const @ByRef primitive.at diff_dst,
                @Const @ByRef primitive.at weights, @Const @ByRef primitive.at workspace,
                @Const @ByRef memory diff_src, @Const @ByRef memory diff_weights);

    // Prop_kind == backward_data (+ws or +weights)
    /** \warning This constructor works for backward_data propagation
     *           - w/ weights but w/o workspace, or
     *           - w/ workspace but w/o weights */
    public batch_normalization_backward(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at mean,
                @Const @ByRef primitive.at variance,@Const @ByRef primitive.at diff_dst,
                @Const @ByRef primitive.at weights_or_workspace, @Const @ByRef memory diff_src) { super((Pointer)null); allocate(aprimitive_desc, src, mean, variance, diff_dst, weights_or_workspace, diff_src); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at mean,
                @Const @ByRef primitive.at variance,@Const @ByRef primitive.at diff_dst,
                @Const @ByRef primitive.at weights_or_workspace, @Const @ByRef memory diff_src);

    // Prop_kind == backward_data
    public batch_normalization_backward(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at mean,
                @Const @ByRef primitive.at variance, @Const @ByRef primitive.at diff_dst,
                @Const @ByRef memory diff_src) { super((Pointer)null); allocate(aprimitive_desc, src, mean, variance, diff_dst, diff_src); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef primitive.at mean,
                @Const @ByRef primitive.at variance, @Const @ByRef primitive.at diff_dst,
                @Const @ByRef memory diff_src);
}

/** \}
 <p>
 *  \addtogroup cpp_api_inner_product Inner Product
 *  A primitive to compute an inner product.
 * 
 *  \sa \ref c_api_inner_product in \ref c_api
 *  \{ */

@Namespace("mkldnn") public static class inner_product_forward extends primitive {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public inner_product_forward(Pointer p) { super(p); }

    @NoOffset public static class desc extends Pointer {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public desc(Pointer p) { super(p); }
    
        public native @ByRef mkldnn_inner_product_desc_t data(); public native desc data(mkldnn_inner_product_desc_t data);
        public desc(@Cast("mkldnn::prop_kind") int aprop_kind, @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc bias_desc,
                        @Const @ByRef memory.desc dst_desc) { super((Pointer)null); allocate(aprop_kind, src_desc, weights_desc, bias_desc, dst_desc); }
        private native void allocate(@Cast("mkldnn::prop_kind") int aprop_kind, @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc bias_desc,
                        @Const @ByRef memory.desc dst_desc);

        public desc(@Cast("mkldnn::prop_kind") int aprop_kind, @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc dst_desc) { super((Pointer)null); allocate(aprop_kind, src_desc, weights_desc, dst_desc); }
        private native void allocate(@Cast("mkldnn::prop_kind") int aprop_kind, @Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc dst_desc);
    }

    public static class primitive_desc extends mkldnn.primitive_desc {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public primitive_desc(Pointer p) { super(p); }
    
        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef engine e) { super((Pointer)null); allocate(desc, e); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef engine e);

        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e) { super((Pointer)null); allocate(desc, attr, e); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e);

        public native @ByVal memory.primitive_desc src_primitive_desc();
        public native @ByVal memory.primitive_desc weights_primitive_desc();
        public native @ByVal memory.primitive_desc bias_primitive_desc();
        public native @ByVal memory.primitive_desc dst_primitive_desc();
    }

    public inner_product_forward(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByVal primitive.at weights,
                @Const @ByRef primitive.at bias, @Const @ByRef memory dst) { super((Pointer)null); allocate(aprimitive_desc, src, weights, bias, dst); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByVal primitive.at weights,
                @Const @ByRef primitive.at bias, @Const @ByRef memory dst);

    public inner_product_forward(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByVal primitive.at weights,
                @Const @ByRef memory dst) { super((Pointer)null); allocate(aprimitive_desc, src, weights, dst); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByVal primitive.at weights,
                @Const @ByRef memory dst);
}

@Namespace("mkldnn") public static class inner_product_backward_data extends primitive {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public inner_product_backward_data(Pointer p) { super(p); }

    @NoOffset public static class desc extends Pointer {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public desc(Pointer p) { super(p); }
    
        public native @ByRef mkldnn_inner_product_desc_t data(); public native desc data(mkldnn_inner_product_desc_t data);
        public desc(@Const @ByRef memory.desc diff_src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc) { super((Pointer)null); allocate(diff_src_desc, weights_desc, diff_dst_desc); }
        private native void allocate(@Const @ByRef memory.desc diff_src_desc,
                        @Const @ByRef memory.desc weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc);
    }

    public static class primitive_desc extends mkldnn.primitive_desc {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public primitive_desc(Pointer p) { super(p); }
    
        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef engine e,
                        @Const @ByRef inner_product_forward.primitive_desc hint_fwd_pd) { super((Pointer)null); allocate(desc, e, hint_fwd_pd); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef engine e,
                        @Const @ByRef inner_product_forward.primitive_desc hint_fwd_pd);

        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e,
                        @Const @ByRef inner_product_forward.primitive_desc hint_fwd_pd) { super((Pointer)null); allocate(desc, attr, e, hint_fwd_pd); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e,
                        @Const @ByRef inner_product_forward.primitive_desc hint_fwd_pd);

        public native @ByVal memory.primitive_desc diff_src_primitive_desc();
        public native @ByVal memory.primitive_desc weights_primitive_desc();
        public native @ByVal memory.primitive_desc diff_dst_primitive_desc();
    }

    public inner_product_backward_data(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at diff_dst, @Const @ByVal primitive.at weights,
                @Const @ByRef memory diff_src) { super((Pointer)null); allocate(aprimitive_desc, diff_dst, weights, diff_src); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at diff_dst, @Const @ByVal primitive.at weights,
                @Const @ByRef memory diff_src);
}

@Namespace("mkldnn") public static class inner_product_backward_weights extends primitive {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public inner_product_backward_weights(Pointer p) { super(p); }

    @NoOffset public static class desc extends Pointer {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public desc(Pointer p) { super(p); }
    
        public native @ByRef mkldnn_inner_product_desc_t data(); public native desc data(mkldnn_inner_product_desc_t data);
        public desc(@Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_bias_desc,
                        @Const @ByRef memory.desc diff_dst_desc) { super((Pointer)null); allocate(src_desc, diff_weights_desc, diff_bias_desc, diff_dst_desc); }
        private native void allocate(@Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_bias_desc,
                        @Const @ByRef memory.desc diff_dst_desc);
        public desc(@Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc) { super((Pointer)null); allocate(src_desc, diff_weights_desc, diff_dst_desc); }
        private native void allocate(@Const @ByRef memory.desc src_desc,
                        @Const @ByRef memory.desc diff_weights_desc,
                        @Const @ByRef memory.desc diff_dst_desc);
    }

    public static class primitive_desc extends mkldnn.primitive_desc {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public primitive_desc(Pointer p) { super(p); }
    
        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef engine e,
                        @Const @ByRef inner_product_forward.primitive_desc hint_fwd_pd) { super((Pointer)null); allocate(desc, e, hint_fwd_pd); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef engine e,
                        @Const @ByRef inner_product_forward.primitive_desc hint_fwd_pd);

        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e,
                        @Const @ByRef inner_product_forward.primitive_desc hint_fwd_pd) { super((Pointer)null); allocate(desc, attr, e, hint_fwd_pd); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e,
                        @Const @ByRef inner_product_forward.primitive_desc hint_fwd_pd);

        public native @ByVal memory.primitive_desc src_primitive_desc();
        public native @ByVal memory.primitive_desc diff_weights_primitive_desc();
        public native @ByVal memory.primitive_desc diff_bias_primitive_desc();
        public native @ByVal memory.primitive_desc diff_dst_primitive_desc();
    }

    public inner_product_backward_weights(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByVal primitive.at diff_dst,
                @Const @ByRef memory diff_weights) { super((Pointer)null); allocate(aprimitive_desc, src, diff_dst, diff_weights); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByVal primitive.at diff_dst,
                @Const @ByRef memory diff_weights);

    public inner_product_backward_weights(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByVal primitive.at diff_dst,
                @Const @ByRef memory diff_weights, @Const @ByRef memory diff_bias) { super((Pointer)null); allocate(aprimitive_desc, src, diff_dst, diff_weights, diff_bias); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByVal primitive.at diff_dst,
                @Const @ByRef memory diff_weights, @Const @ByRef memory diff_bias);
}

/** \}
 <p>
 *  \addtogroup cpp_api_rnn RNN
 *  A primitive to compute common recurrent layer.
 * 
 *  \sa \ref c_api_rnn in \ref c_api
 *  \{ */

@Namespace("mkldnn") public static class rnn_cell extends Pointer {
    static { Loader.load(); }
    /** Default native constructor. */
    public rnn_cell() { super((Pointer)null); allocate(); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public rnn_cell(long size) { super((Pointer)null); allocateArray(size); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public rnn_cell(Pointer p) { super(p); }
    private native void allocate();
    private native void allocateArray(long size);
    @Override public rnn_cell position(long position) {
        return (rnn_cell)super.position(position);
    }

    @NoOffset public static class desc extends Pointer {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public desc(Pointer p) { super(p); }
    
        public native @ByRef mkldnn_rnn_cell_desc_t c_rnn_cell_(); public native desc c_rnn_cell_(mkldnn_rnn_cell_desc_t c_rnn_cell_);

        public desc(@Cast("mkldnn::algorithm") int kind, @Cast("mkldnn::algorithm") int activation_f) { super((Pointer)null); allocate(kind, activation_f); }
        private native void allocate(@Cast("mkldnn::algorithm") int kind, @Cast("mkldnn::algorithm") int activation_f);
        public desc(@Cast("mkldnn::algorithm") int kind) { super((Pointer)null); allocate(kind); }
        private native void allocate(@Cast("mkldnn::algorithm") int kind);

        public native @Name("operator const mkldnn_rnn_cell_desc_t*") @Const mkldnn_rnn_cell_desc_t as_mkldnn_rnn_cell_desc_t();

        public native @Cast("mkldnn::algorithm") int get_cell_kind();
        public native @Cast("mkldnn::algorithm") int get_activation();

        public native float get_alpha();
        public native void set_alpha(float alpha);

        public native float get_clipping();
        public native void set_clipping(float clipping);

        public native int get_gates_count();
        public native int get_state_count();
    }
}

@Namespace("mkldnn") public static class rnn_forward extends primitive {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public rnn_forward(Pointer p) { super(p); }

    @NoOffset public static class desc extends Pointer {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public desc(Pointer p) { super(p); }
    
        public native @ByRef mkldnn_rnn_desc_t data(); public native desc data(mkldnn_rnn_desc_t data);
        public desc(@Cast("mkldnn::prop_kind") int aprop_kind, @ByVal rnn_cell.desc cell,
                        @Cast("const mkldnn::rnn_direction") int direction,
                        @Const @ByRef memory.desc src_layer_desc,
                        @Const @ByRef memory.desc src_iter_desc,
                        @Const @ByRef memory.desc weights_layer_desc,
                        @Const @ByRef memory.desc weights_iter_desc,
                        @Const @ByRef memory.desc bias_desc,
                        @Const @ByRef memory.desc dst_layer_desc,
                        @Const @ByRef memory.desc dst_iter_desc
                    ) { super((Pointer)null); allocate(aprop_kind, cell, direction, src_layer_desc, src_iter_desc, weights_layer_desc, weights_iter_desc, bias_desc, dst_layer_desc, dst_iter_desc); }
        private native void allocate(@Cast("mkldnn::prop_kind") int aprop_kind, @ByVal rnn_cell.desc cell,
                        @Cast("const mkldnn::rnn_direction") int direction,
                        @Const @ByRef memory.desc src_layer_desc,
                        @Const @ByRef memory.desc src_iter_desc,
                        @Const @ByRef memory.desc weights_layer_desc,
                        @Const @ByRef memory.desc weights_iter_desc,
                        @Const @ByRef memory.desc bias_desc,
                        @Const @ByRef memory.desc dst_layer_desc,
                        @Const @ByRef memory.desc dst_iter_desc
                    );

    }

    public static class primitive_desc extends mkldnn.primitive_desc {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public primitive_desc(Pointer p) { super(p); }
    
        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef engine e) { super((Pointer)null); allocate(desc, e); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef engine e);

        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e) { super((Pointer)null); allocate(desc, attr, e); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e);

        public native @ByVal memory.primitive_desc src_layer_primitive_desc();
        public native @ByVal memory.primitive_desc src_iter_primitive_desc();
        public native @ByVal memory.primitive_desc weights_layer_primitive_desc();
        public native @ByVal memory.primitive_desc weights_iter_primitive_desc();
        public native @ByVal memory.primitive_desc bias_primitive_desc();
        public native @ByVal memory.primitive_desc dst_layer_primitive_desc();
        public native @ByVal memory.primitive_desc dst_iter_primitive_desc();
        public native @ByVal memory.primitive_desc workspace_primitive_desc();
    }

    public rnn_forward(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src_layer, @Const @ByRef primitive.at src_iter,
                @Const @ByRef primitive.at weights_layer,
                @Const @ByRef primitive.at weights_iter, @Const @ByRef primitive.at bias,
                @Const @ByRef memory dst_layer, @Const @ByRef memory dst_iter,
                @Const @ByRef memory workspace) { super((Pointer)null); allocate(aprimitive_desc, src_layer, src_iter, weights_layer, weights_iter, bias, dst_layer, dst_iter, workspace); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src_layer, @Const @ByRef primitive.at src_iter,
                @Const @ByRef primitive.at weights_layer,
                @Const @ByRef primitive.at weights_iter, @Const @ByRef primitive.at bias,
                @Const @ByRef memory dst_layer, @Const @ByRef memory dst_iter,
                @Const @ByRef memory workspace);
}

@Namespace("mkldnn") public static class rnn_backward extends primitive {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public rnn_backward(Pointer p) { super(p); }

    @NoOffset public static class desc extends Pointer {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public desc(Pointer p) { super(p); }
    
        public native @ByRef mkldnn_rnn_desc_t data(); public native desc data(mkldnn_rnn_desc_t data);
        public desc(@Cast("mkldnn::prop_kind") int aprop_kind, @ByVal rnn_cell.desc cell,
                        @Cast("const mkldnn::rnn_direction") int direction,
                        @Const @ByRef memory.desc src_layer_desc,
                        @Const @ByRef memory.desc src_iter_desc,
                        @Const @ByRef memory.desc weights_layer_desc,
                        @Const @ByRef memory.desc weights_iter_desc,
                        @Const @ByRef memory.desc bias_desc,
                        @Const @ByRef memory.desc dst_layer_desc,
                        @Const @ByRef memory.desc dst_iter_desc,
                        @Const @ByRef memory.desc diff_src_layer_desc,
                        @Const @ByRef memory.desc diff_src_iter_desc,
                        @Const @ByRef memory.desc diff_weights_layer_desc,
                        @Const @ByRef memory.desc diff_weights_iter_desc,
                        @Const @ByRef memory.desc diff_bias_desc,
                        @Const @ByRef memory.desc diff_dst_layer_desc,
                        @Const @ByRef memory.desc diff_dst_iter_desc) { super((Pointer)null); allocate(aprop_kind, cell, direction, src_layer_desc, src_iter_desc, weights_layer_desc, weights_iter_desc, bias_desc, dst_layer_desc, dst_iter_desc, diff_src_layer_desc, diff_src_iter_desc, diff_weights_layer_desc, diff_weights_iter_desc, diff_bias_desc, diff_dst_layer_desc, diff_dst_iter_desc); }
        private native void allocate(@Cast("mkldnn::prop_kind") int aprop_kind, @ByVal rnn_cell.desc cell,
                        @Cast("const mkldnn::rnn_direction") int direction,
                        @Const @ByRef memory.desc src_layer_desc,
                        @Const @ByRef memory.desc src_iter_desc,
                        @Const @ByRef memory.desc weights_layer_desc,
                        @Const @ByRef memory.desc weights_iter_desc,
                        @Const @ByRef memory.desc bias_desc,
                        @Const @ByRef memory.desc dst_layer_desc,
                        @Const @ByRef memory.desc dst_iter_desc,
                        @Const @ByRef memory.desc diff_src_layer_desc,
                        @Const @ByRef memory.desc diff_src_iter_desc,
                        @Const @ByRef memory.desc diff_weights_layer_desc,
                        @Const @ByRef memory.desc diff_weights_iter_desc,
                        @Const @ByRef memory.desc diff_bias_desc,
                        @Const @ByRef memory.desc diff_dst_layer_desc,
                        @Const @ByRef memory.desc diff_dst_iter_desc);

    }

    public static class primitive_desc extends mkldnn.primitive_desc {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public primitive_desc(Pointer p) { super(p); }
    
        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef engine e) { super((Pointer)null); allocate(desc, e); }
        private native @Deprecated void allocate(@Const @ByRef desc desc, @Const @ByRef engine e);

        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef engine e,
                        @Const @ByRef rnn_forward.primitive_desc hint_fwd_pd) { super((Pointer)null); allocate(desc, e, hint_fwd_pd); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef engine e,
                        @Const @ByRef rnn_forward.primitive_desc hint_fwd_pd);

        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e,
                        @Const @ByRef rnn_forward.primitive_desc hint_fwd_pd) { super((Pointer)null); allocate(desc, attr, e, hint_fwd_pd); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef primitive_attr attr, @Const @ByRef engine e,
                        @Const @ByRef rnn_forward.primitive_desc hint_fwd_pd);

        public native @ByVal memory.primitive_desc src_layer_primitive_desc();
        public native @ByVal memory.primitive_desc src_iter_primitive_desc();
        public native @ByVal memory.primitive_desc weights_layer_primitive_desc();
        public native @ByVal memory.primitive_desc weights_iter_primitive_desc();
        public native @ByVal memory.primitive_desc bias_primitive_desc();
        public native @ByVal memory.primitive_desc dst_layer_primitive_desc();
        public native @ByVal memory.primitive_desc dst_iter_primitive_desc();
        public native @ByVal memory.primitive_desc workspace_primitive_desc();

        public native @ByVal memory.primitive_desc diff_src_layer_primitive_desc();
        public native @ByVal memory.primitive_desc diff_src_iter_primitive_desc();
        public native @ByVal memory.primitive_desc diff_weights_layer_primitive_desc();
        public native @ByVal memory.primitive_desc diff_weights_iter_primitive_desc();
        public native @ByVal memory.primitive_desc diff_bias_primitive_desc();
        public native @ByVal memory.primitive_desc diff_dst_layer_primitive_desc();
        public native @ByVal memory.primitive_desc diff_dst_iter_primitive_desc();
    }

    // With last iteration (with and without input src_iter)
    public rnn_backward(@Const @ByRef primitive_desc aprimitive_desc,
                     @Const @ByRef primitive.at src_layer,
                     @Const @ByRef primitive.at src_iter,
                     @Const @ByRef primitive.at weights_layer,
                     @Const @ByRef primitive.at weights_iter,
                     @Const @ByRef primitive.at bias,
                     @Const @ByRef primitive.at dst_layer,
                     @Const @ByRef primitive.at dst_iter,
                     @Const @ByRef memory diff_src_layer,
                     @Const @ByRef memory diff_src_iter,
                     @Const @ByRef memory diff_weights_layer,
                     @Const @ByRef memory diff_weights_iter,
                     @Const @ByRef memory diff_bias,
                     @Const @ByRef primitive.at diff_dst_layer,
                     @Const @ByRef primitive.at diff_dst_iter,
                     @Const @ByRef primitive.at workspace) { super((Pointer)null); allocate(aprimitive_desc, src_layer, src_iter, weights_layer, weights_iter, bias, dst_layer, dst_iter, diff_src_layer, diff_src_iter, diff_weights_layer, diff_weights_iter, diff_bias, diff_dst_layer, diff_dst_iter, workspace); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                     @Const @ByRef primitive.at src_layer,
                     @Const @ByRef primitive.at src_iter,
                     @Const @ByRef primitive.at weights_layer,
                     @Const @ByRef primitive.at weights_iter,
                     @Const @ByRef primitive.at bias,
                     @Const @ByRef primitive.at dst_layer,
                     @Const @ByRef primitive.at dst_iter,
                     @Const @ByRef memory diff_src_layer,
                     @Const @ByRef memory diff_src_iter,
                     @Const @ByRef memory diff_weights_layer,
                     @Const @ByRef memory diff_weights_iter,
                     @Const @ByRef memory diff_bias,
                     @Const @ByRef primitive.at diff_dst_layer,
                     @Const @ByRef primitive.at diff_dst_iter,
                     @Const @ByRef primitive.at workspace);
}

/** \}
 <p>
 *  \addtogroup cpp_api_shuffle Shuffle
 *  A primitive to shuffle data along the axis.
 * 
 *  \sa \ref c_api_shuffle in \ref c_api
 *  \{ */

@Namespace("mkldnn") public static class shuffle_forward extends primitive {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public shuffle_forward(Pointer p) { super(p); }

    @NoOffset public static class desc extends Pointer {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public desc(Pointer p) { super(p); }
    
        public native @ByRef mkldnn_shuffle_desc_t data(); public native desc data(mkldnn_shuffle_desc_t data);
        public desc(@Cast("mkldnn::prop_kind") int aprop_kind, @Const @ByRef memory.desc data_desc,
                        int axis, int group_size) { super((Pointer)null); allocate(aprop_kind, data_desc, axis, group_size); }
        private native void allocate(@Cast("mkldnn::prop_kind") int aprop_kind, @Const @ByRef memory.desc data_desc,
                        int axis, int group_size);
    }

    public static class primitive_desc extends mkldnn.primitive_desc {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public primitive_desc(Pointer p) { super(p); }
    
        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef engine e) { super((Pointer)null); allocate(desc, e); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef engine e);

        public native @ByVal memory.primitive_desc src_primitive_desc();
        public native @ByVal memory.primitive_desc dst_primitive_desc();
    }

    public shuffle_forward(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef memory dst) { super((Pointer)null); allocate(aprimitive_desc, src, dst); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at src, @Const @ByRef memory dst);
}

@Namespace("mkldnn") public static class shuffle_backward extends primitive {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public shuffle_backward(Pointer p) { super(p); }

    @NoOffset public static class desc extends Pointer {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public desc(Pointer p) { super(p); }
    
        public native @ByRef mkldnn_shuffle_desc_t data(); public native desc data(mkldnn_shuffle_desc_t data);
        public desc(@Const @ByRef memory.desc diff_data_desc, int axis, int group_size) { super((Pointer)null); allocate(diff_data_desc, axis, group_size); }
        private native void allocate(@Const @ByRef memory.desc diff_data_desc, int axis, int group_size);
    }

    public static class primitive_desc extends mkldnn.primitive_desc {
        static { Loader.load(); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public primitive_desc(Pointer p) { super(p); }
    
        public primitive_desc(@Const @ByRef desc desc, @Const @ByRef engine e,
                        @Const @ByRef shuffle_forward.primitive_desc hint_fwd_pd) { super((Pointer)null); allocate(desc, e, hint_fwd_pd); }
        private native void allocate(@Const @ByRef desc desc, @Const @ByRef engine e,
                        @Const @ByRef shuffle_forward.primitive_desc hint_fwd_pd);

        public native @ByVal memory.primitive_desc diff_src_primitive_desc();
        public native @ByVal memory.primitive_desc diff_dst_primitive_desc();
    }

    public shuffle_backward(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at diff_dst, @Const @ByRef memory diff_src) { super((Pointer)null); allocate(aprimitive_desc, diff_dst, diff_src); }
    private native void allocate(@Const @ByRef primitive_desc aprimitive_desc,
                @Const @ByRef primitive.at diff_dst, @Const @ByRef memory diff_src);
}

/** \}
 <p>
 *  \} Primitives
 <p>
 *  \addtogroup cpp_api_stream Stream
 *  Execution stream operations
 * 
 *  \sa \ref c_api_stream in \ref c_api
 *  \{ */

// #ifndef DOXYGEN_SHOULD_SKIP_THIS
// #endif

@Namespace("mkldnn") public static class stream extends mkldnn_stream_handle {
    static { Loader.load(); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public stream(Pointer p) { super(p); }


    /** enum mkldnn::stream::kind */
    public static final int any = mkldnn_any_stream,
        eager = mkldnn_eager,
        lazy = mkldnn_lazy;

    public static native @Cast("mkldnn_stream_kind_t") int convert_to_c(@Cast("mkldnn::stream::kind") int akind);
    /** Constructs a stream. */
    
    ///
    public stream(@Cast("mkldnn::stream::kind") int akind) { super((Pointer)null); allocate(akind); }
    private native void allocate(@Cast("mkldnn::stream::kind") int akind);

    /** Submits a vector of primitives to a stream for computations.
     * 
     *  @param primitives The vector of primitives to submit.
     *  @return The stream. */
    
    ///
    public native @ByRef stream submit(@ByVal primitive_vector primitives);

    /** Waits for all computations submitted to the stream to complete.
     * 
     *  @param block Specifies whether the operation should wait indefinitely or return
     *               immediately.
     *  @return \c true if all computations completed.
     *  @return \c false if not all computations completed. */
    public native @Cast("bool") @Name("wait") boolean _wait(@Cast("bool") boolean block/*=true*/);
    public native @Cast("bool") @Name("wait") boolean _wait();

    public native @ByRef stream rerun();
}

// #undef REG_QUERY_MPD

/** \}
 <p>
 *  \} C++ API */

 // namespace mkldnn

// #endif


}
